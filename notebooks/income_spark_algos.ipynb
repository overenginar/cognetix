{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3fd977-3107-4150-b241-c18247ac2d48",
   "metadata": {},
   "source": [
    "## Income Prediction with Spark Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b019947-3e52-4742-9a33-8dc33d9f32a3",
   "metadata": {},
   "source": [
    "### Install findspark and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0156047-cfe9-47e1-9622-74666342340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.9/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c38bc1-77fa-400a-b944-44e1d20757aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1712a2-81a4-459c-8e36-c7317a52a07c",
   "metadata": {},
   "source": [
    "### Get spark and h2o sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd3e1e6-51bf-41ad-ab4a-d08c1ef14cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/10/20 20:31:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:31:35.423 172.17.0.2:54321      18300    Thread-4  INFO water.default: ----- H2O started  -----\n",
      "10-20 20:31:35.425 172.17.0.2:54321      18300    Thread-4  INFO water.default: Build git branch: rel-zz_kurka\n",
      "10-20 20:31:35.425 172.17.0.2:54321      18300    Thread-4  INFO water.default: Build git hash: 5ff8870f912c6110d7b6988f577c020de10496ec\n",
      "10-20 20:31:35.425 172.17.0.2:54321      18300    Thread-4  INFO water.default: Build git describe: jenkins-3.40.0.3-122-g5ff8870\n",
      "10-20 20:31:35.425 172.17.0.2:54321      18300    Thread-4  INFO water.default: Build project version: 3.40.0.4\n",
      "10-20 20:31:35.425 172.17.0.2:54321      18300    Thread-4  INFO water.default: Build age: 5 months and 22 days\n",
      "10-20 20:31:35.425 172.17.0.2:54321      18300    Thread-4  INFO water.default: Built by: 'jenkins'\n",
      "10-20 20:31:35.426 172.17.0.2:54321      18300    Thread-4  INFO water.default: Built on: '2023-04-28 12:08:23'\n",
      "10-20 20:31:35.426 172.17.0.2:54321      18300    Thread-4  WARN water.default: \n",
      "10-20 20:31:35.426 172.17.0.2:54321      18300    Thread-4  WARN water.default: *** Your H2O version is over 100 days old. Please download the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html ***\n",
      "10-20 20:31:35.427 172.17.0.2:54321      18300    Thread-4  WARN water.default: \n",
      "10-20 20:31:35.427 172.17.0.2:54321      18300    Thread-4  INFO water.default: Found H2O Core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 20:31:35.427 172.17.0.2:54321      18300    Thread-4  INFO water.default: Processed H2O arguments: [-internal_security_conf_rel_paths, -name, sparkling-water-root_local-1697833892184, -port_offset, 1, -hdfs_config, /tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/userFiles-3b11f810-57f4-4b38-a91b-0c384dbcac98/hdfs_conf13839494150648595978.xml, -log_level, INFO, -embedded, -baseport, 54321, -log_dir, /home/jovyan/notebooks/h2ologs/local-1697833892184, -quiet, -flatfile, /tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/sparkling-water-53ac259c-ada6-4cde-aaa6-4b1e58f3b871/flatfile.txt]\n",
      "10-20 20:31:35.427 172.17.0.2:54321      18300    Thread-4  INFO water.default: Java availableProcessors: 4\n",
      "10-20 20:31:35.427 172.17.0.2:54321      18300    Thread-4  INFO water.default: Java heap totalMemory: 138.0 MB\n",
      "10-20 20:31:35.427 172.17.0.2:54321      18300    Thread-4  INFO water.default: Java heap maxMemory: 1.00 GB\n",
      "10-20 20:31:35.428 172.17.0.2:54321      18300    Thread-4  INFO water.default: Java version: Java 11.0.11 (from Ubuntu)\n",
      "10-20 20:31:35.428 172.17.0.2:54321      18300    Thread-4  INFO water.default: JVM launch parameters: [-Xmx1g, -Dio.netty.tryReflectionSetAccessible=true]\n",
      "10-20 20:31:35.428 172.17.0.2:54321      18300    Thread-4  INFO water.default: JVM process id: 18300@5b5a8eb7561c\n",
      "10-20 20:31:35.428 172.17.0.2:54321      18300    Thread-4  INFO water.default: OS version: Linux 5.15.49-linuxkit-pr (amd64)\n",
      "10-20 20:31:35.428 172.17.0.2:54321      18300    Thread-4  INFO water.default: Machine physical memory: 5.80 GB\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: Machine locale: en_US\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: X-h2o-cluster-id: 1697833894199\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: User name: 'root'\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: IPv6 stack selected: false\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: Possible IP Address: eth0 (eth0), 172.17.0.2\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: Possible IP Address: lo (lo), 127.0.0.1\n",
      "10-20 20:31:35.429 172.17.0.2:54321      18300    Thread-4  INFO water.default: H2O node running in unencrypted mode.\n",
      "10-20 20:31:35.431 172.17.0.2:54321      18300    Thread-4  INFO water.default: Internal communication uses port: 54322\n",
      "10-20 20:31:35.431 172.17.0.2:54321      18300    Thread-4  INFO water.default: Listening for HTTP and REST traffic on http://172.17.0.2:54321/\n",
      "10-20 20:31:35.432 172.17.0.2:54321      18300    Thread-4  WARN water.default: Flatfile configuration does not include self: /172.17.0.2:54321, but contains []\n",
      "10-20 20:31:35.433 172.17.0.2:54321      18300    Thread-4  INFO water.default: H2O cloud name: 'sparkling-water-root_local-1697833892184' on /172.17.0.2:54321, static configuration based on -flatfile /tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/sparkling-water-53ac259c-ada6-4cde-aaa6-4b1e58f3b871/flatfile.txt\n",
      "10-20 20:31:35.433 172.17.0.2:54321      18300    Thread-4  INFO water.default: If you have trouble connecting, try SSH tunneling from your local machine (e.g., via port 55555):\n",
      "10-20 20:31:35.433 172.17.0.2:54321      18300    Thread-4  INFO water.default:   1. Open a terminal and run 'ssh -L 55555:localhost:54321 root@172.17.0.2'\n",
      "10-20 20:31:35.434 172.17.0.2:54321      18300    Thread-4  INFO water.default:   2. Point your browser to http://localhost:55555\n",
      "10-20 20:31:35.850 172.17.0.2:54321      18300    Thread-4  INFO water.default: Log dir: '/home/jovyan/notebooks/h2ologs/local-1697833892184'\n",
      "10-20 20:31:35.850 172.17.0.2:54321      18300    Thread-4  INFO water.default: Cur dir: '/home/jovyan/notebooks'\n",
      "10-20 20:31:35.860 172.17.0.2:54321      18300    Thread-4  INFO water.default: Distributed HTTP import not available (import from HTTP/HTTPS will be eager)\n",
      "10-20 20:31:35.876 172.17.0.2:54321      18300    Thread-4  INFO water.default: HDFS subsystem successfully initialized\n",
      "10-20 20:31:35.887 172.17.0.2:54321      18300    Thread-4  INFO water.default: S3 subsystem successfully initialized\n",
      "10-20 20:31:35.909 172.17.0.2:54321      18300    Thread-4  INFO water.default: GCS subsystem successfully initialized\n",
      "10-20 20:31:35.909 172.17.0.2:54321      18300    Thread-4  INFO water.default: Drive subsystem not available\n",
      "10-20 20:31:35.910 172.17.0.2:54321      18300    Thread-4  INFO water.default: Flow dir: '/root/h2oflows'\n",
      "10-20 20:31:35.921 172.17.0.2:54321      18300    Thread-4  INFO water.default: Cloud of size 1 formed [5b5a8eb7561c/172.17.0.2:54321]\n",
      "10-20 20:31:35.934 172.17.0.2:54321      18300    Thread-4  INFO water.default: Registered parsers: [GUESS, ARFF, XLS, SVMLight, AVRO, PARQUET, ORC, CSV]\n",
      "10-20 20:31:35.936 172.17.0.2:54321      18300    Thread-4  INFO water.default: HiveTableImporter extension initialized\n",
      "10-20 20:31:35.937 172.17.0.2:54321      18300    Thread-4  INFO water.default: StackTraceCollector extension initialized\n",
      "10-20 20:31:35.938 172.17.0.2:54321      18300    Thread-4  INFO water.default: MojoPipeline extension initialized\n",
      "10-20 20:31:35.938 172.17.0.2:54321      18300    Thread-4  INFO water.default: HiveFrameSaver extension initialized\n",
      "10-20 20:31:35.939 172.17.0.2:54321      18300    Thread-4  INFO water.default: XGBoost extension initialized\n",
      "10-20 20:31:35.939 172.17.0.2:54321      18300    Thread-4  INFO water.default: Registered 5 core extensions in: 989ms\n",
      "10-20 20:31:35.939 172.17.0.2:54321      18300    Thread-4  INFO water.default: Registered H2O core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 20:31:36.308 172.17.0.2:54321      18300    Thread-4  INFO hex.tree.xgboost.XGBoostExtension: Found XGBoost backend with library: xgboost4j_gpu\n",
      "10-20 20:31:36.309 172.17.0.2:54321      18300    Thread-4  INFO hex.tree.xgboost.XGBoostExtension: XGBoost supported backends: [WITH_GPU, WITH_OMP]\n",
      "10-20 20:31:36.438 172.17.0.2:54321      18300    Thread-4  INFO water.default: Registered: 280 REST APIs in: 499ms\n",
      "10-20 20:31:36.439 172.17.0.2:54321      18300    Thread-4  INFO water.default: Registered REST API extensions: [XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4]\n",
      "10-20 20:31:36.566 172.17.0.2:54321      18300    Thread-4  INFO water.default: Registered: 329 schemas in 126ms\n",
      "10-20 20:31:36.566 172.17.0.2:54321      18300    Thread-4  INFO water.default: H2O started in 2389ms\n",
      "10-20 20:31:36.567 172.17.0.2:54321      18300    Thread-4  INFO water.default: \n",
      "10-20 20:31:36.567 172.17.0.2:54321      18300    Thread-4  INFO water.default: Open H2O Flow in your web browser: http://172.17.0.2:54321\n",
      "10-20 20:31:36.568 172.17.0.2:54321      18300    Thread-4  INFO water.default: \n",
      "10-20 20:31:36.572 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.H2OContext: Connecting to H2O cluster.\n",
      "10-20 20:31:36.573 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.H2OContext: Trying to lock H2O cluster 172.17.0.2:54321 - sparkling-water-root_local-1697833892184.\n",
      "10-20 20:31:36.665 172.17.0.2:54321      18300  7762763-69  INFO water.default: POST /3/CloudLock, parms: {reason=Locked from Sparkling Water.}\n",
      "10-20 20:31:36.673 172.17.0.2:54321      18300  7762763-69  INFO water.default: Locking cloud to new members, because requested via REST api. Reason: Locked from Sparkling Water.\n",
      "10-20 20:31:36.731 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/CloudLock successfully responded for the POST.\n",
      "10-20 20:31:36.745 172.17.0.2:54321      18300  7762763-65  INFO water.default: GET /3/verifyWebOpen, parms: {}\n",
      "10-20 20:31:36.832 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/verifyWebOpen successfully responded for the GET.\n",
      "10-20 20:31:36.835 172.17.0.2:54321      18300  7762763-65  INFO water.default: GET /3/verifyVersion, parms: {referenced_version=3.40.0.4}\n",
      "10-20 20:31:36.849 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/verifyVersion?referenced_version=3.40.0.4 successfully responded for the GET.\n",
      "10-20 20:31:36.875 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 20:31:36.882 172.17.0.2:54321      18300  7762763-68  INFO water.default: GET /3/LogLevel, parms: {}\n",
      "10-20 20:31:36.890 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/LogLevel successfully responded for the GET.\n",
      "10-20 20:31:36.893 172.17.0.2:54321      18300  7762763-68  INFO water.default: POST /99/Rapids, parms: {ast=(setTimeZone \"UTC\")}\n",
      "10-20 20:31:37.025 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/99/Rapids successfully responded for the POST.\n",
      "10-20 20:31:37.046 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.ProxyStarter: Trying to bind on port 54323 using wildcard ip address\n",
      "10-20 20:31:37.202 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.util.SignalUtils: Registering signal handler for INT\n",
      "10-20 20:31:44.834 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: jetty-9.4.z-SNAPSHOT; built: 2018-06-05T18:24:03.829Z; git: d5fc0523cfa96bfebfbda19606cad384d772f04c; jvm 11.0.11+9-Ubuntu-0ubuntu2.20.04\n",
      "10-20 20:31:44.856 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.handler.ContextHandler: Started a.h.o.e.j.s.ServletContextHandler@405659b0{/,null,AVAILABLE}\n",
      "10-20 20:31:44.857 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@7f55de8a{HTTP/1.1,[http/1.1]}{0.0.0.0:54323}\n",
      "10-20 20:31:44.857 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: Started @15211ms\n",
      "10-20 20:31:44.865 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 20:31:44.945 172.17.0.2:54321      18300    Thread-4  INFO ai.h2o.sparkling.H2OContext: Sparkling Water 3.40.0.4-1-3.1 started, status of context: \n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697833892184\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://5b5a8eb7561c:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "     \n",
      "Connecting to H2O server at http://5b5a8eb7561c:54323 ...10-20 20:31:45.040 172.17.0.2:54321      18300  7762763-69  INFO water.default: GET /3/Metadata/schemas/CloudV3, parms: {}\n",
      "10-20 20:31:45.130 172.17.0.2:54321      18300  7762763-70  INFO water.default: GET /3/Metadata/schemas/H2OErrorV3, parms: {}\n",
      "10-20 20:31:45.152 172.17.0.2:54321      18300  7762763-69  INFO water.default: GET /3/Metadata/schemas/H2OModelBuilderErrorV3, parms: {}\n",
      " successful.\n",
      "Warning: Your H2O cluster version is (5 months and 22 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>09 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-root_local-1697833892184</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://5b5a8eb7561c:54323</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O_cluster_uptime:         09 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    5 months and 22 days\n",
       "H2O_cluster_name:           sparkling-water-root_local-1697833892184\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://5b5a8eb7561c:54323\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697833892184\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://5b5a8eb7561c:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import H2OContext\n",
    "import h2o\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.appName('cognetix-spark-nb')\n",
    "    .config('spark.dynamicAllocation.enabled', 'false')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "sc = spark.sparkContext\n",
    "hc = H2OContext.getOrCreate()\n",
    "h2o_cluster = h2o.cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b11a08-e309-4d12-a74d-56eeb12f1757",
   "metadata": {},
   "source": [
    "### Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d26e8b22-875e-49cc-ae40-499d37ab4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "train_rate = 0.8\n",
    "\n",
    "train_path = '../data/census-train.csv'\n",
    "test_path = '../data/census-test.csv'\n",
    "model_path = 'outputs/income_rf_spark'\n",
    "pred_path = 'outputs/income_rf_spark_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c63fd9-3e8a-43ba-b0ae-c4048ce8e233",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf8c40cb-18a9-4faa-897b-bdd2a3b33274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:00.591 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.\n",
      "10-20 20:32:00.778 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.\n",
      "10-20 20:32:01.229 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:01.230 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:01.231 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:01.811 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 204.08941 ms\n",
      "10-20 20:32:01.917 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 61.007587 ms\n",
      "10-20 20:32:01.959 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 20:32:02.008 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 20:32:02.011 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:02.016 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 0 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 20:32:02.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:02.269 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 20:32:02.281 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "10-20 20:32:02.285 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 20:32:02.285 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 1 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 20:32:02.286 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\n",
      "10-20 20:32:02.287 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)\n",
      "10-20 20:32:02.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 20:32:02.317 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 34.2 KiB, free 434.2 MiB)\n",
      "10-20 20:32:02.321 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 434.2 MiB)\n",
      "10-20 20:32:02.325 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.1 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:02.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:02.338 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:02.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:02.380 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:02.396 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "10-20 20:32:02.399 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Fetching file:/tmp/sparkling-water-1712564973661872805-hash-login.conf with timestamp 1697833894156\n",
      "10-20 20:32:02.419 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.util.Utils: /tmp/sparkling-water-1712564973661872805-hash-login.conf has been previously copied to /tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/userFiles-3b11f810-57f4-4b38-a91b-0c384dbcac98/sparkling-water-1712564973661872805-hash-login.conf\n",
      "10-20 20:32:02.423 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Fetching file:/tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/hdfs_conf13839494150648595978.xml with timestamp 1697833894109\n",
      "10-20 20:32:02.426 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.util.Utils: /tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/hdfs_conf13839494150648595978.xml has been previously copied to /tmp/spark-36586b26-65bf-440d-9e41-7a3af8c0ca1e/userFiles-3b11f810-57f4-4b38-a91b-0c384dbcac98/hdfs_conf13839494150648595978.xml\n",
      "10-20 20:32:02.571 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 28.898143 ms\n",
      "10-20 20:32:02.595 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 9.958305 ms\n",
      "10-20 20:32:02.617 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:02.637 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 14.616614 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:03.265 172.17.0.2:54321      18300  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2775 bytes result sent to driver\n",
      "10-20 20:32:03.300 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 926 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:03.311 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.008 s\n",
      "10-20 20:32:03.311 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:03.312 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:03.312 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 1)\n",
      "10-20 20:32:03.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:03.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 20:32:03.309 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:03.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 434.1 MiB)\n",
      "10-20 20:32:03.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.1 MiB)\n",
      "10-20 20:32:03.346 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 5b5a8eb7561c:44751 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:03.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:03.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:03.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:03.354 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:03.355 172.17.0.2:54321      18300  .0 (TID 1)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "10-20 20:32:03.411 172.17.0.2:54321      18300  .0 (TID 1)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:03.413 172.17.0.2:54321      18300  .0 (TID 1)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\n",
      "10-20 20:32:03.424 172.17.0.2:54321      18300  .0 (TID 1)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 2648 bytes result sent to driver\n",
      "10-20 20:32:03.427 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 76 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:03.427 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:03.428 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.100 s\n",
      "10-20 20:32:03.431 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:03.431 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "10-20 20:32:03.434 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 0 finished: count at NativeMethodAccessorImpl.java:0, took 1.163994 s\n",
      "Train split size: 26076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:03.519 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:03.520 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:03.521 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:03.607 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 45.842719 ms\n",
      "10-20 20:32:03.612 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 20:32:03.667 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 20:32:03.667 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:03.669 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 20:32:03.670 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:03.673 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:03.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 20:32:03.708 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 10 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1\n",
      "10-20 20:32:03.708 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 20:32:03.708 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 20:32:03.708 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\n",
      "10-20 20:32:03.709 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)\n",
      "10-20 20:32:03.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 20:32:03.740 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 34.2 KiB, free 434.0 MiB)\n",
      "10-20 20:32:03.742 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:03.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 434.1 MiB)\n",
      "10-20 20:32:03.747 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.1 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:03.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:03.749 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:03.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:03.752 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:03.753 172.17.0.2:54321      18300  .0 (TID 2)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "10-20 20:32:03.775 172.17.0.2:54321      18300  .0 (TID 2)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:03.821 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on 5b5a8eb7561c:44751 in memory (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:04.152 172.17.0.2:54321      18300  .0 (TID 2)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 2689 bytes result sent to driver\n",
      "10-20 20:32:04.155 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 403 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:04.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.434 s\n",
      "10-20 20:32:04.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:04.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:04.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 3)\n",
      "10-20 20:32:04.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:04.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 20:32:04.160 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:04.162 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 434.1 MiB)\n",
      "10-20 20:32:04.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.1 MiB)\n",
      "10-20 20:32:04.198 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 5b5a8eb7561c:44751 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:04.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:04.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:04.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:04.205 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:04.206 172.17.0.2:54321      18300  .0 (TID 3)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "10-20 20:32:04.211 172.17.0.2:54321      18300  .0 (TID 3)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:04.211 172.17.0.2:54321      18300  .0 (TID 3)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:04.213 172.17.0.2:54321      18300  .0 (TID 3)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 2648 bytes result sent to driver\n",
      "10-20 20:32:04.218 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:04.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.062 s\n",
      "10-20 20:32:04.223 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:04.224 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:04.224 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "10-20 20:32:04.224 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.516873 s\n",
      "Validation split size: 6485\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "train_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(train_path)\n",
    "    .drop('education_num')\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('income_level')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")\n",
    "\n",
    "test_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(test_path)\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('education_num', 'income_level')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")\n",
    "\n",
    "train_df, val_df = train_df.randomSplit([train_rate, 1-train_rate], seed=seed)\n",
    "print(f'Train split size: {train_df.count()}')\n",
    "print(f'Validation split size: {val_df.count()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eead67-429f-443a-acfe-f4b3a777e1a3",
   "metadata": {},
   "source": [
    "###Â ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d03e4-7933-427e-aaa9-541c7bb899df",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6499e814-2c77-4da0-b7a4-8d6ec0052e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    VectorAssembler,\n",
    "    OneHotEncoder,\n",
    "    Imputer,\n",
    ")\n",
    "cols_to_impute = ['fnlwgt', 'age', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "cat_cols = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "imputed_cols = [f'{x}_IMPUTED' for x in cols_to_impute]\n",
    "imputer = Imputer(strategy='mean', inputCols=cols_to_impute, outputCols=imputed_cols)\n",
    "string_indexers = []\n",
    "ohe_indexers = []\n",
    "for cat_col in cat_cols:\n",
    "    si = StringIndexer(inputCol=cat_col, outputCol=f'{cat_col}_idx').setHandleInvalid('keep')\n",
    "    enc = OneHotEncoder(inputCols=[si.getOutputCol()], outputCols=[f'{cat_col}_vec'])\n",
    "    string_indexers.append(si)\n",
    "    ohe_indexers.append(enc)\n",
    "\n",
    "assembler_cols = [f'{c}_vec' for c in cat_cols] + imputed_cols\n",
    "vector_assembler = VectorAssembler(inputCols=assembler_cols, outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85750959-a159-4890-b153-fe91c4a034bd",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b88bfe8-a5e3-4042-9a18-959f267d19c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:17.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:17.112 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:17.113 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:17.197 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 24.564393 ms\n",
      "10-20 20:32:17.264 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 36.934815 ms\n",
      "10-20 20:32:17.267 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 20:32:17.300 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:17.305 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:17.306 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 6 from head at Imputer.scala:169\n",
      "10-20 20:32:17.307 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:17.340 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:17.382 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:169\n",
      "10-20 20:32:17.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 17 (head at Imputer.scala:169) as input to shuffle 2\n",
      "10-20 20:32:17.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 2 (head at Imputer.scala:169) with 1 output partitions\n",
      "10-20 20:32:17.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 5 (head at Imputer.scala:169)\n",
      "10-20 20:32:17.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "10-20 20:32:17.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 4)\n",
      "10-20 20:32:17.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:32:17.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 54.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:17.396 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:17.398 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 5b5a8eb7561c:44751 (size: 22.1 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:17.409 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:17.411 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:17.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:17.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:17.414 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:17.414 172.17.0.2:54321      18300  .0 (TID 4)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 4.0 (TID 4)\n",
      "10-20 20:32:17.449 172.17.0.2:54321      18300  .0 (TID 4)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:17.481 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on 5b5a8eb7561c:44751 in memory (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:17.782 172.17.0.2:54321      18300  .0 (TID 4)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 2689 bytes result sent to driver\n",
      "10-20 20:32:17.783 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 369 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:17.783 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:17.783 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 4 (head at Imputer.scala:169) finished in 0.396 s\n",
      "10-20 20:32:17.783 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:17.783 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:17.783 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 5)\n",
      "10-20 20:32:17.784 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:17.784 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:32:17.786 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 19.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:17.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:17.799 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 5b5a8eb7561c:44751 (size: 7.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:17.799 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:17.800 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:17.800 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:17.801 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:17.802 172.17.0.2:54321      18300  .0 (TID 5)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 5.0 (TID 5)\n",
      "10-20 20:32:17.804 172.17.0.2:54321      18300  .0 (TID 5)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:17.804 172.17.0.2:54321      18300  .0 (TID 5)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:17.809 172.17.0.2:54321      18300  .0 (TID 5)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 5.0 (TID 5). 2681 bytes result sent to driver\n",
      "10-20 20:32:17.810 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:17.810 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:17.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 5 (head at Imputer.scala:169) finished in 0.026 s\n",
      "10-20 20:32:17.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:17.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "10-20 20:32:17.811 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 2 finished: head at Imputer.scala:169, took 0.428530 s\n",
      "10-20 20:32:17.828 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.706965 ms\n",
      "10-20 20:32:17.905 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 11.269406 ms\n",
      "10-20 20:32:17.921 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:32:17.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 3 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 20:32:17.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 6 (head at Imputer.scala:258)\n",
      "10-20 20:32:17.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:17.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:17.924 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:32:17.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:17.967 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:17.967 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:17.968 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:17.969 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:17.969 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:17.972 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:17.973 172.17.0.2:54321      18300  .0 (TID 6)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 6.0 (TID 6)\n",
      "10-20 20:32:18.001 172.17.0.2:54321      18300  .0 (TID 6)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 6.0 (TID 6). 1347 bytes result sent to driver\n",
      "10-20 20:32:18.002 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 32 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:18.002 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:18.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 6 (head at Imputer.scala:258) finished in 0.078 s\n",
      "10-20 20:32:18.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:18.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "10-20 20:32:18.003 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 3 finished: head at Imputer.scala:258, took 0.081194 s\n",
      "10-20 20:32:18.008 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:32:18.009 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 4 (head at Imputer.scala:258) with 3 output partitions\n",
      "10-20 20:32:18.009 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 7 (head at Imputer.scala:258)\n",
      "10-20 20:32:18.009 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:18.009 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:18.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[24] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:32:18.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:18.014 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:18.015 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:18.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:18.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 3 missing tasks from ResultStage 7 (MapPartitionsRDD[24] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(1, 2, 3))\n",
      "10-20 20:32:18.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 7.0 with 3 tasks resource profile 0\n",
      "10-20 20:32:18.017 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (5b5a8eb7561c, executor driver, partition 1, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:18.018 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8) (5b5a8eb7561c, executor driver, partition 2, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:18.020 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9) (5b5a8eb7561c, executor driver, partition 3, PROCESS_LOCAL, 4717 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:18.020 172.17.0.2:54321      18300  .0 (TID 7)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 7.0 (TID 7)\n",
      "10-20 20:32:18.022 172.17.0.2:54321      18300  .0 (TID 8)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 7.0 (TID 8)\n",
      "10-20 20:32:18.024 172.17.0.2:54321      18300  .0 (TID 7)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 7.0 (TID 7). 1304 bytes result sent to driver\n",
      "10-20 20:32:18.031 172.17.0.2:54321      18300  .0 (TID 9)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 7.0 (TID 9)\n",
      "10-20 20:32:18.031 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 14 ms on 5b5a8eb7561c (executor driver) (1/3)\n",
      "10-20 20:32:18.045 172.17.0.2:54321      18300  .0 (TID 8)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 7.0 (TID 8). 1304 bytes result sent to driver\n",
      "10-20 20:32:18.046 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 29 ms on 5b5a8eb7561c (executor driver) (2/3)\n",
      "10-20 20:32:18.076 172.17.0.2:54321      18300  .0 (TID 9)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 21.563246 ms\n",
      "10-20 20:32:18.079 172.17.0.2:54321      18300  .0 (TID 9)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 7.0 (TID 9). 1400 bytes result sent to driver\n",
      "10-20 20:32:18.079 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 61 ms on 5b5a8eb7561c (executor driver) (3/3)\n",
      "10-20 20:32:18.080 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:18.080 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 7 (head at Imputer.scala:258) finished in 0.068 s\n",
      "10-20 20:32:18.080 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:18.080 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "10-20 20:32:18.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 4 finished: head at Imputer.scala:258, took 0.072108 s\n",
      "10-20 20:32:18.087 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.815338 ms\n",
      "10-20 20:32:18.203 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:18.204 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:18.204 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:18.248 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 19.352771 ms\n",
      "10-20 20:32:18.253 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:18.287 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:18.290 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:18.291 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 11 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:18.292 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:18.300 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_9_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:18.334 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:18.335 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on 5b5a8eb7561c:44751 in memory (size: 22.1 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:18.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 29 (collect at StringIndexer.scala:204) as input to shuffle 3\n",
      "10-20 20:32:18.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 5 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:18.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 9 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:18.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n",
      "10-20 20:32:18.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 8)\n",
      "10-20 20:32:18.337 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[29] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:18.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:18.341 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:18.342 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:18.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:18.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[29] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:18.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:18.344 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:18.346 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 8.0 (TID 10)\n",
      "10-20 20:32:18.378 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:18.379 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on 5b5a8eb7561c:44751 in memory (size: 7.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:18.396 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:18.419 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:18.698 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.824858 ms\n",
      "10-20 20:32:18.712 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.470739 ms\n",
      "10-20 20:32:18.722 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.595306 ms\n",
      "10-20 20:32:18.743 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 9.409976 ms\n",
      "10-20 20:32:18.801 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 10.266504 ms\n",
      "10-20 20:32:18.989 172.17.0.2:54321      18300  0 (TID 10)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 8.0 (TID 10). 2511 bytes result sent to driver\n",
      "10-20 20:32:18.990 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 646 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:18.990 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:18.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 8 (collect at StringIndexer.scala:204) finished in 0.653 s\n",
      "10-20 20:32:18.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:18.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:18.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 9)\n",
      "10-20 20:32:18.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:18.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[32] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:18.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.008 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.010 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:19.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:19.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:19.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:19.013 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 11) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:19.014 172.17.0.2:54321      18300  0 (TID 11)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 9.0 (TID 11)\n",
      "10-20 20:32:19.029 172.17.0.2:54321      18300  0 (TID 11)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:19.029 172.17.0.2:54321      18300  0 (TID 11)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:19.043 172.17.0.2:54321      18300  0 (TID 11)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.160679 ms\n",
      "10-20 20:32:19.115 172.17.0.2:54321      18300  0 (TID 11)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 9.0 (TID 11). 3904 bytes result sent to driver\n",
      "10-20 20:32:19.117 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 11) in 105 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:19.117 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:19.118 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 9 (collect at StringIndexer.scala:204) finished in 0.126 s\n",
      "10-20 20:32:19.118 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:19.118 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "10-20 20:32:19.119 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 5 finished: collect at StringIndexer.scala:204, took 0.783696 s\n",
      "10-20 20:32:19.310 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:19.310 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:19.311 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:19.357 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 14.760402 ms\n",
      "10-20 20:32:19.360 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:19.382 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_11_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:19.394 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.395 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:19.395 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 14 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:19.396 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:19.427 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:19.427 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:19.428 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 37 (collect at StringIndexer.scala:204) as input to shuffle 4\n",
      "10-20 20:32:19.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 6 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:19.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 11 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:19.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\n",
      "10-20 20:32:19.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 10)\n",
      "10-20 20:32:19.431 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[37] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:19.433 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 35.3 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.433 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.436 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:19.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:19.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[37] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:19.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:19.441 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:19.441 172.17.0.2:54321      18300  0 (TID 12)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 10.0 (TID 12)\n",
      "10-20 20:32:19.467 172.17.0.2:54321      18300  0 (TID 12)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:19.484 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:19.821 172.17.0.2:54321      18300  0 (TID 12)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 10.0 (TID 12). 2468 bytes result sent to driver\n",
      "10-20 20:32:19.823 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 382 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:19.823 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:19.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 10 (collect at StringIndexer.scala:204) finished in 0.393 s\n",
      "10-20 20:32:19.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:19.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:19.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 11)\n",
      "10-20 20:32:19.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:19.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[40] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:19.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.846 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:19.846 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:19.847 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:19.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[40] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:19.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:19.850 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:19.850 172.17.0.2:54321      18300  0 (TID 13)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 11.0 (TID 13)\n",
      "10-20 20:32:19.858 172.17.0.2:54321      18300  0 (TID 13)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:19.858 172.17.0.2:54321      18300  0 (TID 13)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:19.885 172.17.0.2:54321      18300  0 (TID 13)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 11.0 (TID 13). 3956 bytes result sent to driver\n",
      "10-20 20:32:19.886 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 37 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:19.887 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:19.887 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 11 (collect at StringIndexer.scala:204) finished in 0.062 s\n",
      "10-20 20:32:19.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:19.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished\n",
      "10-20 20:32:19.888 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 6 finished: collect at StringIndexer.scala:204, took 0.460305 s\n",
      "10-20 20:32:20.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:20.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:20.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:20.085 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 21.687864 ms\n",
      "10-20 20:32:20.090 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.097 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.098 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.099 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 17 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:20.099 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:20.114 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:20.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 45 (collect at StringIndexer.scala:204) as input to shuffle 5\n",
      "10-20 20:32:20.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 7 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:20.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:20.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "10-20 20:32:20.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 12)\n",
      "10-20 20:32:20.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[45] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:20.121 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.140 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.140 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.145 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:20.145 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[45] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:20.145 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:20.146 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:20.147 172.17.0.2:54321      18300  0 (TID 14)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 12.0 (TID 14)\n",
      "10-20 20:32:20.153 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.163 172.17.0.2:54321      18300  0 (TID 14)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:20.217 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.227 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:20.447 172.17.0.2:54321      18300  0 (TID 14)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 12.0 (TID 14). 2468 bytes result sent to driver\n",
      "10-20 20:32:20.448 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 302 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:20.449 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:20.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 12 (collect at StringIndexer.scala:204) finished in 0.332 s\n",
      "10-20 20:32:20.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:20.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:20.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 13)\n",
      "10-20 20:32:20.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:20.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:20.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 26.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:20.469 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:20.470 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.471 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:20.471 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:20.471 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:20.472 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:20.473 172.17.0.2:54321      18300  0 (TID 15)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 13.0 (TID 15)\n",
      "10-20 20:32:20.479 172.17.0.2:54321      18300  0 (TID 15)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:20.479 172.17.0.2:54321      18300  0 (TID 15)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:20.498 172.17.0.2:54321      18300  0 (TID 15)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 13.0 (TID 15). 3884 bytes result sent to driver\n",
      "10-20 20:32:20.500 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 28 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:20.500 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:20.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 13 (collect at StringIndexer.scala:204) finished in 0.048 s\n",
      "10-20 20:32:20.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:20.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "10-20 20:32:20.501 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 7 finished: collect at StringIndexer.scala:204, took 0.386795 s\n",
      "10-20 20:32:20.659 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:20.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:20.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:20.697 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 19.926376 ms\n",
      "10-20 20:32:20.704 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.713 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.714 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.715 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 20 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:20.716 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:20.728 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:20.729 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 53 (collect at StringIndexer.scala:204) as input to shuffle 6\n",
      "10-20 20:32:20.729 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 8 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:20.729 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 15 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:20.729 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\n",
      "10-20 20:32:20.730 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 14)\n",
      "10-20 20:32:20.731 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[53] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:20.732 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:20.733 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:20.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[53] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:20.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:20.736 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:20.736 172.17.0.2:54321      18300  0 (TID 16)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 14.0 (TID 16)\n",
      "10-20 20:32:20.749 172.17.0.2:54321      18300  0 (TID 16)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:20.768 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.825 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:20.858 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:21.050 172.17.0.2:54321      18300  0 (TID 16)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 14.0 (TID 16). 2511 bytes result sent to driver\n",
      "10-20 20:32:21.051 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 316 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:21.051 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:21.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 14 (collect at StringIndexer.scala:204) finished in 0.320 s\n",
      "10-20 20:32:21.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:21.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:21.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 15)\n",
      "10-20 20:32:21.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:21.053 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[56] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:21.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:21.069 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:21.070 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.070 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:21.071 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[56] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:21.071 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:21.073 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:21.074 172.17.0.2:54321      18300  0 (TID 17)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 15.0 (TID 17)\n",
      "10-20 20:32:21.078 172.17.0.2:54321      18300  0 (TID 17)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (789.0 B) non-empty blocks including 1 (789.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:21.079 172.17.0.2:54321      18300  0 (TID 17)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:21.102 172.17.0.2:54321      18300  0 (TID 17)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 15.0 (TID 17). 4046 bytes result sent to driver\n",
      "10-20 20:32:21.103 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 30 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:21.103 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:21.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 15 (collect at StringIndexer.scala:204) finished in 0.050 s\n",
      "10-20 20:32:21.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:21.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "10-20 20:32:21.105 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 8 finished: collect at StringIndexer.scala:204, took 0.376317 s\n",
      "10-20 20:32:21.254 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:21.254 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:21.255 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:21.307 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 32.162641 ms\n",
      "10-20 20:32:21.311 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.319 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.320 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 23 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:21.321 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:21.339 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:21.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 61 (collect at StringIndexer.scala:204) as input to shuffle 7\n",
      "10-20 20:32:21.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 9 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:21.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:21.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "10-20 20:32:21.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 16)\n",
      "10-20 20:32:21.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[61] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:21.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.361 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.362 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:21.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[61] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:21.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:21.363 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:21.364 172.17.0.2:54321      18300  0 (TID 18)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 16.0 (TID 18)\n",
      "10-20 20:32:21.373 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.391 172.17.0.2:54321      18300  0 (TID 18)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:21.440 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:21.659 172.17.0.2:54321      18300  0 (TID 18)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 16.0 (TID 18). 2468 bytes result sent to driver\n",
      "10-20 20:32:21.660 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 297 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:21.660 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:21.661 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 16 (collect at StringIndexer.scala:204) finished in 0.311 s\n",
      "10-20 20:32:21.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:21.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:21.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 17)\n",
      "10-20 20:32:21.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:21.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[64] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:21.665 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:21.676 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:21.677 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.678 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:21.678 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[64] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:21.678 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:21.680 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 19) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:21.680 172.17.0.2:54321      18300  0 (TID 19)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 17.0 (TID 19)\n",
      "10-20 20:32:21.684 172.17.0.2:54321      18300  0 (TID 19)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:21.684 172.17.0.2:54321      18300  0 (TID 19)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:21.711 172.17.0.2:54321      18300  0 (TID 19)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 17.0 (TID 19). 3855 bytes result sent to driver\n",
      "10-20 20:32:21.714 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 19) in 35 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:21.715 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:21.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 17 (collect at StringIndexer.scala:204) finished in 0.053 s\n",
      "10-20 20:32:21.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:21.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "10-20 20:32:21.716 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 9 finished: collect at StringIndexer.scala:204, took 0.376980 s\n",
      "10-20 20:32:21.848 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:21.849 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:21.849 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:21.901 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 35.563555 ms\n",
      "10-20 20:32:21.906 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.921 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.922 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.923 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 26 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:21.924 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:21.942 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:21.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 69 (collect at StringIndexer.scala:204) as input to shuffle 8\n",
      "10-20 20:32:21.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 10 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:21.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 19 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:21.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\n",
      "10-20 20:32:21.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\n",
      "10-20 20:32:21.945 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[69] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:21.947 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.949 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:21.949 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:21.950 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:21.954 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[69] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:21.955 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:21.955 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:21.956 172.17.0.2:54321      18300  0 (TID 20)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 18.0 (TID 20)\n",
      "10-20 20:32:21.968 172.17.0.2:54321      18300  0 (TID 20)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:22.058 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.139 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.201 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:22.274 172.17.0.2:54321      18300  0 (TID 20)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 18.0 (TID 20). 2511 bytes result sent to driver\n",
      "10-20 20:32:22.274 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 319 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:22.274 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:22.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 18 (collect at StringIndexer.scala:204) finished in 0.330 s\n",
      "10-20 20:32:22.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:22.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:22.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 19)\n",
      "10-20 20:32:22.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:22.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:22.277 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:22.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:22.278 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.7 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:22.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:22.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:22.280 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 21) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:22.281 172.17.0.2:54321      18300  0 (TID 21)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 19.0 (TID 21)\n",
      "10-20 20:32:22.288 172.17.0.2:54321      18300  0 (TID 21)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:22.288 172.17.0.2:54321      18300  0 (TID 21)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:22.300 172.17.0.2:54321      18300  0 (TID 21)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 19.0 (TID 21). 3863 bytes result sent to driver\n",
      "10-20 20:32:22.301 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 21) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:22.301 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:22.302 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 19 (collect at StringIndexer.scala:204) finished in 0.026 s\n",
      "10-20 20:32:22.302 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:22.302 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished\n",
      "10-20 20:32:22.303 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 10 finished: collect at StringIndexer.scala:204, took 0.359673 s\n",
      "10-20 20:32:22.397 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:22.397 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:22.397 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:22.423 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 14.094092 ms\n",
      "10-20 20:32:22.426 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:22.446 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:22.447 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.448 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.456 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 29 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:22.457 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:22.473 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.7 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.495 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:22.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 77 (collect at StringIndexer.scala:204) as input to shuffle 9\n",
      "10-20 20:32:22.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 11 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:22.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 21 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:22.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)\n",
      "10-20 20:32:22.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 20)\n",
      "10-20 20:32:22.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[77] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:22.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 35.3 KiB, free 434.2 MiB)\n",
      "10-20 20:32:22.504 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:22.506 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 434.2 MiB)\n",
      "10-20 20:32:22.506 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.4 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:22.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:22.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[77] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:22.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:22.510 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 22) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:22.510 172.17.0.2:54321      18300  0 (TID 22)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 20.0 (TID 22)\n",
      "10-20 20:32:22.534 172.17.0.2:54321      18300  0 (TID 22)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:22.862 172.17.0.2:54321      18300  0 (TID 22)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 20.0 (TID 22). 2468 bytes result sent to driver\n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 22) in 354 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 20 (collect at StringIndexer.scala:204) finished in 0.361 s\n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 21)\n",
      "10-20 20:32:22.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:22.864 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[80] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:22.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 20:32:22.880 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:22.881 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:22.884 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:22.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[80] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:22.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:22.891 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 21.0 (TID 23) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:22.891 172.17.0.2:54321      18300  0 (TID 23)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 21.0 (TID 23)\n",
      "10-20 20:32:22.895 172.17.0.2:54321      18300  0 (TID 23)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:22.896 172.17.0.2:54321      18300  0 (TID 23)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:22.911 172.17.0.2:54321      18300  0 (TID 23)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 21.0 (TID 23). 3768 bytes result sent to driver\n",
      "10-20 20:32:22.912 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 21.0 (TID 23) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:22.912 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:22.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 21 (collect at StringIndexer.scala:204) finished in 0.049 s\n",
      "10-20 20:32:22.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:22.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "10-20 20:32:22.913 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 11 finished: collect at StringIndexer.scala:204, took 0.416853 s\n",
      "10-20 20:32:23.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:23.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:23.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:23.079 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 14.667921 ms\n",
      "10-20 20:32:23.085 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 20:32:23.095 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 20:32:23.095 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:23.096 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 32 from collect at StringIndexer.scala:204\n",
      "10-20 20:32:23.097 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:23.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:32:23.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 85 (collect at StringIndexer.scala:204) as input to shuffle 10\n",
      "10-20 20:32:23.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 12 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:32:23.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 23 (collect at StringIndexer.scala:204)\n",
      "10-20 20:32:23.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)\n",
      "10-20 20:32:23.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 22)\n",
      "10-20 20:32:23.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[85] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:23.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 20:32:23.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:23.116 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:23.117 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:23.117 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[85] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:23.117 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:23.118 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 24) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:23.119 172.17.0.2:54321      18300  0 (TID 24)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 22.0 (TID 24)\n",
      "10-20 20:32:23.131 172.17.0.2:54321      18300  0 (TID 24)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:23.223 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:23.246 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:23.255 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.4 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:23.435 172.17.0.2:54321      18300  0 (TID 24)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 22.0 (TID 24). 2511 bytes result sent to driver\n",
      "10-20 20:32:23.437 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 24) in 319 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:23.438 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:23.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 22 (collect at StringIndexer.scala:204) finished in 0.324 s\n",
      "10-20 20:32:23.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:23.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:23.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 23)\n",
      "10-20 20:32:23.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:23.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[88] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:32:23.441 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 26.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:23.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 20:32:23.443 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:23.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:23.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[88] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:23.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:23.445 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 25) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:23.446 172.17.0.2:54321      18300  0 (TID 25)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 23.0 (TID 25)\n",
      "10-20 20:32:23.451 172.17.0.2:54321      18300  0 (TID 25)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (955.0 B) non-empty blocks including 1 (955.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:23.452 172.17.0.2:54321      18300  0 (TID 25)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:23.466 172.17.0.2:54321      18300  0 (TID 25)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 23.0 (TID 25). 4215 bytes result sent to driver\n",
      "10-20 20:32:23.468 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 25) in 23 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:23.468 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:23.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 23 (collect at StringIndexer.scala:204) finished in 0.029 s\n",
      "10-20 20:32:23.469 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:23.469 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished\n",
      "10-20 20:32:23.469 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 12 finished: collect at StringIndexer.scala:204, took 0.356910 s\n",
      "10-20 20:32:24.471 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] Stage class: LinearSVC\n",
      "10-20 20:32:24.471 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] Stage uid: LinearSVC_14ad6524bbfc\n",
      "10-20 20:32:24.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:24.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:24.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:24.573 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:24.577 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:24.582 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:24.783 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 85.361787 ms\n",
      "10-20 20:32:24.786 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 20:32:24.804 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 20:32:24.805 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 20:32:24.806 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 35 from rdd at Instrumentation.scala:62\n",
      "10-20 20:32:24.807 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:24.908 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "10-20 20:32:24.914 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"labelCol\":\"label\",\"featuresCol\":\"features\"}\n",
      "10-20 20:32:25.042 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:25.055 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:25.056 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:25.136 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 42.19474 ms\n",
      "10-20 20:32:25.141 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 20:32:25.160 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 20:32:25.160 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:25.163 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 36 from rdd at Predictor.scala:81\n",
      "10-20 20:32:25.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:25.293 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at Summarizer.scala:232\n",
      "10-20 20:32:25.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 13 (treeAggregate at Summarizer.scala:232) with 1 output partitions\n",
      "10-20 20:32:25.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 24 (treeAggregate at Summarizer.scala:232)\n",
      "10-20 20:32:25.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:25.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:25.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[102] at treeAggregate at Summarizer.scala:232), which has no missing parents\n",
      "10-20 20:32:25.311 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 130.4 KiB, free 433.9 MiB)\n",
      "10-20 20:32:25.321 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 433.8 MiB)\n",
      "10-20 20:32:25.322 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 5b5a8eb7561c:44751 (size: 41.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:25.324 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:25.325 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[102] at treeAggregate at Summarizer.scala:232) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:25.325 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:25.326 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 26) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:25.327 172.17.0.2:54321      18300  0 (TID 26)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 24.0 (TID 26)\n",
      "10-20 20:32:25.470 172.17.0.2:54321      18300  0 (TID 26)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.348903 ms\n",
      "10-20 20:32:25.472 172.17.0.2:54321      18300  0 (TID 26)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:26.114 172.17.0.2:54321      18300  0 (TID 26)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.718918 ms\n",
      "10-20 20:32:26.132 172.17.0.2:54321      18300  0 (TID 26)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.961625 ms\n",
      "10-20 20:32:27.018 172.17.0.2:54321      18300  0 (TID 26)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 24.0 (TID 26). 5776 bytes result sent to driver\n",
      "10-20 20:32:27.019 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 26) in 1693 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:27.020 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:27.020 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 24 (treeAggregate at Summarizer.scala:232) finished in 1.724 s\n",
      "10-20 20:32:27.020 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:27.020 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished\n",
      "10-20 20:32:27.020 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 13 finished: treeAggregate at Summarizer.scala:232, took 1.726703 s\n",
      "10-20 20:32:27.024 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"numExamples\":26076}\n",
      "10-20 20:32:27.025 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"lowestLabelWeight\":\"6289.0\"}\n",
      "10-20 20:32:27.025 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"highestLabelWeight\":\"19787.0\"}\n",
      "10-20 20:32:27.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"sumOfWeights\":26076.0}\n",
      "10-20 20:32:27.030 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"actualBlockSizeInMB\":\"1.0\"}\n",
      "10-20 20:32:27.032 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"numClasses\":2}\n",
      "10-20 20:32:27.032 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] {\"numFeatures\":106}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:27.416 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on 5b5a8eb7561c:44751 in memory (size: 41.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:27.456 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 888.0 B, free 434.0 MiB)\n",
      "10-20 20:32:27.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 860.0 B, free 434.0 MiB)\n",
      "10-20 20:32:27.472 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 5b5a8eb7561c:44751 (size: 860.0 B, free: 434.3 MiB)\n",
      "10-20 20:32:27.474 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 38 from broadcast at LinearSVC.scala:285\n",
      "10-20 20:32:27.516 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 912.0 B, free 434.0 MiB)\n",
      "10-20 20:32:27.519 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 154.0 B, free 434.0 MiB)\n",
      "10-20 20:32:27.520 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 5b5a8eb7561c:44751 (size: 154.0 B, free: 434.3 MiB)\n",
      "10-20 20:32:27.521 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 39 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:27.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:27.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 14 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:27.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 25 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:27.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:27.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:27.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[105] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:27.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 131.5 KiB, free 433.9 MiB)\n",
      "10-20 20:32:27.579 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 433.8 MiB)\n",
      "10-20 20:32:27.580 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:27.580 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:27.581 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[105] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:27.581 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:27.583 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 27) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:27.584 172.17.0.2:54321      18300  0 (TID 27)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 25.0 (TID 27)\n",
      "10-20 20:32:27.635 172.17.0.2:54321      18300  0 (TID 27)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:28.594 172.17.0.2:54321      18300  0 (TID 27)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_104_0 stored as values in memory (estimated size 3.6 MiB, free 430.2 MiB)\n",
      "10-20 20:32:28.595 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_104_0 in memory on 5b5a8eb7561c:44751 (size: 3.6 MiB, free: 430.7 MiB)\n",
      "10-20 20:32:28.631 172.17.0.2:54321      18300  0 (TID 27)  WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "10-20 20:32:28.631 172.17.0.2:54321      18300  0 (TID 27)  WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "10-20 20:32:28.652 172.17.0.2:54321      18300  0 (TID 27)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 25.0 (TID 27). 3542 bytes result sent to driver\n",
      "10-20 20:32:28.653 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 27) in 1071 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:28.653 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:28.654 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 25 (treeAggregate at RDDLossFunction.scala:61) finished in 1.093 s\n",
      "10-20 20:32:28.654 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:28.654 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished\n",
      "10-20 20:32:28.654 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 14 finished: treeAggregate at RDDLossFunction.scala:61, took 1.104743 s\n",
      "10-20 20:32:28.656 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(39) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:28.659 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on 5b5a8eb7561c:44751 in memory (size: 154.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:28.732 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:28.733 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:28.734 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:28.735 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 41 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:28.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:28.755 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 15 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:28.755 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 26 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:28.755 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:28.756 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:28.757 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[106] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:28.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:28.766 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:28.767 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:28.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:28.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[106] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:28.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:28.771 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 28) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:28.773 172.17.0.2:54321      18300  0 (TID 28)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 26.0 (TID 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:28.801 172.17.0.2:54321      18300  0 (TID 28)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:28.823 172.17.0.2:54321      18300  0 (TID 28)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 26.0 (TID 28). 3456 bytes result sent to driver\n",
      "10-20 20:32:28.825 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 28) in 55 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:28.825 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:28.825 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 26 (treeAggregate at RDDLossFunction.scala:61) finished in 0.068 s\n",
      "10-20 20:32:28.826 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:28.826 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n",
      "10-20 20:32:28.826 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 15 finished: treeAggregate at RDDLossFunction.scala:61, took 0.071556 s\n",
      "10-20 20:32:28.826 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(41) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:28.828 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:28.832 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:28.833 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:28.834 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:28.835 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 43 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:28.847 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:28.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 16 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:28.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 27 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:28.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:28.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:28.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[107] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:28.852 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:28.857 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:28.858 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:28.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:28.859 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[107] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:28.859 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:28.860 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 29) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:28.861 172.17.0.2:54321      18300  0 (TID 29)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 27.0 (TID 29)\n",
      "10-20 20:32:28.874 172.17.0.2:54321      18300  0 (TID 29)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:28.900 172.17.0.2:54321      18300  0 (TID 29)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 27.0 (TID 29). 3456 bytes result sent to driver\n",
      "10-20 20:32:28.901 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 29) in 41 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:28.901 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:28.902 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 27 (treeAggregate at RDDLossFunction.scala:61) finished in 0.053 s\n",
      "10-20 20:32:28.902 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:28.902 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished\n",
      "10-20 20:32:28.903 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 16 finished: treeAggregate at RDDLossFunction.scala:61, took 0.054872 s\n",
      "10-20 20:32:28.904 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(43) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:28.906 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:28.908 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:28.936 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:28.937 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:28.938 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 45 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:28.943 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:28.947 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:28.951 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:28.955 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:28.956 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 17 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:28.956 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 28 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:28.956 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:28.957 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:28.958 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[108] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:28.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:28.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:28.966 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:28.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:28.967 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[108] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:28.967 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:28.969 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 30) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:28.969 172.17.0.2:54321      18300  0 (TID 30)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 28.0 (TID 30)\n",
      "10-20 20:32:28.979 172.17.0.2:54321      18300  0 (TID 30)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:28.992 172.17.0.2:54321      18300  0 (TID 30)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 28.0 (TID 30). 3456 bytes result sent to driver\n",
      "10-20 20:32:28.993 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 30) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:28.994 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:28.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 28 (treeAggregate at RDDLossFunction.scala:61) finished in 0.036 s\n",
      "10-20 20:32:28.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:28.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished\n",
      "10-20 20:32:28.997 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 17 finished: treeAggregate at RDDLossFunction.scala:61, took 0.041113 s\n",
      "10-20 20:32:28.998 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(45) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.000 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:29.002 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:29.007 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:29.008 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:29.010 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 47 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 18 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 29 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.030 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.031 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[109] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:29.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:29.039 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[109] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.042 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 31) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.043 172.17.0.2:54321      18300  0 (TID 31)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 29.0 (TID 31)\n",
      "10-20 20:32:29.053 172.17.0.2:54321      18300  0 (TID 31)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.066 172.17.0.2:54321      18300  0 (TID 31)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 29.0 (TID 31). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.067 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 31) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.067 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 29 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:32:29.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n",
      "10-20 20:32:29.068 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 18 finished: treeAggregate at RDDLossFunction.scala:61, took 0.040791 s\n",
      "10-20 20:32:29.069 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(47) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.071 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.076 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.06351\n",
      "10-20 20:32:29.080 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.596495 (rel: 0.404) 1.82004\n",
      "10-20 20:32:29.088 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:29.089 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 969.0 B, free 430.0 MiB)\n",
      "10-20 20:32:29.089 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 5b5a8eb7561c:44751 (size: 969.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.091 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 49 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.105 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.106 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 19 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.106 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 30 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.106 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.107 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.107 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[110] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:29.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:29.114 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[110] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.118 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.119 172.17.0.2:54321      18300  0 (TID 32)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 30.0 (TID 32)\n",
      "10-20 20:32:29.135 172.17.0.2:54321      18300  0 (TID 32)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.150 172.17.0.2:54321      18300  0 (TID 32)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 30.0 (TID 32). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.153 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 34 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.153 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.154 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 30 (treeAggregate at RDDLossFunction.scala:61) finished in 0.046 s\n",
      "10-20 20:32:29.154 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.154 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n",
      "10-20 20:32:29.154 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 19 finished: treeAggregate at RDDLossFunction.scala:61, took 0.048691 s\n",
      "10-20 20:32:29.156 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(49) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.157 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on 5b5a8eb7561c:44751 in memory (size: 969.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.159 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:29.163 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 990.0 B, free 429.9 MiB)\n",
      "10-20 20:32:29.163 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 5b5a8eb7561c:44751 (size: 990.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 51 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.240 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.242 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 20 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.242 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 31 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.242 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[111] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:29.254 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:29.255 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[111] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.258 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.258 172.17.0.2:54321      18300  0 (TID 33)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 31.0 (TID 33)\n",
      "10-20 20:32:29.268 172.17.0.2:54321      18300  0 (TID 33)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.279 172.17.0.2:54321      18300  0 (TID 33)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 31.0 (TID 33). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.280 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 23 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.280 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.281 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 31 (treeAggregate at RDDLossFunction.scala:61) finished in 0.036 s\n",
      "10-20 20:32:29.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished\n",
      "10-20 20:32:29.283 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 20 finished: treeAggregate at RDDLossFunction.scala:61, took 0.041697 s\n",
      "10-20 20:32:29.283 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(51) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.285 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on 5b5a8eb7561c:44751 in memory (size: 990.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.286 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:29.287 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 969.0 B, free 429.7 MiB)\n",
      "10-20 20:32:29.288 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 5b5a8eb7561c:44751 (size: 969.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.289 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 53 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.300 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.301 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 21 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.301 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 32 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.301 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.301 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.302 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.306 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:29.307 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:29.307 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:29.308 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.308 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.308 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.309 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.310 172.17.0.2:54321      18300  0 (TID 34)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 32.0 (TID 34)\n",
      "10-20 20:32:29.322 172.17.0.2:54321      18300  0 (TID 34)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.334 172.17.0.2:54321      18300  0 (TID 34)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 32.0 (TID 34). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.335 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.336 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 32 (treeAggregate at RDDLossFunction.scala:61) finished in 0.033 s\n",
      "10-20 20:32:29.337 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.337 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished\n",
      "10-20 20:32:29.337 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 21 finished: treeAggregate at RDDLossFunction.scala:61, took 0.036338 s\n",
      "10-20 20:32:29.338 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(53) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.339 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_53_piece0 on 5b5a8eb7561c:44751 in memory (size: 969.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:29.341 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 1.050\n",
      "10-20 20:32:29.342 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.502355 (rel: 0.158) 0.658710\n",
      "10-20 20:32:29.343 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:29.344 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:29.344 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:29.345 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 55 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.356 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 22 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 33 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.358 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[113] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:29.363 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:29.363 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:29.364 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.364 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[113] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.364 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.365 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.366 172.17.0.2:54321      18300  0 (TID 35)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 33.0 (TID 35)\n",
      "10-20 20:32:29.377 172.17.0.2:54321      18300  0 (TID 35)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.388 172.17.0.2:54321      18300  0 (TID 35)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 33.0 (TID 35). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.389 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.389 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.390 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 33 (treeAggregate at RDDLossFunction.scala:61) finished in 0.031 s\n",
      "10-20 20:32:29.390 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "10-20 20:32:29.391 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 22 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034815 s\n",
      "10-20 20:32:29.392 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(55) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.393 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:29.393 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_55_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:29.414 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:29.415 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:29.417 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:29.417 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 57 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.423 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_54_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.432 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_56_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.434 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.435 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:29.437 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:29.441 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 23 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 34 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[114] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:29.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:29.456 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:29.457 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.457 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[114] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.457 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.459 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.460 172.17.0.2:54321      18300  0 (TID 36)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 34.0 (TID 36)\n",
      "10-20 20:32:29.473 172.17.0.2:54321      18300  0 (TID 36)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.484 172.17.0.2:54321      18300  0 (TID 36)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 34.0 (TID 36). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.485 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.485 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.486 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 34 (treeAggregate at RDDLossFunction.scala:61) finished in 0.043 s\n",
      "10-20 20:32:29.486 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.486 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "10-20 20:32:29.486 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 23 finished: treeAggregate at RDDLossFunction.scala:61, took 0.045029 s\n",
      "10-20 20:32:29.488 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(57) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.489 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:29.490 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:29.491 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.497506 (rel: 0.00965) 0.519095\n",
      "10-20 20:32:29.493 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:29.494 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:29.494 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:29.495 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 59 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.511 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.512 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 24 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.512 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 35 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.512 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[115] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:29.518 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:29.518 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.518 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[115] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.520 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.521 172.17.0.2:54321      18300  0 (TID 37)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 35.0 (TID 37)\n",
      "10-20 20:32:29.529 172.17.0.2:54321      18300  0 (TID 37)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.539 172.17.0.2:54321      18300  0 (TID 37)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 35.0 (TID 37). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.540 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.540 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 35 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:29.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "10-20 20:32:29.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 24 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031335 s\n",
      "10-20 20:32:29.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(59) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.545 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_59_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.547 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:29.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:29.549 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.550 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 61 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.565 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 25 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 36 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.567 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[116] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:29.580 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:29.581 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.582 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.583 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[116] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.584 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.588 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.589 172.17.0.2:54321      18300  0 (TID 38)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 36.0 (TID 38)\n",
      "10-20 20:32:29.599 172.17.0.2:54321      18300  0 (TID 38)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.607 172.17.0.2:54321      18300  0 (TID 38)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 36.0 (TID 38). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.608 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.608 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 36 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:32:29.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n",
      "10-20 20:32:29.609 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 25 finished: treeAggregate at RDDLossFunction.scala:61, took 0.043770 s\n",
      "10-20 20:32:29.612 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(61) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.613 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_61_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.614 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:29.616 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.487900 (rel: 0.0193) 0.382300\n",
      "10-20 20:32:29.644 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:29.645 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:29.646 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.648 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 63 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.668 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 26 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 37 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.670 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.670 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[117] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.677 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:29.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:29.679 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[117] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.683 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.684 172.17.0.2:54321      18300  0 (TID 39)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 37.0 (TID 39)\n",
      "10-20 20:32:29.693 172.17.0.2:54321      18300  0 (TID 39)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.698 172.17.0.2:54321      18300  0 (TID 39)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 37.0 (TID 39). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.702 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.702 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.703 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 37 (treeAggregate at RDDLossFunction.scala:61) finished in 0.031 s\n",
      "10-20 20:32:29.703 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.703 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished\n",
      "10-20 20:32:29.704 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 26 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035548 s\n",
      "10-20 20:32:29.705 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(63) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.706 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_63_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:29.708 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:29.709 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.710 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 65 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.720 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 27 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 38 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[118] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.724 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:29.726 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:29.727 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:29.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.732 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[118] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.734 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.735 172.17.0.2:54321      18300  0 (TID 40)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 38.0 (TID 40)\n",
      "10-20 20:32:29.743 172.17.0.2:54321      18300  0 (TID 40)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.749 172.17.0.2:54321      18300  0 (TID 40)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 38.0 (TID 40). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.750 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.750 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 38 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:29.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished\n",
      "10-20 20:32:29.751 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 27 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030807 s\n",
      "10-20 20:32:29.752 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(65) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.752 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:29.753 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.473902 (rel: 0.0287) 0.274972\n",
      "10-20 20:32:29.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:29.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:29.755 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_65_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:29.755 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:29.757 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 67 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.770 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.771 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 28 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.771 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 39 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.771 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[119] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.775 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:29.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:29.796 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:29.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[119] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.798 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.800 172.17.0.2:54321      18300  0 (TID 41)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 39.0 (TID 41)\n",
      "10-20 20:32:29.804 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_60_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:29.805 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_62_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.807 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_66_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.808 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_64_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.810 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_58_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:29.816 172.17.0.2:54321      18300  0 (TID 41)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.821 172.17.0.2:54321      18300  0 (TID 41)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 39.0 (TID 41). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.823 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.823 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 39 (treeAggregate at RDDLossFunction.scala:61) finished in 0.051 s\n",
      "10-20 20:32:29.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished\n",
      "10-20 20:32:29.824 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 28 finished: treeAggregate at RDDLossFunction.scala:61, took 0.052947 s\n",
      "10-20 20:32:29.824 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(67) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.825 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_67_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:29.826 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:29.826 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:29.827 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:29.827 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 69 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.835 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 29 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 40 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[120] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:29.840 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:29.841 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.841 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[120] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.843 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.844 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.845 172.17.0.2:54321      18300  0 (TID 42)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 40.0 (TID 42)\n",
      "10-20 20:32:29.862 172.17.0.2:54321      18300  0 (TID 42)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.871 172.17.0.2:54321      18300  0 (TID 42)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 40.0 (TID 42). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.872 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 28 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.872 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.873 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 40 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:32:29.873 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.873 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished\n",
      "10-20 20:32:29.873 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 29 finished: treeAggregate at RDDLossFunction.scala:61, took 0.038535 s\n",
      "10-20 20:32:29.874 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(69) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.876 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_69_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.877 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:29.877 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.453189 (rel: 0.0437) 0.289808\n",
      "10-20 20:32:29.878 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:29.879 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:29.880 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.882 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 71 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.892 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.892 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 30 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.892 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 41 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.892 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.893 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.893 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[121] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:29.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:29.898 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.899 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[121] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.899 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.900 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.905 172.17.0.2:54321      18300  0 (TID 43)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 41.0 (TID 43)\n",
      "10-20 20:32:29.915 172.17.0.2:54321      18300  0 (TID 43)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.921 172.17.0.2:54321      18300  0 (TID 43)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 41.0 (TID 43). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.922 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.922 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 41 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:29.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.923 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished\n",
      "10-20 20:32:29.924 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 30 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031831 s\n",
      "10-20 20:32:29.924 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(71) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.925 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_71_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.927 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:29.929 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:29.929 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 73 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.939 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.939 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 31 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.939 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 42 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.939 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.940 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.940 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[122] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:29.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:29.944 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:29.945 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:29.946 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[122] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:29.946 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:29.947 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:29.951 172.17.0.2:54321      18300  0 (TID 44)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 42.0 (TID 44)\n",
      "10-20 20:32:29.966 172.17.0.2:54321      18300  0 (TID 44)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:29.972 172.17.0.2:54321      18300  0 (TID 44)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 42.0 (TID 44). 3456 bytes result sent to driver\n",
      "10-20 20:32:29.973 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:29.973 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:29.974 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 42 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:32:29.974 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:29.974 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished\n",
      "10-20 20:32:29.975 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 31 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035798 s\n",
      "10-20 20:32:29.975 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(73) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:29.977 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_73_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.979 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:29.980 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.432609 (rel: 0.0454) 0.934189\n",
      "10-20 20:32:29.981 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:29.982 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:29.982 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:29.983 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 75 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:29.991 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:29.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 32 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:29.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 43 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:29.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:29.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:29.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[123] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:29.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:30.001 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:30.039 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[123] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.041 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.042 172.17.0.2:54321      18300  0 (TID 45)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 43.0 (TID 45)\n",
      "10-20 20:32:30.055 172.17.0.2:54321      18300  0 (TID 45)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.062 172.17.0.2:54321      18300  0 (TID 45)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 43.0 (TID 45). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.063 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.063 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 43 (treeAggregate at RDDLossFunction.scala:61) finished in 0.069 s\n",
      "10-20 20:32:30.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n",
      "10-20 20:32:30.064 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 32 finished: treeAggregate at RDDLossFunction.scala:61, took 0.072278 s\n",
      "10-20 20:32:30.064 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(75) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.065 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_75_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.066 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:30.067 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:30.068 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.068 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 77 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 33 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 44 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.083 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.083 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[124] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:30.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:30.090 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[124] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.092 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.092 172.17.0.2:54321      18300  0 (TID 46)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 44.0 (TID 46)\n",
      "10-20 20:32:30.101 172.17.0.2:54321      18300  0 (TID 46)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.118 172.17.0.2:54321      18300  0 (TID 46)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 44.0 (TID 46). 3499 bytes result sent to driver\n",
      "10-20 20:32:30.119 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.119 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.120 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 44 (treeAggregate at RDDLossFunction.scala:61) finished in 0.036 s\n",
      "10-20 20:32:30.120 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.120 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "10-20 20:32:30.121 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 33 finished: treeAggregate at RDDLossFunction.scala:61, took 0.039373 s\n",
      "10-20 20:32:30.121 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(77) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.122 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_77_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.123 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.123 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.397531 (rel: 0.0811) 0.239881\n",
      "10-20 20:32:30.125 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:30.126 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:30.126 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.127 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 79 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.135 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 34 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 45 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.140 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.140 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[125] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.143 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:30.144 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:30.145 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.145 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.145 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[125] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.146 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.146 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.147 172.17.0.2:54321      18300  0 (TID 47)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 45.0 (TID 47)\n",
      "10-20 20:32:30.153 172.17.0.2:54321      18300  0 (TID 47)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.159 172.17.0.2:54321      18300  0 (TID 47)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 45.0 (TID 47). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.160 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.160 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.160 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 45 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:30.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "10-20 20:32:30.161 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 34 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025839 s\n",
      "10-20 20:32:30.161 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(79) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.162 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_79_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.163 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:30.163 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:30.164 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 81 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.171 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.172 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 35 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.172 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 46 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.172 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.172 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.172 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[126] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.182 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:30.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:30.184 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[126] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.186 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.187 172.17.0.2:54321      18300  0 (TID 48)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 46.0 (TID 48)\n",
      "10-20 20:32:30.195 172.17.0.2:54321      18300  0 (TID 48)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.203 172.17.0.2:54321      18300  0 (TID 48)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 46.0 (TID 48). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.204 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.204 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 46 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:32:30.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished\n",
      "10-20 20:32:30.205 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 35 finished: treeAggregate at RDDLossFunction.scala:61, took 0.033663 s\n",
      "10-20 20:32:30.206 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(81) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.206 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.207 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.385786 (rel: 0.0295) 0.307046\n",
      "10-20 20:32:30.210 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_81_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.211 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:30.223 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:30.224 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.224 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 83 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.225 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_76_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.228 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_72_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.232 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_68_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.233 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.233 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_82_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.234 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 36 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.234 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 47 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.234 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.234 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.235 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[127] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.235 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_74_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.239 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:30.240 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_80_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.241 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_78_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:30.241 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:30.242 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.242 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[127] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.244 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_70_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:30.244 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.253 172.17.0.2:54321      18300  0 (TID 49)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 47.0 (TID 49)\n",
      "10-20 20:32:30.260 172.17.0.2:54321      18300  0 (TID 49)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.266 172.17.0.2:54321      18300  0 (TID 49)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 47.0 (TID 49). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.267 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 23 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.267 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 47 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:32:30.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "10-20 20:32:30.269 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 36 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035220 s\n",
      "10-20 20:32:30.269 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(83) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.271 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:30.271 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_83_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:30.272 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:30.273 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:30.274 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 85 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.283 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.283 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 37 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.284 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 48 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.284 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.284 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.284 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[128] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.290 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:30.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:30.295 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.298 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[128] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.299 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.300 172.17.0.2:54321      18300  0 (TID 50)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 48.0 (TID 50)\n",
      "10-20 20:32:30.314 172.17.0.2:54321      18300  0 (TID 50)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.325 172.17.0.2:54321      18300  0 (TID 50)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 48.0 (TID 50). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.326 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.326 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 48 (treeAggregate at RDDLossFunction.scala:61) finished in 0.041 s\n",
      "10-20 20:32:30.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished\n",
      "10-20 20:32:30.327 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 37 finished: treeAggregate at RDDLossFunction.scala:61, took 0.044233 s\n",
      "10-20 20:32:30.328 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(85) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.329 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_85_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.330 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.330 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.377941 (rel: 0.0203) 0.193084\n",
      "10-20 20:32:30.332 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:30.333 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:30.334 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.334 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 87 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.342 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 38 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 49 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.344 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[129] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:30.349 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:30.350 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[129] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.353 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.354 172.17.0.2:54321      18300  0 (TID 51)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 49.0 (TID 51)\n",
      "10-20 20:32:30.361 172.17.0.2:54321      18300  0 (TID 51)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.366 172.17.0.2:54321      18300  0 (TID 51)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 49.0 (TID 51). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.367 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.367 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 49 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:30.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.369 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "10-20 20:32:30.369 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 38 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026932 s\n",
      "10-20 20:32:30.370 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(87) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.371 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_87_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.372 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:30.373 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:30.374 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.377 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 89 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.384 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 39 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 50 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[130] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.389 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:30.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:30.392 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.393 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[130] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.393 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.394 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.396 172.17.0.2:54321      18300  0 (TID 52)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 50.0 (TID 52)\n",
      "10-20 20:32:30.436 172.17.0.2:54321      18300  0 (TID 52)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.443 172.17.0.2:54321      18300  0 (TID 52)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 50.0 (TID 52). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.445 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 51 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.445 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 50 (treeAggregate at RDDLossFunction.scala:61) finished in 0.060 s\n",
      "10-20 20:32:30.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished\n",
      "10-20 20:32:30.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 39 finished: treeAggregate at RDDLossFunction.scala:61, took 0.063591 s\n",
      "10-20 20:32:30.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(89) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.449 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.449 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.369437 (rel: 0.0225) 0.270667\n",
      "10-20 20:32:30.450 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_89_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.452 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:30.453 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:30.454 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.455 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 91 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.463 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 40 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.463 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 51 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.463 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.464 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.464 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[131] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:30.473 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:30.474 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[131] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.478 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.479 172.17.0.2:54321      18300  0 (TID 53)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 51.0 (TID 53)\n",
      "10-20 20:32:30.489 172.17.0.2:54321      18300  0 (TID 53)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.495 172.17.0.2:54321      18300  0 (TID 53)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 51.0 (TID 53). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.496 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.496 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.498 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 51 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:32:30.499 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.499 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "10-20 20:32:30.500 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 40 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037065 s\n",
      "10-20 20:32:30.501 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(91) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.503 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:30.503 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:30.504 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_91_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.504 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.504 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 93 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.513 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.514 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 41 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.514 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 52 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.514 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[132] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:30.520 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:30.521 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.521 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.522 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[132] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.522 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.524 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.525 172.17.0.2:54321      18300  0 (TID 54)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 52.0 (TID 54)\n",
      "10-20 20:32:30.531 172.17.0.2:54321      18300  0 (TID 54)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.538 172.17.0.2:54321      18300  0 (TID 54)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 52.0 (TID 54). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.538 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.539 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 52 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:30.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n",
      "10-20 20:32:30.540 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 41 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026780 s\n",
      "10-20 20:32:30.541 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(93) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.542 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.542 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_93_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.542 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.364868 (rel: 0.0124) 0.0880531\n",
      "10-20 20:32:30.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:30.546 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:30.548 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.548 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 95 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.555 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 42 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 53 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[133] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:30.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:30.575 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_88_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.575 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[133] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.577 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_92_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.578 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.578 172.17.0.2:54321      18300  0 (TID 55)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 53.0 (TID 55)\n",
      "10-20 20:32:30.579 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_86_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.581 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_84_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.583 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_94_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.585 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_90_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:30.587 172.17.0.2:54321      18300  0 (TID 55)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.593 172.17.0.2:54321      18300  0 (TID 55)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 53.0 (TID 55). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.594 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.594 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 53 (treeAggregate at RDDLossFunction.scala:61) finished in 0.035 s\n",
      "10-20 20:32:30.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "10-20 20:32:30.595 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 42 finished: treeAggregate at RDDLossFunction.scala:61, took 0.039385 s\n",
      "10-20 20:32:30.596 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(95) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.597 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:30.598 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_95_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:30.599 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:30.599 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:30.600 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 97 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.607 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 43 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 54 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.610 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[134] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:30.614 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:30.615 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.615 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.616 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[134] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.616 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.617 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.618 172.17.0.2:54321      18300  0 (TID 56)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 54.0 (TID 56)\n",
      "10-20 20:32:30.625 172.17.0.2:54321      18300  0 (TID 56)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.631 172.17.0.2:54321      18300  0 (TID 56)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 54.0 (TID 56). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.632 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.632 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 54 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:30.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "10-20 20:32:30.634 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 43 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024766 s\n",
      "10-20 20:32:30.634 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(97) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.634 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.635 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.360842 (rel: 0.0110) 0.0884416\n",
      "10-20 20:32:30.635 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_97_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.635 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:30.636 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 988.0 B, free 430.0 MiB)\n",
      "10-20 20:32:30.637 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 5b5a8eb7561c:44751 (size: 988.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.637 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 99 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.645 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 44 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 55 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[135] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:30.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:30.652 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.652 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.653 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[135] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.653 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.653 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.654 172.17.0.2:54321      18300  0 (TID 57)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 55.0 (TID 57)\n",
      "10-20 20:32:30.660 172.17.0.2:54321      18300  0 (TID 57)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.666 172.17.0.2:54321      18300  0 (TID 57)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 55.0 (TID 57). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.667 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.667 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 55 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:30.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "10-20 20:32:30.668 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 44 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022998 s\n",
      "10-20 20:32:30.669 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(99) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.670 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:30.671 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:30.671 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_99_piece0 on 5b5a8eb7561c:44751 in memory (size: 988.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.671 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.672 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 101 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.681 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 45 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 56 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[136] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.686 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:30.688 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:30.689 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.690 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[136] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.693 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.694 172.17.0.2:54321      18300  0 (TID 58)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 56.0 (TID 58)\n",
      "10-20 20:32:30.701 172.17.0.2:54321      18300  0 (TID 58)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.707 172.17.0.2:54321      18300  0 (TID 58)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 56.0 (TID 58). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.708 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.708 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.709 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 56 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:30.710 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.710 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished\n",
      "10-20 20:32:30.710 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 45 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028621 s\n",
      "10-20 20:32:30.711 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(101) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.712 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_101_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.713 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.713 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.352183 (rel: 0.0240) 0.119662\n",
      "10-20 20:32:30.715 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:30.716 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:30.717 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:30.718 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 103 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.727 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 46 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 57 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[137] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.732 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:30.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:30.734 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[137] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.736 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.736 172.17.0.2:54321      18300  0 (TID 59)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 57.0 (TID 59)\n",
      "10-20 20:32:30.747 172.17.0.2:54321      18300  0 (TID 59)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.755 172.17.0.2:54321      18300  0 (TID 59)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 57.0 (TID 59). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.755 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.756 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.756 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 57 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:30.756 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.756 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "10-20 20:32:30.756 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 46 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029429 s\n",
      "10-20 20:32:30.757 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(103) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.758 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:30.759 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:30.759 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_103_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.759 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.760 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 105 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.768 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 47 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 58 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.769 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.769 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[138] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:30.774 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:30.775 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.775 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.776 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[138] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.776 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.777 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.802 172.17.0.2:54321      18300  0 (TID 60)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 58.0 (TID 60)\n",
      "10-20 20:32:30.809 172.17.0.2:54321      18300  0 (TID 60)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.814 172.17.0.2:54321      18300  0 (TID 60)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 58.0 (TID 60). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.815 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 38 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.815 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 58 (treeAggregate at RDDLossFunction.scala:61) finished in 0.046 s\n",
      "10-20 20:32:30.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished\n",
      "10-20 20:32:30.816 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 47 finished: treeAggregate at RDDLossFunction.scala:61, took 0.048142 s\n",
      "10-20 20:32:30.817 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(105) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.817 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.818 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_105_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.818 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.350210 (rel: 0.00560) 0.367147\n",
      "10-20 20:32:30.820 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:30.821 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:30.822 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:30.823 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 107 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.830 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 48 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 59 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.833 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[139] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:30.838 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:30.838 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[139] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.840 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.841 172.17.0.2:54321      18300  0 (TID 61)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 59.0 (TID 61)\n",
      "10-20 20:32:30.846 172.17.0.2:54321      18300  0 (TID 61)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.852 172.17.0.2:54321      18300  0 (TID 61)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 59.0 (TID 61). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.853 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.853 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 59 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:30.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n",
      "10-20 20:32:30.855 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 48 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024077 s\n",
      "10-20 20:32:30.855 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(107) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.856 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_107_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:30.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:30.858 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.858 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 109 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.865 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 49 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.867 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 60 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.874 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.875 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.877 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[140] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:30.893 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:30.893 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.894 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[140] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.896 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.897 172.17.0.2:54321      18300  0 (TID 62)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 60.0 (TID 62)\n",
      "10-20 20:32:30.908 172.17.0.2:54321      18300  0 (TID 62)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.914 172.17.0.2:54321      18300  0 (TID 62)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 60.0 (TID 62). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.915 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.915 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 60 (treeAggregate at RDDLossFunction.scala:61) finished in 0.038 s\n",
      "10-20 20:32:30.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished\n",
      "10-20 20:32:30.916 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 49 finished: treeAggregate at RDDLossFunction.scala:61, took 0.050918 s\n",
      "10-20 20:32:30.917 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(109) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.918 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:30.918 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_109_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.919 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.347601 (rel: 0.00745) 0.172029\n",
      "10-20 20:32:30.920 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:30.921 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:30.922 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:30.923 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 111 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.934 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 50 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 61 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[141] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:30.940 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_112 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:30.951 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:30.952 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.952 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_110_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.953 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:30.953 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[141] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:30.953 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_98_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:30.953 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:30.956 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:30.956 172.17.0.2:54321      18300  0 (TID 63)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 61.0 (TID 63)\n",
      "10-20 20:32:30.957 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_96_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.959 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_104_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:30.960 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_108_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.962 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_102_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.963 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_100_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:30.967 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_106_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:30.971 172.17.0.2:54321      18300  0 (TID 63)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:30.977 172.17.0.2:54321      18300  0 (TID 63)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 61.0 (TID 63). 3456 bytes result sent to driver\n",
      "10-20 20:32:30.978 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:30.978 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:30.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 61 (treeAggregate at RDDLossFunction.scala:61) finished in 0.043 s\n",
      "10-20 20:32:30.980 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:30.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n",
      "10-20 20:32:30.981 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 50 finished: treeAggregate at RDDLossFunction.scala:61, took 0.046430 s\n",
      "10-20 20:32:30.982 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(111) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:30.983 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_111_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:30.983 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_113 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:30.984 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:30.985 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:30.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 113 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:30.995 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:30.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 51 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:30.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 62 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:30.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:30.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:30.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[142] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.001 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_114 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:31.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:31.003 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[142] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.005 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.006 172.17.0.2:54321      18300  0 (TID 64)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 62.0 (TID 64)\n",
      "10-20 20:32:31.017 172.17.0.2:54321      18300  0 (TID 64)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.023 172.17.0.2:54321      18300  0 (TID 64)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 62.0 (TID 64). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.024 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.024 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 62 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:31.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished\n",
      "10-20 20:32:31.025 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 51 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029721 s\n",
      "10-20 20:32:31.026 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(113) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.026 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.027 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.346303 (rel: 0.00374) 0.0479282\n",
      "10-20 20:32:31.028 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_115 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:31.028 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:31.029 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.029 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_113_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.030 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 115 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.037 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 52 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 63 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[143] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.043 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_116 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:31.044 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:31.045 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[143] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.048 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.048 172.17.0.2:54321      18300  0 (TID 65)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 63.0 (TID 65)\n",
      "10-20 20:32:31.056 172.17.0.2:54321      18300  0 (TID 65)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.064 172.17.0.2:54321      18300  0 (TID 65)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 63.0 (TID 65). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.065 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.065 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.066 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 63 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:31.066 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.066 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished\n",
      "10-20 20:32:31.066 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 52 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029157 s\n",
      "10-20 20:32:31.067 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(115) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.067 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_117 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:31.068 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:31.069 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_115_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.069 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.070 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 117 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.086 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.087 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 53 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.087 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 64 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.087 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.087 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[144] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_118 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:31.092 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:31.092 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[144] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.094 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.095 172.17.0.2:54321      18300  0 (TID 66)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 64.0 (TID 66)\n",
      "10-20 20:32:31.106 172.17.0.2:54321      18300  0 (TID 66)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.119 172.17.0.2:54321      18300  0 (TID 66)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 64.0 (TID 66). 3499 bytes result sent to driver\n",
      "10-20 20:32:31.121 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.121 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.122 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 64 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:32:31.122 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.122 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished\n",
      "10-20 20:32:31.122 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 53 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035496 s\n",
      "10-20 20:32:31.123 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(117) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.123 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.123 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_117_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.124 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.345162 (rel: 0.00329) 0.0439294\n",
      "10-20 20:32:31.126 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_119 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:31.127 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:31.128 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.128 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 119 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 54 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 65 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.138 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.138 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[145] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.142 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_120 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:31.143 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:31.143 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.144 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.144 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[145] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.144 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.145 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.148 172.17.0.2:54321      18300  0 (TID 67)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 65.0 (TID 67)\n",
      "10-20 20:32:31.157 172.17.0.2:54321      18300  0 (TID 67)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.171 172.17.0.2:54321      18300  0 (TID 67)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 65.0 (TID 67). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.172 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.172 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.173 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 65 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:32:31.173 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.173 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "10-20 20:32:31.175 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 54 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037746 s\n",
      "10-20 20:32:31.175 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(119) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.176 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_119_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.178 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_121 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:31.180 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:31.181 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.182 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 121 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.193 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 55 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 66 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.197 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[146] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_122 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:31.203 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:31.203 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.203 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[146] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.206 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.207 172.17.0.2:54321      18300  0 (TID 68)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 66.0 (TID 68)\n",
      "10-20 20:32:31.239 172.17.0.2:54321      18300  0 (TID 68)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.248 172.17.0.2:54321      18300  0 (TID 68)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 66.0 (TID 68). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.249 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 43 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.249 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 66 (treeAggregate at RDDLossFunction.scala:61) finished in 0.051 s\n",
      "10-20 20:32:31.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished\n",
      "10-20 20:32:31.250 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 55 finished: treeAggregate at RDDLossFunction.scala:61, took 0.056988 s\n",
      "10-20 20:32:31.251 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(121) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.252 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.252 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.342643 (rel: 0.00730) 0.160789\n",
      "10-20 20:32:31.253 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_123 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:31.254 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_121_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.255 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:31.256 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 123 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.275 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 56 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 67 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.277 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[147] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.283 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_124 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:31.285 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:31.285 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.287 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.287 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[147] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.287 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.289 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 69) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.290 172.17.0.2:54321      18300  0 (TID 69)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 67.0 (TID 69)\n",
      "10-20 20:32:31.307 172.17.0.2:54321      18300  0 (TID 69)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.316 172.17.0.2:54321      18300  0 (TID 69)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 67.0 (TID 69). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.317 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 69) in 28 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.317 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.318 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 67 (treeAggregate at RDDLossFunction.scala:61) finished in 0.040 s\n",
      "10-20 20:32:31.319 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.319 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "10-20 20:32:31.319 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 56 finished: treeAggregate at RDDLossFunction.scala:61, took 0.043908 s\n",
      "10-20 20:32:31.320 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(123) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.321 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_125 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:31.322 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_123_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.322 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:31.323 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.324 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 125 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.335 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 57 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 68 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.338 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[148] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_126 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:31.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:31.346 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[148] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.349 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 70) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.353 172.17.0.2:54321      18300  0 (TID 70)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 68.0 (TID 70)\n",
      "10-20 20:32:31.367 172.17.0.2:54321      18300  0 (TID 70)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.374 172.17.0.2:54321      18300  0 (TID 70)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 68.0 (TID 70). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.374 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 70) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.374 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.375 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 68 (treeAggregate at RDDLossFunction.scala:61) finished in 0.036 s\n",
      "10-20 20:32:31.375 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.375 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished\n",
      "10-20 20:32:31.375 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 57 finished: treeAggregate at RDDLossFunction.scala:61, took 0.040058 s\n",
      "10-20 20:32:31.376 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(125) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.377 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.377 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.341378 (rel: 0.00369) 0.0470574\n",
      "10-20 20:32:31.378 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_127 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:31.379 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:31.380 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_125_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.380 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.391 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 127 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.400 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.402 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 58 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.402 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 69 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.402 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.403 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.403 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[149] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.409 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_128 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:31.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:31.429 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.433 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[149] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.433 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.434 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 71) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.434 172.17.0.2:54321      18300  0 (TID 71)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 69.0 (TID 71)\n",
      "10-20 20:32:31.439 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_112_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.441 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_126_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.442 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_118_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.443 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_116_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.446 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_120_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.447 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_114_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.447 172.17.0.2:54321      18300  0 (TID 71)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.449 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_124_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.451 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_122_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:31.462 172.17.0.2:54321      18300  0 (TID 71)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 69.0 (TID 71). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.467 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 71) in 34 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.467 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 69 (treeAggregate at RDDLossFunction.scala:61) finished in 0.065 s\n",
      "10-20 20:32:31.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished\n",
      "10-20 20:32:31.469 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 58 finished: treeAggregate at RDDLossFunction.scala:61, took 0.066674 s\n",
      "10-20 20:32:31.469 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(127) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.470 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_127_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:31.470 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_129 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:31.471 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:31.472 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:31.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 129 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.480 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.481 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 59 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.481 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 70 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.481 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.482 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.482 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[150] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_130 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:31.489 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:31.490 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.490 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[150] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.492 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 70.0 (TID 72) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.492 172.17.0.2:54321      18300  0 (TID 72)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 70.0 (TID 72)\n",
      "10-20 20:32:31.500 172.17.0.2:54321      18300  0 (TID 72)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.510 172.17.0.2:54321      18300  0 (TID 72)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 70.0 (TID 72). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.517 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 70.0 (TID 72) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.517 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 70 (treeAggregate at RDDLossFunction.scala:61) finished in 0.035 s\n",
      "10-20 20:32:31.520 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.520 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished\n",
      "10-20 20:32:31.520 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 59 finished: treeAggregate at RDDLossFunction.scala:61, took 0.039139 s\n",
      "10-20 20:32:31.521 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(129) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.523 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_129_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.524 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.525 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.340668 (rel: 0.00208) 0.0811123\n",
      "10-20 20:32:31.528 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_131 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:31.529 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:31.529 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.530 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 131 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.540 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 60 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 71 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[151] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.546 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_132 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:31.547 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:31.547 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.548 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.548 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[151] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.548 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.549 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 73) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.550 172.17.0.2:54321      18300  0 (TID 73)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 71.0 (TID 73)\n",
      "10-20 20:32:31.557 172.17.0.2:54321      18300  0 (TID 73)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.562 172.17.0.2:54321      18300  0 (TID 73)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 71.0 (TID 73). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.563 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 73) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.564 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 71 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:31.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished\n",
      "10-20 20:32:31.564 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 60 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023978 s\n",
      "10-20 20:32:31.566 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(131) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.574 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_131_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.576 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_133 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:31.577 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:31.577 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.578 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 133 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.589 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.589 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 61 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.589 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 72 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.589 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.590 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.590 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_134 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:31.596 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:31.596 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.598 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 74) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.599 172.17.0.2:54321      18300  0 (TID 74)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 72.0 (TID 74)\n",
      "10-20 20:32:31.608 172.17.0.2:54321      18300  0 (TID 74)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.614 172.17.0.2:54321      18300  0 (TID 74)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 72.0 (TID 74). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.615 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 74) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.615 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.616 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 72 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:32:31.616 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.616 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished\n",
      "10-20 20:32:31.616 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 61 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027170 s\n",
      "10-20 20:32:31.617 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(133) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.617 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.617 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_133_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.618 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.340063 (rel: 0.00178) 0.0439857\n",
      "10-20 20:32:31.619 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_135 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:31.620 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:31.620 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.621 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 135 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.628 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 62 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 73 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.630 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[153] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_136 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:31.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:31.635 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[153] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.638 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 75) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.639 172.17.0.2:54321      18300  0 (TID 75)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 73.0 (TID 75)\n",
      "10-20 20:32:31.646 172.17.0.2:54321      18300  0 (TID 75)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.654 172.17.0.2:54321      18300  0 (TID 75)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 73.0 (TID 75). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.655 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 75) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.655 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.656 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 73 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:31.656 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.656 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished\n",
      "10-20 20:32:31.656 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 62 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027692 s\n",
      "10-20 20:32:31.657 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(135) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.658 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_135_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.659 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_137 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:31.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:31.660 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 137 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.690 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 63 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 74 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.692 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[154] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.696 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_138 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:31.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:31.700 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.700 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[154] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.702 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 76) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.703 172.17.0.2:54321      18300  0 (TID 76)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 74.0 (TID 76)\n",
      "10-20 20:32:31.712 172.17.0.2:54321      18300  0 (TID 76)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.718 172.17.0.2:54321      18300  0 (TID 76)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 74.0 (TID 76). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.719 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 76) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.719 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 74 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:32:31.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished\n",
      "10-20 20:32:31.729 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 63 finished: treeAggregate at RDDLossFunction.scala:61, took 0.038016 s\n",
      "10-20 20:32:31.729 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(137) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.730 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.730 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.339847 (rel: 0.000636) 0.0314028\n",
      "10-20 20:32:31.731 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_137_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.731 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_139 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:31.736 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:31.737 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:31.737 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 139 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.750 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 64 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 75 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[155] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_140 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:31.763 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:31.764 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[155] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.766 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.767 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 75.0 (TID 77) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.768 172.17.0.2:54321      18300  0 (TID 77)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 75.0 (TID 77)\n",
      "10-20 20:32:31.779 172.17.0.2:54321      18300  0 (TID 77)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.792 172.17.0.2:54321      18300  0 (TID 77)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 75.0 (TID 77). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.793 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 75.0 (TID 77) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.793 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 75 (treeAggregate at RDDLossFunction.scala:61) finished in 0.041 s\n",
      "10-20 20:32:31.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished\n",
      "10-20 20:32:31.794 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 64 finished: treeAggregate at RDDLossFunction.scala:61, took 0.043653 s\n",
      "10-20 20:32:31.796 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(139) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.799 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_139_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.799 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_141 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:31.801 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:31.801 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.802 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 141 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.816 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 65 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 76 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[156] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_142 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:31.825 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:31.826 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.826 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[156] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.828 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 78) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.829 172.17.0.2:54321      18300  0 (TID 78)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 76.0 (TID 78)\n",
      "10-20 20:32:31.837 172.17.0.2:54321      18300  0 (TID 78)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.846 172.17.0.2:54321      18300  0 (TID 78)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 76.0 (TID 78). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.847 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 78) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.847 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 76 (treeAggregate at RDDLossFunction.scala:61) finished in 0.029 s\n",
      "10-20 20:32:31.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished\n",
      "10-20 20:32:31.848 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 65 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031922 s\n",
      "10-20 20:32:31.849 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(141) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.850 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_141_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.850 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.851 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.339727 (rel: 0.000352) 0.0284331\n",
      "10-20 20:32:31.853 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_143 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:31.866 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:31.867 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_140_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:31.869 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:31.870 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 143 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.871 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_136_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.873 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_128_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.876 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_130_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.880 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.880 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 66 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.880 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 77 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.880 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.881 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.881 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[157] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.885 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_144 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:31.886 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:31.887 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:31.887 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[157] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.889 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 79) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.890 172.17.0.2:54321      18300  0 (TID 79)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 77.0 (TID 79)\n",
      "10-20 20:32:31.890 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_134_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.898 172.17.0.2:54321      18300  0 (TID 79)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.907 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_142_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.909 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_132_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.911 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_138_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:31.912 172.17.0.2:54321      18300  0 (TID 79)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 77.0 (TID 79). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.913 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 79) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.913 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.914 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 77 (treeAggregate at RDDLossFunction.scala:61) finished in 0.033 s\n",
      "10-20 20:32:31.914 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.914 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished\n",
      "10-20 20:32:31.914 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 66 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034386 s\n",
      "10-20 20:32:31.915 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(143) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.917 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_145 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:31.919 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:31.920 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_143_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:31.920 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:31.921 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 145 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.935 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 67 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 78 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.935 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[158] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_146 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:31.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:31.943 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_146_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[158] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.945 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 80) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.946 172.17.0.2:54321      18300  0 (TID 80)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 78.0 (TID 80)\n",
      "10-20 20:32:31.952 172.17.0.2:54321      18300  0 (TID 80)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.958 172.17.0.2:54321      18300  0 (TID 80)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 78.0 (TID 80). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.959 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 80) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.959 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.960 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 78 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:31.960 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.960 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished\n",
      "10-20 20:32:31.961 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 67 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025761 s\n",
      "10-20 20:32:31.961 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(145) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:31.962 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:31.963 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.339206 (rel: 0.00153) 0.0242865\n",
      "10-20 20:32:31.964 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_147 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:31.964 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:31.964 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_145_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.965 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_147_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:31.966 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 147 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:31.973 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:31.974 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 68 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:31.974 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 79 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:31.974 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:31.975 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:31.975 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[159] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:31.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_148 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:31.980 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:31.980 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_148_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:31.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:31.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[159] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:31.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:31.982 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 79.0 (TID 81) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:31.983 172.17.0.2:54321      18300  0 (TID 81)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 79.0 (TID 81)\n",
      "10-20 20:32:31.989 172.17.0.2:54321      18300  0 (TID 81)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:31.996 172.17.0.2:54321      18300  0 (TID 81)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 79.0 (TID 81). 3456 bytes result sent to driver\n",
      "10-20 20:32:31.997 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 79.0 (TID 81) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:31.997 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:31.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 79 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:31.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:31.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished\n",
      "10-20 20:32:31.999 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 68 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024813 s\n",
      "10-20 20:32:31.999 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(147) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.000 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_147_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.001 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_149 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:32.002 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:32.003 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_149_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.003 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 149 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.012 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 69 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 80 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.014 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.014 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[160] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.017 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_150 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:32.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:32.019 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_150_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.020 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[160] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.020 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.021 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 82) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.022 172.17.0.2:54321      18300  0 (TID 82)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 80.0 (TID 82)\n",
      "10-20 20:32:32.029 172.17.0.2:54321      18300  0 (TID 82)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.034 172.17.0.2:54321      18300  0 (TID 82)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 80.0 (TID 82). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.035 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 82) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.035 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 80 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:32.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n",
      "10-20 20:32:32.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 69 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025151 s\n",
      "10-20 20:32:32.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(149) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.039 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:32.039 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_149_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.040 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.338586 (rel: 0.00183) 0.0246537\n",
      "10-20 20:32:32.041 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_151 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:32.042 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:32.043 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_151_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.043 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 151 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.051 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 70 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.051 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 81 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.051 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.051 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[161] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.056 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_152 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:32.057 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:32.057 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_152_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.057 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.058 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[161] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.058 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.060 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 83) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.061 172.17.0.2:54321      18300  0 (TID 83)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 81.0 (TID 83)\n",
      "10-20 20:32:32.094 172.17.0.2:54321      18300  0 (TID 83)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.099 172.17.0.2:54321      18300  0 (TID 83)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 81.0 (TID 83). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.100 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 83) in 41 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.100 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.100 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 81 (treeAggregate at RDDLossFunction.scala:61) finished in 0.048 s\n",
      "10-20 20:32:32.101 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.101 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished\n",
      "10-20 20:32:32.101 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 70 finished: treeAggregate at RDDLossFunction.scala:61, took 0.049958 s\n",
      "10-20 20:32:32.101 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(151) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.103 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_153 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:32.104 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_151_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.105 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:32.105 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_153_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.106 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 153 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.114 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 71 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 82 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[162] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.119 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_154 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:32.120 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:32.121 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_154_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.121 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.121 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[162] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.122 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.122 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 84) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.123 172.17.0.2:54321      18300  0 (TID 84)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 82.0 (TID 84)\n",
      "10-20 20:32:32.129 172.17.0.2:54321      18300  0 (TID 84)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.135 172.17.0.2:54321      18300  0 (TID 84)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 82.0 (TID 84). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.136 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 84) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.136 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 82 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:32.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished\n",
      "10-20 20:32:32.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 71 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022769 s\n",
      "10-20 20:32:32.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(153) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.137 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:32.138 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_153_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.138 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.338267 (rel: 0.000941) 0.0953306\n",
      "10-20 20:32:32.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_155 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:32.151 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:32.151 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_155_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.152 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 155 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.162 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 72 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 83 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[163] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.167 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_156 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:32.168 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:32.169 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_156_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.170 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.171 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[163] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.171 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.172 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 85) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.173 172.17.0.2:54321      18300  0 (TID 85)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 83.0 (TID 85)\n",
      "10-20 20:32:32.179 172.17.0.2:54321      18300  0 (TID 85)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.185 172.17.0.2:54321      18300  0 (TID 85)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 83.0 (TID 85). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.186 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 85) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.186 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.187 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 83 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:32.187 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.187 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished\n",
      "10-20 20:32:32.187 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 72 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025010 s\n",
      "10-20 20:32:32.188 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(155) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.189 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_155_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.190 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_157 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:32.191 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:32.191 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_157_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.192 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 157 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.200 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 73 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 84 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[164] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_158 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:32.206 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:32.207 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_158_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.207 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.207 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[164] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.207 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.209 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 84.0 (TID 86) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.210 172.17.0.2:54321      18300  0 (TID 86)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 84.0 (TID 86)\n",
      "10-20 20:32:32.218 172.17.0.2:54321      18300  0 (TID 86)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.223 172.17.0.2:54321      18300  0 (TID 86)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 84.0 (TID 86). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.224 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 84.0 (TID 86) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.224 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.225 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 84 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:32.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished\n",
      "10-20 20:32:32.226 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 73 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026080 s\n",
      "10-20 20:32:32.227 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(157) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.228 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:32.228 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_157_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.228 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.338029 (rel: 0.000704) 0.0434616\n",
      "10-20 20:32:32.229 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_159 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:32.238 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:32.238 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_159_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.238 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_158_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.239 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 159 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.239 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_148_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.242 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_156_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.246 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_144_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.248 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_154_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.249 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_150_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.250 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 74 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 85 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[165] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.254 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_160 stored as values in memory (estimated size 131.5 KiB, free 430.0 MiB)\n",
      "10-20 20:32:32.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:32.256 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_152_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:32.256 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_160_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[165] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.257 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.257 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_146_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:32.258 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 87) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.259 172.17.0.2:54321      18300  0 (TID 87)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 85.0 (TID 87)\n",
      "10-20 20:32:32.268 172.17.0.2:54321      18300  0 (TID 87)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.274 172.17.0.2:54321      18300  0 (TID 87)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 85.0 (TID 87). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.274 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 87) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.274 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 85 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:32.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished\n",
      "10-20 20:32:32.276 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 74 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026140 s\n",
      "10-20 20:32:32.277 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(159) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.278 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_159_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:32.279 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_161 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:32.280 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:32.280 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_161_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:32.281 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 161 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.289 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.290 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 75 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.290 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 86 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.290 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.290 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.290 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[166] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.294 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_162 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:32.296 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:32.296 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_162_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.296 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[166] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.298 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 88) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.298 172.17.0.2:54321      18300  0 (TID 88)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 86.0 (TID 88)\n",
      "10-20 20:32:32.305 172.17.0.2:54321      18300  0 (TID 88)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.311 172.17.0.2:54321      18300  0 (TID 88)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 86.0 (TID 88). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.312 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 88) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.312 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 86 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:32.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished\n",
      "10-20 20:32:32.313 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 75 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024191 s\n",
      "10-20 20:32:32.314 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(161) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.315 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_161_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.315 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_163 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:32.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:32.317 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_163_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.317 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 163 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.325 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 76 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 87 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[167] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_164 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:32.337 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:32.337 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_164_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.338 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.338 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[167] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.338 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.339 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 89) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.339 172.17.0.2:54321      18300  0 (TID 89)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 87.0 (TID 89)\n",
      "10-20 20:32:32.351 172.17.0.2:54321      18300  0 (TID 89)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.358 172.17.0.2:54321      18300  0 (TID 89)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 87.0 (TID 89). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.359 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 89) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.359 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 87 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:32:32.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished\n",
      "10-20 20:32:32.361 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 76 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035724 s\n",
      "10-20 20:32:32.362 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(163) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.363 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.2500\n",
      "10-20 20:32:32.363 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_163_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.363 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337954 (rel: 0.000220) 0.0286528\n",
      "10-20 20:32:32.365 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_165 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:32.366 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:32.366 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_165_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.367 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 165 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.375 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.376 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 77 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.376 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 88 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.376 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.376 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.377 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[168] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_166 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:32.381 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:32.382 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_166_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[168] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.384 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 88.0 (TID 90) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.384 172.17.0.2:54321      18300  0 (TID 90)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 88.0 (TID 90)\n",
      "10-20 20:32:32.391 172.17.0.2:54321      18300  0 (TID 90)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.398 172.17.0.2:54321      18300  0 (TID 90)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 88.0 (TID 90). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.399 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 88.0 (TID 90) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.399 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 88 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:32.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished\n",
      "10-20 20:32:32.400 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 77 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024027 s\n",
      "10-20 20:32:32.400 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(165) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.401 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_167 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:32.402 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_165_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.402 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:32.403 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_167_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.404 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 167 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.411 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 78 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 89 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.414 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[169] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.417 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_168 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:32.418 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:32.419 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_168_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.419 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.419 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[169] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.419 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.423 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 91) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.425 172.17.0.2:54321      18300  0 (TID 91)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 89.0 (TID 91)\n",
      "10-20 20:32:32.464 172.17.0.2:54321      18300  0 (TID 91)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.470 172.17.0.2:54321      18300  0 (TID 91)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 89.0 (TID 91). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.471 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 91) in 48 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.471 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 89 (treeAggregate at RDDLossFunction.scala:61) finished in 0.057 s\n",
      "10-20 20:32:32.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished\n",
      "10-20 20:32:32.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 78 finished: treeAggregate at RDDLossFunction.scala:61, took 0.060719 s\n",
      "10-20 20:32:32.473 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(167) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.474 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_169 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:32.474 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_167_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.474 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:32.474 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_169_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.475 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 169 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.482 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 79 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 90 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[170] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.486 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_170 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:32.487 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:32.488 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_170_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[170] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.489 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.489 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 92) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.490 172.17.0.2:54321      18300  0 (TID 92)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 90.0 (TID 92)\n",
      "10-20 20:32:32.496 172.17.0.2:54321      18300  0 (TID 92)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.501 172.17.0.2:54321      18300  0 (TID 92)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 90.0 (TID 92). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.502 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 92) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.502 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.502 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 90 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:32.502 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.502 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished\n",
      "10-20 20:32:32.503 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 79 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020181 s\n",
      "10-20 20:32:32.503 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(169) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.504 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.2500\n",
      "10-20 20:32:32.504 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337922 (rel: 9.45e-05) 0.0353488\n",
      "10-20 20:32:32.505 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_171 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:32.505 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:32.506 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_169_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.506 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_171_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.506 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 171 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.514 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 80 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 91 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[171] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.518 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_172 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:32.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:32.520 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_172_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.520 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.520 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[171] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.520 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.521 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 93) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.522 172.17.0.2:54321      18300  0 (TID 93)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 91.0 (TID 93)\n",
      "10-20 20:32:32.527 172.17.0.2:54321      18300  0 (TID 93)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.532 172.17.0.2:54321      18300  0 (TID 93)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 91.0 (TID 93). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.533 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 93) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.533 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 91 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:32.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "10-20 20:32:32.534 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 80 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019499 s\n",
      "10-20 20:32:32.534 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(171) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.535 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_173 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:32.535 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_171_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.536 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:32.536 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_173_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.537 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 173 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.544 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 81 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.544 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 92 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.544 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.544 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.544 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[172] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.547 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_174 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:32.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:32.549 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_174_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[172] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.550 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 94) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.551 172.17.0.2:54321      18300  0 (TID 94)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 92.0 (TID 94)\n",
      "10-20 20:32:32.559 172.17.0.2:54321      18300  0 (TID 94)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.566 172.17.0.2:54321      18300  0 (TID 94)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 92.0 (TID 94). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.566 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 94) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.566 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 92 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:32.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished\n",
      "10-20 20:32:32.568 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 81 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024533 s\n",
      "10-20 20:32:32.569 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(173) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.570 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_173_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.571 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_175 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:32.572 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:32.573 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_175_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.574 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 175 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.592 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 82 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 93 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[173] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_176 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:32.599 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:32.599 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_168_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.600 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_176_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[173] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.603 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 93.0 (TID 95) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.603 172.17.0.2:54321      18300  0 (TID 95)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 93.0 (TID 95)\n",
      "10-20 20:32:32.605 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_172_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.607 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_162_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.609 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_164_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.610 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_160_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.611 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_174_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.613 172.17.0.2:54321      18300  0 (TID 95)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.614 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_166_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.619 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_170_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:32.620 172.17.0.2:54321      18300  0 (TID 95)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 93.0 (TID 95). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.621 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 93.0 (TID 95) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.621 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.621 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 93 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:32.622 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.622 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "10-20 20:32:32.622 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 82 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029262 s\n",
      "10-20 20:32:32.623 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(175) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.624 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.2500\n",
      "10-20 20:32:32.624 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337875 (rel: 0.000142) 0.0278510\n",
      "10-20 20:32:32.624 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_175_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:32.626 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_177 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:32.651 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:32.651 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_176_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:32.652 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_177_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:32.654 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 177 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.663 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 83 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 94 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.665 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.665 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[174] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_178 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:32.670 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:32.670 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_178_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:32.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.672 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[174] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.672 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.673 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 96) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.674 172.17.0.2:54321      18300  0 (TID 96)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 94.0 (TID 96)\n",
      "10-20 20:32:32.681 172.17.0.2:54321      18300  0 (TID 96)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.688 172.17.0.2:54321      18300  0 (TID 96)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 94.0 (TID 96). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.691 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 96) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.691 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.692 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 94 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:32.692 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.692 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished\n",
      "10-20 20:32:32.693 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 83 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028809 s\n",
      "10-20 20:32:32.693 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(177) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.694 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_177_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:32.695 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_179 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:32.696 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:32.696 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_179_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:32.696 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 179 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.704 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.705 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 84 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.705 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 95 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.705 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.706 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.706 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[175] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_180 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:32.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:32.713 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_180_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[175] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.716 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 97) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.716 172.17.0.2:54321      18300  0 (TID 97)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 95.0 (TID 97)\n",
      "10-20 20:32:32.724 172.17.0.2:54321      18300  0 (TID 97)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.729 172.17.0.2:54321      18300  0 (TID 97)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 95.0 (TID 97). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.730 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 97) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.730 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.731 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 95 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:32.731 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.731 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished\n",
      "10-20 20:32:32.732 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 84 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027241 s\n",
      "10-20 20:32:32.732 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(179) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.733 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_181 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:32.733 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:32.734 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_179_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.734 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_181_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.734 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 181 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.741 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 85 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 96 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[176] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.746 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_182 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:32.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:32.748 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_182_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.748 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.748 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[176] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.749 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.749 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 98) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.750 172.17.0.2:54321      18300  0 (TID 98)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 96.0 (TID 98)\n",
      "10-20 20:32:32.761 172.17.0.2:54321      18300  0 (TID 98)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.770 172.17.0.2:54321      18300  0 (TID 98)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 96.0 (TID 98). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.771 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 98) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.771 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 96 (treeAggregate at RDDLossFunction.scala:61) finished in 0.029 s\n",
      "10-20 20:32:32.774 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.774 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished\n",
      "10-20 20:32:32.776 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 85 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034669 s\n",
      "10-20 20:32:32.777 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(181) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.778 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.2500\n",
      "10-20 20:32:32.778 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_181_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.778 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337848 (rel: 7.81e-05) 0.0299119\n",
      "10-20 20:32:32.779 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_183 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:32.780 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:32.781 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_183_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.781 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 183 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.796 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 86 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 97 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[177] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.803 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_184 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:32.804 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:32.804 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_184_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:32.805 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.805 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[177] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.805 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.806 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 97.0 (TID 99) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.806 172.17.0.2:54321      18300  0 (TID 99)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 97.0 (TID 99)\n",
      "10-20 20:32:32.813 172.17.0.2:54321      18300  0 (TID 99)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.818 172.17.0.2:54321      18300  0 (TID 99)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 97.0 (TID 99). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.819 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 97.0 (TID 99) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.819 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.820 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 97 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:32.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished\n",
      "10-20 20:32:32.822 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 86 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025474 s\n",
      "10-20 20:32:32.822 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(183) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.824 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_183_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.824 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_185 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:32.825 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:32.826 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_185_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:32.826 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 185 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.834 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 87 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 98 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[178] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_186 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:32.840 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:32.841 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_186_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.841 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[178] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.843 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 100) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.854 172.17.0.2:54321      18300   (TID 100)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 98.0 (TID 100)\n",
      "10-20 20:32:32.860 172.17.0.2:54321      18300   (TID 100)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.866 172.17.0.2:54321      18300   (TID 100)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 98.0 (TID 100). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.867 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 100) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.867 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.867 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 98 (treeAggregate at RDDLossFunction.scala:61) finished in 0.031 s\n",
      "10-20 20:32:32.867 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.867 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished\n",
      "10-20 20:32:32.868 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 87 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034033 s\n",
      "10-20 20:32:32.868 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(185) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.869 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:32.869 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_185_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.869 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337838 (rel: 2.95e-05) 0.0629046\n",
      "10-20 20:32:32.872 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_187 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:32.874 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:32.875 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_187_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.875 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 187 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.883 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.883 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 88 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.883 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 99 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.883 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.884 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.884 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[179] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_188 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:32.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:32.889 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_188_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:32.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[179] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.891 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 101) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.891 172.17.0.2:54321      18300   (TID 101)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 99.0 (TID 101)\n",
      "10-20 20:32:32.897 172.17.0.2:54321      18300   (TID 101)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.902 172.17.0.2:54321      18300   (TID 101)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 99.0 (TID 101). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.903 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 101) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.903 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 99 (treeAggregate at RDDLossFunction.scala:61) finished in 0.041 s\n",
      "10-20 20:32:32.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished\n",
      "10-20 20:32:32.936 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 88 finished: treeAggregate at RDDLossFunction.scala:61, took 0.052783 s\n",
      "10-20 20:32:32.936 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(187) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.937 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_187_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.937 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_189 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:32.938 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:32.938 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_189_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:32.939 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 189 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.956 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:32.957 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 89 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:32.957 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 100 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:32.957 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:32.957 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:32.958 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[180] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:32.961 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_190 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:32.963 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:32.964 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_190_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:32.964 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:32.964 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[180] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:32.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:32.966 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 102) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:32.966 172.17.0.2:54321      18300   (TID 102)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 100.0 (TID 102)\n",
      "10-20 20:32:32.975 172.17.0.2:54321      18300   (TID 102)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:32.984 172.17.0.2:54321      18300   (TID 102)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 100.0 (TID 102). 3456 bytes result sent to driver\n",
      "10-20 20:32:32.985 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 102) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:32.985 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:32.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 100 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:32.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:32.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished\n",
      "10-20 20:32:32.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 89 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030306 s\n",
      "10-20 20:32:32.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(189) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:32.988 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:32.988 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337748 (rel: 0.000268) 0.0389423\n",
      "10-20 20:32:32.989 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_189_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.990 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_191 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:32.991 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:32.991 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_191_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:32.992 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 191 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:32.999 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 90 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 101 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.001 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.001 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[181] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_192 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:33.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:33.005 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_192_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.006 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[181] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.006 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.007 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 103) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.009 172.17.0.2:54321      18300   (TID 103)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 101.0 (TID 103)\n",
      "10-20 20:32:33.017 172.17.0.2:54321      18300   (TID 103)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.025 172.17.0.2:54321      18300   (TID 103)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 101.0 (TID 103). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.026 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 103) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.026 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.026 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 101 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:32:33.026 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.026 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished\n",
      "10-20 20:32:33.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 90 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026927 s\n",
      "10-20 20:32:33.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(191) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.028 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_191_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.029 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_193 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:33.030 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:33.031 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_193_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.031 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 193 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 91 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 102 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[182] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.044 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_194 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:33.045 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:33.045 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_194_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[182] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.047 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 102.0 (TID 104) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.048 172.17.0.2:54321      18300   (TID 104)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 102.0 (TID 104)\n",
      "10-20 20:32:33.057 172.17.0.2:54321      18300   (TID 104)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.068 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_192_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.070 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_184_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.072 172.17.0.2:54321      18300   (TID 104)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 102.0 (TID 104). 3499 bytes result sent to driver\n",
      "10-20 20:32:33.073 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 102.0 (TID 104) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.073 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.074 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 102 (treeAggregate at RDDLossFunction.scala:61) finished in 0.033 s\n",
      "10-20 20:32:33.074 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.074 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished\n",
      "10-20 20:32:33.075 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 91 finished: treeAggregate at RDDLossFunction.scala:61, took 0.036395 s\n",
      "10-20 20:32:33.075 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(193) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.076 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_188_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.076 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_193_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.076 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.077 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_182_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.077 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337713 (rel: 0.000102) 0.0550533\n",
      "10-20 20:32:33.078 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_195 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:32:33.078 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_180_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.088 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_194_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.089 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.090 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_195_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.091 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_178_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.091 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 195 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.094 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_186_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:33.096 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_190_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:33.103 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 92 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 103 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[183] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.109 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_196 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:33.110 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:33.110 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_196_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:33.111 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.111 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[183] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.111 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.113 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 105) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.114 172.17.0.2:54321      18300   (TID 105)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 103.0 (TID 105)\n",
      "10-20 20:32:33.123 172.17.0.2:54321      18300   (TID 105)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.130 172.17.0.2:54321      18300   (TID 105)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 103.0 (TID 105). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.131 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 105) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.131 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 103 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:33.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished\n",
      "10-20 20:32:33.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 92 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035459 s\n",
      "10-20 20:32:33.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(195) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.141 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_197 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:33.141 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_195_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:33.142 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:33.142 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_197_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:33.143 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 197 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.152 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 93 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 104 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[184] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_198 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:33.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:33.158 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_198_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[184] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.160 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 106) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.162 172.17.0.2:54321      18300   (TID 106)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 104.0 (TID 106)\n",
      "10-20 20:32:33.168 172.17.0.2:54321      18300   (TID 106)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.174 172.17.0.2:54321      18300   (TID 106)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 104.0 (TID 106). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.175 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 106) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.175 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.175 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 104 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:33.176 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.176 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished\n",
      "10-20 20:32:33.176 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 93 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023779 s\n",
      "10-20 20:32:33.177 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(197) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.177 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.178 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337637 (rel: 0.000226) 0.0300670\n",
      "10-20 20:32:33.178 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_197_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.179 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_199 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:33.180 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:33.180 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_199_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.181 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 199 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.188 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.189 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 94 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.189 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 105 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.189 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.189 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[185] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.193 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_200 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:33.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:33.195 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_200_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[185] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.197 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 107) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.197 172.17.0.2:54321      18300   (TID 107)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 105.0 (TID 107)\n",
      "10-20 20:32:33.203 172.17.0.2:54321      18300   (TID 107)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.209 172.17.0.2:54321      18300   (TID 107)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 105.0 (TID 107). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.209 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 107) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.209 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 105 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:33.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "10-20 20:32:33.211 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 94 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022345 s\n",
      "10-20 20:32:33.211 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(199) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.212 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_199_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.213 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_201 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.213 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.214 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_201_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.214 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 201 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.221 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 95 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 106 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[186] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.225 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_202 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.227 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_202_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.228 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[186] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.228 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.229 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 106.0 (TID 108) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.229 172.17.0.2:54321      18300   (TID 108)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 106.0 (TID 108)\n",
      "10-20 20:32:33.236 172.17.0.2:54321      18300   (TID 108)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.241 172.17.0.2:54321      18300   (TID 108)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 106.0 (TID 108). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.242 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 106.0 (TID 108) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.242 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 106 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:33.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished\n",
      "10-20 20:32:33.244 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 95 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022675 s\n",
      "10-20 20:32:33.244 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(201) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.245 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.245 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337605 (rel: 9.40e-05) 0.0488254\n",
      "10-20 20:32:33.245 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_201_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.246 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_203 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:33.247 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:33.248 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_203_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.248 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 203 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.256 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 96 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 107 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.257 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.257 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[187] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.260 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_204 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:33.261 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:33.261 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_204_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.262 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.262 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[187] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.262 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.271 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 109) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.272 172.17.0.2:54321      18300   (TID 109)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 107.0 (TID 109)\n",
      "10-20 20:32:33.308 172.17.0.2:54321      18300   (TID 109)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.314 172.17.0.2:54321      18300   (TID 109)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 107.0 (TID 109). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.315 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 109) in 44 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.315 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 107 (treeAggregate at RDDLossFunction.scala:61) finished in 0.059 s\n",
      "10-20 20:32:33.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished\n",
      "10-20 20:32:33.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 96 finished: treeAggregate at RDDLossFunction.scala:61, took 0.060141 s\n",
      "10-20 20:32:33.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(203) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.317 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_205 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:33.317 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_203_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:33.318 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_205_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.319 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 205 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.325 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 97 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 108 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[188] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_206 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:33.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:33.330 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_206_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[188] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.332 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 110) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.333 172.17.0.2:54321      18300   (TID 110)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 108.0 (TID 110)\n",
      "10-20 20:32:33.338 172.17.0.2:54321      18300   (TID 110)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.344 172.17.0.2:54321      18300   (TID 110)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 108.0 (TID 110). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.344 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 110) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.344 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 108 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:33.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished\n",
      "10-20 20:32:33.346 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 97 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020298 s\n",
      "10-20 20:32:33.346 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(205) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.346 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.347 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_205_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.347 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337530 (rel: 0.000223) 0.0298497\n",
      "10-20 20:32:33.348 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_207 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:33.348 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:33.349 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_207_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.349 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 207 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.355 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 98 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 109 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[189] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_208 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:33.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:33.360 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_208_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[189] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.362 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 111) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.366 172.17.0.2:54321      18300   (TID 111)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 109.0 (TID 111)\n",
      "10-20 20:32:33.372 172.17.0.2:54321      18300   (TID 111)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.378 172.17.0.2:54321      18300   (TID 111)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 109.0 (TID 111). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.379 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 111) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.379 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 109 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:33.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished\n",
      "10-20 20:32:33.381 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 98 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025075 s\n",
      "10-20 20:32:33.381 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(207) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.382 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_209 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:33.383 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_207_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.383 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:33.384 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_209_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.384 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 209 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.390 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 99 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 110 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[190] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_210 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:33.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:33.396 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_210_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.396 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.397 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[190] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.397 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.397 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 112) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.400 172.17.0.2:54321      18300   (TID 112)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 110.0 (TID 112)\n",
      "10-20 20:32:33.406 172.17.0.2:54321      18300   (TID 112)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.411 172.17.0.2:54321      18300   (TID 112)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 110.0 (TID 112). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.412 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 112) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.412 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 110 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:33.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished\n",
      "10-20 20:32:33.414 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 99 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023399 s\n",
      "10-20 20:32:33.414 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(209) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.415 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_209_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.415 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.415 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337506 (rel: 7.05e-05) 0.0546179\n",
      "10-20 20:32:33.416 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_211 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:33.417 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:33.417 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_211_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.417 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 211 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.425 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.426 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 100 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.426 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 111 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.426 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.426 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.426 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[191] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_212 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:33.444 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_198_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:33.445 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_212_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.445 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_202_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[191] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.448 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 111.0 (TID 113) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.449 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_206_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.451 172.17.0.2:54321      18300   (TID 113)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 111.0 (TID 113)\n",
      "10-20 20:32:33.452 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_196_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.454 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_200_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.455 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_208_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.458 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_210_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.459 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_204_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:33.462 172.17.0.2:54321      18300   (TID 113)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.469 172.17.0.2:54321      18300   (TID 113)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 111.0 (TID 113). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.472 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 111.0 (TID 113) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.472 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.473 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 111 (treeAggregate at RDDLossFunction.scala:61) finished in 0.046 s\n",
      "10-20 20:32:33.473 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.473 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished\n",
      "10-20 20:32:33.473 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 100 finished: treeAggregate at RDDLossFunction.scala:61, took 0.047734 s\n",
      "10-20 20:32:33.473 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(211) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.475 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_213 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:33.475 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_211_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:33.476 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:33.476 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_213_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:33.476 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 213 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.483 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 101 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 112 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[192] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.489 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_214 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:33.490 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:33.491 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_214_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.492 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.492 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[192] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.493 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.494 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 114) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.494 172.17.0.2:54321      18300   (TID 114)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 112.0 (TID 114)\n",
      "10-20 20:32:33.500 172.17.0.2:54321      18300   (TID 114)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.506 172.17.0.2:54321      18300   (TID 114)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 112.0 (TID 114). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.506 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 114) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.507 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 112 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:33.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished\n",
      "10-20 20:32:33.510 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 101 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026473 s\n",
      "10-20 20:32:33.510 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(213) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.511 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_213_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.511 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.512 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337436 (rel: 0.000209) 0.0368696\n",
      "10-20 20:32:33.512 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_215 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:33.513 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:33.513 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_215_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.514 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 215 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.521 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.521 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 102 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.521 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 113 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.521 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.521 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.522 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[193] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.524 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_216 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:33.525 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:33.526 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_216_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.526 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.527 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[193] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.527 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.528 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 115) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.528 172.17.0.2:54321      18300   (TID 115)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 113.0 (TID 115)\n",
      "10-20 20:32:33.535 172.17.0.2:54321      18300   (TID 115)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.540 172.17.0.2:54321      18300   (TID 115)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 113.0 (TID 115). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.541 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 115) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.541 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 113 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:33.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished\n",
      "10-20 20:32:33.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 102 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021542 s\n",
      "10-20 20:32:33.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(215) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.544 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_215_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.545 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_217 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.546 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.546 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_217_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.547 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 217 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.556 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 103 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 114 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.558 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[194] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_218 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.564 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_218_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[194] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.565 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 116) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.566 172.17.0.2:54321      18300   (TID 116)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 114.0 (TID 116)\n",
      "10-20 20:32:33.573 172.17.0.2:54321      18300   (TID 116)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.580 172.17.0.2:54321      18300   (TID 116)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 114.0 (TID 116). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.581 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 116) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.581 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.582 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 114 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:33.582 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.583 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished\n",
      "10-20 20:32:33.583 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 103 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027106 s\n",
      "10-20 20:32:33.584 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(217) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.584 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.584 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337395 (rel: 0.000120) 0.0399835\n",
      "10-20 20:32:33.585 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_217_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.586 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_219 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:33.587 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:33.587 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_219_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.588 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 219 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.594 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.595 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 104 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.595 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 115 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.595 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.596 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.596 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[195] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.600 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_220 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:33.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:33.601 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_220_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.605 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.605 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[195] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.606 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.607 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 115.0 (TID 117) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.608 172.17.0.2:54321      18300   (TID 117)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 115.0 (TID 117)\n",
      "10-20 20:32:33.615 172.17.0.2:54321      18300   (TID 117)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.644 172.17.0.2:54321      18300   (TID 117)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 115.0 (TID 117). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.646 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 115.0 (TID 117) in 40 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.646 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 115 (treeAggregate at RDDLossFunction.scala:61) finished in 0.054 s\n",
      "10-20 20:32:33.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished\n",
      "10-20 20:32:33.651 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 104 finished: treeAggregate at RDDLossFunction.scala:61, took 0.056857 s\n",
      "10-20 20:32:33.652 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(219) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.653 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_219_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.654 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_221 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:33.655 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:33.655 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_221_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.656 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 221 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.666 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.670 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 105 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 116 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[196] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_222 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:33.675 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:33.676 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_222_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.676 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.677 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[196] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.677 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.678 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 118) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.678 172.17.0.2:54321      18300   (TID 118)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 116.0 (TID 118)\n",
      "10-20 20:32:33.685 172.17.0.2:54321      18300   (TID 118)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.691 172.17.0.2:54321      18300   (TID 118)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 116.0 (TID 118). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.692 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 118) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.692 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.692 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 116 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:33.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished\n",
      "10-20 20:32:33.693 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 105 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027171 s\n",
      "10-20 20:32:33.694 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(221) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.695 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.695 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337344 (rel: 0.000154) 0.0290617\n",
      "10-20 20:32:33.695 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_221_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.696 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_223 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:33.697 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:33.698 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_223_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:33.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 223 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.715 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 106 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 117 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.717 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.717 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[197] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.721 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_224 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:33.730 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:33.732 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_224_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.732 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.732 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[197] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.732 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.734 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 119) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.735 172.17.0.2:54321      18300   (TID 119)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 117.0 (TID 119)\n",
      "10-20 20:32:33.742 172.17.0.2:54321      18300   (TID 119)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.748 172.17.0.2:54321      18300   (TID 119)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 117.0 (TID 119). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.749 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 119) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.749 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.750 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 117 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:32:33.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.751 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished\n",
      "10-20 20:32:33.751 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 106 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035732 s\n",
      "10-20 20:32:33.752 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(223) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.753 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_223_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.753 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_225 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:33.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:33.754 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_225_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.755 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 225 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.763 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 107 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 118 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[198] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.769 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_226 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:33.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:33.771 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_226_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[198] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.774 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 120) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.775 172.17.0.2:54321      18300   (TID 120)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 118.0 (TID 120)\n",
      "10-20 20:32:33.788 172.17.0.2:54321      18300   (TID 120)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.793 172.17.0.2:54321      18300   (TID 120)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 118.0 (TID 120). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.794 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 120) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.795 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 118 (treeAggregate at RDDLossFunction.scala:61) finished in 0.030 s\n",
      "10-20 20:32:33.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished\n",
      "10-20 20:32:33.796 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 107 finished: treeAggregate at RDDLossFunction.scala:61, took 0.032679 s\n",
      "10-20 20:32:33.797 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(225) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.798 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.798 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_225_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.798 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337317 (rel: 7.88e-05) 0.0383630\n",
      "10-20 20:32:33.800 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_227 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:33.810 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:33.811 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_216_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:33.811 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_227_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:33.812 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 227 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.814 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_220_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.818 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_224_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.821 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.822 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 108 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.822 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 119 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.822 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[199] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.830 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_214_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.832 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_222_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.833 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_228 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.834 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.834 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_228_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[199] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.836 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 121) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.837 172.17.0.2:54321      18300   (TID 121)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 119.0 (TID 121)\n",
      "10-20 20:32:33.843 172.17.0.2:54321      18300   (TID 121)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.848 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_218_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.849 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_212_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.851 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_226_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:33.851 172.17.0.2:54321      18300   (TID 121)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 119.0 (TID 121). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.852 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 121) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.852 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.853 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 119 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:33.853 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.853 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished\n",
      "10-20 20:32:33.853 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 108 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031420 s\n",
      "10-20 20:32:33.854 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(227) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.855 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_227_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:33.856 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_229 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:33.856 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:33.857 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_229_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:33.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 229 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.865 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 109 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 120 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[200] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.869 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_230 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:33.870 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:33.870 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_230_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.871 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.871 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[200] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.872 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.873 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 120.0 (TID 122) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.873 172.17.0.2:54321      18300   (TID 122)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 120.0 (TID 122)\n",
      "10-20 20:32:33.881 172.17.0.2:54321      18300   (TID 122)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.888 172.17.0.2:54321      18300   (TID 122)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 120.0 (TID 122). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.888 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 120.0 (TID 122) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.888 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 120 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:33.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished\n",
      "10-20 20:32:33.891 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 109 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026218 s\n",
      "10-20 20:32:33.891 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(229) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.892 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_229_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.892 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.892 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337276 (rel: 0.000123) 0.0335876\n",
      "10-20 20:32:33.893 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_231 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:33.894 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:33.894 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_231_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.895 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 231 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.903 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 110 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 121 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[201] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_232 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:33.911 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:33.912 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_232_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[201] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.915 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 123) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.915 172.17.0.2:54321      18300   (TID 123)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 121.0 (TID 123)\n",
      "10-20 20:32:33.922 172.17.0.2:54321      18300   (TID 123)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.928 172.17.0.2:54321      18300   (TID 123)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 121.0 (TID 123). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.929 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 123) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.929 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 121 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:32:33.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished\n",
      "10-20 20:32:33.930 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 110 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027131 s\n",
      "10-20 20:32:33.930 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(231) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.931 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_231_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_233 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.932 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:33.932 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_233_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.933 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 233 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.940 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 111 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 122 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[202] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.947 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_234 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.948 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:33.949 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_234_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:33.949 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.950 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[202] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.950 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.951 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 124) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:33.952 172.17.0.2:54321      18300   (TID 124)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 122.0 (TID 124)\n",
      "10-20 20:32:33.958 172.17.0.2:54321      18300   (TID 124)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:33.963 172.17.0.2:54321      18300   (TID 124)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 122.0 (TID 124). 3456 bytes result sent to driver\n",
      "10-20 20:32:33.964 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 124) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:33.964 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:33.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 122 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:33.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:33.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished\n",
      "10-20 20:32:33.966 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 111 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025880 s\n",
      "10-20 20:32:33.967 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(233) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:33.967 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_233_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.969 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:33.969 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337233 (rel: 0.000125) 0.0354449\n",
      "10-20 20:32:33.971 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_235 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:33.972 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:33.972 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_235_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:33.977 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 235 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:33.990 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:33.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 112 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:33.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 123 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:33.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:33.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:33.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[203] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:33.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_236 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:33.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:33.996 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_236_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:33.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:33.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[203] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:33.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:33.998 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 125) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.000 172.17.0.2:54321      18300   (TID 125)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 123.0 (TID 125)\n",
      "10-20 20:32:34.030 172.17.0.2:54321      18300   (TID 125)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.045 172.17.0.2:54321      18300   (TID 125)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 123.0 (TID 125). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.046 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 125) in 48 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.046 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 123 (treeAggregate at RDDLossFunction.scala:61) finished in 0.054 s\n",
      "10-20 20:32:34.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished\n",
      "10-20 20:32:34.047 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 112 finished: treeAggregate at RDDLossFunction.scala:61, took 0.056661 s\n",
      "10-20 20:32:34.047 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(235) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.048 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_235_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.049 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_237 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:34.049 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:34.050 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_237_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.050 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 237 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.059 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 113 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 124 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.061 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[204] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_238 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:34.064 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:34.065 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_238_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.066 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.066 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[204] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.066 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.067 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 124.0 (TID 126) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.069 172.17.0.2:54321      18300   (TID 126)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 124.0 (TID 126)\n",
      "10-20 20:32:34.076 172.17.0.2:54321      18300   (TID 126)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.083 172.17.0.2:54321      18300   (TID 126)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 124.0 (TID 126). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.084 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 124.0 (TID 126) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.084 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.085 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 124 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:34.086 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.086 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 124: Stage finished\n",
      "10-20 20:32:34.087 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 113 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027437 s\n",
      "10-20 20:32:34.087 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(237) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.088 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.088 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337199 (rel: 0.000102) 0.0361903\n",
      "10-20 20:32:34.089 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_239 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:34.089 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_237_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.090 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:34.090 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_239_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.091 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 239 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.099 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.100 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 114 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.100 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 125 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.100 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.100 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.100 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[205] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.110 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_240 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:34.111 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:34.112 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_240_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[205] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.113 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 125.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.114 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 127) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.117 172.17.0.2:54321      18300   (TID 127)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 125.0 (TID 127)\n",
      "10-20 20:32:34.126 172.17.0.2:54321      18300   (TID 127)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.134 172.17.0.2:54321      18300   (TID 127)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 125.0 (TID 127). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.135 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 127) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.136 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 125 (treeAggregate at RDDLossFunction.scala:61) finished in 0.035 s\n",
      "10-20 20:32:34.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished\n",
      "10-20 20:32:34.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 114 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037812 s\n",
      "10-20 20:32:34.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(239) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.138 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_239_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_241 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:34.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:34.140 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_241_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.140 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 241 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.148 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 115 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 126 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.149 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.149 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[206] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.154 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_242 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:34.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:34.165 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_242_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.165 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_240_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.166 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[206] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.167 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.167 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_236_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.168 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 128) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.169 172.17.0.2:54321      18300   (TID 128)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 126.0 (TID 128)\n",
      "10-20 20:32:34.179 172.17.0.2:54321      18300   (TID 128)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.180 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_238_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.183 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_230_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.188 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_234_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.190 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_228_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.192 172.17.0.2:54321      18300   (TID 128)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 126.0 (TID 128). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.192 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_232_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:34.194 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 128) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.194 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 126 (treeAggregate at RDDLossFunction.scala:61) finished in 0.044 s\n",
      "10-20 20:32:34.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished\n",
      "10-20 20:32:34.195 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 115 finished: treeAggregate at RDDLossFunction.scala:61, took 0.047336 s\n",
      "10-20 20:32:34.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(241) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.196 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.196 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_241_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:34.196 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337147 (rel: 0.000155) 0.0369175\n",
      "10-20 20:32:34.198 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_243 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:34.199 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:34.199 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_243_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:34.200 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 243 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.207 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 116 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 127 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[207] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.213 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_244 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:34.215 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:34.215 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_244_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.216 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.216 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[207] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.216 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.218 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 129) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.219 172.17.0.2:54321      18300   (TID 129)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 127.0 (TID 129)\n",
      "10-20 20:32:34.227 172.17.0.2:54321      18300   (TID 129)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.234 172.17.0.2:54321      18300   (TID 129)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 127.0 (TID 129). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.235 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 129) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.235 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.236 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 127 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:34.237 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 116 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.237 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished\n",
      "10-20 20:32:34.237 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 116 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029356 s\n",
      "10-20 20:32:34.238 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(243) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.239 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_243_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.241 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_245 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:34.242 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:34.243 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_245_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.243 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 245 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.254 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 117 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 128 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[208] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.260 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_246 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:34.261 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:34.261 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_246_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.262 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 246 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.263 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[208] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.263 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.264 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 130) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.264 172.17.0.2:54321      18300   (TID 130)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 128.0 (TID 130)\n",
      "10-20 20:32:34.271 172.17.0.2:54321      18300   (TID 130)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.276 172.17.0.2:54321      18300   (TID 130)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 128.0 (TID 130). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.277 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 130) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.277 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 128 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:34.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished\n",
      "10-20 20:32:34.278 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 117 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023940 s\n",
      "10-20 20:32:34.279 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(245) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.280 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_245_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.280 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.280 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337095 (rel: 0.000152) 0.0318164\n",
      "10-20 20:32:34.281 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_247 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:34.282 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:34.282 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_247_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.285 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 247 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.292 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 118 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 129 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[209] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_248 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:34.298 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:34.298 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_248_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[209] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.301 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 129.0 (TID 131) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.301 172.17.0.2:54321      18300   (TID 131)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 129.0 (TID 131)\n",
      "10-20 20:32:34.308 172.17.0.2:54321      18300   (TID 131)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.314 172.17.0.2:54321      18300   (TID 131)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 129.0 (TID 131). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.315 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 129.0 (TID 131) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.315 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 129 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:34.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished\n",
      "10-20 20:32:34.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 118 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023941 s\n",
      "10-20 20:32:34.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(247) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.317 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_249 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:34.317 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:34.317 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_249_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 249 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.322 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_247_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.326 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 119 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 130 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.326 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[210] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_250 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:34.344 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:34.346 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_250_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[210] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.351 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 132) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.353 172.17.0.2:54321      18300   (TID 132)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 130.0 (TID 132)\n",
      "10-20 20:32:34.362 172.17.0.2:54321      18300   (TID 132)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.368 172.17.0.2:54321      18300   (TID 132)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 130.0 (TID 132). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.369 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 132) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.369 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.370 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 130 (treeAggregate at RDDLossFunction.scala:61) finished in 0.042 s\n",
      "10-20 20:32:34.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished\n",
      "10-20 20:32:34.371 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 119 finished: treeAggregate at RDDLossFunction.scala:61, took 0.045187 s\n",
      "10-20 20:32:34.372 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(249) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.372 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.373 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337080 (rel: 4.55e-05) 0.0445873\n",
      "10-20 20:32:34.374 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_249_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.374 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_251 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:34.375 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:34.375 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_251_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.376 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 251 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.384 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 120 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 131 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.390 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[211] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.419 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_252 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:34.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:34.420 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_252_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.421 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.421 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[211] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.421 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.422 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 131.0 (TID 133) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.422 172.17.0.2:54321      18300   (TID 133)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 131.0 (TID 133)\n",
      "10-20 20:32:34.428 172.17.0.2:54321      18300   (TID 133)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.434 172.17.0.2:54321      18300   (TID 133)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 131.0 (TID 133). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.435 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 131.0 (TID 133) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.435 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 131 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:34.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished\n",
      "10-20 20:32:34.436 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 120 finished: treeAggregate at RDDLossFunction.scala:61, took 0.051965 s\n",
      "10-20 20:32:34.437 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(251) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.438 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_251_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.438 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_253 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:34.439 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:34.439 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_253_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.439 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 253 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.447 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 121 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 132 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.448 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[212] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.452 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_254 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:34.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:34.454 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_254_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.455 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[212] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.455 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.456 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 132.0 (TID 134) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.456 172.17.0.2:54321      18300   (TID 134)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 132.0 (TID 134)\n",
      "10-20 20:32:34.464 172.17.0.2:54321      18300   (TID 134)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.469 172.17.0.2:54321      18300   (TID 134)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 132.0 (TID 134). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.470 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 132.0 (TID 134) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.471 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.471 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 132 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:34.471 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 132: Stage finished\n",
      "10-20 20:32:34.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 121 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024963 s\n",
      "10-20 20:32:34.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(253) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.473 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.473 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337033 (rel: 0.000138) 0.0158355\n",
      "10-20 20:32:34.473 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_253_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.474 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_255 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:34.475 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:34.475 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_255_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.476 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 255 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.483 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 122 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 133 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[213] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_256 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:34.489 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:34.490 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_256_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.490 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[213] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.492 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 133.0 (TID 135) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.493 172.17.0.2:54321      18300   (TID 135)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 133.0 (TID 135)\n",
      "10-20 20:32:34.501 172.17.0.2:54321      18300   (TID 135)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.507 172.17.0.2:54321      18300   (TID 135)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 133.0 (TID 135). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.508 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 133.0 (TID 135) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.508 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 133 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:34.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished\n",
      "10-20 20:32:34.519 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 122 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035329 s\n",
      "10-20 20:32:34.519 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(255) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.521 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_257 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:34.521 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_255_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.522 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:34.522 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_257_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.522 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 257 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.530 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 123 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 134 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.531 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.531 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[214] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_258 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:34.537 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:34.537 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_258_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[214] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.540 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 134.0 (TID 136) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.541 172.17.0.2:54321      18300   (TID 136)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 134.0 (TID 136)\n",
      "10-20 20:32:34.554 172.17.0.2:54321      18300   (TID 136)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.561 172.17.0.2:54321      18300   (TID 136)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 134.0 (TID 136). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.561 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 134.0 (TID 136) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.561 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 134 (treeAggregate at RDDLossFunction.scala:61) finished in 0.030 s\n",
      "10-20 20:32:34.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 134: Stage finished\n",
      "10-20 20:32:34.562 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 123 finished: treeAggregate at RDDLossFunction.scala:61, took 0.032473 s\n",
      "10-20 20:32:34.563 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(257) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.563 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_257_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.564 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.564 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337023 (rel: 3.19e-05) 0.0160597\n",
      "10-20 20:32:34.565 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_259 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:34.582 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:34.582 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_259_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.583 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 259 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.590 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_258_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.592 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_244_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.596 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_256_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.599 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_246_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.600 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_248_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.601 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.602 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_242_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 124 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 135 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[215] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_260 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:34.609 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_252_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.610 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:34.611 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_260_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.611 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_254_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.612 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.613 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_250_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:34.614 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[215] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.614 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.615 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 135.0 (TID 137) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.615 172.17.0.2:54321      18300   (TID 137)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 135.0 (TID 137)\n",
      "10-20 20:32:34.623 172.17.0.2:54321      18300   (TID 137)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.629 172.17.0.2:54321      18300   (TID 137)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 135.0 (TID 137). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.630 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 135.0 (TID 137) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.630 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 135 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:34.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished\n",
      "10-20 20:32:34.632 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 124 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030202 s\n",
      "10-20 20:32:34.632 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(259) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.634 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_259_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:34.635 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_261 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:34.636 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:34.636 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_261_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:34.637 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 261 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.646 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 125 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 136 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.647 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[216] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_262 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:34.652 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:34.652 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_262_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.652 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.653 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[216] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.653 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.654 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 138) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.658 172.17.0.2:54321      18300   (TID 138)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 136.0 (TID 138)\n",
      "10-20 20:32:34.666 172.17.0.2:54321      18300   (TID 138)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.672 172.17.0.2:54321      18300   (TID 138)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 136.0 (TID 138). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.673 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 138) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.673 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 136 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:34.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished\n",
      "10-20 20:32:34.674 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 125 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028519 s\n",
      "10-20 20:32:34.675 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(261) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.676 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.676 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.337002 (rel: 5.99e-05) 0.0140146\n",
      "10-20 20:32:34.676 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_261_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.678 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_263 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:34.679 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:34.679 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_263_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.680 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 263 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.687 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.688 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 126 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.688 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 137 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.688 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[217] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.696 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_264 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:34.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:34.698 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_264_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[217] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.700 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 139) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.701 172.17.0.2:54321      18300   (TID 139)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 137.0 (TID 139)\n",
      "10-20 20:32:34.710 172.17.0.2:54321      18300   (TID 139)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.716 172.17.0.2:54321      18300   (TID 139)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 137.0 (TID 139). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.717 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 139) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.718 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.718 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 137 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:34.718 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.718 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished\n",
      "10-20 20:32:34.719 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 126 finished: treeAggregate at RDDLossFunction.scala:61, took 0.032059 s\n",
      "10-20 20:32:34.720 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(263) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.721 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_263_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.721 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_265 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:34.723 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:34.723 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_265_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.724 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 265 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.732 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 127 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 138 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[218] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.739 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_266 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:34.740 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:34.741 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_266_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:34.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[218] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.744 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 138.0 (TID 140) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.745 172.17.0.2:54321      18300   (TID 140)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 138.0 (TID 140)\n",
      "10-20 20:32:34.753 172.17.0.2:54321      18300   (TID 140)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.760 172.17.0.2:54321      18300   (TID 140)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 138.0 (TID 140). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.760 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 138.0 (TID 140) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.761 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 138 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:34.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished\n",
      "10-20 20:32:34.762 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 127 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029627 s\n",
      "10-20 20:32:34.763 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(265) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.763 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.763 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_265_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.763 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336987 (rel: 4.59e-05) 0.0358023\n",
      "10-20 20:32:34.764 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_267 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:34.765 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:34.765 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_267_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:34.766 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 267 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.775 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.775 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 128 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.775 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 139 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.775 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.776 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.776 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[219] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.780 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_268 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:34.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:34.781 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_268_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[219] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.782 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.782 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 141) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.783 172.17.0.2:54321      18300   (TID 141)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 139.0 (TID 141)\n",
      "10-20 20:32:34.796 172.17.0.2:54321      18300   (TID 141)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.833 172.17.0.2:54321      18300   (TID 141)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 139.0 (TID 141). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.834 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 141) in 52 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.834 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 139 (treeAggregate at RDDLossFunction.scala:61) finished in 0.058 s\n",
      "10-20 20:32:34.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished\n",
      "10-20 20:32:34.835 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 128 finished: treeAggregate at RDDLossFunction.scala:61, took 0.060508 s\n",
      "10-20 20:32:34.836 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(267) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.838 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_267_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.838 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_269 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:34.840 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:34.840 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_269_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.841 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 269 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.849 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 129 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 140 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.851 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.851 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[220] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_270 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:34.856 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:34.856 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_270_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:34.857 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[220] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.860 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 142) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.860 172.17.0.2:54321      18300   (TID 142)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 140.0 (TID 142)\n",
      "10-20 20:32:34.868 172.17.0.2:54321      18300   (TID 142)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.875 172.17.0.2:54321      18300   (TID 142)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 140.0 (TID 142). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.876 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 142) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.876 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.877 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 140 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:34.877 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 129 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.877 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 140: Stage finished\n",
      "10-20 20:32:34.878 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 129 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029207 s\n",
      "10-20 20:32:34.883 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(269) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.883 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.884 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_269_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.884 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336966 (rel: 6.31e-05) 0.0400447\n",
      "10-20 20:32:34.885 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_271 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:34.886 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:34.886 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_271_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:34.886 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 271 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.896 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 130 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 141 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[221] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.901 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_272 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:34.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:34.903 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_272_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 272 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[221] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.904 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 141.0 (TID 143) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.905 172.17.0.2:54321      18300   (TID 143)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 141.0 (TID 143)\n",
      "10-20 20:32:34.915 172.17.0.2:54321      18300   (TID 143)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.922 172.17.0.2:54321      18300   (TID 143)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 141.0 (TID 143). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.923 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 141.0 (TID 143) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.923 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.924 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 141 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:32:34.924 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.924 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished\n",
      "10-20 20:32:34.924 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 130 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027750 s\n",
      "10-20 20:32:34.925 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(271) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.928 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_273 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:34.930 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_271_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.930 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:34.931 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_273_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 273 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.941 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 131 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 142 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[222] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.945 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_274 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:34.947 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:34.948 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_274_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:34.948 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 274 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:34.948 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[222] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:34.948 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:34.949 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 142.0 (TID 144) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:34.950 172.17.0.2:54321      18300   (TID 144)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 142.0 (TID 144)\n",
      "10-20 20:32:34.959 172.17.0.2:54321      18300   (TID 144)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:34.965 172.17.0.2:54321      18300   (TID 144)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 142.0 (TID 144). 3456 bytes result sent to driver\n",
      "10-20 20:32:34.966 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 142.0 (TID 144) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:34.967 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:34.967 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 142 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:32:34.968 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:34.968 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 142: Stage finished\n",
      "10-20 20:32:34.968 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 131 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027062 s\n",
      "10-20 20:32:34.968 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(273) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:34.969 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:34.969 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336928 (rel: 0.000111) 0.0326502\n",
      "10-20 20:32:34.970 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_273_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.972 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_275 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:34.973 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:34.974 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_275_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:34.975 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 275 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:34.983 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:34.983 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 132 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:34.983 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 143 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:34.983 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:34.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:34.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[223] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:34.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_276 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:35.008 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:35.008 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_276_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.008 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_274_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.008 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 276 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.009 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[223] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.009 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 143.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.010 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 143.0 (TID 145) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.010 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_262_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.012 172.17.0.2:54321      18300   (TID 145)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 143.0 (TID 145)\n",
      "10-20 20:32:35.014 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_268_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.016 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_270_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.017 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_264_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.018 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_272_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.023 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_260_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.025 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_266_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:35.026 172.17.0.2:54321      18300   (TID 145)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.032 172.17.0.2:54321      18300   (TID 145)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 143.0 (TID 145). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.033 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 143.0 (TID 145) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.033 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.033 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 143 (treeAggregate at RDDLossFunction.scala:61) finished in 0.048 s\n",
      "10-20 20:32:35.033 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.033 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 143: Stage finished\n",
      "10-20 20:32:35.033 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 132 finished: treeAggregate at RDDLossFunction.scala:61, took 0.050538 s\n",
      "10-20 20:32:35.034 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(275) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.035 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_275_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:35.035 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_277 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:35.037 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:35.037 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_277_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:35.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 277 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.048 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 133 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 144 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[224] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.054 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_278 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:35.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:35.055 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_278_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.056 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.057 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[224] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.057 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.058 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 144.0 (TID 146) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.061 172.17.0.2:54321      18300   (TID 146)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 144.0 (TID 146)\n",
      "10-20 20:32:35.075 172.17.0.2:54321      18300   (TID 146)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.082 172.17.0.2:54321      18300   (TID 146)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 144.0 (TID 146). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.083 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 144.0 (TID 146) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.084 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 144 (treeAggregate at RDDLossFunction.scala:61) finished in 0.035 s\n",
      "10-20 20:32:35.085 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.085 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 144: Stage finished\n",
      "10-20 20:32:35.086 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 133 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037850 s\n",
      "10-20 20:32:35.086 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(277) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.087 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.088 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_277_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.088 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336903 (rel: 7.35e-05) 0.0252517\n",
      "10-20 20:32:35.090 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_279 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:35.091 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:35.092 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_279_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.093 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 279 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.102 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 134 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 145 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[225] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.109 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_280 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.110 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.111 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_280_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.111 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 280 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[225] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.113 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 145.0 (TID 147) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.114 172.17.0.2:54321      18300   (TID 147)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 145.0 (TID 147)\n",
      "10-20 20:32:35.122 172.17.0.2:54321      18300   (TID 147)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.129 172.17.0.2:54321      18300   (TID 147)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 145.0 (TID 147). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.130 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 145.0 (TID 147) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.130 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 145 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:35.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished\n",
      "10-20 20:32:35.132 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 134 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030163 s\n",
      "10-20 20:32:35.133 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(279) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.134 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_279_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.135 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_281 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:35.136 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:35.137 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_281_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.138 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 281 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.145 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.146 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 135 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 146 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[226] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.152 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_282 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:35.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:35.154 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_282_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 282 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[226] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 146.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.157 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 148) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.157 172.17.0.2:54321      18300   (TID 148)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 146.0 (TID 148)\n",
      "10-20 20:32:35.165 172.17.0.2:54321      18300   (TID 148)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.172 172.17.0.2:54321      18300   (TID 148)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 146.0 (TID 148). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.173 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 148) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.173 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.173 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 146 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:35.174 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.174 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished\n",
      "10-20 20:32:35.174 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 135 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028119 s\n",
      "10-20 20:32:35.175 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(281) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.175 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_281_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.176 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.177 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336893 (rel: 3.06e-05) 0.0314604\n",
      "10-20 20:32:35.179 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_283 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:35.180 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:35.180 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_283_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.181 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 283 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 136 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 147 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.191 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[227] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_284 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:35.196 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:35.197 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_284_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.197 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.197 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[227] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.197 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.198 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 147.0 (TID 149) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.199 172.17.0.2:54321      18300   (TID 149)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 147.0 (TID 149)\n",
      "10-20 20:32:35.209 172.17.0.2:54321      18300   (TID 149)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.218 172.17.0.2:54321      18300   (TID 149)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 147.0 (TID 149). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.220 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 147.0 (TID 149) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.220 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 147 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:35.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished\n",
      "10-20 20:32:35.222 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 136 finished: treeAggregate at RDDLossFunction.scala:61, took 0.032829 s\n",
      "10-20 20:32:35.223 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(283) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.224 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_283_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.226 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_285 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:35.228 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_285_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:35.228 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_285_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.229 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 285 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.266 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.267 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 137 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.267 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 148 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.267 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[228] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_286 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:35.277 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_286_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:35.277 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_286_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.277 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 286 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[228] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.279 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 148.0 (TID 150) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.279 172.17.0.2:54321      18300   (TID 150)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 148.0 (TID 150)\n",
      "10-20 20:32:35.285 172.17.0.2:54321      18300   (TID 150)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.291 172.17.0.2:54321      18300   (TID 150)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 148.0 (TID 150). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.292 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 148.0 (TID 150) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.292 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 148 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:35.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 148: Stage finished\n",
      "10-20 20:32:35.293 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 137 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027296 s\n",
      "10-20 20:32:35.294 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(285) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.294 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.294 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336862 (rel: 9.35e-05) 0.0171902\n",
      "10-20 20:32:35.295 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_287 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:35.295 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_287_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:35.295 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_285_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.296 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_287_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.296 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 287 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.304 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.305 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 138 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.305 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 149 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.305 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.305 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.307 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[229] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.311 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_288 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:35.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_288_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:35.314 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_288_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.314 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 288 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[229] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 149.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.316 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 149.0 (TID 151) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.316 172.17.0.2:54321      18300   (TID 151)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 149.0 (TID 151)\n",
      "10-20 20:32:35.323 172.17.0.2:54321      18300   (TID 151)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.329 172.17.0.2:54321      18300   (TID 151)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 149.0 (TID 151). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.330 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 149.0 (TID 151) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.330 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 149 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:35.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 138 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished\n",
      "10-20 20:32:35.330 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 138 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026191 s\n",
      "10-20 20:32:35.331 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(287) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.332 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_289 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:35.332 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_287_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.333 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_289_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:35.333 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_289_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.334 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 289 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.341 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 139 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 150 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[230] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_290 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:35.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_290_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:35.347 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_290_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 290 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[230] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.348 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.349 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 150.0 (TID 152) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.349 172.17.0.2:54321      18300   (TID 152)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 150.0 (TID 152)\n",
      "10-20 20:32:35.356 172.17.0.2:54321      18300   (TID 152)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.362 172.17.0.2:54321      18300   (TID 152)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 150.0 (TID 152). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.363 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 150.0 (TID 152) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.363 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.363 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 150 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:35.364 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.364 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished\n",
      "10-20 20:32:35.364 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 139 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022336 s\n",
      "10-20 20:32:35.364 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(289) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.365 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.365 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_289_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.365 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336855 (rel: 1.93e-05) 0.0277263\n",
      "10-20 20:32:35.366 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_291 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:35.367 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_291_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:35.367 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_291_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.368 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 291 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.377 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 140 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 151 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.379 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[231] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.381 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_292 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:35.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_292_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:35.382 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_292_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 292 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[231] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 151.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.384 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 151.0 (TID 153) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.384 172.17.0.2:54321      18300   (TID 153)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 151.0 (TID 153)\n",
      "10-20 20:32:35.394 172.17.0.2:54321      18300   (TID 153)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.399 172.17.0.2:54321      18300   (TID 153)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 151.0 (TID 153). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.400 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 151.0 (TID 153) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.400 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 151 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:35.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 140 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished\n",
      "10-20 20:32:35.400 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 140 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023282 s\n",
      "10-20 20:32:35.401 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(291) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.401 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_291_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.402 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_293 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:35.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_293_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:35.412 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_293_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 293 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.413 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_284_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.418 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_288_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_286_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 141 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 152 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[232] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.421 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_290_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.423 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_280_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_294 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:35.424 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_276_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.425 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_294_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.426 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_292_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.427 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_294_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.427 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 294 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.428 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[232] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.428 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 152.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.428 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 152.0 (TID 154) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.429 172.17.0.2:54321      18300   (TID 154)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 152.0 (TID 154)\n",
      "10-20 20:32:35.431 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_278_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.432 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_282_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:35.439 172.17.0.2:54321      18300   (TID 154)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.445 172.17.0.2:54321      18300   (TID 154)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 152.0 (TID 154). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.447 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 152.0 (TID 154) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.447 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 152 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:35.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 152: Stage finished\n",
      "10-20 20:32:35.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 141 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027789 s\n",
      "10-20 20:32:35.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(293) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.449 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.449 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336842 (rel: 3.79e-05) 0.0275646\n",
      "10-20 20:32:35.451 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_295 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:35.451 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_295_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:35.452 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_293_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:35.452 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_295_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:35.453 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 295 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.461 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 142 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 153 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[233] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.465 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_296 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:35.466 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_296_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:35.466 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_296_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.466 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 296 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.467 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[233] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.467 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 153.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.468 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 153.0 (TID 155) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.469 172.17.0.2:54321      18300   (TID 155)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 153.0 (TID 155)\n",
      "10-20 20:32:35.477 172.17.0.2:54321      18300   (TID 155)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.483 172.17.0.2:54321      18300   (TID 155)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 153.0 (TID 155). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.484 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 153.0 (TID 155) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.484 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 153 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:35.484 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 142 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 153: Stage finished\n",
      "10-20 20:32:35.485 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 142 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023579 s\n",
      "10-20 20:32:35.485 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(295) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.487 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_297 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:35.488 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_297_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:35.488 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_295_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.488 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_297_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.488 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 297 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.495 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.496 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 143 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.496 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 154 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.496 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.496 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[234] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.499 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_298 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.500 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_298_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.500 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_298_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 298 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[234] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.502 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 154.0 (TID 156) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.503 172.17.0.2:54321      18300   (TID 156)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 154.0 (TID 156)\n",
      "10-20 20:32:35.510 172.17.0.2:54321      18300   (TID 156)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.515 172.17.0.2:54321      18300   (TID 156)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 154.0 (TID 156). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.516 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 154.0 (TID 156) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.516 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 154 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:35.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 143 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 154: Stage finished\n",
      "10-20 20:32:35.517 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 143 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021554 s\n",
      "10-20 20:32:35.517 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(297) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.518 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_297_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.518 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.519 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336826 (rel: 4.83e-05) 0.0262193\n",
      "10-20 20:32:35.519 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_299 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:35.520 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_299_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:35.520 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_299_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.521 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 299 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.529 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.529 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 144 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 155 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.530 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[235] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.533 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_300 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:35.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_300_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:35.535 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_300_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.535 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 300 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[235] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 155.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.537 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 155.0 (TID 157) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.537 172.17.0.2:54321      18300   (TID 157)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 155.0 (TID 157)\n",
      "10-20 20:32:35.543 172.17.0.2:54321      18300   (TID 157)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.548 172.17.0.2:54321      18300   (TID 157)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 155.0 (TID 157). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.548 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 155.0 (TID 157) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.548 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 155 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:35.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 144 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 155: Stage finished\n",
      "10-20 20:32:35.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 144 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020350 s\n",
      "10-20 20:32:35.550 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(299) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.551 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_299_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.551 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_301 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:35.552 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_301_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:35.552 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_301_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.553 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 301 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.558 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 145 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 156 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[236] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_302 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:35.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_302_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:35.564 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_302_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 302 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[236] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.565 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 156.0 (TID 158) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.566 172.17.0.2:54321      18300   (TID 158)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 156.0 (TID 158)\n",
      "10-20 20:32:35.571 172.17.0.2:54321      18300   (TID 158)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.576 172.17.0.2:54321      18300   (TID 158)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 156.0 (TID 158). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.577 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 156.0 (TID 158) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.578 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.578 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 156 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:35.578 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.578 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished\n",
      "10-20 20:32:35.579 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 145 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020072 s\n",
      "10-20 20:32:35.579 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(301) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.579 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.580 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_301_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.580 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336814 (rel: 3.48e-05) 0.0261850\n",
      "10-20 20:32:35.581 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_303 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:35.582 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_303_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:35.582 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_303_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.583 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 303 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.589 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.589 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 146 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.589 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 157 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.589 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.590 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.590 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[237] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_304 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:35.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_304_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:35.594 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_304_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 304 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[237] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.594 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 157.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.595 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 157.0 (TID 159) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.595 172.17.0.2:54321      18300   (TID 159)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 157.0 (TID 159)\n",
      "10-20 20:32:35.601 172.17.0.2:54321      18300   (TID 159)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.625 172.17.0.2:54321      18300   (TID 159)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 157.0 (TID 159). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.626 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 157.0 (TID 159) in 31 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.626 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 157 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:32:35.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished\n",
      "10-20 20:32:35.628 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 146 finished: treeAggregate at RDDLossFunction.scala:61, took 0.038510 s\n",
      "10-20 20:32:35.628 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(303) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.629 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_305 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:35.631 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_305_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:35.631 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_305_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.631 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 305 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.633 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_303_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:35.640 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 147 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 158 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[238] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.645 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_306 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:35.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_306_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:35.648 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_306_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 306 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[238] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 158.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.652 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 158.0 (TID 160) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.653 172.17.0.2:54321      18300   (TID 160)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 158.0 (TID 160)\n",
      "10-20 20:32:35.661 172.17.0.2:54321      18300   (TID 160)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.668 172.17.0.2:54321      18300   (TID 160)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 158.0 (TID 160). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.669 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 158.0 (TID 160) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.669 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.673 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 158 (treeAggregate at RDDLossFunction.scala:61) finished in 0.031 s\n",
      "10-20 20:32:35.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 147 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 158: Stage finished\n",
      "10-20 20:32:35.674 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 147 finished: treeAggregate at RDDLossFunction.scala:61, took 0.033230 s\n",
      "10-20 20:32:35.674 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(305) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.675 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.675 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_305_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.678 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336796 (rel: 5.31e-05) 0.0216899\n",
      "10-20 20:32:35.680 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_307 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:35.687 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_307_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:35.687 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_307_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.687 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 307 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.695 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 148 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 159 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[239] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_308 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:35.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_308_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:35.700 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_308_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.700 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 308 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.700 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[239] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.700 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 159.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.704 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 159.0 (TID 161) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.705 172.17.0.2:54321      18300   (TID 161)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 159.0 (TID 161)\n",
      "10-20 20:32:35.711 172.17.0.2:54321      18300   (TID 161)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.717 172.17.0.2:54321      18300   (TID 161)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 159.0 (TID 161). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.718 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 159.0 (TID 161) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.718 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.718 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 159 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:35.718 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 148 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.718 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished\n",
      "10-20 20:32:35.719 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 148 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024016 s\n",
      "10-20 20:32:35.719 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(307) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.720 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_307_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.721 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_309 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:35.721 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_309_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:35.722 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_309_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.722 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 309 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.730 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.730 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 149 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.730 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 160 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.730 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.731 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.731 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[240] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_310 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:35.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_310_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:35.735 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_310_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 310 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[240] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 160.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.738 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 160.0 (TID 162) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.739 172.17.0.2:54321      18300   (TID 162)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 160.0 (TID 162)\n",
      "10-20 20:32:35.744 172.17.0.2:54321      18300   (TID 162)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.751 172.17.0.2:54321      18300   (TID 162)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 160.0 (TID 162). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.751 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 160.0 (TID 162) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.752 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 160 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:35.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 149 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 160: Stage finished\n",
      "10-20 20:32:35.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 149 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024209 s\n",
      "10-20 20:32:35.755 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(309) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.756 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.756 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_309_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.756 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336787 (rel: 2.69e-05) 0.0233726\n",
      "10-20 20:32:35.757 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_311 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:35.766 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_311_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:35.766 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_311_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:35.767 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_296_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.767 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 311 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.768 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_302_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:35.769 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_308_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.770 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_310_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.771 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_298_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.772 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_294_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.773 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_300_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.774 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_306_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:35.776 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_304_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:35.777 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.777 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 150 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.777 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 161 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.777 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.778 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.778 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[241] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.780 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_312 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:35.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_312_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:35.782 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_312_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:35.782 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 312 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.782 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[241] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.782 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 161.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.783 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 161.0 (TID 163) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.784 172.17.0.2:54321      18300   (TID 163)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 161.0 (TID 163)\n",
      "10-20 20:32:35.790 172.17.0.2:54321      18300   (TID 163)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.796 172.17.0.2:54321      18300   (TID 163)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 161.0 (TID 163). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.797 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 161.0 (TID 163) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.797 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 161 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:35.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 150 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished\n",
      "10-20 20:32:35.798 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 150 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020766 s\n",
      "10-20 20:32:35.798 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(311) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.799 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_311_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:35.799 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_313 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:35.808 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_313_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:35.808 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_313_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:35.809 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 313 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.815 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 151 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 162 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 162 (MapPartitionsRDD[242] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.819 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_314 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:35.820 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_314_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:35.820 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_314_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 314 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[242] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.822 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 162.0 (TID 164) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.832 172.17.0.2:54321      18300   (TID 164)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 162.0 (TID 164)\n",
      "10-20 20:32:35.842 172.17.0.2:54321      18300   (TID 164)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.848 172.17.0.2:54321      18300   (TID 164)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 162.0 (TID 164). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.849 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 162.0 (TID 164) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.849 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 162 (treeAggregate at RDDLossFunction.scala:61) finished in 0.033 s\n",
      "10-20 20:32:35.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 162: Stage finished\n",
      "10-20 20:32:35.850 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 151 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035020 s\n",
      "10-20 20:32:35.852 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(313) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.852 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_313_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.854 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.854 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336777 (rel: 3.22e-05) 0.0244065\n",
      "10-20 20:32:35.855 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_315 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:35.856 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_315_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:35.856 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_315_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 315 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.865 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 152 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 163 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[243] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.870 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_316 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.871 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_316_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:35.871 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_316_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.872 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 316 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.872 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (MapPartitionsRDD[243] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.872 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 163.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.873 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 163.0 (TID 165) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.880 172.17.0.2:54321      18300   (TID 165)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 163.0 (TID 165)\n",
      "10-20 20:32:35.887 172.17.0.2:54321      18300   (TID 165)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.894 172.17.0.2:54321      18300   (TID 165)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 163.0 (TID 165). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.895 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 163.0 (TID 165) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.895 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 163 (treeAggregate at RDDLossFunction.scala:61) finished in 0.029 s\n",
      "10-20 20:32:35.896 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.896 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 163: Stage finished\n",
      "10-20 20:32:35.896 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 152 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030749 s\n",
      "10-20 20:32:35.896 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(315) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.897 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_315_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.897 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_317 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:35.898 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_317_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:35.898 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_317_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.898 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 317 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.907 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.908 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 153 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.908 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 164 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.908 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[244] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_318 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:35.914 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_318_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:35.914 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_318_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:35.915 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 318 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.915 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[244] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.915 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 164.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.917 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 164.0 (TID 166) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.917 172.17.0.2:54321      18300   (TID 166)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 164.0 (TID 166)\n",
      "10-20 20:32:35.926 172.17.0.2:54321      18300   (TID 166)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:35.934 172.17.0.2:54321      18300   (TID 166)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 164.0 (TID 166). 3456 bytes result sent to driver\n",
      "10-20 20:32:35.935 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 164.0 (TID 166) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:35.935 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:35.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 164 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:35.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 153 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:35.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 164: Stage finished\n",
      "10-20 20:32:35.936 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 153 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028424 s\n",
      "10-20 20:32:35.937 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(317) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:35.938 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_317_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.938 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:35.939 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336764 (rel: 3.62e-05) 0.0197199\n",
      "10-20 20:32:35.939 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_319 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:35.941 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_319_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:35.942 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_319_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:35.942 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 319 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:35.950 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:35.951 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 154 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:35.951 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 165 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:35.951 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:35.951 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:35.952 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[245] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:35.955 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_320 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:35.956 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_320_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:35.957 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_320_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:35.957 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 320 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:35.958 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[245] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:35.958 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 165.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:35.985 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 165.0 (TID 167) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:35.986 172.17.0.2:54321      18300   (TID 167)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 165.0 (TID 167)\n",
      "10-20 20:32:35.995 172.17.0.2:54321      18300   (TID 167)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.010 172.17.0.2:54321      18300   (TID 167)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 165.0 (TID 167). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.011 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 165.0 (TID 167) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.011 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.012 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 165 (treeAggregate at RDDLossFunction.scala:61) finished in 0.060 s\n",
      "10-20 20:32:36.012 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 154 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.012 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 165: Stage finished\n",
      "10-20 20:32:36.012 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 154 finished: treeAggregate at RDDLossFunction.scala:61, took 0.061741 s\n",
      "10-20 20:32:36.013 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(319) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.014 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_321 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:36.014 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_319_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.015 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_321_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:36.015 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_321_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.016 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 321 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.023 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 155 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 166 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[246] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.027 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_322 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:36.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_322_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:36.028 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_322_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 322 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[246] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 166.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.029 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 166.0 (TID 168) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.030 172.17.0.2:54321      18300   (TID 168)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 166.0 (TID 168)\n",
      "10-20 20:32:36.036 172.17.0.2:54321      18300   (TID 168)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.043 172.17.0.2:54321      18300   (TID 168)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 166.0 (TID 168). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.044 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 166.0 (TID 168) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.044 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.045 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 166 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:36.045 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 155 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.045 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 166: Stage finished\n",
      "10-20 20:32:36.046 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 155 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022884 s\n",
      "10-20 20:32:36.047 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(321) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.048 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_321_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.048 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.049 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336757 (rel: 2.19e-05) 0.0254437\n",
      "10-20 20:32:36.049 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_323 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:36.050 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_323_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:36.050 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_323_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 323 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.059 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 156 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 167 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[247] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_324 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:36.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_324_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:36.063 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_324_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.064 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 324 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.064 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[247] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.064 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 167.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.065 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 167.0 (TID 169) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.066 172.17.0.2:54321      18300   (TID 169)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 167.0 (TID 169)\n",
      "10-20 20:32:36.073 172.17.0.2:54321      18300   (TID 169)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.078 172.17.0.2:54321      18300   (TID 169)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 167.0 (TID 169). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.078 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 167.0 (TID 169) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.078 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.079 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 167 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:36.079 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.079 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished\n",
      "10-20 20:32:36.079 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 156 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020254 s\n",
      "10-20 20:32:36.080 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(323) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.081 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_323_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_325 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:36.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_325_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:36.081 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_325_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.082 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 325 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.089 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 157 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 168 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[248] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_326 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:36.094 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_326_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:36.094 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_326_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.095 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 326 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.095 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[248] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.095 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 168.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.097 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 168.0 (TID 170) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.097 172.17.0.2:54321      18300   (TID 170)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 168.0 (TID 170)\n",
      "10-20 20:32:36.102 172.17.0.2:54321      18300   (TID 170)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.109 172.17.0.2:54321      18300   (TID 170)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 168.0 (TID 170). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.110 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 168.0 (TID 170) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.110 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.110 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 168 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:36.110 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 157 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.110 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 168: Stage finished\n",
      "10-20 20:32:36.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 157 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021221 s\n",
      "10-20 20:32:36.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(325) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.111 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.112 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336745 (rel: 3.61e-05) 0.0204807\n",
      "10-20 20:32:36.112 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_325_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.112 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_327 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:36.121 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_327_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:36.121 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_314_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.121 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_327_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.122 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 327 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.124 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_320_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.125 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_322_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.127 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_312_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.128 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_318_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.130 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_324_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.130 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 158 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 169 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.131 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_316_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:36.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[249] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.132 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_326_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:36.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_328 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:36.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_328_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:36.137 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_328_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:36.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 328 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.138 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[249] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.138 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 169.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.140 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 169.0 (TID 171) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.140 172.17.0.2:54321      18300   (TID 171)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 169.0 (TID 171)\n",
      "10-20 20:32:36.146 172.17.0.2:54321      18300   (TID 171)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.152 172.17.0.2:54321      18300   (TID 171)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 169.0 (TID 171). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.153 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 169.0 (TID 171) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.153 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.153 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 169 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:36.154 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 158 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.154 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished\n",
      "10-20 20:32:36.154 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 158 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023732 s\n",
      "10-20 20:32:36.155 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(327) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.155 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_327_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:36.156 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_329 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:36.156 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_329_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:36.157 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_329_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:36.157 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 329 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 159 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 170 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[250] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.169 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_330 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:36.170 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_330_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:36.170 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_330_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.170 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 330 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.170 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[250] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.170 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.171 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 170.0 (TID 172) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.172 172.17.0.2:54321      18300   (TID 172)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 170.0 (TID 172)\n",
      "10-20 20:32:36.178 172.17.0.2:54321      18300   (TID 172)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.183 172.17.0.2:54321      18300   (TID 172)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 170.0 (TID 172). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.183 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 170.0 (TID 172) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.183 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 170 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:36.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 159 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 170: Stage finished\n",
      "10-20 20:32:36.184 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 159 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020640 s\n",
      "10-20 20:32:36.185 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(329) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.186 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.186 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_329_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.186 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336734 (rel: 3.10e-05) 0.0226382\n",
      "10-20 20:32:36.187 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_331 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:36.187 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_331_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:36.188 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_331_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.188 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 331 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.195 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 160 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 171 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.196 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.196 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 171 (MapPartitionsRDD[251] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.199 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_332 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:36.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_332_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:36.201 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_332_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 332 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (MapPartitionsRDD[251] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 171.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.202 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 171.0 (TID 173) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.203 172.17.0.2:54321      18300   (TID 173)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 171.0 (TID 173)\n",
      "10-20 20:32:36.209 172.17.0.2:54321      18300   (TID 173)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.214 172.17.0.2:54321      18300   (TID 173)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 171.0 (TID 173). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.214 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 171.0 (TID 173) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.215 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.215 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 171 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:36.215 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 160 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.215 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 171: Stage finished\n",
      "10-20 20:32:36.216 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 160 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021239 s\n",
      "10-20 20:32:36.216 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(331) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.218 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_331_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.218 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_333 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:36.219 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_333_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:36.219 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_333_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.220 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 333 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.226 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 161 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 172 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 172 (MapPartitionsRDD[252] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.230 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_334 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:36.231 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_334_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:36.231 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_334_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.232 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 334 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.232 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (MapPartitionsRDD[252] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.232 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.232 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 172.0 (TID 174) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.235 172.17.0.2:54321      18300   (TID 174)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 172.0 (TID 174)\n",
      "10-20 20:32:36.241 172.17.0.2:54321      18300   (TID 174)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.249 172.17.0.2:54321      18300   (TID 174)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 172.0 (TID 174). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.250 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 172.0 (TID 174) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.251 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 172 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:32:36.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 161 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 172: Stage finished\n",
      "10-20 20:32:36.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 161 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030727 s\n",
      "10-20 20:32:36.258 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(333) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.258 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.259 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336724 (rel: 3.01e-05) 0.0198355\n",
      "10-20 20:32:36.260 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_335 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:36.260 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_335_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:36.261 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_333_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.261 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_335_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.263 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 335 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.270 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.272 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 162 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.272 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 173 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.272 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.272 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.273 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 173 (MapPartitionsRDD[253] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.277 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_336 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:36.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_336_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:36.278 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_336_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 336 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 173 (MapPartitionsRDD[253] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 173.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.280 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 173.0 (TID 175) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.281 172.17.0.2:54321      18300   (TID 175)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 173.0 (TID 175)\n",
      "10-20 20:32:36.288 172.17.0.2:54321      18300   (TID 175)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.295 172.17.0.2:54321      18300   (TID 175)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 173.0 (TID 175). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.296 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 173.0 (TID 175) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.296 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 173 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:36.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 162 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 173: Stage finished\n",
      "10-20 20:32:36.297 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 162 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026980 s\n",
      "10-20 20:32:36.298 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(335) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.299 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_335_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.299 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_337 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:36.300 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_337_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:36.301 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_337_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.301 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 337 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.327 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 163 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 174 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 174 (MapPartitionsRDD[254] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.333 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_338 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:36.334 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_338_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:36.334 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_338_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.334 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 338 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.334 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[254] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.334 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 174.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.335 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 174.0 (TID 176) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.336 172.17.0.2:54321      18300   (TID 176)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 174.0 (TID 176)\n",
      "10-20 20:32:36.342 172.17.0.2:54321      18300   (TID 176)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.348 172.17.0.2:54321      18300   (TID 176)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 174.0 (TID 176). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.349 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 174.0 (TID 176) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.349 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.350 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 174 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:36.350 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 163 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.350 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 174: Stage finished\n",
      "10-20 20:32:36.350 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 163 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023398 s\n",
      "10-20 20:32:36.351 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(337) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.352 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.352 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_337_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.352 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336714 (rel: 3.16e-05) 0.0212989\n",
      "10-20 20:32:36.353 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_339 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:36.354 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_339_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:36.354 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_339_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.355 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 339 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.362 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 164 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 175 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.363 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[255] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.366 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_340 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:36.367 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_340_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:36.367 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_340_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 340 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[255] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.369 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 175.0 (TID 177) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.369 172.17.0.2:54321      18300   (TID 177)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 175.0 (TID 177)\n",
      "10-20 20:32:36.376 172.17.0.2:54321      18300   (TID 177)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.381 172.17.0.2:54321      18300   (TID 177)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 175.0 (TID 177). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.382 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 175.0 (TID 177) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.382 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 175 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:36.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 164 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished\n",
      "10-20 20:32:36.382 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 164 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020672 s\n",
      "10-20 20:32:36.383 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(339) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.383 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_339_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.383 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_341 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:36.384 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_341_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:36.384 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_341_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.385 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 341 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.391 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 165 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 176 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[256] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_342 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:36.396 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_342_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:36.397 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_342_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.397 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 342 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.397 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[256] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.397 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.398 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 176.0 (TID 178) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.399 172.17.0.2:54321      18300   (TID 178)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 176.0 (TID 178)\n",
      "10-20 20:32:36.404 172.17.0.2:54321      18300   (TID 178)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.409 172.17.0.2:54321      18300   (TID 178)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 176.0 (TID 178). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.410 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 176.0 (TID 178) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.410 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.411 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 176 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:36.411 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 165 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.411 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 176: Stage finished\n",
      "10-20 20:32:36.411 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 165 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019820 s\n",
      "10-20 20:32:36.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(341) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.412 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.413 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336705 (rel: 2.59e-05) 0.0200642\n",
      "10-20 20:32:36.413 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_341_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.414 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_343 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:36.415 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_343_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:36.416 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_343_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.416 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 343 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.423 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.423 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 166 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 177 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[257] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.427 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_344 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:36.428 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_344_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:36.428 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_344_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.428 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 344 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[257] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.429 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 177.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.430 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 177.0 (TID 179) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.430 172.17.0.2:54321      18300   (TID 179)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 177.0 (TID 179)\n",
      "10-20 20:32:36.436 172.17.0.2:54321      18300   (TID 179)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.442 172.17.0.2:54321      18300   (TID 179)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 177.0 (TID 179). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.442 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 177.0 (TID 179) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.443 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.443 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 177 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:36.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 166 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished\n",
      "10-20 20:32:36.444 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 166 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020579 s\n",
      "10-20 20:32:36.444 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(343) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.445 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_345 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:36.445 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_343_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.468 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_345_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:36.468 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_345_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:36.469 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 345 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.473 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_328_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.475 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_334_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.477 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_336_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.479 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_332_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.484 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 167 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 178 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.485 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.486 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_342_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.486 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.486 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[258] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_346 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:36.493 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_346_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:36.493 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_346_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 346 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[258] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.495 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_330_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.496 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 178.0 (TID 180) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.507 172.17.0.2:54321      18300   (TID 180)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 178.0 (TID 180)\n",
      "10-20 20:32:36.519 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_340_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.533 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_338_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.535 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_344_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:36.539 172.17.0.2:54321      18300   (TID 180)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.549 172.17.0.2:54321      18300   (TID 180)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 178.0 (TID 180). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.551 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 178.0 (TID 180) in 56 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.551 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.552 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 178 (treeAggregate at RDDLossFunction.scala:61) finished in 0.065 s\n",
      "10-20 20:32:36.552 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 167 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.552 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 178: Stage finished\n",
      "10-20 20:32:36.553 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 167 finished: treeAggregate at RDDLossFunction.scala:61, took 0.067733 s\n",
      "10-20 20:32:36.554 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(345) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.555 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.556 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336693 (rel: 3.39e-05) 0.0222418\n",
      "10-20 20:32:36.557 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_347 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:36.557 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_347_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:36.557 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_345_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:36.558 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_347_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:36.558 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 347 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.570 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 168 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 179 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.571 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.571 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[259] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_348 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:36.579 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_348_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:36.580 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_348_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.581 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 348 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.582 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[259] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.582 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 179.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.584 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 179.0 (TID 181) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.585 172.17.0.2:54321      18300   (TID 181)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 179.0 (TID 181)\n",
      "10-20 20:32:36.595 172.17.0.2:54321      18300   (TID 181)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.604 172.17.0.2:54321      18300   (TID 181)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 179.0 (TID 181). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.605 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 179.0 (TID 181) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.605 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 179 (treeAggregate at RDDLossFunction.scala:61) finished in 0.035 s\n",
      "10-20 20:32:36.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 168 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 179: Stage finished\n",
      "10-20 20:32:36.607 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 168 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037615 s\n",
      "10-20 20:32:36.608 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(347) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.609 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_347_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.611 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_349 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:36.612 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_349_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:36.612 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_349_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.613 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 349 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.626 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 169 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 180 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 180 (MapPartitionsRDD[260] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_350 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:36.638 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_350_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:36.639 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_350_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 350 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 180 (MapPartitionsRDD[260] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 180.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.641 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 180.0 (TID 182) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.642 172.17.0.2:54321      18300   (TID 182)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 180.0 (TID 182)\n",
      "10-20 20:32:36.653 172.17.0.2:54321      18300   (TID 182)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.700 172.17.0.2:54321      18300   (TID 182)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 180.0 (TID 182). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.706 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 180.0 (TID 182) in 65 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.706 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.707 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 180 (treeAggregate at RDDLossFunction.scala:61) finished in 0.077 s\n",
      "10-20 20:32:36.707 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 169 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.707 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 180: Stage finished\n",
      "10-20 20:32:36.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 169 finished: treeAggregate at RDDLossFunction.scala:61, took 0.081104 s\n",
      "10-20 20:32:36.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(349) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.708 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.708 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336684 (rel: 2.70e-05) 0.0192629\n",
      "10-20 20:32:36.708 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_349_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.709 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_351 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:36.710 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_351_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:36.711 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_351_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.711 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 351 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.722 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 170 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 181 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.724 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[261] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.730 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_352 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:36.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_352_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:36.734 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_352_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:36.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 352 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[261] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 181.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.737 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 181.0 (TID 183) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.738 172.17.0.2:54321      18300   (TID 183)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 181.0 (TID 183)\n",
      "10-20 20:32:36.751 172.17.0.2:54321      18300   (TID 183)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.764 172.17.0.2:54321      18300   (TID 183)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 181.0 (TID 183). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.767 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 181.0 (TID 183) in 30 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.767 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 181 (treeAggregate at RDDLossFunction.scala:61) finished in 0.044 s\n",
      "10-20 20:32:36.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 170 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished\n",
      "10-20 20:32:36.771 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 170 finished: treeAggregate at RDDLossFunction.scala:61, took 0.048445 s\n",
      "10-20 20:32:36.771 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(351) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.773 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_351_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.773 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_353 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:36.776 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_353_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:36.777 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_353_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:36.778 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 353 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 171 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 182 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.793 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 182 (MapPartitionsRDD[262] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.803 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_354 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:36.805 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_354_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:36.805 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_354_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.806 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 354 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.807 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 182 (MapPartitionsRDD[262] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.807 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.808 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 182.0 (TID 184) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.809 172.17.0.2:54321      18300   (TID 184)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 182.0 (TID 184)\n",
      "10-20 20:32:36.821 172.17.0.2:54321      18300   (TID 184)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.830 172.17.0.2:54321      18300   (TID 184)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 182.0 (TID 184). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.831 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 182.0 (TID 184) in 23 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.831 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.832 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 182 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:32:36.832 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 171 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.832 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 182: Stage finished\n",
      "10-20 20:32:36.833 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 171 finished: treeAggregate at RDDLossFunction.scala:61, took 0.042536 s\n",
      "10-20 20:32:36.833 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(353) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.834 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:36.834 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336675 (rel: 2.74e-05) 0.0212747\n",
      "10-20 20:32:36.834 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_353_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.836 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_355 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:36.837 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_355_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:36.837 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_355_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.838 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 355 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.848 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 172 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 183 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.850 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 183 (MapPartitionsRDD[263] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.856 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_356 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:36.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_356_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:36.859 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_356_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:36.859 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 356 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.860 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 183 (MapPartitionsRDD[263] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.860 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 183.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.861 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 183.0 (TID 185) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.862 172.17.0.2:54321      18300   (TID 185)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 183.0 (TID 185)\n",
      "10-20 20:32:36.882 172.17.0.2:54321      18300   (TID 185)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:36.957 172.17.0.2:54321      18300   (TID 185)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 183.0 (TID 185). 3456 bytes result sent to driver\n",
      "10-20 20:32:36.957 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 183.0 (TID 185) in 96 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:36.958 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:36.959 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 183 (treeAggregate at RDDLossFunction.scala:61) finished in 0.109 s\n",
      "10-20 20:32:36.959 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 172 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:36.959 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 183: Stage finished\n",
      "10-20 20:32:36.960 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 172 finished: treeAggregate at RDDLossFunction.scala:61, took 0.111784 s\n",
      "10-20 20:32:36.960 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(355) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:36.961 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_355_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.965 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_357 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:36.969 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_357_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:36.970 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_357_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:36.976 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 357 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:36.983 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:36.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 173 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:36.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 184 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:36.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:36.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:36.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[264] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:36.989 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_358 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:36.990 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_358_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:36.990 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_358_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:36.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 358 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:36.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[264] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:36.991 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 184.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:36.993 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 184.0 (TID 186) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:36.994 172.17.0.2:54321      18300   (TID 186)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 184.0 (TID 186)\n",
      "10-20 20:32:37.001 172.17.0.2:54321      18300   (TID 186)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.007 172.17.0.2:54321      18300   (TID 186)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 184.0 (TID 186). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.008 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 184.0 (TID 186) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.008 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.008 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 184 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:37.008 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 173 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.008 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 184: Stage finished\n",
      "10-20 20:32:37.009 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 173 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024575 s\n",
      "10-20 20:32:37.009 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(357) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.010 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.010 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336665 (rel: 3.04e-05) 0.0153450\n",
      "10-20 20:32:37.010 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_357_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.011 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_359 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:37.011 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_359_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:37.011 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_359_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.012 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 359 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.018 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 174 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 185 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[265] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_360 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:37.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_360_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:37.023 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_360_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 360 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (MapPartitionsRDD[265] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 185.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.024 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 185.0 (TID 187) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.024 172.17.0.2:54321      18300   (TID 187)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 185.0 (TID 187)\n",
      "10-20 20:32:37.031 172.17.0.2:54321      18300   (TID 187)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.037 172.17.0.2:54321      18300   (TID 187)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 185.0 (TID 187). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.038 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 185.0 (TID 187) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.038 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 185 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:37.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 174 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 185: Stage finished\n",
      "10-20 20:32:37.039 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 174 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020925 s\n",
      "10-20 20:32:37.039 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(359) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.040 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_359_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.040 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_361 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:37.041 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_361_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:37.041 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_361_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.041 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 361 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.048 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 175 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 186 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 186 (MapPartitionsRDD[266] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.053 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_362 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:37.054 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_362_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:37.054 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_362_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 362 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[266] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 186.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.056 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 186.0 (TID 188) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.056 172.17.0.2:54321      18300   (TID 188)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 186.0 (TID 188)\n",
      "10-20 20:32:37.062 172.17.0.2:54321      18300   (TID 188)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.067 172.17.0.2:54321      18300   (TID 188)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 186.0 (TID 188). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.068 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 186.0 (TID 188) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.068 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 186 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:37.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 175 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 186: Stage finished\n",
      "10-20 20:32:37.069 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 175 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020746 s\n",
      "10-20 20:32:37.070 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(361) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.071 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_361_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.071 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.071 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336659 (rel: 1.84e-05) 0.0203799\n",
      "10-20 20:32:37.072 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_363 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:37.073 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_363_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:37.073 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_363_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.074 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 363 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 176 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 187 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.083 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 187 (MapPartitionsRDD[267] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.085 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_364 stored as values in memory (estimated size 131.5 KiB, free 428.7 MiB)\n",
      "10-20 20:32:37.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_364_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.7 MiB)\n",
      "10-20 20:32:37.104 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_364_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.3 MiB)\n",
      "10-20 20:32:37.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 364 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.105 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 187 (MapPartitionsRDD[267] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.105 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 187.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.105 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_358_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.106 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 187.0 (TID 189) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.106 172.17.0.2:54321      18300   (TID 189)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 187.0 (TID 189)\n",
      "10-20 20:32:37.108 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_354_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.110 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_360_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.113 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_356_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.116 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_362_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.119 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_352_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.119 172.17.0.2:54321      18300   (TID 189)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.120 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_348_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.123 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_346_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.124 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_350_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.124 172.17.0.2:54321      18300   (TID 189)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 187.0 (TID 189). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.125 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 187.0 (TID 189) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.125 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 187 (treeAggregate at RDDLossFunction.scala:61) finished in 0.042 s\n",
      "10-20 20:32:37.126 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 176 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.126 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 187: Stage finished\n",
      "10-20 20:32:37.126 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 176 finished: treeAggregate at RDDLossFunction.scala:61, took 0.044444 s\n",
      "10-20 20:32:37.126 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(363) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.127 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_363_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.128 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_365 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_365_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.138 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_365_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.138 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 365 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.142 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_364_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.146 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 177 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 188 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[268] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.150 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_366 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:37.151 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_366_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:37.152 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_366_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.152 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 366 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.152 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 188 (MapPartitionsRDD[268] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.152 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.153 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 188.0 (TID 190) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.153 172.17.0.2:54321      18300   (TID 190)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 188.0 (TID 190)\n",
      "10-20 20:32:37.159 172.17.0.2:54321      18300   (TID 190)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.164 172.17.0.2:54321      18300   (TID 190)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 188.0 (TID 190). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.165 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 188.0 (TID 190) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.165 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 188 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:32:37.166 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 177 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.166 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 188: Stage finished\n",
      "10-20 20:32:37.166 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 177 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019814 s\n",
      "10-20 20:32:37.166 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(365) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.166 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.166 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336649 (rel: 2.79e-05) 0.0128161\n",
      "10-20 20:32:37.167 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_367 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.167 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_367_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.168 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_365_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.168 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_367_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.168 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 367 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.174 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.175 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 178 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.175 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 189 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.175 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.175 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.175 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[269] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.178 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_368 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:37.179 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_368_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:37.180 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_368_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.180 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 368 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.180 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[269] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.180 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 189.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.181 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 189.0 (TID 191) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.181 172.17.0.2:54321      18300   (TID 191)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 189.0 (TID 191)\n",
      "10-20 20:32:37.187 172.17.0.2:54321      18300   (TID 191)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.192 172.17.0.2:54321      18300   (TID 191)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 189.0 (TID 191). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.193 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 189.0 (TID 191) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.193 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.193 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 189 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:32:37.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 178 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished\n",
      "10-20 20:32:37.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 178 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021183 s\n",
      "10-20 20:32:37.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(367) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.197 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_367_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.197 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_369 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:37.198 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_369_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:37.198 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_369_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.199 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 369 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.205 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 179 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 190 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.206 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.206 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[270] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_370 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:37.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_370_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:37.210 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_370_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.211 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 370 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.211 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[270] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.211 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 190.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.212 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 190.0 (TID 192) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.213 172.17.0.2:54321      18300   (TID 192)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 190.0 (TID 192)\n",
      "10-20 20:32:37.219 172.17.0.2:54321      18300   (TID 192)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.224 172.17.0.2:54321      18300   (TID 192)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 190.0 (TID 192). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.225 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 190.0 (TID 192) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.225 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 190 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:37.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 179 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 190: Stage finished\n",
      "10-20 20:32:37.227 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 179 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022022 s\n",
      "10-20 20:32:37.227 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(369) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.228 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.228 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_369_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.228 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336645 (rel: 1.24e-05) 0.0206737\n",
      "10-20 20:32:37.229 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_371 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:37.229 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_371_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:37.229 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_371_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.230 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 371 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.237 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.238 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 180 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.238 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 191 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.238 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.238 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.239 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[271] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.242 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_372 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:37.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_372_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:37.243 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_372_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 372 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (MapPartitionsRDD[271] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 191.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.245 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 191.0 (TID 193) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.246 172.17.0.2:54321      18300   (TID 193)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 191.0 (TID 193)\n",
      "10-20 20:32:37.251 172.17.0.2:54321      18300   (TID 193)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.256 172.17.0.2:54321      18300   (TID 193)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 191.0 (TID 193). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.257 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 191.0 (TID 193) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.257 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.258 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 191 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:37.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 180 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 191: Stage finished\n",
      "10-20 20:32:37.259 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 180 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022031 s\n",
      "10-20 20:32:37.260 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(371) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.260 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_371_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.260 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_373 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:37.261 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_373_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:37.262 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_373_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.262 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 373 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.268 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 181 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 192 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.270 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 192 (MapPartitionsRDD[272] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.273 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_374 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:37.274 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_374_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:37.275 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_374_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 374 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[272] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.275 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 192.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.277 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 192.0 (TID 194) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.277 172.17.0.2:54321      18300   (TID 194)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 192.0 (TID 194)\n",
      "10-20 20:32:37.284 172.17.0.2:54321      18300   (TID 194)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.291 172.17.0.2:54321      18300   (TID 194)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 192.0 (TID 194). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.292 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 192.0 (TID 194) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.292 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 192 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:37.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 181 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.293 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 192: Stage finished\n",
      "10-20 20:32:37.294 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 181 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025691 s\n",
      "10-20 20:32:37.294 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(373) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.295 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.295 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_373_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.296 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336635 (rel: 3.12e-05) 0.0147355\n",
      "10-20 20:32:37.296 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_375 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:37.297 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_375_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:37.302 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_375_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.304 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 375 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.312 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 182 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 193 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[273] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.317 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_376 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:37.317 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_376_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:37.318 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_376_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.318 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 376 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.318 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[273] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.318 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 193.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.319 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 193.0 (TID 195) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.319 172.17.0.2:54321      18300   (TID 195)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 193.0 (TID 195)\n",
      "10-20 20:32:37.350 172.17.0.2:54321      18300   (TID 195)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.356 172.17.0.2:54321      18300   (TID 195)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 193.0 (TID 195). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.357 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 193.0 (TID 195) in 38 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.357 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 193 (treeAggregate at RDDLossFunction.scala:61) finished in 0.043 s\n",
      "10-20 20:32:37.358 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 182 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.358 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished\n",
      "10-20 20:32:37.358 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 182 finished: treeAggregate at RDDLossFunction.scala:61, took 0.045574 s\n",
      "10-20 20:32:37.358 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(375) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.359 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_377 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:37.359 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_377_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:37.359 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_375_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.360 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_377_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.360 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 377 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.366 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.366 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 183 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.366 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 194 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.366 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.367 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.367 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 194 (MapPartitionsRDD[274] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.370 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_378 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:37.370 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_378_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:37.371 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_378_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 378 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 194 (MapPartitionsRDD[274] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 194.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.372 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 194.0 (TID 196) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.373 172.17.0.2:54321      18300   (TID 196)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 194.0 (TID 196)\n",
      "10-20 20:32:37.378 172.17.0.2:54321      18300   (TID 196)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.383 172.17.0.2:54321      18300   (TID 196)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 194.0 (TID 196). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.383 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 194.0 (TID 196) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.384 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 194 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:32:37.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 183 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 194: Stage finished\n",
      "10-20 20:32:37.384 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 183 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018467 s\n",
      "10-20 20:32:37.385 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(377) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.386 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.386 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_377_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.386 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336628 (rel: 2.12e-05) 0.0166413\n",
      "10-20 20:32:37.386 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_379 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:37.387 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_379_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:37.387 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_379_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.387 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 379 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.394 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.394 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 184 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.394 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 195 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.394 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[275] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.398 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_380 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:37.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_380_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:37.399 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_380_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 380 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[275] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 195.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.400 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 195.0 (TID 197) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.401 172.17.0.2:54321      18300   (TID 197)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 195.0 (TID 197)\n",
      "10-20 20:32:37.406 172.17.0.2:54321      18300   (TID 197)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.411 172.17.0.2:54321      18300   (TID 197)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 195.0 (TID 197). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.411 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 195.0 (TID 197) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.411 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 195 (treeAggregate at RDDLossFunction.scala:61) finished in 0.016 s\n",
      "10-20 20:32:37.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 184 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished\n",
      "10-20 20:32:37.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 184 finished: treeAggregate at RDDLossFunction.scala:61, took 0.017952 s\n",
      "10-20 20:32:37.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(379) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.412 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_379_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_381 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:37.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_381_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:37.414 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_381_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.414 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 381 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.420 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 185 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 196 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.421 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.421 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[276] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.423 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_382 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:37.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_382_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:37.424 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_382_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 382 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.431 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[276] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.431 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 196.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.432 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 196.0 (TID 198) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.432 172.17.0.2:54321      18300   (TID 198)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 196.0 (TID 198)\n",
      "10-20 20:32:37.437 172.17.0.2:54321      18300   (TID 198)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.442 172.17.0.2:54321      18300   (TID 198)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 196.0 (TID 198). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.443 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 196.0 (TID 198) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.443 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.443 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 196 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:37.443 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 185 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.443 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished\n",
      "10-20 20:32:37.444 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 185 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023757 s\n",
      "10-20 20:32:37.444 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(381) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.444 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.444 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_381_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.445 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336622 (rel: 1.59e-05) 0.0138151\n",
      "10-20 20:32:37.445 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_383 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:37.446 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_383_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:37.446 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_383_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.447 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 383 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.453 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 186 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 197 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[277] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.456 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_384 stored as values in memory (estimated size 131.5 KiB, free 428.7 MiB)\n",
      "10-20 20:32:37.457 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_384_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.7 MiB)\n",
      "10-20 20:32:37.457 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_384_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.3 MiB)\n",
      "10-20 20:32:37.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 384 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[277] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 197.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.459 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 197.0 (TID 199) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.459 172.17.0.2:54321      18300   (TID 199)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 197.0 (TID 199)\n",
      "10-20 20:32:37.465 172.17.0.2:54321      18300   (TID 199)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.474 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_380_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.476 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_372_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.476 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_378_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.478 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_382_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.478 172.17.0.2:54321      18300   (TID 199)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 197.0 (TID 199). 3499 bytes result sent to driver\n",
      "10-20 20:32:37.479 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 197.0 (TID 199) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.479 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.480 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 197 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:37.480 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 186 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.480 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished\n",
      "10-20 20:32:37.480 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 186 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027703 s\n",
      "10-20 20:32:37.480 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_370_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.481 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(383) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.481 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_383_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.482 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_385 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:37.482 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_385_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:37.482 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_385_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.483 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 385 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.484 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_366_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.484 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_368_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.485 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_376_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.487 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_374_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.491 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 187 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 198 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 198 (MapPartitionsRDD[278] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_386 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:37.506 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_384_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.506 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_386_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:37.507 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_386_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 386 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[278] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.508 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 198.0 (TID 200) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.510 172.17.0.2:54321      18300   (TID 200)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 198.0 (TID 200)\n",
      "10-20 20:32:37.516 172.17.0.2:54321      18300   (TID 200)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.522 172.17.0.2:54321      18300   (TID 200)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 198.0 (TID 200). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.523 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 198.0 (TID 200) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.523 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.523 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 198 (treeAggregate at RDDLossFunction.scala:61) finished in 0.031 s\n",
      "10-20 20:32:37.523 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 187 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.523 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 198: Stage finished\n",
      "10-20 20:32:37.523 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 187 finished: treeAggregate at RDDLossFunction.scala:61, took 0.032678 s\n",
      "10-20 20:32:37.524 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(385) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.524 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.524 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336612 (rel: 2.92e-05) 0.0156794\n",
      "10-20 20:32:37.524 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_385_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.525 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_387 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.525 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_387_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.525 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_387_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.526 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 387 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.532 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.533 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 188 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.533 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 199 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.533 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.533 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[279] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.537 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_388 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:37.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_388_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:37.538 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_388_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 388 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 199 (MapPartitionsRDD[279] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 199.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.539 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 199.0 (TID 201) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.540 172.17.0.2:54321      18300   (TID 201)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 199.0 (TID 201)\n",
      "10-20 20:32:37.546 172.17.0.2:54321      18300   (TID 201)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.551 172.17.0.2:54321      18300   (TID 201)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 199.0 (TID 201). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.551 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 199.0 (TID 201) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.551 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.552 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 199 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:37.552 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 188 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.552 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 199: Stage finished\n",
      "10-20 20:32:37.552 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 188 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019763 s\n",
      "10-20 20:32:37.553 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(387) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.554 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_387_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.554 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_389 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:37.555 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_389_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:37.555 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_389_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.556 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 389 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.562 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 189 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 200 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[280] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.567 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_390 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:37.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_390_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:37.568 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_390_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 390 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[280] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 200.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.571 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 200.0 (TID 202) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.572 172.17.0.2:54321      18300   (TID 202)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 200.0 (TID 202)\n",
      "10-20 20:32:37.577 172.17.0.2:54321      18300   (TID 202)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.583 172.17.0.2:54321      18300   (TID 202)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 200.0 (TID 202). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.584 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 200.0 (TID 202) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.584 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 200 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:32:37.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 189 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished\n",
      "10-20 20:32:37.585 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 189 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022280 s\n",
      "10-20 20:32:37.585 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(389) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.586 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.586 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_389_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.587 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336609 (rel: 1.05e-05) 0.0182018\n",
      "10-20 20:32:37.588 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_391 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:37.589 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_391_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:37.589 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_391_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.589 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 391 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.597 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 190 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 201 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.597 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.598 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.598 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 201 (MapPartitionsRDD[281] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_392 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:37.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_392_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:37.603 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_392_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 392 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.604 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 201 (MapPartitionsRDD[281] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.604 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 201.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.605 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 201.0 (TID 203) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.605 172.17.0.2:54321      18300   (TID 203)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 201.0 (TID 203)\n",
      "10-20 20:32:37.612 172.17.0.2:54321      18300   (TID 203)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.618 172.17.0.2:54321      18300   (TID 203)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 201.0 (TID 203). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.619 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 201.0 (TID 203) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.619 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.620 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 201 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:37.620 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 190 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.620 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 201: Stage finished\n",
      "10-20 20:32:37.620 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 190 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023531 s\n",
      "10-20 20:32:37.621 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(391) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.622 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_393 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:37.622 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_391_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.623 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_393_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:37.624 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_393_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.624 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 393 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.634 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 191 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 202 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 202 (MapPartitionsRDD[282] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.638 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_394 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:37.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_394_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:37.639 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_394_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 394 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 202 (MapPartitionsRDD[282] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 202.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.640 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 202.0 (TID 204) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.641 172.17.0.2:54321      18300   (TID 204)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 202.0 (TID 204)\n",
      "10-20 20:32:37.649 172.17.0.2:54321      18300   (TID 204)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.656 172.17.0.2:54321      18300   (TID 204)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 202.0 (TID 204). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.657 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 202.0 (TID 204) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.657 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.658 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 202 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:37.658 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 191 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.658 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 202: Stage finished\n",
      "10-20 20:32:37.658 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 191 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023797 s\n",
      "10-20 20:32:37.658 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(393) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.659 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.659 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336601 (rel: 2.26e-05) 0.0177886\n",
      "10-20 20:32:37.659 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_393_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_395 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:37.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_395_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:37.660 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_395_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 395 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.667 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 192 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 203 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 203 (MapPartitionsRDD[283] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.670 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_396 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:37.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_396_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:37.671 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_396_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 396 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.672 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 203 (MapPartitionsRDD[283] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.672 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 203.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.672 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 203.0 (TID 205) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.673 172.17.0.2:54321      18300   (TID 205)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 203.0 (TID 205)\n",
      "10-20 20:32:37.679 172.17.0.2:54321      18300   (TID 205)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.684 172.17.0.2:54321      18300   (TID 205)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 203.0 (TID 205). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.685 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 203.0 (TID 205) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.685 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.685 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 203 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:32:37.685 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 192 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.685 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 203: Stage finished\n",
      "10-20 20:32:37.685 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 192 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018408 s\n",
      "10-20 20:32:37.686 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(395) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.686 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_395_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.686 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_397 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:37.687 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_397_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:37.687 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_397_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:37.688 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 397 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.694 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 193 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 204 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.695 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 204 (MapPartitionsRDD[284] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_398 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:37.725 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_398_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:37.725 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_398_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.726 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 398 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.726 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[284] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.726 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 204.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.727 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 204.0 (TID 206) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.727 172.17.0.2:54321      18300   (TID 206)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 204.0 (TID 206)\n",
      "10-20 20:32:37.734 172.17.0.2:54321      18300   (TID 206)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.739 172.17.0.2:54321      18300   (TID 206)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 204.0 (TID 206). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.740 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 204.0 (TID 206) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.740 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.741 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 204 (treeAggregate at RDDLossFunction.scala:61) finished in 0.046 s\n",
      "10-20 20:32:37.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 193 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 204: Stage finished\n",
      "10-20 20:32:37.742 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 193 finished: treeAggregate at RDDLossFunction.scala:61, took 0.047995 s\n",
      "10-20 20:32:37.743 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(397) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.743 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.743 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_397_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.743 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336594 (rel: 2.16e-05) 0.0166001\n",
      "10-20 20:32:37.745 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_399 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:37.745 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_399_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:37.746 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_399_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.747 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 399 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.754 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 194 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.754 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 205 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.754 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.755 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.756 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[285] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_400 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:37.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_400_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:37.761 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_400_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.762 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 400 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.762 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 205 (MapPartitionsRDD[285] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.762 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 205.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.763 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 205.0 (TID 207) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.764 172.17.0.2:54321      18300   (TID 207)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 205.0 (TID 207)\n",
      "10-20 20:32:37.770 172.17.0.2:54321      18300   (TID 207)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.775 172.17.0.2:54321      18300   (TID 207)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 205.0 (TID 207). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.776 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 205.0 (TID 207) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.776 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.777 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 205 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:37.777 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 194 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.777 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 205: Stage finished\n",
      "10-20 20:32:37.778 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 194 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024195 s\n",
      "10-20 20:32:37.779 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(399) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.779 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_399_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.780 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_401 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:37.781 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_401_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:37.781 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_401_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.782 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 401 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.788 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.789 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 195 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.789 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 206 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.789 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.790 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.791 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 206 (MapPartitionsRDD[286] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_402 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:37.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_402_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:37.795 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_402_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 402 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[286] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 206.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.796 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 206.0 (TID 208) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.797 172.17.0.2:54321      18300   (TID 208)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 206.0 (TID 208)\n",
      "10-20 20:32:37.805 172.17.0.2:54321      18300   (TID 208)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.812 172.17.0.2:54321      18300   (TID 208)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 206.0 (TID 208). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.813 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 206.0 (TID 208) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.813 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.813 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 206 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:32:37.813 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 195 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.814 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 206: Stage finished\n",
      "10-20 20:32:37.814 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 195 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025321 s\n",
      "10-20 20:32:37.814 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(401) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.815 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.815 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_401_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.815 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336587 (rel: 2.17e-05) 0.0120578\n",
      "10-20 20:32:37.816 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_403 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:37.817 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_403_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:37.817 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_403_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:37.817 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 403 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.830 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_402_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.831 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 196 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 207 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.832 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.832 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[287] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.833 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_386_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_404 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:37.837 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_404_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.1 MiB)\n",
      "10-20 20:32:37.837 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_396_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.837 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_404_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:37.837 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 404 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.838 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 207 (MapPartitionsRDD[287] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.838 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 207.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.839 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 207.0 (TID 209) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.840 172.17.0.2:54321      18300   (TID 209)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 207.0 (TID 209)\n",
      "10-20 20:32:37.840 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_400_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.841 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_390_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:37.841 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_394_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.843 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_398_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.843 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_392_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.844 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_388_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.847 172.17.0.2:54321      18300   (TID 209)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.852 172.17.0.2:54321      18300   (TID 209)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 207.0 (TID 209). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.853 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 207.0 (TID 209) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.853 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.853 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 207 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:37.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 196 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished\n",
      "10-20 20:32:37.854 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 196 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023036 s\n",
      "10-20 20:32:37.855 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(403) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.856 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_403_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.856 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_405 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_405_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.857 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_405_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 405 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.865 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 197 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 208 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.865 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 208 (MapPartitionsRDD[288] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.868 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_406 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:37.876 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_406_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:37.877 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_406_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.877 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_404_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:37.877 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 406 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.878 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 208 (MapPartitionsRDD[288] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.878 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 208.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.878 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 208.0 (TID 210) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.879 172.17.0.2:54321      18300   (TID 210)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 208.0 (TID 210)\n",
      "10-20 20:32:37.884 172.17.0.2:54321      18300   (TID 210)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.889 172.17.0.2:54321      18300   (TID 210)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 208.0 (TID 210). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.890 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 208.0 (TID 210) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.890 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 208 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:37.890 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 197 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.891 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished\n",
      "10-20 20:32:37.892 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 197 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027060 s\n",
      "10-20 20:32:37.892 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(405) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.893 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.893 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_405_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.893 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336584 (rel: 8.32e-06) 0.0169150\n",
      "10-20 20:32:37.894 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_407 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.895 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_407_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:37.896 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_407_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:37.897 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 407 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.908 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 198 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 209 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[289] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_408 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:37.914 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_408_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:37.915 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_408_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 408 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (MapPartitionsRDD[289] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 209.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.917 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 209.0 (TID 211) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.917 172.17.0.2:54321      18300   (TID 211)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 209.0 (TID 211)\n",
      "10-20 20:32:37.924 172.17.0.2:54321      18300   (TID 211)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.930 172.17.0.2:54321      18300   (TID 211)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 209.0 (TID 211). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.930 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 209.0 (TID 211) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.930 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.931 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 209 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:37.931 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 198 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.931 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 209: Stage finished\n",
      "10-20 20:32:37.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 198 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022834 s\n",
      "10-20 20:32:37.932 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(407) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.933 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_407_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.933 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_409 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:37.944 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_409_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:37.944 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_409_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.945 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 409 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.951 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.952 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 199 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.952 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 210 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.952 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.953 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.953 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[290] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.956 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_410 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:37.958 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_410_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:37.958 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_410_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.959 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 410 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.959 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[290] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.959 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 210.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.960 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 210.0 (TID 212) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.966 172.17.0.2:54321      18300   (TID 212)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 210.0 (TID 212)\n",
      "10-20 20:32:37.972 172.17.0.2:54321      18300   (TID 212)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:37.978 172.17.0.2:54321      18300   (TID 212)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 210.0 (TID 212). 3456 bytes result sent to driver\n",
      "10-20 20:32:37.978 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 210.0 (TID 212) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:37.978 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:37.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 210 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:32:37.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 199 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:37.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 210: Stage finished\n",
      "10-20 20:32:37.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 199 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027921 s\n",
      "10-20 20:32:37.980 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(409) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:37.980 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:37.980 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336575 (rel: 2.65e-05) 0.00915051\n",
      "10-20 20:32:37.981 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_411 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:37.981 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_411_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:37.981 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_409_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.981 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_411_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:37.982 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 411 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:37.989 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:37.989 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 200 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:37.989 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 211 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:37.989 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:37.989 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:37.989 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[291] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:37.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_412 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:37.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_412_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:37.995 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_412_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:37.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 412 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:37.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 211 (MapPartitionsRDD[291] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:37.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 211.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:37.996 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 211.0 (TID 213) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:37.997 172.17.0.2:54321      18300   (TID 213)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 211.0 (TID 213)\n",
      "10-20 20:32:38.003 172.17.0.2:54321      18300   (TID 213)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.009 172.17.0.2:54321      18300   (TID 213)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 211.0 (TID 213). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.009 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 211.0 (TID 213) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.009 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.010 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 211 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:38.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 200 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 211: Stage finished\n",
      "10-20 20:32:38.012 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 200 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023025 s\n",
      "10-20 20:32:38.012 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(411) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.013 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_411_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.014 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_413 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:38.014 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_413_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:38.015 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_413_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.015 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 413 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.022 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 201 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 212 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 212 (MapPartitionsRDD[292] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.026 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_414 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:38.027 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_414_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:38.028 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_414_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 414 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 212 (MapPartitionsRDD[292] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 212.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.029 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 212.0 (TID 214) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.034 172.17.0.2:54321      18300   (TID 214)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 212.0 (TID 214)\n",
      "10-20 20:32:38.040 172.17.0.2:54321      18300   (TID 214)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.047 172.17.0.2:54321      18300   (TID 214)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 212.0 (TID 214). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.047 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 212.0 (TID 214) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.047 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 212 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:38.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 201 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 212: Stage finished\n",
      "10-20 20:32:38.049 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 201 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026833 s\n",
      "10-20 20:32:38.049 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(413) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.050 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.050 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_413_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.051 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336572 (rel: 7.53e-06) 0.0165038\n",
      "10-20 20:32:38.052 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_415 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:38.052 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_415_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:38.053 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_415_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.053 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 415 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.081 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 202 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.081 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 213 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.081 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.081 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 213 (MapPartitionsRDD[293] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.086 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_416 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:38.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_416_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:38.088 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_416_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 416 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 213 (MapPartitionsRDD[293] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 213.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.089 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 213.0 (TID 215) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.090 172.17.0.2:54321      18300   (TID 215)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 213.0 (TID 215)\n",
      "10-20 20:32:38.097 172.17.0.2:54321      18300   (TID 215)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.104 172.17.0.2:54321      18300   (TID 215)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 213.0 (TID 215). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.104 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 213.0 (TID 215) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.105 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.107 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 213 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:32:38.108 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 202 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.108 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 213: Stage finished\n",
      "10-20 20:32:38.109 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 202 finished: treeAggregate at RDDLossFunction.scala:61, took 0.027841 s\n",
      "10-20 20:32:38.109 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(415) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.110 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_415_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_417 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:38.112 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_417_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:38.112 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_417_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.114 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 417 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.122 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.123 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 203 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.123 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 214 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.123 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.124 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[294] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.128 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_418 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:38.129 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_418_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:38.129 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_418_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.130 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 418 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 214 (MapPartitionsRDD[294] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 214.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.132 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 214.0 (TID 216) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.133 172.17.0.2:54321      18300   (TID 216)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 214.0 (TID 216)\n",
      "10-20 20:32:38.146 172.17.0.2:54321      18300   (TID 216)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.157 172.17.0.2:54321      18300   (TID 216)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 214.0 (TID 216). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.159 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 214.0 (TID 216) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.159 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.162 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 214 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:32:38.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 203 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 214: Stage finished\n",
      "10-20 20:32:38.163 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 203 finished: treeAggregate at RDDLossFunction.scala:61, took 0.040415 s\n",
      "10-20 20:32:38.163 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(417) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.164 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.164 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_417_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.165 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336565 (rel: 2.06e-05) 0.0139569\n",
      "10-20 20:32:38.166 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_419 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:38.167 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_419_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:38.173 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_419_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.174 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 419 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 204 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 215 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.191 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 215 (MapPartitionsRDD[295] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.196 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_420 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:38.197 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_420_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:38.198 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_420_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 420 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 215 (MapPartitionsRDD[295] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 215.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.202 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 215.0 (TID 217) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.204 172.17.0.2:54321      18300   (TID 217)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 215.0 (TID 217)\n",
      "10-20 20:32:38.224 172.17.0.2:54321      18300   (TID 217)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.236 172.17.0.2:54321      18300   (TID 217)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 215.0 (TID 217). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.238 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 215.0 (TID 217) in 36 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.238 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.238 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 215 (treeAggregate at RDDLossFunction.scala:61) finished in 0.047 s\n",
      "10-20 20:32:38.239 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 204 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.239 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 215: Stage finished\n",
      "10-20 20:32:38.239 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 204 finished: treeAggregate at RDDLossFunction.scala:61, took 0.050263 s\n",
      "10-20 20:32:38.240 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(419) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.241 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_419_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.241 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_421 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:38.242 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_421_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:38.242 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_421_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.243 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 421 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.250 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 205 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 216 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.251 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[296] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_422 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:38.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_422_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:38.257 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_422_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.257 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 422 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.257 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[296] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.258 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 216.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.259 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 216.0 (TID 218) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.259 172.17.0.2:54321      18300   (TID 218)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 216.0 (TID 218)\n",
      "10-20 20:32:38.267 172.17.0.2:54321      18300   (TID 218)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.274 172.17.0.2:54321      18300   (TID 218)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 216.0 (TID 218). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.275 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 216.0 (TID 218) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.275 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 216 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:32:38.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 205 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.276 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 216: Stage finished\n",
      "10-20 20:32:38.276 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 205 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026201 s\n",
      "10-20 20:32:38.277 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(421) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.277 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.278 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336561 (rel: 1.28e-05) 0.0165400\n",
      "10-20 20:32:38.278 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_421_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.278 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_423 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:38.290 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_423_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:38.290 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_418_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.291 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_423_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.293 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 423 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.293 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_412_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.298 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_414_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.299 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_422_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.300 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_420_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.301 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_416_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.302 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_410_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.306 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_408_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:38.308 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.308 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 206 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.309 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 217 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.309 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.309 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_406_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:38.309 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.310 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[297] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_424 stored as values in memory (estimated size 131.5 KiB, free 430.2 MiB)\n",
      "10-20 20:32:38.318 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_424_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.2 MiB)\n",
      "10-20 20:32:38.318 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_424_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:38.319 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 424 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.320 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 217 (MapPartitionsRDD[297] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.320 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 217.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.321 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 217.0 (TID 219) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.324 172.17.0.2:54321      18300   (TID 219)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 217.0 (TID 219)\n",
      "10-20 20:32:38.334 172.17.0.2:54321      18300   (TID 219)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.342 172.17.0.2:54321      18300   (TID 219)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 217.0 (TID 219). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.342 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 217.0 (TID 219) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.343 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 217 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:32:38.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 206 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 217: Stage finished\n",
      "10-20 20:32:38.343 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 206 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035400 s\n",
      "10-20 20:32:38.344 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(423) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.345 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_423_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:38.345 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_425 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:38.346 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_425_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:38.347 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_425_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:38.347 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 425 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.355 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.355 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 207 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.355 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 218 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.355 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.356 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 218 (MapPartitionsRDD[298] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_426 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:38.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_426_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:38.360 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_426_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 426 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 218 (MapPartitionsRDD[298] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 218.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.362 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 218.0 (TID 220) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.363 172.17.0.2:54321      18300   (TID 220)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 218.0 (TID 220)\n",
      "10-20 20:32:38.368 172.17.0.2:54321      18300   (TID 220)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.374 172.17.0.2:54321      18300   (TID 220)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 218.0 (TID 220). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.374 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 218.0 (TID 220) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.374 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.374 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 218 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:32:38.375 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 207 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.375 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 218: Stage finished\n",
      "10-20 20:32:38.375 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 207 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019960 s\n",
      "10-20 20:32:38.375 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(425) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.376 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_425_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.376 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.377 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336555 (rel: 1.88e-05) 0.0108459\n",
      "10-20 20:32:38.377 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_427 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:38.378 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_427_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:38.378 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_427_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.379 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 427 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.385 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 208 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 219 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 219 (MapPartitionsRDD[299] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.389 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_428 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:38.390 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_428_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:38.390 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_428_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 428 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 219 (MapPartitionsRDD[299] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.391 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 219.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.392 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 219.0 (TID 221) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.392 172.17.0.2:54321      18300   (TID 221)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 219.0 (TID 221)\n",
      "10-20 20:32:38.398 172.17.0.2:54321      18300   (TID 221)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.403 172.17.0.2:54321      18300   (TID 221)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 219.0 (TID 221). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.403 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 219.0 (TID 221) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.403 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.404 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 219 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:32:38.404 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 208 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.404 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 219: Stage finished\n",
      "10-20 20:32:38.404 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 208 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019578 s\n",
      "10-20 20:32:38.404 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(427) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.405 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_427_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.405 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_429 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:38.406 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_429_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:38.406 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_429_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.407 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 429 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 209 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 220 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.414 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.414 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 220 (MapPartitionsRDD[300] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.418 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_430 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:38.419 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_430_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:38.419 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_430_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 430 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 220 (MapPartitionsRDD[300] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 220.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.421 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 220.0 (TID 222) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.421 172.17.0.2:54321      18300   (TID 222)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 220.0 (TID 222)\n",
      "10-20 20:32:38.433 172.17.0.2:54321      18300   (TID 222)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.443 172.17.0.2:54321      18300   (TID 222)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 220.0 (TID 222). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.444 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 220.0 (TID 222) in 23 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.444 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 220 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:32:38.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 209 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 220: Stage finished\n",
      "10-20 20:32:38.447 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 209 finished: treeAggregate at RDDLossFunction.scala:61, took 0.033856 s\n",
      "10-20 20:32:38.447 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(429) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.448 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.448 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336551 (rel: 1.10e-05) 0.0113538\n",
      "10-20 20:32:38.448 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_429_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.449 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_431 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:38.450 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_431_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:38.451 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_431_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.451 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 431 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.459 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.460 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 210 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.460 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 221 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.460 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.460 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.460 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[301] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.469 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_432 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:38.470 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_432_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:38.471 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_432_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.471 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 432 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 221 (MapPartitionsRDD[301] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 221.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.473 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 221.0 (TID 223) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.473 172.17.0.2:54321      18300   (TID 223)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 221.0 (TID 223)\n",
      "10-20 20:32:38.480 172.17.0.2:54321      18300   (TID 223)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.486 172.17.0.2:54321      18300   (TID 223)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 221.0 (TID 223). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.487 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 221.0 (TID 223) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.487 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 221 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:38.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 210 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.488 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished\n",
      "10-20 20:32:38.489 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 210 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029764 s\n",
      "10-20 20:32:38.489 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(431) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.490 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_431_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.493 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_433 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:38.494 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_433_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:38.494 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_433_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.494 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 433 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.502 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.502 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 211 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 222 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[302] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.531 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_434 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:38.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_434_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:38.534 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_434_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.535 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 434 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[302] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.538 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 222.0 (TID 224) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.538 172.17.0.2:54321      18300   (TID 224)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 222.0 (TID 224)\n",
      "10-20 20:32:38.547 172.17.0.2:54321      18300   (TID 224)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.553 172.17.0.2:54321      18300   (TID 224)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 222.0 (TID 224). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.554 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 222.0 (TID 224) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.554 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.554 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 222 (treeAggregate at RDDLossFunction.scala:61) finished in 0.050 s\n",
      "10-20 20:32:38.554 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 211 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.554 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 222: Stage finished\n",
      "10-20 20:32:38.555 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 211 finished: treeAggregate at RDDLossFunction.scala:61, took 0.052675 s\n",
      "10-20 20:32:38.555 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(433) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.556 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.556 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336547 (rel: 1.11e-05) 0.0114871\n",
      "10-20 20:32:38.557 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_435 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:38.558 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_435_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:38.558 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_433_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.558 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_435_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.559 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 435 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.567 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.567 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 212 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 223 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 223 (MapPartitionsRDD[303] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.573 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_436 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:38.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_436_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:38.574 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_436_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 436 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.575 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 223 (MapPartitionsRDD[303] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.575 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 223.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.576 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 223.0 (TID 225) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.576 172.17.0.2:54321      18300   (TID 225)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 223.0 (TID 225)\n",
      "10-20 20:32:38.585 172.17.0.2:54321      18300   (TID 225)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.591 172.17.0.2:54321      18300   (TID 225)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 223.0 (TID 225). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.592 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 223.0 (TID 225) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.592 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.592 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 223 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:38.592 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 212 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 223: Stage finished\n",
      "10-20 20:32:38.593 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 212 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025692 s\n",
      "10-20 20:32:38.593 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(435) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.593 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_435_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.594 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_437 stored as values in memory (estimated size 912.0 B, free 429.2 MiB)\n",
      "10-20 20:32:38.594 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_437_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.2 MiB)\n",
      "10-20 20:32:38.594 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_437_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.595 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 437 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.601 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 213 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 224 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[304] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_438 stored as values in memory (estimated size 131.5 KiB, free 429.1 MiB)\n",
      "10-20 20:32:38.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_438_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:38.609 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_438_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 438 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 224 (MapPartitionsRDD[304] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.609 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 224.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.610 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 224.0 (TID 226) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.611 172.17.0.2:54321      18300   (TID 226)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 224.0 (TID 226)\n",
      "10-20 20:32:38.618 172.17.0.2:54321      18300   (TID 226)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.625 172.17.0.2:54321      18300   (TID 226)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 224.0 (TID 226). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.625 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 224.0 (TID 226) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.626 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 224 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:38.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 213 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 224: Stage finished\n",
      "10-20 20:32:38.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 213 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025011 s\n",
      "10-20 20:32:38.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(437) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.627 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.627 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336543 (rel: 1.43e-05) 0.00921007\n",
      "10-20 20:32:38.628 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_437_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.628 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_439 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:32:38.629 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_439_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:32:38.629 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_439_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.630 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 439 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.639 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 214 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 225 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[305] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.643 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_440 stored as values in memory (estimated size 131.5 KiB, free 428.9 MiB)\n",
      "10-20 20:32:38.644 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_440_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 428.8 MiB)\n",
      "10-20 20:32:38.645 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_440_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.645 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 440 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 225 (MapPartitionsRDD[305] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.646 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 225.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.647 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 225.0 (TID 227) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.648 172.17.0.2:54321      18300   (TID 227)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 225.0 (TID 227)\n",
      "10-20 20:32:38.655 172.17.0.2:54321      18300   (TID 227)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.661 172.17.0.2:54321      18300   (TID 227)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 225.0 (TID 227). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.662 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 225.0 (TID 227) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.662 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 225 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:38.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 214 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished\n",
      "10-20 20:32:38.664 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 214 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024653 s\n",
      "10-20 20:32:38.664 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(439) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.665 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_439_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.666 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_441 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:32:38.667 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_441_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:32:38.667 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_441_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:38.668 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 441 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.679 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 215 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 226 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 226 (MapPartitionsRDD[306] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.685 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_442 stored as values in memory (estimated size 131.5 KiB, free 428.7 MiB)\n",
      "10-20 20:32:38.698 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_430_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.699 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_426_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_442_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.0 MiB)\n",
      "10-20 20:32:38.700 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_442_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 442 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.702 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_428_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:38.703 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (MapPartitionsRDD[306] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.703 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 226.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.705 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 226.0 (TID 228) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.706 172.17.0.2:54321      18300   (TID 228)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 226.0 (TID 228)\n",
      "10-20 20:32:38.707 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_438_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.709 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_424_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.711 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_440_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.712 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_434_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.714 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_436_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.716 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_432_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 430.7 MiB)\n",
      "10-20 20:32:38.724 172.17.0.2:54321      18300   (TID 228)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.731 172.17.0.2:54321      18300   (TID 228)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 226.0 (TID 228). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.732 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 226.0 (TID 228) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.732 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 226 (treeAggregate at RDDLossFunction.scala:61) finished in 0.052 s\n",
      "10-20 20:32:38.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 215 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 226: Stage finished\n",
      "10-20 20:32:38.734 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 215 finished: treeAggregate at RDDLossFunction.scala:61, took 0.054397 s\n",
      "10-20 20:32:38.734 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(441) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.735 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.736 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336539 (rel: 9.61e-06) 0.0133020\n",
      "10-20 20:32:38.736 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_441_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:38.738 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_443 stored as values in memory (estimated size 912.0 B, free 430.2 MiB)\n",
      "10-20 20:32:38.739 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_443_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.2 MiB)\n",
      "10-20 20:32:38.740 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_443_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:32:38.740 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 443 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 216 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 227 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.762 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.762 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[307] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.766 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_444 stored as values in memory (estimated size 131.5 KiB, free 430.1 MiB)\n",
      "10-20 20:32:38.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_444_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 430.0 MiB)\n",
      "10-20 20:32:38.769 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_444_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.769 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 444 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[307] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 227.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.771 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 227.0 (TID 229) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.772 172.17.0.2:54321      18300   (TID 229)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 227.0 (TID 229)\n",
      "10-20 20:32:38.781 172.17.0.2:54321      18300   (TID 229)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.789 172.17.0.2:54321      18300   (TID 229)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 227.0 (TID 229). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.790 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 227.0 (TID 229) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.791 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 227 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:32:38.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 216 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 227: Stage finished\n",
      "10-20 20:32:38.792 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 216 finished: treeAggregate at RDDLossFunction.scala:61, took 0.038186 s\n",
      "10-20 20:32:38.793 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(443) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.794 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_445 stored as values in memory (estimated size 912.0 B, free 430.0 MiB)\n",
      "10-20 20:32:38.795 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_443_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.795 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_445_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:32:38.796 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_445_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.796 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 445 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.809 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 217 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 228 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 228 (MapPartitionsRDD[308] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.814 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_446 stored as values in memory (estimated size 131.5 KiB, free 429.9 MiB)\n",
      "10-20 20:32:38.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_446_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.9 MiB)\n",
      "10-20 20:32:38.816 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_446_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 446 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 228 (MapPartitionsRDD[308] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 228.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.818 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 228.0 (TID 230) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.819 172.17.0.2:54321      18300   (TID 230)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 228.0 (TID 230)\n",
      "10-20 20:32:38.830 172.17.0.2:54321      18300   (TID 230)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.839 172.17.0.2:54321      18300   (TID 230)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 228.0 (TID 230). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.840 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 228.0 (TID 230) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.840 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.841 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 228 (treeAggregate at RDDLossFunction.scala:61) finished in 0.030 s\n",
      "10-20 20:32:38.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 217 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 228: Stage finished\n",
      "10-20 20:32:38.843 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 217 finished: treeAggregate at RDDLossFunction.scala:61, took 0.033442 s\n",
      "10-20 20:32:38.843 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(445) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.844 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.844 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_445_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.844 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336535 (rel: 1.15e-05) 0.0114448\n",
      "10-20 20:32:38.845 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_447 stored as values in memory (estimated size 912.0 B, free 429.9 MiB)\n",
      "10-20 20:32:38.846 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_447_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.9 MiB)\n",
      "10-20 20:32:38.847 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_447_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.847 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 447 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.857 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 218 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 229 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[309] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_448 stored as values in memory (estimated size 131.5 KiB, free 429.7 MiB)\n",
      "10-20 20:32:38.862 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_448_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.7 MiB)\n",
      "10-20 20:32:38.863 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_448_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.6 MiB)\n",
      "10-20 20:32:38.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 448 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 229 (MapPartitionsRDD[309] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 229.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.864 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 229.0 (TID 231) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.864 172.17.0.2:54321      18300   (TID 231)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 229.0 (TID 231)\n",
      "10-20 20:32:38.872 172.17.0.2:54321      18300   (TID 231)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.878 172.17.0.2:54321      18300   (TID 231)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 229.0 (TID 231). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.878 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 229.0 (TID 231) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.878 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.879 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 229 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:32:38.879 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 218 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.879 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 229: Stage finished\n",
      "10-20 20:32:38.879 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 218 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022097 s\n",
      "10-20 20:32:38.879 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(447) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.880 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_447_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.880 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_449 stored as values in memory (estimated size 912.0 B, free 429.7 MiB)\n",
      "10-20 20:32:38.881 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_449_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.7 MiB)\n",
      "10-20 20:32:38.881 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_449_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:32:38.882 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 449 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.888 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 219 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 230 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[310] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.892 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_450 stored as values in memory (estimated size 131.5 KiB, free 429.6 MiB)\n",
      "10-20 20:32:38.893 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_450_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.5 MiB)\n",
      "10-20 20:32:38.893 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_450_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.894 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 450 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.894 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 230 (MapPartitionsRDD[310] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.894 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 230.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.895 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 230.0 (TID 232) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.896 172.17.0.2:54321      18300   (TID 232)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 230.0 (TID 232)\n",
      "10-20 20:32:38.902 172.17.0.2:54321      18300   (TID 232)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.908 172.17.0.2:54321      18300   (TID 232)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 230.0 (TID 232). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.908 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 230.0 (TID 232) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.908 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 230 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:32:38.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 219 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 230: Stage finished\n",
      "10-20 20:32:38.910 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 219 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021185 s\n",
      "10-20 20:32:38.910 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(449) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.911 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:38.911 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_449_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.911 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336531 (rel: 1.28e-05) 0.00681753\n",
      "10-20 20:32:38.912 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_451 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:32:38.912 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_451_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:32:38.913 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_451_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.913 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 451 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:38.920 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:38.921 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 220 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:38.921 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 231 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:38.921 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:38.921 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:38.921 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[311] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:38.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_452 stored as values in memory (estimated size 131.5 KiB, free 429.4 MiB)\n",
      "10-20 20:32:38.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_452_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.4 MiB)\n",
      "10-20 20:32:38.926 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_452_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.5 MiB)\n",
      "10-20 20:32:38.927 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 452 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:38.927 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[311] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:38.927 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 231.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:38.928 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 231.0 (TID 233) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:38.928 172.17.0.2:54321      18300   (TID 233)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 231.0 (TID 233)\n",
      "10-20 20:32:38.981 172.17.0.2:54321      18300   (TID 233)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:38.987 172.17.0.2:54321      18300   (TID 233)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 231.0 (TID 233). 3456 bytes result sent to driver\n",
      "10-20 20:32:38.989 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 231.0 (TID 233) in 62 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:38.989 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:38.990 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 231 (treeAggregate at RDDLossFunction.scala:61) finished in 0.067 s\n",
      "10-20 20:32:38.990 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 220 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:38.990 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished\n",
      "10-20 20:32:38.991 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 220 finished: treeAggregate at RDDLossFunction.scala:61, took 0.070404 s\n",
      "10-20 20:32:38.991 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(451) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:38.992 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_453 stored as values in memory (estimated size 912.0 B, free 429.4 MiB)\n",
      "10-20 20:32:38.992 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_453_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.4 MiB)\n",
      "10-20 20:32:38.993 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_451_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.993 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_453_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:32:38.994 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 453 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:32:39.004 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:32:39.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 221 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:32:39.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 232 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:32:39.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:32:39.010 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:39.010 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 232 (MapPartitionsRDD[312] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:32:39.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_454 stored as values in memory (estimated size 131.5 KiB, free 429.2 MiB)\n",
      "10-20 20:32:39.017 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_454_piece0 stored as bytes in memory (estimated size 42.4 KiB, free 429.2 MiB)\n",
      "10-20 20:32:39.017 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_454_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.4 KiB, free: 430.4 MiB)\n",
      "10-20 20:32:39.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 454 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:39.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 232 (MapPartitionsRDD[312] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:39.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 232.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:39.019 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 232.0 (TID 234) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:39.020 172.17.0.2:54321      18300   (TID 234)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 232.0 (TID 234)\n",
      "10-20 20:32:39.027 172.17.0.2:54321      18300   (TID 234)  INFO org.apache.spark.storage.BlockManager: Found block rdd_104_0 locally\n",
      "10-20 20:32:39.032 172.17.0.2:54321      18300   (TID 234)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 232.0 (TID 234). 3456 bytes result sent to driver\n",
      "10-20 20:32:39.033 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 232.0 (TID 234) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:39.033 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:39.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 232 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:32:39.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 221 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:39.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 232: Stage finished\n",
      "10-20 20:32:39.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 221 finished: treeAggregate at RDDLossFunction.scala:61, took 0.046989 s\n",
      "10-20 20:32:39.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(453) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:32:39.052 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Step Size: 0.5000\n",
      "10-20 20:32:39.053 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_453_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:32:39.053 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Val and Grad Norm: 0.336529 (rel: 5.35e-06) 0.00951391\n",
      "10-20 20:32:39.057 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.OWLQN: Converged because max iterations reached\n",
      "10-20 20:32:39.057 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 104 from persistence list\n",
      "10-20 20:32:39.063 172.17.0.2:54321      18300  ad-pool-70  INFO org.apache.spark.storage.BlockManager: Removing RDD 104\n",
      "10-20 20:32:39.073 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(38) (from destroy at LinearSVC.scala:312)\n",
      "10-20 20:32:39.074 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on 5b5a8eb7561c:44751 in memory (size: 860.0 B, free: 434.1 MiB)\n",
      "10-20 20:32:39.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:39.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:39.258 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:39.365 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_450_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.1 MiB)\n",
      "10-20 20:32:39.367 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_454_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.1 MiB)\n",
      "10-20 20:32:39.368 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_452_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:39.369 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_448_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:39.370 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_444_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:39.372 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_446_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:39.373 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_442_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:39.380 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 71.135577 ms\n",
      "10-20 20:32:39.383 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_455 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 20:32:39.390 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_455_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.8 MiB)\n",
      "10-20 20:32:39.390 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_455_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:39.391 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 455 from rdd at ClassificationSummary.scala:58\n",
      "10-20 20:32:39.392 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:39.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:39.473 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:39.473 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:39.540 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 32.410339 ms\n",
      "10-20 20:32:39.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_456 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 20:32:39.559 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_456_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.6 MiB)\n",
      "10-20 20:32:39.560 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_456_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:39.560 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 456 from rdd at ClassificationSummary.scala:191\n",
      "10-20 20:32:39.561 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:39.586 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [41f1d860] training finished\n",
      "10-20 20:32:39.759 172.17.0.2:54321      18300  ad-pool-11  INFO org.apache.spark.storage.BlockManager: Removing RDD 104\n",
      "Metric name: areaUnderROC\n",
      "10-20 20:32:40.843 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:40.843 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:40.843 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:40.922 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 44.286484 ms\n",
      "10-20 20:32:40.924 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_457 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 20:32:40.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_457_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.4 MiB)\n",
      "10-20 20:32:40.932 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_457_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:40.933 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 457 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:32:40.934 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:41.018 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:32:41.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 335 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 12\n",
      "10-20 20:32:41.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 336 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 11\n",
      "10-20 20:32:41.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 222 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:32:41.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 235 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:32:41.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 234)\n",
      "10-20 20:32:41.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 234)\n",
      "10-20 20:32:41.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 233 (MapPartitionsRDD[335] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:32:41.053 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_458 stored as values in memory (estimated size 141.7 KiB, free 433.3 MiB)\n",
      "10-20 20:32:41.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_458_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 433.2 MiB)\n",
      "10-20 20:32:41.088 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_458_piece0 in memory on 5b5a8eb7561c:44751 (size: 47.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:41.089 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 458 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:41.089 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 233 (MapPartitionsRDD[335] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:41.089 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 233.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:41.090 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 233.0 (TID 235) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:41.091 172.17.0.2:54321      18300   (TID 235)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 233.0 (TID 235)\n",
      "10-20 20:32:41.140 172.17.0.2:54321      18300   (TID 235)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.526708 ms\n",
      "10-20 20:32:41.158 172.17.0.2:54321      18300   (TID 235)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:32:41.317 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:41.319 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 233:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:42.159 172.17.0.2:54321      18300   (TID 235)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 233.0 (TID 235). 2133 bytes result sent to driver\n",
      "10-20 20:32:42.160 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 233.0 (TID 235) in 1070 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:42.160 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:42.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 233 (map at BinaryClassificationMetrics.scala:48) finished in 1.136 s\n",
      "10-20 20:32:42.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:42.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:42.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 234, ResultStage 235)\n",
      "10-20 20:32:42.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:42.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 234 (ShuffledRDD[336] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:32:42.167 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_459 stored as values in memory (estimated size 5.1 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_459_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.185 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_459_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 459 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:42.186 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 234 (ShuffledRDD[336] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:42.186 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 234.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:42.191 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 234.0 (TID 236) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:42.192 172.17.0.2:54321      18300   (TID 236)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 234.0 (TID 236)\n",
      "10-20 20:32:42.201 172.17.0.2:54321      18300   (TID 236)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:42.202 172.17.0.2:54321      18300   (TID 236)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:42.325 172.17.0.2:54321      18300   (TID 236)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 234.0 (TID 236). 1462 bytes result sent to driver\n",
      "10-20 20:32:42.327 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 234.0 (TID 236) in 137 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:42.327 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:42.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 234 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.166 s\n",
      "10-20 20:32:42.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:42.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:42.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 235)\n",
      "10-20 20:32:42.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:42.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 235 (ShuffledRDD[337] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:32:42.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_460 stored as values in memory (estimated size 3.9 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_460_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.331 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_460_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.332 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 460 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:42.333 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 235 (ShuffledRDD[337] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:42.333 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 235.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:42.333 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 235.0 (TID 237) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:42.337 172.17.0.2:54321      18300   (TID 237)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 235.0 (TID 237)\n",
      "10-20 20:32:42.341 172.17.0.2:54321      18300   (TID 237)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:42.341 172.17.0.2:54321      18300   (TID 237)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:42.492 172.17.0.2:54321      18300   (TID 237)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 235.0 (TID 237). 1305 bytes result sent to driver\n",
      "10-20 20:32:42.493 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 235.0 (TID 237) in 160 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:42.493 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:42.493 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 235 (count at BinaryClassificationMetrics.scala:197) finished in 0.164 s\n",
      "10-20 20:32:42.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 222 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:42.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 235: Stage finished\n",
      "10-20 20:32:42.494 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 222 finished: count at BinaryClassificationMetrics.scala:197, took 1.475387 s\n",
      "10-20 20:32:42.514 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:32:42.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 223 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:32:42.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 238 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:32:42.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 237)\n",
      "10-20 20:32:42.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:42.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[340] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:32:42.517 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_461 stored as values in memory (estimated size 5.6 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.518 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_461_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.518 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_461_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 461 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:42.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 238 (MapPartitionsRDD[340] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:42.519 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 238.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:42.520 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 238.0 (TID 238) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:42.520 172.17.0.2:54321      18300   (TID 238)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 238.0 (TID 238)\n",
      "10-20 20:32:42.528 172.17.0.2:54321      18300   (TID 238)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:42.529 172.17.0.2:54321      18300   (TID 238)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:42.638 172.17.0.2:54321      18300   (TID 238)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 238.0 (TID 238). 1448 bytes result sent to driver\n",
      "10-20 20:32:42.639 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 238.0 (TID 238) in 119 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:42.639 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:42.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 238 (collect at BinaryClassificationMetrics.scala:237) finished in 0.124 s\n",
      "10-20 20:32:42.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 223 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:42.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished\n",
      "10-20 20:32:42.641 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 223 finished: collect at BinaryClassificationMetrics.scala:237, took 0.125863 s\n",
      "10-20 20:32:42.641 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 1552.0, numNeg: 4933.0}\n",
      "10-20 20:32:42.657 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:32:42.658 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 224 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:32:42.658 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 241 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:32:42.658 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 240)\n",
      "10-20 20:32:42.659 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:42.659 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 241 (MapPartitionsRDD[345] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:32:42.660 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_462 stored as values in memory (estimated size 7.2 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.676 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_462_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.6 MiB)\n",
      "10-20 20:32:42.676 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_462_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.677 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_458_piece0 on 5b5a8eb7561c:44751 in memory (size: 47.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 462 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:42.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 241 (MapPartitionsRDD[345] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:42.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 241.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:42.685 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 241.0 (TID 239) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:42.685 172.17.0.2:54321      18300   (TID 239)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 241.0 (TID 239)\n",
      "10-20 20:32:42.686 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_460_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.688 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_459_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:42.689 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_461_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.0 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:42.699 172.17.0.2:54321      18300   (TID 239)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:42.699 172.17.0.2:54321      18300   (TID 239)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:32:42.843 172.17.0.2:54321      18300   (TID 239)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_341_0 stored as values in memory (estimated size 82.4 KiB, free 433.7 MiB)\n",
      "10-20 20:32:42.844 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_341_0 in memory on 5b5a8eb7561c:44751 (size: 82.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:42.860 172.17.0.2:54321      18300   (TID 239)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 241.0 (TID 239). 1524 bytes result sent to driver\n",
      "10-20 20:32:42.861 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 241.0 (TID 239) in 176 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:42.861 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 241.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:42.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 241 (collect at AreaUnderCurve.scala:44) finished in 0.202 s\n",
      "10-20 20:32:42.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 224 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:42.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 241: Stage finished\n",
      "10-20 20:32:42.861 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 224 finished: collect at AreaUnderCurve.scala:44, took 0.203493 s\n",
      "10-20 20:32:42.863 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 341 from persistence list\n",
      "CV Metric value: 0.895540186958855\n",
      "10-20 20:32:42.863 172.17.0.2:54321      18300  ad-pool-35  INFO org.apache.spark.storage.BlockManager: Removing RDD 341\n",
      "10-20 20:32:42.996 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:32:42.997 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:32:42.999 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:32:43.104 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 64.483073 ms\n",
      "10-20 20:32:43.106 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_463 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 20:32:43.116 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_463_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.6 MiB)\n",
      "10-20 20:32:43.116 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_463_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:43.118 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 463 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:32:43.120 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:32:43.290 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:32:43.291 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 353 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 14\n",
      "10-20 20:32:43.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 354 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 13\n",
      "10-20 20:32:43.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 225 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:32:43.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 244 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:32:43.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 243)\n",
      "10-20 20:32:43.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 243)\n",
      "10-20 20:32:43.303 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 242 (MapPartitionsRDD[353] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:32:43.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_464 stored as values in memory (estimated size 134.4 KiB, free 433.5 MiB)\n",
      "10-20 20:32:43.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_464_piece0 stored as bytes in memory (estimated size 45.7 KiB, free 433.4 MiB)\n",
      "10-20 20:32:43.472 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_464_piece0 in memory on 5b5a8eb7561c:44751 (size: 45.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:43.473 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 464 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:43.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 242 (MapPartitionsRDD[353] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:43.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 242.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:43.476 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_457_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:43.479 172.17.0.2:54321      18300  ad-pool-48  INFO org.apache.spark.storage.BlockManager: Removing RDD 341\n",
      "10-20 20:32:43.482 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_462_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:43.484 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 242.0 (TID 240) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4854 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:43.485 172.17.0.2:54321      18300   (TID 240)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 242.0 (TID 240)\n",
      "10-20 20:32:43.534 172.17.0.2:54321      18300   (TID 240)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 242:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:44.506 172.17.0.2:54321      18300   (TID 240)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 242.0 (TID 240). 1861 bytes result sent to driver\n",
      "10-20 20:32:44.507 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 242.0 (TID 240) in 1024 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:44.507 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:44.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 242 (map at BinaryClassificationMetrics.scala:48) finished in 1.204 s\n",
      "10-20 20:32:44.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:44.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:44.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 243, ResultStage 244)\n",
      "10-20 20:32:44.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:44.509 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 243 (ShuffledRDD[354] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:32:44.511 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_465 stored as values in memory (estimated size 5.1 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.512 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_465_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.512 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_465_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 465 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:44.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 243 (ShuffledRDD[354] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:44.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 243.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:44.514 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 243.0 (TID 241) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:44.514 172.17.0.2:54321      18300   (TID 241)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 243.0 (TID 241)\n",
      "10-20 20:32:44.517 172.17.0.2:54321      18300   (TID 241)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:44.517 172.17.0.2:54321      18300   (TID 241)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:44.630 172.17.0.2:54321      18300   (TID 241)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 243.0 (TID 241). 1462 bytes result sent to driver\n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 243.0 (TID 241) in 117 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 243 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.121 s\n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 244)\n",
      "10-20 20:32:44.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:32:44.632 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 244 (ShuffledRDD[355] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:32:44.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_466 stored as values in memory (estimated size 3.9 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.634 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_466_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.635 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_466_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 466 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:44.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 244 (ShuffledRDD[355] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:44.635 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 244.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:44.636 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 244.0 (TID 242) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:44.637 172.17.0.2:54321      18300   (TID 242)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 244.0 (TID 242)\n",
      "10-20 20:32:44.640 172.17.0.2:54321      18300   (TID 242)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:44.640 172.17.0.2:54321      18300   (TID 242)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:44.778 172.17.0.2:54321      18300   (TID 242)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 244.0 (TID 242). 1305 bytes result sent to driver\n",
      "10-20 20:32:44.779 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 244.0 (TID 242) in 143 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:44.779 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:44.779 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 244 (count at BinaryClassificationMetrics.scala:197) finished in 0.147 s\n",
      "10-20 20:32:44.780 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 225 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:44.780 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 244: Stage finished\n",
      "10-20 20:32:44.780 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 225 finished: count at BinaryClassificationMetrics.scala:197, took 1.489947 s\n",
      "10-20 20:32:44.792 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:32:44.793 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 226 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:32:44.793 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 247 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:32:44.793 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 246)\n",
      "10-20 20:32:44.793 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:44.793 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 247 (MapPartitionsRDD[358] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:32:44.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_467 stored as values in memory (estimated size 5.6 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_467_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.795 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_467_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 467 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:44.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 247 (MapPartitionsRDD[358] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:44.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 247.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:44.797 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 247.0 (TID 243) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:44.799 172.17.0.2:54321      18300   (TID 243)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 247.0 (TID 243)\n",
      "10-20 20:32:44.801 172.17.0.2:54321      18300   (TID 243)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:44.802 172.17.0.2:54321      18300   (TID 243)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:32:44.898 172.17.0.2:54321      18300   (TID 243)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 247.0 (TID 243). 1448 bytes result sent to driver\n",
      "10-20 20:32:44.899 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 247.0 (TID 243) in 102 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:44.899 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 247.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:44.899 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 247 (collect at BinaryClassificationMetrics.scala:237) finished in 0.106 s\n",
      "10-20 20:32:44.899 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 226 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:44.899 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 247: Stage finished\n",
      "10-20 20:32:44.900 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 226 finished: collect at BinaryClassificationMetrics.scala:237, took 0.107505 s\n",
      "10-20 20:32:44.900 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 3846.0, numNeg: 12436.0}\n",
      "10-20 20:32:44.910 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:32:44.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 227 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:32:44.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 250 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:32:44.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 249)\n",
      "10-20 20:32:44.911 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:32:44.911 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 250 (MapPartitionsRDD[363] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:32:44.912 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_468 stored as values in memory (estimated size 7.2 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.929 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_468_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.6 MiB)\n",
      "10-20 20:32:44.930 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_468_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 468 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:32:44.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 250 (MapPartitionsRDD[363] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:32:44.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 250.0 with 1 tasks resource profile 0\n",
      "10-20 20:32:44.930 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_466_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.931 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 250.0 (TID 244) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:32:44.931 172.17.0.2:54321      18300   (TID 244)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 250.0 (TID 244)\n",
      "10-20 20:32:44.931 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_465_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.933 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_464_piece0 on 5b5a8eb7561c:44751 in memory (size: 45.7 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.934 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_467_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:32:44.935 172.17.0.2:54321      18300   (TID 244)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:32:44.936 172.17.0.2:54321      18300   (TID 244)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:32:45.037 172.17.0.2:54321      18300   (TID 244)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_359_0 stored as values in memory (estimated size 82.1 KiB, free 433.7 MiB)\n",
      "10-20 20:32:45.039 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_359_0 in memory on 5b5a8eb7561c:44751 (size: 82.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:32:45.044 172.17.0.2:54321      18300   (TID 244)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 250.0 (TID 244). 1524 bytes result sent to driver\n",
      "10-20 20:32:45.046 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 250.0 (TID 244) in 116 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:32:45.046 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool \n",
      "10-20 20:32:45.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 250 (collect at AreaUnderCurve.scala:44) finished in 0.136 s\n",
      "10-20 20:32:45.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 227 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:32:45.048 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 250: Stage finished\n",
      "10-20 20:32:45.048 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 227 finished: collect at AreaUnderCurve.scala:44, took 0.138053 s\n",
      "10-20 20:32:45.048 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 359 from persistence list\n",
      "10-20 20:32:45.049 172.17.0.2:54321      18300  ad-pool-72  INFO org.apache.spark.storage.BlockManager: Removing RDD 359\n",
      "Test Metric value: 0.9008982778095308\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "svc = LinearSVC(labelCol='label', featuresCol='features')\n",
    "svc_stages = [imputer] + string_indexers + ohe_indexers + [vector_assembler] + [svc]\n",
    "pipeline = Pipeline().setStages(svc_stages)\n",
    "svc_model = pipeline.fit(train_df)\n",
    "\n",
    "val_df_pred = svc_model.transform(val_df)\n",
    "test_df_pred = svc_model.transform(test_df)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'Metric name: {evaluator.getMetricName()}')\n",
    "print(f'CV Metric value: {evaluator.evaluate(val_df_pred)}')\n",
    "print(f'Test Metric value: {evaluator.evaluate(test_df_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d30bfa-53b8-4972-9816-28c69816afaf",
   "metadata": {},
   "source": [
    "### LogisticRegresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e751ee1-d7f5-4370-90ac-0eadfa78c1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:33:30.601 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:30.602 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:30.602 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:30.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_469 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 20:33:30.643 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_463_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:30.645 172.17.0.2:54321      18300  ad-pool-83  INFO org.apache.spark.storage.BlockManager: Removing RDD 359\n",
      "10-20 20:33:30.646 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_469_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.8 MiB)\n",
      "10-20 20:33:30.647 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_469_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:30.648 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 469 from head at Imputer.scala:169\n",
      "10-20 20:33:30.648 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_468_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:30.649 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:30.662 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:169\n",
      "10-20 20:33:30.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 367 (head at Imputer.scala:169) as input to shuffle 15\n",
      "10-20 20:33:30.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 228 (head at Imputer.scala:169) with 1 output partitions\n",
      "10-20 20:33:30.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 252 (head at Imputer.scala:169)\n",
      "10-20 20:33:30.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 251)\n",
      "10-20 20:33:30.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 251)\n",
      "10-20 20:33:30.663 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 251 (MapPartitionsRDD[367] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:33:30.665 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_470 stored as values in memory (estimated size 54.3 KiB, free 433.7 MiB)\n",
      "10-20 20:33:30.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_470_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 433.7 MiB)\n",
      "10-20 20:33:30.666 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_470_piece0 in memory on 5b5a8eb7561c:44751 (size: 22.1 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:30.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 470 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:30.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 251 (MapPartitionsRDD[367] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:30.667 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 251.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:30.667 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 251.0 (TID 245) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:30.668 172.17.0.2:54321      18300   (TID 245)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 251.0 (TID 245)\n",
      "10-20 20:33:30.675 172.17.0.2:54321      18300   (TID 245)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:30.961 172.17.0.2:54321      18300   (TID 245)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 251.0 (TID 245). 2689 bytes result sent to driver\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 251.0 (TID 245) in 295 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 251 (head at Imputer.scala:169) finished in 0.298 s\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 252)\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:30.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 252 (MapPartitionsRDD[370] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:33:30.963 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_471 stored as values in memory (estimated size 19.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:30.973 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_471_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:30.974 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_471_piece0 in memory on 5b5a8eb7561c:44751 (size: 7.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:30.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 471 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:30.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 252 (MapPartitionsRDD[370] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:30.979 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 252.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:30.980 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 252.0 (TID 246) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:30.980 172.17.0.2:54321      18300   (TID 246)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 252.0 (TID 246)\n",
      "10-20 20:33:30.982 172.17.0.2:54321      18300   (TID 246)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:30.982 172.17.0.2:54321      18300   (TID 246)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:30.984 172.17.0.2:54321      18300   (TID 246)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 252.0 (TID 246). 2681 bytes result sent to driver\n",
      "10-20 20:33:30.984 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 252.0 (TID 246) in 4 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:30.984 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:30.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 252 (head at Imputer.scala:169) finished in 0.022 s\n",
      "10-20 20:33:30.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 228 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:30.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished\n",
      "10-20 20:33:30.986 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 228 finished: head at Imputer.scala:169, took 0.323206 s\n",
      "10-20 20:33:31.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:33:31.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 229 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 20:33:31.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 253 (head at Imputer.scala:258)\n",
      "10-20 20:33:31.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:31.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:31.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 253 (MapPartitionsRDD[374] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:33:31.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_472 stored as values in memory (estimated size 10.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:31.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_472_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:31.036 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_472_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 472 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:31.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 253 (MapPartitionsRDD[374] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:31.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 253.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:31.038 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 253.0 (TID 247) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.039 172.17.0.2:54321      18300   (TID 247)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 253.0 (TID 247)\n",
      "10-20 20:33:31.042 172.17.0.2:54321      18300   (TID 247)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 253.0 (TID 247). 1304 bytes result sent to driver\n",
      "10-20 20:33:31.043 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 253.0 (TID 247) in 5 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:31.043 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:31.043 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 253 (head at Imputer.scala:258) finished in 0.015 s\n",
      "10-20 20:33:31.044 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 229 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:31.044 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 253: Stage finished\n",
      "10-20 20:33:31.044 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 229 finished: head at Imputer.scala:258, took 0.016902 s\n",
      "10-20 20:33:31.047 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:33:31.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 230 (head at Imputer.scala:258) with 3 output partitions\n",
      "10-20 20:33:31.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 254 (head at Imputer.scala:258)\n",
      "10-20 20:33:31.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:31.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:31.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 254 (MapPartitionsRDD[374] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:33:31.050 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_473 stored as values in memory (estimated size 10.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:31.051 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_473_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:31.051 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_473_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.051 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 473 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:31.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 3 missing tasks from ResultStage 254 (MapPartitionsRDD[374] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(1, 2, 3))\n",
      "10-20 20:33:31.052 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 254.0 with 3 tasks resource profile 0\n",
      "10-20 20:33:31.053 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 254.0 (TID 248) (5b5a8eb7561c, executor driver, partition 1, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.053 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 254.0 (TID 249) (5b5a8eb7561c, executor driver, partition 2, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.053 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 254.0 (TID 250) (5b5a8eb7561c, executor driver, partition 3, PROCESS_LOCAL, 4717 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.054 172.17.0.2:54321      18300   (TID 248)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 254.0 (TID 248)\n",
      "10-20 20:33:31.057 172.17.0.2:54321      18300   (TID 248)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 254.0 (TID 248). 1304 bytes result sent to driver\n",
      "10-20 20:33:31.057 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 254.0 (TID 248) in 5 ms on 5b5a8eb7561c (executor driver) (1/3)\n",
      "10-20 20:33:31.058 172.17.0.2:54321      18300   (TID 249)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 254.0 (TID 249)\n",
      "10-20 20:33:31.061 172.17.0.2:54321      18300   (TID 249)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 254.0 (TID 249). 1304 bytes result sent to driver\n",
      "10-20 20:33:31.061 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 254.0 (TID 249) in 8 ms on 5b5a8eb7561c (executor driver) (2/3)\n",
      "10-20 20:33:31.061 172.17.0.2:54321      18300   (TID 250)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 254.0 (TID 250)\n",
      "10-20 20:33:31.066 172.17.0.2:54321      18300   (TID 250)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 254.0 (TID 250). 1400 bytes result sent to driver\n",
      "10-20 20:33:31.067 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 254.0 (TID 250) in 14 ms on 5b5a8eb7561c (executor driver) (3/3)\n",
      "10-20 20:33:31.067 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:31.067 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 254 (head at Imputer.scala:258) finished in 0.018 s\n",
      "10-20 20:33:31.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 230 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:31.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 254: Stage finished\n",
      "10-20 20:33:31.068 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 230 finished: head at Imputer.scala:258, took 0.020457 s\n",
      "10-20 20:33:31.129 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:31.129 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:31.130 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:31.140 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_474 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:31.147 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_474_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:31.147 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_474_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.148 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 474 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:31.149 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:31.207 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:31.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 379 (collect at StringIndexer.scala:204) as input to shuffle 16\n",
      "10-20 20:33:31.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 231 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:31.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 256 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:31.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 255)\n",
      "10-20 20:33:31.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 255)\n",
      "10-20 20:33:31.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 255 (MapPartitionsRDD[379] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:31.213 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_475 stored as values in memory (estimated size 35.3 KiB, free 433.4 MiB)\n",
      "10-20 20:33:31.216 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_475_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.4 MiB)\n",
      "10-20 20:33:31.217 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_475_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:31.218 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 475 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:31.219 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 255 (MapPartitionsRDD[379] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:31.220 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 255.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:31.221 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 255.0 (TID 251) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.222 172.17.0.2:54321      18300   (TID 251)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 255.0 (TID 251)\n",
      "10-20 20:33:31.251 172.17.0.2:54321      18300   (TID 251)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:31.352 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_472_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:31.353 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_473_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:31.353 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_471_piece0 on 5b5a8eb7561c:44751 in memory (size: 7.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.354 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_469_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.355 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_470_piece0 on 5b5a8eb7561c:44751 in memory (size: 22.1 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.573 172.17.0.2:54321      18300   (TID 251)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 255.0 (TID 251). 2511 bytes result sent to driver\n",
      "10-20 20:33:31.573 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 255.0 (TID 251) in 352 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:31.573 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:31.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 255 (collect at StringIndexer.scala:204) finished in 0.364 s\n",
      "10-20 20:33:31.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:31.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:31.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 256)\n",
      "10-20 20:33:31.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:31.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 256 (MapPartitionsRDD[382] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:31.575 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_476 stored as values in memory (estimated size 26.7 KiB, free 433.7 MiB)\n",
      "10-20 20:33:31.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_476_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:31.576 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_476_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 476 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:31.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 256 (MapPartitionsRDD[382] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:31.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 256.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:31.577 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 256.0 (TID 252) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.578 172.17.0.2:54321      18300   (TID 252)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 256.0 (TID 252)\n",
      "10-20 20:33:31.582 172.17.0.2:54321      18300   (TID 252)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:31.582 172.17.0.2:54321      18300   (TID 252)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:31.599 172.17.0.2:54321      18300   (TID 252)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 256.0 (TID 252). 3904 bytes result sent to driver\n",
      "10-20 20:33:31.599 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 256.0 (TID 252) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:31.599 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:31.600 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 256 (collect at StringIndexer.scala:204) finished in 0.026 s\n",
      "10-20 20:33:31.600 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 231 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:31.600 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 256: Stage finished\n",
      "10-20 20:33:31.600 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 231 finished: collect at StringIndexer.scala:204, took 0.392895 s\n",
      "10-20 20:33:31.665 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:31.665 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:31.665 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:31.674 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_477 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:31.689 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_477_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.6 MiB)\n",
      "10-20 20:33:31.690 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_476_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.691 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_477_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.691 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_474_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.692 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_475_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.695 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 477 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:31.696 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:31.713 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:31.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 387 (collect at StringIndexer.scala:204) as input to shuffle 17\n",
      "10-20 20:33:31.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 232 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:31.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 258 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:31.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 257)\n",
      "10-20 20:33:31.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 257)\n",
      "10-20 20:33:31.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 257 (MapPartitionsRDD[387] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:31.715 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_478 stored as values in memory (estimated size 35.3 KiB, free 433.8 MiB)\n",
      "10-20 20:33:31.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_478_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.8 MiB)\n",
      "10-20 20:33:31.716 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_478_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:31.717 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 478 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:31.717 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 257 (MapPartitionsRDD[387] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:31.717 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 257.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:31.718 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 257.0 (TID 253) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:31.718 172.17.0.2:54321      18300   (TID 253)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 257.0 (TID 253)\n",
      "10-20 20:33:31.723 172.17.0.2:54321      18300   (TID 253)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:32.021 172.17.0.2:54321      18300   (TID 253)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 257.0 (TID 253). 2468 bytes result sent to driver\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 257.0 (TID 253) in 305 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 257 (collect at StringIndexer.scala:204) finished in 0.308 s\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 258)\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:32.022 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 258 (MapPartitionsRDD[390] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:32.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_479 stored as values in memory (estimated size 26.7 KiB, free 433.7 MiB)\n",
      "10-20 20:33:32.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_479_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.7 MiB)\n",
      "10-20 20:33:32.037 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_479_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 479 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:32.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 258 (MapPartitionsRDD[390] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:32.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 258.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:32.038 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 258.0 (TID 254) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:32.041 172.17.0.2:54321      18300   (TID 254)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 258.0 (TID 254)\n",
      "10-20 20:33:32.043 172.17.0.2:54321      18300   (TID 254)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:32.043 172.17.0.2:54321      18300   (TID 254)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:32.054 172.17.0.2:54321      18300   (TID 254)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 258.0 (TID 254). 3956 bytes result sent to driver\n",
      "10-20 20:33:32.054 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 258.0 (TID 254) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:32.054 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:32.054 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 258 (collect at StringIndexer.scala:204) finished in 0.031 s\n",
      "10-20 20:33:32.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 232 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:32.055 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 258: Stage finished\n",
      "10-20 20:33:32.055 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 232 finished: collect at StringIndexer.scala:204, took 0.341372 s\n",
      "10-20 20:33:32.125 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:32.125 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:32.125 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:32.136 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_480 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.141 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_480_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.142 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_480_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.142 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 480 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:32.143 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 395 (collect at StringIndexer.scala:204) as input to shuffle 18\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 233 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 260 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 259)\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 259)\n",
      "10-20 20:33:32.155 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 259 (MapPartitionsRDD[395] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:32.156 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_481 stored as values in memory (estimated size 35.3 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_481_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.157 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_481_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:32.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 481 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:32.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 259 (MapPartitionsRDD[395] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:32.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 259.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:32.159 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 259.0 (TID 255) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:32.159 172.17.0.2:54321      18300   (TID 255)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 259.0 (TID 255)\n",
      "10-20 20:33:32.164 172.17.0.2:54321      18300   (TID 255)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:32.434 172.17.0.2:54321      18300   (TID 255)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 259.0 (TID 255). 2468 bytes result sent to driver\n",
      "10-20 20:33:32.435 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 259.0 (TID 255) in 276 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:32.435 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:32.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 259 (collect at StringIndexer.scala:204) finished in 0.279 s\n",
      "10-20 20:33:32.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:32.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:32.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 260)\n",
      "10-20 20:33:32.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:32.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 260 (MapPartitionsRDD[398] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:32.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_482 stored as values in memory (estimated size 26.8 KiB, free 433.4 MiB)\n",
      "10-20 20:33:32.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_482_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.4 MiB)\n",
      "10-20 20:33:32.450 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_482_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:32.450 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_478_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.451 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_479_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.452 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_477_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 482 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:32.455 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 260 (MapPartitionsRDD[398] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:32.455 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 260.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:32.456 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 260.0 (TID 256) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:32.460 172.17.0.2:54321      18300   (TID 256)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 260.0 (TID 256)\n",
      "10-20 20:33:32.463 172.17.0.2:54321      18300   (TID 256)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:32.463 172.17.0.2:54321      18300   (TID 256)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:32.473 172.17.0.2:54321      18300   (TID 256)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 260.0 (TID 256). 3884 bytes result sent to driver\n",
      "10-20 20:33:32.474 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 260.0 (TID 256) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:32.474 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:32.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 260 (collect at StringIndexer.scala:204) finished in 0.037 s\n",
      "10-20 20:33:32.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 233 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:32.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 260: Stage finished\n",
      "10-20 20:33:32.475 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 233 finished: collect at StringIndexer.scala:204, took 0.319816 s\n",
      "10-20 20:33:32.532 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:32.532 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:32.532 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:32.544 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_483 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_483_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.550 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_483_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.551 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 483 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:32.551 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:32.561 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:32.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 403 (collect at StringIndexer.scala:204) as input to shuffle 19\n",
      "10-20 20:33:32.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 234 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:32.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 262 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:32.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 261)\n",
      "10-20 20:33:32.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 261)\n",
      "10-20 20:33:32.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 261 (MapPartitionsRDD[403] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:32.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_484 stored as values in memory (estimated size 35.3 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_484_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.564 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_484_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:32.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 484 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:32.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 261 (MapPartitionsRDD[403] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:32.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 261.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:32.565 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 261.0 (TID 257) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:32.566 172.17.0.2:54321      18300   (TID 257)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 261.0 (TID 257)\n",
      "10-20 20:33:32.572 172.17.0.2:54321      18300   (TID 257)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:32.860 172.17.0.2:54321      18300   (TID 257)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 261.0 (TID 257). 2468 bytes result sent to driver\n",
      "10-20 20:33:32.860 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 261.0 (TID 257) in 295 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 261 (collect at StringIndexer.scala:204) finished in 0.299 s\n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 262)\n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:32.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[406] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:32.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_485 stored as values in memory (estimated size 26.7 KiB, free 433.4 MiB)\n",
      "10-20 20:33:32.872 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_485_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.4 MiB)\n",
      "10-20 20:33:32.872 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_485_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:32.873 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 485 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:32.873 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 262 (MapPartitionsRDD[406] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:32.873 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 262.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:32.874 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 262.0 (TID 258) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:32.874 172.17.0.2:54321      18300   (TID 258)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 262.0 (TID 258)\n",
      "10-20 20:33:32.876 172.17.0.2:54321      18300   (TID 258)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (789.0 B) non-empty blocks including 1 (789.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:32.876 172.17.0.2:54321      18300   (TID 258)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:32.876 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_481_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.878 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_482_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.878 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_480_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.886 172.17.0.2:54321      18300   (TID 258)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 262.0 (TID 258). 4046 bytes result sent to driver\n",
      "10-20 20:33:32.887 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 262.0 (TID 258) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:32.887 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:32.887 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 262 (collect at StringIndexer.scala:204) finished in 0.025 s\n",
      "10-20 20:33:32.887 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 234 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:32.887 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished\n",
      "10-20 20:33:32.887 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 234 finished: collect at StringIndexer.scala:204, took 0.326290 s\n",
      "10-20 20:33:32.963 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:32.963 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:32.964 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:32.972 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_486 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.978 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_486_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.978 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_486_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:32.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 486 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:32.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 411 (collect at StringIndexer.scala:204) as input to shuffle 20\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 235 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 264 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 263)\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 263)\n",
      "10-20 20:33:32.988 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 263 (MapPartitionsRDD[411] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:32.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_487 stored as values in memory (estimated size 35.3 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.992 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_487_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.5 MiB)\n",
      "10-20 20:33:32.993 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_487_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:32.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 487 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:32.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 263 (MapPartitionsRDD[411] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:32.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 263.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:32.995 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 263.0 (TID 259) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:32.995 172.17.0.2:54321      18300   (TID 259)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 263.0 (TID 259)\n",
      "10-20 20:33:33.000 172.17.0.2:54321      18300   (TID 259)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:33.266 172.17.0.2:54321      18300   (TID 259)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 263.0 (TID 259). 2468 bytes result sent to driver\n",
      "10-20 20:33:33.267 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 263.0 (TID 259) in 272 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:33.267 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:33.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 263 (collect at StringIndexer.scala:204) finished in 0.279 s\n",
      "10-20 20:33:33.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:33.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:33.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 264)\n",
      "10-20 20:33:33.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:33.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 264 (MapPartitionsRDD[414] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:33.270 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_488 stored as values in memory (estimated size 26.7 KiB, free 433.4 MiB)\n",
      "10-20 20:33:33.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_488_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.4 MiB)\n",
      "10-20 20:33:33.279 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_488_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:33.279 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_485_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:33.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 488 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:33.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 264 (MapPartitionsRDD[414] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:33.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 264.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:33.281 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_484_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.281 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 264.0 (TID 260) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:33.281 172.17.0.2:54321      18300   (TID 260)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 264.0 (TID 260)\n",
      "10-20 20:33:33.282 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_483_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.284 172.17.0.2:54321      18300   (TID 260)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:33.284 172.17.0.2:54321      18300   (TID 260)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:33.297 172.17.0.2:54321      18300   (TID 260)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 264.0 (TID 260). 3855 bytes result sent to driver\n",
      "10-20 20:33:33.298 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 264.0 (TID 260) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:33.298 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:33.298 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 264 (collect at StringIndexer.scala:204) finished in 0.029 s\n",
      "10-20 20:33:33.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 235 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:33.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 264: Stage finished\n",
      "10-20 20:33:33.299 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 235 finished: collect at StringIndexer.scala:204, took 0.311325 s\n",
      "10-20 20:33:33.359 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:33.359 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:33.359 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:33.368 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_489 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.373 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_489_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.373 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_489_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.374 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 489 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:33.374 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:33.382 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:33.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 419 (collect at StringIndexer.scala:204) as input to shuffle 21\n",
      "10-20 20:33:33.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 236 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:33.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 266 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:33.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 265)\n",
      "10-20 20:33:33.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 265)\n",
      "10-20 20:33:33.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 265 (MapPartitionsRDD[419] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:33.384 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_490 stored as values in memory (estimated size 35.3 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_490_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.385 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_490_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:33.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 490 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:33.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 265 (MapPartitionsRDD[419] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:33.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 265.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:33.387 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 265.0 (TID 261) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:33.387 172.17.0.2:54321      18300   (TID 261)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 265.0 (TID 261)\n",
      "10-20 20:33:33.391 172.17.0.2:54321      18300   (TID 261)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:33.680 172.17.0.2:54321      18300   (TID 261)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 265.0 (TID 261). 2468 bytes result sent to driver\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 265.0 (TID 261) in 294 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 265 (collect at StringIndexer.scala:204) finished in 0.297 s\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 266)\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:33.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 266 (MapPartitionsRDD[422] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:33.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_491 stored as values in memory (estimated size 26.7 KiB, free 433.4 MiB)\n",
      "10-20 20:33:33.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_491_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.4 MiB)\n",
      "10-20 20:33:33.693 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_491_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:33.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 491 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:33.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 266 (MapPartitionsRDD[422] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:33.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 266.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:33.695 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 266.0 (TID 262) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:33.695 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_487_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.695 172.17.0.2:54321      18300   (TID 262)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 266.0 (TID 262)\n",
      "10-20 20:33:33.697 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_486_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.698 172.17.0.2:54321      18300   (TID 262)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:33.699 172.17.0.2:54321      18300   (TID 262)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:33.700 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_488_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.7 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.711 172.17.0.2:54321      18300   (TID 262)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 266.0 (TID 262). 3863 bytes result sent to driver\n",
      "10-20 20:33:33.712 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 266.0 (TID 262) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:33.712 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 266.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:33.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 266 (collect at StringIndexer.scala:204) finished in 0.030 s\n",
      "10-20 20:33:33.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 236 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:33.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 266: Stage finished\n",
      "10-20 20:33:33.713 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 236 finished: collect at StringIndexer.scala:204, took 0.330231 s\n",
      "10-20 20:33:33.774 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:33.775 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:33.775 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:33.789 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_492 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.795 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_492_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.795 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_492_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:33.796 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 492 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:33.799 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:33.809 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:33.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 427 (collect at StringIndexer.scala:204) as input to shuffle 22\n",
      "10-20 20:33:33.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 237 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:33.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 268 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:33.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 267)\n",
      "10-20 20:33:33.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 267)\n",
      "10-20 20:33:33.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 267 (MapPartitionsRDD[427] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:33.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_493 stored as values in memory (estimated size 35.3 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.814 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_493_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.5 MiB)\n",
      "10-20 20:33:33.814 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_493_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:33.814 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 493 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:33.815 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 267 (MapPartitionsRDD[427] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:33.815 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 267.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:33.815 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 267.0 (TID 263) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:33.816 172.17.0.2:54321      18300   (TID 263)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 267.0 (TID 263)\n",
      "10-20 20:33:33.820 172.17.0.2:54321      18300   (TID 263)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:34.102 172.17.0.2:54321      18300   (TID 263)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 267.0 (TID 263). 2468 bytes result sent to driver\n",
      "10-20 20:33:34.102 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 267.0 (TID 263) in 287 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:34.102 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:34.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 267 (collect at StringIndexer.scala:204) finished in 0.292 s\n",
      "10-20 20:33:34.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:34.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:34.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 268)\n",
      "10-20 20:33:34.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:34.104 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 268 (MapPartitionsRDD[430] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:34.105 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_494 stored as values in memory (estimated size 26.7 KiB, free 433.4 MiB)\n",
      "10-20 20:33:34.114 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_494_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.4 MiB)\n",
      "10-20 20:33:34.115 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_494_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:34.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 494 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:34.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 268 (MapPartitionsRDD[430] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:34.116 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 268.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:34.116 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_489_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.117 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 268.0 (TID 264) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:34.118 172.17.0.2:54321      18300   (TID 264)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 268.0 (TID 264)\n",
      "10-20 20:33:34.119 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_490_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.120 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_491_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.7 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.123 172.17.0.2:54321      18300   (TID 264)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:34.123 172.17.0.2:54321      18300   (TID 264)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:34.135 172.17.0.2:54321      18300   (TID 264)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 268.0 (TID 264). 3768 bytes result sent to driver\n",
      "10-20 20:33:34.136 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 268.0 (TID 264) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:34.136 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:34.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 268 (collect at StringIndexer.scala:204) finished in 0.031 s\n",
      "10-20 20:33:34.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 237 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:34.136 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 268: Stage finished\n",
      "10-20 20:33:34.137 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 237 finished: collect at StringIndexer.scala:204, took 0.327324 s\n",
      "10-20 20:33:34.219 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:34.219 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:34.219 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:34.231 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_495 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:34.239 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_495_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.5 MiB)\n",
      "10-20 20:33:34.240 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_495_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.240 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 495 from collect at StringIndexer.scala:204\n",
      "10-20 20:33:34.241 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 435 (collect at StringIndexer.scala:204) as input to shuffle 23\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 238 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 270 (collect at StringIndexer.scala:204)\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 269)\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 269)\n",
      "10-20 20:33:34.253 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 269 (MapPartitionsRDD[435] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:34.254 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_496 stored as values in memory (estimated size 35.3 KiB, free 433.5 MiB)\n",
      "10-20 20:33:34.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_496_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.5 MiB)\n",
      "10-20 20:33:34.255 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_496_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:34.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 496 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:34.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 269 (MapPartitionsRDD[435] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:34.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 269.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:34.257 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 269.0 (TID 265) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:34.257 172.17.0.2:54321      18300   (TID 265)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 269.0 (TID 265)\n",
      "10-20 20:33:34.262 172.17.0.2:54321      18300   (TID 265)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:34.565 172.17.0.2:54321      18300   (TID 265)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 269.0 (TID 265). 2468 bytes result sent to driver\n",
      "10-20 20:33:34.565 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 269.0 (TID 265) in 309 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:34.565 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:34.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 269 (collect at StringIndexer.scala:204) finished in 0.312 s\n",
      "10-20 20:33:34.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:34.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:34.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 270)\n",
      "10-20 20:33:34.566 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:34.567 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 270 (MapPartitionsRDD[438] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:33:34.568 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_497 stored as values in memory (estimated size 26.8 KiB, free 433.4 MiB)\n",
      "10-20 20:33:34.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_497_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.4 MiB)\n",
      "10-20 20:33:34.577 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_497_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:34.577 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_493_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 497 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:34.578 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 270 (MapPartitionsRDD[438] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:34.578 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 270.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:34.578 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_494_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.579 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 270.0 (TID 266) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:34.579 172.17.0.2:54321      18300   (TID 266)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 270.0 (TID 266)\n",
      "10-20 20:33:34.580 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_492_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:34.583 172.17.0.2:54321      18300   (TID 266)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (955.0 B) non-empty blocks including 1 (955.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:34.583 172.17.0.2:54321      18300   (TID 266)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:34.597 172.17.0.2:54321      18300   (TID 266)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 270.0 (TID 266). 4215 bytes result sent to driver\n",
      "10-20 20:33:34.598 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 270.0 (TID 266) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:34.598 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:34.598 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 270 (collect at StringIndexer.scala:204) finished in 0.031 s\n",
      "10-20 20:33:34.599 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 238 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:34.599 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished\n",
      "10-20 20:33:34.599 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 238 finished: collect at StringIndexer.scala:204, took 0.346056 s\n",
      "10-20 20:33:35.079 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] Stage class: LogisticRegression\n",
      "10-20 20:33:35.080 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] Stage uid: LogisticRegression_5ff9b43d9b23\n",
      "10-20 20:33:35.151 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:35.151 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:35.152 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:35.268 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 65.022628 ms\n",
      "10-20 20:33:35.269 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_498 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 20:33:35.288 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_497_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:35.292 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_498_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.6 MiB)\n",
      "10-20 20:33:35.293 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_498_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:35.294 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 498 from rdd at Instrumentation.scala:62\n",
      "10-20 20:33:35.295 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:35.299 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_496_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:35.312 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "10-20 20:33:35.312 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"labelCol\":\"label\",\"featuresCol\":\"features\"}\n",
      "10-20 20:33:35.378 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:35.378 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:35.378 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:35.405 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_499 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 20:33:35.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_499_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.4 MiB)\n",
      "10-20 20:33:35.413 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_499_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:35.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 499 from rdd at Predictor.scala:81\n",
      "10-20 20:33:35.414 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:35.430 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at Summarizer.scala:232\n",
      "10-20 20:33:35.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 239 (treeAggregate at Summarizer.scala:232) with 1 output partitions\n",
      "10-20 20:33:35.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 271 (treeAggregate at Summarizer.scala:232)\n",
      "10-20 20:33:35.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:35.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:35.431 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[452] at treeAggregate at Summarizer.scala:232), which has no missing parents\n",
      "10-20 20:33:35.438 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_500 stored as values in memory (estimated size 130.4 KiB, free 433.3 MiB)\n",
      "10-20 20:33:35.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_500_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 433.2 MiB)\n",
      "10-20 20:33:35.439 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_500_piece0 in memory on 5b5a8eb7561c:44751 (size: 41.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:35.441 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 500 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:35.441 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[452] at treeAggregate at Summarizer.scala:232) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:35.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 271.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:35.443 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 271.0 (TID 267) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:35.443 172.17.0.2:54321      18300   (TID 267)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 271.0 (TID 267)\n",
      "10-20 20:33:35.467 172.17.0.2:54321      18300   (TID 267)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:35.763 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_495_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:33:36.186 172.17.0.2:54321      18300   (TID 267)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 271.0 (TID 267). 5776 bytes result sent to driver\n",
      "10-20 20:33:36.187 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 271.0 (TID 267) in 744 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:36.187 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:36.187 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 271 (treeAggregate at Summarizer.scala:232) finished in 0.756 s\n",
      "10-20 20:33:36.187 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 239 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:36.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished\n",
      "10-20 20:33:36.188 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 239 finished: treeAggregate at Summarizer.scala:232, took 0.757724 s\n",
      "10-20 20:33:36.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"numClasses\":2}\n",
      "10-20 20:33:36.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"numFeatures\":106}\n",
      "10-20 20:33:36.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"numExamples\":26076}\n",
      "10-20 20:33:36.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"lowestLabelWeight\":\"6289.0\"}\n",
      "10-20 20:33:36.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"highestLabelWeight\":\"19787.0\"}\n",
      "10-20 20:33:36.190 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"sumOfWeights\":26076.0}\n",
      "10-20 20:33:36.190 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [cb43d9ea] {\"actualBlockSizeInMB\":\"1.0\"}\n",
      "10-20 20:33:36.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_501 stored as values in memory (estimated size 888.0 B, free 433.4 MiB)\n",
      "10-20 20:33:36.197 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_501_piece0 stored as bytes in memory (estimated size 860.0 B, free 433.4 MiB)\n",
      "10-20 20:33:36.197 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_501_piece0 in memory on 5b5a8eb7561c:44751 (size: 860.0 B, free: 434.2 MiB)\n",
      "10-20 20:33:36.197 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 501 from broadcast at LogisticRegression.scala:942\n",
      "10-20 20:33:36.204 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_502 stored as values in memory (estimated size 912.0 B, free 433.4 MiB)\n",
      "10-20 20:33:36.204 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_502_piece0 stored as bytes in memory (estimated size 157.0 B, free 433.4 MiB)\n",
      "10-20 20:33:36.205 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_502_piece0 in memory on 5b5a8eb7561c:44751 (size: 157.0 B, free: 434.2 MiB)\n",
      "10-20 20:33:36.215 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 502 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:36.243 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:36.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 240 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:36.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 272 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:36.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:36.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:36.245 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 272 (MapPartitionsRDD[455] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:36.247 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_503 stored as values in memory (estimated size 132.0 KiB, free 433.3 MiB)\n",
      "10-20 20:33:36.248 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_503_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 433.3 MiB)\n",
      "10-20 20:33:36.248 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_503_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:36.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 503 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:36.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[455] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:36.250 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 272.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:36.250 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 272.0 (TID 268) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:36.251 172.17.0.2:54321      18300   (TID 268)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 272.0 (TID 268)\n",
      "10-20 20:33:36.264 172.17.0.2:54321      18300   (TID 268)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:36.313 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_500_piece0 on 5b5a8eb7561c:44751 in memory (size: 41.9 KiB, free: 434.2 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:33:36.945 172.17.0.2:54321      18300   (TID 268)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_454_0 stored as values in memory (estimated size 3.6 MiB, free 429.8 MiB)\n",
      "10-20 20:33:36.945 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_454_0 in memory on 5b5a8eb7561c:44751 (size: 3.6 MiB, free: 430.6 MiB)\n",
      "10-20 20:33:36.970 172.17.0.2:54321      18300   (TID 268)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 272.0 (TID 268). 3630 bytes result sent to driver\n",
      "10-20 20:33:36.970 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 272.0 (TID 268) in 720 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:36.971 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:36.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 272 (treeAggregate at RDDLossFunction.scala:61) finished in 0.726 s\n",
      "10-20 20:33:36.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 240 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:36.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 272: Stage finished\n",
      "10-20 20:33:36.971 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 240 finished: treeAggregate at RDDLossFunction.scala:61, took 0.728474 s\n",
      "10-20 20:33:36.972 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(502) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:36.972 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_502_piece0 on 5b5a8eb7561c:44751 in memory (size: 157.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:36.978 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_504 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:36.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_504_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:36.979 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_504_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:36.980 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 504 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:36.997 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:36.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 241 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:36.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 273 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:36.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:36.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:36.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 273 (MapPartitionsRDD[456] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.001 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_505 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:37.002 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_505_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:37.002 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_505_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 505 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 273 (MapPartitionsRDD[456] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 273.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.004 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 273.0 (TID 269) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.005 172.17.0.2:54321      18300   (TID 269)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 273.0 (TID 269)\n",
      "10-20 20:33:37.010 172.17.0.2:54321      18300   (TID 269)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.034 172.17.0.2:54321      18300   (TID 269)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 273.0 (TID 269). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.035 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 273.0 (TID 269) in 31 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.035 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 273 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:33:37.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 241 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 273: Stage finished\n",
      "10-20 20:33:37.036 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 241 finished: treeAggregate at RDDLossFunction.scala:61, took 0.038749 s\n",
      "10-20 20:33:37.037 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(504) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.038 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_504_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.040 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_506 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.050 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_505_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.051 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_503_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.7 MiB)\n",
      "10-20 20:33:37.053 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_506_piece0 stored as bytes in memory (estimated size 994.0 B, free 430.0 MiB)\n",
      "10-20 20:33:37.053 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_506_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.7 MiB)\n",
      "10-20 20:33:37.056 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 506 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.074 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.075 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 242 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.075 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 274 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.075 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.075 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.076 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 274 (MapPartitionsRDD[457] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.079 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_507 stored as values in memory (estimated size 132.0 KiB, free 429.8 MiB)\n",
      "10-20 20:33:37.080 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_507_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.8 MiB)\n",
      "10-20 20:33:37.081 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_507_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.081 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 507 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 274 (MapPartitionsRDD[457] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.082 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 274.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.082 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 274.0 (TID 270) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.083 172.17.0.2:54321      18300   (TID 270)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 274.0 (TID 270)\n",
      "10-20 20:33:37.091 172.17.0.2:54321      18300   (TID 270)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.107 172.17.0.2:54321      18300   (TID 270)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 274.0 (TID 270). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.108 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 274.0 (TID 270) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.108 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.109 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 274 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:33:37.109 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 242 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.109 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 274: Stage finished\n",
      "10-20 20:33:37.109 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 242 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034179 s\n",
      "10-20 20:33:37.109 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(506) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.111 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.5936348549535222 fval: 0.47695672984310117 rhs: 0.5524221525966474 cdd: -0.013812036425934777\n",
      "10-20 20:33:37.111 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.5936\n",
      "10-20 20:33:37.111 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.476957 (rel: 0.137) 0.770287\n",
      "10-20 20:33:37.112 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_506_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.112 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_508 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:37.113 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_508_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:37.113 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_508_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.114 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 508 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.133 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.134 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 243 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.134 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 275 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.134 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.135 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.135 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 275 (MapPartitionsRDD[458] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.137 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_509 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:37.138 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_509_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:37.138 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_509_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.139 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 509 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.139 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 275 (MapPartitionsRDD[458] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.139 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 275.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.140 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 275.0 (TID 271) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.141 172.17.0.2:54321      18300   (TID 271)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 275.0 (TID 271)\n",
      "10-20 20:33:37.147 172.17.0.2:54321      18300   (TID 271)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.157 172.17.0.2:54321      18300   (TID 271)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 275.0 (TID 271). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.158 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 275.0 (TID 271) in 18 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.158 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 275 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:33:37.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 243 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 275: Stage finished\n",
      "10-20 20:33:37.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 243 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030518 s\n",
      "10-20 20:33:37.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(508) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.165 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.165 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.401910 (rel: 0.157) 0.337960\n",
      "10-20 20:33:37.165 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_508_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.165 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_510 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.166 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_510_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.166 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_510_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.167 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 510 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.187 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 244 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 276 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 276 (MapPartitionsRDD[459] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.194 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_511 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:37.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_511_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:37.200 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_511_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 511 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 276 (MapPartitionsRDD[459] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 276.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.203 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 276.0 (TID 272) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.203 172.17.0.2:54321      18300   (TID 272)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 276.0 (TID 272)\n",
      "10-20 20:33:37.210 172.17.0.2:54321      18300   (TID 272)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.219 172.17.0.2:54321      18300   (TID 272)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 276.0 (TID 272). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.220 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 276.0 (TID 272) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.220 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.220 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 276 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:33:37.220 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 244 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.220 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 276: Stage finished\n",
      "10-20 20:33:37.221 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 244 finished: treeAggregate at RDDLossFunction.scala:61, took 0.033411 s\n",
      "10-20 20:33:37.221 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(510) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.221 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.221 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.373688 (rel: 0.0702) 0.156422\n",
      "10-20 20:33:37.222 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_510_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.222 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_512 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:37.222 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_512_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:37.223 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_512_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.223 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 512 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.245 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.245 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 245 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.246 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 277 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.246 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.246 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.246 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 277 (MapPartitionsRDD[460] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.294 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_513 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:37.296 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_513_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:37.297 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_513_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.298 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 513 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 277 (MapPartitionsRDD[460] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.299 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 277.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.300 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 277.0 (TID 273) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.300 172.17.0.2:54321      18300   (TID 273)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 277.0 (TID 273)\n",
      "10-20 20:33:37.307 172.17.0.2:54321      18300   (TID 273)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.314 172.17.0.2:54321      18300   (TID 273)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 277.0 (TID 273). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.315 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 277.0 (TID 273) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.315 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 277.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 277 (treeAggregate at RDDLossFunction.scala:61) finished in 0.068 s\n",
      "10-20 20:33:37.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 245 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 277: Stage finished\n",
      "10-20 20:33:37.315 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 245 finished: treeAggregate at RDDLossFunction.scala:61, took 0.070240 s\n",
      "10-20 20:33:37.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(512) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.316 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.317 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_512_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.317 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.358615 (rel: 0.0403) 0.0832949\n",
      "10-20 20:33:37.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_514 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:37.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_514_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:37.318 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_514_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.319 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 514 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.338 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 246 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 278 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.339 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[461] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_515 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:37.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_515_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:37.343 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_515_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.344 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 515 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.344 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 278 (MapPartitionsRDD[461] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.344 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 278.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.345 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 278.0 (TID 274) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.346 172.17.0.2:54321      18300   (TID 274)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 278.0 (TID 274)\n",
      "10-20 20:33:37.351 172.17.0.2:54321      18300   (TID 274)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.359 172.17.0.2:54321      18300   (TID 274)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 278.0 (TID 274). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.360 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 278.0 (TID 274) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.360 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 278 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:33:37.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 246 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished\n",
      "10-20 20:33:37.361 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 246 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023077 s\n",
      "10-20 20:33:37.362 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(514) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.362 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.363 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_514_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.363 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.348066 (rel: 0.0294) 0.0666240\n",
      "10-20 20:33:37.363 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_516 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:37.364 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_516_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:37.364 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_516_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.364 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 516 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.382 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 247 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 279 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.382 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.383 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 279 (MapPartitionsRDD[462] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.386 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_517 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:37.387 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_517_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:37.387 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_517_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.387 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 517 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.387 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 279 (MapPartitionsRDD[462] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.388 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 279.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.388 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 279.0 (TID 275) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.389 172.17.0.2:54321      18300   (TID 275)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 279.0 (TID 275)\n",
      "10-20 20:33:37.393 172.17.0.2:54321      18300   (TID 275)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.399 172.17.0.2:54321      18300   (TID 275)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 279.0 (TID 275). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.400 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 279.0 (TID 275) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.400 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 279.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 279 (treeAggregate at RDDLossFunction.scala:61) finished in 0.016 s\n",
      "10-20 20:33:37.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 247 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 279: Stage finished\n",
      "10-20 20:33:37.400 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 247 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018534 s\n",
      "10-20 20:33:37.401 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(516) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.401 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.401 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.338392 (rel: 0.0278) 0.0544734\n",
      "10-20 20:33:37.401 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_518 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:37.402 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_518_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:37.402 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_518_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.403 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 518 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.404 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_516_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.410 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.410 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 248 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.410 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 280 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.410 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.411 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.411 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 280 (MapPartitionsRDD[463] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_519 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:37.422 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_519_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:37.423 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_519_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.423 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 519 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.423 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 280 (MapPartitionsRDD[463] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.423 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 280.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.424 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 280.0 (TID 276) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.424 172.17.0.2:54321      18300   (TID 276)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 280.0 (TID 276)\n",
      "10-20 20:33:37.425 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_509_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.426 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_515_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.427 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_513_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.428 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_507_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.429 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_517_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.430 172.17.0.2:54321      18300   (TID 276)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.430 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_511_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.436 172.17.0.2:54321      18300   (TID 276)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 280.0 (TID 276). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.437 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 280.0 (TID 276) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.437 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 280.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 280 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:33:37.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 248 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 280: Stage finished\n",
      "10-20 20:33:37.438 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 248 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028107 s\n",
      "10-20 20:33:37.438 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(518) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.439 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.439 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_518_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.439 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.327641 (rel: 0.0318) 0.0448982\n",
      "10-20 20:33:37.439 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_520 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:37.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_520_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:37.440 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_520_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 520 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.446 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 249 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 281 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 281 (MapPartitionsRDD[464] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_521 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:37.452 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_521_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:37.453 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_521_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 521 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 281 (MapPartitionsRDD[464] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 281.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.454 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 281.0 (TID 277) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.455 172.17.0.2:54321      18300   (TID 277)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 281.0 (TID 277)\n",
      "10-20 20:33:37.460 172.17.0.2:54321      18300   (TID 277)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.466 172.17.0.2:54321      18300   (TID 277)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 281.0 (TID 277). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.467 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 281.0 (TID 277) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.467 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 281 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:33:37.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 249 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 281: Stage finished\n",
      "10-20 20:33:37.468 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 249 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022249 s\n",
      "10-20 20:33:37.469 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(520) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.470 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.470 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_520_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.470 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.320042 (rel: 0.0232) 0.0456070\n",
      "10-20 20:33:37.470 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_522 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.471 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_522_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.471 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_522_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.472 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 522 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.478 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 250 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 282 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.479 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.479 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 282 (MapPartitionsRDD[465] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.481 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_523 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:37.482 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_523_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:37.482 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_523_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 523 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (MapPartitionsRDD[465] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.483 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 282.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.484 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 282.0 (TID 278) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.484 172.17.0.2:54321      18300   (TID 278)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 282.0 (TID 278)\n",
      "10-20 20:33:37.490 172.17.0.2:54321      18300   (TID 278)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.497 172.17.0.2:54321      18300   (TID 278)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 282.0 (TID 278). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.497 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 282.0 (TID 278) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.497 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 282 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:37.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 250 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 282: Stage finished\n",
      "10-20 20:33:37.498 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 250 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019585 s\n",
      "10-20 20:33:37.498 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(522) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.499 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.499 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.317226 (rel: 0.00880) 0.0386862\n",
      "10-20 20:33:37.499 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_524 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:37.499 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_522_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.500 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_524_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:37.500 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_524_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.501 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 524 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.507 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 251 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 283 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.507 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.508 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 283 (MapPartitionsRDD[466] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.511 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_525 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:37.512 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_525_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:37.512 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_525_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.512 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 525 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 283 (MapPartitionsRDD[466] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.513 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 283.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.514 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 283.0 (TID 279) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.514 172.17.0.2:54321      18300   (TID 279)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 283.0 (TID 279)\n",
      "10-20 20:33:37.519 172.17.0.2:54321      18300   (TID 279)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.525 172.17.0.2:54321      18300   (TID 279)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 283.0 (TID 279). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.525 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 283.0 (TID 279) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.525 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.526 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 283 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:37.526 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 251 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.526 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 283: Stage finished\n",
      "10-20 20:33:37.526 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 251 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019251 s\n",
      "10-20 20:33:37.526 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(524) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.527 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_524_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.527 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.528 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.315499 (rel: 0.00544) 0.0234626\n",
      "10-20 20:33:37.528 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_526 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:37.529 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_526_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:37.529 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_526_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.530 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 526 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.535 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 252 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 284 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.536 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.537 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 284 (MapPartitionsRDD[467] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_527 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:37.540 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_527_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:37.540 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_527_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 527 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 284 (MapPartitionsRDD[467] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 284.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.543 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 284.0 (TID 280) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.543 172.17.0.2:54321      18300   (TID 280)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 284.0 (TID 280)\n",
      "10-20 20:33:37.548 172.17.0.2:54321      18300   (TID 280)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.555 172.17.0.2:54321      18300   (TID 280)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 284.0 (TID 280). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.556 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 284.0 (TID 280) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.556 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 284.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 284 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:33:37.558 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 252 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.558 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 284: Stage finished\n",
      "10-20 20:33:37.558 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 252 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022502 s\n",
      "10-20 20:33:37.559 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(526) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.560 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_526_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.560 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.560 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.314389 (rel: 0.00352) 0.0108680\n",
      "10-20 20:33:37.561 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_528 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:37.562 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_528_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:37.562 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_528_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.562 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 528 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.568 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 253 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 285 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 285 (MapPartitionsRDD[468] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.574 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_529 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:37.575 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_529_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:37.576 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_529_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 529 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 285 (MapPartitionsRDD[468] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.577 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 285.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.577 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 285.0 (TID 281) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.578 172.17.0.2:54321      18300   (TID 281)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 285.0 (TID 281)\n",
      "10-20 20:33:37.604 172.17.0.2:54321      18300   (TID 281)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.612 172.17.0.2:54321      18300   (TID 281)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 285.0 (TID 281). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.613 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 285.0 (TID 281) in 36 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.613 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 285.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 285 (treeAggregate at RDDLossFunction.scala:61) finished in 0.043 s\n",
      "10-20 20:33:37.615 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 253 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.615 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 285: Stage finished\n",
      "10-20 20:33:37.616 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 253 finished: treeAggregate at RDDLossFunction.scala:61, took 0.047413 s\n",
      "10-20 20:33:37.617 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(528) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.617 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.617 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_528_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.617 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.314108 (rel: 0.000892) 0.0566904\n",
      "10-20 20:33:37.618 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_530 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:37.619 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_530_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:37.620 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_530_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.620 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 530 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 254 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 286 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 286 (MapPartitionsRDD[469] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.631 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_531 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:37.632 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_531_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:37.632 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_531_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 531 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 286 (MapPartitionsRDD[469] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 286.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.634 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 286.0 (TID 282) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.634 172.17.0.2:54321      18300   (TID 282)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 286.0 (TID 282)\n",
      "10-20 20:33:37.640 172.17.0.2:54321      18300   (TID 282)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.647 172.17.0.2:54321      18300   (TID 282)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 286.0 (TID 282). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.648 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 286.0 (TID 282) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.648 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 286.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 286 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:33:37.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 254 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 286: Stage finished\n",
      "10-20 20:33:37.650 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 254 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022770 s\n",
      "10-20 20:33:37.650 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(530) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.651 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.651 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_530_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.651 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.313579 (rel: 0.00168) 0.0169388\n",
      "10-20 20:33:37.652 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_532 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:37.653 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_532_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:37.653 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_532_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.654 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 532 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.663 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 255 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 287 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.668 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 287 (MapPartitionsRDD[470] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_533 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:37.672 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_533_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:37.672 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_533_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:37.673 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 533 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.673 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 287 (MapPartitionsRDD[470] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.673 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 287.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.673 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 287.0 (TID 283) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.674 172.17.0.2:54321      18300   (TID 283)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 287.0 (TID 283)\n",
      "10-20 20:33:37.684 172.17.0.2:54321      18300   (TID 283)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.693 172.17.0.2:54321      18300   (TID 283)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 287.0 (TID 283). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.694 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 287.0 (TID 283) in 21 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.694 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 287.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 287 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:33:37.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 255 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.694 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 287: Stage finished\n",
      "10-20 20:33:37.695 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 255 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031385 s\n",
      "10-20 20:33:37.697 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(532) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.698 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_532_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:37.699 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.699 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.313411 (rel: 0.000536) 0.0105420\n",
      "10-20 20:33:37.701 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_534 stored as values in memory (estimated size 912.0 B, free 428.6 MiB)\n",
      "10-20 20:33:37.702 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_534_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.6 MiB)\n",
      "10-20 20:33:37.703 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_534_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:37.703 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 534 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.711 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 256 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 288 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 288 (MapPartitionsRDD[471] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.714 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_535 stored as values in memory (estimated size 132.0 KiB, free 428.5 MiB)\n",
      "10-20 20:33:37.715 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_535_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.4 MiB)\n",
      "10-20 20:33:37.715 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_535_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:37.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 535 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 288 (MapPartitionsRDD[471] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.716 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 288.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.716 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 288.0 (TID 284) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.717 172.17.0.2:54321      18300   (TID 284)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 288.0 (TID 284)\n",
      "10-20 20:33:37.725 172.17.0.2:54321      18300   (TID 284)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.733 172.17.0.2:54321      18300   (TID 284)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 288.0 (TID 284). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.733 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 288.0 (TID 284) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.733 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 288.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 288 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:33:37.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 256 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 288: Stage finished\n",
      "10-20 20:33:37.734 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 256 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023368 s\n",
      "10-20 20:33:37.735 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(534) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.735 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.735 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.313194 (rel: 0.000693) 0.00754761\n",
      "10-20 20:33:37.735 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_534_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:37.736 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_536 stored as values in memory (estimated size 912.0 B, free 428.4 MiB)\n",
      "10-20 20:33:37.749 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_536_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.4 MiB)\n",
      "10-20 20:33:37.749 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_536_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:37.750 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 536 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.764 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 257 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 289 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.764 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_525_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:37.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 289 (MapPartitionsRDD[472] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.766 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_531_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.770 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_537 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:37.770 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_527_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.771 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_537_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:37.771 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_537_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 537 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.772 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_523_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 289 (MapPartitionsRDD[472] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 289.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.773 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_519_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.773 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 289.0 (TID 285) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.774 172.17.0.2:54321      18300   (TID 285)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 289.0 (TID 285)\n",
      "10-20 20:33:37.775 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_529_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.776 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_535_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.778 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_533_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.779 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_521_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.782 172.17.0.2:54321      18300   (TID 285)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.789 172.17.0.2:54321      18300   (TID 285)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 289.0 (TID 285). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.789 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 289.0 (TID 285) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.789 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 289.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.790 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 289 (treeAggregate at RDDLossFunction.scala:61) finished in 0.025 s\n",
      "10-20 20:33:37.790 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 257 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.790 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 289: Stage finished\n",
      "10-20 20:33:37.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 257 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026097 s\n",
      "10-20 20:33:37.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(536) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.791 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.791 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312974 (rel: 0.000702) 0.00813499\n",
      "10-20 20:33:37.792 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_536_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.792 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_538 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:37.793 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_538_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:37.793 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_538_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.794 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 538 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.800 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.801 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 258 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.801 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 290 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.801 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.802 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.802 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 290 (MapPartitionsRDD[473] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.805 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_539 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:37.806 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_539_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:37.806 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_539_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:37.806 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 539 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.807 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 290 (MapPartitionsRDD[473] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.807 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 290.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.808 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 290.0 (TID 286) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.808 172.17.0.2:54321      18300   (TID 286)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 290.0 (TID 286)\n",
      "10-20 20:33:37.813 172.17.0.2:54321      18300   (TID 286)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.820 172.17.0.2:54321      18300   (TID 286)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 290.0 (TID 286). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.820 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 290.0 (TID 286) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 290 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:37.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 258 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.821 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 290.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 290: Stage finished\n",
      "10-20 20:33:37.821 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 258 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020725 s\n",
      "10-20 20:33:37.821 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(538) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.822 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.822 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312695 (rel: 0.000893) 0.00936897\n",
      "10-20 20:33:37.822 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_540 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.823 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_540_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:37.823 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_538_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.823 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_540_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:37.824 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 540 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.829 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 259 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 291 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 291 (MapPartitionsRDD[474] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.833 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_541 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:37.834 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_541_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:37.834 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_541_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.834 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 541 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 291 (MapPartitionsRDD[474] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 291.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.835 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 291.0 (TID 287) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.835 172.17.0.2:54321      18300   (TID 287)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 291.0 (TID 287)\n",
      "10-20 20:33:37.840 172.17.0.2:54321      18300   (TID 287)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.848 172.17.0.2:54321      18300   (TID 287)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 291.0 (TID 287). 3587 bytes result sent to driver\n",
      "10-20 20:33:37.849 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 291.0 (TID 287) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.849 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 291.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 291 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:37.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 259 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 291: Stage finished\n",
      "10-20 20:33:37.850 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 259 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020761 s\n",
      "10-20 20:33:37.850 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(540) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.851 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_540_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.851 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_542 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:37.852 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_542_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:37.852 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_542_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.852 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 542 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.858 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 260 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 292 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.858 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.859 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.859 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 292 (MapPartitionsRDD[475] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.861 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_543 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:37.862 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_543_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:37.862 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_543_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 543 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 292 (MapPartitionsRDD[475] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.863 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 292.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.863 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 292.0 (TID 288) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.864 172.17.0.2:54321      18300   (TID 288)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 292.0 (TID 288)\n",
      "10-20 20:33:37.869 172.17.0.2:54321      18300   (TID 288)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.875 172.17.0.2:54321      18300   (TID 288)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 292.0 (TID 288). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.876 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 292.0 (TID 288) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.876 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 292.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.876 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 292 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:33:37.876 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 260 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.876 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 292: Stage finished\n",
      "10-20 20:33:37.876 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 260 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018402 s\n",
      "10-20 20:33:37.877 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(542) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.877 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.4462132500068844 fval: 0.31243378409005146 rhs: 0.3126947208671463 cdd: 1.7248721631543998E-7\n",
      "10-20 20:33:37.877 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.4462\n",
      "10-20 20:33:37.877 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312434 (rel: 0.000835) 0.00984590\n",
      "10-20 20:33:37.878 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_544 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:37.878 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_544_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:37.878 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_544_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.879 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 544 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.885 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.885 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 261 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.885 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 293 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.885 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.886 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.886 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 293 (MapPartitionsRDD[476] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.887 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_542_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_545 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:37.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_545_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:37.889 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_545_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:37.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 545 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 293 (MapPartitionsRDD[476] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 293.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.890 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 293.0 (TID 289) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.891 172.17.0.2:54321      18300   (TID 289)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 293.0 (TID 289)\n",
      "10-20 20:33:37.896 172.17.0.2:54321      18300   (TID 289)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.903 172.17.0.2:54321      18300   (TID 289)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 293.0 (TID 289). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.904 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 293.0 (TID 289) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.904 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 293.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 293 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:37.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 261 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 293: Stage finished\n",
      "10-20 20:33:37.904 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 261 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019372 s\n",
      "10-20 20:33:37.905 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(544) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.905 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.905 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312269 (rel: 0.000528) 0.00444061\n",
      "10-20 20:33:37.905 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_546 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:37.906 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_546_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:37.906 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_544_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.906 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_546_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:37.907 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 546 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.912 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 262 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 294 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 294 (MapPartitionsRDD[477] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:37.916 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_547 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:37.917 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_547_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:37.917 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_547_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:37.917 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 547 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:37.917 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 294 (MapPartitionsRDD[477] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:37.917 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 294.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:37.918 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 294.0 (TID 290) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:37.918 172.17.0.2:54321      18300   (TID 290)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 294.0 (TID 290)\n",
      "10-20 20:33:37.924 172.17.0.2:54321      18300   (TID 290)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:37.982 172.17.0.2:54321      18300   (TID 290)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 294.0 (TID 290). 3544 bytes result sent to driver\n",
      "10-20 20:33:37.983 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 294.0 (TID 290) in 65 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:37.983 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 294.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:37.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 294 (treeAggregate at RDDLossFunction.scala:61) finished in 0.071 s\n",
      "10-20 20:33:37.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 262 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:37.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 294: Stage finished\n",
      "10-20 20:33:37.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 262 finished: treeAggregate at RDDLossFunction.scala:61, took 0.072264 s\n",
      "10-20 20:33:37.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(546) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:37.985 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:37.985 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312145 (rel: 0.000396) 0.00434845\n",
      "10-20 20:33:37.986 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_548 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:37.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_548_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:37.987 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_548_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.988 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 548 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:37.996 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_546_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:37.996 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:37.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 263 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:37.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 295 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:37.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:37.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:37.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 295 (MapPartitionsRDD[478] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_549 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:38.001 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_549_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:38.001 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_549_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.002 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 549 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 295 (MapPartitionsRDD[478] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 295.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.004 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 295.0 (TID 291) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.005 172.17.0.2:54321      18300   (TID 291)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 295.0 (TID 291)\n",
      "10-20 20:33:38.011 172.17.0.2:54321      18300   (TID 291)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.023 172.17.0.2:54321      18300   (TID 291)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 295.0 (TID 291). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 295.0 (TID 291) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 295.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 295 (treeAggregate at RDDLossFunction.scala:61) finished in 0.026 s\n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 263 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 295: Stage finished\n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 263 finished: treeAggregate at RDDLossFunction.scala:61, took 0.028328 s\n",
      "10-20 20:33:38.024 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(548) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.025 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.025 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312104 (rel: 0.000131) 0.00299474\n",
      "10-20 20:33:38.026 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_550 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:38.026 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_550_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:38.026 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_548_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.027 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_550_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 550 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.035 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 264 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 296 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 296 (MapPartitionsRDD[479] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_551 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:38.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_551_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:38.041 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_551_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:38.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 551 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.042 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 296 (MapPartitionsRDD[479] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.042 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 296.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.043 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 296.0 (TID 292) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.043 172.17.0.2:54321      18300   (TID 292)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 296.0 (TID 292)\n",
      "10-20 20:33:38.051 172.17.0.2:54321      18300   (TID 292)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.058 172.17.0.2:54321      18300   (TID 292)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 296.0 (TID 292). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.059 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 296.0 (TID 292) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.059 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 296.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 296 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:33:38.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 264 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 296: Stage finished\n",
      "10-20 20:33:38.059 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 264 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024548 s\n",
      "10-20 20:33:38.060 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(550) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.060 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.060 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312059 (rel: 0.000144) 0.00147855\n",
      "10-20 20:33:38.060 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_550_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:38.061 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_552 stored as values in memory (estimated size 912.0 B, free 428.6 MiB)\n",
      "10-20 20:33:38.061 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_552_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.6 MiB)\n",
      "10-20 20:33:38.061 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_552_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:38.062 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 552 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.067 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 265 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 297 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.068 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 297 (MapPartitionsRDD[480] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.072 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_553 stored as values in memory (estimated size 132.0 KiB, free 428.5 MiB)\n",
      "10-20 20:33:38.076 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_553_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.4 MiB)\n",
      "10-20 20:33:38.076 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_553_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:38.076 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 553 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 297 (MapPartitionsRDD[480] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 297.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.078 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 297.0 (TID 293) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.079 172.17.0.2:54321      18300   (TID 293)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 297.0 (TID 293)\n",
      "10-20 20:33:38.084 172.17.0.2:54321      18300   (TID 293)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.109 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_545_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:38.112 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_539_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.113 172.17.0.2:54321      18300   (TID 293)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 297.0 (TID 293). 3587 bytes result sent to driver\n",
      "10-20 20:33:38.113 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_543_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.114 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 297.0 (TID 293) in 36 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.114 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 297.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.114 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 297 (treeAggregate at RDDLossFunction.scala:61) finished in 0.045 s\n",
      "10-20 20:33:38.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 265 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.115 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 297: Stage finished\n",
      "10-20 20:33:38.115 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 265 finished: treeAggregate at RDDLossFunction.scala:61, took 0.047307 s\n",
      "10-20 20:33:38.115 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(552) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.115 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.115 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312048 (rel: 3.78e-05) 0.00522212\n",
      "10-20 20:33:38.116 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_554 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:38.116 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_554_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:38.117 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_547_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.117 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_552_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.117 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_554_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.117 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 554 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.122 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_541_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.123 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_537_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.124 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_551_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.125 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 266 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 298 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.127 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.127 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 298 (MapPartitionsRDD[481] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.130 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_555 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.131 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_555_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.132 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_555_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 555 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.132 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_549_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 298 (MapPartitionsRDD[481] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.132 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 298.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.133 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 298.0 (TID 294) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.133 172.17.0.2:54321      18300   (TID 294)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 298.0 (TID 294)\n",
      "10-20 20:33:38.139 172.17.0.2:54321      18300   (TID 294)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.146 172.17.0.2:54321      18300   (TID 294)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 298.0 (TID 294). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.147 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 298.0 (TID 294) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.147 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 298.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.147 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 298 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:33:38.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 266 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.148 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 298: Stage finished\n",
      "10-20 20:33:38.148 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 266 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022801 s\n",
      "10-20 20:33:38.148 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(554) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.148 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_556 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.149 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_556_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.149 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_554_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.150 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_556_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.150 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 556 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.157 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 267 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 299 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.160 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 299 (MapPartitionsRDD[482] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.162 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_557 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.176 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_557_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.176 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_557_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.177 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 557 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.177 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 299 (MapPartitionsRDD[482] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.177 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 299.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.178 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_553_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.178 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 299.0 (TID 295) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.180 172.17.0.2:54321      18300   (TID 295)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 299.0 (TID 295)\n",
      "10-20 20:33:38.181 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_555_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.190 172.17.0.2:54321      18300   (TID 295)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.208 172.17.0.2:54321      18300   (TID 295)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 299.0 (TID 295). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.209 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 299.0 (TID 295) in 31 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.209 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 299.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 299 (treeAggregate at RDDLossFunction.scala:61) finished in 0.049 s\n",
      "10-20 20:33:38.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 267 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 299: Stage finished\n",
      "10-20 20:33:38.210 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 267 finished: treeAggregate at RDDLossFunction.scala:61, took 0.051341 s\n",
      "10-20 20:33:38.210 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(556) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.211 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.3109396273324573 fval: 0.3120438485785902 rhs: 0.31204750955915406 cdd: -1.1512160588342179E-10\n",
      "10-20 20:33:38.211 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.3109\n",
      "10-20 20:33:38.211 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312044 (rel: 1.17e-05) 0.00212608\n",
      "10-20 20:33:38.211 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_556_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.212 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_558 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.212 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_558_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.213 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_558_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.214 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 558 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.221 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 268 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 300 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.221 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.222 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 300 (MapPartitionsRDD[483] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.225 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_559 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:38.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_559_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:38.226 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_559_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.226 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 559 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 300 (MapPartitionsRDD[483] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.227 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 300.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.227 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 300.0 (TID 296) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.228 172.17.0.2:54321      18300   (TID 296)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 300.0 (TID 296)\n",
      "10-20 20:33:38.235 172.17.0.2:54321      18300   (TID 296)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.243 172.17.0.2:54321      18300   (TID 296)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 300.0 (TID 296). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.244 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 300.0 (TID 296) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.244 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 300.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.244 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 300 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:33:38.245 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 268 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.245 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 300: Stage finished\n",
      "10-20 20:33:38.245 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 268 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024070 s\n",
      "10-20 20:33:38.245 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(558) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.245 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.245 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312039 (rel: 1.60e-05) 0.00195831\n",
      "10-20 20:33:38.246 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_558_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.246 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_560 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.247 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_560_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.247 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_560_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.248 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 560 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.254 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 269 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 301 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 301 (MapPartitionsRDD[484] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_561 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.260 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_561_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.260 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_561_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.260 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 561 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.261 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 301 (MapPartitionsRDD[484] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.261 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 301.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.262 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 301.0 (TID 297) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.262 172.17.0.2:54321      18300   (TID 297)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 301.0 (TID 297)\n",
      "10-20 20:33:38.269 172.17.0.2:54321      18300   (TID 297)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.278 172.17.0.2:54321      18300   (TID 297)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 301.0 (TID 297). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.278 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 301.0 (TID 297) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.279 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 301.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 301 (treeAggregate at RDDLossFunction.scala:61) finished in 0.024 s\n",
      "10-20 20:33:38.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 269 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 301: Stage finished\n",
      "10-20 20:33:38.280 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 269 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025770 s\n",
      "10-20 20:33:38.281 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(560) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.282 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_560_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.282 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.282 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.312019 (rel: 6.25e-05) 0.00160476\n",
      "10-20 20:33:38.284 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_562 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:38.284 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_562_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:38.285 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_562_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.285 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 562 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.291 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 270 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 302 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.292 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 302 (MapPartitionsRDD[485] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_563 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_563_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.296 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_563_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.296 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 563 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 302 (MapPartitionsRDD[485] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.297 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 302.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.297 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 302.0 (TID 298) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.297 172.17.0.2:54321      18300   (TID 298)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 302.0 (TID 298)\n",
      "10-20 20:33:38.303 172.17.0.2:54321      18300   (TID 298)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.309 172.17.0.2:54321      18300   (TID 298)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 302.0 (TID 298). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.310 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 302.0 (TID 298) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.310 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 302.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.310 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 302 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:38.311 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 270 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.311 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 302: Stage finished\n",
      "10-20 20:33:38.311 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 270 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019086 s\n",
      "10-20 20:33:38.311 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(562) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.312 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_562_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.312 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.312 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311995 (rel: 7.66e-05) 0.00237628\n",
      "10-20 20:33:38.314 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_564 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:38.315 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_564_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:38.315 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_564_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.316 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 564 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.321 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.322 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 271 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.322 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 303 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.322 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.323 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.323 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 303 (MapPartitionsRDD[486] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.327 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_565 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:38.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_565_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:38.328 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_565_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 565 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 303 (MapPartitionsRDD[486] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 303.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.331 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 303.0 (TID 299) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.332 172.17.0.2:54321      18300   (TID 299)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 303.0 (TID 299)\n",
      "10-20 20:33:38.337 172.17.0.2:54321      18300   (TID 299)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.344 172.17.0.2:54321      18300   (TID 299)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 303.0 (TID 299). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.345 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 303.0 (TID 299) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.345 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 303.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 303 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:33:38.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 271 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.345 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 303: Stage finished\n",
      "10-20 20:33:38.346 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 271 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023983 s\n",
      "10-20 20:33:38.346 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(564) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.346 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.347 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_564_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.347 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311969 (rel: 8.32e-05) 0.00282253\n",
      "10-20 20:33:38.348 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_566 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:38.349 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_566_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:38.349 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_566_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.350 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 566 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.357 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 272 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 304 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.357 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.358 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.358 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[487] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_567 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:38.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_567_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:38.361 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_567_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 567 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 304 (MapPartitionsRDD[487] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.362 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 304.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.363 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 304.0 (TID 300) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.363 172.17.0.2:54321      18300   (TID 300)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 304.0 (TID 300)\n",
      "10-20 20:33:38.410 172.17.0.2:54321      18300   (TID 300)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.418 172.17.0.2:54321      18300   (TID 300)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 304.0 (TID 300). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.419 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 304.0 (TID 300) in 56 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.420 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 304 (treeAggregate at RDDLossFunction.scala:61) finished in 0.062 s\n",
      "10-20 20:33:38.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 272 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.420 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished\n",
      "10-20 20:33:38.421 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 272 finished: treeAggregate at RDDLossFunction.scala:61, took 0.064198 s\n",
      "10-20 20:33:38.422 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(566) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.422 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.423 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311948 (rel: 6.96e-05) 0.00167890\n",
      "10-20 20:33:38.423 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_566_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.423 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_568 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:38.424 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_568_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:38.424 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_568_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.424 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 568 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.432 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 273 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 305 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 305 (MapPartitionsRDD[488] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_569 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:38.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_569_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:38.436 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_569_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 569 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 305 (MapPartitionsRDD[488] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.437 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 305.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.438 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 305.0 (TID 301) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.439 172.17.0.2:54321      18300   (TID 301)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 305.0 (TID 301)\n",
      "10-20 20:33:38.443 172.17.0.2:54321      18300   (TID 301)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.450 172.17.0.2:54321      18300   (TID 301)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 305.0 (TID 301). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.450 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 305.0 (TID 301) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.450 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 305 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:33:38.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 273 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 305: Stage finished\n",
      "10-20 20:33:38.455 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 273 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023376 s\n",
      "10-20 20:33:38.455 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(568) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.456 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_568_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.466 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.466 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311925 (rel: 7.32e-05) 0.00147387\n",
      "10-20 20:33:38.466 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_570 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:38.467 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_570_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:38.467 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_570_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.467 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 570 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.473 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 274 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 306 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 306 (MapPartitionsRDD[489] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_571 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:38.477 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_571_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:38.477 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_571_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:38.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 571 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 306 (MapPartitionsRDD[489] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 306.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.479 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 306.0 (TID 302) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.479 172.17.0.2:54321      18300   (TID 302)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 306.0 (TID 302)\n",
      "10-20 20:33:38.484 172.17.0.2:54321      18300   (TID 302)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.490 172.17.0.2:54321      18300   (TID 302)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 306.0 (TID 302). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.491 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 306.0 (TID 302) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.491 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 306 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:33:38.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 274 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 306: Stage finished\n",
      "10-20 20:33:38.492 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 274 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018095 s\n",
      "10-20 20:33:38.492 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(570) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.492 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.493 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311905 (rel: 6.51e-05) 0.00146080\n",
      "10-20 20:33:38.493 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_570_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:38.494 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_572 stored as values in memory (estimated size 912.0 B, free 428.6 MiB)\n",
      "10-20 20:33:38.495 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_572_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.6 MiB)\n",
      "10-20 20:33:38.495 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_572_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:38.495 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 572 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.508 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_565_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.509 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.510 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 275 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.510 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 307 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.510 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.510 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_571_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.511 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.511 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[490] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.512 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_561_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.512 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_567_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.513 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_559_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.514 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_573 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_573_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.515 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_573_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 573 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.515 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_563_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 307 (MapPartitionsRDD[490] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.516 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 307.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.516 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 307.0 (TID 303) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.518 172.17.0.2:54321      18300   (TID 303)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 307.0 (TID 303)\n",
      "10-20 20:33:38.521 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_569_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.522 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_557_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.524 172.17.0.2:54321      18300   (TID 303)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.532 172.17.0.2:54321      18300   (TID 303)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 307.0 (TID 303). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.533 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 307.0 (TID 303) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.533 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.534 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 307 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:33:38.535 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 275 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.535 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 307: Stage finished\n",
      "10-20 20:33:38.536 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 275 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025978 s\n",
      "10-20 20:33:38.536 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(572) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.536 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.536 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311869 (rel: 0.000114) 0.00131306\n",
      "10-20 20:33:38.537 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_572_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.537 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_574 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.547 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_574_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.547 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_574_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.548 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_573_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.7 MiB)\n",
      "10-20 20:33:38.548 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 574 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.554 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.555 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 276 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.555 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 308 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.555 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.555 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.555 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 308 (MapPartitionsRDD[491] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.558 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_575 stored as values in memory (estimated size 132.0 KiB, free 429.8 MiB)\n",
      "10-20 20:33:38.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_575_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.8 MiB)\n",
      "10-20 20:33:38.559 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_575_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 575 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 308 (MapPartitionsRDD[491] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 308.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.561 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 308.0 (TID 304) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.562 172.17.0.2:54321      18300   (TID 304)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 308.0 (TID 304)\n",
      "10-20 20:33:38.567 172.17.0.2:54321      18300   (TID 304)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.574 172.17.0.2:54321      18300   (TID 304)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 308.0 (TID 304). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.574 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 308.0 (TID 304) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.574 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.575 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 308 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:38.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 276 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.576 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 308: Stage finished\n",
      "10-20 20:33:38.576 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 276 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021676 s\n",
      "10-20 20:33:38.576 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(574) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.577 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_576 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.577 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_576_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.578 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_574_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.578 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_576_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.578 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 576 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.583 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.587 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 277 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.587 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 309 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.587 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.587 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.588 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[492] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.591 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_577 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:38.592 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_577_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:38.593 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_577_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 577 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 309 (MapPartitionsRDD[492] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 309.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.594 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 309.0 (TID 305) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.594 172.17.0.2:54321      18300   (TID 305)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 309.0 (TID 305)\n",
      "10-20 20:33:38.600 172.17.0.2:54321      18300   (TID 305)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.607 172.17.0.2:54321      18300   (TID 305)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 309.0 (TID 305). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.607 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 309.0 (TID 305) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.607 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 309 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:33:38.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 277 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 309: Stage finished\n",
      "10-20 20:33:38.608 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 277 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024543 s\n",
      "10-20 20:33:38.609 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(576) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.609 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.2799362302152625 fval: 0.31185914144322985 rhs: 0.31186899252456995 cdd: 2.5898604462464377E-8\n",
      "10-20 20:33:38.609 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.2799\n",
      "10-20 20:33:38.609 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_576_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.609 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311859 (rel: 3.16e-05) 0.00170161\n",
      "10-20 20:33:38.610 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_578 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.610 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_578_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.611 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_578_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.616 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 578 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.623 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.623 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 278 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.623 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 310 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.623 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.624 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.624 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 310 (MapPartitionsRDD[493] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_579 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_579_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:38.627 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_579_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 579 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 310 (MapPartitionsRDD[493] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.628 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 310.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.629 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 310.0 (TID 306) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.629 172.17.0.2:54321      18300   (TID 306)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 310.0 (TID 306)\n",
      "10-20 20:33:38.634 172.17.0.2:54321      18300   (TID 306)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.640 172.17.0.2:54321      18300   (TID 306)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 310.0 (TID 306). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.641 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 310.0 (TID 306) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.641 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 310.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 310 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:33:38.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 278 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 310: Stage finished\n",
      "10-20 20:33:38.642 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 278 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019114 s\n",
      "10-20 20:33:38.642 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(578) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.643 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_578_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.643 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.643 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311848 (rel: 3.68e-05) 0.00210301\n",
      "10-20 20:33:38.644 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_580 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:38.645 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_580_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:38.655 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_580_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.655 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 580 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.661 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.661 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 279 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.661 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 311 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 311 (MapPartitionsRDD[494] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_581 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.665 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_581_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.665 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_581_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.665 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 581 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 311 (MapPartitionsRDD[494] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 311.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.666 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 311.0 (TID 307) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.667 172.17.0.2:54321      18300   (TID 307)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 311.0 (TID 307)\n",
      "10-20 20:33:38.672 172.17.0.2:54321      18300   (TID 307)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.682 172.17.0.2:54321      18300   (TID 307)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 311.0 (TID 307). 3587 bytes result sent to driver\n",
      "10-20 20:33:38.683 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 311.0 (TID 307) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.683 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 311.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 311 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:33:38.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 279 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 311: Stage finished\n",
      "10-20 20:33:38.684 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 279 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022588 s\n",
      "10-20 20:33:38.684 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(580) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.685 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_580_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.685 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_582 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:38.686 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_582_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:38.686 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_582_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.686 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 582 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.693 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 280 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 312 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 312 (MapPartitionsRDD[495] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.696 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_583 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:38.697 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_583_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:38.697 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_583_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.697 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 583 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 312 (MapPartitionsRDD[495] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 312.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.698 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 312.0 (TID 308) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.699 172.17.0.2:54321      18300   (TID 308)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 312.0 (TID 308)\n",
      "10-20 20:33:38.704 172.17.0.2:54321      18300   (TID 308)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.711 172.17.0.2:54321      18300   (TID 308)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 312.0 (TID 308). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.712 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 312.0 (TID 308) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.712 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 312.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 312 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:38.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 280 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 312: Stage finished\n",
      "10-20 20:33:38.715 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 280 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022322 s\n",
      "10-20 20:33:38.715 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(582) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.716 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.10661245086655735 fval: 0.3118469173826044 rhs: 0.31184765587372476 cdd: -1.9475608579580616E-10\n",
      "10-20 20:33:38.716 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.1066\n",
      "10-20 20:33:38.716 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_582_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.716 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311847 (rel: 2.37e-06) 0.00129617\n",
      "10-20 20:33:38.716 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_584 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:38.717 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_584_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:38.717 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_584_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:38.718 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 584 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.765 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.766 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 281 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.766 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 313 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.766 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.767 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.767 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 313 (MapPartitionsRDD[496] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.771 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_585 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:38.772 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_585_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:38.773 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_585_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 585 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 313 (MapPartitionsRDD[496] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.773 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 313.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.775 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 313.0 (TID 309) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.775 172.17.0.2:54321      18300   (TID 309)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 313.0 (TID 309)\n",
      "10-20 20:33:38.790 172.17.0.2:54321      18300   (TID 309)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.799 172.17.0.2:54321      18300   (TID 309)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 313.0 (TID 309). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.800 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 313.0 (TID 309) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.800 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 313.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.801 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 313 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:33:38.801 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 281 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.801 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 313: Stage finished\n",
      "10-20 20:33:38.801 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 281 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035580 s\n",
      "10-20 20:33:38.801 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(584) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.803 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_584_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.805 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.805 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311845 (rel: 4.68e-06) 0.00118698\n",
      "10-20 20:33:38.805 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_586 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:38.806 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_586_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:38.806 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_586_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.807 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 586 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.816 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 282 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 314 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 314 (MapPartitionsRDD[497] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.821 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_587 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:38.822 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_587_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:38.822 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_587_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.822 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 587 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 314 (MapPartitionsRDD[497] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 314.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.824 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 314.0 (TID 310) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.825 172.17.0.2:54321      18300   (TID 310)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 314.0 (TID 310)\n",
      "10-20 20:33:38.830 172.17.0.2:54321      18300   (TID 310)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.837 172.17.0.2:54321      18300   (TID 310)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 314.0 (TID 310). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 314.0 (TID 310) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 314.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 314 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 282 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 314: Stage finished\n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 282 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021964 s\n",
      "10-20 20:33:38.838 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(586) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.839 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.839 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311838 (rel: 2.24e-05) 0.000842189\n",
      "10-20 20:33:38.839 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_586_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.839 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_588 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:38.840 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_588_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:38.840 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_588_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:38.841 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 588 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.857 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_585_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:38.865 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_581_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.865 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_579_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.866 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 283 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.866 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 315 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.867 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.867 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_587_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.867 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.868 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 315 (MapPartitionsRDD[498] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.870 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_589 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.872 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_589_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:38.872 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_589_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.873 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_575_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:38.874 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 589 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.874 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_583_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.874 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 315 (MapPartitionsRDD[498] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.874 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 315.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.875 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_577_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.875 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 315.0 (TID 311) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.876 172.17.0.2:54321      18300   (TID 311)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 315.0 (TID 311)\n",
      "10-20 20:33:38.881 172.17.0.2:54321      18300   (TID 311)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.888 172.17.0.2:54321      18300   (TID 311)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 315.0 (TID 311). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.888 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 315.0 (TID 311) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.888 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 315.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.888 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 315 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:33:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 283 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.889 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 315: Stage finished\n",
      "10-20 20:33:38.889 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 283 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022623 s\n",
      "10-20 20:33:38.889 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(588) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.890 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.890 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_588_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.890 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311835 (rel: 1.27e-05) 0.000486810\n",
      "10-20 20:33:38.891 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_590 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.891 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_590_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.891 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_590_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.892 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 590 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.898 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 284 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 316 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.898 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.899 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 316 (MapPartitionsRDD[499] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.902 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_591 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:38.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_591_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:38.905 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_591_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 591 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 316 (MapPartitionsRDD[499] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 316.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.906 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 316.0 (TID 312) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.906 172.17.0.2:54321      18300   (TID 312)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 316.0 (TID 312)\n",
      "10-20 20:33:38.912 172.17.0.2:54321      18300   (TID 312)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.918 172.17.0.2:54321      18300   (TID 312)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 316.0 (TID 312). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.918 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 316.0 (TID 312) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.918 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 316.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.919 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 316 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "10-20 20:33:38.919 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 284 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.919 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 316: Stage finished\n",
      "10-20 20:33:38.919 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 284 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021804 s\n",
      "10-20 20:33:38.920 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(590) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.920 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_590_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.921 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.921 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311833 (rel: 4.91e-06) 0.000338329\n",
      "10-20 20:33:38.921 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_592 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.930 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_592_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:38.931 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_589_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.932 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_592_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.932 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 592 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.934 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_591_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.7 MiB)\n",
      "10-20 20:33:38.940 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.940 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 285 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.940 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 317 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.941 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 317 (MapPartitionsRDD[500] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_593 stored as values in memory (estimated size 132.0 KiB, free 429.8 MiB)\n",
      "10-20 20:33:38.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_593_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.8 MiB)\n",
      "10-20 20:33:38.945 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_593_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.945 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 593 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.945 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 317 (MapPartitionsRDD[500] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.946 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 317.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.946 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 317.0 (TID 313) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.953 172.17.0.2:54321      18300   (TID 313)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 317.0 (TID 313)\n",
      "10-20 20:33:38.961 172.17.0.2:54321      18300   (TID 313)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:38.969 172.17.0.2:54321      18300   (TID 313)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 317.0 (TID 313). 3544 bytes result sent to driver\n",
      "10-20 20:33:38.970 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 317.0 (TID 313) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:38.970 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 317.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:38.970 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 317 (treeAggregate at RDDLossFunction.scala:61) finished in 0.029 s\n",
      "10-20 20:33:38.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 285 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:38.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 317: Stage finished\n",
      "10-20 20:33:38.971 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 285 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030883 s\n",
      "10-20 20:33:38.971 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(592) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:38.971 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:38.971 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311832 (rel: 2.50e-06) 0.000619918\n",
      "10-20 20:33:38.972 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_594 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.973 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_594_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:38.973 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_594_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.973 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 594 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:38.974 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_592_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:38.980 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:38.980 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 286 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:38.980 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 318 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:38.980 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:38.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:38.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 318 (MapPartitionsRDD[501] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:38.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_595 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:38.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_595_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:38.985 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_595_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:38.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 595 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:38.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 318 (MapPartitionsRDD[501] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:38.986 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 318.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:38.987 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 318.0 (TID 314) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:38.987 172.17.0.2:54321      18300   (TID 314)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 318.0 (TID 314)\n",
      "10-20 20:33:38.995 172.17.0.2:54321      18300   (TID 314)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.002 172.17.0.2:54321      18300   (TID 314)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 318.0 (TID 314). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.003 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 318.0 (TID 314) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.003 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 318.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 318 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:33:39.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 286 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 318: Stage finished\n",
      "10-20 20:33:39.005 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 286 finished: treeAggregate at RDDLossFunction.scala:61, took 0.024800 s\n",
      "10-20 20:33:39.006 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(594) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.006 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.007 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_594_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.008 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311831 (rel: 2.72e-06) 0.000357318\n",
      "10-20 20:33:39.008 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_596 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:39.008 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_596_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:39.009 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_596_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.009 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 596 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.018 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 287 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 319 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.019 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 319 (MapPartitionsRDD[502] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.023 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_597 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_597_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.024 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_597_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.024 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 597 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 319 (MapPartitionsRDD[502] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 319.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.026 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 319.0 (TID 315) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.026 172.17.0.2:54321      18300   (TID 315)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 319.0 (TID 315)\n",
      "10-20 20:33:39.033 172.17.0.2:54321      18300   (TID 315)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.048 172.17.0.2:54321      18300   (TID 315)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 319.0 (TID 315). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.049 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 319.0 (TID 315) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.049 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 319.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 319 (treeAggregate at RDDLossFunction.scala:61) finished in 0.030 s\n",
      "10-20 20:33:39.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 287 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 319: Stage finished\n",
      "10-20 20:33:39.050 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 287 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031058 s\n",
      "10-20 20:33:39.050 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(596) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.050 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.050 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311831 (rel: 1.34e-06) 0.000271010\n",
      "10-20 20:33:39.051 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_596_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_598 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:39.051 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_598_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:39.051 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_598_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.052 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 598 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.058 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 288 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 320 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 320 (MapPartitionsRDD[503] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.061 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_599 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:39.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_599_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:39.062 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_599_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 599 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 320 (MapPartitionsRDD[503] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.063 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 320.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.064 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 320.0 (TID 316) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.064 172.17.0.2:54321      18300   (TID 316)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 320.0 (TID 316)\n",
      "10-20 20:33:39.069 172.17.0.2:54321      18300   (TID 316)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.076 172.17.0.2:54321      18300   (TID 316)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 320.0 (TID 316). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.077 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 320.0 (TID 316) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.077 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 320.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 320 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 288 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 320: Stage finished\n",
      "10-20 20:33:39.077 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 288 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018759 s\n",
      "10-20 20:33:39.078 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(598) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.079 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_598_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.079 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.080 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311830 (rel: 2.50e-06) 0.000156592\n",
      "10-20 20:33:39.080 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_600 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:39.081 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_600_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:39.081 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_600_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.082 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 600 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.088 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 289 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 321 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.089 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 321 (MapPartitionsRDD[504] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_601 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:39.092 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_601_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:39.092 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_601_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 601 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 321 (MapPartitionsRDD[504] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 321.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.094 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 321.0 (TID 317) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.094 172.17.0.2:54321      18300   (TID 317)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 321.0 (TID 317)\n",
      "10-20 20:33:39.100 172.17.0.2:54321      18300   (TID 317)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.107 172.17.0.2:54321      18300   (TID 317)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 321.0 (TID 317). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.108 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 321.0 (TID 317) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.108 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 321.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.108 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 321 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:39.108 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 289 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.108 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 321: Stage finished\n",
      "10-20 20:33:39.108 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 289 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020587 s\n",
      "10-20 20:33:39.109 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(600) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.109 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.110 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311830 (rel: 1.15e-06) 0.000176995\n",
      "10-20 20:33:39.110 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_600_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_602 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:39.111 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_602_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:39.112 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_602_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.112 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 602 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.119 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.119 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 290 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.119 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 322 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.119 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.120 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.120 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 322 (MapPartitionsRDD[505] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.123 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_603 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.124 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_603_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.124 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_603_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 603 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 322 (MapPartitionsRDD[505] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 322.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.125 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 322.0 (TID 318) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.126 172.17.0.2:54321      18300   (TID 318)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 322.0 (TID 318)\n",
      "10-20 20:33:39.132 172.17.0.2:54321      18300   (TID 318)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.193 172.17.0.2:54321      18300   (TID 318)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 322.0 (TID 318). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.194 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 322.0 (TID 318) in 69 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.194 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 322.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 322 (treeAggregate at RDDLossFunction.scala:61) finished in 0.075 s\n",
      "10-20 20:33:39.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 290 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.195 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 322: Stage finished\n",
      "10-20 20:33:39.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 290 finished: treeAggregate at RDDLossFunction.scala:61, took 0.076499 s\n",
      "10-20 20:33:39.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(602) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.197 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.197 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_602_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.197 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 1.31e-06) 0.000227293\n",
      "10-20 20:33:39.198 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_604 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.199 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_604_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.199 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_604_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.200 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 604 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.208 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 291 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 323 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 323 (MapPartitionsRDD[506] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_605 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:39.213 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_605_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:39.214 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_605_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.214 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 605 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.215 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 323 (MapPartitionsRDD[506] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.215 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 323.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.216 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 323.0 (TID 319) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.216 172.17.0.2:54321      18300   (TID 319)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 323.0 (TID 319)\n",
      "10-20 20:33:39.234 172.17.0.2:54321      18300   (TID 319)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.252 172.17.0.2:54321      18300   (TID 319)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 323.0 (TID 319). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.256 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 323.0 (TID 319) in 41 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.256 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 323.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.258 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 323 (treeAggregate at RDDLossFunction.scala:61) finished in 0.048 s\n",
      "10-20 20:33:39.258 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 291 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.258 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 323: Stage finished\n",
      "10-20 20:33:39.258 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 291 finished: treeAggregate at RDDLossFunction.scala:61, took 0.050408 s\n",
      "10-20 20:33:39.259 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(604) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.260 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_606 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:39.261 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_606_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:39.261 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_604_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.261 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_606_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.262 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 606 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.272 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.273 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 292 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.273 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 324 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.273 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.274 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.274 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 324 (MapPartitionsRDD[507] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_607 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:39.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_607_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:39.281 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_607_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:39.281 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 607 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 324 (MapPartitionsRDD[507] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 324.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.285 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 324.0 (TID 320) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.286 172.17.0.2:54321      18300   (TID 320)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 324.0 (TID 320)\n",
      "10-20 20:33:39.297 172.17.0.2:54321      18300   (TID 320)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.310 172.17.0.2:54321      18300   (TID 320)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 324.0 (TID 320). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.311 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 324.0 (TID 320) in 28 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.312 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 324.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 324 (treeAggregate at RDDLossFunction.scala:61) finished in 0.038 s\n",
      "10-20 20:33:39.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 292 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.313 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 324: Stage finished\n",
      "10-20 20:33:39.314 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 292 finished: treeAggregate at RDDLossFunction.scala:61, took 0.041281 s\n",
      "10-20 20:33:39.314 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(606) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.315 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.14095562812288598 fval: 0.3118293534693179 rhs: 0.31182939471028104 cdd: 5.275589032479311E-13\n",
      "10-20 20:33:39.316 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.1410\n",
      "10-20 20:33:39.316 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 1.32e-07) 0.000512448\n",
      "10-20 20:33:39.317 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_606_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:39.317 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_608 stored as values in memory (estimated size 912.0 B, free 428.6 MiB)\n",
      "10-20 20:33:39.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_608_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.6 MiB)\n",
      "10-20 20:33:39.318 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_608_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:39.319 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 608 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.329 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 293 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 325 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 325 (MapPartitionsRDD[508] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_609 stored as values in memory (estimated size 132.0 KiB, free 428.5 MiB)\n",
      "10-20 20:33:39.346 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_609_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.4 MiB)\n",
      "10-20 20:33:39.346 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_609_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:39.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 609 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 325 (MapPartitionsRDD[508] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.347 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 325.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.348 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 325.0 (TID 321) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.349 172.17.0.2:54321      18300   (TID 321)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 325.0 (TID 321)\n",
      "10-20 20:33:39.364 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_599_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:39.366 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_597_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.367 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_603_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.372 172.17.0.2:54321      18300   (TID 321)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.379 172.17.0.2:54321      18300   (TID 321)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 325.0 (TID 321). 3587 bytes result sent to driver\n",
      "10-20 20:33:39.380 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 325.0 (TID 321) in 32 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.380 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 325.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 325 (treeAggregate at RDDLossFunction.scala:61) finished in 0.049 s\n",
      "10-20 20:33:39.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 293 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 325: Stage finished\n",
      "10-20 20:33:39.385 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 293 finished: treeAggregate at RDDLossFunction.scala:61, took 0.055884 s\n",
      "10-20 20:33:39.385 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(608) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.386 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.386 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 5.61e-07) 0.000360936\n",
      "10-20 20:33:39.386 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_610 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.394 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_608_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.394 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_610_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.394 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_610_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.395 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 610 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.395 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_605_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.400 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.401 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_609_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.401 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 294 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.401 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 326 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.401 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.402 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.402 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 326 (MapPartitionsRDD[509] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.403 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_601_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.404 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_595_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.405 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_611 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.405 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_593_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_611_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:39.407 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_611_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.407 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 611 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.407 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_607_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.408 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 326 (MapPartitionsRDD[509] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.408 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 326.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.409 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 326.0 (TID 322) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.411 172.17.0.2:54321      18300   (TID 322)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 326.0 (TID 322)\n",
      "10-20 20:33:39.416 172.17.0.2:54321      18300   (TID 322)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.423 172.17.0.2:54321      18300   (TID 322)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 326.0 (TID 322). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.424 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 326.0 (TID 322) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.424 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 326.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.424 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 326 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:33:39.425 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 294 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.425 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 326: Stage finished\n",
      "10-20 20:33:39.425 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 294 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023987 s\n",
      "10-20 20:33:39.425 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(610) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.425 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.425 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 6.01e-07) 0.000237216\n",
      "10-20 20:33:39.426 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_610_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.426 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_612 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:39.428 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_612_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:39.429 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_612_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.429 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 612 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.435 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 295 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 327 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.436 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 327 (MapPartitionsRDD[510] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_613 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:39.441 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_613_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:39.441 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_613_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 613 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.442 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 327 (MapPartitionsRDD[510] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.443 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 327.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.444 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 327.0 (TID 323) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.445 172.17.0.2:54321      18300   (TID 323)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 327.0 (TID 323)\n",
      "10-20 20:33:39.450 172.17.0.2:54321      18300   (TID 323)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.457 172.17.0.2:54321      18300   (TID 323)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 327.0 (TID 323). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.457 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 327.0 (TID 323) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.457 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 327.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 327 (treeAggregate at RDDLossFunction.scala:61) finished in 0.021 s\n",
      "10-20 20:33:39.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 295 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 327: Stage finished\n",
      "10-20 20:33:39.459 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 295 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023246 s\n",
      "10-20 20:33:39.459 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(612) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.460 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.460 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_612_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.460 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 2.98e-07) 0.000179791\n",
      "10-20 20:33:39.461 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_614 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:39.461 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_614_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:39.462 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_614_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 614 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.468 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 296 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 328 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.468 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.469 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.469 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 328 (MapPartitionsRDD[511] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.472 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_615 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.473 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_615_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.473 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_615_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 615 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 328 (MapPartitionsRDD[511] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 328.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.475 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 328.0 (TID 324) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.475 172.17.0.2:54321      18300   (TID 324)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 328.0 (TID 324)\n",
      "10-20 20:33:39.480 172.17.0.2:54321      18300   (TID 324)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.486 172.17.0.2:54321      18300   (TID 324)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 328.0 (TID 324). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.486 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 328.0 (TID 324) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.487 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 328.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.487 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 328 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.487 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 296 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.487 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 328: Stage finished\n",
      "10-20 20:33:39.488 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 296 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019580 s\n",
      "10-20 20:33:39.488 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(614) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.489 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.489 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 5.52e-07) 0.000119460\n",
      "10-20 20:33:39.489 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_614_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.489 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_616 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:39.489 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_616_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:39.490 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_616_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.490 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 616 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.496 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 297 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 329 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 329 (MapPartitionsRDD[512] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.500 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_617 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:39.500 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_617_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:39.500 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_617_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 617 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 329 (MapPartitionsRDD[512] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.501 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 329.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.502 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 329.0 (TID 325) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.502 172.17.0.2:54321      18300   (TID 325)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 329.0 (TID 325)\n",
      "10-20 20:33:39.507 172.17.0.2:54321      18300   (TID 325)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.513 172.17.0.2:54321      18300   (TID 325)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 329.0 (TID 325). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.514 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 329.0 (TID 325) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.514 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 329.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 329 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 297 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 329: Stage finished\n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 297 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018309 s\n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(616) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.515 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 4.65e-07) 0.000120849\n",
      "10-20 20:33:39.516 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_616_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.516 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_618 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:39.516 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_618_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:39.516 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_618_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.517 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 618 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.523 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.523 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 298 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.524 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 330 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.524 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.524 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.524 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 330 (MapPartitionsRDD[513] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.527 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_619 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:39.528 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_619_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:39.528 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_619_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.528 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 619 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.528 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 330 (MapPartitionsRDD[513] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.528 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 330.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.529 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 330.0 (TID 326) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.530 172.17.0.2:54321      18300   (TID 326)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 330.0 (TID 326)\n",
      "10-20 20:33:39.534 172.17.0.2:54321      18300   (TID 326)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.541 172.17.0.2:54321      18300   (TID 326)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 330.0 (TID 326). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.542 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 330.0 (TID 326) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.542 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 330.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 330 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 298 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 330: Stage finished\n",
      "10-20 20:33:39.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 298 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019486 s\n",
      "10-20 20:33:39.543 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(618) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.544 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.544 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311829 (rel: 1.82e-07) 0.000284580\n",
      "10-20 20:33:39.544 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_618_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.544 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_620 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:39.545 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_620_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:39.545 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_620_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.546 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 620 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.552 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.553 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 299 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.553 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 331 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.553 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.553 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.553 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 331 (MapPartitionsRDD[514] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.556 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_621 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_621_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.557 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_621_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 621 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 331 (MapPartitionsRDD[514] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 331.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.558 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 331.0 (TID 327) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.558 172.17.0.2:54321      18300   (TID 327)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 331.0 (TID 327)\n",
      "10-20 20:33:39.587 172.17.0.2:54321      18300   (TID 327)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.595 172.17.0.2:54321      18300   (TID 327)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 331.0 (TID 327). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.595 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 331.0 (TID 327) in 37 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.595 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 331.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.596 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 331 (treeAggregate at RDDLossFunction.scala:61) finished in 0.041 s\n",
      "10-20 20:33:39.596 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 299 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.596 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 331: Stage finished\n",
      "10-20 20:33:39.596 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 299 finished: treeAggregate at RDDLossFunction.scala:61, took 0.043814 s\n",
      "10-20 20:33:39.596 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(620) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.597 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.597 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_620_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.597 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 3.28e-07) 0.000106921\n",
      "10-20 20:33:39.598 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_622 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.599 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_622_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.599 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_622_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.600 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 622 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.607 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 300 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 332 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.607 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.608 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 332 (MapPartitionsRDD[515] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.611 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_623 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:39.612 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_623_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:39.612 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_623_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.612 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 623 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 332 (MapPartitionsRDD[515] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 332.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.613 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 332.0 (TID 328) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.614 172.17.0.2:54321      18300   (TID 328)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 332.0 (TID 328)\n",
      "10-20 20:33:39.620 172.17.0.2:54321      18300   (TID 328)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.626 172.17.0.2:54321      18300   (TID 328)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 332.0 (TID 328). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 332.0 (TID 328) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 332 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 300 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 332: Stage finished\n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 300 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020419 s\n",
      "10-20 20:33:39.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(622) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.628 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.628 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_622_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.628 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 8.93e-08) 6.99900e-05\n",
      "10-20 20:33:39.628 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_624 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:39.629 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_624_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:39.629 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_624_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.630 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 624 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.636 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 301 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 333 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.637 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.637 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 333 (MapPartitionsRDD[516] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_625 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:39.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_625_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:39.640 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_625_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:39.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 625 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 333 (MapPartitionsRDD[516] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 333.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.642 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 333.0 (TID 329) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.643 172.17.0.2:54321      18300   (TID 329)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 333.0 (TID 329)\n",
      "10-20 20:33:39.650 172.17.0.2:54321      18300   (TID 329)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.658 172.17.0.2:54321      18300   (TID 329)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 333.0 (TID 329). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.659 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 333.0 (TID 329) in 17 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.659 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.659 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 333 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "10-20 20:33:39.659 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 301 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.659 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 333: Stage finished\n",
      "10-20 20:33:39.659 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 301 finished: treeAggregate at RDDLossFunction.scala:61, took 0.023092 s\n",
      "10-20 20:33:39.660 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(624) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.660 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.660 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_624_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:39.660 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 1.23e-07) 6.06663e-05\n",
      "10-20 20:33:39.661 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_626 stored as values in memory (estimated size 912.0 B, free 428.6 MiB)\n",
      "10-20 20:33:39.662 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_626_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.6 MiB)\n",
      "10-20 20:33:39.662 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_626_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:39.662 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 626 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.669 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 302 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 334 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.669 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.670 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 334 (MapPartitionsRDD[517] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.673 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_627 stored as values in memory (estimated size 132.0 KiB, free 428.5 MiB)\n",
      "10-20 20:33:39.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_627_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.4 MiB)\n",
      "10-20 20:33:39.674 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_627_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:39.674 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 627 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.675 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 334 (MapPartitionsRDD[517] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.675 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.676 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 334.0 (TID 330) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.677 172.17.0.2:54321      18300   (TID 330)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 334.0 (TID 330)\n",
      "10-20 20:33:39.681 172.17.0.2:54321      18300   (TID 330)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.688 172.17.0.2:54321      18300   (TID 330)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 334.0 (TID 330). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.689 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 334.0 (TID 330) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.689 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.690 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 334 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:39.690 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 302 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.690 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 334: Stage finished\n",
      "10-20 20:33:39.690 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 302 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021470 s\n",
      "10-20 20:33:39.691 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(626) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.692 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_626_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:39.692 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.692 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 1.53e-07) 7.11505e-05\n",
      "10-20 20:33:39.692 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_628 stored as values in memory (estimated size 912.0 B, free 428.4 MiB)\n",
      "10-20 20:33:39.694 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_628_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.4 MiB)\n",
      "10-20 20:33:39.694 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_628_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:39.695 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 628 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.701 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 303 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 335 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.705 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.705 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 335 (MapPartitionsRDD[518] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.715 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_611_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:39.719 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_621_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.720 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_615_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.721 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_623_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_629 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_629_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.724 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_629_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.724 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_627_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.724 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 629 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.725 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 335 (MapPartitionsRDD[518] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.725 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.725 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_617_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.726 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 335.0 (TID 331) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.727 172.17.0.2:54321      18300   (TID 331)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 335.0 (TID 331)\n",
      "10-20 20:33:39.728 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_625_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.729 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_619_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.730 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_613_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.733 172.17.0.2:54321      18300   (TID 331)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.740 172.17.0.2:54321      18300   (TID 331)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 335.0 (TID 331). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.741 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 335.0 (TID 331) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.741 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 335 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:33:39.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 303 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 335: Stage finished\n",
      "10-20 20:33:39.743 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 303 finished: treeAggregate at RDDLossFunction.scala:61, took 0.041448 s\n",
      "10-20 20:33:39.743 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(628) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.743 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_628_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.744 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.744 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 1.87e-07) 6.32761e-05\n",
      "10-20 20:33:39.744 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_630 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:39.752 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_630_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:39.752 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_630_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.753 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_629_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.7 MiB)\n",
      "10-20 20:33:39.754 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 630 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.760 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 304 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 336 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.760 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 336 (MapPartitionsRDD[519] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.764 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_631 stored as values in memory (estimated size 132.0 KiB, free 429.8 MiB)\n",
      "10-20 20:33:39.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_631_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.8 MiB)\n",
      "10-20 20:33:39.765 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_631_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 631 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 336 (MapPartitionsRDD[519] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.765 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.766 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 336.0 (TID 332) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.766 172.17.0.2:54321      18300   (TID 332)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 336.0 (TID 332)\n",
      "10-20 20:33:39.772 172.17.0.2:54321      18300   (TID 332)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.778 172.17.0.2:54321      18300   (TID 332)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 336.0 (TID 332). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.779 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 336.0 (TID 332) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.779 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.779 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 336 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.779 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 304 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.779 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 336: Stage finished\n",
      "10-20 20:33:39.780 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 304 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019538 s\n",
      "10-20 20:33:39.780 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(630) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.781 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_630_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.782 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_632 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:39.783 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_632_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:39.783 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_632_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.783 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 632 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.791 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 305 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.791 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 337 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.791 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.791 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.792 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 337 (MapPartitionsRDD[520] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.794 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_633 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:39.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_633_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:39.795 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_633_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:39.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 633 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.795 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 337 (MapPartitionsRDD[520] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.796 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.796 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 337.0 (TID 333) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.797 172.17.0.2:54321      18300   (TID 333)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 337.0 (TID 333)\n",
      "10-20 20:33:39.802 172.17.0.2:54321      18300   (TID 333)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.808 172.17.0.2:54321      18300   (TID 333)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 337.0 (TID 333). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.809 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 337.0 (TID 333) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.809 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.809 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 337 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:33:39.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 305 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.810 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 337: Stage finished\n",
      "10-20 20:33:39.810 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 305 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019443 s\n",
      "10-20 20:33:39.810 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(632) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.810 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.1 fval: 0.31182826360481924 rhs: 0.3118282496809708 cdd: 4.3883301514723455E-7\n",
      "10-20 20:33:39.811 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_632_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.811 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_634 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:39.811 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_634_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:39.812 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_634_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:39.812 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 634 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.818 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.819 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 306 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.819 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 338 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.819 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.819 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.819 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 338 (MapPartitionsRDD[521] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.823 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_635 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_635_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:39.824 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_635_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.824 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 635 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.825 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 338 (MapPartitionsRDD[521] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.825 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.825 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 338.0 (TID 334) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.826 172.17.0.2:54321      18300   (TID 334)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 338.0 (TID 334)\n",
      "10-20 20:33:39.831 172.17.0.2:54321      18300   (TID 334)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.838 172.17.0.2:54321      18300   (TID 334)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 338.0 (TID 334). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.838 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 338.0 (TID 334) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.838 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 338 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:39.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 306 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 338: Stage finished\n",
      "10-20 20:33:39.839 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 306 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020962 s\n",
      "10-20 20:33:39.839 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(634) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.840 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.02676577408130533 fval: 0.3118282475362868 rhs: 0.3118282496821453 cdd: -9.89323466332497E-15\n",
      "10-20 20:33:39.840 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.02677\n",
      "10-20 20:33:39.840 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 6.88e-09) 0.000153199\n",
      "10-20 20:33:39.840 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_634_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.840 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_636 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:39.841 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_636_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:39.841 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_636_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.841 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 636 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.847 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 307 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 339 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.848 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.849 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.851 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 339 (MapPartitionsRDD[522] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.854 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_637 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:39.855 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_637_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:39.855 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_637_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.856 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 637 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.856 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 339 (MapPartitionsRDD[522] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.856 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.857 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 339.0 (TID 335) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.857 172.17.0.2:54321      18300   (TID 335)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 339.0 (TID 335)\n",
      "10-20 20:33:39.863 172.17.0.2:54321      18300   (TID 335)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.869 172.17.0.2:54321      18300   (TID 335)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 339.0 (TID 335). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.869 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 339.0 (TID 335) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.869 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.870 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 339 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "10-20 20:33:39.870 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 307 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.870 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 339: Stage finished\n",
      "10-20 20:33:39.870 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 307 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022349 s\n",
      "10-20 20:33:39.870 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(636) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.871 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_636_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.871 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.871 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 1.10e-07) 8.85273e-05\n",
      "10-20 20:33:39.872 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_638 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:39.872 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_638_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:39.872 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_638_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.872 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 638 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.878 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.878 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 308 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.878 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 340 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.878 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.879 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.879 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 340 (MapPartitionsRDD[523] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.881 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_639 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:39.882 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_639_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:39.883 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_639_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:39.883 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 639 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.883 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 340 (MapPartitionsRDD[523] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.883 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.884 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 340.0 (TID 336) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.884 172.17.0.2:54321      18300   (TID 336)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 340.0 (TID 336)\n",
      "10-20 20:33:39.889 172.17.0.2:54321      18300   (TID 336)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.895 172.17.0.2:54321      18300   (TID 336)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 340.0 (TID 336). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.896 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 340.0 (TID 336) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.896 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 340 (treeAggregate at RDDLossFunction.scala:61) finished in 0.017 s\n",
      "10-20 20:33:39.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 308 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.897 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 340: Stage finished\n",
      "10-20 20:33:39.897 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 308 finished: treeAggregate at RDDLossFunction.scala:61, took 0.018906 s\n",
      "10-20 20:33:39.897 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(638) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.897 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.898 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 6.61e-08) 8.28888e-05\n",
      "10-20 20:33:39.898 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_638_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.898 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_640 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:39.899 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_640_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:39.899 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_640_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:39.899 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 640 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.906 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.906 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 309 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.906 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 341 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.906 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.906 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.906 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 341 (MapPartitionsRDD[524] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.909 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_641 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.911 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_641_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:39.911 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_641_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.912 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 641 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.912 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 341 (MapPartitionsRDD[524] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.912 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 341.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.913 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 341.0 (TID 337) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.913 172.17.0.2:54321      18300   (TID 337)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 341.0 (TID 337)\n",
      "10-20 20:33:39.918 172.17.0.2:54321      18300   (TID 337)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.924 172.17.0.2:54321      18300   (TID 337)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 341.0 (TID 337). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.925 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 341.0 (TID 337) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.925 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 341 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 309 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 341: Stage finished\n",
      "10-20 20:33:39.926 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 309 finished: treeAggregate at RDDLossFunction.scala:61, took 0.019856 s\n",
      "10-20 20:33:39.926 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(640) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.927 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.927 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_640_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.927 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 5.97e-08) 8.99539e-05\n",
      "10-20 20:33:39.956 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_642 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.956 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_642_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:39.957 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_642_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.957 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 642 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.965 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 310 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 342 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 342 (MapPartitionsRDD[525] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.969 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_643 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:39.970 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_643_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:39.970 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_643_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:39.970 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 643 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:39.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 342 (MapPartitionsRDD[525] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:39.971 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:39.971 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 342.0 (TID 338) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:39.972 172.17.0.2:54321      18300   (TID 338)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 342.0 (TID 338)\n",
      "10-20 20:33:39.977 172.17.0.2:54321      18300   (TID 338)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:39.983 172.17.0.2:54321      18300   (TID 338)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 342.0 (TID 338). 3544 bytes result sent to driver\n",
      "10-20 20:33:39.984 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 342.0 (TID 338) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:39.984 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:39.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 342 (treeAggregate at RDDLossFunction.scala:61) finished in 0.018 s\n",
      "10-20 20:33:39.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 310 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:39.985 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 342: Stage finished\n",
      "10-20 20:33:39.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 310 finished: treeAggregate at RDDLossFunction.scala:61, took 0.020444 s\n",
      "10-20 20:33:39.986 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(642) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:39.986 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:39.986 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 1.07e-07) 6.35133e-05\n",
      "10-20 20:33:39.986 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_642_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_644 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:39.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_644_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:39.988 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_644_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:39.988 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 644 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:39.993 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:39.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 311 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:39.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 343 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:39.994 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:39.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:39.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 343 (MapPartitionsRDD[526] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:39.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_645 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:39.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_645_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:39.998 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_645_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:40.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 645 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 343 (MapPartitionsRDD[526] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 343.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.001 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 343.0 (TID 339) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.002 172.17.0.2:54321      18300   (TID 339)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 343.0 (TID 339)\n",
      "10-20 20:33:40.007 172.17.0.2:54321      18300   (TID 339)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.013 172.17.0.2:54321      18300   (TID 339)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 343.0 (TID 339). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.014 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 343.0 (TID 339) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.014 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 343 (treeAggregate at RDDLossFunction.scala:61) finished in 0.030 s\n",
      "10-20 20:33:40.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 311 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.025 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 343: Stage finished\n",
      "10-20 20:33:40.025 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 311 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031630 s\n",
      "10-20 20:33:40.026 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(644) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.026 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_644_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.026 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.027 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 3.97e-08) 6.17324e-05\n",
      "10-20 20:33:40.027 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_646 stored as values in memory (estimated size 912.0 B, free 428.6 MiB)\n",
      "10-20 20:33:40.028 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_646_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.6 MiB)\n",
      "10-20 20:33:40.028 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_646_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.029 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 646 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.035 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 312 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 344 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.035 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[527] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_647 stored as values in memory (estimated size 132.0 KiB, free 428.5 MiB)\n",
      "10-20 20:33:40.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_647_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.4 MiB)\n",
      "10-20 20:33:40.040 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_647_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:40.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 647 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[527] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 344.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.041 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 344.0 (TID 340) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.042 172.17.0.2:54321      18300   (TID 340)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 344.0 (TID 340)\n",
      "10-20 20:33:40.057 172.17.0.2:54321      18300   (TID 340)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.069 172.17.0.2:54321      18300   (TID 340)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 344.0 (TID 340). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.071 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 344.0 (TID 340) in 30 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.072 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.073 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 344 (treeAggregate at RDDLossFunction.scala:61) finished in 0.037 s\n",
      "10-20 20:33:40.073 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 312 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.073 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 344: Stage finished\n",
      "10-20 20:33:40.074 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 312 finished: treeAggregate at RDDLossFunction.scala:61, took 0.038822 s\n",
      "10-20 20:33:40.074 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(646) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.075 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.075 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_646_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.075 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.98e-08) 3.58186e-05\n",
      "10-20 20:33:40.077 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_648 stored as values in memory (estimated size 912.0 B, free 428.4 MiB)\n",
      "10-20 20:33:40.078 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_648_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.4 MiB)\n",
      "10-20 20:33:40.078 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_648_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.078 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 648 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.090 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 313 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 345 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.091 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.092 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.093 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 345 (MapPartitionsRDD[528] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.101 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_649 stored as values in memory (estimated size 132.0 KiB, free 428.3 MiB)\n",
      "10-20 20:33:40.105 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_649_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.3 MiB)\n",
      "10-20 20:33:40.105 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_649_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:40.105 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 649 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.106 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 345 (MapPartitionsRDD[528] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.106 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 345.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.107 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 345.0 (TID 341) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.107 172.17.0.2:54321      18300   (TID 341)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 345.0 (TID 341)\n",
      "10-20 20:33:40.115 172.17.0.2:54321      18300   (TID 341)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.124 172.17.0.2:54321      18300   (TID 341)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 345.0 (TID 341). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.125 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 345.0 (TID 341) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.125 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.125 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 345 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:33:40.126 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 313 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.126 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 345: Stage finished\n",
      "10-20 20:33:40.126 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 313 finished: treeAggregate at RDDLossFunction.scala:61, took 0.035379 s\n",
      "10-20 20:33:40.126 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(648) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.127 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.127 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.51e-08) 5.12582e-05\n",
      "10-20 20:33:40.127 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_648_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.127 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_650 stored as values in memory (estimated size 912.0 B, free 428.3 MiB)\n",
      "10-20 20:33:40.138 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_650_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.3 MiB)\n",
      "10-20 20:33:40.138 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_650_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.139 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_643_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:40.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 650 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.142 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_645_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:40.144 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_635_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:40.145 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_641_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:40.147 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_633_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:40.149 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_649_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:40.150 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_631_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:40.153 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_639_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:40.154 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_647_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:40.155 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.156 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 314 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.156 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 346 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.156 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.156 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.156 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_637_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 430.7 MiB)\n",
      "10-20 20:33:40.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 346 (MapPartitionsRDD[529] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.162 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_651 stored as values in memory (estimated size 132.0 KiB, free 429.8 MiB)\n",
      "10-20 20:33:40.163 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_651_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.8 MiB)\n",
      "10-20 20:33:40.163 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_651_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:40.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 651 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 346 (MapPartitionsRDD[529] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 346.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.166 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 346.0 (TID 342) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.166 172.17.0.2:54321      18300   (TID 342)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 346.0 (TID 342)\n",
      "10-20 20:33:40.175 172.17.0.2:54321      18300   (TID 342)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.184 172.17.0.2:54321      18300   (TID 342)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 346.0 (TID 342). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.184 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 346.0 (TID 342) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.184 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.186 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 346 (treeAggregate at RDDLossFunction.scala:61) finished in 0.028 s\n",
      "10-20 20:33:40.186 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 314 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.186 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 346: Stage finished\n",
      "10-20 20:33:40.187 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 314 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031554 s\n",
      "10-20 20:33:40.187 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(650) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.188 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.188 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.31e-08) 3.40395e-05\n",
      "10-20 20:33:40.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_652 stored as values in memory (estimated size 912.0 B, free 429.8 MiB)\n",
      "10-20 20:33:40.189 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_652_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.8 MiB)\n",
      "10-20 20:33:40.189 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_650_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:40.190 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_652_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:40.190 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 652 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.202 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 315 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 347 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.203 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 347 (MapPartitionsRDD[530] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_653 stored as values in memory (estimated size 132.0 KiB, free 429.7 MiB)\n",
      "10-20 20:33:40.211 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_653_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.6 MiB)\n",
      "10-20 20:33:40.211 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_653_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.6 MiB)\n",
      "10-20 20:33:40.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 653 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 347 (MapPartitionsRDD[530] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 347.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.214 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 347.0 (TID 343) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.214 172.17.0.2:54321      18300   (TID 343)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 347.0 (TID 343)\n",
      "10-20 20:33:40.229 172.17.0.2:54321      18300   (TID 343)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.240 172.17.0.2:54321      18300   (TID 343)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 347.0 (TID 343). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.242 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 347.0 (TID 343) in 28 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.243 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 347.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 347 (treeAggregate at RDDLossFunction.scala:61) finished in 0.038 s\n",
      "10-20 20:33:40.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 315 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 347: Stage finished\n",
      "10-20 20:33:40.243 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 315 finished: treeAggregate at RDDLossFunction.scala:61, took 0.041438 s\n",
      "10-20 20:33:40.244 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(652) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.245 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.245 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_652_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:40.246 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.70e-08) 3.61054e-05\n",
      "10-20 20:33:40.247 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_654 stored as values in memory (estimated size 912.0 B, free 429.6 MiB)\n",
      "10-20 20:33:40.247 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_654_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.6 MiB)\n",
      "10-20 20:33:40.247 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_654_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.6 MiB)\n",
      "10-20 20:33:40.248 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 654 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.258 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 316 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 348 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.260 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 348 (MapPartitionsRDD[531] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.264 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_655 stored as values in memory (estimated size 132.0 KiB, free 429.5 MiB)\n",
      "10-20 20:33:40.266 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_655_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.5 MiB)\n",
      "10-20 20:33:40.267 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_655_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:40.268 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 655 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 348 (MapPartitionsRDD[531] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.269 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 348.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.272 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 348.0 (TID 344) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.274 172.17.0.2:54321      18300   (TID 344)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 348.0 (TID 344)\n",
      "10-20 20:33:40.284 172.17.0.2:54321      18300   (TID 344)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.293 172.17.0.2:54321      18300   (TID 344)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 348.0 (TID 344). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.294 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 348.0 (TID 344) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.294 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 348.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 348 (treeAggregate at RDDLossFunction.scala:61) finished in 0.035 s\n",
      "10-20 20:33:40.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 316 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.295 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 348: Stage finished\n",
      "10-20 20:33:40.296 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 316 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037050 s\n",
      "10-20 20:33:40.297 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(654) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.297 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_654_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:40.298 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.298 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 5.58e-08) 4.61058e-05\n",
      "10-20 20:33:40.298 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_656 stored as values in memory (estimated size 912.0 B, free 429.5 MiB)\n",
      "10-20 20:33:40.303 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_656_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.5 MiB)\n",
      "10-20 20:33:40.303 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_656_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:40.304 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 656 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.314 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 317 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 349 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.315 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.316 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 349 (MapPartitionsRDD[532] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.320 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_657 stored as values in memory (estimated size 132.0 KiB, free 429.3 MiB)\n",
      "10-20 20:33:40.321 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_657_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.3 MiB)\n",
      "10-20 20:33:40.322 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_657_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:40.323 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 657 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.324 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 349 (MapPartitionsRDD[532] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.324 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 349.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.325 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 349.0 (TID 345) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.326 172.17.0.2:54321      18300   (TID 345)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 349.0 (TID 345)\n",
      "10-20 20:33:40.338 172.17.0.2:54321      18300   (TID 345)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.349 172.17.0.2:54321      18300   (TID 345)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 349.0 (TID 345). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.350 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 349.0 (TID 345) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.350 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 349.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 349 (treeAggregate at RDDLossFunction.scala:61) finished in 0.034 s\n",
      "10-20 20:33:40.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 317 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.351 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 349: Stage finished\n",
      "10-20 20:33:40.352 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 317 finished: treeAggregate at RDDLossFunction.scala:61, took 0.037509 s\n",
      "10-20 20:33:40.353 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(656) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.353 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.353 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 1.45e-07) 7.82915e-05\n",
      "10-20 20:33:40.354 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_656_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:40.354 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_658 stored as values in memory (estimated size 912.0 B, free 429.3 MiB)\n",
      "10-20 20:33:40.356 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_658_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.3 MiB)\n",
      "10-20 20:33:40.356 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_658_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:40.356 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 658 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.364 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 318 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 350 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.367 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 350 (MapPartitionsRDD[533] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.370 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_659 stored as values in memory (estimated size 132.0 KiB, free 429.2 MiB)\n",
      "10-20 20:33:40.372 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_659_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.1 MiB)\n",
      "10-20 20:33:40.372 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_659_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.5 MiB)\n",
      "10-20 20:33:40.373 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 659 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.374 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 350 (MapPartitionsRDD[533] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.374 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 350.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.375 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 350.0 (TID 346) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.376 172.17.0.2:54321      18300   (TID 346)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 350.0 (TID 346)\n",
      "10-20 20:33:40.386 172.17.0.2:54321      18300   (TID 346)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.393 172.17.0.2:54321      18300   (TID 346)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 350.0 (TID 346). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.394 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 350.0 (TID 346) in 19 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.394 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 350.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 350 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "10-20 20:33:40.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 318 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 350: Stage finished\n",
      "10-20 20:33:40.396 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 318 finished: treeAggregate at RDDLossFunction.scala:61, took 0.031197 s\n",
      "10-20 20:33:40.396 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(658) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.397 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_660 stored as values in memory (estimated size 912.0 B, free 429.1 MiB)\n",
      "10-20 20:33:40.397 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_658_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:40.397 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_660_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.1 MiB)\n",
      "10-20 20:33:40.398 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_660_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.5 MiB)\n",
      "10-20 20:33:40.398 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 660 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.405 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 319 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 351 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 351 (MapPartitionsRDD[534] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_661 stored as values in memory (estimated size 132.0 KiB, free 429.0 MiB)\n",
      "10-20 20:33:40.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_661_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 429.0 MiB)\n",
      "10-20 20:33:40.455 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_661_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:40.456 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 661 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.456 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 351 (MapPartitionsRDD[534] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.456 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 351.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.458 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 351.0 (TID 347) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.458 172.17.0.2:54321      18300   (TID 347)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 351.0 (TID 347)\n",
      "10-20 20:33:40.465 172.17.0.2:54321      18300   (TID 347)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.476 172.17.0.2:54321      18300   (TID 347)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 351.0 (TID 347). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.477 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 351.0 (TID 347) in 20 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.477 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 351.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 351 (treeAggregate at RDDLossFunction.scala:61) finished in 0.070 s\n",
      "10-20 20:33:40.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 319 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 351: Stage finished\n",
      "10-20 20:33:40.478 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 319 finished: treeAggregate at RDDLossFunction.scala:61, took 0.072885 s\n",
      "10-20 20:33:40.479 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(660) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.480 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.StrongWolfeLineSearch: Line search t: 0.1 fval: 0.31182802667366927 rhs: 0.311828032928267 cdd: 9.035993958667129E-9\n",
      "10-20 20:33:40.480 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 0.1000\n",
      "10-20 20:33:40.480 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_660_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:40.484 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.01e-08) 0.000210764\n",
      "10-20 20:33:40.484 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_662 stored as values in memory (estimated size 912.0 B, free 429.0 MiB)\n",
      "10-20 20:33:40.485 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_662_piece0 stored as bytes in memory (estimated size 994.0 B, free 429.0 MiB)\n",
      "10-20 20:33:40.486 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_662_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:40.486 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 662 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.493 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.493 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 320 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.493 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 352 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.493 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.494 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 352 (MapPartitionsRDD[535] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_663 stored as values in memory (estimated size 132.0 KiB, free 428.8 MiB)\n",
      "10-20 20:33:40.498 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_663_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.8 MiB)\n",
      "10-20 20:33:40.499 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_663_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.4 MiB)\n",
      "10-20 20:33:40.499 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 663 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.499 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 352 (MapPartitionsRDD[535] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.499 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 352.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.500 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 352.0 (TID 348) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.501 172.17.0.2:54321      18300   (TID 348)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 352.0 (TID 348)\n",
      "10-20 20:33:40.510 172.17.0.2:54321      18300   (TID 348)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.522 172.17.0.2:54321      18300   (TID 348)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 352.0 (TID 348). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.524 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 352.0 (TID 348) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.524 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 352.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.526 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 352 (treeAggregate at RDDLossFunction.scala:61) finished in 0.032 s\n",
      "10-20 20:33:40.527 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 320 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.527 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 352: Stage finished\n",
      "10-20 20:33:40.527 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 320 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034026 s\n",
      "10-20 20:33:40.527 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(662) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.528 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.528 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.22e-07) 0.000111290\n",
      "10-20 20:33:40.528 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_664 stored as values in memory (estimated size 912.0 B, free 428.8 MiB)\n",
      "10-20 20:33:40.529 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_664_piece0 stored as bytes in memory (estimated size 994.0 B, free 428.8 MiB)\n",
      "10-20 20:33:40.529 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_662_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:40.530 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_664_piece0 in memory on 5b5a8eb7561c:44751 (size: 994.0 B, free: 430.4 MiB)\n",
      "10-20 20:33:40.530 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 664 from broadcast at RDDLossFunction.scala:57\n",
      "10-20 20:33:40.541 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "10-20 20:33:40.541 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 321 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "10-20 20:33:40.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 353 (treeAggregate at RDDLossFunction.scala:61)\n",
      "10-20 20:33:40.542 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:33:40.543 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:40.545 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 353 (MapPartitionsRDD[536] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "10-20 20:33:40.548 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_665 stored as values in memory (estimated size 132.0 KiB, free 428.7 MiB)\n",
      "10-20 20:33:40.550 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_665_piece0 stored as bytes in memory (estimated size 42.6 KiB, free 428.6 MiB)\n",
      "10-20 20:33:40.550 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_665_piece0 in memory on 5b5a8eb7561c:44751 (size: 42.6 KiB, free: 430.3 MiB)\n",
      "10-20 20:33:40.554 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 665 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:40.554 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 353 (MapPartitionsRDD[536] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:40.554 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 353.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:40.555 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 353.0 (TID 349) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:40.555 172.17.0.2:54321      18300   (TID 349)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 353.0 (TID 349)\n",
      "10-20 20:33:40.561 172.17.0.2:54321      18300   (TID 349)  INFO org.apache.spark.storage.BlockManager: Found block rdd_454_0 locally\n",
      "10-20 20:33:40.568 172.17.0.2:54321      18300   (TID 349)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 353.0 (TID 349). 3544 bytes result sent to driver\n",
      "10-20 20:33:40.569 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 353.0 (TID 349) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:40.569 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 353.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:40.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 353 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "10-20 20:33:40.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 321 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:40.570 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 353: Stage finished\n",
      "10-20 20:33:40.570 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 321 finished: treeAggregate at RDDLossFunction.scala:61, took 0.029103 s\n",
      "10-20 20:33:40.570 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(664) (from destroy at RDDLossFunction.scala:68)\n",
      "10-20 20:33:40.571 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Step Size: 1.000\n",
      "10-20 20:33:40.571 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Val and Grad Norm: 0.311828 (rel: 2.36e-07) 0.000100878\n",
      "10-20 20:33:40.571 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_664_piece0 on 5b5a8eb7561c:44751 in memory (size: 994.0 B, free: 430.3 MiB)\n",
      "10-20 20:33:40.572 172.17.0.2:54321      18300    Thread-4  INFO breeze.optimize.LBFGS: Converged because function values converged\n",
      "10-20 20:33:40.573 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 454 from persistence list\n",
      "10-20 20:33:40.573 172.17.0.2:54321      18300  ad-pool-93  INFO org.apache.spark.storage.BlockManager: Removing RDD 454\n",
      "10-20 20:33:40.573 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(501) (from destroy at LogisticRegression.scala:975)\n",
      "10-20 20:33:40.574 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_501_piece0 on 5b5a8eb7561c:44751 in memory (size: 860.0 B, free: 434.0 MiB)\n",
      "10-20 20:33:40.686 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:40.687 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:40.688 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:40.716 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_666 stored as values in memory (estimated size 176.1 KiB, free 432.1 MiB)\n",
      "10-20 20:33:40.741 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_661_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.0 MiB)\n",
      "10-20 20:33:40.742 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_666_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.1 MiB)\n",
      "10-20 20:33:40.742 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_666_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.0 MiB)\n",
      "10-20 20:33:40.743 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 666 from rdd at ClassificationSummary.scala:58\n",
      "10-20 20:33:40.743 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_659_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.0 MiB)\n",
      "10-20 20:33:40.745 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_655_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.1 MiB)\n",
      "10-20 20:33:40.746 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_651_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.1 MiB)\n",
      "10-20 20:33:40.746 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_657_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.1 MiB)\n",
      "10-20 20:33:40.746 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:40.747 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_653_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:40.748 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_663_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:40.749 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_665_piece0 on 5b5a8eb7561c:44751 in memory (size: 42.6 KiB, free: 434.3 MiB)\n",
      "10-20 20:33:40.815 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:40.815 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:40.815 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:40.908 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 67.124262 ms\n",
      "10-20 20:33:40.910 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_667 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 20:33:40.917 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_667_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:33:40.917 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_667_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:40.918 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 667 from rdd at ClassificationSummary.scala:191\n",
      "10-20 20:33:40.920 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:40.961 172.17.0.2:54321      18300  ad-pool-39  INFO org.apache.spark.storage.BlockManager: Removing RDD 454\n",
      "Metric name: areaUnderROC\n",
      "10-20 20:33:41.969 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:41.969 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:41.970 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:42.002 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_668 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:33:42.015 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_668_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)\n",
      "10-20 20:33:42.015 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_668_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.016 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 668 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:33:42.016 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:42.040 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 559 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 25\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 560 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 24\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 322 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 356 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 355)\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 355)\n",
      "10-20 20:33:42.041 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 354 (MapPartitionsRDD[559] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:33:42.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_669 stored as values in memory (estimated size 145.6 KiB, free 432.9 MiB)\n",
      "10-20 20:33:42.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_669_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 432.8 MiB)\n",
      "10-20 20:33:42.047 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_669_piece0 in memory on 5b5a8eb7561c:44751 (size: 49.2 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 669 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:42.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 354 (MapPartitionsRDD[559] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:42.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 354.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:42.048 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 354.0 (TID 350) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:42.049 172.17.0.2:54321      18300   (TID 350)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 354.0 (TID 350)\n",
      "10-20 20:33:42.072 172.17.0.2:54321      18300   (TID 350)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:33:42.228 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_498_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.229 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_499_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.536 172.17.0.2:54321      18300   (TID 350)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 354.0 (TID 350). 2133 bytes result sent to driver\n",
      "10-20 20:33:42.537 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 354.0 (TID 350) in 489 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:42.537 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 354.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:42.537 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 354 (map at BinaryClassificationMetrics.scala:48) finished in 0.495 s\n",
      "10-20 20:33:42.537 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:42.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:42.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 356, ShuffleMapStage 355)\n",
      "10-20 20:33:42.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:42.538 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 355 (ShuffledRDD[560] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:33:42.539 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_670 stored as values in memory (estimated size 5.1 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.550 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_670_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.550 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_670_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 670 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:42.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 355 (ShuffledRDD[560] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:42.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 355.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:42.552 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 355.0 (TID 351) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:42.555 172.17.0.2:54321      18300   (TID 351)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 355.0 (TID 351)\n",
      "10-20 20:33:42.557 172.17.0.2:54321      18300   (TID 351)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:42.557 172.17.0.2:54321      18300   (TID 351)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:42.599 172.17.0.2:54321      18300   (TID 351)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 355.0 (TID 351). 1462 bytes result sent to driver\n",
      "10-20 20:33:42.600 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 355.0 (TID 351) in 47 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:42.600 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 355.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:42.600 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 355 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.061 s\n",
      "10-20 20:33:42.600 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:42.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:42.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 356)\n",
      "10-20 20:33:42.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:42.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 356 (ShuffledRDD[561] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:33:42.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_671 stored as values in memory (estimated size 3.9 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.602 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_671_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.602 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_671_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 671 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:42.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 356 (ShuffledRDD[561] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:42.603 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 356.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:42.604 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 356.0 (TID 352) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:42.605 172.17.0.2:54321      18300   (TID 352)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 356.0 (TID 352)\n",
      "10-20 20:33:42.606 172.17.0.2:54321      18300   (TID 352)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:42.606 172.17.0.2:54321      18300   (TID 352)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:42.638 172.17.0.2:54321      18300   (TID 352)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 356.0 (TID 352). 1305 bytes result sent to driver\n",
      "10-20 20:33:42.638 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 356.0 (TID 352) in 34 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:42.639 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 356.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:42.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 356 (count at BinaryClassificationMetrics.scala:197) finished in 0.038 s\n",
      "10-20 20:33:42.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 322 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:42.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 356: Stage finished\n",
      "10-20 20:33:42.639 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 322 finished: count at BinaryClassificationMetrics.scala:197, took 0.599150 s\n",
      "10-20 20:33:42.647 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:33:42.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 323 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:33:42.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 359 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:33:42.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 358)\n",
      "10-20 20:33:42.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:42.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 359 (MapPartitionsRDD[564] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:33:42.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_672 stored as values in memory (estimated size 5.6 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_672_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.650 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_672_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 672 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:42.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 359 (MapPartitionsRDD[564] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:42.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 359.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:42.651 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 359.0 (TID 353) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:42.652 172.17.0.2:54321      18300   (TID 353)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 359.0 (TID 353)\n",
      "10-20 20:33:42.653 172.17.0.2:54321      18300   (TID 353)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:42.653 172.17.0.2:54321      18300   (TID 353)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:42.686 172.17.0.2:54321      18300   (TID 353)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 359.0 (TID 353). 1448 bytes result sent to driver\n",
      "10-20 20:33:42.687 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 359.0 (TID 353) in 36 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:42.687 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 359.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:42.687 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 359 (collect at BinaryClassificationMetrics.scala:237) finished in 0.039 s\n",
      "10-20 20:33:42.688 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 323 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:42.688 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 359: Stage finished\n",
      "10-20 20:33:42.689 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 323 finished: collect at BinaryClassificationMetrics.scala:237, took 0.041374 s\n",
      "10-20 20:33:42.689 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 1552.0, numNeg: 4933.0}\n",
      "10-20 20:33:42.697 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:33:42.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 324 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:33:42.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 362 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:33:42.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 361)\n",
      "10-20 20:33:42.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:42.698 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 362 (MapPartitionsRDD[569] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:33:42.699 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_673 stored as values in memory (estimated size 7.2 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.701 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_673_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.2 MiB)\n",
      "10-20 20:33:42.701 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_673_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.702 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 673 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:42.702 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 362 (MapPartitionsRDD[569] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:42.702 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 362.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:42.703 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 362.0 (TID 354) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:42.703 172.17.0.2:54321      18300   (TID 354)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 362.0 (TID 354)\n",
      "10-20 20:33:42.706 172.17.0.2:54321      18300   (TID 354)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:42.706 172.17.0.2:54321      18300   (TID 354)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:42.784 172.17.0.2:54321      18300   (TID 354)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_565_0 stored as values in memory (estimated size 82.4 KiB, free 433.1 MiB)\n",
      "10-20 20:33:42.785 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_565_0 in memory on 5b5a8eb7561c:44751 (size: 82.4 KiB, free: 434.1 MiB)\n",
      "10-20 20:33:42.796 172.17.0.2:54321      18300   (TID 354)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 362.0 (TID 354). 1524 bytes result sent to driver\n",
      "10-20 20:33:42.797 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 362.0 (TID 354) in 94 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:42.797 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 362.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:42.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 362 (collect at AreaUnderCurve.scala:44) finished in 0.098 s\n",
      "10-20 20:33:42.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 324 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:42.797 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 362: Stage finished\n",
      "10-20 20:33:42.798 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 324 finished: collect at AreaUnderCurve.scala:44, took 0.100210 s\n",
      "10-20 20:33:42.798 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 565 from persistence list\n",
      "10-20 20:33:42.799 172.17.0.2:54321      18300  ad-pool-63  INFO org.apache.spark.storage.BlockManager: Removing RDD 565\n",
      "CV Metric value: 0.8975269905392071\n",
      "10-20 20:33:42.847 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:33:42.848 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:33:42.848 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:33:42.872 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_674 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:33:42.878 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_674_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)\n",
      "10-20 20:33:42.878 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_674_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.879 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 674 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:33:42.880 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 577 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 27\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 578 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 26\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 325 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 365 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 364)\n",
      "10-20 20:33:42.903 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 364)\n",
      "10-20 20:33:42.904 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 363 (MapPartitionsRDD[577] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:33:42.922 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_675 stored as values in memory (estimated size 138.2 KiB, free 432.8 MiB)\n",
      "10-20 20:33:42.936 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_675_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 432.8 MiB)\n",
      "10-20 20:33:42.936 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_670_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.936 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_675_piece0 in memory on 5b5a8eb7561c:44751 (size: 47.0 KiB, free: 434.1 MiB)\n",
      "10-20 20:33:42.938 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 675 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:42.938 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_669_piece0 on 5b5a8eb7561c:44751 in memory (size: 49.2 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.938 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 363 (MapPartitionsRDD[577] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:42.938 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 363.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:42.939 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_671_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.940 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 363.0 (TID 355) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4854 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:42.941 172.17.0.2:54321      18300   (TID 355)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 363.0 (TID 355)\n",
      "10-20 20:33:42.942 172.17.0.2:54321      18300  d-pool-102  INFO org.apache.spark.storage.BlockManager: Removing RDD 565\n",
      "10-20 20:33:42.943 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_668_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.948 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_672_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.950 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_673_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:42.962 172.17.0.2:54321      18300   (TID 355)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:33:43.474 172.17.0.2:54321      18300   (TID 355)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 363.0 (TID 355). 1861 bytes result sent to driver\n",
      "10-20 20:33:43.475 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 363.0 (TID 355) in 535 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:43.475 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 363.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:43.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 363 (map at BinaryClassificationMetrics.scala:48) finished in 0.571 s\n",
      "10-20 20:33:43.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:43.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:43.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 365, ShuffleMapStage 364)\n",
      "10-20 20:33:43.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:43.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 364 (ShuffledRDD[578] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:33:43.477 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_676 stored as values in memory (estimated size 5.1 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.490 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_676_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.490 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_676_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:43.490 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 676 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:43.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 364 (ShuffledRDD[578] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:43.491 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 364.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:43.491 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 364.0 (TID 356) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:43.492 172.17.0.2:54321      18300   (TID 356)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 364.0 (TID 356)\n",
      "10-20 20:33:43.493 172.17.0.2:54321      18300   (TID 356)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:43.493 172.17.0.2:54321      18300   (TID 356)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:43.558 172.17.0.2:54321      18300   (TID 356)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 364.0 (TID 356). 1462 bytes result sent to driver\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 364.0 (TID 356) in 68 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 364.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 364 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.083 s\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 365)\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:33:43.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 365 (ShuffledRDD[579] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:33:43.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_677 stored as values in memory (estimated size 3.9 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_677_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.561 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_677_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:43.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 677 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:43.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 365 (ShuffledRDD[579] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:43.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 365.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:43.563 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 365.0 (TID 357) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:43.563 172.17.0.2:54321      18300   (TID 357)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 365.0 (TID 357)\n",
      "10-20 20:33:43.566 172.17.0.2:54321      18300   (TID 357)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:43.566 172.17.0.2:54321      18300   (TID 357)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:43.624 172.17.0.2:54321      18300   (TID 357)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 365.0 (TID 357). 1305 bytes result sent to driver\n",
      "10-20 20:33:43.625 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 365.0 (TID 357) in 63 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:43.625 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 365.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:43.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 365 (count at BinaryClassificationMetrics.scala:197) finished in 0.065 s\n",
      "10-20 20:33:43.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 325 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:43.626 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 365: Stage finished\n",
      "10-20 20:33:43.626 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 325 finished: count at BinaryClassificationMetrics.scala:197, took 0.723041 s\n",
      "10-20 20:33:43.635 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:33:43.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 326 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:33:43.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 368 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:33:43.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 367)\n",
      "10-20 20:33:43.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:43.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 368 (MapPartitionsRDD[582] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:33:43.637 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_678 stored as values in memory (estimated size 5.6 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.638 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_678_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.638 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_678_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:43.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 678 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:43.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (MapPartitionsRDD[582] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:43.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 368.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:43.639 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 368.0 (TID 358) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:43.640 172.17.0.2:54321      18300   (TID 358)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 368.0 (TID 358)\n",
      "10-20 20:33:43.643 172.17.0.2:54321      18300   (TID 358)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:43.643 172.17.0.2:54321      18300   (TID 358)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:43.727 172.17.0.2:54321      18300   (TID 358)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 368.0 (TID 358). 1448 bytes result sent to driver\n",
      "10-20 20:33:43.727 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 368.0 (TID 358) in 88 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:43.728 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:43.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 368 (collect at BinaryClassificationMetrics.scala:237) finished in 0.091 s\n",
      "10-20 20:33:43.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 326 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:43.728 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 368: Stage finished\n",
      "10-20 20:33:43.728 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 326 finished: collect at BinaryClassificationMetrics.scala:237, took 0.093409 s\n",
      "10-20 20:33:43.729 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 3846.0, numNeg: 12436.0}\n",
      "10-20 20:33:43.742 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:33:43.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 327 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:33:43.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 371 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:33:43.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 370)\n",
      "10-20 20:33:43.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:33:43.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 371 (MapPartitionsRDD[587] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:33:43.745 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_679 stored as values in memory (estimated size 7.2 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.746 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_679_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.2 MiB)\n",
      "10-20 20:33:43.746 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_679_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:33:43.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 679 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:33:43.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 371 (MapPartitionsRDD[587] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:33:43.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 371.0 with 1 tasks resource profile 0\n",
      "10-20 20:33:43.748 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 371.0 (TID 359) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:33:43.749 172.17.0.2:54321      18300   (TID 359)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 371.0 (TID 359)\n",
      "10-20 20:33:43.752 172.17.0.2:54321      18300   (TID 359)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (234.8 KiB) non-empty blocks including 1 (234.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:33:43.753 172.17.0.2:54321      18300   (TID 359)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:33:43.830 172.17.0.2:54321      18300   (TID 359)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_583_0 stored as values in memory (estimated size 82.1 KiB, free 433.1 MiB)\n",
      "10-20 20:33:43.830 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_583_0 in memory on 5b5a8eb7561c:44751 (size: 82.1 KiB, free: 434.1 MiB)\n",
      "10-20 20:33:43.834 172.17.0.2:54321      18300   (TID 359)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 371.0 (TID 359). 1524 bytes result sent to driver\n",
      "10-20 20:33:43.835 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 371.0 (TID 359) in 87 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:33:43.835 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 371.0, whose tasks have all completed, from pool \n",
      "10-20 20:33:43.835 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 371 (collect at AreaUnderCurve.scala:44) finished in 0.091 s\n",
      "10-20 20:33:43.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 327 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:33:43.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 371: Stage finished\n",
      "10-20 20:33:43.836 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 327 finished: collect at AreaUnderCurve.scala:44, took 0.093688 s\n",
      "10-20 20:33:43.836 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 583 from persistence list\n",
      "10-20 20:33:43.837 172.17.0.2:54321      18300  ad-pool-94  INFO org.apache.spark.storage.BlockManager: Removing RDD 583\n",
      "Test Metric value: 0.903392807471707\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(labelCol='label', featuresCol='features')\n",
    "lr_stages = [imputer] + string_indexers + ohe_indexers + [vector_assembler] + [lr]\n",
    "pipeline = Pipeline().setStages(lr_stages)\n",
    "lr_model = pipeline.fit(train_df)\n",
    "\n",
    "val_df_pred = lr_model.transform(val_df)\n",
    "test_df_pred = lr_model.transform(test_df)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'Metric name: {evaluator.getMetricName()}')\n",
    "print(f'CV Metric value: {evaluator.evaluate(val_df_pred)}')\n",
    "print(f'Test Metric value: {evaluator.evaluate(test_df_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d594e-6bd8-4f7e-a5f3-642545d62cf7",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ee68b36-766c-4f98-b7d2-542a6d3584f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:35:01.097 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:01.097 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:01.097 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:01.121 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_680 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:35:01.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_680_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)\n",
      "10-20 20:35:01.139 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_680_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.140 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 680 from head at Imputer.scala:169\n",
      "10-20 20:35:01.141 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:01.143 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_678_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.155 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:169\n",
      "10-20 20:35:01.156 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 591 (head at Imputer.scala:169) as input to shuffle 28\n",
      "10-20 20:35:01.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 328 (head at Imputer.scala:169) with 1 output partitions\n",
      "10-20 20:35:01.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 373 (head at Imputer.scala:169)\n",
      "10-20 20:35:01.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 372)\n",
      "10-20 20:35:01.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 372)\n",
      "10-20 20:35:01.157 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 372 (MapPartitionsRDD[591] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:35:01.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_681 stored as values in memory (estimated size 54.3 KiB, free 432.9 MiB)\n",
      "10-20 20:35:01.160 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_681_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 432.9 MiB)\n",
      "10-20 20:35:01.160 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_681_piece0 in memory on 5b5a8eb7561c:44751 (size: 22.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 681 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 372 (MapPartitionsRDD[591] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:01.162 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:01.162 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 372.0 (TID 360) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.165 172.17.0.2:54321      18300   (TID 360)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 372.0 (TID 360)\n",
      "10-20 20:35:01.172 172.17.0.2:54321      18300   (TID 360)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:01.198 172.17.0.2:54321      18300  d-pool-113  INFO org.apache.spark.storage.BlockManager: Removing RDD 583\n",
      "10-20 20:35:01.209 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_675_piece0 on 5b5a8eb7561c:44751 in memory (size: 47.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.212 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_676_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.219 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_677_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.222 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_674_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.226 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_679_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.358 172.17.0.2:54321      18300   (TID 360)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 372.0 (TID 360). 2689 bytes result sent to driver\n",
      "10-20 20:35:01.358 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 372.0 (TID 360) in 196 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:01.358 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:01.358 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 372 (head at Imputer.scala:169) finished in 0.200 s\n",
      "10-20 20:35:01.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:01.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:01.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 373)\n",
      "10-20 20:35:01.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:01.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 373 (MapPartitionsRDD[594] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:35:01.359 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_682 stored as values in memory (estimated size 19.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_682_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.360 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_682_piece0 in memory on 5b5a8eb7561c:44751 (size: 7.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.360 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 682 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 373 (MapPartitionsRDD[594] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:01.361 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 373.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:01.361 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 373.0 (TID 361) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.362 172.17.0.2:54321      18300   (TID 361)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 373.0 (TID 361)\n",
      "10-20 20:35:01.363 172.17.0.2:54321      18300   (TID 361)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:01.363 172.17.0.2:54321      18300   (TID 361)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:01.364 172.17.0.2:54321      18300   (TID 361)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 373.0 (TID 361). 2638 bytes result sent to driver\n",
      "10-20 20:35:01.365 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 373.0 (TID 361) in 4 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:01.365 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 373.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:01.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 373 (head at Imputer.scala:169) finished in 0.006 s\n",
      "10-20 20:35:01.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 328 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:01.365 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 373: Stage finished\n",
      "10-20 20:35:01.365 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 328 finished: head at Imputer.scala:169, took 0.209836 s\n",
      "10-20 20:35:01.392 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:35:01.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 329 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 20:35:01.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 374 (head at Imputer.scala:258)\n",
      "10-20 20:35:01.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:35:01.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:01.392 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 374 (MapPartitionsRDD[598] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:35:01.398 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_683 stored as values in memory (estimated size 10.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.398 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_683_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.398 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_683_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.399 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 683 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 374 (MapPartitionsRDD[598] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:01.400 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 374.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:01.400 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 374.0 (TID 362) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.401 172.17.0.2:54321      18300   (TID 362)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 374.0 (TID 362)\n",
      "10-20 20:35:01.402 172.17.0.2:54321      18300   (TID 362)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 374.0 (TID 362). 1304 bytes result sent to driver\n",
      "10-20 20:35:01.403 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 374.0 (TID 362) in 3 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:01.403 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 374.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:01.403 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 374 (head at Imputer.scala:258) finished in 0.011 s\n",
      "10-20 20:35:01.403 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 329 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:01.403 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 374: Stage finished\n",
      "10-20 20:35:01.403 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 329 finished: head at Imputer.scala:258, took 0.011841 s\n",
      "10-20 20:35:01.406 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:35:01.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 330 (head at Imputer.scala:258) with 3 output partitions\n",
      "10-20 20:35:01.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 375 (head at Imputer.scala:258)\n",
      "10-20 20:35:01.407 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:35:01.407 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:01.407 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 375 (MapPartitionsRDD[598] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:35:01.407 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_684 stored as values in memory (estimated size 10.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.408 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_684_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.408 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_684_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.408 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 684 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.408 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 3 missing tasks from ResultStage 375 (MapPartitionsRDD[598] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(1, 2, 3))\n",
      "10-20 20:35:01.408 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 375.0 with 3 tasks resource profile 0\n",
      "10-20 20:35:01.409 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 375.0 (TID 363) (5b5a8eb7561c, executor driver, partition 1, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.409 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 375.0 (TID 364) (5b5a8eb7561c, executor driver, partition 2, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.409 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 375.0 (TID 365) (5b5a8eb7561c, executor driver, partition 3, PROCESS_LOCAL, 4717 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.409 172.17.0.2:54321      18300   (TID 363)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 375.0 (TID 363)\n",
      "10-20 20:35:01.412 172.17.0.2:54321      18300   (TID 364)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 375.0 (TID 364)\n",
      "10-20 20:35:01.413 172.17.0.2:54321      18300   (TID 363)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 375.0 (TID 363). 1304 bytes result sent to driver\n",
      "10-20 20:35:01.413 172.17.0.2:54321      18300   (TID 364)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 375.0 (TID 364). 1261 bytes result sent to driver\n",
      "10-20 20:35:01.413 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 375.0 (TID 363) in 4 ms on 5b5a8eb7561c (executor driver) (1/3)\n",
      "10-20 20:35:01.414 172.17.0.2:54321      18300   (TID 365)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 375.0 (TID 365)\n",
      "10-20 20:35:01.414 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 375.0 (TID 364) in 5 ms on 5b5a8eb7561c (executor driver) (2/3)\n",
      "10-20 20:35:01.417 172.17.0.2:54321      18300   (TID 365)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 375.0 (TID 365). 1357 bytes result sent to driver\n",
      "10-20 20:35:01.417 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 375.0 (TID 365) in 8 ms on 5b5a8eb7561c (executor driver) (3/3)\n",
      "10-20 20:35:01.418 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 375.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:01.418 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 375 (head at Imputer.scala:258) finished in 0.011 s\n",
      "10-20 20:35:01.418 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 330 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:01.418 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 375: Stage finished\n",
      "10-20 20:35:01.418 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 330 finished: head at Imputer.scala:258, took 0.012131 s\n",
      "10-20 20:35:01.450 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:01.450 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:01.450 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:01.457 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_685 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:01.467 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_680_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:01.471 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_685_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.471 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_685_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.484 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 685 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:01.484 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:01.497 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_683_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.502 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:01.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 603 (collect at StringIndexer.scala:204) as input to shuffle 29\n",
      "10-20 20:35:01.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 331 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:01.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 377 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:01.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 376)\n",
      "10-20 20:35:01.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 376)\n",
      "10-20 20:35:01.503 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 376 (MapPartitionsRDD[603] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:01.504 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_686 stored as values in memory (estimated size 35.3 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.505 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_686_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.2 MiB)\n",
      "10-20 20:35:01.505 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_686_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.505 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 686 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.505 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 376 (MapPartitionsRDD[603] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:01.506 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 376.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:01.506 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 376.0 (TID 366) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.506 172.17.0.2:54321      18300   (TID 366)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 376.0 (TID 366)\n",
      "10-20 20:35:01.520 172.17.0.2:54321      18300   (TID 366)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:01.532 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_682_piece0 on 5b5a8eb7561c:44751 in memory (size: 7.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.535 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_681_piece0 on 5b5a8eb7561c:44751 in memory (size: 22.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.546 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_684_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.710 172.17.0.2:54321      18300   (TID 366)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 376.0 (TID 366). 2468 bytes result sent to driver\n",
      "10-20 20:35:01.710 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 376.0 (TID 366) in 204 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:01.710 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 376.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:01.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 376 (collect at StringIndexer.scala:204) finished in 0.207 s\n",
      "10-20 20:35:01.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:01.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:01.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 377)\n",
      "10-20 20:35:01.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:01.711 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 377 (MapPartitionsRDD[606] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:01.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_687 stored as values in memory (estimated size 26.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.712 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_687_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:01.713 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_687_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 687 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 377 (MapPartitionsRDD[606] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:01.713 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 377.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:01.714 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 377.0 (TID 367) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.714 172.17.0.2:54321      18300   (TID 367)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 377.0 (TID 367)\n",
      "10-20 20:35:01.717 172.17.0.2:54321      18300   (TID 367)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:01.717 172.17.0.2:54321      18300   (TID 367)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:01.726 172.17.0.2:54321      18300   (TID 367)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 377.0 (TID 367). 3904 bytes result sent to driver\n",
      "10-20 20:35:01.727 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 377.0 (TID 367) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:01.727 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 377.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:01.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 377 (collect at StringIndexer.scala:204) finished in 0.016 s\n",
      "10-20 20:35:01.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 331 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:01.727 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 377: Stage finished\n",
      "10-20 20:35:01.727 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 331 finished: collect at StringIndexer.scala:204, took 0.224734 s\n",
      "10-20 20:35:01.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:01.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:01.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:01.800 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_688 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:01.812 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_686_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:01.815 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_688_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:35:01.815 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_687_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:01.815 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_688_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.816 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 688 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:01.816 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:01.826 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_685_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:01.826 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:01.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 611 (collect at StringIndexer.scala:204) as input to shuffle 30\n",
      "10-20 20:35:01.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 332 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:01.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 379 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:01.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 378)\n",
      "10-20 20:35:01.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 378)\n",
      "10-20 20:35:01.827 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 378 (MapPartitionsRDD[611] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:01.829 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_689 stored as values in memory (estimated size 35.3 KiB, free 433.4 MiB)\n",
      "10-20 20:35:01.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_689_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.4 MiB)\n",
      "10-20 20:35:01.830 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_689_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:01.830 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 689 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:01.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 378 (MapPartitionsRDD[611] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:01.831 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 378.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:01.831 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 378.0 (TID 368) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:01.832 172.17.0.2:54321      18300   (TID 368)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 378.0 (TID 368)\n",
      "10-20 20:35:01.841 172.17.0.2:54321      18300   (TID 368)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:02.058 172.17.0.2:54321      18300   (TID 368)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 378.0 (TID 368). 2468 bytes result sent to driver\n",
      "10-20 20:35:02.059 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 378.0 (TID 368) in 228 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.059 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 378.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 378 (collect at StringIndexer.scala:204) finished in 0.231 s\n",
      "10-20 20:35:02.059 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:02.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:02.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 379)\n",
      "10-20 20:35:02.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:02.060 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 379 (MapPartitionsRDD[614] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.061 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_690 stored as values in memory (estimated size 26.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.061 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_690_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.061 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_690_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 690 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:02.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 379 (MapPartitionsRDD[614] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:02.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 379.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:02.063 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 379.0 (TID 369) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:02.063 172.17.0.2:54321      18300   (TID 369)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 379.0 (TID 369)\n",
      "10-20 20:35:02.066 172.17.0.2:54321      18300   (TID 369)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:02.066 172.17.0.2:54321      18300   (TID 369)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:02.076 172.17.0.2:54321      18300   (TID 369)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 379.0 (TID 369). 3956 bytes result sent to driver\n",
      "10-20 20:35:02.077 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 379.0 (TID 369) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.077 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 379 (collect at StringIndexer.scala:204) finished in 0.017 s\n",
      "10-20 20:35:02.077 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 332 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:02.078 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 379: Stage finished\n",
      "10-20 20:35:02.078 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 332 finished: collect at StringIndexer.scala:204, took 0.251394 s\n",
      "10-20 20:35:02.127 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:02.127 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:02.127 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:02.136 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_691 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.151 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_689_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:02.154 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_691_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:35:02.154 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_691_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.155 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 691 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:02.155 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:02.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:02.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 619 (collect at StringIndexer.scala:204) as input to shuffle 31\n",
      "10-20 20:35:02.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 333 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:02.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 381 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:02.164 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)\n",
      "10-20 20:35:02.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 380)\n",
      "10-20 20:35:02.165 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 380 (MapPartitionsRDD[619] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.166 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_692 stored as values in memory (estimated size 35.3 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.166 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_692_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.167 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_692_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.167 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 692 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:02.167 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 380 (MapPartitionsRDD[619] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:02.167 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 380.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:02.168 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 380.0 (TID 370) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:02.168 172.17.0.2:54321      18300   (TID 370)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 380.0 (TID 370)\n",
      "10-20 20:35:02.174 172.17.0.2:54321      18300   (TID 370)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:02.181 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_690_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.199 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_688_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.372 172.17.0.2:54321      18300   (TID 370)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 380.0 (TID 370). 2468 bytes result sent to driver\n",
      "10-20 20:35:02.377 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 380.0 (TID 370) in 209 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.377 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 380.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 380 (collect at StringIndexer.scala:204) finished in 0.213 s\n",
      "10-20 20:35:02.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:02.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:02.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 381)\n",
      "10-20 20:35:02.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:02.378 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 381 (MapPartitionsRDD[622] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.379 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_693 stored as values in memory (estimated size 26.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_693_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.380 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_693_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 693 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:02.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 381 (MapPartitionsRDD[622] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:02.380 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 381.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:02.381 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 381.0 (TID 371) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:02.381 172.17.0.2:54321      18300   (TID 371)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 381.0 (TID 371)\n",
      "10-20 20:35:02.384 172.17.0.2:54321      18300   (TID 371)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:02.384 172.17.0.2:54321      18300   (TID 371)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:02.392 172.17.0.2:54321      18300   (TID 371)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 381.0 (TID 371). 3884 bytes result sent to driver\n",
      "10-20 20:35:02.392 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 381.0 (TID 371) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.392 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 381.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.393 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 381 (collect at StringIndexer.scala:204) finished in 0.014 s\n",
      "10-20 20:35:02.393 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 333 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:02.393 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 381: Stage finished\n",
      "10-20 20:35:02.393 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 333 finished: collect at StringIndexer.scala:204, took 0.228508 s\n",
      "10-20 20:35:02.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:02.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:02.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:02.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_694 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.458 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_693_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.461 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_694_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:35:02.461 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_694_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.461 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 694 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:02.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:02.472 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_692_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.474 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_691_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:02.474 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:02.474 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 627 (collect at StringIndexer.scala:204) as input to shuffle 32\n",
      "10-20 20:35:02.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 334 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:02.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 383 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:02.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 382)\n",
      "10-20 20:35:02.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 382)\n",
      "10-20 20:35:02.475 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 382 (MapPartitionsRDD[627] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_695 stored as values in memory (estimated size 35.3 KiB, free 433.4 MiB)\n",
      "10-20 20:35:02.476 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_695_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.4 MiB)\n",
      "10-20 20:35:02.477 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_695_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.477 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 695 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:02.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 382 (MapPartitionsRDD[627] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:02.478 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 382.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:02.478 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 382.0 (TID 372) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:02.479 172.17.0.2:54321      18300   (TID 372)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 382.0 (TID 372)\n",
      "10-20 20:35:02.483 172.17.0.2:54321      18300   (TID 372)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:02.688 172.17.0.2:54321      18300   (TID 372)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 382.0 (TID 372). 2468 bytes result sent to driver\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 382.0 (TID 372) in 211 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 382.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 382 (collect at StringIndexer.scala:204) finished in 0.214 s\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 383)\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:02.689 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 383 (MapPartitionsRDD[630] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.690 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_696 stored as values in memory (estimated size 26.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.691 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_696_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.692 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_696_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 696 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:02.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 383 (MapPartitionsRDD[630] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:02.693 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 383.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:02.694 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 383.0 (TID 373) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:02.695 172.17.0.2:54321      18300   (TID 373)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 383.0 (TID 373)\n",
      "10-20 20:35:02.699 172.17.0.2:54321      18300   (TID 373)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (789.0 B) non-empty blocks including 1 (789.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:02.699 172.17.0.2:54321      18300   (TID 373)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:02.709 172.17.0.2:54321      18300   (TID 373)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 383.0 (TID 373). 4046 bytes result sent to driver\n",
      "10-20 20:35:02.710 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 383.0 (TID 373) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.710 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 383.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.710 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 383 (collect at StringIndexer.scala:204) finished in 0.020 s\n",
      "10-20 20:35:02.710 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 334 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:02.710 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 383: Stage finished\n",
      "10-20 20:35:02.710 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 334 finished: collect at StringIndexer.scala:204, took 0.236103 s\n",
      "10-20 20:35:02.764 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:02.764 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:02.765 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:02.773 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_697 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.787 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_697_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.787 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_697_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.789 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 697 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:02.789 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:02.790 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_696_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 635 (collect at StringIndexer.scala:204) as input to shuffle 33\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 335 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 385 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 384)\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 384)\n",
      "10-20 20:35:02.798 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 384 (MapPartitionsRDD[635] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.799 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_698 stored as values in memory (estimated size 35.3 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.800 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_698_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.1 MiB)\n",
      "10-20 20:35:02.800 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_698_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.800 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 698 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:02.800 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 384 (MapPartitionsRDD[635] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:02.800 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 384.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:02.801 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 384.0 (TID 374) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:02.801 172.17.0.2:54321      18300   (TID 374)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 384.0 (TID 374)\n",
      "10-20 20:35:02.807 172.17.0.2:54321      18300   (TID 374)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:02.821 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_695_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.839 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_694_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300   (TID 374)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 384.0 (TID 374). 2468 bytes result sent to driver\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 384.0 (TID 374) in 195 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 384 (collect at StringIndexer.scala:204) finished in 0.197 s\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 385)\n",
      "10-20 20:35:02.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:02.997 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 385 (MapPartitionsRDD[638] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:02.998 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_699 stored as values in memory (estimated size 26.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.999 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_699_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:02.999 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_699_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 699 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:03.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 385 (MapPartitionsRDD[638] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:03.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 385.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:03.000 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 385.0 (TID 375) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:03.001 172.17.0.2:54321      18300   (TID 375)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 385.0 (TID 375)\n",
      "10-20 20:35:03.003 172.17.0.2:54321      18300   (TID 375)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:03.003 172.17.0.2:54321      18300   (TID 375)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:03.011 172.17.0.2:54321      18300   (TID 375)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 385.0 (TID 375). 3855 bytes result sent to driver\n",
      "10-20 20:35:03.012 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 385.0 (TID 375) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:03.012 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:03.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 385 (collect at StringIndexer.scala:204) finished in 0.016 s\n",
      "10-20 20:35:03.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 335 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:03.013 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 385: Stage finished\n",
      "10-20 20:35:03.013 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 335 finished: collect at StringIndexer.scala:204, took 0.215187 s\n",
      "10-20 20:35:03.073 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:03.073 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:03.073 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:03.087 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_700 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.091 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_700_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.091 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_700_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.092 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 700 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:03.093 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:03.101 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:03.101 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 643 (collect at StringIndexer.scala:204) as input to shuffle 34\n",
      "10-20 20:35:03.101 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 336 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:03.102 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 387 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:03.102 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 386)\n",
      "10-20 20:35:03.102 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 386)\n",
      "10-20 20:35:03.102 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 386 (MapPartitionsRDD[643] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:03.103 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_701 stored as values in memory (estimated size 35.3 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.111 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_701_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.111 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_701_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 701 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:03.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 386 (MapPartitionsRDD[643] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:03.112 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 386.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:03.113 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 386.0 (TID 376) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:03.114 172.17.0.2:54321      18300   (TID 376)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 386.0 (TID 376)\n",
      "10-20 20:35:03.119 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_697_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.119 172.17.0.2:54321      18300   (TID 376)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:03.134 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_699_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.153 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_698_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.329 172.17.0.2:54321      18300   (TID 376)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 386.0 (TID 376). 2468 bytes result sent to driver\n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 386.0 (TID 376) in 216 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 386 (collect at StringIndexer.scala:204) finished in 0.228 s\n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 387)\n",
      "10-20 20:35:03.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:03.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 387 (MapPartitionsRDD[646] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:03.333 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_702 stored as values in memory (estimated size 26.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:03.334 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_702_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:03.334 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_702_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 702 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:03.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 387 (MapPartitionsRDD[646] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:03.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 387.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:03.336 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 387.0 (TID 377) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:03.336 172.17.0.2:54321      18300   (TID 377)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 387.0 (TID 377)\n",
      "10-20 20:35:03.340 172.17.0.2:54321      18300   (TID 377)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:03.340 172.17.0.2:54321      18300   (TID 377)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:03.351 172.17.0.2:54321      18300   (TID 377)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 387.0 (TID 377). 3863 bytes result sent to driver\n",
      "10-20 20:35:03.351 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 387.0 (TID 377) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:03.352 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:03.352 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 387 (collect at StringIndexer.scala:204) finished in 0.021 s\n",
      "10-20 20:35:03.352 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 336 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:03.352 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 387: Stage finished\n",
      "10-20 20:35:03.352 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 336 finished: collect at StringIndexer.scala:204, took 0.251275 s\n",
      "10-20 20:35:03.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:03.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:03.413 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:03.421 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_703 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.432 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_702_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.434 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_700_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:03.435 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_703_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.4 MiB)\n",
      "10-20 20:35:03.435 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_703_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.435 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 703 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:03.436 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:03.442 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_701_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:03.445 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:03.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 651 (collect at StringIndexer.scala:204) as input to shuffle 35\n",
      "10-20 20:35:03.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 337 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:03.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 389 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:03.446 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 388)\n",
      "10-20 20:35:03.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 388)\n",
      "10-20 20:35:03.447 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 388 (MapPartitionsRDD[651] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:03.448 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_704 stored as values in memory (estimated size 35.3 KiB, free 433.4 MiB)\n",
      "10-20 20:35:03.448 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_704_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.4 MiB)\n",
      "10-20 20:35:03.448 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_704_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 704 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:03.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 388 (MapPartitionsRDD[651] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:03.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 388.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:03.449 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 388.0 (TID 378) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:03.450 172.17.0.2:54321      18300   (TID 378)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 388.0 (TID 378)\n",
      "10-20 20:35:03.454 172.17.0.2:54321      18300   (TID 378)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:03.647 172.17.0.2:54321      18300   (TID 378)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 388.0 (TID 378). 2468 bytes result sent to driver\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 388.0 (TID 378) in 198 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 388 (collect at StringIndexer.scala:204) finished in 0.201 s\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 389)\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:03.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 389 (MapPartitionsRDD[654] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:03.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_705 stored as values in memory (estimated size 26.7 KiB, free 433.3 MiB)\n",
      "10-20 20:35:03.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_705_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:03.650 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_705_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 705 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:03.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 389 (MapPartitionsRDD[654] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:03.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 389.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:03.651 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 389.0 (TID 379) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:03.651 172.17.0.2:54321      18300   (TID 379)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 389.0 (TID 379)\n",
      "10-20 20:35:03.653 172.17.0.2:54321      18300   (TID 379)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:03.653 172.17.0.2:54321      18300   (TID 379)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:03.660 172.17.0.2:54321      18300   (TID 379)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 389.0 (TID 379). 3768 bytes result sent to driver\n",
      "10-20 20:35:03.661 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 389.0 (TID 379) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:03.661 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:03.661 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 389 (collect at StringIndexer.scala:204) finished in 0.013 s\n",
      "10-20 20:35:03.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 337 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:03.662 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 389: Stage finished\n",
      "10-20 20:35:03.662 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 337 finished: collect at StringIndexer.scala:204, took 0.216917 s\n",
      "10-20 20:35:03.709 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:03.710 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:03.710 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:03.718 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_706 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.723 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_706_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.723 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_706_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.724 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 706 from collect at StringIndexer.scala:204\n",
      "10-20 20:35:03.724 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:03.735 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:35:03.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 659 (collect at StringIndexer.scala:204) as input to shuffle 36\n",
      "10-20 20:35:03.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 338 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:35:03.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 391 (collect at StringIndexer.scala:204)\n",
      "10-20 20:35:03.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 390)\n",
      "10-20 20:35:03.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 390)\n",
      "10-20 20:35:03.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 390 (MapPartitionsRDD[659] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:03.738 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_707 stored as values in memory (estimated size 35.3 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_707_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.1 MiB)\n",
      "10-20 20:35:03.747 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_707_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.747 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_703_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.748 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 707 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:03.748 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 390 (MapPartitionsRDD[659] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:03.748 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 390.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:03.749 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 390.0 (TID 380) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:03.750 172.17.0.2:54321      18300   (TID 380)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 390.0 (TID 380)\n",
      "10-20 20:35:03.755 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_704_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:03.756 172.17.0.2:54321      18300   (TID 380)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:03.770 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_705_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:04.004 172.17.0.2:54321      18300   (TID 380)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 390.0 (TID 380). 2468 bytes result sent to driver\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 390.0 (TID 380) in 256 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 390.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 390 (collect at StringIndexer.scala:204) finished in 0.268 s\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 391)\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:04.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 391 (MapPartitionsRDD[662] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:35:04.007 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_708 stored as values in memory (estimated size 26.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:04.011 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_708_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:35:04.012 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_708_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:04.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 708 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:04.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 391 (MapPartitionsRDD[662] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:04.016 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 391.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:04.017 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 391.0 (TID 381) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:04.018 172.17.0.2:54321      18300   (TID 381)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 391.0 (TID 381)\n",
      "10-20 20:35:04.020 172.17.0.2:54321      18300   (TID 381)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (955.0 B) non-empty blocks including 1 (955.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:04.020 172.17.0.2:54321      18300   (TID 381)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:04.029 172.17.0.2:54321      18300   (TID 381)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 391.0 (TID 381). 4215 bytes result sent to driver\n",
      "10-20 20:35:04.030 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 391.0 (TID 381) in 14 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:04.030 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 391.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:04.031 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 391 (collect at StringIndexer.scala:204) finished in 0.025 s\n",
      "10-20 20:35:04.032 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 338 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:04.032 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 391: Stage finished\n",
      "10-20 20:35:04.032 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 338 finished: collect at StringIndexer.scala:204, took 0.296666 s\n",
      "10-20 20:35:04.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] Stage class: DecisionTreeClassifier\n",
      "10-20 20:35:04.412 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] Stage uid: DecisionTreeClassifier_f242a885acd5\n",
      "10-20 20:35:04.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:04.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:04.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:04.492 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_707_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:04.494 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_708_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:04.553 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 48.57811 ms\n",
      "10-20 20:35:04.554 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_709 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 20:35:04.567 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_706_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:04.570 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_709_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.4 MiB)\n",
      "10-20 20:35:04.570 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_709_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:35:04.570 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 709 from rdd at Instrumentation.scala:62\n",
      "10-20 20:35:04.571 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:04.584 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "10-20 20:35:04.629 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:04.639 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:04.640 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:04.683 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 30.011881 ms\n",
      "10-20 20:35:04.711 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 16.317601 ms\n",
      "10-20 20:35:04.712 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_710 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 20:35:04.718 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_710_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:35:04.718 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_710_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:04.719 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 710 from take at Classifier.scala:146\n",
      "10-20 20:35:04.721 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:04.737 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: take at Classifier.scala:146\n",
      "10-20 20:35:04.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 672 (take at Classifier.scala:146) as input to shuffle 37\n",
      "10-20 20:35:04.738 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 339 (take at Classifier.scala:146) with 1 output partitions\n",
      "10-20 20:35:04.738 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 393 (take at Classifier.scala:146)\n",
      "10-20 20:35:04.738 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 392)\n",
      "10-20 20:35:04.738 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 392)\n",
      "10-20 20:35:04.738 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 392 (MapPartitionsRDD[672] at take at Classifier.scala:146), which has no missing parents\n",
      "10-20 20:35:04.740 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_711 stored as values in memory (estimated size 35.9 KiB, free 433.2 MiB)\n",
      "10-20 20:35:04.741 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_711_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 433.2 MiB)\n",
      "10-20 20:35:04.741 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_711_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:04.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 711 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:04.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 392 (MapPartitionsRDD[672] at take at Classifier.scala:146) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:04.742 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:04.743 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 392.0 (TID 382) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:04.744 172.17.0.2:54321      18300   (TID 382)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 392.0 (TID 382)\n",
      "10-20 20:35:04.752 172.17.0.2:54321      18300   (TID 382)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:05.035 172.17.0.2:54321      18300   (TID 382)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 392.0 (TID 382). 2689 bytes result sent to driver\n",
      "10-20 20:35:05.035 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 392.0 (TID 382) in 292 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 392 (take at Classifier.scala:146) finished in 0.298 s\n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 393)\n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:05.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 393 (MapPartitionsRDD[675] at take at Classifier.scala:146), which has no missing parents\n",
      "10-20 20:35:05.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_712 stored as values in memory (estimated size 10.8 KiB, free 433.1 MiB)\n",
      "10-20 20:35:05.049 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_712_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 433.1 MiB)\n",
      "10-20 20:35:05.049 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_712_piece0 in memory on 5b5a8eb7561c:44751 (size: 5.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.050 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 712 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:05.050 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 393 (MapPartitionsRDD[675] at take at Classifier.scala:146) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:05.050 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 393.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:05.051 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 393.0 (TID 383) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:05.054 172.17.0.2:54321      18300   (TID 383)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 393.0 (TID 383)\n",
      "10-20 20:35:05.056 172.17.0.2:54321      18300   (TID 383)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:05.057 172.17.0.2:54321      18300   (TID 383)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:05.061 172.17.0.2:54321      18300   (TID 383)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 393.0 (TID 383). 2642 bytes result sent to driver\n",
      "10-20 20:35:05.061 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 393.0 (TID 383) in 10 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:05.061 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 393.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:05.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 393 (take at Classifier.scala:146) finished in 0.024 s\n",
      "10-20 20:35:05.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 339 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:05.062 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 393: Stage finished\n",
      "10-20 20:35:05.062 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 339 finished: take at Classifier.scala:146, took 0.325435 s\n",
      "10-20 20:35:05.067 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.272339 ms\n",
      "10-20 20:35:05.069 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.classification.DecisionTreeClassifier: org.apache.spark.ml.classification.DecisionTreeClassifier inferred 2 classes for labelCol=DecisionTreeClassifier_f242a885acd5__labelCol since numClasses was not specified in the column metadata.\n",
      "10-20 20:35:05.115 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:05.116 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:05.116 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:05.139 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_713 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:35:05.144 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_713_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:35:05.144 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_713_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.145 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 713 from rdd at Predictor.scala:81\n",
      "10-20 20:35:05.146 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:05.158 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] {\"numClasses\":2}\n",
      "10-20 20:35:05.158 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] {\"labelCol\":\"label\",\"featuresCol\":\"features\"}\n",
      "10-20 20:35:05.191 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: take at DecisionTreeMetadata.scala:119\n",
      "10-20 20:35:05.192 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 340 (take at DecisionTreeMetadata.scala:119) with 1 output partitions\n",
      "10-20 20:35:05.192 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 394 (take at DecisionTreeMetadata.scala:119)\n",
      "10-20 20:35:05.192 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:35:05.192 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:05.192 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 394 (MapPartitionsRDD[685] at map at DecisionTreeMetadata.scala:119), which has no missing parents\n",
      "10-20 20:35:05.197 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_714 stored as values in memory (estimated size 129.8 KiB, free 432.8 MiB)\n",
      "10-20 20:35:05.198 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_714_piece0 stored as bytes in memory (estimated size 41.6 KiB, free 432.8 MiB)\n",
      "10-20 20:35:05.199 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_714_piece0 in memory on 5b5a8eb7561c:44751 (size: 41.6 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:05.200 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 714 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:05.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 394 (MapPartitionsRDD[685] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:05.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 394.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:05.202 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 394.0 (TID 384) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:05.203 172.17.0.2:54321      18300   (TID 384)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 394.0 (TID 384)\n",
      "10-20 20:35:05.236 172.17.0.2:54321      18300   (TID 384)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:05.379 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_712_piece0 on 5b5a8eb7561c:44751 in memory (size: 5.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.396 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_711_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.424 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_710_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.443 172.17.0.2:54321      18300   (TID 384)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 394.0 (TID 384). 1839 bytes result sent to driver\n",
      "10-20 20:35:05.444 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 394.0 (TID 384) in 242 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:05.444 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 394.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:05.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 394 (take at DecisionTreeMetadata.scala:119) finished in 0.251 s\n",
      "10-20 20:35:05.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 340 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:05.444 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 394: Stage finished\n",
      "10-20 20:35:05.444 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 340 finished: take at DecisionTreeMetadata.scala:119, took 0.252791 s\n",
      "10-20 20:35:05.451 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125\n",
      "10-20 20:35:05.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 341 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions\n",
      "10-20 20:35:05.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 395 (aggregate at DecisionTreeMetadata.scala:125)\n",
      "10-20 20:35:05.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:35:05.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:05.451 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 395 (MapPartitionsRDD[684] at retag at RandomForest.scala:274), which has no missing parents\n",
      "10-20 20:35:05.454 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_715 stored as values in memory (estimated size 130.0 KiB, free 432.9 MiB)\n",
      "10-20 20:35:05.462 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_714_piece0 on 5b5a8eb7561c:44751 in memory (size: 41.6 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_715_piece0 stored as bytes in memory (estimated size 41.6 KiB, free 433.0 MiB)\n",
      "10-20 20:35:05.463 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_715_piece0 in memory on 5b5a8eb7561c:44751 (size: 41.6 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:05.463 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 715 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:05.463 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 395 (MapPartitionsRDD[684] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:05.464 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 395.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:05.464 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 395.0 (TID 385) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:05.464 172.17.0.2:54321      18300   (TID 385)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 395.0 (TID 385)\n",
      "10-20 20:35:05.474 172.17.0.2:54321      18300   (TID 385)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:05.980 172.17.0.2:54321      18300   (TID 385)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 395.0 (TID 385). 1954 bytes result sent to driver\n",
      "10-20 20:35:05.980 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 395.0 (TID 385) in 516 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:05.981 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 395.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:05.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 395 (aggregate at DecisionTreeMetadata.scala:125) finished in 0.529 s\n",
      "10-20 20:35:05.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 341 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:05.981 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 395: Stage finished\n",
      "10-20 20:35:05.981 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 341 finished: aggregate at DecisionTreeMetadata.scala:125, took 0.530446 s\n",
      "10-20 20:35:06.038 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:1054\n",
      "10-20 20:35:06.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 688 (flatMap at RandomForest.scala:1039) as input to shuffle 38\n",
      "10-20 20:35:06.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 342 (collectAsMap at RandomForest.scala:1054) with 1 output partitions\n",
      "10-20 20:35:06.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 397 (collectAsMap at RandomForest.scala:1054)\n",
      "10-20 20:35:06.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 396)\n",
      "10-20 20:35:06.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 396)\n",
      "10-20 20:35:06.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 396 (MapPartitionsRDD[688] at flatMap at RandomForest.scala:1039), which has no missing parents\n",
      "10-20 20:35:06.045 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_716 stored as values in memory (estimated size 136.5 KiB, free 432.9 MiB)\n",
      "10-20 20:35:06.046 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_716_piece0 stored as bytes in memory (estimated size 44.4 KiB, free 432.9 MiB)\n",
      "10-20 20:35:06.047 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_716_piece0 in memory on 5b5a8eb7561c:44751 (size: 44.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:06.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 716 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:06.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 396 (MapPartitionsRDD[688] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:06.047 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 396.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:06.048 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 396.0 (TID 386) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:06.049 172.17.0.2:54321      18300   (TID 386)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 396.0 (TID 386)\n",
      "10-20 20:35:06.090 172.17.0.2:54321      18300   (TID 386)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:06.359 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_715_piece0 on 5b5a8eb7561c:44751 in memory (size: 41.6 KiB, free: 434.2 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 396:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:35:06.903 172.17.0.2:54321      18300   (TID 386)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 396.0 (TID 386). 2133 bytes result sent to driver\n",
      "10-20 20:35:06.904 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 396.0 (TID 386) in 856 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:06.904 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:06.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 396 (flatMap at RandomForest.scala:1039) finished in 0.866 s\n",
      "10-20 20:35:06.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:06.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:06.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 397)\n",
      "10-20 20:35:06.905 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:06.906 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 397 (MapPartitionsRDD[690] at map at RandomForest.scala:1054), which has no missing parents\n",
      "10-20 20:35:06.907 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_717 stored as values in memory (estimated size 12.3 KiB, free 433.0 MiB)\n",
      "10-20 20:35:06.908 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_717_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 433.0 MiB)\n",
      "10-20 20:35:06.909 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_717_piece0 in memory on 5b5a8eb7561c:44751 (size: 5.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:06.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 717 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:06.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 397 (MapPartitionsRDD[690] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:06.910 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 397.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:06.911 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 397.0 (TID 387) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:06.912 172.17.0.2:54321      18300   (TID 387)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 397.0 (TID 387)\n",
      "10-20 20:35:06.923 172.17.0.2:54321      18300   (TID 387)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (99.6 KiB) non-empty blocks including 1 (99.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:06.924 172.17.0.2:54321      18300   (TID 387)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:06.965 172.17.0.2:54321      18300   (TID 387)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 397.0 (TID 387). 4543 bytes result sent to driver\n",
      "10-20 20:35:06.966 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 397.0 (TID 387) in 54 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:06.966 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 397.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:06.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 397 (collectAsMap at RandomForest.scala:1054) finished in 0.059 s\n",
      "10-20 20:35:06.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 342 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:06.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 397: Stage finished\n",
      "10-20 20:35:06.966 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 342 finished: collectAsMap at RandomForest.scala:1054, took 0.928037 s\n",
      "10-20 20:35:06.973 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_718 stored as values in memory (estimated size 6.4 KiB, free 433.0 MiB)\n",
      "10-20 20:35:06.974 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_718_piece0 stored as bytes in memory (estimated size 1038.0 B, free 433.0 MiB)\n",
      "10-20 20:35:06.974 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_718_piece0 in memory on 5b5a8eb7561c:44751 (size: 1038.0 B, free: 434.2 MiB)\n",
      "10-20 20:35:06.975 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 718 from broadcast at RandomForest.scala:293\n",
      "10-20 20:35:06.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] {\"numFeatures\":106}\n",
      "10-20 20:35:06.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] {\"numClasses\":2}\n",
      "10-20 20:35:06.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] {\"numExamples\":26076}\n",
      "10-20 20:35:06.979 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] {\"sumOfWeights\":26076.0}\n",
      "10-20 20:35:06.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_719 stored as values in memory (estimated size 40.0 B, free 433.0 MiB)\n",
      "10-20 20:35:06.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_719_piece0 stored as bytes in memory (estimated size 101.0 B, free 433.0 MiB)\n",
      "10-20 20:35:06.985 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_719_piece0 in memory on 5b5a8eb7561c:44751 (size: 101.0 B, free: 434.2 MiB)\n",
      "10-20 20:35:06.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 719 from broadcast at RandomForest.scala:622\n",
      "10-20 20:35:07.014 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 20:35:07.015 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 693 (mapPartitions at RandomForest.scala:644) as input to shuffle 39\n",
      "10-20 20:35:07.015 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 343 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 20:35:07.015 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 399 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 20:35:07.015 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 398)\n",
      "10-20 20:35:07.015 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 398)\n",
      "10-20 20:35:07.015 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 398 (MapPartitionsRDD[693] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 20:35:07.018 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_720 stored as values in memory (estimated size 138.5 KiB, free 432.9 MiB)\n",
      "10-20 20:35:07.028 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_720_piece0 stored as bytes in memory (estimated size 44.9 KiB, free 432.9 MiB)\n",
      "10-20 20:35:07.028 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_716_piece0 on 5b5a8eb7561c:44751 in memory (size: 44.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:07.028 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_720_piece0 in memory on 5b5a8eb7561c:44751 (size: 44.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:07.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 720 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:07.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 398 (MapPartitionsRDD[693] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:07.029 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 398.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:07.029 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_717_piece0 on 5b5a8eb7561c:44751 in memory (size: 5.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:07.030 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 398.0 (TID 388) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:07.031 172.17.0.2:54321      18300   (TID 388)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 398.0 (TID 388)\n",
      "10-20 20:35:07.047 172.17.0.2:54321      18300   (TID 388)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:35:07.639 172.17.0.2:54321      18300   (TID 388)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_692_0 stored as values in memory (estimated size 12.6 MiB, free 420.4 MiB)\n",
      "10-20 20:35:07.639 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_692_0 in memory on 5b5a8eb7561c:44751 (size: 12.6 MiB, free: 421.6 MiB)\n",
      "10-20 20:35:07.678 172.17.0.2:54321      18300   (TID 388)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 398.0 (TID 388). 2133 bytes result sent to driver\n",
      "10-20 20:35:07.679 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 398.0 (TID 388) in 649 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:07.679 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:07.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 398 (mapPartitions at RandomForest.scala:644) finished in 0.663 s\n",
      "10-20 20:35:07.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:07.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:07.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 399)\n",
      "10-20 20:35:07.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:07.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 399 (MapPartitionsRDD[695] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 20:35:07.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_721 stored as values in memory (estimated size 6.0 KiB, free 420.4 MiB)\n",
      "10-20 20:35:07.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_721_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 420.4 MiB)\n",
      "10-20 20:35:07.682 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_721_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.2 KiB, free: 421.6 MiB)\n",
      "10-20 20:35:07.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 721 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:07.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 399 (MapPartitionsRDD[695] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:07.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 399.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:07.683 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 399.0 (TID 389) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:07.685 172.17.0.2:54321      18300   (TID 389)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 399.0 (TID 389)\n",
      "10-20 20:35:07.687 172.17.0.2:54321      18300   (TID 389)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (6.9 KiB) non-empty blocks including 1 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:07.688 172.17.0.2:54321      18300   (TID 389)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:07.819 172.17.0.2:54321      18300   (TID 389)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 399.0 (TID 389). 2311 bytes result sent to driver\n",
      "10-20 20:35:07.820 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 399.0 (TID 389) in 137 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:07.820 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:07.820 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 399 (collectAsMap at RandomForest.scala:663) finished in 0.139 s\n",
      "10-20 20:35:07.820 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 343 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:07.820 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 399: Stage finished\n",
      "10-20 20:35:07.821 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 343 finished: collectAsMap at RandomForest.scala:663, took 0.806452 s\n",
      "10-20 20:35:07.821 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(719) (from destroy at RandomForest.scala:674)\n",
      "10-20 20:35:07.822 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_719_piece0 on 5b5a8eb7561c:44751 in memory (size: 101.0 B, free: 421.6 MiB)\n",
      "10-20 20:35:07.824 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_722 stored as values in memory (estimated size 40.0 B, free 420.4 MiB)\n",
      "10-20 20:35:07.825 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_722_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.4 MiB)\n",
      "10-20 20:35:07.825 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_722_piece0 in memory on 5b5a8eb7561c:44751 (size: 101.0 B, free: 421.6 MiB)\n",
      "10-20 20:35:07.825 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 722 from broadcast at RandomForest.scala:622\n",
      "10-20 20:35:07.835 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 20:35:07.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 696 (mapPartitions at RandomForest.scala:644) as input to shuffle 40\n",
      "10-20 20:35:07.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 344 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 20:35:07.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 401 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 20:35:07.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 400)\n",
      "10-20 20:35:07.836 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 400)\n",
      "10-20 20:35:07.837 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 400 (MapPartitionsRDD[696] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 20:35:07.839 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_723 stored as values in memory (estimated size 139.3 KiB, free 420.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:35:07.840 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_723_piece0 stored as bytes in memory (estimated size 45.4 KiB, free 420.2 MiB)\n",
      "10-20 20:35:07.841 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_723_piece0 in memory on 5b5a8eb7561c:44751 (size: 45.4 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:07.841 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 723 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:07.841 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 400 (MapPartitionsRDD[696] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:07.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 400.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:07.842 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 400.0 (TID 390) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:07.843 172.17.0.2:54321      18300   (TID 390)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 400.0 (TID 390)\n",
      "10-20 20:35:07.849 172.17.0.2:54321      18300   (TID 390)  INFO org.apache.spark.storage.BlockManager: Found block rdd_692_0 locally\n",
      "10-20 20:35:07.924 172.17.0.2:54321      18300   (TID 390)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 400.0 (TID 390). 2090 bytes result sent to driver\n",
      "10-20 20:35:07.925 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 400.0 (TID 390) in 83 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:07.925 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:07.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 400 (mapPartitions at RandomForest.scala:644) finished in 0.089 s\n",
      "10-20 20:35:07.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:07.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:07.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 401)\n",
      "10-20 20:35:07.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:07.926 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 401 (MapPartitionsRDD[698] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 20:35:07.927 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_724 stored as values in memory (estimated size 6.5 KiB, free 420.2 MiB)\n",
      "10-20 20:35:07.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_724_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 420.2 MiB)\n",
      "10-20 20:35:07.942 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_721_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.2 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:07.942 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_724_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.5 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:07.942 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 724 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:07.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 401 (MapPartitionsRDD[698] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:07.943 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 401.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:07.943 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 401.0 (TID 391) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:07.944 172.17.0.2:54321      18300   (TID 391)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 401.0 (TID 391)\n",
      "10-20 20:35:07.947 172.17.0.2:54321      18300   (TID 391)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (10.1 KiB) non-empty blocks including 1 (10.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:07.947 172.17.0.2:54321      18300   (TID 391)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:07.980 172.17.0.2:54321      18300   (TID 391)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 401.0 (TID 391). 2231 bytes result sent to driver\n",
      "10-20 20:35:07.984 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 401.0 (TID 391) in 41 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:07.984 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:07.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 401 (collectAsMap at RandomForest.scala:663) finished in 0.058 s\n",
      "10-20 20:35:07.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 344 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:07.984 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 401: Stage finished\n",
      "10-20 20:35:07.984 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 344 finished: collectAsMap at RandomForest.scala:663, took 0.148865 s\n",
      "10-20 20:35:07.985 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(722) (from destroy at RandomForest.scala:674)\n",
      "10-20 20:35:07.985 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_722_piece0 on 5b5a8eb7561c:44751 in memory (size: 101.0 B, free: 421.5 MiB)\n",
      "10-20 20:35:07.986 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_725 stored as values in memory (estimated size 40.0 B, free 420.2 MiB)\n",
      "10-20 20:35:07.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_725_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.2 MiB)\n",
      "10-20 20:35:07.987 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_725_piece0 in memory on 5b5a8eb7561c:44751 (size: 101.0 B, free: 421.5 MiB)\n",
      "10-20 20:35:07.987 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 725 from broadcast at RandomForest.scala:622\n",
      "10-20 20:35:07.999 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 20:35:07.999 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 699 (mapPartitions at RandomForest.scala:644) as input to shuffle 41\n",
      "10-20 20:35:08.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 345 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 20:35:08.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 403 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 20:35:08.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 402)\n",
      "10-20 20:35:08.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 402)\n",
      "10-20 20:35:08.000 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 402 (MapPartitionsRDD[699] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 20:35:08.003 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_726 stored as values in memory (estimated size 139.9 KiB, free 420.1 MiB)\n",
      "10-20 20:35:08.004 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_726_piece0 stored as bytes in memory (estimated size 45.7 KiB, free 420.0 MiB)\n",
      "10-20 20:35:08.005 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_726_piece0 in memory on 5b5a8eb7561c:44751 (size: 45.7 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:08.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 726 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:08.005 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 402 (MapPartitionsRDD[699] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:08.006 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:08.007 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 402.0 (TID 392) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:08.007 172.17.0.2:54321      18300   (TID 392)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 402.0 (TID 392)\n",
      "10-20 20:35:08.013 172.17.0.2:54321      18300   (TID 392)  INFO org.apache.spark.storage.BlockManager: Found block rdd_692_0 locally\n",
      "10-20 20:35:08.035 172.17.0.2:54321      18300   (TID 392)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 402.0 (TID 392). 2090 bytes result sent to driver\n",
      "10-20 20:35:08.036 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 402.0 (TID 392) in 30 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:08.036 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:08.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 402 (mapPartitions at RandomForest.scala:644) finished in 0.035 s\n",
      "10-20 20:35:08.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:08.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:08.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 403)\n",
      "10-20 20:35:08.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:08.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 403 (MapPartitionsRDD[701] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 20:35:08.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_727 stored as values in memory (estimated size 6.7 KiB, free 420.0 MiB)\n",
      "10-20 20:35:08.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_727_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 420.0 MiB)\n",
      "10-20 20:35:08.039 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_727_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.6 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:08.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 727 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:08.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 403 (MapPartitionsRDD[701] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:08.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 403.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:08.041 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 403.0 (TID 393) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:08.041 172.17.0.2:54321      18300   (TID 393)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 403.0 (TID 393)\n",
      "10-20 20:35:08.048 172.17.0.2:54321      18300   (TID 393)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (14.8 KiB) non-empty blocks including 1 (14.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:08.048 172.17.0.2:54321      18300   (TID 393)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:08.066 172.17.0.2:54321      18300   (TID 393)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 403.0 (TID 393). 2602 bytes result sent to driver\n",
      "10-20 20:35:08.067 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 403.0 (TID 393) in 26 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:08.067 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:08.067 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 403 (collectAsMap at RandomForest.scala:663) finished in 0.030 s\n",
      "10-20 20:35:08.067 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 345 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:08.067 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 403: Stage finished\n",
      "10-20 20:35:08.067 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 345 finished: collectAsMap at RandomForest.scala:663, took 0.068302 s\n",
      "10-20 20:35:08.068 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(725) (from destroy at RandomForest.scala:674)\n",
      "10-20 20:35:08.068 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_725_piece0 on 5b5a8eb7561c:44751 in memory (size: 101.0 B, free: 421.5 MiB)\n",
      "10-20 20:35:08.069 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_728 stored as values in memory (estimated size 40.0 B, free 420.0 MiB)\n",
      "10-20 20:35:08.070 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_728_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.0 MiB)\n",
      "10-20 20:35:08.070 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_728_piece0 in memory on 5b5a8eb7561c:44751 (size: 101.0 B, free: 421.5 MiB)\n",
      "10-20 20:35:08.071 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 728 from broadcast at RandomForest.scala:622\n",
      "10-20 20:35:08.083 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 20:35:08.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 702 (mapPartitions at RandomForest.scala:644) as input to shuffle 42\n",
      "10-20 20:35:08.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 346 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 20:35:08.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 405 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 20:35:08.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 404)\n",
      "10-20 20:35:08.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 404)\n",
      "10-20 20:35:08.084 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 404 (MapPartitionsRDD[702] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 20:35:08.088 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_729 stored as values in memory (estimated size 141.0 KiB, free 419.9 MiB)\n",
      "10-20 20:35:08.089 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_729_piece0 stored as bytes in memory (estimated size 46.1 KiB, free 419.9 MiB)\n",
      "10-20 20:35:08.089 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_729_piece0 in memory on 5b5a8eb7561c:44751 (size: 46.1 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:08.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 729 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:08.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 404 (MapPartitionsRDD[702] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:08.090 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 404.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:08.091 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 404.0 (TID 394) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:08.091 172.17.0.2:54321      18300   (TID 394)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 404.0 (TID 394)\n",
      "10-20 20:35:08.098 172.17.0.2:54321      18300   (TID 394)  INFO org.apache.spark.storage.BlockManager: Found block rdd_692_0 locally\n",
      "10-20 20:35:08.181 172.17.0.2:54321      18300   (TID 394)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 404.0 (TID 394). 2090 bytes result sent to driver\n",
      "10-20 20:35:08.183 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 404.0 (TID 394) in 92 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:08.183 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:08.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 404 (mapPartitions at RandomForest.scala:644) finished in 0.098 s\n",
      "10-20 20:35:08.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:08.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:08.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 405)\n",
      "10-20 20:35:08.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:08.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 405 (MapPartitionsRDD[704] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 20:35:08.186 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_720_piece0 on 5b5a8eb7561c:44751 in memory (size: 44.9 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:08.187 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_730 stored as values in memory (estimated size 6.9 KiB, free 420.0 MiB)\n",
      "10-20 20:35:08.188 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_730_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 420.0 MiB)\n",
      "10-20 20:35:08.189 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_730_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.6 KiB, free: 421.5 MiB)\n",
      "10-20 20:35:08.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 730 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:08.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 405 (MapPartitionsRDD[704] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:08.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 405.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:08.191 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 405.0 (TID 395) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:08.192 172.17.0.2:54321      18300   (TID 395)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 405.0 (TID 395)\n",
      "10-20 20:35:08.195 172.17.0.2:54321      18300   (TID 395)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (19.7 KiB) non-empty blocks including 1 (19.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:08.196 172.17.0.2:54321      18300   (TID 395)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:08.215 172.17.0.2:54321      18300   (TID 395)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 405.0 (TID 395). 3592 bytes result sent to driver\n",
      "10-20 20:35:08.216 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 405.0 (TID 395) in 25 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:08.216 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 405.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:08.217 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 405 (collectAsMap at RandomForest.scala:663) finished in 0.031 s\n",
      "10-20 20:35:08.218 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 346 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:08.218 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 405: Stage finished\n",
      "10-20 20:35:08.219 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 346 finished: collectAsMap at RandomForest.scala:663, took 0.135166 s\n",
      "10-20 20:35:08.220 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(728) (from destroy at RandomForest.scala:674)\n",
      "10-20 20:35:08.221 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_728_piece0 on 5b5a8eb7561c:44751 in memory (size: 101.0 B, free: 421.5 MiB)\n",
      "10-20 20:35:08.221 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_731 stored as values in memory (estimated size 40.0 B, free 420.0 MiB)\n",
      "10-20 20:35:08.222 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_731_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.0 MiB)\n",
      "10-20 20:35:08.222 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_731_piece0 in memory on 5b5a8eb7561c:44751 (size: 101.0 B, free: 421.5 MiB)\n",
      "10-20 20:35:08.223 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 731 from broadcast at RandomForest.scala:622\n",
      "10-20 20:35:08.239 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 20:35:08.241 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 705 (mapPartitions at RandomForest.scala:644) as input to shuffle 43\n",
      "10-20 20:35:08.241 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 347 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 20:35:08.241 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 407 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 20:35:08.241 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 406)\n",
      "10-20 20:35:08.241 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 406)\n",
      "10-20 20:35:08.243 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 406 (MapPartitionsRDD[705] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 20:35:08.247 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_732 stored as values in memory (estimated size 142.9 KiB, free 419.9 MiB)\n",
      "10-20 20:35:08.248 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_732_piece0 stored as bytes in memory (estimated size 46.8 KiB, free 419.8 MiB)\n",
      "10-20 20:35:08.248 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_732_piece0 in memory on 5b5a8eb7561c:44751 (size: 46.8 KiB, free: 421.4 MiB)\n",
      "10-20 20:35:08.248 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 732 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:08.249 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 406 (MapPartitionsRDD[705] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:08.249 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 406.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:08.249 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 406.0 (TID 396) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:08.250 172.17.0.2:54321      18300   (TID 396)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 406.0 (TID 396)\n",
      "10-20 20:35:08.260 172.17.0.2:54321      18300   (TID 396)  INFO org.apache.spark.storage.BlockManager: Found block rdd_692_0 locally\n",
      "10-20 20:35:08.277 172.17.0.2:54321      18300   (TID 396)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 406.0 (TID 396). 2090 bytes result sent to driver\n",
      "10-20 20:35:08.278 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 406.0 (TID 396) in 29 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:08.278 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 406.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:08.278 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 406 (mapPartitions at RandomForest.scala:644) finished in 0.035 s\n",
      "10-20 20:35:08.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:08.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:08.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 407)\n",
      "10-20 20:35:08.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:08.279 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 407 (MapPartitionsRDD[707] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 20:35:08.280 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_733 stored as values in memory (estimated size 7.3 KiB, free 419.8 MiB)\n",
      "10-20 20:35:08.281 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_733_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 419.8 MiB)\n",
      "10-20 20:35:08.281 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_733_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.8 KiB, free: 421.4 MiB)\n",
      "10-20 20:35:08.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 733 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:08.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 407 (MapPartitionsRDD[707] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:08.282 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 407.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:08.283 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 407.0 (TID 397) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:08.283 172.17.0.2:54321      18300   (TID 397)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 407.0 (TID 397)\n",
      "10-20 20:35:08.285 172.17.0.2:54321      18300   (TID 397)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:08.285 172.17.0.2:54321      18300   (TID 397)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:08.298 172.17.0.2:54321      18300   (TID 397)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 407.0 (TID 397). 4326 bytes result sent to driver\n",
      "10-20 20:35:08.299 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 407.0 (TID 397) in 16 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:08.299 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 407.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:08.300 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 407 (collectAsMap at RandomForest.scala:663) finished in 0.021 s\n",
      "10-20 20:35:08.300 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 347 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:08.300 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 407: Stage finished\n",
      "10-20 20:35:08.300 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 347 finished: collectAsMap at RandomForest.scala:663, took 0.060073 s\n",
      "10-20 20:35:08.300 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(731) (from destroy at RandomForest.scala:674)\n",
      "10-20 20:35:08.301 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 20:35:08.302 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 0.002919581\n",
      "  total: 1.322139756\n",
      "  findBestSplits: 1.315650279\n",
      "  chooseSplits: 1.311637954\n",
      "10-20 20:35:08.302 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_731_piece0 on 5b5a8eb7561c:44751 in memory (size: 101.0 B, free: 421.4 MiB)\n",
      "10-20 20:35:08.305 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 692 from persistence list\n",
      "10-20 20:35:08.305 172.17.0.2:54321      18300  d-pool-201  INFO org.apache.spark.storage.BlockManager: Removing RDD 692\n",
      "10-20 20:35:08.306 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(718) (from destroy at RandomForest.scala:305)\n",
      "10-20 20:35:08.306 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [46ac3bfb] training finished\n",
      "10-20 20:35:08.306 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_718_piece0 on 5b5a8eb7561c:44751 in memory (size: 1038.0 B, free: 434.0 MiB)\n",
      "10-20 20:35:09.078 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_732_piece0 on 5b5a8eb7561c:44751 in memory (size: 46.8 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.078 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_726_piece0 on 5b5a8eb7561c:44751 in memory (size: 45.7 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.079 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_730_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.6 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.080 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_724_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.5 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.084 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_733_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.8 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.085 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_727_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.6 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.086 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_723_piece0 on 5b5a8eb7561c:44751 in memory (size: 45.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.089 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_729_piece0 on 5b5a8eb7561c:44751 in memory (size: 46.1 KiB, free: 434.2 MiB)\n",
      "Metric name: areaUnderROC\n",
      "10-20 20:35:09.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:09.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:09.257 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:09.283 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_734 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:35:09.299 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_734_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)\n",
      "10-20 20:35:09.300 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_734_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.301 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 734 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:35:09.302 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:09.327 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:35:09.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 715 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 45\n",
      "10-20 20:35:09.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 716 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 44\n",
      "10-20 20:35:09.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 348 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:35:09.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 410 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:35:09.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 409)\n",
      "10-20 20:35:09.328 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 409)\n",
      "10-20 20:35:09.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 408 (MapPartitionsRDD[715] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:35:09.333 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_735 stored as values in memory (estimated size 145.5 KiB, free 432.9 MiB)\n",
      "10-20 20:35:09.334 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_735_piece0 stored as bytes in memory (estimated size 48.9 KiB, free 432.8 MiB)\n",
      "10-20 20:35:09.334 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_735_piece0 in memory on 5b5a8eb7561c:44751 (size: 48.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 735 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:09.335 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 408 (MapPartitionsRDD[715] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:09.336 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 408.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:09.336 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 408.0 (TID 398) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:09.336 172.17.0.2:54321      18300   (TID 398)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 408.0 (TID 398)\n",
      "10-20 20:35:09.349 172.17.0.2:54321      18300   (TID 398)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:35:09.512 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_713_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.522 172.17.0.2:54321      18300  d-pool-161  INFO org.apache.spark.storage.BlockManager: Removing RDD 692\n",
      "10-20 20:35:09.523 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_709_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.721 172.17.0.2:54321      18300   (TID 398)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 408.0 (TID 398). 2133 bytes result sent to driver\n",
      "10-20 20:35:09.721 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 408.0 (TID 398) in 385 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:09.721 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 408.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:09.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 408 (map at BinaryClassificationMetrics.scala:48) finished in 0.393 s\n",
      "10-20 20:35:09.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:09.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:09.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 409, ResultStage 410)\n",
      "10-20 20:35:09.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:09.722 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 409 (ShuffledRDD[716] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:35:09.723 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_736 stored as values in memory (estimated size 5.1 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.733 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_736_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.733 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_736_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 736 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:09.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 409 (ShuffledRDD[716] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:09.734 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 409.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:09.735 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 409.0 (TID 399) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:09.736 172.17.0.2:54321      18300   (TID 399)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 409.0 (TID 399)\n",
      "10-20 20:35:09.740 172.17.0.2:54321      18300   (TID 399)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:09.740 172.17.0.2:54321      18300   (TID 399)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:09.743 172.17.0.2:54321      18300   (TID 399)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 409.0 (TID 399). 1462 bytes result sent to driver\n",
      "10-20 20:35:09.743 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 409.0 (TID 399) in 8 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:09.743 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 409.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:09.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 409 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.021 s\n",
      "10-20 20:35:09.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:09.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:09.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 410)\n",
      "10-20 20:35:09.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:09.744 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 410 (ShuffledRDD[717] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:35:09.745 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_737 stored as values in memory (estimated size 3.9 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.746 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_737_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.746 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_737_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 737 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:09.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 410 (ShuffledRDD[717] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:09.747 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 410.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:09.748 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 410.0 (TID 400) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:09.748 172.17.0.2:54321      18300   (TID 400)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 410.0 (TID 400)\n",
      "10-20 20:35:09.750 172.17.0.2:54321      18300   (TID 400)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:09.750 172.17.0.2:54321      18300   (TID 400)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:09.751 172.17.0.2:54321      18300   (TID 400)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 410.0 (TID 400). 1305 bytes result sent to driver\n",
      "10-20 20:35:09.752 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 410.0 (TID 400) in 3 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:09.752 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 410.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:09.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 410 (count at BinaryClassificationMetrics.scala:197) finished in 0.007 s\n",
      "10-20 20:35:09.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 348 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:09.752 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 410: Stage finished\n",
      "10-20 20:35:09.752 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 348 finished: count at BinaryClassificationMetrics.scala:197, took 0.425244 s\n",
      "10-20 20:35:09.753 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Curve is too small (17) for 1000 bins to be useful\n",
      "10-20 20:35:09.761 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:35:09.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 349 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:35:09.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 413 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:35:09.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 412)\n",
      "10-20 20:35:09.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:09.761 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 413 (MapPartitionsRDD[719] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:35:09.762 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_738 stored as values in memory (estimated size 5.3 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.763 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_738_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.763 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_738_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.763 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 738 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:09.763 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 413 (MapPartitionsRDD[719] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:09.763 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 413.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:09.764 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 413.0 (TID 401) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:09.764 172.17.0.2:54321      18300   (TID 401)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 413.0 (TID 401)\n",
      "10-20 20:35:09.766 172.17.0.2:54321      18300   (TID 401)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:09.766 172.17.0.2:54321      18300   (TID 401)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:09.768 172.17.0.2:54321      18300   (TID 401)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 413.0 (TID 401). 1448 bytes result sent to driver\n",
      "10-20 20:35:09.768 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 413.0 (TID 401) in 4 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:09.768 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 413.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:09.768 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 413 (collect at BinaryClassificationMetrics.scala:237) finished in 0.006 s\n",
      "10-20 20:35:09.769 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 349 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:09.769 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 413: Stage finished\n",
      "10-20 20:35:09.769 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 349 finished: collect at BinaryClassificationMetrics.scala:237, took 0.008056 s\n",
      "10-20 20:35:09.769 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 1552.0, numNeg: 4933.0}\n",
      "10-20 20:35:09.778 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:35:09.778 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 350 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:35:09.778 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 416 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:35:09.778 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 415)\n",
      "10-20 20:35:09.779 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:09.779 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 416 (MapPartitionsRDD[724] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:35:09.780 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_739 stored as values in memory (estimated size 6.9 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.780 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_739_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 433.2 MiB)\n",
      "10-20 20:35:09.781 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_739_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 739 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:09.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 416 (MapPartitionsRDD[724] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:09.781 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 416.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:09.782 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 416.0 (TID 402) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:09.783 172.17.0.2:54321      18300   (TID 402)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 416.0 (TID 402)\n",
      "10-20 20:35:09.786 172.17.0.2:54321      18300   (TID 402)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:09.786 172.17.0.2:54321      18300   (TID 402)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:09.786 172.17.0.2:54321      18300   (TID 402)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_720_0 stored as values in memory (estimated size 1448.0 B, free 433.2 MiB)\n",
      "10-20 20:35:09.787 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_720_0 in memory on 5b5a8eb7561c:44751 (size: 1448.0 B, free: 434.2 MiB)\n",
      "10-20 20:35:09.788 172.17.0.2:54321      18300   (TID 402)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 416.0 (TID 402). 1524 bytes result sent to driver\n",
      "10-20 20:35:09.788 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 416.0 (TID 402) in 6 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:09.788 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 416.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:09.789 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 416 (collect at AreaUnderCurve.scala:44) finished in 0.009 s\n",
      "10-20 20:35:09.789 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 350 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:09.789 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 416: Stage finished\n",
      "10-20 20:35:09.789 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 350 finished: collect at AreaUnderCurve.scala:44, took 0.011737 s\n",
      "10-20 20:35:09.790 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 720 from persistence list\n",
      "10-20 20:35:09.790 172.17.0.2:54321      18300  d-pool-166  INFO org.apache.spark.storage.BlockManager: Removing RDD 720\n",
      "CV Metric value: 0.6814580194189772\n",
      "10-20 20:35:09.842 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:35:09.842 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:35:09.842 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:35:09.864 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_740 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:35:09.870 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_740_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)\n",
      "10-20 20:35:09.870 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_740_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:09.871 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 740 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:35:09.871 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:35:09.894 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:35:09.894 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 732 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 47\n",
      "10-20 20:35:09.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 733 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 46\n",
      "10-20 20:35:09.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 351 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:35:09.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 419 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:35:09.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 418)\n",
      "10-20 20:35:09.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 418)\n",
      "10-20 20:35:09.895 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 417 (MapPartitionsRDD[732] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:35:09.913 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_741 stored as values in memory (estimated size 138.1 KiB, free 432.8 MiB)\n",
      "10-20 20:35:09.914 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_741_piece0 stored as bytes in memory (estimated size 46.7 KiB, free 432.8 MiB)\n",
      "10-20 20:35:09.914 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_741_piece0 in memory on 5b5a8eb7561c:44751 (size: 46.7 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:09.915 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 741 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:09.915 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 417 (MapPartitionsRDD[732] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:09.915 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 417.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:09.916 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 417.0 (TID 403) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4854 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:09.916 172.17.0.2:54321      18300   (TID 403)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 417.0 (TID 403)\n",
      "10-20 20:35:09.926 172.17.0.2:54321      18300   (TID 403)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n",
      "10-20 20:35:10.198 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_739_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.3 KiB, free: 434.1 MiB)\n",
      "10-20 20:35:10.199 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_735_piece0 on 5b5a8eb7561c:44751 in memory (size: 48.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.200 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_737_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.200 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_738_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.201 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_736_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.202 172.17.0.2:54321      18300  d-pool-192  INFO org.apache.spark.storage.BlockManager: Removing RDD 720\n",
      "10-20 20:35:10.394 172.17.0.2:54321      18300   (TID 403)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 417.0 (TID 403). 1861 bytes result sent to driver\n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 417.0 (TID 403) in 479 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 417 (map at BinaryClassificationMetrics.scala:48) finished in 0.500 s\n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 419, ShuffleMapStage 418)\n",
      "10-20 20:35:10.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:10.396 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 418 (ShuffledRDD[733] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:35:10.396 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_742 stored as values in memory (estimated size 5.1 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.405 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_742_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.406 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_742_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 742 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:10.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 418 (ShuffledRDD[733] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:10.406 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 418.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:10.407 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 418.0 (TID 404) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:10.407 172.17.0.2:54321      18300   (TID 404)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 418.0 (TID 404)\n",
      "10-20 20:35:10.409 172.17.0.2:54321      18300   (TID 404)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:10.409 172.17.0.2:54321      18300   (TID 404)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:10.411 172.17.0.2:54321      18300   (TID 404)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 418.0 (TID 404). 1462 bytes result sent to driver\n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 418.0 (TID 404) in 5 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 418.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 418 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.016 s\n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 419)\n",
      "10-20 20:35:10.412 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:35:10.413 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 419 (ShuffledRDD[734] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:35:10.414 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_743 stored as values in memory (estimated size 3.9 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.414 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_743_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.414 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_743_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.415 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 743 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:10.416 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 419 (ShuffledRDD[734] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:10.416 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 419.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:10.416 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 419.0 (TID 405) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:10.417 172.17.0.2:54321      18300   (TID 405)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 419.0 (TID 405)\n",
      "10-20 20:35:10.419 172.17.0.2:54321      18300   (TID 405)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:10.419 172.17.0.2:54321      18300   (TID 405)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:10.420 172.17.0.2:54321      18300   (TID 405)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 419.0 (TID 405). 1305 bytes result sent to driver\n",
      "10-20 20:35:10.421 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 419.0 (TID 405) in 5 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:10.421 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 419.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:10.422 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 419 (count at BinaryClassificationMetrics.scala:197) finished in 0.008 s\n",
      "10-20 20:35:10.422 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 351 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:10.422 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 419: Stage finished\n",
      "10-20 20:35:10.422 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 351 finished: count at BinaryClassificationMetrics.scala:197, took 0.528325 s\n",
      "10-20 20:35:10.422 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Curve is too small (18) for 1000 bins to be useful\n",
      "10-20 20:35:10.429 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:35:10.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 352 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:35:10.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 422 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:35:10.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 421)\n",
      "10-20 20:35:10.430 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:10.432 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 422 (MapPartitionsRDD[736] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:35:10.433 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_744 stored as values in memory (estimated size 5.3 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.434 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_744_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.434 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_744_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.434 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 744 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:10.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 422 (MapPartitionsRDD[736] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:10.435 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 422.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:10.435 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 422.0 (TID 406) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:10.436 172.17.0.2:54321      18300   (TID 406)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 422.0 (TID 406)\n",
      "10-20 20:35:10.437 172.17.0.2:54321      18300   (TID 406)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:10.437 172.17.0.2:54321      18300   (TID 406)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:10.438 172.17.0.2:54321      18300   (TID 406)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 422.0 (TID 406). 1448 bytes result sent to driver\n",
      "10-20 20:35:10.439 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 422.0 (TID 406) in 4 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:10.439 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 422.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:10.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 422 (collect at BinaryClassificationMetrics.scala:237) finished in 0.007 s\n",
      "10-20 20:35:10.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 352 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:10.439 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 422: Stage finished\n",
      "10-20 20:35:10.439 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 352 finished: collect at BinaryClassificationMetrics.scala:237, took 0.010087 s\n",
      "10-20 20:35:10.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 3846.0, numNeg: 12436.0}\n",
      "10-20 20:35:10.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:35:10.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 353 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:35:10.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 425 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:35:10.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 424)\n",
      "10-20 20:35:10.449 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:35:10.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 425 (MapPartitionsRDD[741] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:35:10.452 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_745 stored as values in memory (estimated size 6.9 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.452 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_745_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 433.0 MiB)\n",
      "10-20 20:35:10.452 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_745_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:35:10.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 745 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:35:10.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 425 (MapPartitionsRDD[741] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:35:10.453 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 425.0 with 1 tasks resource profile 0\n",
      "10-20 20:35:10.454 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 425.0 (TID 407) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:35:10.455 172.17.0.2:54321      18300   (TID 407)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 425.0 (TID 407)\n",
      "10-20 20:35:10.457 172.17.0.2:54321      18300   (TID 407)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:35:10.457 172.17.0.2:54321      18300   (TID 407)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:35:10.458 172.17.0.2:54321      18300   (TID 407)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_737_0 stored as values in memory (estimated size 1528.0 B, free 433.0 MiB)\n",
      "10-20 20:35:10.458 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_737_0 in memory on 5b5a8eb7561c:44751 (size: 1528.0 B, free: 434.2 MiB)\n",
      "10-20 20:35:10.460 172.17.0.2:54321      18300   (TID 407)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 425.0 (TID 407). 1524 bytes result sent to driver\n",
      "10-20 20:35:10.460 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 425.0 (TID 407) in 6 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:35:10.460 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 425.0, whose tasks have all completed, from pool \n",
      "10-20 20:35:10.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 425 (collect at AreaUnderCurve.scala:44) finished in 0.011 s\n",
      "10-20 20:35:10.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 353 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:35:10.462 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 425: Stage finished\n",
      "10-20 20:35:10.462 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 353 finished: collect at AreaUnderCurve.scala:44, took 0.014140 s\n",
      "10-20 20:35:10.463 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 737 from persistence list\n",
      "10-20 20:35:10.463 172.17.0.2:54321      18300  d-pool-194  INFO org.apache.spark.storage.BlockManager: Removing RDD 737\n",
      "Test Metric value: 0.686947101557269\n",
      "10-20 20:36:26.620 172.17.0.2:54321      18300  d-pool-207  INFO org.apache.spark.storage.BlockManager: Removing RDD 737\n",
      "10-20 20:36:26.693 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_740_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:26.759 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_744_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:26.830 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_742_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:26.932 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_743_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:27.010 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_745_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:27.020 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_741_piece0 on 5b5a8eb7561c:44751 in memory (size: 46.7 KiB, free: 434.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol='label', featuresCol='features')\n",
    "dt_stages = [imputer] + string_indexers + ohe_indexers + [vector_assembler] + [dt]\n",
    "pipeline = Pipeline().setStages(dt_stages)\n",
    "dt_model = pipeline.fit(train_df)\n",
    "\n",
    "val_df_pred = dt_model.transform(val_df)\n",
    "test_df_pred = dt_model.transform(test_df)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'Metric name: {evaluator.getMetricName()}')\n",
    "print(f'CV Metric value: {evaluator.evaluate(val_df_pred)}')\n",
    "print(f'Test Metric value: {evaluator.evaluate(test_df_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6360f3-47c9-485f-bb2a-ca26c99e0a78",
   "metadata": {},
   "source": [
    "#### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7f562ed-f19b-49ba-928d-8c2377a8ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:36:57.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:57.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:57.196 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:57.217 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_746 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 20:36:57.230 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_746_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:36:57.231 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_746_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.231 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 746 from head at Imputer.scala:169\n",
      "10-20 20:36:57.232 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:57.255 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:169\n",
      "10-20 20:36:57.255 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 745 (head at Imputer.scala:169) as input to shuffle 48\n",
      "10-20 20:36:57.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 354 (head at Imputer.scala:169) with 1 output partitions\n",
      "10-20 20:36:57.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 427 (head at Imputer.scala:169)\n",
      "10-20 20:36:57.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 426)\n",
      "10-20 20:36:57.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 426)\n",
      "10-20 20:36:57.256 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 426 (MapPartitionsRDD[745] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:36:57.257 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_747 stored as values in memory (estimated size 54.3 KiB, free 433.2 MiB)\n",
      "10-20 20:36:57.258 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_747_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.258 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_747_piece0 in memory on 5b5a8eb7561c:44751 (size: 22.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 747 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:57.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 426 (MapPartitionsRDD[745] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:57.259 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 426.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:57.259 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 426.0 (TID 408) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.260 172.17.0.2:54321      18300   (TID 408)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 426.0 (TID 408)\n",
      "10-20 20:36:57.266 172.17.0.2:54321      18300   (TID 408)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:57.556 172.17.0.2:54321      18300   (TID 408)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 426.0 (TID 408). 2689 bytes result sent to driver\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 426.0 (TID 408) in 297 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 426.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 426 (head at Imputer.scala:169) finished in 0.301 s\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 427)\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:57.557 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 427 (MapPartitionsRDD[748] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 20:36:57.559 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_748 stored as values in memory (estimated size 19.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_748_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.560 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_748_piece0 in memory on 5b5a8eb7561c:44751 (size: 7.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.560 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 748 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:57.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 427 (MapPartitionsRDD[748] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:57.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 427.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:57.562 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 427.0 (TID 409) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.563 172.17.0.2:54321      18300   (TID 409)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 427.0 (TID 409)\n",
      "10-20 20:36:57.566 172.17.0.2:54321      18300   (TID 409)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:57.566 172.17.0.2:54321      18300   (TID 409)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:57.568 172.17.0.2:54321      18300   (TID 409)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 427.0 (TID 409). 2681 bytes result sent to driver\n",
      "10-20 20:36:57.568 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 427.0 (TID 409) in 6 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:57.569 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 427.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:57.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 427 (head at Imputer.scala:169) finished in 0.011 s\n",
      "10-20 20:36:57.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 354 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:57.569 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 427: Stage finished\n",
      "10-20 20:36:57.570 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 354 finished: head at Imputer.scala:169, took 0.314895 s\n",
      "10-20 20:36:57.628 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:36:57.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 355 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 20:36:57.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 428 (head at Imputer.scala:258)\n",
      "10-20 20:36:57.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:36:57.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:36:57.629 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 428 (MapPartitionsRDD[752] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:36:57.636 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_749 stored as values in memory (estimated size 10.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.637 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_749_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.637 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_749_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.638 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 749 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:57.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 428 (MapPartitionsRDD[752] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:57.639 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 428.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:57.640 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 428.0 (TID 410) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.641 172.17.0.2:54321      18300   (TID 410)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 428.0 (TID 410)\n",
      "10-20 20:36:57.642 172.17.0.2:54321      18300   (TID 410)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 428.0 (TID 410). 1304 bytes result sent to driver\n",
      "10-20 20:36:57.643 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 428.0 (TID 410) in 3 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:57.643 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 428.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:57.644 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 428 (head at Imputer.scala:258) finished in 0.015 s\n",
      "10-20 20:36:57.644 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 355 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:57.644 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 428: Stage finished\n",
      "10-20 20:36:57.645 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 355 finished: head at Imputer.scala:258, took 0.016451 s\n",
      "10-20 20:36:57.648 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 20:36:57.648 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 356 (head at Imputer.scala:258) with 3 output partitions\n",
      "10-20 20:36:57.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 429 (head at Imputer.scala:258)\n",
      "10-20 20:36:57.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 20:36:57.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:36:57.649 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 429 (MapPartitionsRDD[752] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 20:36:57.650 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_750 stored as values in memory (estimated size 10.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_750_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.651 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_750_piece0 in memory on 5b5a8eb7561c:44751 (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.651 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 750 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:57.652 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 3 missing tasks from ResultStage 429 (MapPartitionsRDD[752] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(1, 2, 3))\n",
      "10-20 20:36:57.652 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 429.0 with 3 tasks resource profile 0\n",
      "10-20 20:36:57.653 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 429.0 (TID 411) (5b5a8eb7561c, executor driver, partition 1, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.653 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 429.0 (TID 412) (5b5a8eb7561c, executor driver, partition 2, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.653 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 429.0 (TID 413) (5b5a8eb7561c, executor driver, partition 3, PROCESS_LOCAL, 4717 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.653 172.17.0.2:54321      18300   (TID 411)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 429.0 (TID 411)\n",
      "10-20 20:36:57.656 172.17.0.2:54321      18300   (TID 411)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 429.0 (TID 411). 1304 bytes result sent to driver\n",
      "10-20 20:36:57.656 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 429.0 (TID 411) in 4 ms on 5b5a8eb7561c (executor driver) (1/3)\n",
      "10-20 20:36:57.657 172.17.0.2:54321      18300   (TID 412)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 429.0 (TID 412)\n",
      "10-20 20:36:57.659 172.17.0.2:54321      18300   (TID 412)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 429.0 (TID 412). 1261 bytes result sent to driver\n",
      "10-20 20:36:57.659 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 429.0 (TID 412) in 6 ms on 5b5a8eb7561c (executor driver) (2/3)\n",
      "10-20 20:36:57.659 172.17.0.2:54321      18300   (TID 413)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 429.0 (TID 413)\n",
      "10-20 20:36:57.663 172.17.0.2:54321      18300   (TID 413)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 429.0 (TID 413). 1400 bytes result sent to driver\n",
      "10-20 20:36:57.663 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 429.0 (TID 413) in 10 ms on 5b5a8eb7561c (executor driver) (3/3)\n",
      "10-20 20:36:57.664 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 429.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:57.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 429 (head at Imputer.scala:258) finished in 0.014 s\n",
      "10-20 20:36:57.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 356 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:57.664 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 429: Stage finished\n",
      "10-20 20:36:57.665 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 356 finished: head at Imputer.scala:258, took 0.016578 s\n",
      "10-20 20:36:57.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:57.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:57.707 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:57.714 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_751 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:57.724 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_747_piece0 on 5b5a8eb7561c:44751 in memory (size: 22.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.726 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_751_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:36:57.726 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_751_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.726 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 751 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:57.727 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 757 (collect at StringIndexer.scala:204) as input to shuffle 49\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 357 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 431 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 430)\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 430)\n",
      "10-20 20:36:57.735 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 430 (MapPartitionsRDD[757] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:57.736 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_752 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:57.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_752_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:57.737 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_752_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 752 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:57.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 430 (MapPartitionsRDD[757] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:57.737 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 430.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:57.738 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 430.0 (TID 414) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.738 172.17.0.2:54321      18300   (TID 414)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 430.0 (TID 414)\n",
      "10-20 20:36:57.743 172.17.0.2:54321      18300   (TID 414)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:57.754 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_748_piece0 on 5b5a8eb7561c:44751 in memory (size: 7.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.756 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_746_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.760 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_750_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.779 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_749_piece0 on 5b5a8eb7561c:44751 in memory (size: 4.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.928 172.17.0.2:54321      18300   (TID 414)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 430.0 (TID 414). 2468 bytes result sent to driver\n",
      "10-20 20:36:57.929 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 430.0 (TID 414) in 191 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:57.929 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 430.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:57.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 430 (collect at StringIndexer.scala:204) finished in 0.195 s\n",
      "10-20 20:36:57.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:57.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:57.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 431)\n",
      "10-20 20:36:57.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:57.930 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 431 (MapPartitionsRDD[760] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:57.931 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_753 stored as values in memory (estimated size 26.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.932 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_753_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:57.932 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_753_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:57.933 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 753 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:57.933 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 431 (MapPartitionsRDD[760] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:57.933 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 431.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:57.934 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 431.0 (TID 415) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:57.934 172.17.0.2:54321      18300   (TID 415)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 431.0 (TID 415)\n",
      "10-20 20:36:57.938 172.17.0.2:54321      18300   (TID 415)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:57.938 172.17.0.2:54321      18300   (TID 415)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:57.949 172.17.0.2:54321      18300   (TID 415)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 431.0 (TID 415). 3904 bytes result sent to driver\n",
      "10-20 20:36:57.949 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 431.0 (TID 415) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:57.949 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 431.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:57.950 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 431 (collect at StringIndexer.scala:204) finished in 0.020 s\n",
      "10-20 20:36:57.950 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 357 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:57.950 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 431: Stage finished\n",
      "10-20 20:36:57.950 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 357 finished: collect at StringIndexer.scala:204, took 0.215435 s\n",
      "10-20 20:36:58.004 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:58.005 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:58.005 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:58.013 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_754 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.021 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_754_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.022 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_754_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.023 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 754 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.024 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:58.035 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 765 (collect at StringIndexer.scala:204) as input to shuffle 50\n",
      "10-20 20:36:58.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 358 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:58.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 433 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:58.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 432)\n",
      "10-20 20:36:58.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 432)\n",
      "10-20 20:36:58.036 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 432 (MapPartitionsRDD[765] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.037 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_755 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.038 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_755_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.039 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_755_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.039 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 755 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 432 (MapPartitionsRDD[765] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.040 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 432.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.040 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 432.0 (TID 416) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.040 172.17.0.2:54321      18300   (TID 416)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 432.0 (TID 416)\n",
      "10-20 20:36:58.045 172.17.0.2:54321      18300   (TID 416)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:58.090 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_751_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.093 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_753_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.106 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_752_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.206 172.17.0.2:54321      18300   (TID 416)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 432.0 (TID 416). 2511 bytes result sent to driver\n",
      "10-20 20:36:58.207 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 432.0 (TID 416) in 167 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:58.207 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 432.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:58.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 432 (collect at StringIndexer.scala:204) finished in 0.172 s\n",
      "10-20 20:36:58.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:58.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:58.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 433)\n",
      "10-20 20:36:58.208 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:58.209 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 433 (MapPartitionsRDD[768] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.210 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_756 stored as values in memory (estimated size 26.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:58.211 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_756_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:58.211 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_756_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 756 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 433 (MapPartitionsRDD[768] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.212 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 433.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.213 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 433.0 (TID 417) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.214 172.17.0.2:54321      18300   (TID 417)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 433.0 (TID 417)\n",
      "10-20 20:36:58.222 172.17.0.2:54321      18300   (TID 417)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:58.222 172.17.0.2:54321      18300   (TID 417)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:58.235 172.17.0.2:54321      18300   (TID 417)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 433.0 (TID 417). 3956 bytes result sent to driver\n",
      "10-20 20:36:58.235 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 433.0 (TID 417) in 22 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:58.235 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 433.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:58.239 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 433 (collect at StringIndexer.scala:204) finished in 0.030 s\n",
      "10-20 20:36:58.240 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 358 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:58.240 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 433: Stage finished\n",
      "10-20 20:36:58.241 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 358 finished: collect at StringIndexer.scala:204, took 0.205251 s\n",
      "10-20 20:36:58.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:58.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:58.318 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:58.326 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_757 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.331 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_757_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.332 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_757_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.332 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 757 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.333 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:58.340 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 773 (collect at StringIndexer.scala:204) as input to shuffle 51\n",
      "10-20 20:36:58.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 359 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:58.340 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 435 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:58.341 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 434)\n",
      "10-20 20:36:58.341 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 434)\n",
      "10-20 20:36:58.341 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 434 (MapPartitionsRDD[773] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_758 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.342 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_758_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.343 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_758_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 758 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 434 (MapPartitionsRDD[773] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.343 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 434.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.344 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 434.0 (TID 418) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.344 172.17.0.2:54321      18300   (TID 418)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 434.0 (TID 418)\n",
      "10-20 20:36:58.348 172.17.0.2:54321      18300   (TID 418)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:58.453 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_756_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.456 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_754_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.462 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_755_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.494 172.17.0.2:54321      18300   (TID 418)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 434.0 (TID 418). 2511 bytes result sent to driver\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 434.0 (TID 418) in 152 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 434 (collect at StringIndexer.scala:204) finished in 0.154 s\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 435)\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:58.495 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 435 (MapPartitionsRDD[776] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_759 stored as values in memory (estimated size 26.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:58.497 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_759_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:58.497 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_759_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.498 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 759 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.498 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 435 (MapPartitionsRDD[776] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.498 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 435.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.498 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 435.0 (TID 419) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.499 172.17.0.2:54321      18300   (TID 419)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 435.0 (TID 419)\n",
      "10-20 20:36:58.502 172.17.0.2:54321      18300   (TID 419)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:58.502 172.17.0.2:54321      18300   (TID 419)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:58.510 172.17.0.2:54321      18300   (TID 419)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 435.0 (TID 419). 3884 bytes result sent to driver\n",
      "10-20 20:36:58.510 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 435.0 (TID 419) in 12 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:58.510 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 435.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:58.510 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 435 (collect at StringIndexer.scala:204) finished in 0.014 s\n",
      "10-20 20:36:58.510 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 359 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:58.510 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 435: Stage finished\n",
      "10-20 20:36:58.511 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 359 finished: collect at StringIndexer.scala:204, took 0.170877 s\n",
      "10-20 20:36:58.561 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:58.562 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:58.562 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:58.569 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_760 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.580 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_758_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.581 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_760_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)\n",
      "10-20 20:36:58.581 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_760_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.582 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 760 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.582 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:58.590 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.590 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 781 (collect at StringIndexer.scala:204) as input to shuffle 52\n",
      "10-20 20:36:58.590 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 360 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:58.591 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 437 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:58.591 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 436)\n",
      "10-20 20:36:58.591 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 436)\n",
      "10-20 20:36:58.591 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 436 (MapPartitionsRDD[781] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.592 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_761 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_761_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.593 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_761_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 761 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 436 (MapPartitionsRDD[781] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.593 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 436.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.594 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 436.0 (TID 420) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.594 172.17.0.2:54321      18300   (TID 420)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 436.0 (TID 420)\n",
      "10-20 20:36:58.599 172.17.0.2:54321      18300   (TID 420)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:58.603 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_759_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.612 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_757_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.783 172.17.0.2:54321      18300   (TID 420)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 436.0 (TID 420). 2468 bytes result sent to driver\n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 436.0 (TID 420) in 191 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 436 (collect at StringIndexer.scala:204) finished in 0.194 s\n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 437)\n",
      "10-20 20:36:58.785 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:58.786 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 437 (MapPartitionsRDD[784] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.787 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_762 stored as values in memory (estimated size 26.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:58.788 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_762_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:58.788 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_762_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.788 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 762 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.788 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 437 (MapPartitionsRDD[784] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.788 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 437.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.790 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 437.0 (TID 421) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.790 172.17.0.2:54321      18300   (TID 421)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 437.0 (TID 421)\n",
      "10-20 20:36:58.794 172.17.0.2:54321      18300   (TID 421)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (789.0 B) non-empty blocks including 1 (789.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:58.794 172.17.0.2:54321      18300   (TID 421)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:58.835 172.17.0.2:54321      18300   (TID 421)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 437.0 (TID 421). 4046 bytes result sent to driver\n",
      "10-20 20:36:58.836 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 437.0 (TID 421) in 46 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:58.836 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 437.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:58.837 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 437 (collect at StringIndexer.scala:204) finished in 0.051 s\n",
      "10-20 20:36:58.837 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 360 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:58.837 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 437: Stage finished\n",
      "10-20 20:36:58.837 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 360 finished: collect at StringIndexer.scala:204, took 0.246895 s\n",
      "10-20 20:36:58.930 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:58.930 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:58.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:58.942 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_763 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.973 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_763_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.974 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_763_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.974 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 763 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.975 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:58.992 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:58.993 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 789 (collect at StringIndexer.scala:204) as input to shuffle 53\n",
      "10-20 20:36:58.993 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 361 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:58.993 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 439 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:58.993 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 438)\n",
      "10-20 20:36:58.993 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 438)\n",
      "10-20 20:36:58.993 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 438 (MapPartitionsRDD[789] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:58.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_764 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.995 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_764_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:58.996 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_764_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:58.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 764 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:58.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 438 (MapPartitionsRDD[789] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:58.996 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 438.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:58.997 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 438.0 (TID 422) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:58.997 172.17.0.2:54321      18300   (TID 422)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 438.0 (TID 422)\n",
      "10-20 20:36:59.002 172.17.0.2:54321      18300   (TID 422)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:59.061 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_762_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.104 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_761_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.106 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_760_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.203 172.17.0.2:54321      18300   (TID 422)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 438.0 (TID 422). 2511 bytes result sent to driver\n",
      "10-20 20:36:59.203 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 438.0 (TID 422) in 206 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:59.203 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 438.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:59.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 438 (collect at StringIndexer.scala:204) finished in 0.210 s\n",
      "10-20 20:36:59.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:59.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:59.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 439)\n",
      "10-20 20:36:59.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:59.204 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 439 (MapPartitionsRDD[792] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:59.205 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_765 stored as values in memory (estimated size 26.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:59.206 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_765_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:59.206 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_765_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.207 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 765 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:59.207 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 439 (MapPartitionsRDD[792] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:59.207 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 439.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:59.208 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 439.0 (TID 423) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:59.218 172.17.0.2:54321      18300   (TID 423)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 439.0 (TID 423)\n",
      "10-20 20:36:59.221 172.17.0.2:54321      18300   (TID 423)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:59.221 172.17.0.2:54321      18300   (TID 423)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:59.232 172.17.0.2:54321      18300   (TID 423)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 439.0 (TID 423). 3855 bytes result sent to driver\n",
      "10-20 20:36:59.232 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 439.0 (TID 423) in 24 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:59.232 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 439.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:59.233 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 439 (collect at StringIndexer.scala:204) finished in 0.029 s\n",
      "10-20 20:36:59.233 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 361 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:59.233 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 439: Stage finished\n",
      "10-20 20:36:59.233 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 361 finished: collect at StringIndexer.scala:204, took 0.241190 s\n",
      "10-20 20:36:59.344 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:59.344 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:59.344 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:59.351 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_766 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.356 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_766_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.356 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_766_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.356 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 766 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:59.357 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:59.368 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:59.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 797 (collect at StringIndexer.scala:204) as input to shuffle 54\n",
      "10-20 20:36:59.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 362 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:59.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 441 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:59.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 440)\n",
      "10-20 20:36:59.368 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 440)\n",
      "10-20 20:36:59.369 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 440 (MapPartitionsRDD[797] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:59.370 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_767 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.370 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_767_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.371 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_767_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 767 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:59.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 440 (MapPartitionsRDD[797] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:59.371 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 440.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:59.372 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 440.0 (TID 424) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:59.372 172.17.0.2:54321      18300   (TID 424)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 440.0 (TID 424)\n",
      "10-20 20:36:59.378 172.17.0.2:54321      18300   (TID 424)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:59.430 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_764_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.439 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_765_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.7 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.440 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_763_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.545 172.17.0.2:54321      18300   (TID 424)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 440.0 (TID 424). 2511 bytes result sent to driver\n",
      "10-20 20:36:59.546 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 440.0 (TID 424) in 174 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:59.546 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 440.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:59.546 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 440 (collect at StringIndexer.scala:204) finished in 0.177 s\n",
      "10-20 20:36:59.546 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:59.546 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:59.547 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 441)\n",
      "10-20 20:36:59.547 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:59.547 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 441 (MapPartitionsRDD[800] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:59.548 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_768 stored as values in memory (estimated size 26.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:59.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_768_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:59.549 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_768_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 768 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:59.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 441 (MapPartitionsRDD[800] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:59.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 441.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:59.551 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 441.0 (TID 425) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:59.551 172.17.0.2:54321      18300   (TID 425)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 441.0 (TID 425)\n",
      "10-20 20:36:59.554 172.17.0.2:54321      18300   (TID 425)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:59.554 172.17.0.2:54321      18300   (TID 425)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:59.562 172.17.0.2:54321      18300   (TID 425)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 441.0 (TID 425). 3863 bytes result sent to driver\n",
      "10-20 20:36:59.563 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 441.0 (TID 425) in 13 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:59.563 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 441.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:59.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 441 (collect at StringIndexer.scala:204) finished in 0.016 s\n",
      "10-20 20:36:59.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 362 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:59.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 441: Stage finished\n",
      "10-20 20:36:59.564 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 362 finished: collect at StringIndexer.scala:204, took 0.196115 s\n",
      "10-20 20:36:59.655 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:59.655 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:59.656 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:59.664 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_769 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.669 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_769_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.670 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_769_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.670 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 769 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:59.671 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:59.679 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:59.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 805 (collect at StringIndexer.scala:204) as input to shuffle 55\n",
      "10-20 20:36:59.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 363 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:59.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 443 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:59.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 442)\n",
      "10-20 20:36:59.679 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 442)\n",
      "10-20 20:36:59.680 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 442 (MapPartitionsRDD[805] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:59.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_770 stored as values in memory (estimated size 35.3 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_770_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.683 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_770_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 770 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:59.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 442 (MapPartitionsRDD[805] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:59.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 442.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:59.683 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 442.0 (TID 426) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:59.684 172.17.0.2:54321      18300   (TID 426)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 442.0 (TID 426)\n",
      "10-20 20:36:59.688 172.17.0.2:54321      18300   (TID 426)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:36:59.798 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_766_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.800 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_767_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.803 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_768_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.841 172.17.0.2:54321      18300   (TID 426)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 442.0 (TID 426). 2511 bytes result sent to driver\n",
      "10-20 20:36:59.841 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 442.0 (TID 426) in 158 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:59.841 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 442.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:59.842 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 442 (collect at StringIndexer.scala:204) finished in 0.161 s\n",
      "10-20 20:36:59.843 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:36:59.843 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:36:59.843 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 443)\n",
      "10-20 20:36:59.843 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:36:59.843 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 443 (MapPartitionsRDD[808] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:59.844 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_771 stored as values in memory (estimated size 26.7 KiB, free 433.1 MiB)\n",
      "10-20 20:36:59.845 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_771_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.1 MiB)\n",
      "10-20 20:36:59.845 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_771_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.845 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 771 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:59.846 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 443 (MapPartitionsRDD[808] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:59.846 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 443.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:59.846 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 443.0 (TID 427) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:59.846 172.17.0.2:54321      18300   (TID 427)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 443.0 (TID 427)\n",
      "10-20 20:36:59.849 172.17.0.2:54321      18300   (TID 427)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:36:59.849 172.17.0.2:54321      18300   (TID 427)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:36:59.857 172.17.0.2:54321      18300   (TID 427)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 443.0 (TID 427). 3768 bytes result sent to driver\n",
      "10-20 20:36:59.857 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 443.0 (TID 427) in 11 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:36:59.857 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 443.0, whose tasks have all completed, from pool \n",
      "10-20 20:36:59.857 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 443 (collect at StringIndexer.scala:204) finished in 0.014 s\n",
      "10-20 20:36:59.857 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 363 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:36:59.857 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 443: Stage finished\n",
      "10-20 20:36:59.858 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 363 finished: collect at StringIndexer.scala:204, took 0.178672 s\n",
      "10-20 20:36:59.923 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:36:59.923 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:36:59.923 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:36:59.931 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_772 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:36:59.943 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_770_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.944 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_769_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:36:59.945 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_772_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:36:59.945 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_772_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.946 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 772 from collect at StringIndexer.scala:204\n",
      "10-20 20:36:59.946 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:36:59.956 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_771_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.961 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 20:36:59.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 813 (collect at StringIndexer.scala:204) as input to shuffle 56\n",
      "10-20 20:36:59.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 364 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 20:36:59.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 445 (collect at StringIndexer.scala:204)\n",
      "10-20 20:36:59.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 444)\n",
      "10-20 20:36:59.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 444)\n",
      "10-20 20:36:59.962 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 444 (MapPartitionsRDD[813] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:36:59.964 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_773 stored as values in memory (estimated size 35.3 KiB, free 433.2 MiB)\n",
      "10-20 20:36:59.964 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_773_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.2 MiB)\n",
      "10-20 20:36:59.965 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_773_piece0 in memory on 5b5a8eb7561c:44751 (size: 15.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:36:59.965 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 773 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:36:59.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 444 (MapPartitionsRDD[813] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:36:59.966 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 444.0 with 1 tasks resource profile 0\n",
      "10-20 20:36:59.967 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 444.0 (TID 428) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:36:59.967 172.17.0.2:54321      18300   (TID 428)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 444.0 (TID 428)\n",
      "10-20 20:36:59.974 172.17.0.2:54321      18300   (TID 428)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:37:00.146 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_734_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:00.156 172.17.0.2:54321      18300   (TID 428)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 444.0 (TID 428). 2468 bytes result sent to driver\n",
      "10-20 20:37:00.157 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 444.0 (TID 428) in 190 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:00.157 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 444.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:00.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 444 (collect at StringIndexer.scala:204) finished in 0.195 s\n",
      "10-20 20:37:00.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:37:00.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:37:00.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 445)\n",
      "10-20 20:37:00.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:37:00.158 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 445 (MapPartitionsRDD[816] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 20:37:00.159 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_774 stored as values in memory (estimated size 26.8 KiB, free 433.3 MiB)\n",
      "10-20 20:37:00.160 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_774_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.3 MiB)\n",
      "10-20 20:37:00.160 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_774_piece0 in memory on 5b5a8eb7561c:44751 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:00.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 774 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:00.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 445 (MapPartitionsRDD[816] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:00.161 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 445.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:00.162 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 445.0 (TID 429) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:00.162 172.17.0.2:54321      18300   (TID 429)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 445.0 (TID 429)\n",
      "10-20 20:37:00.165 172.17.0.2:54321      18300   (TID 429)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (955.0 B) non-empty blocks including 1 (955.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:00.165 172.17.0.2:54321      18300   (TID 429)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:00.176 172.17.0.2:54321      18300   (TID 429)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 445.0 (TID 429). 4215 bytes result sent to driver\n",
      "10-20 20:37:00.176 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 445.0 (TID 429) in 15 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:00.177 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 445.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:00.177 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 445 (collect at StringIndexer.scala:204) finished in 0.018 s\n",
      "10-20 20:37:00.177 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 364 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:00.177 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 445: Stage finished\n",
      "10-20 20:37:00.177 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 364 finished: collect at StringIndexer.scala:204, took 0.215654 s\n",
      "10-20 20:37:00.475 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] Stage class: NaiveBayes\n",
      "10-20 20:37:00.476 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] Stage uid: NaiveBayes_3ec24b23f140\n",
      "10-20 20:37:00.535 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_773_piece0 on 5b5a8eb7561c:44751 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:00.537 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_774_piece0 on 5b5a8eb7561c:44751 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:00.546 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:37:00.546 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:37:00.546 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:37:00.619 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 47.452605 ms\n",
      "10-20 20:37:00.621 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_775 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 20:37:00.626 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_775_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:37:00.626 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_775_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:00.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 775 from rdd at Instrumentation.scala:62\n",
      "10-20 20:37:00.627 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:37:00.639 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "10-20 20:37:00.640 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] {\"labelCol\":\"label\",\"featuresCol\":\"features\"}\n",
      "10-20 20:37:00.724 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:37:00.724 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:37:00.724 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:37:00.732 172.17.0.2:54321      18300    Thread-4  WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "10-20 20:37:00.774 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 22.837268 ms\n",
      "10-20 20:37:00.775 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_776 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 20:37:00.787 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_772_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:00.791 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_776_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:37:00.791 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_776_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:00.791 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 776 from collect at NaiveBayes.scala:193\n",
      "10-20 20:37:00.792 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:37:00.810 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at NaiveBayes.scala:193\n",
      "10-20 20:37:00.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 827 (collect at NaiveBayes.scala:193) as input to shuffle 57\n",
      "10-20 20:37:00.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 365 (collect at NaiveBayes.scala:193) with 200 output partitions\n",
      "10-20 20:37:00.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 447 (collect at NaiveBayes.scala:193)\n",
      "10-20 20:37:00.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 446)\n",
      "10-20 20:37:00.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 446)\n",
      "10-20 20:37:00.811 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 446 (MapPartitionsRDD[827] at collect at NaiveBayes.scala:193), which has no missing parents\n",
      "10-20 20:37:00.814 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_777 stored as values in memory (estimated size 135.3 KiB, free 433.1 MiB)\n",
      "10-20 20:37:00.814 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_777_piece0 stored as bytes in memory (estimated size 44.1 KiB, free 433.0 MiB)\n",
      "10-20 20:37:00.816 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_777_piece0 in memory on 5b5a8eb7561c:44751 (size: 44.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:00.816 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 777 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:00.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 446 (MapPartitionsRDD[827] at collect at NaiveBayes.scala:193) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:00.817 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 446.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:00.818 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 446.0 (TID 430) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:00.818 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 446.0 (TID 430)\n",
      "10-20 20:37:00.830 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:37:01.123 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.762826 ms\n",
      "10-20 20:37:01.132 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 2.995664 ms\n",
      "10-20 20:37:01.137 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.885307 ms\n",
      "10-20 20:37:01.141 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.364095 ms\n",
      "10-20 20:37:01.147 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.941624 ms\n",
      "10-20 20:37:01.152 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.509087 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 446:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:37:01.603 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.667343 ms\n",
      "10-20 20:37:01.612 172.17.0.2:54321      18300   (TID 430)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 446.0 (TID 430). 2713 bytes result sent to driver\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 446.0 (TID 430) in 795 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 446.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 446 (collect at NaiveBayes.scala:193) finished in 0.802 s\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 447)\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:37:01.613 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 447 (MapPartitionsRDD[830] at collect at NaiveBayes.scala:193), which has no missing parents\n",
      "10-20 20:37:01.621 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_778 stored as values in memory (estimated size 88.6 KiB, free 432.9 MiB)\n",
      "10-20 20:37:01.622 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_778_piece0 stored as bytes in memory (estimated size 32.2 KiB, free 432.9 MiB)\n",
      "10-20 20:37:01.623 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_778_piece0 in memory on 5b5a8eb7561c:44751 (size: 32.2 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:01.623 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 778 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:01.624 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 200 missing tasks from ResultStage 447 (MapPartitionsRDD[830] at collect at NaiveBayes.scala:193) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "10-20 20:37:01.624 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 447.0 with 200 tasks resource profile 0\n",
      "10-20 20:37:01.626 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 5.0 in stage 447.0 (TID 431) (5b5a8eb7561c, executor driver, partition 5, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.626 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 58.0 in stage 447.0 (TID 432) (5b5a8eb7561c, executor driver, partition 58, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.626 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 447.0 (TID 433) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.627 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 447.0 (TID 434) (5b5a8eb7561c, executor driver, partition 1, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.627 172.17.0.2:54321      18300   (TID 433)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 447.0 (TID 433)\n",
      "10-20 20:37:01.627 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.executor.Executor: Running task 58.0 in stage 447.0 (TID 432)\n",
      "10-20 20:37:01.627 172.17.0.2:54321      18300   (TID 431)  INFO org.apache.spark.executor.Executor: Running task 5.0 in stage 447.0 (TID 431)\n",
      "10-20 20:37:01.639 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (1156.0 B) non-empty blocks including 1 (1156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.639 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.639 172.17.0.2:54321      18300   (TID 431)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (1271.0 B) non-empty blocks including 1 (1271.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.640 172.17.0.2:54321      18300   (TID 431)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.643 172.17.0.2:54321      18300   (TID 434)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 447.0 (TID 434)\n",
      "10-20 20:37:01.646 172.17.0.2:54321      18300   (TID 433)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.646 172.17.0.2:54321      18300   (TID 433)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.647 172.17.0.2:54321      18300   (TID 433)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 447.0 (TID 433). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.647 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 447.0 (TID 435) (5b5a8eb7561c, executor driver, partition 2, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.647 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 447.0 (TID 433) in 21 ms on 5b5a8eb7561c (executor driver) (1/200)\n",
      "10-20 20:37:01.648 172.17.0.2:54321      18300   (TID 435)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 447.0 (TID 435)\n",
      "10-20 20:37:01.650 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 9.235715 ms\n",
      "10-20 20:37:01.652 172.17.0.2:54321      18300   (TID 435)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.653 172.17.0.2:54321      18300   (TID 435)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.653 172.17.0.2:54321      18300   (TID 435)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 447.0 (TID 435). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.653 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 447.0 (TID 436) (5b5a8eb7561c, executor driver, partition 3, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.654 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 447.0 (TID 435) in 7 ms on 5b5a8eb7561c (executor driver) (2/200)\n",
      "10-20 20:37:01.656 172.17.0.2:54321      18300   (TID 434)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.656 172.17.0.2:54321      18300   (TID 434)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.657 172.17.0.2:54321      18300   (TID 434)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 447.0 (TID 434). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.658 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 4.0 in stage 447.0 (TID 437) (5b5a8eb7561c, executor driver, partition 4, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.658 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 447.0 (TID 434) in 32 ms on 5b5a8eb7561c (executor driver) (3/200)\n",
      "10-20 20:37:01.658 172.17.0.2:54321      18300   (TID 437)  INFO org.apache.spark.executor.Executor: Running task 4.0 in stage 447.0 (TID 437)\n",
      "10-20 20:37:01.660 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.594845 ms\n",
      "10-20 20:37:01.663 172.17.0.2:54321      18300   (TID 437)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.663 172.17.0.2:54321      18300   (TID 437)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.663 172.17.0.2:54321      18300   (TID 437)  INFO org.apache.spark.executor.Executor: Finished task 4.0 in stage 447.0 (TID 437). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.665 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 6.0 in stage 447.0 (TID 438) (5b5a8eb7561c, executor driver, partition 6, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.665 172.17.0.2:54321      18300   (TID 438)  INFO org.apache.spark.executor.Executor: Running task 6.0 in stage 447.0 (TID 438)\n",
      "10-20 20:37:01.667 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 4.0 in stage 447.0 (TID 437) in 8 ms on 5b5a8eb7561c (executor driver) (4/200)\n",
      "10-20 20:37:01.667 172.17.0.2:54321      18300   (TID 436)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 447.0 (TID 436)\n",
      "10-20 20:37:01.670 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.228625 ms\n",
      "10-20 20:37:01.674 172.17.0.2:54321      18300   (TID 438)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.674 172.17.0.2:54321      18300   (TID 438)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.675 172.17.0.2:54321      18300   (TID 438)  INFO org.apache.spark.executor.Executor: Finished task 6.0 in stage 447.0 (TID 438). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.676 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 7.0 in stage 447.0 (TID 439) (5b5a8eb7561c, executor driver, partition 7, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.676 172.17.0.2:54321      18300   (TID 439)  INFO org.apache.spark.executor.Executor: Running task 7.0 in stage 447.0 (TID 439)\n",
      "10-20 20:37:01.676 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 6.0 in stage 447.0 (TID 438) in 11 ms on 5b5a8eb7561c (executor driver) (5/200)\n",
      "10-20 20:37:01.681 172.17.0.2:54321      18300   (TID 431)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.037726 ms\n",
      "10-20 20:37:01.682 172.17.0.2:54321      18300   (TID 439)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.685 172.17.0.2:54321      18300   (TID 439)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 20:37:01.685 172.17.0.2:54321      18300   (TID 439)  INFO org.apache.spark.executor.Executor: Finished task 7.0 in stage 447.0 (TID 439). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.686 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 8.0 in stage 447.0 (TID 440) (5b5a8eb7561c, executor driver, partition 8, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.686 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 7.0 in stage 447.0 (TID 439) in 10 ms on 5b5a8eb7561c (executor driver) (6/200)\n",
      "10-20 20:37:01.686 172.17.0.2:54321      18300   (TID 440)  INFO org.apache.spark.executor.Executor: Running task 8.0 in stage 447.0 (TID 440)\n",
      "10-20 20:37:01.689 172.17.0.2:54321      18300   (TID 431)  INFO org.apache.spark.executor.Executor: Finished task 5.0 in stage 447.0 (TID 431). 3863 bytes result sent to driver\n",
      "10-20 20:37:01.690 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 9.0 in stage 447.0 (TID 441) (5b5a8eb7561c, executor driver, partition 9, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.690 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 5.0 in stage 447.0 (TID 431) in 65 ms on 5b5a8eb7561c (executor driver) (7/200)\n",
      "10-20 20:37:01.690 172.17.0.2:54321      18300   (TID 441)  INFO org.apache.spark.executor.Executor: Running task 9.0 in stage 447.0 (TID 441)\n",
      "10-20 20:37:01.692 172.17.0.2:54321      18300   (TID 436)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.692 172.17.0.2:54321      18300   (TID 436)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.692 172.17.0.2:54321      18300   (TID 436)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 447.0 (TID 436). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.693 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 10.0 in stage 447.0 (TID 442) (5b5a8eb7561c, executor driver, partition 10, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.693 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 447.0 (TID 436) in 40 ms on 5b5a8eb7561c (executor driver) (8/200)\n",
      "10-20 20:37:01.694 172.17.0.2:54321      18300   (TID 442)  INFO org.apache.spark.executor.Executor: Running task 10.0 in stage 447.0 (TID 442)\n",
      "10-20 20:37:01.697 172.17.0.2:54321      18300   (TID 432)  INFO org.apache.spark.executor.Executor: Finished task 58.0 in stage 447.0 (TID 432). 3823 bytes result sent to driver\n",
      "10-20 20:37:01.700 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 11.0 in stage 447.0 (TID 443) (5b5a8eb7561c, executor driver, partition 11, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.700 172.17.0.2:54321      18300   (TID 443)  INFO org.apache.spark.executor.Executor: Running task 11.0 in stage 447.0 (TID 443)\n",
      "10-20 20:37:01.700 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 58.0 in stage 447.0 (TID 432) in 74 ms on 5b5a8eb7561c (executor driver) (9/200)\n",
      "10-20 20:37:01.705 172.17.0.2:54321      18300   (TID 441)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.705 172.17.0.2:54321      18300   (TID 441)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.706 172.17.0.2:54321      18300   (TID 441)  INFO org.apache.spark.executor.Executor: Finished task 9.0 in stage 447.0 (TID 441). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.706 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 12.0 in stage 447.0 (TID 444) (5b5a8eb7561c, executor driver, partition 12, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.707 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 9.0 in stage 447.0 (TID 441) in 17 ms on 5b5a8eb7561c (executor driver) (10/200)\n",
      "10-20 20:37:01.707 172.17.0.2:54321      18300   (TID 444)  INFO org.apache.spark.executor.Executor: Running task 12.0 in stage 447.0 (TID 444)\n",
      "10-20 20:37:01.708 172.17.0.2:54321      18300   (TID 442)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.708 172.17.0.2:54321      18300   (TID 442)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.709 172.17.0.2:54321      18300   (TID 442)  INFO org.apache.spark.executor.Executor: Finished task 10.0 in stage 447.0 (TID 442). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.709 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 13.0 in stage 447.0 (TID 445) (5b5a8eb7561c, executor driver, partition 13, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.709 172.17.0.2:54321      18300   (TID 445)  INFO org.apache.spark.executor.Executor: Running task 13.0 in stage 447.0 (TID 445)\n",
      "10-20 20:37:01.710 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 10.0 in stage 447.0 (TID 442) in 17 ms on 5b5a8eb7561c (executor driver) (11/200)\n",
      "10-20 20:37:01.711 172.17.0.2:54321      18300   (TID 440)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.711 172.17.0.2:54321      18300   (TID 440)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.712 172.17.0.2:54321      18300   (TID 440)  INFO org.apache.spark.executor.Executor: Finished task 8.0 in stage 447.0 (TID 440). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.713 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 14.0 in stage 447.0 (TID 446) (5b5a8eb7561c, executor driver, partition 14, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.714 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 8.0 in stage 447.0 (TID 440) in 28 ms on 5b5a8eb7561c (executor driver) (12/200)\n",
      "10-20 20:37:01.714 172.17.0.2:54321      18300   (TID 446)  INFO org.apache.spark.executor.Executor: Running task 14.0 in stage 447.0 (TID 446)\n",
      "10-20 20:37:01.715 172.17.0.2:54321      18300   (TID 444)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.716 172.17.0.2:54321      18300   (TID 444)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.717 172.17.0.2:54321      18300   (TID 444)  INFO org.apache.spark.executor.Executor: Finished task 12.0 in stage 447.0 (TID 444). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.717 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 15.0 in stage 447.0 (TID 447) (5b5a8eb7561c, executor driver, partition 15, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.717 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 12.0 in stage 447.0 (TID 444) in 11 ms on 5b5a8eb7561c (executor driver) (13/200)\n",
      "10-20 20:37:01.718 172.17.0.2:54321      18300   (TID 447)  INFO org.apache.spark.executor.Executor: Running task 15.0 in stage 447.0 (TID 447)\n",
      "10-20 20:37:01.719 172.17.0.2:54321      18300   (TID 443)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.719 172.17.0.2:54321      18300   (TID 443)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.720 172.17.0.2:54321      18300   (TID 445)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.720 172.17.0.2:54321      18300   (TID 445)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.720 172.17.0.2:54321      18300   (TID 445)  INFO org.apache.spark.executor.Executor: Finished task 13.0 in stage 447.0 (TID 445). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.720 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 16.0 in stage 447.0 (TID 448) (5b5a8eb7561c, executor driver, partition 16, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.721 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 13.0 in stage 447.0 (TID 445) in 12 ms on 5b5a8eb7561c (executor driver) (14/200)\n",
      "10-20 20:37:01.721 172.17.0.2:54321      18300   (TID 448)  INFO org.apache.spark.executor.Executor: Running task 16.0 in stage 447.0 (TID 448)\n",
      "10-20 20:37:01.725 172.17.0.2:54321      18300   (TID 447)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.726 172.17.0.2:54321      18300   (TID 447)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.726 172.17.0.2:54321      18300   (TID 447)  INFO org.apache.spark.executor.Executor: Finished task 15.0 in stage 447.0 (TID 447). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.726 172.17.0.2:54321      18300   (TID 443)  INFO org.apache.spark.executor.Executor: Finished task 11.0 in stage 447.0 (TID 443). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.727 172.17.0.2:54321      18300   (TID 448)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.727 172.17.0.2:54321      18300   (TID 448)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.727 172.17.0.2:54321      18300   (TID 448)  INFO org.apache.spark.executor.Executor: Finished task 16.0 in stage 447.0 (TID 448). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.727 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 17.0 in stage 447.0 (TID 449) (5b5a8eb7561c, executor driver, partition 17, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.728 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 18.0 in stage 447.0 (TID 450) (5b5a8eb7561c, executor driver, partition 18, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.728 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 19.0 in stage 447.0 (TID 451) (5b5a8eb7561c, executor driver, partition 19, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.728 172.17.0.2:54321      18300   (TID 450)  INFO org.apache.spark.executor.Executor: Running task 18.0 in stage 447.0 (TID 450)\n",
      "10-20 20:37:01.728 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 15.0 in stage 447.0 (TID 447) in 11 ms on 5b5a8eb7561c (executor driver) (15/200)\n",
      "10-20 20:37:01.728 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 11.0 in stage 447.0 (TID 443) in 28 ms on 5b5a8eb7561c (executor driver) (16/200)\n",
      "10-20 20:37:01.728 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 16.0 in stage 447.0 (TID 448) in 8 ms on 5b5a8eb7561c (executor driver) (17/200)\n",
      "10-20 20:37:01.729 172.17.0.2:54321      18300   (TID 449)  INFO org.apache.spark.executor.Executor: Running task 17.0 in stage 447.0 (TID 449)\n",
      "10-20 20:37:01.729 172.17.0.2:54321      18300   (TID 451)  INFO org.apache.spark.executor.Executor: Running task 19.0 in stage 447.0 (TID 451)\n",
      "10-20 20:37:01.734 172.17.0.2:54321      18300   (TID 450)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.734 172.17.0.2:54321      18300   (TID 449)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.734 172.17.0.2:54321      18300   (TID 450)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.734 172.17.0.2:54321      18300   (TID 449)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.735 172.17.0.2:54321      18300   (TID 449)  INFO org.apache.spark.executor.Executor: Finished task 17.0 in stage 447.0 (TID 449). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.735 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 20.0 in stage 447.0 (TID 452) (5b5a8eb7561c, executor driver, partition 20, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.735 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 17.0 in stage 447.0 (TID 449) in 8 ms on 5b5a8eb7561c (executor driver) (18/200)\n",
      "10-20 20:37:01.736 172.17.0.2:54321      18300   (TID 451)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.736 172.17.0.2:54321      18300   (TID 451)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.737 172.17.0.2:54321      18300   (TID 451)  INFO org.apache.spark.executor.Executor: Finished task 19.0 in stage 447.0 (TID 451). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.742 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 21.0 in stage 447.0 (TID 453) (5b5a8eb7561c, executor driver, partition 21, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.742 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 19.0 in stage 447.0 (TID 451) in 14 ms on 5b5a8eb7561c (executor driver) (19/200)\n",
      "10-20 20:37:01.747 172.17.0.2:54321      18300   (TID 446)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.747 172.17.0.2:54321      18300   (TID 446)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.748 172.17.0.2:54321      18300   (TID 446)  INFO org.apache.spark.executor.Executor: Finished task 14.0 in stage 447.0 (TID 446). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.749 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 22.0 in stage 447.0 (TID 454) (5b5a8eb7561c, executor driver, partition 22, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.749 172.17.0.2:54321      18300   (TID 454)  INFO org.apache.spark.executor.Executor: Running task 22.0 in stage 447.0 (TID 454)\n",
      "10-20 20:37:01.749 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 14.0 in stage 447.0 (TID 446) in 36 ms on 5b5a8eb7561c (executor driver) (20/200)\n",
      "10-20 20:37:01.750 172.17.0.2:54321      18300   (TID 450)  INFO org.apache.spark.executor.Executor: Finished task 18.0 in stage 447.0 (TID 450). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.751 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 23.0 in stage 447.0 (TID 455) (5b5a8eb7561c, executor driver, partition 23, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.751 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 18.0 in stage 447.0 (TID 450) in 23 ms on 5b5a8eb7561c (executor driver) (21/200)\n",
      "10-20 20:37:01.751 172.17.0.2:54321      18300   (TID 455)  INFO org.apache.spark.executor.Executor: Running task 23.0 in stage 447.0 (TID 455)\n",
      "10-20 20:37:01.755 172.17.0.2:54321      18300   (TID 454)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.755 172.17.0.2:54321      18300   (TID 454)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.756 172.17.0.2:54321      18300   (TID 454)  INFO org.apache.spark.executor.Executor: Finished task 22.0 in stage 447.0 (TID 454). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.756 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 24.0 in stage 447.0 (TID 456) (5b5a8eb7561c, executor driver, partition 24, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.756 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 22.0 in stage 447.0 (TID 454) in 8 ms on 5b5a8eb7561c (executor driver) (22/200)\n",
      "10-20 20:37:01.757 172.17.0.2:54321      18300   (TID 456)  INFO org.apache.spark.executor.Executor: Running task 24.0 in stage 447.0 (TID 456)\n",
      "10-20 20:37:01.757 172.17.0.2:54321      18300   (TID 453)  INFO org.apache.spark.executor.Executor: Running task 21.0 in stage 447.0 (TID 453)\n",
      "10-20 20:37:01.758 172.17.0.2:54321      18300   (TID 452)  INFO org.apache.spark.executor.Executor: Running task 20.0 in stage 447.0 (TID 452)\n",
      "10-20 20:37:01.764 172.17.0.2:54321      18300   (TID 456)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.764 172.17.0.2:54321      18300   (TID 456)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.765 172.17.0.2:54321      18300   (TID 455)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.765 172.17.0.2:54321      18300   (TID 455)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.765 172.17.0.2:54321      18300   (TID 455)  INFO org.apache.spark.executor.Executor: Finished task 23.0 in stage 447.0 (TID 455). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.766 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 25.0 in stage 447.0 (TID 457) (5b5a8eb7561c, executor driver, partition 25, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.766 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 23.0 in stage 447.0 (TID 455) in 15 ms on 5b5a8eb7561c (executor driver) (23/200)\n",
      "10-20 20:37:01.766 172.17.0.2:54321      18300   (TID 457)  INFO org.apache.spark.executor.Executor: Running task 25.0 in stage 447.0 (TID 457)\n",
      "10-20 20:37:01.767 172.17.0.2:54321      18300   (TID 452)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.767 172.17.0.2:54321      18300   (TID 452)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:01.767 172.17.0.2:54321      18300   (TID 452)  INFO org.apache.spark.executor.Executor: Finished task 20.0 in stage 447.0 (TID 452). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.769 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 26.0 in stage 447.0 (TID 458) (5b5a8eb7561c, executor driver, partition 26, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.769 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 20.0 in stage 447.0 (TID 452) in 34 ms on 5b5a8eb7561c (executor driver) (24/200)\n",
      "10-20 20:37:01.770 172.17.0.2:54321      18300   (TID 458)  INFO org.apache.spark.executor.Executor: Running task 26.0 in stage 447.0 (TID 458)\n",
      "10-20 20:37:01.772 172.17.0.2:54321      18300   (TID 457)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.772 172.17.0.2:54321      18300   (TID 457)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.774 172.17.0.2:54321      18300   (TID 453)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.775 172.17.0.2:54321      18300   (TID 453)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.775 172.17.0.2:54321      18300   (TID 458)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.775 172.17.0.2:54321      18300   (TID 458)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.775 172.17.0.2:54321      18300   (TID 457)  INFO org.apache.spark.executor.Executor: Finished task 25.0 in stage 447.0 (TID 457). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.776 172.17.0.2:54321      18300   (TID 458)  INFO org.apache.spark.executor.Executor: Finished task 26.0 in stage 447.0 (TID 458). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.776 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 27.0 in stage 447.0 (TID 459) (5b5a8eb7561c, executor driver, partition 27, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.776 172.17.0.2:54321      18300   (TID 453)  INFO org.apache.spark.executor.Executor: Finished task 21.0 in stage 447.0 (TID 453). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.776 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 25.0 in stage 447.0 (TID 457) in 10 ms on 5b5a8eb7561c (executor driver) (25/200)\n",
      "10-20 20:37:01.777 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 28.0 in stage 447.0 (TID 460) (5b5a8eb7561c, executor driver, partition 28, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.777 172.17.0.2:54321      18300   (TID 459)  INFO org.apache.spark.executor.Executor: Running task 27.0 in stage 447.0 (TID 459)\n",
      "10-20 20:37:01.777 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 26.0 in stage 447.0 (TID 458) in 8 ms on 5b5a8eb7561c (executor driver) (26/200)\n",
      "10-20 20:37:01.778 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 29.0 in stage 447.0 (TID 461) (5b5a8eb7561c, executor driver, partition 29, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.778 172.17.0.2:54321      18300   (TID 461)  INFO org.apache.spark.executor.Executor: Running task 29.0 in stage 447.0 (TID 461)\n",
      "10-20 20:37:01.778 172.17.0.2:54321      18300   (TID 460)  INFO org.apache.spark.executor.Executor: Running task 28.0 in stage 447.0 (TID 460)\n",
      "10-20 20:37:01.778 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 21.0 in stage 447.0 (TID 453) in 36 ms on 5b5a8eb7561c (executor driver) (27/200)\n",
      "10-20 20:37:01.781 172.17.0.2:54321      18300   (TID 456)  INFO org.apache.spark.executor.Executor: Finished task 24.0 in stage 447.0 (TID 456). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.782 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 30.0 in stage 447.0 (TID 462) (5b5a8eb7561c, executor driver, partition 30, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.782 172.17.0.2:54321      18300   (TID 462)  INFO org.apache.spark.executor.Executor: Running task 30.0 in stage 447.0 (TID 462)\n",
      "10-20 20:37:01.782 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 24.0 in stage 447.0 (TID 456) in 26 ms on 5b5a8eb7561c (executor driver) (28/200)\n",
      "10-20 20:37:01.784 172.17.0.2:54321      18300   (TID 460)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.784 172.17.0.2:54321      18300   (TID 460)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.785 172.17.0.2:54321      18300   (TID 460)  INFO org.apache.spark.executor.Executor: Finished task 28.0 in stage 447.0 (TID 460). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.785 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 31.0 in stage 447.0 (TID 463) (5b5a8eb7561c, executor driver, partition 31, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.786 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 28.0 in stage 447.0 (TID 460) in 9 ms on 5b5a8eb7561c (executor driver) (29/200)\n",
      "10-20 20:37:01.787 172.17.0.2:54321      18300   (TID 463)  INFO org.apache.spark.executor.Executor: Running task 31.0 in stage 447.0 (TID 463)\n",
      "10-20 20:37:01.789 172.17.0.2:54321      18300   (TID 461)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.790 172.17.0.2:54321      18300   (TID 461)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.790 172.17.0.2:54321      18300   (TID 461)  INFO org.apache.spark.executor.Executor: Finished task 29.0 in stage 447.0 (TID 461). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.792 172.17.0.2:54321      18300   (TID 463)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.792 172.17.0.2:54321      18300   (TID 463)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.793 172.17.0.2:54321      18300   (TID 463)  INFO org.apache.spark.executor.Executor: Finished task 31.0 in stage 447.0 (TID 463). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.793 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 32.0 in stage 447.0 (TID 464) (5b5a8eb7561c, executor driver, partition 32, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.794 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 33.0 in stage 447.0 (TID 465) (5b5a8eb7561c, executor driver, partition 33, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.794 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 29.0 in stage 447.0 (TID 461) in 17 ms on 5b5a8eb7561c (executor driver) (30/200)\n",
      "10-20 20:37:01.794 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 31.0 in stage 447.0 (TID 463) in 9 ms on 5b5a8eb7561c (executor driver) (31/200)\n",
      "10-20 20:37:01.794 172.17.0.2:54321      18300   (TID 464)  INFO org.apache.spark.executor.Executor: Running task 32.0 in stage 447.0 (TID 464)\n",
      "10-20 20:37:01.797 172.17.0.2:54321      18300   (TID 462)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.797 172.17.0.2:54321      18300   (TID 462)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.798 172.17.0.2:54321      18300   (TID 459)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.799 172.17.0.2:54321      18300   (TID 459)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.800 172.17.0.2:54321      18300   (TID 459)  INFO org.apache.spark.executor.Executor: Finished task 27.0 in stage 447.0 (TID 459). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.799 172.17.0.2:54321      18300   (TID 462)  INFO org.apache.spark.executor.Executor: Finished task 30.0 in stage 447.0 (TID 462). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.801 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 34.0 in stage 447.0 (TID 466) (5b5a8eb7561c, executor driver, partition 34, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.801 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 27.0 in stage 447.0 (TID 459) in 25 ms on 5b5a8eb7561c (executor driver) (32/200)\n",
      "10-20 20:37:01.801 172.17.0.2:54321      18300   (TID 465)  INFO org.apache.spark.executor.Executor: Running task 33.0 in stage 447.0 (TID 465)\n",
      "10-20 20:37:01.801 172.17.0.2:54321      18300   (TID 466)  INFO org.apache.spark.executor.Executor: Running task 34.0 in stage 447.0 (TID 466)\n",
      "10-20 20:37:01.801 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 30.0 in stage 447.0 (TID 462) in 19 ms on 5b5a8eb7561c (executor driver) (33/200)\n",
      "10-20 20:37:01.802 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 35.0 in stage 447.0 (TID 467) (5b5a8eb7561c, executor driver, partition 35, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.802 172.17.0.2:54321      18300   (TID 467)  INFO org.apache.spark.executor.Executor: Running task 35.0 in stage 447.0 (TID 467)\n",
      "10-20 20:37:01.810 172.17.0.2:54321      18300   (TID 465)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.819 172.17.0.2:54321      18300   (TID 465)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "10-20 20:37:01.820 172.17.0.2:54321      18300   (TID 465)  INFO org.apache.spark.executor.Executor: Finished task 33.0 in stage 447.0 (TID 465). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.820 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 36.0 in stage 447.0 (TID 468) (5b5a8eb7561c, executor driver, partition 36, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.821 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 33.0 in stage 447.0 (TID 465) in 27 ms on 5b5a8eb7561c (executor driver) (34/200)\n",
      "10-20 20:37:01.821 172.17.0.2:54321      18300   (TID 468)  INFO org.apache.spark.executor.Executor: Running task 36.0 in stage 447.0 (TID 468)\n",
      "10-20 20:37:01.828 172.17.0.2:54321      18300   (TID 468)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.828 172.17.0.2:54321      18300   (TID 468)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.828 172.17.0.2:54321      18300   (TID 468)  INFO org.apache.spark.executor.Executor: Finished task 36.0 in stage 447.0 (TID 468). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.829 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 37.0 in stage 447.0 (TID 469) (5b5a8eb7561c, executor driver, partition 37, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.829 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 36.0 in stage 447.0 (TID 468) in 9 ms on 5b5a8eb7561c (executor driver) (35/200)\n",
      "10-20 20:37:01.831 172.17.0.2:54321      18300   (TID 469)  INFO org.apache.spark.executor.Executor: Running task 37.0 in stage 447.0 (TID 469)\n",
      "10-20 20:37:01.819 172.17.0.2:54321      18300   (TID 467)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.817 172.17.0.2:54321      18300   (TID 464)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.835 172.17.0.2:54321      18300   (TID 464)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms\n",
      "10-20 20:37:01.835 172.17.0.2:54321      18300   (TID 469)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.835 172.17.0.2:54321      18300   (TID 469)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.836 172.17.0.2:54321      18300   (TID 464)  INFO org.apache.spark.executor.Executor: Finished task 32.0 in stage 447.0 (TID 464). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.836 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 38.0 in stage 447.0 (TID 470) (5b5a8eb7561c, executor driver, partition 38, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.819 172.17.0.2:54321      18300   (TID 466)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.837 172.17.0.2:54321      18300   (TID 470)  INFO org.apache.spark.executor.Executor: Running task 38.0 in stage 447.0 (TID 470)\n",
      "10-20 20:37:01.837 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 32.0 in stage 447.0 (TID 464) in 44 ms on 5b5a8eb7561c (executor driver) (36/200)\n",
      "10-20 20:37:01.837 172.17.0.2:54321      18300   (TID 469)  INFO org.apache.spark.executor.Executor: Finished task 37.0 in stage 447.0 (TID 469). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.838 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 39.0 in stage 447.0 (TID 471) (5b5a8eb7561c, executor driver, partition 39, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.838 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 37.0 in stage 447.0 (TID 469) in 9 ms on 5b5a8eb7561c (executor driver) (37/200)\n",
      "10-20 20:37:01.839 172.17.0.2:54321      18300   (TID 471)  INFO org.apache.spark.executor.Executor: Running task 39.0 in stage 447.0 (TID 471)\n",
      "10-20 20:37:01.843 172.17.0.2:54321      18300   (TID 470)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.843 172.17.0.2:54321      18300   (TID 470)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.843 172.17.0.2:54321      18300   (TID 466)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms\n",
      "10-20 20:37:01.844 172.17.0.2:54321      18300   (TID 467)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms\n",
      "10-20 20:37:01.845 172.17.0.2:54321      18300   (TID 466)  INFO org.apache.spark.executor.Executor: Finished task 34.0 in stage 447.0 (TID 466). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.846 172.17.0.2:54321      18300   (TID 467)  INFO org.apache.spark.executor.Executor: Finished task 35.0 in stage 447.0 (TID 467). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.847 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 40.0 in stage 447.0 (TID 472) (5b5a8eb7561c, executor driver, partition 40, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.847 172.17.0.2:54321      18300   (TID 472)  INFO org.apache.spark.executor.Executor: Running task 40.0 in stage 447.0 (TID 472)\n",
      "10-20 20:37:01.847 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 41.0 in stage 447.0 (TID 473) (5b5a8eb7561c, executor driver, partition 41, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.847 172.17.0.2:54321      18300   (TID 473)  INFO org.apache.spark.executor.Executor: Running task 41.0 in stage 447.0 (TID 473)\n",
      "10-20 20:37:01.847 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 34.0 in stage 447.0 (TID 466) in 46 ms on 5b5a8eb7561c (executor driver) (38/200)\n",
      "10-20 20:37:01.848 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 35.0 in stage 447.0 (TID 467) in 46 ms on 5b5a8eb7561c (executor driver) (39/200)\n",
      "10-20 20:37:01.849 172.17.0.2:54321      18300   (TID 471)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.849 172.17.0.2:54321      18300   (TID 471)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.850 172.17.0.2:54321      18300   (TID 471)  INFO org.apache.spark.executor.Executor: Finished task 39.0 in stage 447.0 (TID 471). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.850 172.17.0.2:54321      18300   (TID 470)  INFO org.apache.spark.executor.Executor: Finished task 38.0 in stage 447.0 (TID 470). 3363 bytes result sent to driver\n",
      "10-20 20:37:01.851 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 42.0 in stage 447.0 (TID 474) (5b5a8eb7561c, executor driver, partition 42, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.851 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 39.0 in stage 447.0 (TID 471) in 13 ms on 5b5a8eb7561c (executor driver) (40/200)\n",
      "10-20 20:37:01.851 172.17.0.2:54321      18300   (TID 474)  INFO org.apache.spark.executor.Executor: Running task 42.0 in stage 447.0 (TID 474)\n",
      "10-20 20:37:01.854 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 43.0 in stage 447.0 (TID 475) (5b5a8eb7561c, executor driver, partition 43, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.855 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 38.0 in stage 447.0 (TID 470) in 18 ms on 5b5a8eb7561c (executor driver) (41/200)\n",
      "10-20 20:37:01.855 172.17.0.2:54321      18300   (TID 475)  INFO org.apache.spark.executor.Executor: Running task 43.0 in stage 447.0 (TID 475)\n",
      "10-20 20:37:01.857 172.17.0.2:54321      18300   (TID 474)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.857 172.17.0.2:54321      18300   (TID 474)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.857 172.17.0.2:54321      18300   (TID 474)  INFO org.apache.spark.executor.Executor: Finished task 42.0 in stage 447.0 (TID 474). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.858 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 44.0 in stage 447.0 (TID 476) (5b5a8eb7561c, executor driver, partition 44, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.859 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 42.0 in stage 447.0 (TID 474) in 9 ms on 5b5a8eb7561c (executor driver) (42/200)\n",
      "10-20 20:37:01.859 172.17.0.2:54321      18300   (TID 476)  INFO org.apache.spark.executor.Executor: Running task 44.0 in stage 447.0 (TID 476)\n",
      "10-20 20:37:01.865 172.17.0.2:54321      18300   (TID 472)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.865 172.17.0.2:54321      18300   (TID 472)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.866 172.17.0.2:54321      18300   (TID 476)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.866 172.17.0.2:54321      18300   (TID 476)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.867 172.17.0.2:54321      18300   (TID 476)  INFO org.apache.spark.executor.Executor: Finished task 44.0 in stage 447.0 (TID 476). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.867 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 45.0 in stage 447.0 (TID 477) (5b5a8eb7561c, executor driver, partition 45, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.868 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 44.0 in stage 447.0 (TID 476) in 10 ms on 5b5a8eb7561c (executor driver) (43/200)\n",
      "10-20 20:37:01.868 172.17.0.2:54321      18300   (TID 477)  INFO org.apache.spark.executor.Executor: Running task 45.0 in stage 447.0 (TID 477)\n",
      "10-20 20:37:01.874 172.17.0.2:54321      18300   (TID 475)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.874 172.17.0.2:54321      18300   (TID 475)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.875 172.17.0.2:54321      18300   (TID 472)  INFO org.apache.spark.executor.Executor: Finished task 40.0 in stage 447.0 (TID 472). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.876 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 46.0 in stage 447.0 (TID 478) (5b5a8eb7561c, executor driver, partition 46, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.877 172.17.0.2:54321      18300   (TID 478)  INFO org.apache.spark.executor.Executor: Running task 46.0 in stage 447.0 (TID 478)\n",
      "10-20 20:37:01.877 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 40.0 in stage 447.0 (TID 472) in 30 ms on 5b5a8eb7561c (executor driver) (44/200)\n",
      "10-20 20:37:01.878 172.17.0.2:54321      18300   (TID 475)  INFO org.apache.spark.executor.Executor: Finished task 43.0 in stage 447.0 (TID 475). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.878 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 47.0 in stage 447.0 (TID 479) (5b5a8eb7561c, executor driver, partition 47, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.878 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 43.0 in stage 447.0 (TID 475) in 24 ms on 5b5a8eb7561c (executor driver) (45/200)\n",
      "10-20 20:37:01.878 172.17.0.2:54321      18300   (TID 479)  INFO org.apache.spark.executor.Executor: Running task 47.0 in stage 447.0 (TID 479)\n",
      "10-20 20:37:01.881 172.17.0.2:54321      18300   (TID 477)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.881 172.17.0.2:54321      18300   (TID 477)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.883 172.17.0.2:54321      18300   (TID 477)  INFO org.apache.spark.executor.Executor: Finished task 45.0 in stage 447.0 (TID 477). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.883 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 48.0 in stage 447.0 (TID 480) (5b5a8eb7561c, executor driver, partition 48, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.883 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 45.0 in stage 447.0 (TID 477) in 16 ms on 5b5a8eb7561c (executor driver) (46/200)\n",
      "10-20 20:37:01.884 172.17.0.2:54321      18300   (TID 480)  INFO org.apache.spark.executor.Executor: Running task 48.0 in stage 447.0 (TID 480)\n",
      "10-20 20:37:01.885 172.17.0.2:54321      18300   (TID 473)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.885 172.17.0.2:54321      18300   (TID 473)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.889 172.17.0.2:54321      18300   (TID 473)  INFO org.apache.spark.executor.Executor: Finished task 41.0 in stage 447.0 (TID 473). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.889 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 49.0 in stage 447.0 (TID 481) (5b5a8eb7561c, executor driver, partition 49, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.890 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 41.0 in stage 447.0 (TID 473) in 43 ms on 5b5a8eb7561c (executor driver) (47/200)\n",
      "10-20 20:37:01.890 172.17.0.2:54321      18300   (TID 481)  INFO org.apache.spark.executor.Executor: Running task 49.0 in stage 447.0 (TID 481)\n",
      "10-20 20:37:01.892 172.17.0.2:54321      18300   (TID 478)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.893 172.17.0.2:54321      18300   (TID 478)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.894 172.17.0.2:54321      18300   (TID 478)  INFO org.apache.spark.executor.Executor: Finished task 46.0 in stage 447.0 (TID 478). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.894 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 50.0 in stage 447.0 (TID 482) (5b5a8eb7561c, executor driver, partition 50, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.895 172.17.0.2:54321      18300   (TID 480)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.895 172.17.0.2:54321      18300   (TID 480)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.895 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 46.0 in stage 447.0 (TID 478) in 19 ms on 5b5a8eb7561c (executor driver) (48/200)\n",
      "10-20 20:37:01.896 172.17.0.2:54321      18300   (TID 482)  INFO org.apache.spark.executor.Executor: Running task 50.0 in stage 447.0 (TID 482)\n",
      "10-20 20:37:01.900 172.17.0.2:54321      18300   (TID 479)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.900 172.17.0.2:54321      18300   (TID 479)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.901 172.17.0.2:54321      18300   (TID 479)  INFO org.apache.spark.executor.Executor: Finished task 47.0 in stage 447.0 (TID 479). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.901 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 51.0 in stage 447.0 (TID 483) (5b5a8eb7561c, executor driver, partition 51, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.901 172.17.0.2:54321      18300   (TID 480)  INFO org.apache.spark.executor.Executor: Finished task 48.0 in stage 447.0 (TID 480). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.901 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 47.0 in stage 447.0 (TID 479) in 23 ms on 5b5a8eb7561c (executor driver) (49/200)\n",
      "10-20 20:37:01.902 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 52.0 in stage 447.0 (TID 484) (5b5a8eb7561c, executor driver, partition 52, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.902 172.17.0.2:54321      18300   (TID 484)  INFO org.apache.spark.executor.Executor: Running task 52.0 in stage 447.0 (TID 484)\n",
      "10-20 20:37:01.902 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 48.0 in stage 447.0 (TID 480) in 19 ms on 5b5a8eb7561c (executor driver) (50/200)\n",
      "10-20 20:37:01.904 172.17.0.2:54321      18300   (TID 482)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.904 172.17.0.2:54321      18300   (TID 482)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.905 172.17.0.2:54321      18300   (TID 482)  INFO org.apache.spark.executor.Executor: Finished task 50.0 in stage 447.0 (TID 482). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.905 172.17.0.2:54321      18300   (TID 481)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.905 172.17.0.2:54321      18300   (TID 481)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.906 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 53.0 in stage 447.0 (TID 485) (5b5a8eb7561c, executor driver, partition 53, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.906 172.17.0.2:54321      18300   (TID 481)  INFO org.apache.spark.executor.Executor: Finished task 49.0 in stage 447.0 (TID 481). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.906 172.17.0.2:54321      18300   (TID 485)  INFO org.apache.spark.executor.Executor: Running task 53.0 in stage 447.0 (TID 485)\n",
      "10-20 20:37:01.906 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 50.0 in stage 447.0 (TID 482) in 12 ms on 5b5a8eb7561c (executor driver) (51/200)\n",
      "10-20 20:37:01.906 172.17.0.2:54321      18300   (TID 483)  INFO org.apache.spark.executor.Executor: Running task 51.0 in stage 447.0 (TID 483)\n",
      "10-20 20:37:01.910 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 54.0 in stage 447.0 (TID 486) (5b5a8eb7561c, executor driver, partition 54, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.911 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 49.0 in stage 447.0 (TID 481) in 22 ms on 5b5a8eb7561c (executor driver) (52/200)\n",
      "10-20 20:37:01.913 172.17.0.2:54321      18300   (TID 484)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.913 172.17.0.2:54321      18300   (TID 484)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.914 172.17.0.2:54321      18300   (TID 486)  INFO org.apache.spark.executor.Executor: Running task 54.0 in stage 447.0 (TID 486)\n",
      "10-20 20:37:01.915 172.17.0.2:54321      18300   (TID 485)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.914 172.17.0.2:54321      18300   (TID 484)  INFO org.apache.spark.executor.Executor: Finished task 52.0 in stage 447.0 (TID 484). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.917 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 55.0 in stage 447.0 (TID 487) (5b5a8eb7561c, executor driver, partition 55, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.918 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 52.0 in stage 447.0 (TID 484) in 16 ms on 5b5a8eb7561c (executor driver) (53/200)\n",
      "10-20 20:37:01.918 172.17.0.2:54321      18300   (TID 487)  INFO org.apache.spark.executor.Executor: Running task 55.0 in stage 447.0 (TID 487)\n",
      "10-20 20:37:01.922 172.17.0.2:54321      18300   (TID 486)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.925 172.17.0.2:54321      18300   (TID 485)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms\n",
      "10-20 20:37:01.926 172.17.0.2:54321      18300   (TID 486)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 20:37:01.928 172.17.0.2:54321      18300   (TID 485)  INFO org.apache.spark.executor.Executor: Finished task 53.0 in stage 447.0 (TID 485). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.928 172.17.0.2:54321      18300   (TID 483)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.929 172.17.0.2:54321      18300   (TID 487)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.928 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 56.0 in stage 447.0 (TID 488) (5b5a8eb7561c, executor driver, partition 56, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.930 172.17.0.2:54321      18300   (TID 483)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 20:37:01.931 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 53.0 in stage 447.0 (TID 485) in 25 ms on 5b5a8eb7561c (executor driver) (54/200)\n",
      "10-20 20:37:01.932 172.17.0.2:54321      18300   (TID 483)  INFO org.apache.spark.executor.Executor: Finished task 51.0 in stage 447.0 (TID 483). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.932 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 57.0 in stage 447.0 (TID 489) (5b5a8eb7561c, executor driver, partition 57, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.933 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 51.0 in stage 447.0 (TID 483) in 32 ms on 5b5a8eb7561c (executor driver) (55/200)\n",
      "10-20 20:37:01.932 172.17.0.2:54321      18300   (TID 486)  INFO org.apache.spark.executor.Executor: Finished task 54.0 in stage 447.0 (TID 486). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.933 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 59.0 in stage 447.0 (TID 490) (5b5a8eb7561c, executor driver, partition 59, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.933 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 54.0 in stage 447.0 (TID 486) in 23 ms on 5b5a8eb7561c (executor driver) (56/200)\n",
      "10-20 20:37:01.933 172.17.0.2:54321      18300   (TID 490)  INFO org.apache.spark.executor.Executor: Running task 59.0 in stage 447.0 (TID 490)\n",
      "10-20 20:37:01.935 172.17.0.2:54321      18300   (TID 489)  INFO org.apache.spark.executor.Executor: Running task 57.0 in stage 447.0 (TID 489)\n",
      "10-20 20:37:01.936 172.17.0.2:54321      18300   (TID 488)  INFO org.apache.spark.executor.Executor: Running task 56.0 in stage 447.0 (TID 488)\n",
      "10-20 20:37:01.940 172.17.0.2:54321      18300   (TID 490)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.940 172.17.0.2:54321      18300   (TID 490)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.940 172.17.0.2:54321      18300   (TID 487)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms\n",
      "10-20 20:37:01.941 172.17.0.2:54321      18300   (TID 487)  INFO org.apache.spark.executor.Executor: Finished task 55.0 in stage 447.0 (TID 487). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.941 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 60.0 in stage 447.0 (TID 491) (5b5a8eb7561c, executor driver, partition 60, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.942 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 55.0 in stage 447.0 (TID 487) in 25 ms on 5b5a8eb7561c (executor driver) (57/200)\n",
      "10-20 20:37:01.941 172.17.0.2:54321      18300   (TID 490)  INFO org.apache.spark.executor.Executor: Finished task 59.0 in stage 447.0 (TID 490). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.944 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 61.0 in stage 447.0 (TID 492) (5b5a8eb7561c, executor driver, partition 61, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.945 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 59.0 in stage 447.0 (TID 490) in 12 ms on 5b5a8eb7561c (executor driver) (58/200)\n",
      "10-20 20:37:01.945 172.17.0.2:54321      18300   (TID 492)  INFO org.apache.spark.executor.Executor: Running task 61.0 in stage 447.0 (TID 492)\n",
      "10-20 20:37:01.946 172.17.0.2:54321      18300   (TID 489)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.946 172.17.0.2:54321      18300   (TID 489)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.947 172.17.0.2:54321      18300   (TID 489)  INFO org.apache.spark.executor.Executor: Finished task 57.0 in stage 447.0 (TID 489). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.947 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 62.0 in stage 447.0 (TID 493) (5b5a8eb7561c, executor driver, partition 62, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.947 172.17.0.2:54321      18300   (TID 493)  INFO org.apache.spark.executor.Executor: Running task 62.0 in stage 447.0 (TID 493)\n",
      "10-20 20:37:01.948 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 57.0 in stage 447.0 (TID 489) in 16 ms on 5b5a8eb7561c (executor driver) (59/200)\n",
      "10-20 20:37:01.950 172.17.0.2:54321      18300   (TID 488)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.950 172.17.0.2:54321      18300   (TID 488)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.951 172.17.0.2:54321      18300   (TID 491)  INFO org.apache.spark.executor.Executor: Running task 60.0 in stage 447.0 (TID 491)\n",
      "10-20 20:37:01.957 172.17.0.2:54321      18300   (TID 488)  INFO org.apache.spark.executor.Executor: Finished task 56.0 in stage 447.0 (TID 488). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.957 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 63.0 in stage 447.0 (TID 494) (5b5a8eb7561c, executor driver, partition 63, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.958 172.17.0.2:54321      18300   (TID 494)  INFO org.apache.spark.executor.Executor: Running task 63.0 in stage 447.0 (TID 494)\n",
      "10-20 20:37:01.958 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 56.0 in stage 447.0 (TID 488) in 30 ms on 5b5a8eb7561c (executor driver) (60/200)\n",
      "10-20 20:37:01.959 172.17.0.2:54321      18300   (TID 493)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.959 172.17.0.2:54321      18300   (TID 493)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.960 172.17.0.2:54321      18300   (TID 493)  INFO org.apache.spark.executor.Executor: Finished task 62.0 in stage 447.0 (TID 493). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.960 172.17.0.2:54321      18300   (TID 492)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.960 172.17.0.2:54321      18300   (TID 492)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.960 172.17.0.2:54321      18300   (TID 492)  INFO org.apache.spark.executor.Executor: Finished task 61.0 in stage 447.0 (TID 492). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.962 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 64.0 in stage 447.0 (TID 495) (5b5a8eb7561c, executor driver, partition 64, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.962 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 65.0 in stage 447.0 (TID 496) (5b5a8eb7561c, executor driver, partition 65, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.962 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 62.0 in stage 447.0 (TID 493) in 15 ms on 5b5a8eb7561c (executor driver) (61/200)\n",
      "10-20 20:37:01.962 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 61.0 in stage 447.0 (TID 492) in 18 ms on 5b5a8eb7561c (executor driver) (62/200)\n",
      "10-20 20:37:01.963 172.17.0.2:54321      18300   (TID 496)  INFO org.apache.spark.executor.Executor: Running task 65.0 in stage 447.0 (TID 496)\n",
      "10-20 20:37:01.964 172.17.0.2:54321      18300   (TID 494)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.964 172.17.0.2:54321      18300   (TID 494)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.964 172.17.0.2:54321      18300   (TID 494)  INFO org.apache.spark.executor.Executor: Finished task 63.0 in stage 447.0 (TID 494). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.965 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 66.0 in stage 447.0 (TID 497) (5b5a8eb7561c, executor driver, partition 66, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.965 172.17.0.2:54321      18300   (TID 491)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.965 172.17.0.2:54321      18300   (TID 497)  INFO org.apache.spark.executor.Executor: Running task 66.0 in stage 447.0 (TID 497)\n",
      "10-20 20:37:01.965 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 63.0 in stage 447.0 (TID 494) in 8 ms on 5b5a8eb7561c (executor driver) (63/200)\n",
      "10-20 20:37:01.966 172.17.0.2:54321      18300   (TID 495)  INFO org.apache.spark.executor.Executor: Running task 64.0 in stage 447.0 (TID 495)\n",
      "10-20 20:37:01.971 172.17.0.2:54321      18300   (TID 497)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.972 172.17.0.2:54321      18300   (TID 491)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 20:37:01.972 172.17.0.2:54321      18300   (TID 491)  INFO org.apache.spark.executor.Executor: Finished task 60.0 in stage 447.0 (TID 491). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.972 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 67.0 in stage 447.0 (TID 498) (5b5a8eb7561c, executor driver, partition 67, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.972 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 60.0 in stage 447.0 (TID 491) in 31 ms on 5b5a8eb7561c (executor driver) (64/200)\n",
      "10-20 20:37:01.973 172.17.0.2:54321      18300   (TID 498)  INFO org.apache.spark.executor.Executor: Running task 67.0 in stage 447.0 (TID 498)\n",
      "10-20 20:37:01.977 172.17.0.2:54321      18300   (TID 498)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.977 172.17.0.2:54321      18300   (TID 498)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.977 172.17.0.2:54321      18300   (TID 498)  INFO org.apache.spark.executor.Executor: Finished task 67.0 in stage 447.0 (TID 498). 3277 bytes result sent to driver\n",
      "10-20 20:37:01.977 172.17.0.2:54321      18300   (TID 497)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 20:37:01.978 172.17.0.2:54321      18300   (TID 497)  INFO org.apache.spark.executor.Executor: Finished task 66.0 in stage 447.0 (TID 497). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.978 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 68.0 in stage 447.0 (TID 499) (5b5a8eb7561c, executor driver, partition 68, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.978 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 67.0 in stage 447.0 (TID 498) in 6 ms on 5b5a8eb7561c (executor driver) (65/200)\n",
      "10-20 20:37:01.978 172.17.0.2:54321      18300   (TID 499)  INFO org.apache.spark.executor.Executor: Running task 68.0 in stage 447.0 (TID 499)\n",
      "10-20 20:37:01.978 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 69.0 in stage 447.0 (TID 500) (5b5a8eb7561c, executor driver, partition 69, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.979 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 66.0 in stage 447.0 (TID 497) in 15 ms on 5b5a8eb7561c (executor driver) (66/200)\n",
      "10-20 20:37:01.979 172.17.0.2:54321      18300   (TID 500)  INFO org.apache.spark.executor.Executor: Running task 69.0 in stage 447.0 (TID 500)\n",
      "10-20 20:37:01.980 172.17.0.2:54321      18300   (TID 496)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.981 172.17.0.2:54321      18300   (TID 496)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.981 172.17.0.2:54321      18300   (TID 496)  INFO org.apache.spark.executor.Executor: Finished task 65.0 in stage 447.0 (TID 496). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.982 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 70.0 in stage 447.0 (TID 501) (5b5a8eb7561c, executor driver, partition 70, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.982 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 65.0 in stage 447.0 (TID 496) in 20 ms on 5b5a8eb7561c (executor driver) (67/200)\n",
      "10-20 20:37:01.982 172.17.0.2:54321      18300   (TID 495)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.982 172.17.0.2:54321      18300   (TID 501)  INFO org.apache.spark.executor.Executor: Running task 70.0 in stage 447.0 (TID 501)\n",
      "10-20 20:37:01.983 172.17.0.2:54321      18300   (TID 495)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.984 172.17.0.2:54321      18300   (TID 495)  INFO org.apache.spark.executor.Executor: Finished task 64.0 in stage 447.0 (TID 495). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.984 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 71.0 in stage 447.0 (TID 502) (5b5a8eb7561c, executor driver, partition 71, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.984 172.17.0.2:54321      18300   (TID 502)  INFO org.apache.spark.executor.Executor: Running task 71.0 in stage 447.0 (TID 502)\n",
      "10-20 20:37:01.984 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 64.0 in stage 447.0 (TID 495) in 23 ms on 5b5a8eb7561c (executor driver) (68/200)\n",
      "10-20 20:37:01.987 172.17.0.2:54321      18300   (TID 501)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.987 172.17.0.2:54321      18300   (TID 501)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.991 172.17.0.2:54321      18300   (TID 502)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.991 172.17.0.2:54321      18300   (TID 502)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.991 172.17.0.2:54321      18300   (TID 501)  INFO org.apache.spark.executor.Executor: Finished task 70.0 in stage 447.0 (TID 501). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.992 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 72.0 in stage 447.0 (TID 503) (5b5a8eb7561c, executor driver, partition 72, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.992 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 70.0 in stage 447.0 (TID 501) in 10 ms on 5b5a8eb7561c (executor driver) (69/200)\n",
      "10-20 20:37:01.992 172.17.0.2:54321      18300   (TID 503)  INFO org.apache.spark.executor.Executor: Running task 72.0 in stage 447.0 (TID 503)\n",
      "10-20 20:37:01.993 172.17.0.2:54321      18300   (TID 500)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.993 172.17.0.2:54321      18300   (TID 500)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.994 172.17.0.2:54321      18300   (TID 499)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.994 172.17.0.2:54321      18300   (TID 499)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.995 172.17.0.2:54321      18300   (TID 499)  INFO org.apache.spark.executor.Executor: Finished task 68.0 in stage 447.0 (TID 499). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.995 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 73.0 in stage 447.0 (TID 504) (5b5a8eb7561c, executor driver, partition 73, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.995 172.17.0.2:54321      18300   (TID 500)  INFO org.apache.spark.executor.Executor: Finished task 69.0 in stage 447.0 (TID 500). 3320 bytes result sent to driver\n",
      "10-20 20:37:01.995 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 74.0 in stage 447.0 (TID 505) (5b5a8eb7561c, executor driver, partition 74, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:01.996 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 68.0 in stage 447.0 (TID 499) in 19 ms on 5b5a8eb7561c (executor driver) (70/200)\n",
      "10-20 20:37:01.996 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 69.0 in stage 447.0 (TID 500) in 18 ms on 5b5a8eb7561c (executor driver) (71/200)\n",
      "10-20 20:37:01.996 172.17.0.2:54321      18300   (TID 505)  INFO org.apache.spark.executor.Executor: Running task 74.0 in stage 447.0 (TID 505)\n",
      "10-20 20:37:01.999 172.17.0.2:54321      18300   (TID 503)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:01.999 172.17.0.2:54321      18300   (TID 503)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:01.999 172.17.0.2:54321      18300   (TID 504)  INFO org.apache.spark.executor.Executor: Running task 73.0 in stage 447.0 (TID 504)\n",
      "10-20 20:37:02.000 172.17.0.2:54321      18300   (TID 503)  INFO org.apache.spark.executor.Executor: Finished task 72.0 in stage 447.0 (TID 503). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.001 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 75.0 in stage 447.0 (TID 506) (5b5a8eb7561c, executor driver, partition 75, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.001 172.17.0.2:54321      18300   (TID 506)  INFO org.apache.spark.executor.Executor: Running task 75.0 in stage 447.0 (TID 506)\n",
      "10-20 20:37:02.001 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 72.0 in stage 447.0 (TID 503) in 10 ms on 5b5a8eb7561c (executor driver) (72/200)\n",
      "10-20 20:37:02.002 172.17.0.2:54321      18300   (TID 505)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.002 172.17.0.2:54321      18300   (TID 505)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.002 172.17.0.2:54321      18300   (TID 502)  INFO org.apache.spark.executor.Executor: Finished task 71.0 in stage 447.0 (TID 502). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.003 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 76.0 in stage 447.0 (TID 507) (5b5a8eb7561c, executor driver, partition 76, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.003 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 71.0 in stage 447.0 (TID 502) in 19 ms on 5b5a8eb7561c (executor driver) (73/200)\n",
      "10-20 20:37:02.003 172.17.0.2:54321      18300   (TID 507)  INFO org.apache.spark.executor.Executor: Running task 76.0 in stage 447.0 (TID 507)\n",
      "10-20 20:37:02.004 172.17.0.2:54321      18300   (TID 505)  INFO org.apache.spark.executor.Executor: Finished task 74.0 in stage 447.0 (TID 505). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.004 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 77.0 in stage 447.0 (TID 508) (5b5a8eb7561c, executor driver, partition 77, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.004 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 74.0 in stage 447.0 (TID 505) in 9 ms on 5b5a8eb7561c (executor driver) (74/200)\n",
      "10-20 20:37:02.005 172.17.0.2:54321      18300   (TID 508)  INFO org.apache.spark.executor.Executor: Running task 77.0 in stage 447.0 (TID 508)\n",
      "10-20 20:37:02.009 172.17.0.2:54321      18300   (TID 508)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.009 172.17.0.2:54321      18300   (TID 508)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.011 172.17.0.2:54321      18300   (TID 504)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.011 172.17.0.2:54321      18300   (TID 504)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.011 172.17.0.2:54321      18300   (TID 504)  INFO org.apache.spark.executor.Executor: Finished task 73.0 in stage 447.0 (TID 504). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.012 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 78.0 in stage 447.0 (TID 509) (5b5a8eb7561c, executor driver, partition 78, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.012 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 73.0 in stage 447.0 (TID 504) in 17 ms on 5b5a8eb7561c (executor driver) (75/200)\n",
      "10-20 20:37:02.012 172.17.0.2:54321      18300   (TID 509)  INFO org.apache.spark.executor.Executor: Running task 78.0 in stage 447.0 (TID 509)\n",
      "10-20 20:37:02.014 172.17.0.2:54321      18300   (TID 507)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.014 172.17.0.2:54321      18300   (TID 507)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.014 172.17.0.2:54321      18300   (TID 506)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.015 172.17.0.2:54321      18300   (TID 506)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.015 172.17.0.2:54321      18300   (TID 506)  INFO org.apache.spark.executor.Executor: Finished task 75.0 in stage 447.0 (TID 506). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.016 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 79.0 in stage 447.0 (TID 510) (5b5a8eb7561c, executor driver, partition 79, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.016 172.17.0.2:54321      18300   (TID 510)  INFO org.apache.spark.executor.Executor: Running task 79.0 in stage 447.0 (TID 510)\n",
      "10-20 20:37:02.016 172.17.0.2:54321      18300   (TID 509)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.016 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 75.0 in stage 447.0 (TID 506) in 15 ms on 5b5a8eb7561c (executor driver) (76/200)\n",
      "10-20 20:37:02.016 172.17.0.2:54321      18300   (TID 509)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.017 172.17.0.2:54321      18300   (TID 509)  INFO org.apache.spark.executor.Executor: Finished task 78.0 in stage 447.0 (TID 509). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.018 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 80.0 in stage 447.0 (TID 511) (5b5a8eb7561c, executor driver, partition 80, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.018 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 78.0 in stage 447.0 (TID 509) in 7 ms on 5b5a8eb7561c (executor driver) (77/200)\n",
      "10-20 20:37:02.018 172.17.0.2:54321      18300   (TID 511)  INFO org.apache.spark.executor.Executor: Running task 80.0 in stage 447.0 (TID 511)\n",
      "10-20 20:37:02.019 172.17.0.2:54321      18300   (TID 507)  INFO org.apache.spark.executor.Executor: Finished task 76.0 in stage 447.0 (TID 507). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.020 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 81.0 in stage 447.0 (TID 512) (5b5a8eb7561c, executor driver, partition 81, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.021 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 76.0 in stage 447.0 (TID 507) in 18 ms on 5b5a8eb7561c (executor driver) (78/200)\n",
      "10-20 20:37:02.021 172.17.0.2:54321      18300   (TID 512)  INFO org.apache.spark.executor.Executor: Running task 81.0 in stage 447.0 (TID 512)\n",
      "10-20 20:37:02.041 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_777_piece0 on 5b5a8eb7561c:44751 in memory (size: 44.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:02.042 172.17.0.2:54321      18300   (TID 511)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.042 172.17.0.2:54321      18300   (TID 511)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.042 172.17.0.2:54321      18300   (TID 511)  INFO org.apache.spark.executor.Executor: Finished task 80.0 in stage 447.0 (TID 511). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.043 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 82.0 in stage 447.0 (TID 513) (5b5a8eb7561c, executor driver, partition 82, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.043 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 80.0 in stage 447.0 (TID 511) in 25 ms on 5b5a8eb7561c (executor driver) (79/200)\n",
      "10-20 20:37:02.044 172.17.0.2:54321      18300   (TID 510)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.044 172.17.0.2:54321      18300   (TID 510)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.045 172.17.0.2:54321      18300   (TID 510)  INFO org.apache.spark.executor.Executor: Finished task 79.0 in stage 447.0 (TID 510). 3363 bytes result sent to driver\n",
      "10-20 20:37:02.046 172.17.0.2:54321      18300   (TID 512)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.046 172.17.0.2:54321      18300   (TID 512)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.047 172.17.0.2:54321      18300   (TID 512)  INFO org.apache.spark.executor.Executor: Finished task 81.0 in stage 447.0 (TID 512). 3363 bytes result sent to driver\n",
      "10-20 20:37:02.048 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 83.0 in stage 447.0 (TID 514) (5b5a8eb7561c, executor driver, partition 83, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.048 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 79.0 in stage 447.0 (TID 510) in 32 ms on 5b5a8eb7561c (executor driver) (80/200)\n",
      "10-20 20:37:02.048 172.17.0.2:54321      18300   (TID 514)  INFO org.apache.spark.executor.Executor: Running task 83.0 in stage 447.0 (TID 514)\n",
      "10-20 20:37:02.049 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 81.0 in stage 447.0 (TID 512) in 28 ms on 5b5a8eb7561c (executor driver) (81/200)\n",
      "10-20 20:37:02.050 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 84.0 in stage 447.0 (TID 515) (5b5a8eb7561c, executor driver, partition 84, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.050 172.17.0.2:54321      18300   (TID 515)  INFO org.apache.spark.executor.Executor: Running task 84.0 in stage 447.0 (TID 515)\n",
      "10-20 20:37:02.055 172.17.0.2:54321      18300   (TID 508)  INFO org.apache.spark.executor.Executor: Finished task 77.0 in stage 447.0 (TID 508). 3363 bytes result sent to driver\n",
      "10-20 20:37:02.060 172.17.0.2:54321      18300   (TID 513)  INFO org.apache.spark.executor.Executor: Running task 82.0 in stage 447.0 (TID 513)\n",
      "10-20 20:37:02.064 172.17.0.2:54321      18300   (TID 513)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.065 172.17.0.2:54321      18300   (TID 513)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.065 172.17.0.2:54321      18300   (TID 513)  INFO org.apache.spark.executor.Executor: Finished task 82.0 in stage 447.0 (TID 513). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.064 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 85.0 in stage 447.0 (TID 516) (5b5a8eb7561c, executor driver, partition 85, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.066 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 77.0 in stage 447.0 (TID 508) in 62 ms on 5b5a8eb7561c (executor driver) (82/200)\n",
      "10-20 20:37:02.066 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 82.0 in stage 447.0 (TID 513) in 23 ms on 5b5a8eb7561c (executor driver) (83/200)\n",
      "10-20 20:37:02.066 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 86.0 in stage 447.0 (TID 517) (5b5a8eb7561c, executor driver, partition 86, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.066 172.17.0.2:54321      18300   (TID 517)  INFO org.apache.spark.executor.Executor: Running task 86.0 in stage 447.0 (TID 517)\n",
      "10-20 20:37:02.066 172.17.0.2:54321      18300   (TID 516)  INFO org.apache.spark.executor.Executor: Running task 85.0 in stage 447.0 (TID 516)\n",
      "10-20 20:37:02.069 172.17.0.2:54321      18300   (TID 516)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.069 172.17.0.2:54321      18300   (TID 517)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.069 172.17.0.2:54321      18300   (TID 517)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.069 172.17.0.2:54321      18300   (TID 516)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.070 172.17.0.2:54321      18300   (TID 517)  INFO org.apache.spark.executor.Executor: Finished task 86.0 in stage 447.0 (TID 517). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.070 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 87.0 in stage 447.0 (TID 518) (5b5a8eb7561c, executor driver, partition 87, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.070 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 86.0 in stage 447.0 (TID 517) in 4 ms on 5b5a8eb7561c (executor driver) (84/200)\n",
      "10-20 20:37:02.071 172.17.0.2:54321      18300   (TID 518)  INFO org.apache.spark.executor.Executor: Running task 87.0 in stage 447.0 (TID 518)\n",
      "10-20 20:37:02.073 172.17.0.2:54321      18300   (TID 515)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.073 172.17.0.2:54321      18300   (TID 515)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300   (TID 514)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300   (TID 514)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300   (TID 515)  INFO org.apache.spark.executor.Executor: Finished task 84.0 in stage 447.0 (TID 515). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300   (TID 518)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300   (TID 518)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 88.0 in stage 447.0 (TID 519) (5b5a8eb7561c, executor driver, partition 88, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.075 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 84.0 in stage 447.0 (TID 515) in 26 ms on 5b5a8eb7561c (executor driver) (85/200)\n",
      "10-20 20:37:02.076 172.17.0.2:54321      18300   (TID 519)  INFO org.apache.spark.executor.Executor: Running task 88.0 in stage 447.0 (TID 519)\n",
      "10-20 20:37:02.076 172.17.0.2:54321      18300   (TID 514)  INFO org.apache.spark.executor.Executor: Finished task 83.0 in stage 447.0 (TID 514). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.077 172.17.0.2:54321      18300   (TID 518)  INFO org.apache.spark.executor.Executor: Finished task 87.0 in stage 447.0 (TID 518). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.076 172.17.0.2:54321      18300   (TID 516)  INFO org.apache.spark.executor.Executor: Finished task 85.0 in stage 447.0 (TID 516). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.077 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 89.0 in stage 447.0 (TID 520) (5b5a8eb7561c, executor driver, partition 89, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.077 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 90.0 in stage 447.0 (TID 521) (5b5a8eb7561c, executor driver, partition 90, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.078 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 91.0 in stage 447.0 (TID 522) (5b5a8eb7561c, executor driver, partition 91, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.078 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 83.0 in stage 447.0 (TID 514) in 31 ms on 5b5a8eb7561c (executor driver) (86/200)\n",
      "10-20 20:37:02.078 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 87.0 in stage 447.0 (TID 518) in 8 ms on 5b5a8eb7561c (executor driver) (87/200)\n",
      "10-20 20:37:02.078 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 85.0 in stage 447.0 (TID 516) in 14 ms on 5b5a8eb7561c (executor driver) (88/200)\n",
      "10-20 20:37:02.078 172.17.0.2:54321      18300   (TID 520)  INFO org.apache.spark.executor.Executor: Running task 89.0 in stage 447.0 (TID 520)\n",
      "10-20 20:37:02.079 172.17.0.2:54321      18300   (TID 521)  INFO org.apache.spark.executor.Executor: Running task 90.0 in stage 447.0 (TID 521)\n",
      "10-20 20:37:02.079 172.17.0.2:54321      18300   (TID 522)  INFO org.apache.spark.executor.Executor: Running task 91.0 in stage 447.0 (TID 522)\n",
      "10-20 20:37:02.082 172.17.0.2:54321      18300   (TID 520)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.082 172.17.0.2:54321      18300   (TID 520)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.082 172.17.0.2:54321      18300   (TID 520)  INFO org.apache.spark.executor.Executor: Finished task 89.0 in stage 447.0 (TID 520). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.082 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 92.0 in stage 447.0 (TID 523) (5b5a8eb7561c, executor driver, partition 92, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.083 172.17.0.2:54321      18300   (TID 523)  INFO org.apache.spark.executor.Executor: Running task 92.0 in stage 447.0 (TID 523)\n",
      "10-20 20:37:02.083 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 89.0 in stage 447.0 (TID 520) in 6 ms on 5b5a8eb7561c (executor driver) (89/200)\n",
      "10-20 20:37:02.085 172.17.0.2:54321      18300   (TID 521)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.085 172.17.0.2:54321      18300   (TID 521)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.086 172.17.0.2:54321      18300   (TID 521)  INFO org.apache.spark.executor.Executor: Finished task 90.0 in stage 447.0 (TID 521). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.086 172.17.0.2:54321      18300   (TID 523)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.086 172.17.0.2:54321      18300   (TID 523)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.087 172.17.0.2:54321      18300   (TID 523)  INFO org.apache.spark.executor.Executor: Finished task 92.0 in stage 447.0 (TID 523). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.087 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 93.0 in stage 447.0 (TID 524) (5b5a8eb7561c, executor driver, partition 93, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.087 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 90.0 in stage 447.0 (TID 521) in 10 ms on 5b5a8eb7561c (executor driver) (90/200)\n",
      "10-20 20:37:02.088 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 94.0 in stage 447.0 (TID 525) (5b5a8eb7561c, executor driver, partition 94, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.088 172.17.0.2:54321      18300   (TID 525)  INFO org.apache.spark.executor.Executor: Running task 94.0 in stage 447.0 (TID 525)\n",
      "10-20 20:37:02.088 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 92.0 in stage 447.0 (TID 523) in 6 ms on 5b5a8eb7561c (executor driver) (91/200)\n",
      "10-20 20:37:02.089 172.17.0.2:54321      18300   (TID 524)  INFO org.apache.spark.executor.Executor: Running task 93.0 in stage 447.0 (TID 524)\n",
      "10-20 20:37:02.094 172.17.0.2:54321      18300   (TID 522)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.094 172.17.0.2:54321      18300   (TID 522)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.094 172.17.0.2:54321      18300   (TID 519)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.094 172.17.0.2:54321      18300   (TID 519)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:02.095 172.17.0.2:54321      18300   (TID 519)  INFO org.apache.spark.executor.Executor: Finished task 88.0 in stage 447.0 (TID 519). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.095 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 95.0 in stage 447.0 (TID 526) (5b5a8eb7561c, executor driver, partition 95, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.095 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 88.0 in stage 447.0 (TID 519) in 20 ms on 5b5a8eb7561c (executor driver) (92/200)\n",
      "10-20 20:37:02.095 172.17.0.2:54321      18300   (TID 526)  INFO org.apache.spark.executor.Executor: Running task 95.0 in stage 447.0 (TID 526)\n",
      "10-20 20:37:02.096 172.17.0.2:54321      18300   (TID 522)  INFO org.apache.spark.executor.Executor: Finished task 91.0 in stage 447.0 (TID 522). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.097 172.17.0.2:54321      18300   (TID 524)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.097 172.17.0.2:54321      18300   (TID 524)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.097 172.17.0.2:54321      18300   (TID 525)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.098 172.17.0.2:54321      18300   (TID 525)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.098 172.17.0.2:54321      18300   (TID 524)  INFO org.apache.spark.executor.Executor: Finished task 93.0 in stage 447.0 (TID 524). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.098 172.17.0.2:54321      18300   (TID 525)  INFO org.apache.spark.executor.Executor: Finished task 94.0 in stage 447.0 (TID 525). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.099 172.17.0.2:54321      18300   (TID 526)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.099 172.17.0.2:54321      18300   (TID 526)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.099 172.17.0.2:54321      18300   (TID 526)  INFO org.apache.spark.executor.Executor: Finished task 95.0 in stage 447.0 (TID 526). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.100 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 96.0 in stage 447.0 (TID 527) (5b5a8eb7561c, executor driver, partition 96, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.100 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 97.0 in stage 447.0 (TID 528) (5b5a8eb7561c, executor driver, partition 97, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.100 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 98.0 in stage 447.0 (TID 529) (5b5a8eb7561c, executor driver, partition 98, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.100 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 99.0 in stage 447.0 (TID 530) (5b5a8eb7561c, executor driver, partition 99, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.101 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 91.0 in stage 447.0 (TID 522) in 22 ms on 5b5a8eb7561c (executor driver) (93/200)\n",
      "10-20 20:37:02.101 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 93.0 in stage 447.0 (TID 524) in 14 ms on 5b5a8eb7561c (executor driver) (94/200)\n",
      "10-20 20:37:02.101 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 94.0 in stage 447.0 (TID 525) in 13 ms on 5b5a8eb7561c (executor driver) (95/200)\n",
      "10-20 20:37:02.101 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 95.0 in stage 447.0 (TID 526) in 6 ms on 5b5a8eb7561c (executor driver) (96/200)\n",
      "10-20 20:37:02.101 172.17.0.2:54321      18300   (TID 527)  INFO org.apache.spark.executor.Executor: Running task 96.0 in stage 447.0 (TID 527)\n",
      "10-20 20:37:02.101 172.17.0.2:54321      18300   (TID 529)  INFO org.apache.spark.executor.Executor: Running task 98.0 in stage 447.0 (TID 529)\n",
      "10-20 20:37:02.105 172.17.0.2:54321      18300   (TID 527)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.105 172.17.0.2:54321      18300   (TID 527)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.105 172.17.0.2:54321      18300   (TID 529)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.105 172.17.0.2:54321      18300   (TID 529)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.105 172.17.0.2:54321      18300   (TID 530)  INFO org.apache.spark.executor.Executor: Running task 99.0 in stage 447.0 (TID 530)\n",
      "10-20 20:37:02.106 172.17.0.2:54321      18300   (TID 529)  INFO org.apache.spark.executor.Executor: Finished task 98.0 in stage 447.0 (TID 529). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.106 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 100.0 in stage 447.0 (TID 531) (5b5a8eb7561c, executor driver, partition 100, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.106 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 98.0 in stage 447.0 (TID 529) in 6 ms on 5b5a8eb7561c (executor driver) (97/200)\n",
      "10-20 20:37:02.107 172.17.0.2:54321      18300   (TID 531)  INFO org.apache.spark.executor.Executor: Running task 100.0 in stage 447.0 (TID 531)\n",
      "10-20 20:37:02.110 172.17.0.2:54321      18300   (TID 530)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.110 172.17.0.2:54321      18300   (TID 530)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.110 172.17.0.2:54321      18300   (TID 530)  INFO org.apache.spark.executor.Executor: Finished task 99.0 in stage 447.0 (TID 530). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.110 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 101.0 in stage 447.0 (TID 532) (5b5a8eb7561c, executor driver, partition 101, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.111 172.17.0.2:54321      18300   (TID 532)  INFO org.apache.spark.executor.Executor: Running task 101.0 in stage 447.0 (TID 532)\n",
      "10-20 20:37:02.105 172.17.0.2:54321      18300   (TID 527)  INFO org.apache.spark.executor.Executor: Finished task 96.0 in stage 447.0 (TID 527). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.111 172.17.0.2:54321      18300   (TID 528)  INFO org.apache.spark.executor.Executor: Running task 97.0 in stage 447.0 (TID 528)\n",
      "10-20 20:37:02.111 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 99.0 in stage 447.0 (TID 530) in 11 ms on 5b5a8eb7561c (executor driver) (98/200)\n",
      "10-20 20:37:02.111 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 102.0 in stage 447.0 (TID 533) (5b5a8eb7561c, executor driver, partition 102, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.111 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 96.0 in stage 447.0 (TID 527) in 11 ms on 5b5a8eb7561c (executor driver) (99/200)\n",
      "10-20 20:37:02.111 172.17.0.2:54321      18300   (TID 533)  INFO org.apache.spark.executor.Executor: Running task 102.0 in stage 447.0 (TID 533)\n",
      "10-20 20:37:02.113 172.17.0.2:54321      18300   (TID 531)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.113 172.17.0.2:54321      18300   (TID 531)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.114 172.17.0.2:54321      18300   (TID 531)  INFO org.apache.spark.executor.Executor: Finished task 100.0 in stage 447.0 (TID 531). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.114 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 103.0 in stage 447.0 (TID 534) (5b5a8eb7561c, executor driver, partition 103, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.114 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 100.0 in stage 447.0 (TID 531) in 8 ms on 5b5a8eb7561c (executor driver) (100/200)\n",
      "10-20 20:37:02.115 172.17.0.2:54321      18300   (TID 534)  INFO org.apache.spark.executor.Executor: Running task 103.0 in stage 447.0 (TID 534)\n",
      "10-20 20:37:02.116 172.17.0.2:54321      18300   (TID 532)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.116 172.17.0.2:54321      18300   (TID 532)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.117 172.17.0.2:54321      18300   (TID 532)  INFO org.apache.spark.executor.Executor: Finished task 101.0 in stage 447.0 (TID 532). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.117 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 104.0 in stage 447.0 (TID 535) (5b5a8eb7561c, executor driver, partition 104, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.117 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 101.0 in stage 447.0 (TID 532) in 7 ms on 5b5a8eb7561c (executor driver) (101/200)\n",
      "10-20 20:37:02.117 172.17.0.2:54321      18300   (TID 535)  INFO org.apache.spark.executor.Executor: Running task 104.0 in stage 447.0 (TID 535)\n",
      "10-20 20:37:02.119 172.17.0.2:54321      18300   (TID 533)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.119 172.17.0.2:54321      18300   (TID 533)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.120 172.17.0.2:54321      18300   (TID 533)  INFO org.apache.spark.executor.Executor: Finished task 102.0 in stage 447.0 (TID 533). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.120 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 105.0 in stage 447.0 (TID 536) (5b5a8eb7561c, executor driver, partition 105, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.120 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 102.0 in stage 447.0 (TID 533) in 9 ms on 5b5a8eb7561c (executor driver) (102/200)\n",
      "10-20 20:37:02.120 172.17.0.2:54321      18300   (TID 536)  INFO org.apache.spark.executor.Executor: Running task 105.0 in stage 447.0 (TID 536)\n",
      "10-20 20:37:02.122 172.17.0.2:54321      18300   (TID 534)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.122 172.17.0.2:54321      18300   (TID 534)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.123 172.17.0.2:54321      18300   (TID 534)  INFO org.apache.spark.executor.Executor: Finished task 103.0 in stage 447.0 (TID 534). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.123 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 106.0 in stage 447.0 (TID 537) (5b5a8eb7561c, executor driver, partition 106, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.124 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 103.0 in stage 447.0 (TID 534) in 10 ms on 5b5a8eb7561c (executor driver) (103/200)\n",
      "10-20 20:37:02.124 172.17.0.2:54321      18300   (TID 535)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.124 172.17.0.2:54321      18300   (TID 535)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.125 172.17.0.2:54321      18300   (TID 537)  INFO org.apache.spark.executor.Executor: Running task 106.0 in stage 447.0 (TID 537)\n",
      "10-20 20:37:02.124 172.17.0.2:54321      18300   (TID 528)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.125 172.17.0.2:54321      18300   (TID 528)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.125 172.17.0.2:54321      18300   (TID 535)  INFO org.apache.spark.executor.Executor: Finished task 104.0 in stage 447.0 (TID 535). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.125 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 107.0 in stage 447.0 (TID 538) (5b5a8eb7561c, executor driver, partition 107, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.126 172.17.0.2:54321      18300   (TID 538)  INFO org.apache.spark.executor.Executor: Running task 107.0 in stage 447.0 (TID 538)\n",
      "10-20 20:37:02.126 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 104.0 in stage 447.0 (TID 535) in 9 ms on 5b5a8eb7561c (executor driver) (104/200)\n",
      "10-20 20:37:02.126 172.17.0.2:54321      18300   (TID 528)  INFO org.apache.spark.executor.Executor: Finished task 97.0 in stage 447.0 (TID 528). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.126 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 108.0 in stage 447.0 (TID 539) (5b5a8eb7561c, executor driver, partition 108, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.126 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 97.0 in stage 447.0 (TID 528) in 26 ms on 5b5a8eb7561c (executor driver) (105/200)\n",
      "10-20 20:37:02.126 172.17.0.2:54321      18300   (TID 539)  INFO org.apache.spark.executor.Executor: Running task 108.0 in stage 447.0 (TID 539)\n",
      "10-20 20:37:02.128 172.17.0.2:54321      18300   (TID 536)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.128 172.17.0.2:54321      18300   (TID 536)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.129 172.17.0.2:54321      18300   (TID 536)  INFO org.apache.spark.executor.Executor: Finished task 105.0 in stage 447.0 (TID 536). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.129 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 109.0 in stage 447.0 (TID 540) (5b5a8eb7561c, executor driver, partition 109, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.129 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 105.0 in stage 447.0 (TID 536) in 9 ms on 5b5a8eb7561c (executor driver) (106/200)\n",
      "10-20 20:37:02.129 172.17.0.2:54321      18300   (TID 540)  INFO org.apache.spark.executor.Executor: Running task 109.0 in stage 447.0 (TID 540)\n",
      "10-20 20:37:02.132 172.17.0.2:54321      18300   (TID 537)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.132 172.17.0.2:54321      18300   (TID 537)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.132 172.17.0.2:54321      18300   (TID 537)  INFO org.apache.spark.executor.Executor: Finished task 106.0 in stage 447.0 (TID 537). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.133 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 110.0 in stage 447.0 (TID 541) (5b5a8eb7561c, executor driver, partition 110, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.133 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 106.0 in stage 447.0 (TID 537) in 10 ms on 5b5a8eb7561c (executor driver) (107/200)\n",
      "10-20 20:37:02.132 172.17.0.2:54321      18300   (TID 538)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.133 172.17.0.2:54321      18300   (TID 538)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:02.134 172.17.0.2:54321      18300   (TID 538)  INFO org.apache.spark.executor.Executor: Finished task 107.0 in stage 447.0 (TID 538). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.134 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 111.0 in stage 447.0 (TID 542) (5b5a8eb7561c, executor driver, partition 111, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.134 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 107.0 in stage 447.0 (TID 538) in 9 ms on 5b5a8eb7561c (executor driver) (108/200)\n",
      "10-20 20:37:02.134 172.17.0.2:54321      18300   (TID 542)  INFO org.apache.spark.executor.Executor: Running task 111.0 in stage 447.0 (TID 542)\n",
      "10-20 20:37:02.132 172.17.0.2:54321      18300   (TID 539)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.136 172.17.0.2:54321      18300   (TID 539)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 20:37:02.136 172.17.0.2:54321      18300   (TID 540)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.136 172.17.0.2:54321      18300   (TID 540)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.137 172.17.0.2:54321      18300   (TID 540)  INFO org.apache.spark.executor.Executor: Finished task 109.0 in stage 447.0 (TID 540). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.137 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 112.0 in stage 447.0 (TID 543) (5b5a8eb7561c, executor driver, partition 112, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.137 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 109.0 in stage 447.0 (TID 540) in 8 ms on 5b5a8eb7561c (executor driver) (109/200)\n",
      "10-20 20:37:02.137 172.17.0.2:54321      18300   (TID 543)  INFO org.apache.spark.executor.Executor: Running task 112.0 in stage 447.0 (TID 543)\n",
      "10-20 20:37:02.133 172.17.0.2:54321      18300   (TID 541)  INFO org.apache.spark.executor.Executor: Running task 110.0 in stage 447.0 (TID 541)\n",
      "10-20 20:37:02.139 172.17.0.2:54321      18300   (TID 542)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.139 172.17.0.2:54321      18300   (TID 542)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.140 172.17.0.2:54321      18300   (TID 539)  INFO org.apache.spark.executor.Executor: Finished task 108.0 in stage 447.0 (TID 539). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.140 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 113.0 in stage 447.0 (TID 544) (5b5a8eb7561c, executor driver, partition 113, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.140 172.17.0.2:54321      18300   (TID 544)  INFO org.apache.spark.executor.Executor: Running task 113.0 in stage 447.0 (TID 544)\n",
      "10-20 20:37:02.140 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 108.0 in stage 447.0 (TID 539) in 14 ms on 5b5a8eb7561c (executor driver) (110/200)\n",
      "10-20 20:37:02.141 172.17.0.2:54321      18300   (TID 542)  INFO org.apache.spark.executor.Executor: Finished task 111.0 in stage 447.0 (TID 542). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.141 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 114.0 in stage 447.0 (TID 545) (5b5a8eb7561c, executor driver, partition 114, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.142 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 111.0 in stage 447.0 (TID 542) in 8 ms on 5b5a8eb7561c (executor driver) (111/200)\n",
      "10-20 20:37:02.142 172.17.0.2:54321      18300   (TID 545)  INFO org.apache.spark.executor.Executor: Running task 114.0 in stage 447.0 (TID 545)\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 545)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 545)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 544)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 544)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 541)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 541)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.145 172.17.0.2:54321      18300   (TID 545)  INFO org.apache.spark.executor.Executor: Finished task 114.0 in stage 447.0 (TID 545). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 115.0 in stage 447.0 (TID 546) (5b5a8eb7561c, executor driver, partition 115, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300   (TID 546)  INFO org.apache.spark.executor.Executor: Running task 115.0 in stage 447.0 (TID 546)\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 114.0 in stage 447.0 (TID 545) in 5 ms on 5b5a8eb7561c (executor driver) (112/200)\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300   (TID 543)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300   (TID 543)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300   (TID 543)  INFO org.apache.spark.executor.Executor: Finished task 112.0 in stage 447.0 (TID 543). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.146 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 116.0 in stage 447.0 (TID 547) (5b5a8eb7561c, executor driver, partition 116, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.147 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 112.0 in stage 447.0 (TID 543) in 10 ms on 5b5a8eb7561c (executor driver) (113/200)\n",
      "10-20 20:37:02.147 172.17.0.2:54321      18300   (TID 547)  INFO org.apache.spark.executor.Executor: Running task 116.0 in stage 447.0 (TID 547)\n",
      "10-20 20:37:02.150 172.17.0.2:54321      18300   (TID 546)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.150 172.17.0.2:54321      18300   (TID 547)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.151 172.17.0.2:54321      18300   (TID 547)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.151 172.17.0.2:54321      18300   (TID 547)  INFO org.apache.spark.executor.Executor: Finished task 116.0 in stage 447.0 (TID 547). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.152 172.17.0.2:54321      18300   (TID 541)  INFO org.apache.spark.executor.Executor: Finished task 110.0 in stage 447.0 (TID 541). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.152 172.17.0.2:54321      18300   (TID 544)  INFO org.apache.spark.executor.Executor: Finished task 113.0 in stage 447.0 (TID 544). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.153 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 117.0 in stage 447.0 (TID 548) (5b5a8eb7561c, executor driver, partition 117, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.153 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 118.0 in stage 447.0 (TID 549) (5b5a8eb7561c, executor driver, partition 118, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.153 172.17.0.2:54321      18300   (TID 548)  INFO org.apache.spark.executor.Executor: Running task 117.0 in stage 447.0 (TID 548)\n",
      "10-20 20:37:02.153 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 119.0 in stage 447.0 (TID 550) (5b5a8eb7561c, executor driver, partition 119, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.153 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 116.0 in stage 447.0 (TID 547) in 7 ms on 5b5a8eb7561c (executor driver) (114/200)\n",
      "10-20 20:37:02.154 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 110.0 in stage 447.0 (TID 541) in 22 ms on 5b5a8eb7561c (executor driver) (115/200)\n",
      "10-20 20:37:02.154 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 113.0 in stage 447.0 (TID 544) in 14 ms on 5b5a8eb7561c (executor driver) (116/200)\n",
      "10-20 20:37:02.154 172.17.0.2:54321      18300   (TID 550)  INFO org.apache.spark.executor.Executor: Running task 119.0 in stage 447.0 (TID 550)\n",
      "10-20 20:37:02.154 172.17.0.2:54321      18300   (TID 549)  INFO org.apache.spark.executor.Executor: Running task 118.0 in stage 447.0 (TID 549)\n",
      "10-20 20:37:02.157 172.17.0.2:54321      18300   (TID 550)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.157 172.17.0.2:54321      18300   (TID 550)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.158 172.17.0.2:54321      18300   (TID 550)  INFO org.apache.spark.executor.Executor: Finished task 119.0 in stage 447.0 (TID 550). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.158 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 120.0 in stage 447.0 (TID 551) (5b5a8eb7561c, executor driver, partition 120, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.158 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 119.0 in stage 447.0 (TID 550) in 5 ms on 5b5a8eb7561c (executor driver) (117/200)\n",
      "10-20 20:37:02.158 172.17.0.2:54321      18300   (TID 551)  INFO org.apache.spark.executor.Executor: Running task 120.0 in stage 447.0 (TID 551)\n",
      "10-20 20:37:02.159 172.17.0.2:54321      18300   (TID 546)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "10-20 20:37:02.159 172.17.0.2:54321      18300   (TID 546)  INFO org.apache.spark.executor.Executor: Finished task 115.0 in stage 447.0 (TID 546). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.160 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 121.0 in stage 447.0 (TID 552) (5b5a8eb7561c, executor driver, partition 121, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.160 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 115.0 in stage 447.0 (TID 546) in 14 ms on 5b5a8eb7561c (executor driver) (118/200)\n",
      "10-20 20:37:02.160 172.17.0.2:54321      18300   (TID 552)  INFO org.apache.spark.executor.Executor: Running task 121.0 in stage 447.0 (TID 552)\n",
      "10-20 20:37:02.163 172.17.0.2:54321      18300   (TID 549)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.163 172.17.0.2:54321      18300   (TID 549)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.163 172.17.0.2:54321      18300   (TID 548)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.163 172.17.0.2:54321      18300   (TID 548)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.164 172.17.0.2:54321      18300   (TID 548)  INFO org.apache.spark.executor.Executor: Finished task 117.0 in stage 447.0 (TID 548). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.164 172.17.0.2:54321      18300   (TID 551)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.164 172.17.0.2:54321      18300   (TID 551)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.164 172.17.0.2:54321      18300   (TID 549)  INFO org.apache.spark.executor.Executor: Finished task 118.0 in stage 447.0 (TID 549). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.164 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 122.0 in stage 447.0 (TID 553) (5b5a8eb7561c, executor driver, partition 122, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.165 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 117.0 in stage 447.0 (TID 548) in 12 ms on 5b5a8eb7561c (executor driver) (119/200)\n",
      "10-20 20:37:02.165 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 123.0 in stage 447.0 (TID 554) (5b5a8eb7561c, executor driver, partition 123, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.165 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 118.0 in stage 447.0 (TID 549) in 12 ms on 5b5a8eb7561c (executor driver) (120/200)\n",
      "10-20 20:37:02.165 172.17.0.2:54321      18300   (TID 554)  INFO org.apache.spark.executor.Executor: Running task 123.0 in stage 447.0 (TID 554)\n",
      "10-20 20:37:02.165 172.17.0.2:54321      18300   (TID 553)  INFO org.apache.spark.executor.Executor: Running task 122.0 in stage 447.0 (TID 553)\n",
      "10-20 20:37:02.168 172.17.0.2:54321      18300   (TID 552)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.168 172.17.0.2:54321      18300   (TID 552)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.168 172.17.0.2:54321      18300   (TID 554)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.168 172.17.0.2:54321      18300   (TID 554)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.169 172.17.0.2:54321      18300   (TID 553)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.169 172.17.0.2:54321      18300   (TID 554)  INFO org.apache.spark.executor.Executor: Finished task 123.0 in stage 447.0 (TID 554). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.169 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 124.0 in stage 447.0 (TID 555) (5b5a8eb7561c, executor driver, partition 124, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.169 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 123.0 in stage 447.0 (TID 554) in 4 ms on 5b5a8eb7561c (executor driver) (121/200)\n",
      "10-20 20:37:02.169 172.17.0.2:54321      18300   (TID 555)  INFO org.apache.spark.executor.Executor: Running task 124.0 in stage 447.0 (TID 555)\n",
      "10-20 20:37:02.173 172.17.0.2:54321      18300   (TID 551)  INFO org.apache.spark.executor.Executor: Finished task 120.0 in stage 447.0 (TID 551). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.174 172.17.0.2:54321      18300   (TID 553)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "10-20 20:37:02.174 172.17.0.2:54321      18300   (TID 553)  INFO org.apache.spark.executor.Executor: Finished task 122.0 in stage 447.0 (TID 553). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.174 172.17.0.2:54321      18300   (TID 552)  INFO org.apache.spark.executor.Executor: Finished task 121.0 in stage 447.0 (TID 552). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.175 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 125.0 in stage 447.0 (TID 556) (5b5a8eb7561c, executor driver, partition 125, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.175 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 126.0 in stage 447.0 (TID 557) (5b5a8eb7561c, executor driver, partition 126, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.175 172.17.0.2:54321      18300   (TID 556)  INFO org.apache.spark.executor.Executor: Running task 125.0 in stage 447.0 (TID 556)\n",
      "10-20 20:37:02.176 172.17.0.2:54321      18300   (TID 557)  INFO org.apache.spark.executor.Executor: Running task 126.0 in stage 447.0 (TID 557)\n",
      "10-20 20:37:02.175 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 127.0 in stage 447.0 (TID 558) (5b5a8eb7561c, executor driver, partition 127, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.176 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 120.0 in stage 447.0 (TID 551) in 18 ms on 5b5a8eb7561c (executor driver) (122/200)\n",
      "10-20 20:37:02.176 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 121.0 in stage 447.0 (TID 552) in 16 ms on 5b5a8eb7561c (executor driver) (123/200)\n",
      "10-20 20:37:02.176 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 122.0 in stage 447.0 (TID 553) in 12 ms on 5b5a8eb7561c (executor driver) (124/200)\n",
      "10-20 20:37:02.179 172.17.0.2:54321      18300   (TID 558)  INFO org.apache.spark.executor.Executor: Running task 127.0 in stage 447.0 (TID 558)\n",
      "10-20 20:37:02.181 172.17.0.2:54321      18300   (TID 555)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.181 172.17.0.2:54321      18300   (TID 555)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.186 172.17.0.2:54321      18300   (TID 555)  INFO org.apache.spark.executor.Executor: Finished task 124.0 in stage 447.0 (TID 555). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.187 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 128.0 in stage 447.0 (TID 559) (5b5a8eb7561c, executor driver, partition 128, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.187 172.17.0.2:54321      18300   (TID 559)  INFO org.apache.spark.executor.Executor: Running task 128.0 in stage 447.0 (TID 559)\n",
      "10-20 20:37:02.187 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 124.0 in stage 447.0 (TID 555) in 18 ms on 5b5a8eb7561c (executor driver) (125/200)\n",
      "10-20 20:37:02.188 172.17.0.2:54321      18300   (TID 558)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.192 172.17.0.2:54321      18300   (TID 558)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 20:37:02.192 172.17.0.2:54321      18300   (TID 556)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.192 172.17.0.2:54321      18300   (TID 556)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.192 172.17.0.2:54321      18300   (TID 559)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.192 172.17.0.2:54321      18300   (TID 559)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300   (TID 556)  INFO org.apache.spark.executor.Executor: Finished task 125.0 in stage 447.0 (TID 556). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.189 172.17.0.2:54321      18300   (TID 557)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300   (TID 557)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 129.0 in stage 447.0 (TID 560) (5b5a8eb7561c, executor driver, partition 129, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300   (TID 558)  INFO org.apache.spark.executor.Executor: Finished task 127.0 in stage 447.0 (TID 558). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300   (TID 560)  INFO org.apache.spark.executor.Executor: Running task 129.0 in stage 447.0 (TID 560)\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 125.0 in stage 447.0 (TID 556) in 18 ms on 5b5a8eb7561c (executor driver) (126/200)\n",
      "10-20 20:37:02.193 172.17.0.2:54321      18300   (TID 559)  INFO org.apache.spark.executor.Executor: Finished task 128.0 in stage 447.0 (TID 559). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.194 172.17.0.2:54321      18300   (TID 557)  INFO org.apache.spark.executor.Executor: Finished task 126.0 in stage 447.0 (TID 557). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.197 172.17.0.2:54321      18300   (TID 560)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.197 172.17.0.2:54321      18300   (TID 560)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.197 172.17.0.2:54321      18300   (TID 560)  INFO org.apache.spark.executor.Executor: Finished task 129.0 in stage 447.0 (TID 560). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.197 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 130.0 in stage 447.0 (TID 561) (5b5a8eb7561c, executor driver, partition 130, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 131.0 in stage 447.0 (TID 562) (5b5a8eb7561c, executor driver, partition 131, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 132.0 in stage 447.0 (TID 563) (5b5a8eb7561c, executor driver, partition 132, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 133.0 in stage 447.0 (TID 564) (5b5a8eb7561c, executor driver, partition 133, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 127.0 in stage 447.0 (TID 558) in 23 ms on 5b5a8eb7561c (executor driver) (127/200)\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 126.0 in stage 447.0 (TID 557) in 23 ms on 5b5a8eb7561c (executor driver) (128/200)\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 128.0 in stage 447.0 (TID 559) in 11 ms on 5b5a8eb7561c (executor driver) (129/200)\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 129.0 in stage 447.0 (TID 560) in 5 ms on 5b5a8eb7561c (executor driver) (130/200)\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300   (TID 561)  INFO org.apache.spark.executor.Executor: Running task 130.0 in stage 447.0 (TID 561)\n",
      "10-20 20:37:02.198 172.17.0.2:54321      18300   (TID 564)  INFO org.apache.spark.executor.Executor: Running task 133.0 in stage 447.0 (TID 564)\n",
      "10-20 20:37:02.200 172.17.0.2:54321      18300   (TID 562)  INFO org.apache.spark.executor.Executor: Running task 131.0 in stage 447.0 (TID 562)\n",
      "10-20 20:37:02.200 172.17.0.2:54321      18300   (TID 563)  INFO org.apache.spark.executor.Executor: Running task 132.0 in stage 447.0 (TID 563)\n",
      "10-20 20:37:02.202 172.17.0.2:54321      18300   (TID 561)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.202 172.17.0.2:54321      18300   (TID 561)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.202 172.17.0.2:54321      18300   (TID 561)  INFO org.apache.spark.executor.Executor: Finished task 130.0 in stage 447.0 (TID 561). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.203 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 134.0 in stage 447.0 (TID 565) (5b5a8eb7561c, executor driver, partition 134, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.203 172.17.0.2:54321      18300   (TID 565)  INFO org.apache.spark.executor.Executor: Running task 134.0 in stage 447.0 (TID 565)\n",
      "10-20 20:37:02.203 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 130.0 in stage 447.0 (TID 561) in 6 ms on 5b5a8eb7561c (executor driver) (131/200)\n",
      "10-20 20:37:02.208 172.17.0.2:54321      18300   (TID 565)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.208 172.17.0.2:54321      18300   (TID 565)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.209 172.17.0.2:54321      18300   (TID 565)  INFO org.apache.spark.executor.Executor: Finished task 134.0 in stage 447.0 (TID 565). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.209 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 135.0 in stage 447.0 (TID 566) (5b5a8eb7561c, executor driver, partition 135, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.210 172.17.0.2:54321      18300   (TID 566)  INFO org.apache.spark.executor.Executor: Running task 135.0 in stage 447.0 (TID 566)\n",
      "10-20 20:37:02.210 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 134.0 in stage 447.0 (TID 565) in 7 ms on 5b5a8eb7561c (executor driver) (132/200)\n",
      "10-20 20:37:02.211 172.17.0.2:54321      18300   (TID 563)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.212 172.17.0.2:54321      18300   (TID 563)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.212 172.17.0.2:54321      18300   (TID 564)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.212 172.17.0.2:54321      18300   (TID 564)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.213 172.17.0.2:54321      18300   (TID 564)  INFO org.apache.spark.executor.Executor: Finished task 133.0 in stage 447.0 (TID 564). 3277 bytes result sent to driver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 447:============================================>        (169 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 20:37:02.214 172.17.0.2:54321      18300   (TID 562)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300   (TID 562)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 136.0 in stage 447.0 (TID 567) (5b5a8eb7561c, executor driver, partition 136, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 133.0 in stage 447.0 (TID 564) in 16 ms on 5b5a8eb7561c (executor driver) (133/200)\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300   (TID 563)  INFO org.apache.spark.executor.Executor: Finished task 132.0 in stage 447.0 (TID 563). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300   (TID 567)  INFO org.apache.spark.executor.Executor: Running task 136.0 in stage 447.0 (TID 567)\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 137.0 in stage 447.0 (TID 568) (5b5a8eb7561c, executor driver, partition 137, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.214 172.17.0.2:54321      18300   (TID 568)  INFO org.apache.spark.executor.Executor: Running task 137.0 in stage 447.0 (TID 568)\n",
      "10-20 20:37:02.215 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 132.0 in stage 447.0 (TID 563) in 17 ms on 5b5a8eb7561c (executor driver) (134/200)\n",
      "10-20 20:37:02.217 172.17.0.2:54321      18300   (TID 566)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.217 172.17.0.2:54321      18300   (TID 566)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.218 172.17.0.2:54321      18300   (TID 566)  INFO org.apache.spark.executor.Executor: Finished task 135.0 in stage 447.0 (TID 566). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.218 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 138.0 in stage 447.0 (TID 569) (5b5a8eb7561c, executor driver, partition 138, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.218 172.17.0.2:54321      18300   (TID 569)  INFO org.apache.spark.executor.Executor: Running task 138.0 in stage 447.0 (TID 569)\n",
      "10-20 20:37:02.218 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 135.0 in stage 447.0 (TID 566) in 9 ms on 5b5a8eb7561c (executor driver) (135/200)\n",
      "10-20 20:37:02.220 172.17.0.2:54321      18300   (TID 567)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.220 172.17.0.2:54321      18300   (TID 567)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.221 172.17.0.2:54321      18300   (TID 567)  INFO org.apache.spark.executor.Executor: Finished task 136.0 in stage 447.0 (TID 567). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.221 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 139.0 in stage 447.0 (TID 570) (5b5a8eb7561c, executor driver, partition 139, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.221 172.17.0.2:54321      18300   (TID 570)  INFO org.apache.spark.executor.Executor: Running task 139.0 in stage 447.0 (TID 570)\n",
      "10-20 20:37:02.221 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 136.0 in stage 447.0 (TID 567) in 8 ms on 5b5a8eb7561c (executor driver) (136/200)\n",
      "10-20 20:37:02.223 172.17.0.2:54321      18300   (TID 569)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.223 172.17.0.2:54321      18300   (TID 569)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.223 172.17.0.2:54321      18300   (TID 569)  INFO org.apache.spark.executor.Executor: Finished task 138.0 in stage 447.0 (TID 569). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.223 172.17.0.2:54321      18300   (TID 568)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.223 172.17.0.2:54321      18300   (TID 568)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.224 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 140.0 in stage 447.0 (TID 571) (5b5a8eb7561c, executor driver, partition 140, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.224 172.17.0.2:54321      18300   (TID 568)  INFO org.apache.spark.executor.Executor: Finished task 137.0 in stage 447.0 (TID 568). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.224 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 141.0 in stage 447.0 (TID 572) (5b5a8eb7561c, executor driver, partition 141, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.225 172.17.0.2:54321      18300   (TID 571)  INFO org.apache.spark.executor.Executor: Running task 140.0 in stage 447.0 (TID 571)\n",
      "10-20 20:37:02.225 172.17.0.2:54321      18300   (TID 572)  INFO org.apache.spark.executor.Executor: Running task 141.0 in stage 447.0 (TID 572)\n",
      "10-20 20:37:02.226 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 137.0 in stage 447.0 (TID 568) in 11 ms on 5b5a8eb7561c (executor driver) (137/200)\n",
      "10-20 20:37:02.226 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 138.0 in stage 447.0 (TID 569) in 8 ms on 5b5a8eb7561c (executor driver) (138/200)\n",
      "10-20 20:37:02.229 172.17.0.2:54321      18300   (TID 570)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.229 172.17.0.2:54321      18300   (TID 570)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.230 172.17.0.2:54321      18300   (TID 571)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.230 172.17.0.2:54321      18300   (TID 571)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.231 172.17.0.2:54321      18300   (TID 571)  INFO org.apache.spark.executor.Executor: Finished task 140.0 in stage 447.0 (TID 571). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.232 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 142.0 in stage 447.0 (TID 573) (5b5a8eb7561c, executor driver, partition 142, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.232 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 140.0 in stage 447.0 (TID 571) in 8 ms on 5b5a8eb7561c (executor driver) (139/200)\n",
      "10-20 20:37:02.232 172.17.0.2:54321      18300   (TID 573)  INFO org.apache.spark.executor.Executor: Running task 142.0 in stage 447.0 (TID 573)\n",
      "10-20 20:37:02.233 172.17.0.2:54321      18300   (TID 562)  INFO org.apache.spark.executor.Executor: Finished task 131.0 in stage 447.0 (TID 562). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.234 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 143.0 in stage 447.0 (TID 574) (5b5a8eb7561c, executor driver, partition 143, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.234 172.17.0.2:54321      18300   (TID 574)  INFO org.apache.spark.executor.Executor: Running task 143.0 in stage 447.0 (TID 574)\n",
      "10-20 20:37:02.234 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 131.0 in stage 447.0 (TID 562) in 36 ms on 5b5a8eb7561c (executor driver) (140/200)\n",
      "10-20 20:37:02.237 172.17.0.2:54321      18300   (TID 570)  INFO org.apache.spark.executor.Executor: Finished task 139.0 in stage 447.0 (TID 570). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.237 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 144.0 in stage 447.0 (TID 575) (5b5a8eb7561c, executor driver, partition 144, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.237 172.17.0.2:54321      18300   (TID 573)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.237 172.17.0.2:54321      18300   (TID 573)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.238 172.17.0.2:54321      18300   (TID 575)  INFO org.apache.spark.executor.Executor: Running task 144.0 in stage 447.0 (TID 575)\n",
      "10-20 20:37:02.238 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 139.0 in stage 447.0 (TID 570) in 17 ms on 5b5a8eb7561c (executor driver) (141/200)\n",
      "10-20 20:37:02.238 172.17.0.2:54321      18300   (TID 573)  INFO org.apache.spark.executor.Executor: Finished task 142.0 in stage 447.0 (TID 573). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.238 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 145.0 in stage 447.0 (TID 576) (5b5a8eb7561c, executor driver, partition 145, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.238 172.17.0.2:54321      18300   (TID 576)  INFO org.apache.spark.executor.Executor: Running task 145.0 in stage 447.0 (TID 576)\n",
      "10-20 20:37:02.238 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 142.0 in stage 447.0 (TID 573) in 6 ms on 5b5a8eb7561c (executor driver) (142/200)\n",
      "10-20 20:37:02.241 172.17.0.2:54321      18300   (TID 574)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.241 172.17.0.2:54321      18300   (TID 574)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.241 172.17.0.2:54321      18300   (TID 576)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.242 172.17.0.2:54321      18300   (TID 576)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.242 172.17.0.2:54321      18300   (TID 574)  INFO org.apache.spark.executor.Executor: Finished task 143.0 in stage 447.0 (TID 574). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.242 172.17.0.2:54321      18300   (TID 576)  INFO org.apache.spark.executor.Executor: Finished task 145.0 in stage 447.0 (TID 576). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.241 172.17.0.2:54321      18300   (TID 575)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.242 172.17.0.2:54321      18300   (TID 575)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.242 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 146.0 in stage 447.0 (TID 577) (5b5a8eb7561c, executor driver, partition 146, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.243 172.17.0.2:54321      18300   (TID 577)  INFO org.apache.spark.executor.Executor: Running task 146.0 in stage 447.0 (TID 577)\n",
      "10-20 20:37:02.243 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 147.0 in stage 447.0 (TID 578) (5b5a8eb7561c, executor driver, partition 147, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.243 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 143.0 in stage 447.0 (TID 574) in 9 ms on 5b5a8eb7561c (executor driver) (143/200)\n",
      "10-20 20:37:02.243 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 145.0 in stage 447.0 (TID 576) in 5 ms on 5b5a8eb7561c (executor driver) (144/200)\n",
      "10-20 20:37:02.244 172.17.0.2:54321      18300   (TID 578)  INFO org.apache.spark.executor.Executor: Running task 147.0 in stage 447.0 (TID 578)\n",
      "10-20 20:37:02.247 172.17.0.2:54321      18300   (TID 577)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.247 172.17.0.2:54321      18300   (TID 577)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.247 172.17.0.2:54321      18300   (TID 578)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.247 172.17.0.2:54321      18300   (TID 578)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.247 172.17.0.2:54321      18300   (TID 577)  INFO org.apache.spark.executor.Executor: Finished task 146.0 in stage 447.0 (TID 577). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.247 172.17.0.2:54321      18300   (TID 575)  INFO org.apache.spark.executor.Executor: Finished task 144.0 in stage 447.0 (TID 575). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300   (TID 578)  INFO org.apache.spark.executor.Executor: Finished task 147.0 in stage 447.0 (TID 578). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300   (TID 572)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300   (TID 572)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 148.0 in stage 447.0 (TID 579) (5b5a8eb7561c, executor driver, partition 148, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300   (TID 572)  INFO org.apache.spark.executor.Executor: Finished task 141.0 in stage 447.0 (TID 572). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300   (TID 579)  INFO org.apache.spark.executor.Executor: Running task 148.0 in stage 447.0 (TID 579)\n",
      "10-20 20:37:02.248 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 149.0 in stage 447.0 (TID 580) (5b5a8eb7561c, executor driver, partition 149, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.249 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 146.0 in stage 447.0 (TID 577) in 7 ms on 5b5a8eb7561c (executor driver) (145/200)\n",
      "10-20 20:37:02.249 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 144.0 in stage 447.0 (TID 575) in 12 ms on 5b5a8eb7561c (executor driver) (146/200)\n",
      "10-20 20:37:02.249 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 150.0 in stage 447.0 (TID 581) (5b5a8eb7561c, executor driver, partition 150, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.249 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 151.0 in stage 447.0 (TID 582) (5b5a8eb7561c, executor driver, partition 151, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.249 172.17.0.2:54321      18300   (TID 582)  INFO org.apache.spark.executor.Executor: Running task 151.0 in stage 447.0 (TID 582)\n",
      "10-20 20:37:02.249 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 147.0 in stage 447.0 (TID 578) in 6 ms on 5b5a8eb7561c (executor driver) (147/200)\n",
      "10-20 20:37:02.250 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 141.0 in stage 447.0 (TID 572) in 26 ms on 5b5a8eb7561c (executor driver) (148/200)\n",
      "10-20 20:37:02.250 172.17.0.2:54321      18300   (TID 581)  INFO org.apache.spark.executor.Executor: Running task 150.0 in stage 447.0 (TID 581)\n",
      "10-20 20:37:02.254 172.17.0.2:54321      18300   (TID 582)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.254 172.17.0.2:54321      18300   (TID 582)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.254 172.17.0.2:54321      18300   (TID 582)  INFO org.apache.spark.executor.Executor: Finished task 151.0 in stage 447.0 (TID 582). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.255 172.17.0.2:54321      18300   (TID 580)  INFO org.apache.spark.executor.Executor: Running task 149.0 in stage 447.0 (TID 580)\n",
      "10-20 20:37:02.255 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 152.0 in stage 447.0 (TID 583) (5b5a8eb7561c, executor driver, partition 152, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.255 172.17.0.2:54321      18300   (TID 581)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.255 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 151.0 in stage 447.0 (TID 582) in 6 ms on 5b5a8eb7561c (executor driver) (149/200)\n",
      "10-20 20:37:02.255 172.17.0.2:54321      18300   (TID 581)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.255 172.17.0.2:54321      18300   (TID 583)  INFO org.apache.spark.executor.Executor: Running task 152.0 in stage 447.0 (TID 583)\n",
      "10-20 20:37:02.256 172.17.0.2:54321      18300   (TID 581)  INFO org.apache.spark.executor.Executor: Finished task 150.0 in stage 447.0 (TID 581). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.257 172.17.0.2:54321      18300   (TID 579)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.257 172.17.0.2:54321      18300   (TID 579)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.259 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 153.0 in stage 447.0 (TID 584) (5b5a8eb7561c, executor driver, partition 153, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.259 172.17.0.2:54321      18300   (TID 579)  INFO org.apache.spark.executor.Executor: Finished task 148.0 in stage 447.0 (TID 579). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.259 172.17.0.2:54321      18300   (TID 584)  INFO org.apache.spark.executor.Executor: Running task 153.0 in stage 447.0 (TID 584)\n",
      "10-20 20:37:02.260 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 154.0 in stage 447.0 (TID 585) (5b5a8eb7561c, executor driver, partition 154, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.260 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 150.0 in stage 447.0 (TID 581) in 11 ms on 5b5a8eb7561c (executor driver) (150/200)\n",
      "10-20 20:37:02.260 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 148.0 in stage 447.0 (TID 579) in 12 ms on 5b5a8eb7561c (executor driver) (151/200)\n",
      "10-20 20:37:02.260 172.17.0.2:54321      18300   (TID 585)  INFO org.apache.spark.executor.Executor: Running task 154.0 in stage 447.0 (TID 585)\n",
      "10-20 20:37:02.260 172.17.0.2:54321      18300   (TID 583)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.260 172.17.0.2:54321      18300   (TID 583)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.261 172.17.0.2:54321      18300   (TID 583)  INFO org.apache.spark.executor.Executor: Finished task 152.0 in stage 447.0 (TID 583). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.261 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 155.0 in stage 447.0 (TID 586) (5b5a8eb7561c, executor driver, partition 155, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.262 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 152.0 in stage 447.0 (TID 583) in 7 ms on 5b5a8eb7561c (executor driver) (152/200)\n",
      "10-20 20:37:02.262 172.17.0.2:54321      18300   (TID 586)  INFO org.apache.spark.executor.Executor: Running task 155.0 in stage 447.0 (TID 586)\n",
      "10-20 20:37:02.266 172.17.0.2:54321      18300   (TID 586)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.266 172.17.0.2:54321      18300   (TID 586)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.267 172.17.0.2:54321      18300   (TID 586)  INFO org.apache.spark.executor.Executor: Finished task 155.0 in stage 447.0 (TID 586). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.267 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 156.0 in stage 447.0 (TID 587) (5b5a8eb7561c, executor driver, partition 156, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.267 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 155.0 in stage 447.0 (TID 586) in 6 ms on 5b5a8eb7561c (executor driver) (153/200)\n",
      "10-20 20:37:02.268 172.17.0.2:54321      18300   (TID 587)  INFO org.apache.spark.executor.Executor: Running task 156.0 in stage 447.0 (TID 587)\n",
      "10-20 20:37:02.271 172.17.0.2:54321      18300   (TID 587)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.271 172.17.0.2:54321      18300   (TID 587)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.271 172.17.0.2:54321      18300   (TID 587)  INFO org.apache.spark.executor.Executor: Finished task 156.0 in stage 447.0 (TID 587). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.272 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 157.0 in stage 447.0 (TID 588) (5b5a8eb7561c, executor driver, partition 157, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.272 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 156.0 in stage 447.0 (TID 587) in 5 ms on 5b5a8eb7561c (executor driver) (154/200)\n",
      "10-20 20:37:02.274 172.17.0.2:54321      18300   (TID 584)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.274 172.17.0.2:54321      18300   (TID 584)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.274 172.17.0.2:54321      18300   (TID 588)  INFO org.apache.spark.executor.Executor: Running task 157.0 in stage 447.0 (TID 588)\n",
      "10-20 20:37:02.275 172.17.0.2:54321      18300   (TID 584)  INFO org.apache.spark.executor.Executor: Finished task 153.0 in stage 447.0 (TID 584). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.275 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 158.0 in stage 447.0 (TID 589) (5b5a8eb7561c, executor driver, partition 158, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.275 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 153.0 in stage 447.0 (TID 584) in 16 ms on 5b5a8eb7561c (executor driver) (155/200)\n",
      "10-20 20:37:02.275 172.17.0.2:54321      18300   (TID 589)  INFO org.apache.spark.executor.Executor: Running task 158.0 in stage 447.0 (TID 589)\n",
      "10-20 20:37:02.277 172.17.0.2:54321      18300   (TID 585)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.277 172.17.0.2:54321      18300   (TID 585)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.278 172.17.0.2:54321      18300   (TID 585)  INFO org.apache.spark.executor.Executor: Finished task 154.0 in stage 447.0 (TID 585). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.271 172.17.0.2:54321      18300   (TID 580)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.278 172.17.0.2:54321      18300   (TID 580)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 20:37:02.278 172.17.0.2:54321      18300   (TID 580)  INFO org.apache.spark.executor.Executor: Finished task 149.0 in stage 447.0 (TID 580). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.279 172.17.0.2:54321      18300   (TID 588)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.279 172.17.0.2:54321      18300   (TID 588)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.279 172.17.0.2:54321      18300   (TID 588)  INFO org.apache.spark.executor.Executor: Finished task 157.0 in stage 447.0 (TID 588). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.290 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 159.0 in stage 447.0 (TID 590) (5b5a8eb7561c, executor driver, partition 159, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.290 172.17.0.2:54321      18300   (TID 590)  INFO org.apache.spark.executor.Executor: Running task 159.0 in stage 447.0 (TID 590)\n",
      "10-20 20:37:02.290 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 157.0 in stage 447.0 (TID 588) in 18 ms on 5b5a8eb7561c (executor driver) (156/200)\n",
      "10-20 20:37:02.291 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 160.0 in stage 447.0 (TID 591) (5b5a8eb7561c, executor driver, partition 160, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.291 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 161.0 in stage 447.0 (TID 592) (5b5a8eb7561c, executor driver, partition 161, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.291 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 154.0 in stage 447.0 (TID 585) in 31 ms on 5b5a8eb7561c (executor driver) (157/200)\n",
      "10-20 20:37:02.292 172.17.0.2:54321      18300   (TID 591)  INFO org.apache.spark.executor.Executor: Running task 160.0 in stage 447.0 (TID 591)\n",
      "10-20 20:37:02.292 172.17.0.2:54321      18300   (TID 592)  INFO org.apache.spark.executor.Executor: Running task 161.0 in stage 447.0 (TID 592)\n",
      "10-20 20:37:02.293 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 149.0 in stage 447.0 (TID 580) in 45 ms on 5b5a8eb7561c (executor driver) (158/200)\n",
      "10-20 20:37:02.297 172.17.0.2:54321      18300   (TID 589)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.297 172.17.0.2:54321      18300   (TID 589)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.298 172.17.0.2:54321      18300   (TID 589)  INFO org.apache.spark.executor.Executor: Finished task 158.0 in stage 447.0 (TID 589). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.298 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 162.0 in stage 447.0 (TID 593) (5b5a8eb7561c, executor driver, partition 162, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.299 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 158.0 in stage 447.0 (TID 589) in 24 ms on 5b5a8eb7561c (executor driver) (159/200)\n",
      "10-20 20:37:02.299 172.17.0.2:54321      18300   (TID 593)  INFO org.apache.spark.executor.Executor: Running task 162.0 in stage 447.0 (TID 593)\n",
      "10-20 20:37:02.301 172.17.0.2:54321      18300   (TID 592)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.302 172.17.0.2:54321      18300   (TID 592)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.303 172.17.0.2:54321      18300   (TID 593)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.303 172.17.0.2:54321      18300   (TID 593)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.303 172.17.0.2:54321      18300   (TID 593)  INFO org.apache.spark.executor.Executor: Finished task 162.0 in stage 447.0 (TID 593). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.303 172.17.0.2:54321      18300   (TID 590)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.303 172.17.0.2:54321      18300   (TID 590)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.304 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 163.0 in stage 447.0 (TID 594) (5b5a8eb7561c, executor driver, partition 163, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.297 172.17.0.2:54321      18300   (TID 591)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.304 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 162.0 in stage 447.0 (TID 593) in 6 ms on 5b5a8eb7561c (executor driver) (160/200)\n",
      "10-20 20:37:02.304 172.17.0.2:54321      18300   (TID 591)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 20:37:02.304 172.17.0.2:54321      18300   (TID 594)  INFO org.apache.spark.executor.Executor: Running task 163.0 in stage 447.0 (TID 594)\n",
      "10-20 20:37:02.304 172.17.0.2:54321      18300   (TID 591)  INFO org.apache.spark.executor.Executor: Finished task 160.0 in stage 447.0 (TID 591). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.304 172.17.0.2:54321      18300   (TID 590)  INFO org.apache.spark.executor.Executor: Finished task 159.0 in stage 447.0 (TID 590). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.305 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 164.0 in stage 447.0 (TID 595) (5b5a8eb7561c, executor driver, partition 164, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.305 172.17.0.2:54321      18300   (TID 592)  INFO org.apache.spark.executor.Executor: Finished task 161.0 in stage 447.0 (TID 592). 3363 bytes result sent to driver\n",
      "10-20 20:37:02.305 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 160.0 in stage 447.0 (TID 591) in 14 ms on 5b5a8eb7561c (executor driver) (161/200)\n",
      "10-20 20:37:02.305 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 165.0 in stage 447.0 (TID 596) (5b5a8eb7561c, executor driver, partition 165, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.305 172.17.0.2:54321      18300   (TID 596)  INFO org.apache.spark.executor.Executor: Running task 165.0 in stage 447.0 (TID 596)\n",
      "10-20 20:37:02.305 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 166.0 in stage 447.0 (TID 597) (5b5a8eb7561c, executor driver, partition 166, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.306 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 159.0 in stage 447.0 (TID 590) in 16 ms on 5b5a8eb7561c (executor driver) (162/200)\n",
      "10-20 20:37:02.306 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 161.0 in stage 447.0 (TID 592) in 15 ms on 5b5a8eb7561c (executor driver) (163/200)\n",
      "10-20 20:37:02.306 172.17.0.2:54321      18300   (TID 595)  INFO org.apache.spark.executor.Executor: Running task 164.0 in stage 447.0 (TID 595)\n",
      "10-20 20:37:02.306 172.17.0.2:54321      18300   (TID 597)  INFO org.apache.spark.executor.Executor: Running task 166.0 in stage 447.0 (TID 597)\n",
      "10-20 20:37:02.308 172.17.0.2:54321      18300   (TID 594)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.308 172.17.0.2:54321      18300   (TID 594)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.309 172.17.0.2:54321      18300   (TID 594)  INFO org.apache.spark.executor.Executor: Finished task 163.0 in stage 447.0 (TID 594). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.309 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 167.0 in stage 447.0 (TID 598) (5b5a8eb7561c, executor driver, partition 167, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.309 172.17.0.2:54321      18300   (TID 598)  INFO org.apache.spark.executor.Executor: Running task 167.0 in stage 447.0 (TID 598)\n",
      "10-20 20:37:02.309 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 163.0 in stage 447.0 (TID 594) in 5 ms on 5b5a8eb7561c (executor driver) (164/200)\n",
      "10-20 20:37:02.310 172.17.0.2:54321      18300   (TID 595)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.310 172.17.0.2:54321      18300   (TID 595)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.311 172.17.0.2:54321      18300   (TID 595)  INFO org.apache.spark.executor.Executor: Finished task 164.0 in stage 447.0 (TID 595). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.312 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 168.0 in stage 447.0 (TID 599) (5b5a8eb7561c, executor driver, partition 168, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.312 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 164.0 in stage 447.0 (TID 595) in 8 ms on 5b5a8eb7561c (executor driver) (165/200)\n",
      "10-20 20:37:02.312 172.17.0.2:54321      18300   (TID 599)  INFO org.apache.spark.executor.Executor: Running task 168.0 in stage 447.0 (TID 599)\n",
      "10-20 20:37:02.313 172.17.0.2:54321      18300   (TID 598)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.313 172.17.0.2:54321      18300   (TID 598)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.313 172.17.0.2:54321      18300   (TID 598)  INFO org.apache.spark.executor.Executor: Finished task 167.0 in stage 447.0 (TID 598). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.313 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 169.0 in stage 447.0 (TID 600) (5b5a8eb7561c, executor driver, partition 169, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.314 172.17.0.2:54321      18300   (TID 600)  INFO org.apache.spark.executor.Executor: Running task 169.0 in stage 447.0 (TID 600)\n",
      "10-20 20:37:02.314 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 167.0 in stage 447.0 (TID 598) in 4 ms on 5b5a8eb7561c (executor driver) (166/200)\n",
      "10-20 20:37:02.315 172.17.0.2:54321      18300   (TID 597)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.315 172.17.0.2:54321      18300   (TID 597)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.315 172.17.0.2:54321      18300   (TID 596)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.315 172.17.0.2:54321      18300   (TID 596)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.316 172.17.0.2:54321      18300   (TID 597)  INFO org.apache.spark.executor.Executor: Finished task 166.0 in stage 447.0 (TID 597). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.316 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 170.0 in stage 447.0 (TID 601) (5b5a8eb7561c, executor driver, partition 170, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.317 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 166.0 in stage 447.0 (TID 597) in 11 ms on 5b5a8eb7561c (executor driver) (167/200)\n",
      "10-20 20:37:02.317 172.17.0.2:54321      18300   (TID 596)  INFO org.apache.spark.executor.Executor: Finished task 165.0 in stage 447.0 (TID 596). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.317 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 171.0 in stage 447.0 (TID 602) (5b5a8eb7561c, executor driver, partition 171, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300   (TID 600)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300   (TID 600)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 165.0 in stage 447.0 (TID 596) in 13 ms on 5b5a8eb7561c (executor driver) (168/200)\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300   (TID 602)  INFO org.apache.spark.executor.Executor: Running task 171.0 in stage 447.0 (TID 602)\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300   (TID 600)  INFO org.apache.spark.executor.Executor: Finished task 169.0 in stage 447.0 (TID 600). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 172.0 in stage 447.0 (TID 603) (5b5a8eb7561c, executor driver, partition 172, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 169.0 in stage 447.0 (TID 600) in 5 ms on 5b5a8eb7561c (executor driver) (169/200)\n",
      "10-20 20:37:02.318 172.17.0.2:54321      18300   (TID 603)  INFO org.apache.spark.executor.Executor: Running task 172.0 in stage 447.0 (TID 603)\n",
      "10-20 20:37:02.317 172.17.0.2:54321      18300   (TID 601)  INFO org.apache.spark.executor.Executor: Running task 170.0 in stage 447.0 (TID 601)\n",
      "10-20 20:37:02.322 172.17.0.2:54321      18300   (TID 599)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.322 172.17.0.2:54321      18300   (TID 599)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.324 172.17.0.2:54321      18300   (TID 601)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.324 172.17.0.2:54321      18300   (TID 601)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.325 172.17.0.2:54321      18300   (TID 601)  INFO org.apache.spark.executor.Executor: Finished task 170.0 in stage 447.0 (TID 601). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.326 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 173.0 in stage 447.0 (TID 604) (5b5a8eb7561c, executor driver, partition 173, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.326 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 170.0 in stage 447.0 (TID 601) in 10 ms on 5b5a8eb7561c (executor driver) (170/200)\n",
      "10-20 20:37:02.327 172.17.0.2:54321      18300   (TID 604)  INFO org.apache.spark.executor.Executor: Running task 173.0 in stage 447.0 (TID 604)\n",
      "10-20 20:37:02.330 172.17.0.2:54321      18300   (TID 599)  INFO org.apache.spark.executor.Executor: Finished task 168.0 in stage 447.0 (TID 599). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.331 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 174.0 in stage 447.0 (TID 605) (5b5a8eb7561c, executor driver, partition 174, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.331 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 168.0 in stage 447.0 (TID 599) in 20 ms on 5b5a8eb7561c (executor driver) (171/200)\n",
      "10-20 20:37:02.331 172.17.0.2:54321      18300   (TID 605)  INFO org.apache.spark.executor.Executor: Running task 174.0 in stage 447.0 (TID 605)\n",
      "10-20 20:37:02.331 172.17.0.2:54321      18300   (TID 603)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.331 172.17.0.2:54321      18300   (TID 603)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 20:37:02.332 172.17.0.2:54321      18300   (TID 603)  INFO org.apache.spark.executor.Executor: Finished task 172.0 in stage 447.0 (TID 603). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.332 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 175.0 in stage 447.0 (TID 606) (5b5a8eb7561c, executor driver, partition 175, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.332 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 172.0 in stage 447.0 (TID 603) in 14 ms on 5b5a8eb7561c (executor driver) (172/200)\n",
      "10-20 20:37:02.332 172.17.0.2:54321      18300   (TID 606)  INFO org.apache.spark.executor.Executor: Running task 175.0 in stage 447.0 (TID 606)\n",
      "10-20 20:37:02.333 172.17.0.2:54321      18300   (TID 602)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.333 172.17.0.2:54321      18300   (TID 602)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.333 172.17.0.2:54321      18300   (TID 602)  INFO org.apache.spark.executor.Executor: Finished task 171.0 in stage 447.0 (TID 602). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.334 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 176.0 in stage 447.0 (TID 607) (5b5a8eb7561c, executor driver, partition 176, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.335 172.17.0.2:54321      18300   (TID 605)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.335 172.17.0.2:54321      18300   (TID 605)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.336 172.17.0.2:54321      18300   (TID 604)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.336 172.17.0.2:54321      18300   (TID 605)  INFO org.apache.spark.executor.Executor: Finished task 174.0 in stage 447.0 (TID 605). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.338 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 171.0 in stage 447.0 (TID 602) in 21 ms on 5b5a8eb7561c (executor driver) (173/200)\n",
      "10-20 20:37:02.338 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 177.0 in stage 447.0 (TID 608) (5b5a8eb7561c, executor driver, partition 177, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.336 172.17.0.2:54321      18300   (TID 604)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:02.338 172.17.0.2:54321      18300   (TID 608)  INFO org.apache.spark.executor.Executor: Running task 177.0 in stage 447.0 (TID 608)\n",
      "10-20 20:37:02.338 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 174.0 in stage 447.0 (TID 605) in 7 ms on 5b5a8eb7561c (executor driver) (174/200)\n",
      "10-20 20:37:02.338 172.17.0.2:54321      18300   (TID 604)  INFO org.apache.spark.executor.Executor: Finished task 173.0 in stage 447.0 (TID 604). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.339 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 178.0 in stage 447.0 (TID 609) (5b5a8eb7561c, executor driver, partition 178, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.339 172.17.0.2:54321      18300   (TID 609)  INFO org.apache.spark.executor.Executor: Running task 178.0 in stage 447.0 (TID 609)\n",
      "10-20 20:37:02.340 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 173.0 in stage 447.0 (TID 604) in 15 ms on 5b5a8eb7561c (executor driver) (175/200)\n",
      "10-20 20:37:02.340 172.17.0.2:54321      18300   (TID 606)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.340 172.17.0.2:54321      18300   (TID 606)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.341 172.17.0.2:54321      18300   (TID 606)  INFO org.apache.spark.executor.Executor: Finished task 175.0 in stage 447.0 (TID 606). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.341 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 179.0 in stage 447.0 (TID 610) (5b5a8eb7561c, executor driver, partition 179, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.341 172.17.0.2:54321      18300   (TID 610)  INFO org.apache.spark.executor.Executor: Running task 179.0 in stage 447.0 (TID 610)\n",
      "10-20 20:37:02.341 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 175.0 in stage 447.0 (TID 606) in 9 ms on 5b5a8eb7561c (executor driver) (176/200)\n",
      "10-20 20:37:02.344 172.17.0.2:54321      18300   (TID 608)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.344 172.17.0.2:54321      18300   (TID 608)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.345 172.17.0.2:54321      18300   (TID 608)  INFO org.apache.spark.executor.Executor: Finished task 177.0 in stage 447.0 (TID 608). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.345 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 180.0 in stage 447.0 (TID 611) (5b5a8eb7561c, executor driver, partition 180, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.346 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 177.0 in stage 447.0 (TID 608) in 7 ms on 5b5a8eb7561c (executor driver) (177/200)\n",
      "10-20 20:37:02.346 172.17.0.2:54321      18300   (TID 611)  INFO org.apache.spark.executor.Executor: Running task 180.0 in stage 447.0 (TID 611)\n",
      "10-20 20:37:02.346 172.17.0.2:54321      18300   (TID 607)  INFO org.apache.spark.executor.Executor: Running task 176.0 in stage 447.0 (TID 607)\n",
      "10-20 20:37:02.347 172.17.0.2:54321      18300   (TID 609)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.347 172.17.0.2:54321      18300   (TID 609)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.348 172.17.0.2:54321      18300   (TID 609)  INFO org.apache.spark.executor.Executor: Finished task 178.0 in stage 447.0 (TID 609). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.348 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 181.0 in stage 447.0 (TID 612) (5b5a8eb7561c, executor driver, partition 181, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.348 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 178.0 in stage 447.0 (TID 609) in 9 ms on 5b5a8eb7561c (executor driver) (178/200)\n",
      "10-20 20:37:02.348 172.17.0.2:54321      18300   (TID 612)  INFO org.apache.spark.executor.Executor: Running task 181.0 in stage 447.0 (TID 612)\n",
      "10-20 20:37:02.355 172.17.0.2:54321      18300   (TID 607)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.355 172.17.0.2:54321      18300   (TID 607)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.356 172.17.0.2:54321      18300   (TID 607)  INFO org.apache.spark.executor.Executor: Finished task 176.0 in stage 447.0 (TID 607). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.365 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 182.0 in stage 447.0 (TID 613) (5b5a8eb7561c, executor driver, partition 182, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.366 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 176.0 in stage 447.0 (TID 607) in 32 ms on 5b5a8eb7561c (executor driver) (179/200)\n",
      "10-20 20:37:02.366 172.17.0.2:54321      18300   (TID 613)  INFO org.apache.spark.executor.Executor: Running task 182.0 in stage 447.0 (TID 613)\n",
      "10-20 20:37:02.368 172.17.0.2:54321      18300   (TID 610)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.368 172.17.0.2:54321      18300   (TID 610)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 613)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 613)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 610)  INFO org.apache.spark.executor.Executor: Finished task 179.0 in stage 447.0 (TID 610). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 611)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 611)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 613)  INFO org.apache.spark.executor.Executor: Finished task 182.0 in stage 447.0 (TID 613). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300   (TID 611)  INFO org.apache.spark.executor.Executor: Finished task 180.0 in stage 447.0 (TID 611). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.370 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 183.0 in stage 447.0 (TID 614) (5b5a8eb7561c, executor driver, partition 183, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.371 172.17.0.2:54321      18300   (TID 614)  INFO org.apache.spark.executor.Executor: Running task 183.0 in stage 447.0 (TID 614)\n",
      "10-20 20:37:02.371 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 184.0 in stage 447.0 (TID 615) (5b5a8eb7561c, executor driver, partition 184, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.371 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 185.0 in stage 447.0 (TID 616) (5b5a8eb7561c, executor driver, partition 185, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.371 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 179.0 in stage 447.0 (TID 610) in 30 ms on 5b5a8eb7561c (executor driver) (180/200)\n",
      "10-20 20:37:02.371 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 182.0 in stage 447.0 (TID 613) in 15 ms on 5b5a8eb7561c (executor driver) (181/200)\n",
      "10-20 20:37:02.372 172.17.0.2:54321      18300   (TID 616)  INFO org.apache.spark.executor.Executor: Running task 185.0 in stage 447.0 (TID 616)\n",
      "10-20 20:37:02.372 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 180.0 in stage 447.0 (TID 611) in 27 ms on 5b5a8eb7561c (executor driver) (182/200)\n",
      "10-20 20:37:02.375 172.17.0.2:54321      18300   (TID 616)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.375 172.17.0.2:54321      18300   (TID 616)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.376 172.17.0.2:54321      18300   (TID 616)  INFO org.apache.spark.executor.Executor: Finished task 185.0 in stage 447.0 (TID 616). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.376 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 186.0 in stage 447.0 (TID 617) (5b5a8eb7561c, executor driver, partition 186, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.376 172.17.0.2:54321      18300   (TID 617)  INFO org.apache.spark.executor.Executor: Running task 186.0 in stage 447.0 (TID 617)\n",
      "10-20 20:37:02.376 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 185.0 in stage 447.0 (TID 616) in 5 ms on 5b5a8eb7561c (executor driver) (183/200)\n",
      "10-20 20:37:02.379 172.17.0.2:54321      18300   (TID 614)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.379 172.17.0.2:54321      18300   (TID 614)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.379 172.17.0.2:54321      18300   (TID 612)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.379 172.17.0.2:54321      18300   (TID 612)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.379 172.17.0.2:54321      18300   (TID 612)  INFO org.apache.spark.executor.Executor: Finished task 181.0 in stage 447.0 (TID 612). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.385 172.17.0.2:54321      18300   (TID 615)  INFO org.apache.spark.executor.Executor: Running task 184.0 in stage 447.0 (TID 615)\n",
      "10-20 20:37:02.385 172.17.0.2:54321      18300   (TID 614)  INFO org.apache.spark.executor.Executor: Finished task 183.0 in stage 447.0 (TID 614). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.385 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 187.0 in stage 447.0 (TID 618) (5b5a8eb7561c, executor driver, partition 187, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.386 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 188.0 in stage 447.0 (TID 619) (5b5a8eb7561c, executor driver, partition 188, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.386 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 183.0 in stage 447.0 (TID 614) in 16 ms on 5b5a8eb7561c (executor driver) (184/200)\n",
      "10-20 20:37:02.386 172.17.0.2:54321      18300   (TID 619)  INFO org.apache.spark.executor.Executor: Running task 188.0 in stage 447.0 (TID 619)\n",
      "10-20 20:37:02.386 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 181.0 in stage 447.0 (TID 612) in 38 ms on 5b5a8eb7561c (executor driver) (185/200)\n",
      "10-20 20:37:02.389 172.17.0.2:54321      18300   (TID 615)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.389 172.17.0.2:54321      18300   (TID 615)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.389 172.17.0.2:54321      18300   (TID 617)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.390 172.17.0.2:54321      18300   (TID 617)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.390 172.17.0.2:54321      18300   (TID 615)  INFO org.apache.spark.executor.Executor: Finished task 184.0 in stage 447.0 (TID 615). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.390 172.17.0.2:54321      18300   (TID 619)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.390 172.17.0.2:54321      18300   (TID 619)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:02.391 172.17.0.2:54321      18300   (TID 619)  INFO org.apache.spark.executor.Executor: Finished task 188.0 in stage 447.0 (TID 619). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.390 172.17.0.2:54321      18300   (TID 617)  INFO org.apache.spark.executor.Executor: Finished task 186.0 in stage 447.0 (TID 617). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.390 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 189.0 in stage 447.0 (TID 620) (5b5a8eb7561c, executor driver, partition 189, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.391 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 190.0 in stage 447.0 (TID 621) (5b5a8eb7561c, executor driver, partition 190, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.391 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 184.0 in stage 447.0 (TID 615) in 20 ms on 5b5a8eb7561c (executor driver) (186/200)\n",
      "10-20 20:37:02.391 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 188.0 in stage 447.0 (TID 619) in 6 ms on 5b5a8eb7561c (executor driver) (187/200)\n",
      "10-20 20:37:02.391 172.17.0.2:54321      18300   (TID 620)  INFO org.apache.spark.executor.Executor: Running task 189.0 in stage 447.0 (TID 620)\n",
      "10-20 20:37:02.392 172.17.0.2:54321      18300   (TID 621)  INFO org.apache.spark.executor.Executor: Running task 190.0 in stage 447.0 (TID 621)\n",
      "10-20 20:37:02.395 172.17.0.2:54321      18300   (TID 620)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.395 172.17.0.2:54321      18300   (TID 620)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.395 172.17.0.2:54321      18300   (TID 620)  INFO org.apache.spark.executor.Executor: Finished task 189.0 in stage 447.0 (TID 620). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.395 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 191.0 in stage 447.0 (TID 622) (5b5a8eb7561c, executor driver, partition 191, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.396 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 189.0 in stage 447.0 (TID 620) in 6 ms on 5b5a8eb7561c (executor driver) (188/200)\n",
      "10-20 20:37:02.396 172.17.0.2:54321      18300   (TID 622)  INFO org.apache.spark.executor.Executor: Running task 191.0 in stage 447.0 (TID 622)\n",
      "10-20 20:37:02.396 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 192.0 in stage 447.0 (TID 623) (5b5a8eb7561c, executor driver, partition 192, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.396 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 186.0 in stage 447.0 (TID 617) in 20 ms on 5b5a8eb7561c (executor driver) (189/200)\n",
      "10-20 20:37:02.396 172.17.0.2:54321      18300   (TID 623)  INFO org.apache.spark.executor.Executor: Running task 192.0 in stage 447.0 (TID 623)\n",
      "10-20 20:37:02.397 172.17.0.2:54321      18300   (TID 621)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.397 172.17.0.2:54321      18300   (TID 621)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.398 172.17.0.2:54321      18300   (TID 621)  INFO org.apache.spark.executor.Executor: Finished task 190.0 in stage 447.0 (TID 621). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.399 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 193.0 in stage 447.0 (TID 624) (5b5a8eb7561c, executor driver, partition 193, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.399 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 190.0 in stage 447.0 (TID 621) in 8 ms on 5b5a8eb7561c (executor driver) (190/200)\n",
      "10-20 20:37:02.400 172.17.0.2:54321      18300   (TID 624)  INFO org.apache.spark.executor.Executor: Running task 193.0 in stage 447.0 (TID 624)\n",
      "10-20 20:37:02.403 172.17.0.2:54321      18300   (TID 624)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.403 172.17.0.2:54321      18300   (TID 624)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.404 172.17.0.2:54321      18300   (TID 624)  INFO org.apache.spark.executor.Executor: Finished task 193.0 in stage 447.0 (TID 624). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.404 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 194.0 in stage 447.0 (TID 625) (5b5a8eb7561c, executor driver, partition 194, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.404 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 193.0 in stage 447.0 (TID 624) in 5 ms on 5b5a8eb7561c (executor driver) (191/200)\n",
      "10-20 20:37:02.404 172.17.0.2:54321      18300   (TID 618)  INFO org.apache.spark.executor.Executor: Running task 187.0 in stage 447.0 (TID 618)\n",
      "10-20 20:37:02.405 172.17.0.2:54321      18300   (TID 623)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.405 172.17.0.2:54321      18300   (TID 625)  INFO org.apache.spark.executor.Executor: Running task 194.0 in stage 447.0 (TID 625)\n",
      "10-20 20:37:02.405 172.17.0.2:54321      18300   (TID 623)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.405 172.17.0.2:54321      18300   (TID 623)  INFO org.apache.spark.executor.Executor: Finished task 192.0 in stage 447.0 (TID 623). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.405 172.17.0.2:54321      18300   (TID 622)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.405 172.17.0.2:54321      18300   (TID 622)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:02.406 172.17.0.2:54321      18300   (TID 622)  INFO org.apache.spark.executor.Executor: Finished task 191.0 in stage 447.0 (TID 622). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.406 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 195.0 in stage 447.0 (TID 626) (5b5a8eb7561c, executor driver, partition 195, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.406 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 192.0 in stage 447.0 (TID 623) in 10 ms on 5b5a8eb7561c (executor driver) (192/200)\n",
      "10-20 20:37:02.407 172.17.0.2:54321      18300   (TID 626)  INFO org.apache.spark.executor.Executor: Running task 195.0 in stage 447.0 (TID 626)\n",
      "10-20 20:37:02.407 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 196.0 in stage 447.0 (TID 627) (5b5a8eb7561c, executor driver, partition 196, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.407 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 191.0 in stage 447.0 (TID 622) in 12 ms on 5b5a8eb7561c (executor driver) (193/200)\n",
      "10-20 20:37:02.407 172.17.0.2:54321      18300   (TID 627)  INFO org.apache.spark.executor.Executor: Running task 196.0 in stage 447.0 (TID 627)\n",
      "10-20 20:37:02.411 172.17.0.2:54321      18300   (TID 625)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.411 172.17.0.2:54321      18300   (TID 625)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.412 172.17.0.2:54321      18300   (TID 618)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.412 172.17.0.2:54321      18300   (TID 618)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.413 172.17.0.2:54321      18300   (TID 618)  INFO org.apache.spark.executor.Executor: Finished task 187.0 in stage 447.0 (TID 618). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.413 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 197.0 in stage 447.0 (TID 628) (5b5a8eb7561c, executor driver, partition 197, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.414 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 187.0 in stage 447.0 (TID 618) in 29 ms on 5b5a8eb7561c (executor driver) (194/200)\n",
      "10-20 20:37:02.414 172.17.0.2:54321      18300   (TID 628)  INFO org.apache.spark.executor.Executor: Running task 197.0 in stage 447.0 (TID 628)\n",
      "10-20 20:37:02.414 172.17.0.2:54321      18300   (TID 627)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.415 172.17.0.2:54321      18300   (TID 627)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 20:37:02.415 172.17.0.2:54321      18300   (TID 627)  INFO org.apache.spark.executor.Executor: Finished task 196.0 in stage 447.0 (TID 627). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.415 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 198.0 in stage 447.0 (TID 629) (5b5a8eb7561c, executor driver, partition 198, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.415 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 196.0 in stage 447.0 (TID 627) in 8 ms on 5b5a8eb7561c (executor driver) (195/200)\n",
      "10-20 20:37:02.416 172.17.0.2:54321      18300   (TID 629)  INFO org.apache.spark.executor.Executor: Running task 198.0 in stage 447.0 (TID 629)\n",
      "10-20 20:37:02.416 172.17.0.2:54321      18300   (TID 626)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.416 172.17.0.2:54321      18300   (TID 626)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 20:37:02.416 172.17.0.2:54321      18300   (TID 626)  INFO org.apache.spark.executor.Executor: Finished task 195.0 in stage 447.0 (TID 626). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.416 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 199.0 in stage 447.0 (TID 630) (5b5a8eb7561c, executor driver, partition 199, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:02.417 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 195.0 in stage 447.0 (TID 626) in 11 ms on 5b5a8eb7561c (executor driver) (196/200)\n",
      "10-20 20:37:02.417 172.17.0.2:54321      18300   (TID 630)  INFO org.apache.spark.executor.Executor: Running task 199.0 in stage 447.0 (TID 630)\n",
      "10-20 20:37:02.418 172.17.0.2:54321      18300   (TID 625)  INFO org.apache.spark.executor.Executor: Finished task 194.0 in stage 447.0 (TID 625). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.419 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 194.0 in stage 447.0 (TID 625) in 15 ms on 5b5a8eb7561c (executor driver) (197/200)\n",
      "10-20 20:37:02.420 172.17.0.2:54321      18300   (TID 629)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.420 172.17.0.2:54321      18300   (TID 629)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.421 172.17.0.2:54321      18300   (TID 629)  INFO org.apache.spark.executor.Executor: Finished task 198.0 in stage 447.0 (TID 629). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.421 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 198.0 in stage 447.0 (TID 629) in 6 ms on 5b5a8eb7561c (executor driver) (198/200)\n",
      "10-20 20:37:02.421 172.17.0.2:54321      18300   (TID 628)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.421 172.17.0.2:54321      18300   (TID 628)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.422 172.17.0.2:54321      18300   (TID 628)  INFO org.apache.spark.executor.Executor: Finished task 197.0 in stage 447.0 (TID 628). 3320 bytes result sent to driver\n",
      "10-20 20:37:02.422 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 197.0 in stage 447.0 (TID 628) in 9 ms on 5b5a8eb7561c (executor driver) (199/200)\n",
      "10-20 20:37:02.425 172.17.0.2:54321      18300   (TID 630)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:02.425 172.17.0.2:54321      18300   (TID 630)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:02.426 172.17.0.2:54321      18300   (TID 630)  INFO org.apache.spark.executor.Executor: Finished task 199.0 in stage 447.0 (TID 630). 3277 bytes result sent to driver\n",
      "10-20 20:37:02.426 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 199.0 in stage 447.0 (TID 630) in 10 ms on 5b5a8eb7561c (executor driver) (200/200)\n",
      "10-20 20:37:02.426 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 447.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:02.427 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 447 (collect at NaiveBayes.scala:193) finished in 0.809 s\n",
      "10-20 20:37:02.427 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 365 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:02.427 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 447: Stage finished\n",
      "10-20 20:37:02.427 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 365 finished: collect at NaiveBayes.scala:193, took 1.616639 s\n",
      "10-20 20:37:02.440 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.583071 ms\n",
      "10-20 20:37:02.442 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] {\"numFeatures\":106}\n",
      "10-20 20:37:02.443 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] {\"numExamples\":26076}\n",
      "10-20 20:37:02.443 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] {\"numClasses\":2}\n",
      "10-20 20:37:02.444 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] {\"sumOfWeights\":26076.0}\n",
      "10-20 20:37:02.448 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [50f84b4a] training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric name: areaUnderROC\n",
      "10-20 20:37:03.140 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:37:03.140 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:37:03.140 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:37:03.158 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_779 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 20:37:03.164 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_779_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.9 MiB)\n",
      "10-20 20:37:03.164 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_779_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.165 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 779 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:37:03.165 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:37:03.184 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:37:03.184 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 838 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 59\n",
      "10-20 20:37:03.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 839 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 58\n",
      "10-20 20:37:03.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 366 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:37:03.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 450 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:37:03.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 449)\n",
      "10-20 20:37:03.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 449)\n",
      "10-20 20:37:03.185 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 448 (MapPartitionsRDD[838] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:37:03.190 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_780 stored as values in memory (estimated size 139.8 KiB, free 432.7 MiB)\n",
      "10-20 20:37:03.201 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_780_piece0 stored as bytes in memory (estimated size 46.5 KiB, free 432.7 MiB)\n",
      "10-20 20:37:03.202 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_780_piece0 in memory on 5b5a8eb7561c:44751 (size: 46.5 KiB, free: 434.1 MiB)\n",
      "10-20 20:37:03.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 780 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:03.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 448 (MapPartitionsRDD[838] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:03.202 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 448.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:03.203 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 448.0 (TID 631) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:03.203 172.17.0.2:54321      18300   (TID 631)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 448.0 (TID 631)\n",
      "10-20 20:37:03.210 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_775_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.211 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_778_piece0 on 5b5a8eb7561c:44751 in memory (size: 32.2 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.212 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_776_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.215 172.17.0.2:54321      18300   (TID 631)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 20:37:03.548 172.17.0.2:54321      18300   (TID 631)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 448.0 (TID 631). 2133 bytes result sent to driver\n",
      "10-20 20:37:03.548 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 448.0 (TID 631) in 345 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:03.548 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 448.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:03.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 448 (map at BinaryClassificationMetrics.scala:48) finished in 0.364 s\n",
      "10-20 20:37:03.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:37:03.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:37:03.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 449, ResultStage 450)\n",
      "10-20 20:37:03.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:37:03.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 449 (ShuffledRDD[839] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:37:03.550 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_781 stored as values in memory (estimated size 5.1 KiB, free 433.2 MiB)\n",
      "10-20 20:37:03.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_781_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.2 MiB)\n",
      "10-20 20:37:03.551 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_781_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 781 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:03.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 449 (ShuffledRDD[839] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:03.551 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 449.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:03.552 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 449.0 (TID 632) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:03.552 172.17.0.2:54321      18300   (TID 632)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 449.0 (TID 632)\n",
      "10-20 20:37:03.554 172.17.0.2:54321      18300   (TID 632)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:03.554 172.17.0.2:54321      18300   (TID 632)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:03.584 172.17.0.2:54321      18300   (TID 632)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 449.0 (TID 632). 1419 bytes result sent to driver\n",
      "10-20 20:37:03.584 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 449.0 (TID 632) in 32 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:03.584 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 449.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 449 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.035 s\n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 450)\n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 450 (ShuffledRDD[840] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:37:03.585 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_782 stored as values in memory (estimated size 3.9 KiB, free 433.2 MiB)\n",
      "10-20 20:37:03.601 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_782_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.2 MiB)\n",
      "10-20 20:37:03.603 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_780_piece0 on 5b5a8eb7561c:44751 in memory (size: 46.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:03.604 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_782_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:03.604 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 782 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:03.604 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 450 (ShuffledRDD[840] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:03.604 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 450.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:03.605 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 450.0 (TID 633) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:03.605 172.17.0.2:54321      18300   (TID 633)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 450.0 (TID 633)\n",
      "10-20 20:37:03.607 172.17.0.2:54321      18300   (TID 633)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:03.607 172.17.0.2:54321      18300   (TID 633)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:03.633 172.17.0.2:54321      18300   (TID 633)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 450.0 (TID 633). 1305 bytes result sent to driver\n",
      "10-20 20:37:03.633 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 450.0 (TID 633) in 28 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:03.633 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 450.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:03.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 450 (count at BinaryClassificationMetrics.scala:197) finished in 0.048 s\n",
      "10-20 20:37:03.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 366 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:03.633 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 450: Stage finished\n",
      "10-20 20:37:03.634 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 366 finished: count at BinaryClassificationMetrics.scala:197, took 0.449566 s\n",
      "10-20 20:37:03.640 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:37:03.640 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 367 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:37:03.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 453 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:37:03.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 452)\n",
      "10-20 20:37:03.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:37:03.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 453 (MapPartitionsRDD[843] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:37:03.641 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_783 stored as values in memory (estimated size 5.6 KiB, free 433.4 MiB)\n",
      "10-20 20:37:03.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_783_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.4 MiB)\n",
      "10-20 20:37:03.642 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_783_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:03.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 783 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:03.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 453 (MapPartitionsRDD[843] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:03.642 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 453.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:03.643 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 453.0 (TID 634) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:03.644 172.17.0.2:54321      18300   (TID 634)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 453.0 (TID 634)\n",
      "10-20 20:37:03.645 172.17.0.2:54321      18300   (TID 634)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:03.645 172.17.0.2:54321      18300   (TID 634)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:03.670 172.17.0.2:54321      18300   (TID 634)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 453.0 (TID 634). 1405 bytes result sent to driver\n",
      "10-20 20:37:03.670 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 453.0 (TID 634) in 27 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:03.670 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 453.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:03.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 453 (collect at BinaryClassificationMetrics.scala:237) finished in 0.030 s\n",
      "10-20 20:37:03.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 367 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:03.671 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 453: Stage finished\n",
      "10-20 20:37:03.671 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 367 finished: collect at BinaryClassificationMetrics.scala:237, took 0.030928 s\n",
      "10-20 20:37:03.671 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 1552.0, numNeg: 4933.0}\n",
      "10-20 20:37:03.680 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:37:03.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 368 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:37:03.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 456 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:37:03.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 455)\n",
      "10-20 20:37:03.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:37:03.681 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 456 (MapPartitionsRDD[848] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:37:03.682 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_784 stored as values in memory (estimated size 7.2 KiB, free 433.4 MiB)\n",
      "10-20 20:37:03.683 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_784_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.4 MiB)\n",
      "10-20 20:37:03.684 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_784_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:03.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 784 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:03.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 456 (MapPartitionsRDD[848] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:03.684 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 456.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:03.685 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 456.0 (TID 635) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:03.685 172.17.0.2:54321      18300   (TID 635)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 456.0 (TID 635)\n",
      "10-20 20:37:03.689 172.17.0.2:54321      18300   (TID 635)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (90.5 KiB) non-empty blocks including 1 (90.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:03.689 172.17.0.2:54321      18300   (TID 635)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:03.740 172.17.0.2:54321      18300   (TID 635)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_844_0 stored as values in memory (estimated size 82.4 KiB, free 433.3 MiB)\n",
      "10-20 20:37:03.741 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_844_0 in memory on 5b5a8eb7561c:44751 (size: 82.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.742 172.17.0.2:54321      18300   (TID 635)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 456.0 (TID 635). 1524 bytes result sent to driver\n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 456.0 (TID 635) in 58 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 456 (collect at AreaUnderCurve.scala:44) finished in 0.061 s\n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 368 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 456: Stage finished\n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 368 finished: collect at AreaUnderCurve.scala:44, took 0.062549 s\n",
      "10-20 20:37:03.743 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 844 from persistence list\n",
      "CV Metric value: 0.3817183114559842\n",
      "10-20 20:37:03.744 172.17.0.2:54321      18300  d-pool-271  INFO org.apache.spark.storage.BlockManager: Removing RDD 844\n",
      "10-20 20:37:03.795 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 20:37:03.796 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 20:37:03.797 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 20:37:03.888 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_785 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 20:37:03.896 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_785_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.2 MiB)\n",
      "10-20 20:37:03.896 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_785_piece0 in memory on 5b5a8eb7561c:44751 (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.897 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 785 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 20:37:03.898 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 856 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 61\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 857 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 60\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 369 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 459 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 458)\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 458)\n",
      "10-20 20:37:03.925 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 457 (MapPartitionsRDD[856] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 20:37:03.944 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_786 stored as values in memory (estimated size 132.5 KiB, free 433.0 MiB)\n",
      "10-20 20:37:03.945 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_786_piece0 stored as bytes in memory (estimated size 44.5 KiB, free 433.0 MiB)\n",
      "10-20 20:37:03.945 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_786_piece0 in memory on 5b5a8eb7561c:44751 (size: 44.5 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:03.946 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 786 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:03.946 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 457 (MapPartitionsRDD[856] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:03.946 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 457.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:03.947 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 457.0 (TID 636) (5b5a8eb7561c, executor driver, partition 0, PROCESS_LOCAL, 4854 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:03.947 172.17.0.2:54321      18300   (TID 636)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 457.0 (TID 636)\n",
      "10-20 20:37:03.953 172.17.0.2:54321      18300   (TID 636)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n",
      "10-20 20:37:04.040 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_784_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.4 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.041 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_779_piece0 on 5b5a8eb7561c:44751 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.041 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_781_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.042 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_782_piece0 on 5b5a8eb7561c:44751 in memory (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.043 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_783_piece0 on 5b5a8eb7561c:44751 in memory (size: 3.0 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.044 172.17.0.2:54321      18300  d-pool-290  INFO org.apache.spark.storage.BlockManager: Removing RDD 844\n",
      "10-20 20:37:04.327 172.17.0.2:54321      18300   (TID 636)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 457.0 (TID 636). 1861 bytes result sent to driver\n",
      "10-20 20:37:04.328 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 457.0 (TID 636) in 381 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:04.328 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 457.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:04.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 457 (map at BinaryClassificationMetrics.scala:48) finished in 0.402 s\n",
      "10-20 20:37:04.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:37:04.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:37:04.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 458, ResultStage 459)\n",
      "10-20 20:37:04.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:37:04.329 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 458 (ShuffledRDD[857] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 20:37:04.330 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_787 stored as values in memory (estimated size 5.1 KiB, free 433.2 MiB)\n",
      "10-20 20:37:04.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_787_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.2 MiB)\n",
      "10-20 20:37:04.331 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_787_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.331 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 787 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:04.332 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 458 (ShuffledRDD[857] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:04.332 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 458.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:04.332 172.17.0.2:54321      18300  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 458.0 (TID 637) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:04.333 172.17.0.2:54321      18300   (TID 637)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 458.0 (TID 637)\n",
      "10-20 20:37:04.334 172.17.0.2:54321      18300   (TID 637)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (213.5 KiB) non-empty blocks including 1 (213.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:04.334 172.17.0.2:54321      18300   (TID 637)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:04.384 172.17.0.2:54321      18300   (TID 637)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 458.0 (TID 637). 1419 bytes result sent to driver\n",
      "10-20 20:37:04.384 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 458.0 (TID 637) in 52 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:04.384 172.17.0.2:54321      18300  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 458.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 458 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.056 s\n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 459)\n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 459 (ShuffledRDD[858] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 20:37:04.385 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_788 stored as values in memory (estimated size 3.9 KiB, free 433.2 MiB)\n",
      "10-20 20:37:04.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_788_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.2 MiB)\n",
      "10-20 20:37:04.395 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_788_piece0 in memory on 5b5a8eb7561c:44751 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 788 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:04.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 459 (ShuffledRDD[858] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:04.395 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 459.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:04.396 172.17.0.2:54321      18300  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 459.0 (TID 638) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:04.398 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_786_piece0 on 5b5a8eb7561c:44751 in memory (size: 44.5 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:04.399 172.17.0.2:54321      18300   (TID 638)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 459.0 (TID 638)\n",
      "10-20 20:37:04.402 172.17.0.2:54321      18300   (TID 638)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (213.5 KiB) non-empty blocks including 1 (213.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:04.402 172.17.0.2:54321      18300   (TID 638)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:04.449 172.17.0.2:54321      18300   (TID 638)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 459.0 (TID 638). 1262 bytes result sent to driver\n",
      "10-20 20:37:04.450 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 459.0 (TID 638) in 54 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:04.450 172.17.0.2:54321      18300  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 459.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:04.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 459 (count at BinaryClassificationMetrics.scala:197) finished in 0.065 s\n",
      "10-20 20:37:04.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 369 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:04.450 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 459: Stage finished\n",
      "10-20 20:37:04.450 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 369 finished: count at BinaryClassificationMetrics.scala:197, took 0.525459 s\n",
      "10-20 20:37:04.457 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 20:37:04.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 370 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 20:37:04.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 462 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 20:37:04.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 461)\n",
      "10-20 20:37:04.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:37:04.458 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 462 (MapPartitionsRDD[861] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 20:37:04.459 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_789 stored as values in memory (estimated size 5.6 KiB, free 433.4 MiB)\n",
      "10-20 20:37:04.459 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_789_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.4 MiB)\n",
      "10-20 20:37:04.459 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_789_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.0 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:04.461 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 789 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:04.461 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 462 (MapPartitionsRDD[861] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:04.461 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 462.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:04.462 172.17.0.2:54321      18300  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 462.0 (TID 639) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:04.467 172.17.0.2:54321      18300   (TID 639)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 462.0 (TID 639)\n",
      "10-20 20:37:04.470 172.17.0.2:54321      18300   (TID 639)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (213.5 KiB) non-empty blocks including 1 (213.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:04.476 172.17.0.2:54321      18300   (TID 639)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "10-20 20:37:04.544 172.17.0.2:54321      18300   (TID 639)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 462.0 (TID 639). 1448 bytes result sent to driver\n",
      "10-20 20:37:04.548 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 462.0 (TID 639) in 87 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:04.548 172.17.0.2:54321      18300  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 462.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:04.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 462 (collect at BinaryClassificationMetrics.scala:237) finished in 0.091 s\n",
      "10-20 20:37:04.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 370 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:04.549 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 462: Stage finished\n",
      "10-20 20:37:04.549 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 370 finished: collect at BinaryClassificationMetrics.scala:237, took 0.091798 s\n",
      "10-20 20:37:04.550 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 3846.0, numNeg: 12436.0}\n",
      "10-20 20:37:04.561 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 20:37:04.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 371 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 20:37:04.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 465 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 20:37:04.561 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 464)\n",
      "10-20 20:37:04.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 20:37:04.562 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 465 (MapPartitionsRDD[866] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 20:37:04.563 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_790 stored as values in memory (estimated size 7.2 KiB, free 433.4 MiB)\n",
      "10-20 20:37:04.564 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_790_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.4 MiB)\n",
      "10-20 20:37:04.564 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_790_piece0 in memory on 5b5a8eb7561c:44751 (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 20:37:04.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 790 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 20:37:04.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 465 (MapPartitionsRDD[866] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 20:37:04.565 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 465.0 with 1 tasks resource profile 0\n",
      "10-20 20:37:04.566 172.17.0.2:54321      18300  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 465.0 (TID 640) (5b5a8eb7561c, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 20:37:04.566 172.17.0.2:54321      18300   (TID 640)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 465.0 (TID 640)\n",
      "10-20 20:37:04.568 172.17.0.2:54321      18300   (TID 640)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (213.5 KiB) non-empty blocks including 1 (213.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 20:37:04.568 172.17.0.2:54321      18300   (TID 640)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 20:37:04.663 172.17.0.2:54321      18300   (TID 640)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_862_0 stored as values in memory (estimated size 82.1 KiB, free 433.3 MiB)\n",
      "10-20 20:37:04.663 172.17.0.2:54321      18300  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_862_0 in memory on 5b5a8eb7561c:44751 (size: 82.1 KiB, free: 434.2 MiB)\n",
      "10-20 20:37:04.665 172.17.0.2:54321      18300   (TID 640)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 465.0 (TID 640). 1524 bytes result sent to driver\n",
      "10-20 20:37:04.666 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 465.0 (TID 640) in 100 ms on 5b5a8eb7561c (executor driver) (1/1)\n",
      "10-20 20:37:04.666 172.17.0.2:54321      18300  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 465.0, whose tasks have all completed, from pool \n",
      "10-20 20:37:04.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 465 (collect at AreaUnderCurve.scala:44) finished in 0.103 s\n",
      "10-20 20:37:04.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 371 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 20:37:04.666 172.17.0.2:54321      18300  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 465: Stage finished\n",
      "10-20 20:37:04.667 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 371 finished: collect at AreaUnderCurve.scala:44, took 0.105655 s\n",
      "10-20 20:37:04.667 172.17.0.2:54321      18300    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 862 from persistence list\n",
      "10-20 20:37:04.667 172.17.0.2:54321      18300  d-pool-299  INFO org.apache.spark.storage.BlockManager: Removing RDD 862\n",
      "Test Metric value: 0.3628204069944723\n",
      "10-20 20:41:07.904 172.17.0.2:54321      18300  7762763-65  INFO water.default: POST /4/sessions, parms: {}\n",
      "Closing connection _sid_8c9d at exit\n",
      "10-20 20:41:07.959 172.17.0.2:54321      18300  7762763-69  INFO water.default: DELETE /4/sessions/_sid_8c9d, parms: {}\n",
      "H2O session _sid_8c9d closed.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "nb = NaiveBayes(labelCol='label', featuresCol='features')\n",
    "nb_stages = [imputer] + string_indexers + ohe_indexers + [vector_assembler] + [nb]\n",
    "pipeline = Pipeline().setStages(nb_stages)\n",
    "nb_model = pipeline.fit(train_df)\n",
    "\n",
    "val_df_pred = nb_model.transform(val_df)\n",
    "test_df_pred = nb_model.transform(test_df)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'Metric name: {evaluator.getMetricName()}')\n",
    "print(f'CV Metric value: {evaluator.evaluate(val_df_pred)}')\n",
    "print(f'Test Metric value: {evaluator.evaluate(test_df_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d20deb-af42-43f1-8da0-7e513c4498af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
