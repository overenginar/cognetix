{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3fd977-3107-4150-b241-c18247ac2d48",
   "metadata": {},
   "source": [
    "## Income Prediction with Spark Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b019947-3e52-4742-9a33-8dc33d9f32a3",
   "metadata": {},
   "source": [
    "### Install findspark and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0156047-cfe9-47e1-9622-74666342340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.9/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c38bc1-77fa-400a-b944-44e1d20757aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1712a2-81a4-459c-8e36-c7317a52a07c",
   "metadata": {},
   "source": [
    "### Get spark and h2o sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd3e1e6-51bf-41ad-ab4a-d08c1ef14cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/10/20 14:43:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/20 14:43:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:43:41.980 172.17.0.2:54325      7233     Thread-4  INFO water.default: ----- H2O started  -----\n",
      "10-20 14:43:41.981 172.17.0.2:54325      7233     Thread-4  INFO water.default: Build git branch: rel-zz_kurka\n",
      "10-20 14:43:41.981 172.17.0.2:54325      7233     Thread-4  INFO water.default: Build git hash: 5ff8870f912c6110d7b6988f577c020de10496ec\n",
      "10-20 14:43:41.981 172.17.0.2:54325      7233     Thread-4  INFO water.default: Build git describe: jenkins-3.40.0.3-122-g5ff8870\n",
      "10-20 14:43:41.982 172.17.0.2:54325      7233     Thread-4  INFO water.default: Build project version: 3.40.0.4\n",
      "10-20 14:43:41.982 172.17.0.2:54325      7233     Thread-4  INFO water.default: Build age: 5 months and 22 days\n",
      "10-20 14:43:41.982 172.17.0.2:54325      7233     Thread-4  INFO water.default: Built by: 'jenkins'\n",
      "10-20 14:43:41.982 172.17.0.2:54325      7233     Thread-4  INFO water.default: Built on: '2023-04-28 12:08:23'\n",
      "10-20 14:43:41.982 172.17.0.2:54325      7233     Thread-4  WARN water.default: \n",
      "10-20 14:43:41.983 172.17.0.2:54325      7233     Thread-4  WARN water.default: *** Your H2O version is over 100 days old. Please download the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html ***\n",
      "10-20 14:43:41.983 172.17.0.2:54325      7233     Thread-4  WARN water.default: \n",
      "10-20 14:43:41.984 172.17.0.2:54325      7233     Thread-4  INFO water.default: Found H2O Core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 14:43:41.984 172.17.0.2:54325      7233     Thread-4  INFO water.default: Processed H2O arguments: [-internal_security_conf_rel_paths, -name, sparkling-water-root_local-1697813016025, -port_offset, 1, -hdfs_config, /tmp/spark-cce47ace-0779-48be-a311-d6c981f0229f/userFiles-b24a9ad1-a76a-485f-9c79-3275e0be29a0/hdfs_conf17372385375602224929.xml, -log_level, INFO, -embedded, -baseport, 54321, -log_dir, /home/jovyan/notebooks/h2ologs/local-1697813016025, -quiet, -flatfile, /tmp/spark-cce47ace-0779-48be-a311-d6c981f0229f/sparkling-water-85009c21-f320-40c7-8711-a483a9436e35/flatfile.txt]\n",
      "10-20 14:43:41.984 172.17.0.2:54325      7233     Thread-4  INFO water.default: Java availableProcessors: 4\n",
      "10-20 14:43:41.984 172.17.0.2:54325      7233     Thread-4  INFO water.default: Java heap totalMemory: 134.0 MB\n",
      "10-20 14:43:41.985 172.17.0.2:54325      7233     Thread-4  INFO water.default: Java heap maxMemory: 1.00 GB\n",
      "10-20 14:43:41.985 172.17.0.2:54325      7233     Thread-4  INFO water.default: Java version: Java 11.0.11 (from Ubuntu)\n",
      "10-20 14:43:41.985 172.17.0.2:54325      7233     Thread-4  INFO water.default: JVM launch parameters: [-Xmx1g, -Dio.netty.tryReflectionSetAccessible=true]\n",
      "10-20 14:43:41.985 172.17.0.2:54325      7233     Thread-4  INFO water.default: JVM process id: 7233@95675304fa2d\n",
      "10-20 14:43:41.985 172.17.0.2:54325      7233     Thread-4  INFO water.default: OS version: Linux 5.15.49-linuxkit-pr (amd64)\n",
      "10-20 14:43:41.986 172.17.0.2:54325      7233     Thread-4  INFO water.default: Machine physical memory: 5.80 GB\n",
      "10-20 14:43:41.986 172.17.0.2:54325      7233     Thread-4  INFO water.default: Machine locale: en_US\n",
      "10-20 14:43:41.986 172.17.0.2:54325      7233     Thread-4  INFO water.default: X-h2o-cluster-id: 1697813019759\n",
      "10-20 14:43:41.986 172.17.0.2:54325      7233     Thread-4  INFO water.default: User name: 'root'\n",
      "10-20 14:43:41.986 172.17.0.2:54325      7233     Thread-4  INFO water.default: IPv6 stack selected: false\n",
      "10-20 14:43:41.987 172.17.0.2:54325      7233     Thread-4  INFO water.default: Possible IP Address: eth0 (eth0), 172.17.0.2\n",
      "10-20 14:43:41.987 172.17.0.2:54325      7233     Thread-4  INFO water.default: Possible IP Address: lo (lo), 127.0.0.1\n",
      "10-20 14:43:41.987 172.17.0.2:54325      7233     Thread-4  INFO water.default: H2O node running in unencrypted mode.\n",
      "10-20 14:43:41.988 172.17.0.2:54325      7233     Thread-4  INFO water.default: Internal communication uses port: 54326\n",
      "10-20 14:43:41.989 172.17.0.2:54325      7233     Thread-4  INFO water.default: Listening for HTTP and REST traffic on http://172.17.0.2:54325/\n",
      "10-20 14:43:41.989 172.17.0.2:54325      7233     Thread-4  WARN water.default: Flatfile configuration does not include self: /172.17.0.2:54325, but contains []\n",
      "10-20 14:43:41.990 172.17.0.2:54325      7233     Thread-4  INFO water.default: H2O cloud name: 'sparkling-water-root_local-1697813016025' on /172.17.0.2:54325, static configuration based on -flatfile /tmp/spark-cce47ace-0779-48be-a311-d6c981f0229f/sparkling-water-85009c21-f320-40c7-8711-a483a9436e35/flatfile.txt\n",
      "10-20 14:43:41.990 172.17.0.2:54325      7233     Thread-4  INFO water.default: If you have trouble connecting, try SSH tunneling from your local machine (e.g., via port 55555):\n",
      "10-20 14:43:41.990 172.17.0.2:54325      7233     Thread-4  INFO water.default:   1. Open a terminal and run 'ssh -L 55555:localhost:54325 root@172.17.0.2'\n",
      "10-20 14:43:41.990 172.17.0.2:54325      7233     Thread-4  INFO water.default:   2. Point your browser to http://localhost:55555\n",
      "10-20 14:43:42.406 172.17.0.2:54325      7233     Thread-4  INFO water.default: Log dir: '/home/jovyan/notebooks/h2ologs/local-1697813016025'\n",
      "10-20 14:43:42.407 172.17.0.2:54325      7233     Thread-4  INFO water.default: Cur dir: '/home/jovyan/notebooks'\n",
      "10-20 14:43:42.416 172.17.0.2:54325      7233     Thread-4  INFO water.default: Distributed HTTP import not available (import from HTTP/HTTPS will be eager)\n",
      "10-20 14:43:42.435 172.17.0.2:54325      7233     Thread-4  INFO water.default: HDFS subsystem successfully initialized\n",
      "10-20 14:43:42.441 172.17.0.2:54325      7233     Thread-4  INFO water.default: S3 subsystem successfully initialized\n",
      "10-20 14:43:42.464 172.17.0.2:54325      7233     Thread-4  INFO water.default: GCS subsystem successfully initialized\n",
      "10-20 14:43:42.465 172.17.0.2:54325      7233     Thread-4  INFO water.default: Drive subsystem not available\n",
      "10-20 14:43:42.465 172.17.0.2:54325      7233     Thread-4  INFO water.default: Flow dir: '/root/h2oflows'\n",
      "10-20 14:43:42.475 172.17.0.2:54325      7233     Thread-4  INFO water.default: Cloud of size 1 formed [95675304fa2d/172.17.0.2:54325]\n",
      "10-20 14:43:42.489 172.17.0.2:54325      7233     Thread-4  INFO water.default: Registered parsers: [GUESS, ARFF, XLS, SVMLight, AVRO, PARQUET, ORC, CSV]\n",
      "10-20 14:43:42.490 172.17.0.2:54325      7233     Thread-4  INFO water.default: HiveTableImporter extension initialized\n",
      "10-20 14:43:42.491 172.17.0.2:54325      7233     Thread-4  INFO water.default: StackTraceCollector extension initialized\n",
      "10-20 14:43:42.491 172.17.0.2:54325      7233     Thread-4  INFO water.default: MojoPipeline extension initialized\n",
      "10-20 14:43:42.492 172.17.0.2:54325      7233     Thread-4  INFO water.default: HiveFrameSaver extension initialized\n",
      "10-20 14:43:42.492 172.17.0.2:54325      7233     Thread-4  INFO water.default: XGBoost extension initialized\n",
      "10-20 14:43:42.492 172.17.0.2:54325      7233     Thread-4  INFO water.default: Registered 5 core extensions in: 1934ms\n",
      "10-20 14:43:42.492 172.17.0.2:54325      7233     Thread-4  INFO water.default: Registered H2O core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 14:43:42.948 172.17.0.2:54325      7233     Thread-4  INFO hex.tree.xgboost.XGBoostExtension: Found XGBoost backend with library: xgboost4j_gpu\n",
      "10-20 14:43:42.948 172.17.0.2:54325      7233     Thread-4  INFO hex.tree.xgboost.XGBoostExtension: XGBoost supported backends: [WITH_GPU, WITH_OMP]\n",
      "10-20 14:43:43.075 172.17.0.2:54325      7233     Thread-4  INFO water.default: Registered: 280 REST APIs in: 583ms\n",
      "10-20 14:43:43.075 172.17.0.2:54325      7233     Thread-4  INFO water.default: Registered REST API extensions: [XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4]\n",
      "10-20 14:43:43.219 172.17.0.2:54325      7233     Thread-4  INFO water.default: Registered: 329 schemas in 144ms\n",
      "10-20 14:43:43.220 172.17.0.2:54325      7233     Thread-4  INFO water.default: H2O started in 3486ms\n",
      "10-20 14:43:43.221 172.17.0.2:54325      7233     Thread-4  INFO water.default: \n",
      "10-20 14:43:43.221 172.17.0.2:54325      7233     Thread-4  INFO water.default: Open H2O Flow in your web browser: http://172.17.0.2:54325\n",
      "10-20 14:43:43.221 172.17.0.2:54325      7233     Thread-4  INFO water.default: \n",
      "10-20 14:43:43.225 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.H2OContext: Connecting to H2O cluster.\n",
      "10-20 14:43:43.227 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.H2OContext: Trying to lock H2O cluster 172.17.0.2:54325 - sparkling-water-root_local-1697813016025.\n",
      "10-20 14:43:43.339 172.17.0.2:54325      7233   2920931-68  INFO water.default: POST /3/CloudLock, parms: {reason=Locked from Sparkling Water.}\n",
      "10-20 14:43:43.352 172.17.0.2:54325      7233   2920931-68  INFO water.default: Locking cloud to new members, because requested via REST api. Reason: Locked from Sparkling Water.\n",
      "10-20 14:43:43.408 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/3/CloudLock successfully responded for the POST.\n",
      "10-20 14:43:43.421 172.17.0.2:54325      7233   2920931-65  INFO water.default: GET /3/verifyWebOpen, parms: {}\n",
      "10-20 14:43:43.499 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/3/verifyWebOpen successfully responded for the GET.\n",
      "10-20 14:43:43.502 172.17.0.2:54325      7233   2920931-67  INFO water.default: GET /3/verifyVersion, parms: {referenced_version=3.40.0.4}\n",
      "10-20 14:43:43.517 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/3/verifyVersion?referenced_version=3.40.0.4 successfully responded for the GET.\n",
      "10-20 14:43:43.543 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/3/Cloud successfully responded for the GET.\n",
      "10-20 14:43:43.548 172.17.0.2:54325      7233   2920931-67  INFO water.default: GET /3/LogLevel, parms: {}\n",
      "10-20 14:43:43.557 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/3/LogLevel successfully responded for the GET.\n",
      "10-20 14:43:43.560 172.17.0.2:54325      7233   2920931-67  INFO water.default: POST /99/Rapids, parms: {ast=(setTimeZone \"UTC\")}\n",
      "10-20 14:43:43.683 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/99/Rapids successfully responded for the POST.\n",
      "10-20 14:43:43.698 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.ProxyStarter: Trying to bind on port 54323 using wildcard ip address\n",
      "10-20 14:43:43.705 172.17.0.2:54325      7233     Thread-4  WARN ai.h2o.sparkling.backend.utils.ProxyStarter: Tried using port 54323 for Flow proxy, but port was already occupied!\n",
      "10-20 14:43:43.706 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.ProxyStarter: Trying to bind on port 54324 using wildcard ip address\n",
      "10-20 14:43:43.883 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.util.SignalUtils: Registering signal handler for INT\n",
      "10-20 14:43:53.911 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: jetty-9.4.z-SNAPSHOT; built: 2018-06-05T18:24:03.829Z; git: d5fc0523cfa96bfebfbda19606cad384d772f04c; jvm 11.0.11+9-Ubuntu-0ubuntu2.20.04\n",
      "10-20 14:43:53.936 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.handler.ContextHandler: Started a.h.o.e.j.s.ServletContextHandler@36433cd3{/,null,AVAILABLE}\n",
      "10-20 14:43:53.937 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@24fa8718{HTTP/1.1,[http/1.1]}{0.0.0.0:54324}\n",
      "10-20 14:43:53.938 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: Started @21764ms\n",
      "10-20 14:43:53.948 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54325/3/Cloud successfully responded for the GET.\n",
      "10-20 14:43:54.005 172.17.0.2:54325      7233     Thread-4  INFO ai.h2o.sparkling.H2OContext: Sparkling Water 3.40.0.4-1-3.1 started, status of context: \n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697813016025\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54325)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://95675304fa2d:54324 (CMD + click in Mac OSX)\n",
      "\n",
      "     \n",
      "Connecting to H2O server at http://95675304fa2d:54324 ...10-20 14:43:54.072 172.17.0.2:54325      7233   2920931-68  INFO water.default: GET /3/Metadata/schemas/CloudV3, parms: {}\n",
      "10-20 14:43:54.133 172.17.0.2:54325      7233   2920931-71  INFO water.default: GET /3/Metadata/schemas/H2OErrorV3, parms: {}\n",
      "10-20 14:43:54.146 172.17.0.2:54325      7233   2920931-68  INFO water.default: GET /3/Metadata/schemas/H2OModelBuilderErrorV3, parms: {}\n",
      " successful.\n",
      "Warning: Your H2O cluster version is (5 months and 22 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>12 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-root_local-1697813016025</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://95675304fa2d:54324</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O_cluster_uptime:         12 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    5 months and 22 days\n",
       "H2O_cluster_name:           sparkling-water-root_local-1697813016025\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://95675304fa2d:54324\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697813016025\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54325)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://95675304fa2d:54324 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import H2OContext\n",
    "import h2o\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.appName('cognetix-spark-nb')\n",
    "    .config('spark.dynamicAllocation.enabled', 'false')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "sc = spark.sparkContext\n",
    "hc = H2OContext.getOrCreate()\n",
    "h2o_cluster = h2o.cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b11a08-e309-4d12-a74d-56eeb12f1757",
   "metadata": {},
   "source": [
    "### Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d26e8b22-875e-49cc-ae40-499d37ab4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "learning_rate = 0.01\n",
    "train_rate = 0.8\n",
    "seed = 42\n",
    "\n",
    "train_path = '../data/census-train.csv'\n",
    "test_path = '../data/census-test.csv'\n",
    "model_path = 'outputs/income_gbt_spark'\n",
    "pred_path = 'outputs/income_gbt_spark_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c63fd9-3e8a-43ba-b0ae-c4048ce8e233",
   "metadata": {},
   "source": [
    "### Load data and basic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8c40cb-18a9-4faa-897b-bdd2a3b33274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:44:53.193 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "train_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(train_path)\n",
    "    .drop('education_num')\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('income_level')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dfb6c-b722-4fd7-ab7d-f9269e7b6a39",
   "metadata": {},
   "source": [
    "### Explore train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0aa121b-ad53-48ee-83aa-e6930ef42cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:44:55.034 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:44:55.034 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:44:55.034 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<>\n",
      "10-20 14:44:55.053 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 14:44:55.075 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 14:44:55.075 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:55.076 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:44:55.077 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:44:55.094 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:44:55.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 31 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4\n",
      "10-20 14:44:55.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:44:55.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:44:55.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n",
      "10-20 14:44:55.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 8)\n",
      "10-20 14:44:55.096 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:44:55.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 15.9 KiB, free 434.2 MiB)\n",
      "10-20 14:44:55.101 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.2 MiB)\n",
      "10-20 14:44:55.101 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 95675304fa2d:39429 (size: 8.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:55.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:44:55.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:44:55.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "10-20 14:44:55.104 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 207) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:44:55.105 172.17.0.2:54325      7233    (TID 207)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 8.0 (TID 207)\n",
      "10-20 14:44:55.109 172.17.0.2:54325      7233    (TID 207)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:44:55.143 172.17.0.2:54325      7233    (TID 207)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 8.0 (TID 207). 1922 bytes result sent to driver\n",
      "10-20 14:44:55.144 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 207) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:44:55.144 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "10-20 14:44:55.145 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.049 s\n",
      "10-20 14:44:55.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:44:55.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:44:55.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 9)\n",
      "10-20 14:44:55.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:44:55.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:44:55.149 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 434.2 MiB)\n",
      "10-20 14:44:55.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.2 MiB)\n",
      "10-20 14:44:55.151 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 95675304fa2d:39429 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:55.152 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:44:55.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:44:55.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "10-20 14:44:55.155 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 208) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:44:55.156 172.17.0.2:54325      7233    (TID 208)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 9.0 (TID 208)\n",
      "10-20 14:44:55.160 172.17.0.2:54325      7233    (TID 208)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:44:55.160 172.17.0.2:54325      7233    (TID 208)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:44:55.162 172.17.0.2:54325      7233    (TID 208)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 9.0 (TID 208). 2648 bytes result sent to driver\n",
      "10-20 14:44:55.163 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 208) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:44:55.163 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "10-20 14:44:55.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s\n",
      "10-20 14:44:55.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:44:55.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:44:55.165 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.071062 s\n"
     ]
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c419a47-23f1-424c-9638-b2ce82e32c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_per_week',\n",
       " 'native_country',\n",
       " 'label']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5afae865-b5c3-4e52-9f76-c28235e7c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93430319-4f83-4946-a7ea-77e7362e8abd",
   "metadata": {},
   "source": [
    "### Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f97377-33f2-494a-8018-e77e9273765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:44:57.452 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:44:57.452 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:44:57.453 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:44:57.480 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:44:57.505 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on 95675304fa2d:39429 in memory (size: 8.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:57.509 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 14:44:57.510 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:57.511 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:44:57.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:44:57.521 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:57.541 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:44:57.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 38 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5\n",
      "10-20 14:44:57.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:44:57.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:44:57.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\n",
      "10-20 14:44:57.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 10)\n",
      "10-20 14:44:57.547 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:44:57.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 34.2 KiB, free 434.2 MiB)\n",
      "10-20 14:44:57.553 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 434.2 MiB)\n",
      "10-20 14:44:57.553 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 95675304fa2d:39429 (size: 15.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:57.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:44:57.555 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on 95675304fa2d:39429 in memory (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:57.556 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:44:57.556 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "10-20 14:44:57.557 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 209) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:44:57.558 172.17.0.2:54325      7233    (TID 209)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 10.0 (TID 209)\n",
      "10-20 14:44:57.568 172.17.0.2:54325      7233    (TID 209)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:44:57.889 172.17.0.2:54325      7233    (TID 209)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 10.0 (TID 209). 2732 bytes result sent to driver\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 209) in 333 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.342 s\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 11)\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:44:57.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[41] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:44:57.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 10.1 KiB, free 434.1 MiB)\n",
      "10-20 14:44:57.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.1 MiB)\n",
      "10-20 14:44:57.902 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 95675304fa2d:39429 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:57.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:44:57.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:44:57.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "10-20 14:44:57.904 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 210) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:44:57.904 172.17.0.2:54325      7233    (TID 210)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 11.0 (TID 210)\n",
      "10-20 14:44:57.906 172.17.0.2:54325      7233    (TID 210)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:44:57.906 172.17.0.2:54325      7233    (TID 210)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:44:57.907 172.17.0.2:54325      7233    (TID 210)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 11.0 (TID 210). 2648 bytes result sent to driver\n",
      "10-20 14:44:57.908 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 210) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:44:57.908 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "10-20 14:44:57.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s\n",
      "10-20 14:44:57.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:44:57.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished\n",
      "10-20 14:44:57.909 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.368085 s\n",
      "Train split size: 26076\n",
      "10-20 14:44:57.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:44:57.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:44:57.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:44:57.952 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:44:57.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:44:57.959 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:57.959 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:44:57.960 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:44:57.987 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:44:57.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 45 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6\n",
      "10-20 14:44:57.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:44:57.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:44:57.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "10-20 14:44:57.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 12)\n",
      "10-20 14:44:57.989 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[45] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:44:57.991 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 34.2 KiB, free 433.9 MiB)\n",
      "10-20 14:44:57.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 433.9 MiB)\n",
      "10-20 14:44:57.992 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 95675304fa2d:39429 (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:57.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:44:57.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[45] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:44:57.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "10-20 14:44:57.994 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 211) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:44:57.995 172.17.0.2:54325      7233    (TID 211)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 12.0 (TID 211)\n",
      "10-20 14:44:58.003 172.17.0.2:54325      7233    (TID 211)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:44:58.241 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on 95675304fa2d:39429 in memory (size: 5.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:58.252 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:58.338 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on 95675304fa2d:39429 in memory (size: 15.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:58.455 172.17.0.2:54325      7233    (TID 211)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 12.0 (TID 211). 2732 bytes result sent to driver\n",
      "10-20 14:44:58.456 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 211) in 462 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:44:58.457 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "10-20 14:44:58.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.468 s\n",
      "10-20 14:44:58.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:44:58.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:44:58.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 13)\n",
      "10-20 14:44:58.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:44:58.458 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:44:58.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 10.1 KiB, free 434.1 MiB)\n",
      "10-20 14:44:58.469 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.1 MiB)\n",
      "10-20 14:44:58.472 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 95675304fa2d:39429 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:44:58.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:44:58.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:44:58.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "10-20 14:44:58.474 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 212) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:44:58.475 172.17.0.2:54325      7233    (TID 212)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 13.0 (TID 212)\n",
      "10-20 14:44:58.477 172.17.0.2:54325      7233    (TID 212)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:44:58.477 172.17.0.2:54325      7233    (TID 212)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:44:58.485 172.17.0.2:54325      7233    (TID 212)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 13.0 (TID 212). 2648 bytes result sent to driver\n",
      "10-20 14:44:58.485 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 212) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:44:58.485 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "10-20 14:44:58.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.027 s\n",
      "10-20 14:44:58.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:44:58.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "10-20 14:44:58.486 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.498909 s\n",
      "Validation split size: 6485\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_df.randomSplit([train_rate, 1-train_rate], seed=seed)\n",
    "print(f'Train split size: {train_df.count()}')\n",
    "print(f'Validation split size: {val_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df909d-7075-4529-8600-455e41994ca4",
   "metadata": {},
   "source": [
    "###Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f42e7b5-1c58-42ce-b120-7180cd5ba25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:00.087 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:00.088 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:00.088 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:00.114 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:45:00.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:00.130 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:00.131 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 21 from toPandas at /tmp/ipykernel_7175/3328129577.py:1\n",
      "10-20 14:45:00.132 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:00.144 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on 95675304fa2d:39429 in memory (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:00.152 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: toPandas at /tmp/ipykernel_7175/3328129577.py:1\n",
      "10-20 14:45:00.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 52 (toPandas at /tmp/ipykernel_7175/3328129577.py:1) as input to shuffle 7\n",
      "10-20 14:45:00.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 7 (toPandas at /tmp/ipykernel_7175/3328129577.py:1) with 200 output partitions\n",
      "10-20 14:45:00.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 15 (toPandas at /tmp/ipykernel_7175/3328129577.py:1)\n",
      "10-20 14:45:00.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\n",
      "10-20 14:45:00.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 14)\n",
      "10-20 14:45:00.159 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[52] at toPandas at /tmp/ipykernel_7175/3328129577.py:1), which has no missing parents\n",
      "10-20 14:45:00.160 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 40.8 KiB, free 433.9 MiB)\n",
      "10-20 14:45:00.163 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:00.163 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 95675304fa2d:39429 (size: 18.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:00.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:00.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[52] at toPandas at /tmp/ipykernel_7175/3328129577.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:00.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:00.165 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 213) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.166 172.17.0.2:54325      7233    (TID 213)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 14.0 (TID 213)\n",
      "10-20 14:45:00.176 172.17.0.2:54325      7233    (TID 213)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:00.185 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on 95675304fa2d:39429 in memory (size: 5.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:00.206 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:00.525 172.17.0.2:54325      7233    (TID 213)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 14.0 (TID 213). 2934 bytes result sent to driver\n",
      "10-20 14:45:00.526 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 213) in 361 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:00.526 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:00.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 14 (toPandas at /tmp/ipykernel_7175/3328129577.py:1) finished in 0.368 s\n",
      "10-20 14:45:00.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:00.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:00.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 15)\n",
      "10-20 14:45:00.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:00.529 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[55] at toPandas at /tmp/ipykernel_7175/3328129577.py:1), which has no missing parents\n",
      "10-20 14:45:00.539 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 34.3 KiB, free 434.1 MiB)\n",
      "10-20 14:45:00.550 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 434.1 MiB)\n",
      "10-20 14:45:00.550 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 95675304fa2d:39429 (size: 17.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:00.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:00.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 200 missing tasks from ResultStage 15 (MapPartitionsRDD[55] at toPandas at /tmp/ipykernel_7175/3328129577.py:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "10-20 14:45:00.556 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 15.0 with 200 tasks resource profile 0\n",
      "10-20 14:45:00.560 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 43.0 in stage 15.0 (TID 214) (95675304fa2d, executor driver, partition 43, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.560 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 191.0 in stage 15.0 (TID 215) (95675304fa2d, executor driver, partition 191, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.560 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 216) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.561 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 15.0 (TID 217) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.561 172.17.0.2:54325      7233    (TID 215)  INFO org.apache.spark.executor.Executor: Running task 191.0 in stage 15.0 (TID 215)\n",
      "10-20 14:45:00.561 172.17.0.2:54325      7233    (TID 214)  INFO org.apache.spark.executor.Executor: Running task 43.0 in stage 15.0 (TID 214)\n",
      "10-20 14:45:00.561 172.17.0.2:54325      7233    (TID 216)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 15.0 (TID 216)\n",
      "10-20 14:45:00.565 172.17.0.2:54325      7233    (TID 216)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.565 172.17.0.2:54325      7233    (TID 217)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 15.0 (TID 217)\n",
      "10-20 14:45:00.568 172.17.0.2:54325      7233    (TID 214)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.568 172.17.0.2:54325      7233    (TID 214)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.569 172.17.0.2:54325      7233    (TID 217)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.569 172.17.0.2:54325      7233    (TID 217)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.565 172.17.0.2:54325      7233    (TID 215)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.571 172.17.0.2:54325      7233    (TID 214)  INFO org.apache.spark.executor.Executor: Finished task 43.0 in stage 15.0 (TID 214). 3853 bytes result sent to driver\n",
      "10-20 14:45:00.572 172.17.0.2:54325      7233    (TID 215)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 14:45:00.566 172.17.0.2:54325      7233    (TID 216)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.572 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 15.0 (TID 218) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.573 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 43.0 in stage 15.0 (TID 214) in 13 ms on 95675304fa2d (executor driver) (1/200)\n",
      "10-20 14:45:00.573 172.17.0.2:54325      7233    (TID 218)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 15.0 (TID 218)\n",
      "10-20 14:45:00.576 172.17.0.2:54325      7233    (TID 216)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 15.0 (TID 216). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.576 172.17.0.2:54325      7233    (TID 217)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 15.0 (TID 217). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.576 172.17.0.2:54325      7233    (TID 215)  INFO org.apache.spark.executor.Executor: Finished task 191.0 in stage 15.0 (TID 215). 3849 bytes result sent to driver\n",
      "10-20 14:45:00.577 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 15.0 (TID 219) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.577 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 4.0 in stage 15.0 (TID 220) (95675304fa2d, executor driver, partition 4, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.578 172.17.0.2:54325      7233    (TID 220)  INFO org.apache.spark.executor.Executor: Running task 4.0 in stage 15.0 (TID 220)\n",
      "10-20 14:45:00.578 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 5.0 in stage 15.0 (TID 221) (95675304fa2d, executor driver, partition 5, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.578 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 216) in 18 ms on 95675304fa2d (executor driver) (2/200)\n",
      "10-20 14:45:00.578 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 191.0 in stage 15.0 (TID 215) in 18 ms on 95675304fa2d (executor driver) (3/200)\n",
      "10-20 14:45:00.578 172.17.0.2:54325      7233    (TID 221)  INFO org.apache.spark.executor.Executor: Running task 5.0 in stage 15.0 (TID 221)\n",
      "10-20 14:45:00.579 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 15.0 (TID 217) in 18 ms on 95675304fa2d (executor driver) (4/200)\n",
      "10-20 14:45:00.578 172.17.0.2:54325      7233    (TID 218)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.579 172.17.0.2:54325      7233    (TID 218)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.581 172.17.0.2:54325      7233    (TID 218)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 15.0 (TID 218). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.582 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 6.0 in stage 15.0 (TID 222) (95675304fa2d, executor driver, partition 6, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.582 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 15.0 (TID 218) in 10 ms on 95675304fa2d (executor driver) (5/200)\n",
      "10-20 14:45:00.583 172.17.0.2:54325      7233    (TID 219)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 15.0 (TID 219)\n",
      "10-20 14:45:00.583 172.17.0.2:54325      7233    (TID 221)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.583 172.17.0.2:54325      7233    (TID 221)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.583 172.17.0.2:54325      7233    (TID 222)  INFO org.apache.spark.executor.Executor: Running task 6.0 in stage 15.0 (TID 222)\n",
      "10-20 14:45:00.585 172.17.0.2:54325      7233    (TID 221)  INFO org.apache.spark.executor.Executor: Finished task 5.0 in stage 15.0 (TID 221). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.586 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 7.0 in stage 15.0 (TID 223) (95675304fa2d, executor driver, partition 7, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.586 172.17.0.2:54325      7233    (TID 222)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.586 172.17.0.2:54325      7233    (TID 222)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.586 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 5.0 in stage 15.0 (TID 221) in 8 ms on 95675304fa2d (executor driver) (6/200)\n",
      "10-20 14:45:00.587 172.17.0.2:54325      7233    (TID 223)  INFO org.apache.spark.executor.Executor: Running task 7.0 in stage 15.0 (TID 223)\n",
      "10-20 14:45:00.588 172.17.0.2:54325      7233    (TID 220)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.588 172.17.0.2:54325      7233    (TID 220)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.589 172.17.0.2:54325      7233    (TID 222)  INFO org.apache.spark.executor.Executor: Finished task 6.0 in stage 15.0 (TID 222). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.590 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 8.0 in stage 15.0 (TID 224) (95675304fa2d, executor driver, partition 8, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.590 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 6.0 in stage 15.0 (TID 222) in 8 ms on 95675304fa2d (executor driver) (7/200)\n",
      "10-20 14:45:00.591 172.17.0.2:54325      7233    (TID 224)  INFO org.apache.spark.executor.Executor: Running task 8.0 in stage 15.0 (TID 224)\n",
      "10-20 14:45:00.592 172.17.0.2:54325      7233    (TID 220)  INFO org.apache.spark.executor.Executor: Finished task 4.0 in stage 15.0 (TID 220). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.593 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 9.0 in stage 15.0 (TID 225) (95675304fa2d, executor driver, partition 9, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.593 172.17.0.2:54325      7233    (TID 225)  INFO org.apache.spark.executor.Executor: Running task 9.0 in stage 15.0 (TID 225)\n",
      "10-20 14:45:00.593 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 4.0 in stage 15.0 (TID 220) in 16 ms on 95675304fa2d (executor driver) (8/200)\n",
      "10-20 14:45:00.592 172.17.0.2:54325      7233    (TID 219)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.594 172.17.0.2:54325      7233    (TID 219)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.593 172.17.0.2:54325      7233    (TID 223)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.594 172.17.0.2:54325      7233    (TID 223)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.595 172.17.0.2:54325      7233    (TID 224)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.595 172.17.0.2:54325      7233    (TID 224)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.597 172.17.0.2:54325      7233    (TID 225)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.597 172.17.0.2:54325      7233    (TID 225)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.598 172.17.0.2:54325      7233    (TID 224)  INFO org.apache.spark.executor.Executor: Finished task 8.0 in stage 15.0 (TID 224). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.599 172.17.0.2:54325      7233    (TID 223)  INFO org.apache.spark.executor.Executor: Finished task 7.0 in stage 15.0 (TID 223). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.599 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 10.0 in stage 15.0 (TID 226) (95675304fa2d, executor driver, partition 10, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.599 172.17.0.2:54325      7233    (TID 226)  INFO org.apache.spark.executor.Executor: Running task 10.0 in stage 15.0 (TID 226)\n",
      "10-20 14:45:00.599 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 11.0 in stage 15.0 (TID 227) (95675304fa2d, executor driver, partition 11, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.599 172.17.0.2:54325      7233    (TID 227)  INFO org.apache.spark.executor.Executor: Running task 11.0 in stage 15.0 (TID 227)\n",
      "10-20 14:45:00.599 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 8.0 in stage 15.0 (TID 224) in 9 ms on 95675304fa2d (executor driver) (9/200)\n",
      "10-20 14:45:00.600 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 7.0 in stage 15.0 (TID 223) in 15 ms on 95675304fa2d (executor driver) (10/200)\n",
      "10-20 14:45:00.602 172.17.0.2:54325      7233    (TID 225)  INFO org.apache.spark.executor.Executor: Finished task 9.0 in stage 15.0 (TID 225). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.602 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 12.0 in stage 15.0 (TID 228) (95675304fa2d, executor driver, partition 12, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.603 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 9.0 in stage 15.0 (TID 225) in 10 ms on 95675304fa2d (executor driver) (11/200)\n",
      "10-20 14:45:00.603 172.17.0.2:54325      7233    (TID 228)  INFO org.apache.spark.executor.Executor: Running task 12.0 in stage 15.0 (TID 228)\n",
      "10-20 14:45:00.604 172.17.0.2:54325      7233    (TID 226)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.604 172.17.0.2:54325      7233    (TID 226)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.605 172.17.0.2:54325      7233    (TID 227)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.605 172.17.0.2:54325      7233    (TID 227)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.606 172.17.0.2:54325      7233    (TID 219)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 15.0 (TID 219). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.607 172.17.0.2:54325      7233    (TID 226)  INFO org.apache.spark.executor.Executor: Finished task 10.0 in stage 15.0 (TID 226). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.607 172.17.0.2:54325      7233    (TID 228)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.608 172.17.0.2:54325      7233    (TID 228)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.607 172.17.0.2:54325      7233    (TID 227)  INFO org.apache.spark.executor.Executor: Finished task 11.0 in stage 15.0 (TID 227). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.608 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 13.0 in stage 15.0 (TID 229) (95675304fa2d, executor driver, partition 13, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.608 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 15.0 (TID 219) in 31 ms on 95675304fa2d (executor driver) (12/200)\n",
      "10-20 14:45:00.608 172.17.0.2:54325      7233    (TID 229)  INFO org.apache.spark.executor.Executor: Running task 13.0 in stage 15.0 (TID 229)\n",
      "10-20 14:45:00.611 172.17.0.2:54325      7233    (TID 228)  INFO org.apache.spark.executor.Executor: Finished task 12.0 in stage 15.0 (TID 228). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.611 172.17.0.2:54325      7233    (TID 229)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.611 172.17.0.2:54325      7233    (TID 229)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.611 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 14.0 in stage 15.0 (TID 230) (95675304fa2d, executor driver, partition 14, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.612 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 15.0 in stage 15.0 (TID 231) (95675304fa2d, executor driver, partition 15, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.612 172.17.0.2:54325      7233    (TID 231)  INFO org.apache.spark.executor.Executor: Running task 15.0 in stage 15.0 (TID 231)\n",
      "10-20 14:45:00.612 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 10.0 in stage 15.0 (TID 226) in 13 ms on 95675304fa2d (executor driver) (13/200)\n",
      "10-20 14:45:00.612 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 12.0 in stage 15.0 (TID 228) in 10 ms on 95675304fa2d (executor driver) (14/200)\n",
      "10-20 14:45:00.612 172.17.0.2:54325      7233    (TID 230)  INFO org.apache.spark.executor.Executor: Running task 14.0 in stage 15.0 (TID 230)\n",
      "10-20 14:45:00.614 172.17.0.2:54325      7233    (TID 229)  INFO org.apache.spark.executor.Executor: Finished task 13.0 in stage 15.0 (TID 229). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.615 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 16.0 in stage 15.0 (TID 232) (95675304fa2d, executor driver, partition 16, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.615 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 17.0 in stage 15.0 (TID 233) (95675304fa2d, executor driver, partition 17, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.615 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 13.0 in stage 15.0 (TID 229) in 7 ms on 95675304fa2d (executor driver) (15/200)\n",
      "10-20 14:45:00.615 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 11.0 in stage 15.0 (TID 227) in 16 ms on 95675304fa2d (executor driver) (16/200)\n",
      "10-20 14:45:00.616 172.17.0.2:54325      7233    (TID 233)  INFO org.apache.spark.executor.Executor: Running task 17.0 in stage 15.0 (TID 233)\n",
      "10-20 14:45:00.617 172.17.0.2:54325      7233    (TID 230)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.617 172.17.0.2:54325      7233    (TID 231)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.617 172.17.0.2:54325      7233    (TID 231)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.617 172.17.0.2:54325      7233    (TID 230)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.618 172.17.0.2:54325      7233    (TID 232)  INFO org.apache.spark.executor.Executor: Running task 16.0 in stage 15.0 (TID 232)\n",
      "10-20 14:45:00.620 172.17.0.2:54325      7233    (TID 231)  INFO org.apache.spark.executor.Executor: Finished task 15.0 in stage 15.0 (TID 231). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.620 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 18.0 in stage 15.0 (TID 234) (95675304fa2d, executor driver, partition 18, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.620 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 15.0 in stage 15.0 (TID 231) in 9 ms on 95675304fa2d (executor driver) (17/200)\n",
      "10-20 14:45:00.618 172.17.0.2:54325      7233    (TID 233)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.620 172.17.0.2:54325      7233    (TID 233)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:45:00.621 172.17.0.2:54325      7233    (TID 234)  INFO org.apache.spark.executor.Executor: Running task 18.0 in stage 15.0 (TID 234)\n",
      "10-20 14:45:00.620 172.17.0.2:54325      7233    (TID 230)  INFO org.apache.spark.executor.Executor: Finished task 14.0 in stage 15.0 (TID 230). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.621 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 19.0 in stage 15.0 (TID 235) (95675304fa2d, executor driver, partition 19, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.621 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 14.0 in stage 15.0 (TID 230) in 10 ms on 95675304fa2d (executor driver) (18/200)\n",
      "10-20 14:45:00.621 172.17.0.2:54325      7233    (TID 235)  INFO org.apache.spark.executor.Executor: Running task 19.0 in stage 15.0 (TID 235)\n",
      "10-20 14:45:00.624 172.17.0.2:54325      7233    (TID 235)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.624 172.17.0.2:54325      7233    (TID 235)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.624 172.17.0.2:54325      7233    (TID 234)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.624 172.17.0.2:54325      7233    (TID 234)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.625 172.17.0.2:54325      7233    (TID 235)  INFO org.apache.spark.executor.Executor: Finished task 19.0 in stage 15.0 (TID 235). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.627 172.17.0.2:54325      7233    (TID 233)  INFO org.apache.spark.executor.Executor: Finished task 17.0 in stage 15.0 (TID 233). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.626 172.17.0.2:54325      7233    (TID 232)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.627 172.17.0.2:54325      7233    (TID 232)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.628 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 20.0 in stage 15.0 (TID 236) (95675304fa2d, executor driver, partition 20, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.628 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 19.0 in stage 15.0 (TID 235) in 7 ms on 95675304fa2d (executor driver) (19/200)\n",
      "10-20 14:45:00.629 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 21.0 in stage 15.0 (TID 237) (95675304fa2d, executor driver, partition 21, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.626 172.17.0.2:54325      7233    (TID 234)  INFO org.apache.spark.executor.Executor: Finished task 18.0 in stage 15.0 (TID 234). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.629 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 17.0 in stage 15.0 (TID 233) in 14 ms on 95675304fa2d (executor driver) (20/200)\n",
      "10-20 14:45:00.630 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 22.0 in stage 15.0 (TID 238) (95675304fa2d, executor driver, partition 22, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.630 172.17.0.2:54325      7233    (TID 238)  INFO org.apache.spark.executor.Executor: Running task 22.0 in stage 15.0 (TID 238)\n",
      "10-20 14:45:00.630 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 18.0 in stage 15.0 (TID 234) in 10 ms on 95675304fa2d (executor driver) (21/200)\n",
      "10-20 14:45:00.630 172.17.0.2:54325      7233    (TID 236)  INFO org.apache.spark.executor.Executor: Running task 20.0 in stage 15.0 (TID 236)\n",
      "10-20 14:45:00.630 172.17.0.2:54325      7233    (TID 237)  INFO org.apache.spark.executor.Executor: Running task 21.0 in stage 15.0 (TID 237)\n",
      "10-20 14:45:00.632 172.17.0.2:54325      7233    (TID 232)  INFO org.apache.spark.executor.Executor: Finished task 16.0 in stage 15.0 (TID 232). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.632 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 23.0 in stage 15.0 (TID 239) (95675304fa2d, executor driver, partition 23, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.633 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 16.0 in stage 15.0 (TID 232) in 19 ms on 95675304fa2d (executor driver) (22/200)\n",
      "10-20 14:45:00.633 172.17.0.2:54325      7233    (TID 239)  INFO org.apache.spark.executor.Executor: Running task 23.0 in stage 15.0 (TID 239)\n",
      "10-20 14:45:00.634 172.17.0.2:54325      7233    (TID 237)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.634 172.17.0.2:54325      7233    (TID 237)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.636 172.17.0.2:54325      7233    (TID 236)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.636 172.17.0.2:54325      7233    (TID 236)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.636 172.17.0.2:54325      7233    (TID 237)  INFO org.apache.spark.executor.Executor: Finished task 21.0 in stage 15.0 (TID 237). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.637 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 24.0 in stage 15.0 (TID 240) (95675304fa2d, executor driver, partition 24, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.637 172.17.0.2:54325      7233    (TID 238)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.637 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 21.0 in stage 15.0 (TID 237) in 8 ms on 95675304fa2d (executor driver) (23/200)\n",
      "10-20 14:45:00.638 172.17.0.2:54325      7233    (TID 238)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.638 172.17.0.2:54325      7233    (TID 240)  INFO org.apache.spark.executor.Executor: Running task 24.0 in stage 15.0 (TID 240)\n",
      "10-20 14:45:00.639 172.17.0.2:54325      7233    (TID 239)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.639 172.17.0.2:54325      7233    (TID 239)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.641 172.17.0.2:54325      7233    (TID 240)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.641 172.17.0.2:54325      7233    (TID 240)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.642 172.17.0.2:54325      7233    (TID 238)  INFO org.apache.spark.executor.Executor: Finished task 22.0 in stage 15.0 (TID 238). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.642 172.17.0.2:54325      7233    (TID 236)  INFO org.apache.spark.executor.Executor: Finished task 20.0 in stage 15.0 (TID 236). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.643 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 25.0 in stage 15.0 (TID 241) (95675304fa2d, executor driver, partition 25, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.643 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 26.0 in stage 15.0 (TID 242) (95675304fa2d, executor driver, partition 26, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.643 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 22.0 in stage 15.0 (TID 238) in 13 ms on 95675304fa2d (executor driver) (24/200)\n",
      "10-20 14:45:00.644 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 20.0 in stage 15.0 (TID 236) in 15 ms on 95675304fa2d (executor driver) (25/200)\n",
      "10-20 14:45:00.645 172.17.0.2:54325      7233    (TID 239)  INFO org.apache.spark.executor.Executor: Finished task 23.0 in stage 15.0 (TID 239). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.645 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 27.0 in stage 15.0 (TID 243) (95675304fa2d, executor driver, partition 27, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.646 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 23.0 in stage 15.0 (TID 239) in 14 ms on 95675304fa2d (executor driver) (26/200)\n",
      "10-20 14:45:00.646 172.17.0.2:54325      7233    (TID 243)  INFO org.apache.spark.executor.Executor: Running task 27.0 in stage 15.0 (TID 243)\n",
      "10-20 14:45:00.647 172.17.0.2:54325      7233    (TID 240)  INFO org.apache.spark.executor.Executor: Finished task 24.0 in stage 15.0 (TID 240). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.647 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 28.0 in stage 15.0 (TID 244) (95675304fa2d, executor driver, partition 28, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.647 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 24.0 in stage 15.0 (TID 240) in 10 ms on 95675304fa2d (executor driver) (27/200)\n",
      "10-20 14:45:00.648 172.17.0.2:54325      7233    (TID 244)  INFO org.apache.spark.executor.Executor: Running task 28.0 in stage 15.0 (TID 244)\n",
      "10-20 14:45:00.648 172.17.0.2:54325      7233    (TID 242)  INFO org.apache.spark.executor.Executor: Running task 26.0 in stage 15.0 (TID 242)\n",
      "10-20 14:45:00.648 172.17.0.2:54325      7233    (TID 241)  INFO org.apache.spark.executor.Executor: Running task 25.0 in stage 15.0 (TID 241)\n",
      "10-20 14:45:00.650 172.17.0.2:54325      7233    (TID 243)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.652 172.17.0.2:54325      7233    (TID 243)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.653 172.17.0.2:54325      7233    (TID 241)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.654 172.17.0.2:54325      7233    (TID 241)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.656 172.17.0.2:54325      7233    (TID 243)  INFO org.apache.spark.executor.Executor: Finished task 27.0 in stage 15.0 (TID 243). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.656 172.17.0.2:54325      7233    (TID 241)  INFO org.apache.spark.executor.Executor: Finished task 25.0 in stage 15.0 (TID 241). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.656 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 29.0 in stage 15.0 (TID 245) (95675304fa2d, executor driver, partition 29, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.657 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 27.0 in stage 15.0 (TID 243) in 12 ms on 95675304fa2d (executor driver) (28/200)\n",
      "10-20 14:45:00.658 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 30.0 in stage 15.0 (TID 246) (95675304fa2d, executor driver, partition 30, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.658 172.17.0.2:54325      7233    (TID 246)  INFO org.apache.spark.executor.Executor: Running task 30.0 in stage 15.0 (TID 246)\n",
      "10-20 14:45:00.661 172.17.0.2:54325      7233    (TID 246)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.661 172.17.0.2:54325      7233    (TID 246)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.663 172.17.0.2:54325      7233    (TID 246)  INFO org.apache.spark.executor.Executor: Finished task 30.0 in stage 15.0 (TID 246). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.650 172.17.0.2:54325      7233    (TID 244)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.658 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 25.0 in stage 15.0 (TID 241) in 16 ms on 95675304fa2d (executor driver) (29/200)\n",
      "10-20 14:45:00.665 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 31.0 in stage 15.0 (TID 247) (95675304fa2d, executor driver, partition 31, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.665 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 30.0 in stage 15.0 (TID 246) in 7 ms on 95675304fa2d (executor driver) (30/200)\n",
      "10-20 14:45:00.665 172.17.0.2:54325      7233    (TID 247)  INFO org.apache.spark.executor.Executor: Running task 31.0 in stage 15.0 (TID 247)\n",
      "10-20 14:45:00.665 172.17.0.2:54325      7233    (TID 244)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms\n",
      "10-20 14:45:00.657 172.17.0.2:54325      7233    (TID 245)  INFO org.apache.spark.executor.Executor: Running task 29.0 in stage 15.0 (TID 245)\n",
      "10-20 14:45:00.654 172.17.0.2:54325      7233    (TID 242)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.666 172.17.0.2:54325      7233    (TID 242)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms\n",
      "10-20 14:45:00.668 172.17.0.2:54325      7233    (TID 244)  INFO org.apache.spark.executor.Executor: Finished task 28.0 in stage 15.0 (TID 244). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.668 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 32.0 in stage 15.0 (TID 248) (95675304fa2d, executor driver, partition 32, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.669 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 28.0 in stage 15.0 (TID 244) in 22 ms on 95675304fa2d (executor driver) (31/200)\n",
      "10-20 14:45:00.669 172.17.0.2:54325      7233    (TID 248)  INFO org.apache.spark.executor.Executor: Running task 32.0 in stage 15.0 (TID 248)\n",
      "10-20 14:45:00.670 172.17.0.2:54325      7233    (TID 242)  INFO org.apache.spark.executor.Executor: Finished task 26.0 in stage 15.0 (TID 242). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.670 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 33.0 in stage 15.0 (TID 249) (95675304fa2d, executor driver, partition 33, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.670 172.17.0.2:54325      7233    (TID 249)  INFO org.apache.spark.executor.Executor: Running task 33.0 in stage 15.0 (TID 249)\n",
      "10-20 14:45:00.670 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 26.0 in stage 15.0 (TID 242) in 27 ms on 95675304fa2d (executor driver) (32/200)\n",
      "10-20 14:45:00.672 172.17.0.2:54325      7233    (TID 247)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.672 172.17.0.2:54325      7233    (TID 247)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.673 172.17.0.2:54325      7233    (TID 248)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.674 172.17.0.2:54325      7233    (TID 248)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.675 172.17.0.2:54325      7233    (TID 247)  INFO org.apache.spark.executor.Executor: Finished task 31.0 in stage 15.0 (TID 247). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.675 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 34.0 in stage 15.0 (TID 250) (95675304fa2d, executor driver, partition 34, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.676 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 31.0 in stage 15.0 (TID 247) in 10 ms on 95675304fa2d (executor driver) (33/200)\n",
      "10-20 14:45:00.676 172.17.0.2:54325      7233    (TID 250)  INFO org.apache.spark.executor.Executor: Running task 34.0 in stage 15.0 (TID 250)\n",
      "10-20 14:45:00.677 172.17.0.2:54325      7233    (TID 245)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.677 172.17.0.2:54325      7233    (TID 245)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.677 172.17.0.2:54325      7233    (TID 249)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.677 172.17.0.2:54325      7233    (TID 249)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.679 172.17.0.2:54325      7233    (TID 250)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.679 172.17.0.2:54325      7233    (TID 250)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.680 172.17.0.2:54325      7233    (TID 248)  INFO org.apache.spark.executor.Executor: Finished task 32.0 in stage 15.0 (TID 248). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.680 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 35.0 in stage 15.0 (TID 251) (95675304fa2d, executor driver, partition 35, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.681 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 32.0 in stage 15.0 (TID 248) in 13 ms on 95675304fa2d (executor driver) (34/200)\n",
      "10-20 14:45:00.681 172.17.0.2:54325      7233    (TID 251)  INFO org.apache.spark.executor.Executor: Running task 35.0 in stage 15.0 (TID 251)\n",
      "10-20 14:45:00.682 172.17.0.2:54325      7233    (TID 250)  INFO org.apache.spark.executor.Executor: Finished task 34.0 in stage 15.0 (TID 250). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.683 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 36.0 in stage 15.0 (TID 252) (95675304fa2d, executor driver, partition 36, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.683 172.17.0.2:54325      7233    (TID 252)  INFO org.apache.spark.executor.Executor: Running task 36.0 in stage 15.0 (TID 252)\n",
      "10-20 14:45:00.683 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 34.0 in stage 15.0 (TID 250) in 8 ms on 95675304fa2d (executor driver) (35/200)\n",
      "10-20 14:45:00.684 172.17.0.2:54325      7233    (TID 245)  INFO org.apache.spark.executor.Executor: Finished task 29.0 in stage 15.0 (TID 245). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.684 172.17.0.2:54325      7233    (TID 249)  INFO org.apache.spark.executor.Executor: Finished task 33.0 in stage 15.0 (TID 249). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.685 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 37.0 in stage 15.0 (TID 253) (95675304fa2d, executor driver, partition 37, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.685 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 38.0 in stage 15.0 (TID 254) (95675304fa2d, executor driver, partition 38, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.686 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 33.0 in stage 15.0 (TID 249) in 16 ms on 95675304fa2d (executor driver) (36/200)\n",
      "10-20 14:45:00.686 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 29.0 in stage 15.0 (TID 245) in 30 ms on 95675304fa2d (executor driver) (37/200)\n",
      "10-20 14:45:00.687 172.17.0.2:54325      7233    (TID 254)  INFO org.apache.spark.executor.Executor: Running task 38.0 in stage 15.0 (TID 254)\n",
      "10-20 14:45:00.688 172.17.0.2:54325      7233    (TID 251)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.689 172.17.0.2:54325      7233    (TID 251)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.688 172.17.0.2:54325      7233    (TID 252)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.689 172.17.0.2:54325      7233    (TID 252)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.688 172.17.0.2:54325      7233    (TID 253)  INFO org.apache.spark.executor.Executor: Running task 37.0 in stage 15.0 (TID 253)\n",
      "10-20 14:45:00.691 172.17.0.2:54325      7233    (TID 252)  INFO org.apache.spark.executor.Executor: Finished task 36.0 in stage 15.0 (TID 252). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.692 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 39.0 in stage 15.0 (TID 255) (95675304fa2d, executor driver, partition 39, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.692 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 36.0 in stage 15.0 (TID 252) in 9 ms on 95675304fa2d (executor driver) (38/200)\n",
      "10-20 14:45:00.692 172.17.0.2:54325      7233    (TID 255)  INFO org.apache.spark.executor.Executor: Running task 39.0 in stage 15.0 (TID 255)\n",
      "10-20 14:45:00.693 172.17.0.2:54325      7233    (TID 251)  INFO org.apache.spark.executor.Executor: Finished task 35.0 in stage 15.0 (TID 251). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.694 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 40.0 in stage 15.0 (TID 256) (95675304fa2d, executor driver, partition 40, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.694 172.17.0.2:54325      7233    (TID 256)  INFO org.apache.spark.executor.Executor: Running task 40.0 in stage 15.0 (TID 256)\n",
      "10-20 14:45:00.694 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 35.0 in stage 15.0 (TID 251) in 14 ms on 95675304fa2d (executor driver) (39/200)\n",
      "10-20 14:45:00.695 172.17.0.2:54325      7233    (TID 255)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.695 172.17.0.2:54325      7233    (TID 255)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.696 172.17.0.2:54325      7233    (TID 254)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.696 172.17.0.2:54325      7233    (TID 254)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.696 172.17.0.2:54325      7233    (TID 256)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.696 172.17.0.2:54325      7233    (TID 256)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.696 172.17.0.2:54325      7233    (TID 255)  INFO org.apache.spark.executor.Executor: Finished task 39.0 in stage 15.0 (TID 255). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.697 172.17.0.2:54325      7233    (TID 253)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.697 172.17.0.2:54325      7233    (TID 253)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.697 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 41.0 in stage 15.0 (TID 257) (95675304fa2d, executor driver, partition 41, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.697 172.17.0.2:54325      7233    (TID 257)  INFO org.apache.spark.executor.Executor: Running task 41.0 in stage 15.0 (TID 257)\n",
      "10-20 14:45:00.698 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 39.0 in stage 15.0 (TID 255) in 6 ms on 95675304fa2d (executor driver) (40/200)\n",
      "10-20 14:45:00.699 172.17.0.2:54325      7233    (TID 256)  INFO org.apache.spark.executor.Executor: Finished task 40.0 in stage 15.0 (TID 256). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.699 172.17.0.2:54325      7233    (TID 254)  INFO org.apache.spark.executor.Executor: Finished task 38.0 in stage 15.0 (TID 254). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.699 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 42.0 in stage 15.0 (TID 258) (95675304fa2d, executor driver, partition 42, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.700 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 40.0 in stage 15.0 (TID 256) in 6 ms on 95675304fa2d (executor driver) (41/200)\n",
      "10-20 14:45:00.700 172.17.0.2:54325      7233    (TID 258)  INFO org.apache.spark.executor.Executor: Running task 42.0 in stage 15.0 (TID 258)\n",
      "10-20 14:45:00.701 172.17.0.2:54325      7233    (TID 257)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.701 172.17.0.2:54325      7233    (TID 257)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.702 172.17.0.2:54325      7233    (TID 253)  INFO org.apache.spark.executor.Executor: Finished task 37.0 in stage 15.0 (TID 253). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.703 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 44.0 in stage 15.0 (TID 259) (95675304fa2d, executor driver, partition 44, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.703 172.17.0.2:54325      7233    (TID 257)  INFO org.apache.spark.executor.Executor: Finished task 41.0 in stage 15.0 (TID 257). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.703 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 45.0 in stage 15.0 (TID 260) (95675304fa2d, executor driver, partition 45, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.704 172.17.0.2:54325      7233    (TID 260)  INFO org.apache.spark.executor.Executor: Running task 45.0 in stage 15.0 (TID 260)\n",
      "10-20 14:45:00.703 172.17.0.2:54325      7233    (TID 259)  INFO org.apache.spark.executor.Executor: Running task 44.0 in stage 15.0 (TID 259)\n",
      "10-20 14:45:00.704 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 46.0 in stage 15.0 (TID 261) (95675304fa2d, executor driver, partition 46, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.705 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 38.0 in stage 15.0 (TID 254) in 20 ms on 95675304fa2d (executor driver) (42/200)\n",
      "10-20 14:45:00.705 172.17.0.2:54325      7233    (TID 261)  INFO org.apache.spark.executor.Executor: Running task 46.0 in stage 15.0 (TID 261)\n",
      "10-20 14:45:00.705 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 41.0 in stage 15.0 (TID 257) in 8 ms on 95675304fa2d (executor driver) (43/200)\n",
      "10-20 14:45:00.705 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 37.0 in stage 15.0 (TID 253) in 20 ms on 95675304fa2d (executor driver) (44/200)\n",
      "10-20 14:45:00.707 172.17.0.2:54325      7233    (TID 258)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.707 172.17.0.2:54325      7233    (TID 258)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.709 172.17.0.2:54325      7233    (TID 258)  INFO org.apache.spark.executor.Executor: Finished task 42.0 in stage 15.0 (TID 258). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.710 172.17.0.2:54325      7233    (TID 260)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.710 172.17.0.2:54325      7233    (TID 260)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.710 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 47.0 in stage 15.0 (TID 262) (95675304fa2d, executor driver, partition 47, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.711 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 42.0 in stage 15.0 (TID 258) in 12 ms on 95675304fa2d (executor driver) (45/200)\n",
      "10-20 14:45:00.711 172.17.0.2:54325      7233    (TID 262)  INFO org.apache.spark.executor.Executor: Running task 47.0 in stage 15.0 (TID 262)\n",
      "10-20 14:45:00.712 172.17.0.2:54325      7233    (TID 260)  INFO org.apache.spark.executor.Executor: Finished task 45.0 in stage 15.0 (TID 260). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.713 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 48.0 in stage 15.0 (TID 263) (95675304fa2d, executor driver, partition 48, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.714 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 45.0 in stage 15.0 (TID 260) in 11 ms on 95675304fa2d (executor driver) (46/200)\n",
      "10-20 14:45:00.714 172.17.0.2:54325      7233    (TID 263)  INFO org.apache.spark.executor.Executor: Running task 48.0 in stage 15.0 (TID 263)\n",
      "10-20 14:45:00.715 172.17.0.2:54325      7233    (TID 262)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.715 172.17.0.2:54325      7233    (TID 262)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.717 172.17.0.2:54325      7233    (TID 259)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.717 172.17.0.2:54325      7233    (TID 259)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.718 172.17.0.2:54325      7233    (TID 261)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.718 172.17.0.2:54325      7233    (TID 261)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:45:00.719 172.17.0.2:54325      7233    (TID 262)  INFO org.apache.spark.executor.Executor: Finished task 47.0 in stage 15.0 (TID 262). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.720 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 49.0 in stage 15.0 (TID 264) (95675304fa2d, executor driver, partition 49, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.720 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 47.0 in stage 15.0 (TID 262) in 10 ms on 95675304fa2d (executor driver) (47/200)\n",
      "10-20 14:45:00.721 172.17.0.2:54325      7233    (TID 263)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.721 172.17.0.2:54325      7233    (TID 263)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.721 172.17.0.2:54325      7233    (TID 264)  INFO org.apache.spark.executor.Executor: Running task 49.0 in stage 15.0 (TID 264)\n",
      "10-20 14:45:00.726 172.17.0.2:54325      7233    (TID 261)  INFO org.apache.spark.executor.Executor: Finished task 46.0 in stage 15.0 (TID 261). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.726 172.17.0.2:54325      7233    (TID 263)  INFO org.apache.spark.executor.Executor: Finished task 48.0 in stage 15.0 (TID 263). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.727 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 50.0 in stage 15.0 (TID 265) (95675304fa2d, executor driver, partition 50, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.727 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 51.0 in stage 15.0 (TID 266) (95675304fa2d, executor driver, partition 51, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.728 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 48.0 in stage 15.0 (TID 263) in 15 ms on 95675304fa2d (executor driver) (48/200)\n",
      "10-20 14:45:00.728 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 46.0 in stage 15.0 (TID 261) in 24 ms on 95675304fa2d (executor driver) (49/200)\n",
      "10-20 14:45:00.728 172.17.0.2:54325      7233    (TID 265)  INFO org.apache.spark.executor.Executor: Running task 50.0 in stage 15.0 (TID 265)\n",
      "10-20 14:45:00.729 172.17.0.2:54325      7233    (TID 259)  INFO org.apache.spark.executor.Executor: Finished task 44.0 in stage 15.0 (TID 259). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.730 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 52.0 in stage 15.0 (TID 267) (95675304fa2d, executor driver, partition 52, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.731 172.17.0.2:54325      7233    (TID 267)  INFO org.apache.spark.executor.Executor: Running task 52.0 in stage 15.0 (TID 267)\n",
      "10-20 14:45:00.731 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 44.0 in stage 15.0 (TID 259) in 29 ms on 95675304fa2d (executor driver) (50/200)\n",
      "10-20 14:45:00.732 172.17.0.2:54325      7233    (TID 266)  INFO org.apache.spark.executor.Executor: Running task 51.0 in stage 15.0 (TID 266)\n",
      "10-20 14:45:00.734 172.17.0.2:54325      7233    (TID 264)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.737 172.17.0.2:54325      7233    (TID 266)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.737 172.17.0.2:54325      7233    (TID 266)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.737 172.17.0.2:54325      7233    (TID 264)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:45:00.737 172.17.0.2:54325      7233    (TID 265)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.739 172.17.0.2:54325      7233    (TID 265)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.740 172.17.0.2:54325      7233    (TID 266)  INFO org.apache.spark.executor.Executor: Finished task 51.0 in stage 15.0 (TID 266). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.741 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 53.0 in stage 15.0 (TID 268) (95675304fa2d, executor driver, partition 53, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.742 172.17.0.2:54325      7233    (TID 268)  INFO org.apache.spark.executor.Executor: Running task 53.0 in stage 15.0 (TID 268)\n",
      "10-20 14:45:00.742 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 51.0 in stage 15.0 (TID 266) in 15 ms on 95675304fa2d (executor driver) (51/200)\n",
      "10-20 14:45:00.737 172.17.0.2:54325      7233    (TID 267)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.742 172.17.0.2:54325      7233    (TID 267)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:00.746 172.17.0.2:54325      7233    (TID 268)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.746 172.17.0.2:54325      7233    (TID 268)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.748 172.17.0.2:54325      7233    (TID 268)  INFO org.apache.spark.executor.Executor: Finished task 53.0 in stage 15.0 (TID 268). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.748 172.17.0.2:54325      7233    (TID 264)  INFO org.apache.spark.executor.Executor: Finished task 49.0 in stage 15.0 (TID 264). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.740 172.17.0.2:54325      7233    (TID 265)  INFO org.apache.spark.executor.Executor: Finished task 50.0 in stage 15.0 (TID 265). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.748 172.17.0.2:54325      7233    (TID 267)  INFO org.apache.spark.executor.Executor: Finished task 52.0 in stage 15.0 (TID 267). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.748 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 54.0 in stage 15.0 (TID 269) (95675304fa2d, executor driver, partition 54, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.748 172.17.0.2:54325      7233    (TID 269)  INFO org.apache.spark.executor.Executor: Running task 54.0 in stage 15.0 (TID 269)\n",
      "10-20 14:45:00.748 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 55.0 in stage 15.0 (TID 270) (95675304fa2d, executor driver, partition 55, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.749 172.17.0.2:54325      7233    (TID 270)  INFO org.apache.spark.executor.Executor: Running task 55.0 in stage 15.0 (TID 270)\n",
      "10-20 14:45:00.750 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 56.0 in stage 15.0 (TID 271) (95675304fa2d, executor driver, partition 56, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.750 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 50.0 in stage 15.0 (TID 265) in 23 ms on 95675304fa2d (executor driver) (52/200)\n",
      "10-20 14:45:00.750 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 52.0 in stage 15.0 (TID 267) in 21 ms on 95675304fa2d (executor driver) (53/200)\n",
      "10-20 14:45:00.750 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 49.0 in stage 15.0 (TID 264) in 30 ms on 95675304fa2d (executor driver) (54/200)\n",
      "10-20 14:45:00.751 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 53.0 in stage 15.0 (TID 268) in 10 ms on 95675304fa2d (executor driver) (55/200)\n",
      "10-20 14:45:00.751 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 57.0 in stage 15.0 (TID 272) (95675304fa2d, executor driver, partition 57, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.751 172.17.0.2:54325      7233    (TID 271)  INFO org.apache.spark.executor.Executor: Running task 56.0 in stage 15.0 (TID 271)\n",
      "10-20 14:45:00.753 172.17.0.2:54325      7233    (TID 272)  INFO org.apache.spark.executor.Executor: Running task 57.0 in stage 15.0 (TID 272)\n",
      "10-20 14:45:00.754 172.17.0.2:54325      7233    (TID 271)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.754 172.17.0.2:54325      7233    (TID 271)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.755 172.17.0.2:54325      7233    (TID 272)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.755 172.17.0.2:54325      7233    (TID 272)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.756 172.17.0.2:54325      7233    (TID 270)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.756 172.17.0.2:54325      7233    (TID 270)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.757 172.17.0.2:54325      7233    (TID 269)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.757 172.17.0.2:54325      7233    (TID 269)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.758 172.17.0.2:54325      7233    (TID 271)  INFO org.apache.spark.executor.Executor: Finished task 56.0 in stage 15.0 (TID 271). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.758 172.17.0.2:54325      7233    (TID 269)  INFO org.apache.spark.executor.Executor: Finished task 54.0 in stage 15.0 (TID 269). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.758 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 58.0 in stage 15.0 (TID 273) (95675304fa2d, executor driver, partition 58, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.759 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 56.0 in stage 15.0 (TID 271) in 10 ms on 95675304fa2d (executor driver) (56/200)\n",
      "10-20 14:45:00.760 172.17.0.2:54325      7233    (TID 273)  INFO org.apache.spark.executor.Executor: Running task 58.0 in stage 15.0 (TID 273)\n",
      "10-20 14:45:00.761 172.17.0.2:54325      7233    (TID 270)  INFO org.apache.spark.executor.Executor: Finished task 55.0 in stage 15.0 (TID 270). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.761 172.17.0.2:54325      7233    (TID 272)  INFO org.apache.spark.executor.Executor: Finished task 57.0 in stage 15.0 (TID 272). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.780 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 59.0 in stage 15.0 (TID 274) (95675304fa2d, executor driver, partition 59, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.781 172.17.0.2:54325      7233    (TID 274)  INFO org.apache.spark.executor.Executor: Running task 59.0 in stage 15.0 (TID 274)\n",
      "10-20 14:45:00.781 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 54.0 in stage 15.0 (TID 269) in 33 ms on 95675304fa2d (executor driver) (57/200)\n",
      "10-20 14:45:00.782 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 55.0 in stage 15.0 (TID 270) in 34 ms on 95675304fa2d (executor driver) (58/200)\n",
      "10-20 14:45:00.784 172.17.0.2:54325      7233    (TID 273)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.784 172.17.0.2:54325      7233    (TID 273)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.786 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 60.0 in stage 15.0 (TID 275) (95675304fa2d, executor driver, partition 60, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.786 172.17.0.2:54325      7233    (TID 275)  INFO org.apache.spark.executor.Executor: Running task 60.0 in stage 15.0 (TID 275)\n",
      "10-20 14:45:00.786 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 61.0 in stage 15.0 (TID 276) (95675304fa2d, executor driver, partition 61, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.786 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 57.0 in stage 15.0 (TID 272) in 35 ms on 95675304fa2d (executor driver) (59/200)\n",
      "10-20 14:45:00.788 172.17.0.2:54325      7233    (TID 276)  INFO org.apache.spark.executor.Executor: Running task 61.0 in stage 15.0 (TID 276)\n",
      "10-20 14:45:00.788 172.17.0.2:54325      7233    (TID 274)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.788 172.17.0.2:54325      7233    (TID 274)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.789 172.17.0.2:54325      7233    (TID 273)  INFO org.apache.spark.executor.Executor: Finished task 58.0 in stage 15.0 (TID 273). 3875 bytes result sent to driver\n",
      "10-20 14:45:00.790 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 62.0 in stage 15.0 (TID 277) (95675304fa2d, executor driver, partition 62, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.790 172.17.0.2:54325      7233    (TID 277)  INFO org.apache.spark.executor.Executor: Running task 62.0 in stage 15.0 (TID 277)\n",
      "10-20 14:45:00.790 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 58.0 in stage 15.0 (TID 273) in 32 ms on 95675304fa2d (executor driver) (60/200)\n",
      "10-20 14:45:00.792 172.17.0.2:54325      7233    (TID 274)  INFO org.apache.spark.executor.Executor: Finished task 59.0 in stage 15.0 (TID 274). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.794 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 63.0 in stage 15.0 (TID 278) (95675304fa2d, executor driver, partition 63, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.794 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 59.0 in stage 15.0 (TID 274) in 25 ms on 95675304fa2d (executor driver) (61/200)\n",
      "10-20 14:45:00.794 172.17.0.2:54325      7233    (TID 278)  INFO org.apache.spark.executor.Executor: Running task 63.0 in stage 15.0 (TID 278)\n",
      "10-20 14:45:00.794 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on 95675304fa2d:39429 in memory (size: 18.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:00.797 172.17.0.2:54325      7233    (TID 276)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.797 172.17.0.2:54325      7233    (TID 277)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.798 172.17.0.2:54325      7233    (TID 277)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.798 172.17.0.2:54325      7233    (TID 275)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.798 172.17.0.2:54325      7233    (TID 275)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.798 172.17.0.2:54325      7233    (TID 276)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.799 172.17.0.2:54325      7233    (TID 277)  INFO org.apache.spark.executor.Executor: Finished task 62.0 in stage 15.0 (TID 277). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.800 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 64.0 in stage 15.0 (TID 279) (95675304fa2d, executor driver, partition 64, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.801 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 62.0 in stage 15.0 (TID 277) in 11 ms on 95675304fa2d (executor driver) (62/200)\n",
      "10-20 14:45:00.802 172.17.0.2:54325      7233    (TID 279)  INFO org.apache.spark.executor.Executor: Running task 64.0 in stage 15.0 (TID 279)\n",
      "10-20 14:45:00.803 172.17.0.2:54325      7233    (TID 276)  INFO org.apache.spark.executor.Executor: Finished task 61.0 in stage 15.0 (TID 276). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.809 172.17.0.2:54325      7233    (TID 278)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.806 172.17.0.2:54325      7233    (TID 279)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.813 172.17.0.2:54325      7233    (TID 279)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 14:45:00.813 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 65.0 in stage 15.0 (TID 280) (95675304fa2d, executor driver, partition 65, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.813 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 61.0 in stage 15.0 (TID 276) in 27 ms on 95675304fa2d (executor driver) (63/200)\n",
      "10-20 14:45:00.814 172.17.0.2:54325      7233    (TID 280)  INFO org.apache.spark.executor.Executor: Running task 65.0 in stage 15.0 (TID 280)\n",
      "10-20 14:45:00.814 172.17.0.2:54325      7233    (TID 275)  INFO org.apache.spark.executor.Executor: Finished task 60.0 in stage 15.0 (TID 275). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.815 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 66.0 in stage 15.0 (TID 281) (95675304fa2d, executor driver, partition 66, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.815 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 60.0 in stage 15.0 (TID 275) in 30 ms on 95675304fa2d (executor driver) (64/200)\n",
      "10-20 14:45:00.818 172.17.0.2:54325      7233    (TID 280)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.818 172.17.0.2:54325      7233    (TID 281)  INFO org.apache.spark.executor.Executor: Running task 66.0 in stage 15.0 (TID 281)\n",
      "10-20 14:45:00.818 172.17.0.2:54325      7233    (TID 280)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.820 172.17.0.2:54325      7233    (TID 280)  INFO org.apache.spark.executor.Executor: Finished task 65.0 in stage 15.0 (TID 280). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.821 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 67.0 in stage 15.0 (TID 282) (95675304fa2d, executor driver, partition 67, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.821 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 65.0 in stage 15.0 (TID 280) in 8 ms on 95675304fa2d (executor driver) (65/200)\n",
      "10-20 14:45:00.822 172.17.0.2:54325      7233    (TID 282)  INFO org.apache.spark.executor.Executor: Running task 67.0 in stage 15.0 (TID 282)\n",
      "10-20 14:45:00.822 172.17.0.2:54325      7233    (TID 279)  INFO org.apache.spark.executor.Executor: Finished task 64.0 in stage 15.0 (TID 279). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.823 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 68.0 in stage 15.0 (TID 283) (95675304fa2d, executor driver, partition 68, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.823 172.17.0.2:54325      7233    (TID 283)  INFO org.apache.spark.executor.Executor: Running task 68.0 in stage 15.0 (TID 283)\n",
      "10-20 14:45:00.823 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 64.0 in stage 15.0 (TID 279) in 23 ms on 95675304fa2d (executor driver) (66/200)\n",
      "10-20 14:45:00.825 172.17.0.2:54325      7233    (TID 281)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.825 172.17.0.2:54325      7233    (TID 281)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.826 172.17.0.2:54325      7233    (TID 283)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.827 172.17.0.2:54325      7233    (TID 283)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.825 172.17.0.2:54325      7233    (TID 278)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms\n",
      "10-20 14:45:00.829 172.17.0.2:54325      7233    (TID 282)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.830 172.17.0.2:54325      7233    (TID 282)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.830 172.17.0.2:54325      7233    (TID 283)  INFO org.apache.spark.executor.Executor: Finished task 68.0 in stage 15.0 (TID 283). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.831 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 69.0 in stage 15.0 (TID 284) (95675304fa2d, executor driver, partition 69, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.831 172.17.0.2:54325      7233    (TID 284)  INFO org.apache.spark.executor.Executor: Running task 69.0 in stage 15.0 (TID 284)\n",
      "10-20 14:45:00.832 172.17.0.2:54325      7233    (TID 282)  INFO org.apache.spark.executor.Executor: Finished task 67.0 in stage 15.0 (TID 282). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.829 172.17.0.2:54325      7233    (TID 281)  INFO org.apache.spark.executor.Executor: Finished task 66.0 in stage 15.0 (TID 281). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.835 172.17.0.2:54325      7233    (TID 278)  INFO org.apache.spark.executor.Executor: Finished task 63.0 in stage 15.0 (TID 278). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.834 172.17.0.2:54325      7233    (TID 284)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.831 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 68.0 in stage 15.0 (TID 283) in 8 ms on 95675304fa2d (executor driver) (67/200)\n",
      "10-20 14:45:00.837 172.17.0.2:54325      7233    (TID 284)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:45:00.838 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 70.0 in stage 15.0 (TID 285) (95675304fa2d, executor driver, partition 70, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.838 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 71.0 in stage 15.0 (TID 286) (95675304fa2d, executor driver, partition 71, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.839 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 63.0 in stage 15.0 (TID 278) in 46 ms on 95675304fa2d (executor driver) (68/200)\n",
      "10-20 14:45:00.839 172.17.0.2:54325      7233    (TID 285)  INFO org.apache.spark.executor.Executor: Running task 70.0 in stage 15.0 (TID 285)\n",
      "10-20 14:45:00.841 172.17.0.2:54325      7233    (TID 285)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.841 172.17.0.2:54325      7233    (TID 285)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.842 172.17.0.2:54325      7233    (TID 284)  INFO org.apache.spark.executor.Executor: Finished task 69.0 in stage 15.0 (TID 284). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.842 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 66.0 in stage 15.0 (TID 281) in 27 ms on 95675304fa2d (executor driver) (69/200)\n",
      "10-20 14:45:00.843 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 72.0 in stage 15.0 (TID 287) (95675304fa2d, executor driver, partition 72, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.844 172.17.0.2:54325      7233    (TID 285)  INFO org.apache.spark.executor.Executor: Finished task 70.0 in stage 15.0 (TID 285). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.844 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 73.0 in stage 15.0 (TID 288) (95675304fa2d, executor driver, partition 73, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.844 172.17.0.2:54325      7233    (TID 287)  INFO org.apache.spark.executor.Executor: Running task 72.0 in stage 15.0 (TID 287)\n",
      "10-20 14:45:00.845 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 74.0 in stage 15.0 (TID 289) (95675304fa2d, executor driver, partition 74, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.845 172.17.0.2:54325      7233    (TID 286)  INFO org.apache.spark.executor.Executor: Running task 71.0 in stage 15.0 (TID 286)\n",
      "10-20 14:45:00.845 172.17.0.2:54325      7233    (TID 289)  INFO org.apache.spark.executor.Executor: Running task 74.0 in stage 15.0 (TID 289)\n",
      "10-20 14:45:00.845 172.17.0.2:54325      7233    (TID 288)  INFO org.apache.spark.executor.Executor: Running task 73.0 in stage 15.0 (TID 288)\n",
      "10-20 14:45:00.845 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 69.0 in stage 15.0 (TID 284) in 14 ms on 95675304fa2d (executor driver) (70/200)\n",
      "10-20 14:45:00.846 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 70.0 in stage 15.0 (TID 285) in 9 ms on 95675304fa2d (executor driver) (71/200)\n",
      "10-20 14:45:00.846 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 67.0 in stage 15.0 (TID 282) in 25 ms on 95675304fa2d (executor driver) (72/200)\n",
      "10-20 14:45:00.848 172.17.0.2:54325      7233    (TID 288)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.848 172.17.0.2:54325      7233    (TID 288)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.854 172.17.0.2:54325      7233    (TID 288)  INFO org.apache.spark.executor.Executor: Finished task 73.0 in stage 15.0 (TID 288). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.855 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 75.0 in stage 15.0 (TID 290) (95675304fa2d, executor driver, partition 75, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.855 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 73.0 in stage 15.0 (TID 288) in 11 ms on 95675304fa2d (executor driver) (73/200)\n",
      "10-20 14:45:00.856 172.17.0.2:54325      7233    (TID 290)  INFO org.apache.spark.executor.Executor: Running task 75.0 in stage 15.0 (TID 290)\n",
      "10-20 14:45:00.857 172.17.0.2:54325      7233    (TID 287)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.857 172.17.0.2:54325      7233    (TID 287)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.860 172.17.0.2:54325      7233    (TID 287)  INFO org.apache.spark.executor.Executor: Finished task 72.0 in stage 15.0 (TID 287). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.882 172.17.0.2:54325      7233    (TID 289)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.883 172.17.0.2:54325      7233    (TID 289)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.885 172.17.0.2:54325      7233    (TID 289)  INFO org.apache.spark.executor.Executor: Finished task 74.0 in stage 15.0 (TID 289). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.893 172.17.0.2:54325      7233    (TID 290)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.894 172.17.0.2:54325      7233    (TID 290)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.895 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 76.0 in stage 15.0 (TID 291) (95675304fa2d, executor driver, partition 76, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.896 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 72.0 in stage 15.0 (TID 287) in 53 ms on 95675304fa2d (executor driver) (74/200)\n",
      "10-20 14:45:00.896 172.17.0.2:54325      7233    (TID 291)  INFO org.apache.spark.executor.Executor: Running task 76.0 in stage 15.0 (TID 291)\n",
      "10-20 14:45:00.900 172.17.0.2:54325      7233    (TID 286)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.900 172.17.0.2:54325      7233    (TID 286)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.903 172.17.0.2:54325      7233    (TID 291)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.903 172.17.0.2:54325      7233    (TID 291)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.905 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 74.0 in stage 15.0 (TID 289) in 60 ms on 95675304fa2d (executor driver) (75/200)\n",
      "10-20 14:45:00.906 172.17.0.2:54325      7233    (TID 290)  INFO org.apache.spark.executor.Executor: Finished task 75.0 in stage 15.0 (TID 290). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.906 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 77.0 in stage 15.0 (TID 292) (95675304fa2d, executor driver, partition 77, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.906 172.17.0.2:54325      7233    (TID 286)  INFO org.apache.spark.executor.Executor: Finished task 71.0 in stage 15.0 (TID 286). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.906 172.17.0.2:54325      7233    (TID 291)  INFO org.apache.spark.executor.Executor: Finished task 76.0 in stage 15.0 (TID 291). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.906 172.17.0.2:54325      7233    (TID 292)  INFO org.apache.spark.executor.Executor: Running task 77.0 in stage 15.0 (TID 292)\n",
      "10-20 14:45:00.906 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 78.0 in stage 15.0 (TID 293) (95675304fa2d, executor driver, partition 78, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.907 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 79.0 in stage 15.0 (TID 294) (95675304fa2d, executor driver, partition 79, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.908 172.17.0.2:54325      7233    (TID 294)  INFO org.apache.spark.executor.Executor: Running task 79.0 in stage 15.0 (TID 294)\n",
      "10-20 14:45:00.912 172.17.0.2:54325      7233    (TID 294)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.912 172.17.0.2:54325      7233    (TID 294)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.910 172.17.0.2:54325      7233    (TID 292)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.912 172.17.0.2:54325      7233    (TID 292)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:45:00.908 172.17.0.2:54325      7233    (TID 293)  INFO org.apache.spark.executor.Executor: Running task 78.0 in stage 15.0 (TID 293)\n",
      "10-20 14:45:00.908 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 80.0 in stage 15.0 (TID 295) (95675304fa2d, executor driver, partition 80, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.913 172.17.0.2:54325      7233    (TID 295)  INFO org.apache.spark.executor.Executor: Running task 80.0 in stage 15.0 (TID 295)\n",
      "10-20 14:45:00.913 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 75.0 in stage 15.0 (TID 290) in 59 ms on 95675304fa2d (executor driver) (76/200)\n",
      "10-20 14:45:00.913 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 76.0 in stage 15.0 (TID 291) in 18 ms on 95675304fa2d (executor driver) (77/200)\n",
      "10-20 14:45:00.913 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 71.0 in stage 15.0 (TID 286) in 75 ms on 95675304fa2d (executor driver) (78/200)\n",
      "10-20 14:45:00.916 172.17.0.2:54325      7233    (TID 293)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.916 172.17.0.2:54325      7233    (TID 293)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.916 172.17.0.2:54325      7233    (TID 295)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.916 172.17.0.2:54325      7233    (TID 295)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.918 172.17.0.2:54325      7233    (TID 295)  INFO org.apache.spark.executor.Executor: Finished task 80.0 in stage 15.0 (TID 295). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.919 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 81.0 in stage 15.0 (TID 296) (95675304fa2d, executor driver, partition 81, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.919 172.17.0.2:54325      7233    (TID 296)  INFO org.apache.spark.executor.Executor: Running task 81.0 in stage 15.0 (TID 296)\n",
      "10-20 14:45:00.918 172.17.0.2:54325      7233    (TID 293)  INFO org.apache.spark.executor.Executor: Finished task 78.0 in stage 15.0 (TID 293). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.921 172.17.0.2:54325      7233    (TID 294)  INFO org.apache.spark.executor.Executor: Finished task 79.0 in stage 15.0 (TID 294). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.919 172.17.0.2:54325      7233    (TID 292)  INFO org.apache.spark.executor.Executor: Finished task 77.0 in stage 15.0 (TID 292). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.919 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 80.0 in stage 15.0 (TID 295) in 11 ms on 95675304fa2d (executor driver) (79/200)\n",
      "10-20 14:45:00.923 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 82.0 in stage 15.0 (TID 297) (95675304fa2d, executor driver, partition 82, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.923 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 83.0 in stage 15.0 (TID 298) (95675304fa2d, executor driver, partition 83, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.923 172.17.0.2:54325      7233    (TID 296)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.923 172.17.0.2:54325      7233    (TID 296)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.924 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 84.0 in stage 15.0 (TID 299) (95675304fa2d, executor driver, partition 84, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.924 172.17.0.2:54325      7233    (TID 298)  INFO org.apache.spark.executor.Executor: Running task 83.0 in stage 15.0 (TID 298)\n",
      "10-20 14:45:00.924 172.17.0.2:54325      7233    (TID 297)  INFO org.apache.spark.executor.Executor: Running task 82.0 in stage 15.0 (TID 297)\n",
      "10-20 14:45:00.924 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 77.0 in stage 15.0 (TID 292) in 18 ms on 95675304fa2d (executor driver) (80/200)\n",
      "10-20 14:45:00.924 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 79.0 in stage 15.0 (TID 294) in 17 ms on 95675304fa2d (executor driver) (81/200)\n",
      "10-20 14:45:00.924 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 78.0 in stage 15.0 (TID 293) in 18 ms on 95675304fa2d (executor driver) (82/200)\n",
      "10-20 14:45:00.925 172.17.0.2:54325      7233    (TID 296)  INFO org.apache.spark.executor.Executor: Finished task 81.0 in stage 15.0 (TID 296). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.925 172.17.0.2:54325      7233    (TID 299)  INFO org.apache.spark.executor.Executor: Running task 84.0 in stage 15.0 (TID 299)\n",
      "10-20 14:45:00.926 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 85.0 in stage 15.0 (TID 300) (95675304fa2d, executor driver, partition 85, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.926 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 81.0 in stage 15.0 (TID 296) in 7 ms on 95675304fa2d (executor driver) (83/200)\n",
      "10-20 14:45:00.927 172.17.0.2:54325      7233    (TID 297)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.927 172.17.0.2:54325      7233    (TID 297)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.927 172.17.0.2:54325      7233    (TID 299)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.927 172.17.0.2:54325      7233    (TID 299)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.928 172.17.0.2:54325      7233    (TID 298)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.928 172.17.0.2:54325      7233    (TID 298)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.929 172.17.0.2:54325      7233    (TID 297)  INFO org.apache.spark.executor.Executor: Finished task 82.0 in stage 15.0 (TID 297). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.929 172.17.0.2:54325      7233    (TID 299)  INFO org.apache.spark.executor.Executor: Finished task 84.0 in stage 15.0 (TID 299). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.929 172.17.0.2:54325      7233    (TID 298)  INFO org.apache.spark.executor.Executor: Finished task 83.0 in stage 15.0 (TID 298). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.929 172.17.0.2:54325      7233    (TID 300)  INFO org.apache.spark.executor.Executor: Running task 85.0 in stage 15.0 (TID 300)\n",
      "10-20 14:45:00.929 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 86.0 in stage 15.0 (TID 301) (95675304fa2d, executor driver, partition 86, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.929 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 82.0 in stage 15.0 (TID 297) in 7 ms on 95675304fa2d (executor driver) (84/200)\n",
      "10-20 14:45:00.930 172.17.0.2:54325      7233    (TID 301)  INFO org.apache.spark.executor.Executor: Running task 86.0 in stage 15.0 (TID 301)\n",
      "10-20 14:45:00.931 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 87.0 in stage 15.0 (TID 302) (95675304fa2d, executor driver, partition 87, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.931 172.17.0.2:54325      7233    (TID 302)  INFO org.apache.spark.executor.Executor: Running task 87.0 in stage 15.0 (TID 302)\n",
      "10-20 14:45:00.931 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 83.0 in stage 15.0 (TID 298) in 8 ms on 95675304fa2d (executor driver) (85/200)\n",
      "10-20 14:45:00.932 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 88.0 in stage 15.0 (TID 303) (95675304fa2d, executor driver, partition 88, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.932 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 84.0 in stage 15.0 (TID 299) in 8 ms on 95675304fa2d (executor driver) (86/200)\n",
      "10-20 14:45:00.935 172.17.0.2:54325      7233    (TID 302)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.935 172.17.0.2:54325      7233    (TID 302)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.938 172.17.0.2:54325      7233    (TID 302)  INFO org.apache.spark.executor.Executor: Finished task 87.0 in stage 15.0 (TID 302). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.938 172.17.0.2:54325      7233    (TID 300)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.938 172.17.0.2:54325      7233    (TID 300)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.939 172.17.0.2:54325      7233    (TID 300)  INFO org.apache.spark.executor.Executor: Finished task 85.0 in stage 15.0 (TID 300). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.940 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 89.0 in stage 15.0 (TID 304) (95675304fa2d, executor driver, partition 89, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.941 172.17.0.2:54325      7233    (TID 304)  INFO org.apache.spark.executor.Executor: Running task 89.0 in stage 15.0 (TID 304)\n",
      "10-20 14:45:00.941 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 87.0 in stage 15.0 (TID 302) in 10 ms on 95675304fa2d (executor driver) (87/200)\n",
      "10-20 14:45:00.941 172.17.0.2:54325      7233    (TID 303)  INFO org.apache.spark.executor.Executor: Running task 88.0 in stage 15.0 (TID 303)\n",
      "10-20 14:45:00.943 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 90.0 in stage 15.0 (TID 305) (95675304fa2d, executor driver, partition 90, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.944 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 85.0 in stage 15.0 (TID 300) in 18 ms on 95675304fa2d (executor driver) (88/200)\n",
      "10-20 14:45:00.944 172.17.0.2:54325      7233    (TID 304)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.944 172.17.0.2:54325      7233    (TID 305)  INFO org.apache.spark.executor.Executor: Running task 90.0 in stage 15.0 (TID 305)\n",
      "10-20 14:45:00.944 172.17.0.2:54325      7233    (TID 304)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.945 172.17.0.2:54325      7233    (TID 301)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.945 172.17.0.2:54325      7233    (TID 301)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.947 172.17.0.2:54325      7233    (TID 304)  INFO org.apache.spark.executor.Executor: Finished task 89.0 in stage 15.0 (TID 304). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.947 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 91.0 in stage 15.0 (TID 306) (95675304fa2d, executor driver, partition 91, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.947 172.17.0.2:54325      7233    (TID 306)  INFO org.apache.spark.executor.Executor: Running task 91.0 in stage 15.0 (TID 306)\n",
      "10-20 14:45:00.947 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 89.0 in stage 15.0 (TID 304) in 7 ms on 95675304fa2d (executor driver) (89/200)\n",
      "10-20 14:45:00.949 172.17.0.2:54325      7233    (TID 301)  INFO org.apache.spark.executor.Executor: Finished task 86.0 in stage 15.0 (TID 301). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.950 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 92.0 in stage 15.0 (TID 307) (95675304fa2d, executor driver, partition 92, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.950 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 86.0 in stage 15.0 (TID 301) in 21 ms on 95675304fa2d (executor driver) (90/200)\n",
      "10-20 14:45:00.950 172.17.0.2:54325      7233    (TID 307)  INFO org.apache.spark.executor.Executor: Running task 92.0 in stage 15.0 (TID 307)\n",
      "10-20 14:45:00.953 172.17.0.2:54325      7233    (TID 306)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.954 172.17.0.2:54325      7233    (TID 306)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.954 172.17.0.2:54325      7233    (TID 305)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.954 172.17.0.2:54325      7233    (TID 305)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.956 172.17.0.2:54325      7233    (TID 306)  INFO org.apache.spark.executor.Executor: Finished task 91.0 in stage 15.0 (TID 306). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.957 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 93.0 in stage 15.0 (TID 308) (95675304fa2d, executor driver, partition 93, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.957 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 91.0 in stage 15.0 (TID 306) in 10 ms on 95675304fa2d (executor driver) (91/200)\n",
      "10-20 14:45:00.958 172.17.0.2:54325      7233    (TID 308)  INFO org.apache.spark.executor.Executor: Running task 93.0 in stage 15.0 (TID 308)\n",
      "10-20 14:45:00.959 172.17.0.2:54325      7233    (TID 305)  INFO org.apache.spark.executor.Executor: Finished task 90.0 in stage 15.0 (TID 305). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.959 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 94.0 in stage 15.0 (TID 309) (95675304fa2d, executor driver, partition 94, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.959 172.17.0.2:54325      7233    (TID 307)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.960 172.17.0.2:54325      7233    (TID 307)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.960 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 90.0 in stage 15.0 (TID 305) in 17 ms on 95675304fa2d (executor driver) (92/200)\n",
      "10-20 14:45:00.961 172.17.0.2:54325      7233    (TID 309)  INFO org.apache.spark.executor.Executor: Running task 94.0 in stage 15.0 (TID 309)\n",
      "10-20 14:45:00.962 172.17.0.2:54325      7233    (TID 307)  INFO org.apache.spark.executor.Executor: Finished task 92.0 in stage 15.0 (TID 307). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.962 172.17.0.2:54325      7233    (TID 308)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.962 172.17.0.2:54325      7233    (TID 308)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.962 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 95.0 in stage 15.0 (TID 310) (95675304fa2d, executor driver, partition 95, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.962 172.17.0.2:54325      7233    (TID 310)  INFO org.apache.spark.executor.Executor: Running task 95.0 in stage 15.0 (TID 310)\n",
      "10-20 14:45:00.962 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 92.0 in stage 15.0 (TID 307) in 12 ms on 95675304fa2d (executor driver) (93/200)\n",
      "10-20 14:45:00.965 172.17.0.2:54325      7233    (TID 309)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.966 172.17.0.2:54325      7233    (TID 310)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.966 172.17.0.2:54325      7233    (TID 310)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.966 172.17.0.2:54325      7233    (TID 303)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.967 172.17.0.2:54325      7233    (TID 303)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:00.968 172.17.0.2:54325      7233    (TID 310)  INFO org.apache.spark.executor.Executor: Finished task 95.0 in stage 15.0 (TID 310). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.966 172.17.0.2:54325      7233    (TID 309)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.969 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 96.0 in stage 15.0 (TID 311) (95675304fa2d, executor driver, partition 96, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.969 172.17.0.2:54325      7233    (TID 311)  INFO org.apache.spark.executor.Executor: Running task 96.0 in stage 15.0 (TID 311)\n",
      "10-20 14:45:00.969 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 95.0 in stage 15.0 (TID 310) in 7 ms on 95675304fa2d (executor driver) (94/200)\n",
      "10-20 14:45:00.973 172.17.0.2:54325      7233    (TID 311)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.973 172.17.0.2:54325      7233    (TID 311)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.973 172.17.0.2:54325      7233    (TID 303)  INFO org.apache.spark.executor.Executor: Finished task 88.0 in stage 15.0 (TID 303). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.974 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 97.0 in stage 15.0 (TID 312) (95675304fa2d, executor driver, partition 97, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.975 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 88.0 in stage 15.0 (TID 303) in 43 ms on 95675304fa2d (executor driver) (95/200)\n",
      "10-20 14:45:00.976 172.17.0.2:54325      7233    (TID 312)  INFO org.apache.spark.executor.Executor: Running task 97.0 in stage 15.0 (TID 312)\n",
      "10-20 14:45:00.977 172.17.0.2:54325      7233    (TID 308)  INFO org.apache.spark.executor.Executor: Finished task 93.0 in stage 15.0 (TID 308). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.977 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 98.0 in stage 15.0 (TID 313) (95675304fa2d, executor driver, partition 98, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.978 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 93.0 in stage 15.0 (TID 308) in 22 ms on 95675304fa2d (executor driver) (96/200)\n",
      "10-20 14:45:00.979 172.17.0.2:54325      7233    (TID 313)  INFO org.apache.spark.executor.Executor: Running task 98.0 in stage 15.0 (TID 313)\n",
      "10-20 14:45:00.979 172.17.0.2:54325      7233    (TID 311)  INFO org.apache.spark.executor.Executor: Finished task 96.0 in stage 15.0 (TID 311). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.980 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 99.0 in stage 15.0 (TID 314) (95675304fa2d, executor driver, partition 99, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.980 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 96.0 in stage 15.0 (TID 311) in 12 ms on 95675304fa2d (executor driver) (97/200)\n",
      "10-20 14:45:00.980 172.17.0.2:54325      7233    (TID 309)  INFO org.apache.spark.executor.Executor: Finished task 94.0 in stage 15.0 (TID 309). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.980 172.17.0.2:54325      7233    (TID 314)  INFO org.apache.spark.executor.Executor: Running task 99.0 in stage 15.0 (TID 314)\n",
      "10-20 14:45:00.981 172.17.0.2:54325      7233    (TID 313)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.981 172.17.0.2:54325      7233    (TID 313)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.983 172.17.0.2:54325      7233    (TID 313)  INFO org.apache.spark.executor.Executor: Finished task 98.0 in stage 15.0 (TID 313). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.983 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 100.0 in stage 15.0 (TID 315) (95675304fa2d, executor driver, partition 100, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.984 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 98.0 in stage 15.0 (TID 313) in 7 ms on 95675304fa2d (executor driver) (98/200)\n",
      "10-20 14:45:00.984 172.17.0.2:54325      7233    (TID 315)  INFO org.apache.spark.executor.Executor: Running task 100.0 in stage 15.0 (TID 315)\n",
      "10-20 14:45:00.986 172.17.0.2:54325      7233    (TID 314)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.986 172.17.0.2:54325      7233    (TID 314)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.989 172.17.0.2:54325      7233    (TID 314)  INFO org.apache.spark.executor.Executor: Finished task 99.0 in stage 15.0 (TID 314). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.989 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 101.0 in stage 15.0 (TID 316) (95675304fa2d, executor driver, partition 101, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.990 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 99.0 in stage 15.0 (TID 314) in 10 ms on 95675304fa2d (executor driver) (99/200)\n",
      "10-20 14:45:00.990 172.17.0.2:54325      7233    (TID 316)  INFO org.apache.spark.executor.Executor: Running task 101.0 in stage 15.0 (TID 316)\n",
      "10-20 14:45:00.991 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 102.0 in stage 15.0 (TID 317) (95675304fa2d, executor driver, partition 102, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.991 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 94.0 in stage 15.0 (TID 309) in 32 ms on 95675304fa2d (executor driver) (100/200)\n",
      "10-20 14:45:00.993 172.17.0.2:54325      7233    (TID 315)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.993 172.17.0.2:54325      7233    (TID 315)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.995 172.17.0.2:54325      7233    (TID 315)  INFO org.apache.spark.executor.Executor: Finished task 100.0 in stage 15.0 (TID 315). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.995 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 103.0 in stage 15.0 (TID 318) (95675304fa2d, executor driver, partition 103, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:00.996 172.17.0.2:54325      7233    (TID 312)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.996 172.17.0.2:54325      7233    (TID 312)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.996 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 100.0 in stage 15.0 (TID 315) in 13 ms on 95675304fa2d (executor driver) (101/200)\n",
      "10-20 14:45:00.997 172.17.0.2:54325      7233    (TID 316)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:00.997 172.17.0.2:54325      7233    (TID 316)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:00.997 172.17.0.2:54325      7233    (TID 312)  INFO org.apache.spark.executor.Executor: Finished task 97.0 in stage 15.0 (TID 312). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.998 172.17.0.2:54325      7233    (TID 316)  INFO org.apache.spark.executor.Executor: Finished task 101.0 in stage 15.0 (TID 316). 3832 bytes result sent to driver\n",
      "10-20 14:45:00.996 172.17.0.2:54325      7233    (TID 317)  INFO org.apache.spark.executor.Executor: Running task 102.0 in stage 15.0 (TID 317)\n",
      "10-20 14:45:01.000 172.17.0.2:54325      7233    (TID 317)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.000 172.17.0.2:54325      7233    (TID 317)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.002 172.17.0.2:54325      7233    (TID 317)  INFO org.apache.spark.executor.Executor: Finished task 102.0 in stage 15.0 (TID 317). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.002 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 104.0 in stage 15.0 (TID 319) (95675304fa2d, executor driver, partition 104, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.003 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 102.0 in stage 15.0 (TID 317) in 12 ms on 95675304fa2d (executor driver) (102/200)\n",
      "10-20 14:45:01.003 172.17.0.2:54325      7233    (TID 319)  INFO org.apache.spark.executor.Executor: Running task 104.0 in stage 15.0 (TID 319)\n",
      "10-20 14:45:01.003 172.17.0.2:54325      7233    (TID 318)  INFO org.apache.spark.executor.Executor: Running task 103.0 in stage 15.0 (TID 318)\n",
      "10-20 14:45:01.004 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 105.0 in stage 15.0 (TID 320) (95675304fa2d, executor driver, partition 105, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.004 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 101.0 in stage 15.0 (TID 316) in 15 ms on 95675304fa2d (executor driver) (103/200)\n",
      "10-20 14:45:01.004 172.17.0.2:54325      7233    (TID 320)  INFO org.apache.spark.executor.Executor: Running task 105.0 in stage 15.0 (TID 320)\n",
      "10-20 14:45:01.005 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 106.0 in stage 15.0 (TID 321) (95675304fa2d, executor driver, partition 106, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.005 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 97.0 in stage 15.0 (TID 312) in 31 ms on 95675304fa2d (executor driver) (104/200)\n",
      "10-20 14:45:01.007 172.17.0.2:54325      7233    (TID 318)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.007 172.17.0.2:54325      7233    (TID 318)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.008 172.17.0.2:54325      7233    (TID 318)  INFO org.apache.spark.executor.Executor: Finished task 103.0 in stage 15.0 (TID 318). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.010 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 107.0 in stage 15.0 (TID 322) (95675304fa2d, executor driver, partition 107, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.011 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 103.0 in stage 15.0 (TID 318) in 16 ms on 95675304fa2d (executor driver) (105/200)\n",
      "10-20 14:45:01.007 172.17.0.2:54325      7233    (TID 320)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.011 172.17.0.2:54325      7233    (TID 320)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:01.012 172.17.0.2:54325      7233    (TID 322)  INFO org.apache.spark.executor.Executor: Running task 107.0 in stage 15.0 (TID 322)\n",
      "10-20 14:45:01.012 172.17.0.2:54325      7233    (TID 320)  INFO org.apache.spark.executor.Executor: Finished task 105.0 in stage 15.0 (TID 320). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.013 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 108.0 in stage 15.0 (TID 323) (95675304fa2d, executor driver, partition 108, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.010 172.17.0.2:54325      7233    (TID 321)  INFO org.apache.spark.executor.Executor: Running task 106.0 in stage 15.0 (TID 321)\n",
      "10-20 14:45:01.013 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 105.0 in stage 15.0 (TID 320) in 9 ms on 95675304fa2d (executor driver) (106/200)\n",
      "10-20 14:45:01.013 172.17.0.2:54325      7233    (TID 323)  INFO org.apache.spark.executor.Executor: Running task 108.0 in stage 15.0 (TID 323)\n",
      "10-20 14:45:01.015 172.17.0.2:54325      7233    (TID 321)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.015 172.17.0.2:54325      7233    (TID 321)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.010 172.17.0.2:54325      7233    (TID 319)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.015 172.17.0.2:54325      7233    (TID 319)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "10-20 14:45:01.016 172.17.0.2:54325      7233    (TID 322)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.016 172.17.0.2:54325      7233    (TID 322)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.016 172.17.0.2:54325      7233    (TID 321)  INFO org.apache.spark.executor.Executor: Finished task 106.0 in stage 15.0 (TID 321). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.017 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 109.0 in stage 15.0 (TID 324) (95675304fa2d, executor driver, partition 109, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.017 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 106.0 in stage 15.0 (TID 321) in 12 ms on 95675304fa2d (executor driver) (107/200)\n",
      "10-20 14:45:01.018 172.17.0.2:54325      7233    (TID 323)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.018 172.17.0.2:54325      7233    (TID 323)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.018 172.17.0.2:54325      7233    (TID 319)  INFO org.apache.spark.executor.Executor: Finished task 104.0 in stage 15.0 (TID 319). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.019 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 110.0 in stage 15.0 (TID 325) (95675304fa2d, executor driver, partition 110, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.019 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 104.0 in stage 15.0 (TID 319) in 17 ms on 95675304fa2d (executor driver) (108/200)\n",
      "10-20 14:45:01.019 172.17.0.2:54325      7233    (TID 325)  INFO org.apache.spark.executor.Executor: Running task 110.0 in stage 15.0 (TID 325)\n",
      "10-20 14:45:01.020 172.17.0.2:54325      7233    (TID 322)  INFO org.apache.spark.executor.Executor: Finished task 107.0 in stage 15.0 (TID 322). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.021 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 111.0 in stage 15.0 (TID 326) (95675304fa2d, executor driver, partition 111, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.021 172.17.0.2:54325      7233    (TID 324)  INFO org.apache.spark.executor.Executor: Running task 109.0 in stage 15.0 (TID 324)\n",
      "10-20 14:45:01.021 172.17.0.2:54325      7233    (TID 326)  INFO org.apache.spark.executor.Executor: Running task 111.0 in stage 15.0 (TID 326)\n",
      "10-20 14:45:01.021 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 107.0 in stage 15.0 (TID 322) in 11 ms on 95675304fa2d (executor driver) (109/200)\n",
      "10-20 14:45:01.021 172.17.0.2:54325      7233    (TID 325)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.021 172.17.0.2:54325      7233    (TID 325)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.022 172.17.0.2:54325      7233    (TID 323)  INFO org.apache.spark.executor.Executor: Finished task 108.0 in stage 15.0 (TID 323). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.022 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 112.0 in stage 15.0 (TID 327) (95675304fa2d, executor driver, partition 112, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.023 172.17.0.2:54325      7233    (TID 325)  INFO org.apache.spark.executor.Executor: Finished task 110.0 in stage 15.0 (TID 325). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.023 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 108.0 in stage 15.0 (TID 323) in 10 ms on 95675304fa2d (executor driver) (110/200)\n",
      "10-20 14:45:01.024 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 113.0 in stage 15.0 (TID 328) (95675304fa2d, executor driver, partition 113, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.024 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 110.0 in stage 15.0 (TID 325) in 5 ms on 95675304fa2d (executor driver) (111/200)\n",
      "10-20 14:45:01.026 172.17.0.2:54325      7233    (TID 324)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.026 172.17.0.2:54325      7233    (TID 324)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.026 172.17.0.2:54325      7233    (TID 326)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.026 172.17.0.2:54325      7233    (TID 326)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.027 172.17.0.2:54325      7233    (TID 327)  INFO org.apache.spark.executor.Executor: Running task 112.0 in stage 15.0 (TID 327)\n",
      "10-20 14:45:01.028 172.17.0.2:54325      7233    (TID 324)  INFO org.apache.spark.executor.Executor: Finished task 109.0 in stage 15.0 (TID 324). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.028 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 114.0 in stage 15.0 (TID 329) (95675304fa2d, executor driver, partition 114, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.029 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 109.0 in stage 15.0 (TID 324) in 12 ms on 95675304fa2d (executor driver) (112/200)\n",
      "10-20 14:45:01.029 172.17.0.2:54325      7233    (TID 328)  INFO org.apache.spark.executor.Executor: Running task 113.0 in stage 15.0 (TID 328)\n",
      "10-20 14:45:01.029 172.17.0.2:54325      7233    (TID 329)  INFO org.apache.spark.executor.Executor: Running task 114.0 in stage 15.0 (TID 329)\n",
      "10-20 14:45:01.031 172.17.0.2:54325      7233    (TID 327)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.031 172.17.0.2:54325      7233    (TID 327)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.032 172.17.0.2:54325      7233    (TID 326)  INFO org.apache.spark.executor.Executor: Finished task 111.0 in stage 15.0 (TID 326). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.033 172.17.0.2:54325      7233    (TID 327)  INFO org.apache.spark.executor.Executor: Finished task 112.0 in stage 15.0 (TID 327). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.038 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 115.0 in stage 15.0 (TID 330) (95675304fa2d, executor driver, partition 115, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.038 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 116.0 in stage 15.0 (TID 331) (95675304fa2d, executor driver, partition 116, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.038 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 111.0 in stage 15.0 (TID 326) in 17 ms on 95675304fa2d (executor driver) (113/200)\n",
      "10-20 14:45:01.039 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 112.0 in stage 15.0 (TID 327) in 17 ms on 95675304fa2d (executor driver) (114/200)\n",
      "10-20 14:45:01.039 172.17.0.2:54325      7233    (TID 331)  INFO org.apache.spark.executor.Executor: Running task 116.0 in stage 15.0 (TID 331)\n",
      "10-20 14:45:01.041 172.17.0.2:54325      7233    (TID 329)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.041 172.17.0.2:54325      7233    (TID 329)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.041 172.17.0.2:54325      7233    (TID 331)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.042 172.17.0.2:54325      7233    (TID 331)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.044 172.17.0.2:54325      7233    (TID 331)  INFO org.apache.spark.executor.Executor: Finished task 116.0 in stage 15.0 (TID 331). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.044 172.17.0.2:54325      7233    (TID 328)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.044 172.17.0.2:54325      7233    (TID 328)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.045 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 117.0 in stage 15.0 (TID 332) (95675304fa2d, executor driver, partition 117, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.045 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 116.0 in stage 15.0 (TID 331) in 7 ms on 95675304fa2d (executor driver) (115/200)\n",
      "10-20 14:45:01.045 172.17.0.2:54325      7233    (TID 332)  INFO org.apache.spark.executor.Executor: Running task 117.0 in stage 15.0 (TID 332)\n",
      "10-20 14:45:01.047 172.17.0.2:54325      7233    (TID 329)  INFO org.apache.spark.executor.Executor: Finished task 114.0 in stage 15.0 (TID 329). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.047 172.17.0.2:54325      7233    (TID 332)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.047 172.17.0.2:54325      7233    (TID 332)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.049 172.17.0.2:54325      7233    (TID 332)  INFO org.apache.spark.executor.Executor: Finished task 117.0 in stage 15.0 (TID 332). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.049 172.17.0.2:54325      7233    (TID 330)  INFO org.apache.spark.executor.Executor: Running task 115.0 in stage 15.0 (TID 330)\n",
      "10-20 14:45:01.049 172.17.0.2:54325      7233    (TID 328)  INFO org.apache.spark.executor.Executor: Finished task 113.0 in stage 15.0 (TID 328). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.049 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 118.0 in stage 15.0 (TID 333) (95675304fa2d, executor driver, partition 118, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.049 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 119.0 in stage 15.0 (TID 334) (95675304fa2d, executor driver, partition 119, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.050 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 120.0 in stage 15.0 (TID 335) (95675304fa2d, executor driver, partition 120, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.050 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 114.0 in stage 15.0 (TID 329) in 22 ms on 95675304fa2d (executor driver) (116/200)\n",
      "10-20 14:45:01.050 172.17.0.2:54325      7233    (TID 333)  INFO org.apache.spark.executor.Executor: Running task 118.0 in stage 15.0 (TID 333)\n",
      "10-20 14:45:01.050 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 117.0 in stage 15.0 (TID 332) in 6 ms on 95675304fa2d (executor driver) (117/200)\n",
      "10-20 14:45:01.050 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 113.0 in stage 15.0 (TID 328) in 26 ms on 95675304fa2d (executor driver) (118/200)\n",
      "10-20 14:45:01.051 172.17.0.2:54325      7233    (TID 334)  INFO org.apache.spark.executor.Executor: Running task 119.0 in stage 15.0 (TID 334)\n",
      "10-20 14:45:01.052 172.17.0.2:54325      7233    (TID 335)  INFO org.apache.spark.executor.Executor: Running task 120.0 in stage 15.0 (TID 335)\n",
      "10-20 14:45:01.057 172.17.0.2:54325      7233    (TID 335)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.057 172.17.0.2:54325      7233    (TID 335)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.055 172.17.0.2:54325      7233    (TID 333)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.057 172.17.0.2:54325      7233    (TID 333)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:45:01.053 172.17.0.2:54325      7233    (TID 330)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.053 172.17.0.2:54325      7233    (TID 334)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.058 172.17.0.2:54325      7233    (TID 334)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "10-20 14:45:01.060 172.17.0.2:54325      7233    (TID 334)  INFO org.apache.spark.executor.Executor: Finished task 119.0 in stage 15.0 (TID 334). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.060 172.17.0.2:54325      7233    (TID 330)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 14:45:01.061 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 121.0 in stage 15.0 (TID 336) (95675304fa2d, executor driver, partition 121, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.061 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 119.0 in stage 15.0 (TID 334) in 12 ms on 95675304fa2d (executor driver) (119/200)\n",
      "10-20 14:45:01.061 172.17.0.2:54325      7233    (TID 336)  INFO org.apache.spark.executor.Executor: Running task 121.0 in stage 15.0 (TID 336)\n",
      "10-20 14:45:01.063 172.17.0.2:54325      7233    (TID 330)  INFO org.apache.spark.executor.Executor: Finished task 115.0 in stage 15.0 (TID 330). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.063 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 122.0 in stage 15.0 (TID 337) (95675304fa2d, executor driver, partition 122, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.064 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 115.0 in stage 15.0 (TID 330) in 27 ms on 95675304fa2d (executor driver) (120/200)\n",
      "10-20 14:45:01.064 172.17.0.2:54325      7233    (TID 337)  INFO org.apache.spark.executor.Executor: Running task 122.0 in stage 15.0 (TID 337)\n",
      "10-20 14:45:01.066 172.17.0.2:54325      7233    (TID 333)  INFO org.apache.spark.executor.Executor: Finished task 118.0 in stage 15.0 (TID 333). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.066 172.17.0.2:54325      7233    (TID 337)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.066 172.17.0.2:54325      7233    (TID 337)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.067 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 123.0 in stage 15.0 (TID 338) (95675304fa2d, executor driver, partition 123, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.068 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 118.0 in stage 15.0 (TID 333) in 19 ms on 95675304fa2d (executor driver) (121/200)\n",
      "10-20 14:45:01.068 172.17.0.2:54325      7233    (TID 337)  INFO org.apache.spark.executor.Executor: Finished task 122.0 in stage 15.0 (TID 337). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.068 172.17.0.2:54325      7233    (TID 336)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.068 172.17.0.2:54325      7233    (TID 336)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.069 172.17.0.2:54325      7233    (TID 338)  INFO org.apache.spark.executor.Executor: Running task 123.0 in stage 15.0 (TID 338)\n",
      "10-20 14:45:01.076 172.17.0.2:54325      7233    (TID 335)  INFO org.apache.spark.executor.Executor: Finished task 120.0 in stage 15.0 (TID 335). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.078 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 124.0 in stage 15.0 (TID 339) (95675304fa2d, executor driver, partition 124, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.079 172.17.0.2:54325      7233    (TID 339)  INFO org.apache.spark.executor.Executor: Running task 124.0 in stage 15.0 (TID 339)\n",
      "10-20 14:45:01.079 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 125.0 in stage 15.0 (TID 340) (95675304fa2d, executor driver, partition 125, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.079 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 120.0 in stage 15.0 (TID 335) in 29 ms on 95675304fa2d (executor driver) (122/200)\n",
      "10-20 14:45:01.079 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 122.0 in stage 15.0 (TID 337) in 16 ms on 95675304fa2d (executor driver) (123/200)\n",
      "10-20 14:45:01.079 172.17.0.2:54325      7233    (TID 340)  INFO org.apache.spark.executor.Executor: Running task 125.0 in stage 15.0 (TID 340)\n",
      "10-20 14:45:01.081 172.17.0.2:54325      7233    (TID 340)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.081 172.17.0.2:54325      7233    (TID 340)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.081 172.17.0.2:54325      7233    (TID 339)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.082 172.17.0.2:54325      7233    (TID 339)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.082 172.17.0.2:54325      7233    (TID 338)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.082 172.17.0.2:54325      7233    (TID 338)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.083 172.17.0.2:54325      7233    (TID 336)  INFO org.apache.spark.executor.Executor: Finished task 121.0 in stage 15.0 (TID 336). 3875 bytes result sent to driver\n",
      "10-20 14:45:01.084 172.17.0.2:54325      7233    (TID 340)  INFO org.apache.spark.executor.Executor: Finished task 125.0 in stage 15.0 (TID 340). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.084 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 126.0 in stage 15.0 (TID 341) (95675304fa2d, executor driver, partition 126, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.084 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 121.0 in stage 15.0 (TID 336) in 23 ms on 95675304fa2d (executor driver) (124/200)\n",
      "10-20 14:45:01.084 172.17.0.2:54325      7233    (TID 341)  INFO org.apache.spark.executor.Executor: Running task 126.0 in stage 15.0 (TID 341)\n",
      "10-20 14:45:01.084 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 127.0 in stage 15.0 (TID 342) (95675304fa2d, executor driver, partition 127, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.085 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 125.0 in stage 15.0 (TID 340) in 6 ms on 95675304fa2d (executor driver) (125/200)\n",
      "10-20 14:45:01.087 172.17.0.2:54325      7233    (TID 342)  INFO org.apache.spark.executor.Executor: Running task 127.0 in stage 15.0 (TID 342)\n",
      "10-20 14:45:01.088 172.17.0.2:54325      7233    (TID 338)  INFO org.apache.spark.executor.Executor: Finished task 123.0 in stage 15.0 (TID 338). 3875 bytes result sent to driver\n",
      "10-20 14:45:01.088 172.17.0.2:54325      7233    (TID 339)  INFO org.apache.spark.executor.Executor: Finished task 124.0 in stage 15.0 (TID 339). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.088 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 128.0 in stage 15.0 (TID 343) (95675304fa2d, executor driver, partition 128, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.089 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 129.0 in stage 15.0 (TID 344) (95675304fa2d, executor driver, partition 129, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.089 172.17.0.2:54325      7233    (TID 343)  INFO org.apache.spark.executor.Executor: Running task 128.0 in stage 15.0 (TID 343)\n",
      "10-20 14:45:01.089 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 123.0 in stage 15.0 (TID 338) in 22 ms on 95675304fa2d (executor driver) (126/200)\n",
      "10-20 14:45:01.090 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 124.0 in stage 15.0 (TID 339) in 12 ms on 95675304fa2d (executor driver) (127/200)\n",
      "10-20 14:45:01.090 172.17.0.2:54325      7233    (TID 344)  INFO org.apache.spark.executor.Executor: Running task 129.0 in stage 15.0 (TID 344)\n",
      "10-20 14:45:01.090 172.17.0.2:54325      7233    (TID 342)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.091 172.17.0.2:54325      7233    (TID 342)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.092 172.17.0.2:54325      7233    (TID 342)  INFO org.apache.spark.executor.Executor: Finished task 127.0 in stage 15.0 (TID 342). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.093 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 130.0 in stage 15.0 (TID 345) (95675304fa2d, executor driver, partition 130, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.093 172.17.0.2:54325      7233    (TID 345)  INFO org.apache.spark.executor.Executor: Running task 130.0 in stage 15.0 (TID 345)\n",
      "10-20 14:45:01.093 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 127.0 in stage 15.0 (TID 342) in 9 ms on 95675304fa2d (executor driver) (128/200)\n",
      "10-20 14:45:01.095 172.17.0.2:54325      7233    (TID 341)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.095 172.17.0.2:54325      7233    (TID 345)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.096 172.17.0.2:54325      7233    (TID 345)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.097 172.17.0.2:54325      7233    (TID 343)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.097 172.17.0.2:54325      7233    (TID 343)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.097 172.17.0.2:54325      7233    (TID 344)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.097 172.17.0.2:54325      7233    (TID 344)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:01.097 172.17.0.2:54325      7233    (TID 345)  INFO org.apache.spark.executor.Executor: Finished task 130.0 in stage 15.0 (TID 345). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.098 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 131.0 in stage 15.0 (TID 346) (95675304fa2d, executor driver, partition 131, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.098 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 130.0 in stage 15.0 (TID 345) in 5 ms on 95675304fa2d (executor driver) (129/200)\n",
      "10-20 14:45:01.098 172.17.0.2:54325      7233    (TID 346)  INFO org.apache.spark.executor.Executor: Running task 131.0 in stage 15.0 (TID 346)\n",
      "10-20 14:45:01.100 172.17.0.2:54325      7233    (TID 344)  INFO org.apache.spark.executor.Executor: Finished task 129.0 in stage 15.0 (TID 344). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.101 172.17.0.2:54325      7233    (TID 343)  INFO org.apache.spark.executor.Executor: Finished task 128.0 in stage 15.0 (TID 343). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.101 172.17.0.2:54325      7233    (TID 341)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "10-20 14:45:01.102 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 132.0 in stage 15.0 (TID 347) (95675304fa2d, executor driver, partition 132, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.101 172.17.0.2:54325      7233    (TID 346)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.102 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 133.0 in stage 15.0 (TID 348) (95675304fa2d, executor driver, partition 133, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.102 172.17.0.2:54325      7233    (TID 347)  INFO org.apache.spark.executor.Executor: Running task 132.0 in stage 15.0 (TID 347)\n",
      "10-20 14:45:01.102 172.17.0.2:54325      7233    (TID 346)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.102 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 128.0 in stage 15.0 (TID 343) in 14 ms on 95675304fa2d (executor driver) (130/200)\n",
      "10-20 14:45:01.102 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 129.0 in stage 15.0 (TID 344) in 13 ms on 95675304fa2d (executor driver) (131/200)\n",
      "10-20 14:45:01.103 172.17.0.2:54325      7233    (TID 348)  INFO org.apache.spark.executor.Executor: Running task 133.0 in stage 15.0 (TID 348)\n",
      "10-20 14:45:01.104 172.17.0.2:54325      7233    (TID 346)  INFO org.apache.spark.executor.Executor: Finished task 131.0 in stage 15.0 (TID 346). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.105 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 134.0 in stage 15.0 (TID 349) (95675304fa2d, executor driver, partition 134, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.105 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 131.0 in stage 15.0 (TID 346) in 7 ms on 95675304fa2d (executor driver) (132/200)\n",
      "10-20 14:45:01.106 172.17.0.2:54325      7233    (TID 349)  INFO org.apache.spark.executor.Executor: Running task 134.0 in stage 15.0 (TID 349)\n",
      "10-20 14:45:01.106 172.17.0.2:54325      7233    (TID 341)  INFO org.apache.spark.executor.Executor: Finished task 126.0 in stage 15.0 (TID 341). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.108 172.17.0.2:54325      7233    (TID 347)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.108 172.17.0.2:54325      7233    (TID 347)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.108 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 135.0 in stage 15.0 (TID 350) (95675304fa2d, executor driver, partition 135, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.108 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 126.0 in stage 15.0 (TID 341) in 25 ms on 95675304fa2d (executor driver) (133/200)\n",
      "10-20 14:45:01.109 172.17.0.2:54325      7233    (TID 350)  INFO org.apache.spark.executor.Executor: Running task 135.0 in stage 15.0 (TID 350)\n",
      "10-20 14:45:01.110 172.17.0.2:54325      7233    (TID 347)  INFO org.apache.spark.executor.Executor: Finished task 132.0 in stage 15.0 (TID 347). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.111 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 136.0 in stage 15.0 (TID 351) (95675304fa2d, executor driver, partition 136, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.111 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 132.0 in stage 15.0 (TID 347) in 9 ms on 95675304fa2d (executor driver) (134/200)\n",
      "10-20 14:45:01.110 172.17.0.2:54325      7233    (TID 349)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.111 172.17.0.2:54325      7233    (TID 348)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.111 172.17.0.2:54325      7233    (TID 351)  INFO org.apache.spark.executor.Executor: Running task 136.0 in stage 15.0 (TID 351)\n",
      "10-20 14:45:01.111 172.17.0.2:54325      7233    (TID 349)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.111 172.17.0.2:54325      7233    (TID 348)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.113 172.17.0.2:54325      7233    (TID 349)  INFO org.apache.spark.executor.Executor: Finished task 134.0 in stage 15.0 (TID 349). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.114 172.17.0.2:54325      7233    (TID 348)  INFO org.apache.spark.executor.Executor: Finished task 133.0 in stage 15.0 (TID 348). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.114 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 137.0 in stage 15.0 (TID 352) (95675304fa2d, executor driver, partition 137, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.114 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 134.0 in stage 15.0 (TID 349) in 10 ms on 95675304fa2d (executor driver) (135/200)\n",
      "10-20 14:45:01.115 172.17.0.2:54325      7233    (TID 352)  INFO org.apache.spark.executor.Executor: Running task 137.0 in stage 15.0 (TID 352)\n",
      "10-20 14:45:01.117 172.17.0.2:54325      7233    (TID 352)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.117 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 138.0 in stage 15.0 (TID 353) (95675304fa2d, executor driver, partition 138, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.118 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 133.0 in stage 15.0 (TID 348) in 16 ms on 95675304fa2d (executor driver) (136/200)\n",
      "10-20 14:45:01.118 172.17.0.2:54325      7233    (TID 352)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.119 172.17.0.2:54325      7233    (TID 351)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.119 172.17.0.2:54325      7233    (TID 351)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.119 172.17.0.2:54325      7233    (TID 352)  INFO org.apache.spark.executor.Executor: Finished task 137.0 in stage 15.0 (TID 352). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.120 172.17.0.2:54325      7233    (TID 353)  INFO org.apache.spark.executor.Executor: Running task 138.0 in stage 15.0 (TID 353)\n",
      "10-20 14:45:01.120 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 139.0 in stage 15.0 (TID 354) (95675304fa2d, executor driver, partition 139, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.120 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 137.0 in stage 15.0 (TID 352) in 6 ms on 95675304fa2d (executor driver) (137/200)\n",
      "10-20 14:45:01.122 172.17.0.2:54325      7233    (TID 353)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.122 172.17.0.2:54325      7233    (TID 353)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.122 172.17.0.2:54325      7233    (TID 351)  INFO org.apache.spark.executor.Executor: Finished task 136.0 in stage 15.0 (TID 351). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.122 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 140.0 in stage 15.0 (TID 355) (95675304fa2d, executor driver, partition 140, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.122 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 136.0 in stage 15.0 (TID 351) in 11 ms on 95675304fa2d (executor driver) (138/200)\n",
      "10-20 14:45:01.123 172.17.0.2:54325      7233    (TID 353)  INFO org.apache.spark.executor.Executor: Finished task 138.0 in stage 15.0 (TID 353). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.122 172.17.0.2:54325      7233    (TID 354)  INFO org.apache.spark.executor.Executor: Running task 139.0 in stage 15.0 (TID 354)\n",
      "10-20 14:45:01.124 172.17.0.2:54325      7233    (TID 355)  INFO org.apache.spark.executor.Executor: Running task 140.0 in stage 15.0 (TID 355)\n",
      "10-20 14:45:01.126 172.17.0.2:54325      7233    (TID 355)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.126 172.17.0.2:54325      7233    (TID 355)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.128 172.17.0.2:54325      7233    (TID 355)  INFO org.apache.spark.executor.Executor: Finished task 140.0 in stage 15.0 (TID 355). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.128 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 141.0 in stage 15.0 (TID 356) (95675304fa2d, executor driver, partition 141, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.128 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 140.0 in stage 15.0 (TID 355) in 6 ms on 95675304fa2d (executor driver) (139/200)\n",
      "10-20 14:45:01.131 172.17.0.2:54325      7233    (TID 354)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.131 172.17.0.2:54325      7233    (TID 354)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.132 172.17.0.2:54325      7233    (TID 354)  INFO org.apache.spark.executor.Executor: Finished task 139.0 in stage 15.0 (TID 354). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.128 172.17.0.2:54325      7233    (TID 356)  INFO org.apache.spark.executor.Executor: Running task 141.0 in stage 15.0 (TID 356)\n",
      "10-20 14:45:01.132 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 142.0 in stage 15.0 (TID 357) (95675304fa2d, executor driver, partition 142, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.133 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 143.0 in stage 15.0 (TID 358) (95675304fa2d, executor driver, partition 143, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.133 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 138.0 in stage 15.0 (TID 353) in 16 ms on 95675304fa2d (executor driver) (140/200)\n",
      "10-20 14:45:01.134 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 139.0 in stage 15.0 (TID 354) in 13 ms on 95675304fa2d (executor driver) (141/200)\n",
      "10-20 14:45:01.134 172.17.0.2:54325      7233    (TID 358)  INFO org.apache.spark.executor.Executor: Running task 143.0 in stage 15.0 (TID 358)\n",
      "10-20 14:45:01.134 172.17.0.2:54325      7233    (TID 357)  INFO org.apache.spark.executor.Executor: Running task 142.0 in stage 15.0 (TID 357)\n",
      "10-20 14:45:01.136 172.17.0.2:54325      7233    (TID 356)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=================================================>    (183 + 5) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:01.141 172.17.0.2:54325      7233    (TID 356)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:01.144 172.17.0.2:54325      7233    (TID 356)  INFO org.apache.spark.executor.Executor: Finished task 141.0 in stage 15.0 (TID 356). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.144 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 144.0 in stage 15.0 (TID 359) (95675304fa2d, executor driver, partition 144, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.144 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 141.0 in stage 15.0 (TID 356) in 16 ms on 95675304fa2d (executor driver) (142/200)\n",
      "10-20 14:45:01.144 172.17.0.2:54325      7233    (TID 359)  INFO org.apache.spark.executor.Executor: Running task 144.0 in stage 15.0 (TID 359)\n",
      "10-20 14:45:01.141 172.17.0.2:54325      7233    (TID 357)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.145 172.17.0.2:54325      7233    (TID 357)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:45:01.146 172.17.0.2:54325      7233    (TID 357)  INFO org.apache.spark.executor.Executor: Finished task 142.0 in stage 15.0 (TID 357). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.139 172.17.0.2:54325      7233    (TID 358)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.150 172.17.0.2:54325      7233    (TID 358)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms\n",
      "10-20 14:45:01.154 172.17.0.2:54325      7233    (TID 358)  INFO org.apache.spark.executor.Executor: Finished task 143.0 in stage 15.0 (TID 358). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.138 172.17.0.2:54325      7233    (TID 350)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.150 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 145.0 in stage 15.0 (TID 360) (95675304fa2d, executor driver, partition 145, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.154 172.17.0.2:54325      7233    (TID 350)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms\n",
      "10-20 14:45:01.155 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 146.0 in stage 15.0 (TID 361) (95675304fa2d, executor driver, partition 146, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.150 172.17.0.2:54325      7233    (TID 359)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.155 172.17.0.2:54325      7233    (TID 359)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "10-20 14:45:01.155 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 143.0 in stage 15.0 (TID 358) in 22 ms on 95675304fa2d (executor driver) (143/200)\n",
      "10-20 14:45:01.155 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 142.0 in stage 15.0 (TID 357) in 23 ms on 95675304fa2d (executor driver) (144/200)\n",
      "10-20 14:45:01.156 172.17.0.2:54325      7233    (TID 360)  INFO org.apache.spark.executor.Executor: Running task 145.0 in stage 15.0 (TID 360)\n",
      "10-20 14:45:01.157 172.17.0.2:54325      7233    (TID 350)  INFO org.apache.spark.executor.Executor: Finished task 135.0 in stage 15.0 (TID 350). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.157 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 147.0 in stage 15.0 (TID 362) (95675304fa2d, executor driver, partition 147, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.157 172.17.0.2:54325      7233    (TID 359)  INFO org.apache.spark.executor.Executor: Finished task 144.0 in stage 15.0 (TID 359). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.160 172.17.0.2:54325      7233    (TID 360)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.158 172.17.0.2:54325      7233    (TID 361)  INFO org.apache.spark.executor.Executor: Running task 146.0 in stage 15.0 (TID 361)\n",
      "10-20 14:45:01.158 172.17.0.2:54325      7233    (TID 362)  INFO org.apache.spark.executor.Executor: Running task 147.0 in stage 15.0 (TID 362)\n",
      "10-20 14:45:01.157 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 135.0 in stage 15.0 (TID 350) in 49 ms on 95675304fa2d (executor driver) (145/200)\n",
      "10-20 14:45:01.162 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 148.0 in stage 15.0 (TID 363) (95675304fa2d, executor driver, partition 148, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.162 172.17.0.2:54325      7233    (TID 360)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.162 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 144.0 in stage 15.0 (TID 359) in 18 ms on 95675304fa2d (executor driver) (146/200)\n",
      "10-20 14:45:01.163 172.17.0.2:54325      7233    (TID 363)  INFO org.apache.spark.executor.Executor: Running task 148.0 in stage 15.0 (TID 363)\n",
      "10-20 14:45:01.165 172.17.0.2:54325      7233    (TID 362)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.165 172.17.0.2:54325      7233    (TID 362)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.166 172.17.0.2:54325      7233    (TID 363)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.166 172.17.0.2:54325      7233    (TID 363)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.167 172.17.0.2:54325      7233    (TID 360)  INFO org.apache.spark.executor.Executor: Finished task 145.0 in stage 15.0 (TID 360). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.166 172.17.0.2:54325      7233    (TID 361)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.167 172.17.0.2:54325      7233    (TID 361)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.167 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 149.0 in stage 15.0 (TID 364) (95675304fa2d, executor driver, partition 149, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.168 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 145.0 in stage 15.0 (TID 360) in 18 ms on 95675304fa2d (executor driver) (147/200)\n",
      "10-20 14:45:01.168 172.17.0.2:54325      7233    (TID 361)  INFO org.apache.spark.executor.Executor: Finished task 146.0 in stage 15.0 (TID 361). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.169 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 150.0 in stage 15.0 (TID 365) (95675304fa2d, executor driver, partition 150, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.169 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 146.0 in stage 15.0 (TID 361) in 15 ms on 95675304fa2d (executor driver) (148/200)\n",
      "10-20 14:45:01.169 172.17.0.2:54325      7233    (TID 365)  INFO org.apache.spark.executor.Executor: Running task 150.0 in stage 15.0 (TID 365)\n",
      "10-20 14:45:01.168 172.17.0.2:54325      7233    (TID 364)  INFO org.apache.spark.executor.Executor: Running task 149.0 in stage 15.0 (TID 364)\n",
      "10-20 14:45:01.170 172.17.0.2:54325      7233    (TID 362)  INFO org.apache.spark.executor.Executor: Finished task 147.0 in stage 15.0 (TID 362). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.171 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 151.0 in stage 15.0 (TID 366) (95675304fa2d, executor driver, partition 151, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.172 172.17.0.2:54325      7233    (TID 366)  INFO org.apache.spark.executor.Executor: Running task 151.0 in stage 15.0 (TID 366)\n",
      "10-20 14:45:01.172 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 147.0 in stage 15.0 (TID 362) in 15 ms on 95675304fa2d (executor driver) (149/200)\n",
      "10-20 14:45:01.173 172.17.0.2:54325      7233    (TID 365)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.173 172.17.0.2:54325      7233    (TID 365)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.174 172.17.0.2:54325      7233    (TID 363)  INFO org.apache.spark.executor.Executor: Finished task 148.0 in stage 15.0 (TID 363). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.175 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 152.0 in stage 15.0 (TID 367) (95675304fa2d, executor driver, partition 152, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.175 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 148.0 in stage 15.0 (TID 363) in 13 ms on 95675304fa2d (executor driver) (150/200)\n",
      "10-20 14:45:01.176 172.17.0.2:54325      7233    (TID 365)  INFO org.apache.spark.executor.Executor: Finished task 150.0 in stage 15.0 (TID 365). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.176 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 153.0 in stage 15.0 (TID 368) (95675304fa2d, executor driver, partition 153, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.177 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 150.0 in stage 15.0 (TID 365) in 9 ms on 95675304fa2d (executor driver) (151/200)\n",
      "10-20 14:45:01.177 172.17.0.2:54325      7233    (TID 366)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.178 172.17.0.2:54325      7233    (TID 366)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.179 172.17.0.2:54325      7233    (TID 364)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.179 172.17.0.2:54325      7233    (TID 364)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.180 172.17.0.2:54325      7233    (TID 364)  INFO org.apache.spark.executor.Executor: Finished task 149.0 in stage 15.0 (TID 364). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.181 172.17.0.2:54325      7233    (TID 368)  INFO org.apache.spark.executor.Executor: Running task 153.0 in stage 15.0 (TID 368)\n",
      "10-20 14:45:01.182 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 154.0 in stage 15.0 (TID 369) (95675304fa2d, executor driver, partition 154, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.182 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 149.0 in stage 15.0 (TID 364) in 15 ms on 95675304fa2d (executor driver) (152/200)\n",
      "10-20 14:45:01.183 172.17.0.2:54325      7233    (TID 366)  INFO org.apache.spark.executor.Executor: Finished task 151.0 in stage 15.0 (TID 366). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.183 172.17.0.2:54325      7233    (TID 368)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.184 172.17.0.2:54325      7233    (TID 368)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.185 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 155.0 in stage 15.0 (TID 370) (95675304fa2d, executor driver, partition 155, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.185 172.17.0.2:54325      7233    (TID 367)  INFO org.apache.spark.executor.Executor: Running task 152.0 in stage 15.0 (TID 367)\n",
      "10-20 14:45:01.185 172.17.0.2:54325      7233    (TID 370)  INFO org.apache.spark.executor.Executor: Running task 155.0 in stage 15.0 (TID 370)\n",
      "10-20 14:45:01.185 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 151.0 in stage 15.0 (TID 366) in 14 ms on 95675304fa2d (executor driver) (153/200)\n",
      "10-20 14:45:01.187 172.17.0.2:54325      7233    (TID 367)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.188 172.17.0.2:54325      7233    (TID 367)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.189 172.17.0.2:54325      7233    (TID 370)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.189 172.17.0.2:54325      7233    (TID 370)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.190 172.17.0.2:54325      7233    (TID 367)  INFO org.apache.spark.executor.Executor: Finished task 152.0 in stage 15.0 (TID 367). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.192 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 156.0 in stage 15.0 (TID 371) (95675304fa2d, executor driver, partition 156, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.192 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 152.0 in stage 15.0 (TID 367) in 17 ms on 95675304fa2d (executor driver) (154/200)\n",
      "10-20 14:45:01.192 172.17.0.2:54325      7233    (TID 371)  INFO org.apache.spark.executor.Executor: Running task 156.0 in stage 15.0 (TID 371)\n",
      "10-20 14:45:01.190 172.17.0.2:54325      7233    (TID 369)  INFO org.apache.spark.executor.Executor: Running task 154.0 in stage 15.0 (TID 369)\n",
      "10-20 14:45:01.191 172.17.0.2:54325      7233    (TID 368)  INFO org.apache.spark.executor.Executor: Finished task 153.0 in stage 15.0 (TID 368). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.193 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 157.0 in stage 15.0 (TID 372) (95675304fa2d, executor driver, partition 157, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.193 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 153.0 in stage 15.0 (TID 368) in 17 ms on 95675304fa2d (executor driver) (155/200)\n",
      "10-20 14:45:01.193 172.17.0.2:54325      7233    (TID 370)  INFO org.apache.spark.executor.Executor: Finished task 155.0 in stage 15.0 (TID 370). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.196 172.17.0.2:54325      7233    (TID 371)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.196 172.17.0.2:54325      7233    (TID 371)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.197 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 158.0 in stage 15.0 (TID 373) (95675304fa2d, executor driver, partition 158, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.198 172.17.0.2:54325      7233    (TID 373)  INFO org.apache.spark.executor.Executor: Running task 158.0 in stage 15.0 (TID 373)\n",
      "10-20 14:45:01.198 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 155.0 in stage 15.0 (TID 370) in 13 ms on 95675304fa2d (executor driver) (156/200)\n",
      "10-20 14:45:01.198 172.17.0.2:54325      7233    (TID 371)  INFO org.apache.spark.executor.Executor: Finished task 156.0 in stage 15.0 (TID 371). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.198 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 159.0 in stage 15.0 (TID 374) (95675304fa2d, executor driver, partition 159, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.198 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 156.0 in stage 15.0 (TID 371) in 7 ms on 95675304fa2d (executor driver) (157/200)\n",
      "10-20 14:45:01.200 172.17.0.2:54325      7233    (TID 369)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.200 172.17.0.2:54325      7233    (TID 369)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.200 172.17.0.2:54325      7233    (TID 373)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.200 172.17.0.2:54325      7233    (TID 373)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.201 172.17.0.2:54325      7233    (TID 369)  INFO org.apache.spark.executor.Executor: Finished task 154.0 in stage 15.0 (TID 369). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.202 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 160.0 in stage 15.0 (TID 375) (95675304fa2d, executor driver, partition 160, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.202 172.17.0.2:54325      7233    (TID 373)  INFO org.apache.spark.executor.Executor: Finished task 158.0 in stage 15.0 (TID 373). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.202 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 154.0 in stage 15.0 (TID 369) in 20 ms on 95675304fa2d (executor driver) (158/200)\n",
      "10-20 14:45:01.202 172.17.0.2:54325      7233    (TID 375)  INFO org.apache.spark.executor.Executor: Running task 160.0 in stage 15.0 (TID 375)\n",
      "10-20 14:45:01.201 172.17.0.2:54325      7233    (TID 372)  INFO org.apache.spark.executor.Executor: Running task 157.0 in stage 15.0 (TID 372)\n",
      "10-20 14:45:01.201 172.17.0.2:54325      7233    (TID 374)  INFO org.apache.spark.executor.Executor: Running task 159.0 in stage 15.0 (TID 374)\n",
      "10-20 14:45:01.205 172.17.0.2:54325      7233    (TID 374)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.208 172.17.0.2:54325      7233    (TID 374)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:45:01.208 172.17.0.2:54325      7233    (TID 372)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.207 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 161.0 in stage 15.0 (TID 376) (95675304fa2d, executor driver, partition 161, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.206 172.17.0.2:54325      7233    (TID 375)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.210 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 158.0 in stage 15.0 (TID 373) in 13 ms on 95675304fa2d (executor driver) (159/200)\n",
      "10-20 14:45:01.210 172.17.0.2:54325      7233    (TID 375)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:01.210 172.17.0.2:54325      7233    (TID 376)  INFO org.apache.spark.executor.Executor: Running task 161.0 in stage 15.0 (TID 376)\n",
      "10-20 14:45:01.210 172.17.0.2:54325      7233    (TID 372)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:45:01.212 172.17.0.2:54325      7233    (TID 372)  INFO org.apache.spark.executor.Executor: Finished task 157.0 in stage 15.0 (TID 372). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.213 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 162.0 in stage 15.0 (TID 377) (95675304fa2d, executor driver, partition 162, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.213 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 157.0 in stage 15.0 (TID 372) in 20 ms on 95675304fa2d (executor driver) (160/200)\n",
      "10-20 14:45:01.213 172.17.0.2:54325      7233    (TID 377)  INFO org.apache.spark.executor.Executor: Running task 162.0 in stage 15.0 (TID 377)\n",
      "10-20 14:45:01.212 172.17.0.2:54325      7233    (TID 375)  INFO org.apache.spark.executor.Executor: Finished task 160.0 in stage 15.0 (TID 375). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.214 172.17.0.2:54325      7233    (TID 376)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.214 172.17.0.2:54325      7233    (TID 376)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.214 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 163.0 in stage 15.0 (TID 378) (95675304fa2d, executor driver, partition 163, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.214 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 160.0 in stage 15.0 (TID 375) in 12 ms on 95675304fa2d (executor driver) (161/200)\n",
      "10-20 14:45:01.215 172.17.0.2:54325      7233    (TID 374)  INFO org.apache.spark.executor.Executor: Finished task 159.0 in stage 15.0 (TID 374). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.215 172.17.0.2:54325      7233    (TID 376)  INFO org.apache.spark.executor.Executor: Finished task 161.0 in stage 15.0 (TID 376). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.217 172.17.0.2:54325      7233    (TID 378)  INFO org.apache.spark.executor.Executor: Running task 163.0 in stage 15.0 (TID 378)\n",
      "10-20 14:45:01.217 172.17.0.2:54325      7233    (TID 377)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.218 172.17.0.2:54325      7233    (TID 377)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.218 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 164.0 in stage 15.0 (TID 379) (95675304fa2d, executor driver, partition 164, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.219 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 159.0 in stage 15.0 (TID 374) in 20 ms on 95675304fa2d (executor driver) (162/200)\n",
      "10-20 14:45:01.219 172.17.0.2:54325      7233    (TID 379)  INFO org.apache.spark.executor.Executor: Running task 164.0 in stage 15.0 (TID 379)\n",
      "10-20 14:45:01.221 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 165.0 in stage 15.0 (TID 380) (95675304fa2d, executor driver, partition 165, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.221 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 161.0 in stage 15.0 (TID 376) in 14 ms on 95675304fa2d (executor driver) (163/200)\n",
      "10-20 14:45:01.222 172.17.0.2:54325      7233    (TID 380)  INFO org.apache.spark.executor.Executor: Running task 165.0 in stage 15.0 (TID 380)\n",
      "10-20 14:45:01.222 172.17.0.2:54325      7233    (TID 377)  INFO org.apache.spark.executor.Executor: Finished task 162.0 in stage 15.0 (TID 377). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.224 172.17.0.2:54325      7233    (TID 380)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.224 172.17.0.2:54325      7233    (TID 380)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.226 172.17.0.2:54325      7233    (TID 380)  INFO org.apache.spark.executor.Executor: Finished task 165.0 in stage 15.0 (TID 380). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.227 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 166.0 in stage 15.0 (TID 381) (95675304fa2d, executor driver, partition 166, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.227 172.17.0.2:54325      7233    (TID 381)  INFO org.apache.spark.executor.Executor: Running task 166.0 in stage 15.0 (TID 381)\n",
      "10-20 14:45:01.227 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 165.0 in stage 15.0 (TID 380) in 6 ms on 95675304fa2d (executor driver) (164/200)\n",
      "10-20 14:45:01.229 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 167.0 in stage 15.0 (TID 382) (95675304fa2d, executor driver, partition 167, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.229 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 162.0 in stage 15.0 (TID 377) in 17 ms on 95675304fa2d (executor driver) (165/200)\n",
      "10-20 14:45:01.230 172.17.0.2:54325      7233    (TID 382)  INFO org.apache.spark.executor.Executor: Running task 167.0 in stage 15.0 (TID 382)\n",
      "10-20 14:45:01.232 172.17.0.2:54325      7233    (TID 382)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.232 172.17.0.2:54325      7233    (TID 381)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.232 172.17.0.2:54325      7233    (TID 381)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.232 172.17.0.2:54325      7233    (TID 382)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.234 172.17.0.2:54325      7233    (TID 382)  INFO org.apache.spark.executor.Executor: Finished task 167.0 in stage 15.0 (TID 382). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.237 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 168.0 in stage 15.0 (TID 383) (95675304fa2d, executor driver, partition 168, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.237 172.17.0.2:54325      7233    (TID 383)  INFO org.apache.spark.executor.Executor: Running task 168.0 in stage 15.0 (TID 383)\n",
      "10-20 14:45:01.237 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 167.0 in stage 15.0 (TID 382) in 8 ms on 95675304fa2d (executor driver) (166/200)\n",
      "10-20 14:45:01.236 172.17.0.2:54325      7233    (TID 378)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.238 172.17.0.2:54325      7233    (TID 378)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.235 172.17.0.2:54325      7233    (TID 381)  INFO org.apache.spark.executor.Executor: Finished task 166.0 in stage 15.0 (TID 381). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.238 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 169.0 in stage 15.0 (TID 384) (95675304fa2d, executor driver, partition 169, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.239 172.17.0.2:54325      7233    (TID 384)  INFO org.apache.spark.executor.Executor: Running task 169.0 in stage 15.0 (TID 384)\n",
      "10-20 14:45:01.239 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 166.0 in stage 15.0 (TID 381) in 12 ms on 95675304fa2d (executor driver) (167/200)\n",
      "10-20 14:45:01.235 172.17.0.2:54325      7233    (TID 379)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.239 172.17.0.2:54325      7233    (TID 379)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:01.241 172.17.0.2:54325      7233    (TID 379)  INFO org.apache.spark.executor.Executor: Finished task 164.0 in stage 15.0 (TID 379). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.243 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 170.0 in stage 15.0 (TID 385) (95675304fa2d, executor driver, partition 170, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.243 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 164.0 in stage 15.0 (TID 379) in 25 ms on 95675304fa2d (executor driver) (168/200)\n",
      "10-20 14:45:01.243 172.17.0.2:54325      7233    (TID 383)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.243 172.17.0.2:54325      7233    (TID 383)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.244 172.17.0.2:54325      7233    (TID 385)  INFO org.apache.spark.executor.Executor: Running task 170.0 in stage 15.0 (TID 385)\n",
      "10-20 14:45:01.244 172.17.0.2:54325      7233    (TID 384)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.244 172.17.0.2:54325      7233    (TID 384)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.246 172.17.0.2:54325      7233    (TID 385)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.246 172.17.0.2:54325      7233    (TID 385)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.242 172.17.0.2:54325      7233    (TID 378)  INFO org.apache.spark.executor.Executor: Finished task 163.0 in stage 15.0 (TID 378). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.247 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 171.0 in stage 15.0 (TID 386) (95675304fa2d, executor driver, partition 171, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.248 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 163.0 in stage 15.0 (TID 378) in 34 ms on 95675304fa2d (executor driver) (169/200)\n",
      "10-20 14:45:01.248 172.17.0.2:54325      7233    (TID 386)  INFO org.apache.spark.executor.Executor: Running task 171.0 in stage 15.0 (TID 386)\n",
      "10-20 14:45:01.250 172.17.0.2:54325      7233    (TID 384)  INFO org.apache.spark.executor.Executor: Finished task 169.0 in stage 15.0 (TID 384). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.251 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 172.0 in stage 15.0 (TID 387) (95675304fa2d, executor driver, partition 172, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.251 172.17.0.2:54325      7233    (TID 387)  INFO org.apache.spark.executor.Executor: Running task 172.0 in stage 15.0 (TID 387)\n",
      "10-20 14:45:01.251 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 169.0 in stage 15.0 (TID 384) in 13 ms on 95675304fa2d (executor driver) (170/200)\n",
      "10-20 14:45:01.252 172.17.0.2:54325      7233    (TID 383)  INFO org.apache.spark.executor.Executor: Finished task 168.0 in stage 15.0 (TID 383). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.253 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 173.0 in stage 15.0 (TID 388) (95675304fa2d, executor driver, partition 173, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.253 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 168.0 in stage 15.0 (TID 383) in 16 ms on 95675304fa2d (executor driver) (171/200)\n",
      "10-20 14:45:01.253 172.17.0.2:54325      7233    (TID 388)  INFO org.apache.spark.executor.Executor: Running task 173.0 in stage 15.0 (TID 388)\n",
      "10-20 14:45:01.255 172.17.0.2:54325      7233    (TID 386)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.257 172.17.0.2:54325      7233    (TID 386)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:45:01.257 172.17.0.2:54325      7233    (TID 387)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.257 172.17.0.2:54325      7233    (TID 387)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.256 172.17.0.2:54325      7233    (TID 388)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.258 172.17.0.2:54325      7233    (TID 388)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.259 172.17.0.2:54325      7233    (TID 386)  INFO org.apache.spark.executor.Executor: Finished task 171.0 in stage 15.0 (TID 386). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.260 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 174.0 in stage 15.0 (TID 389) (95675304fa2d, executor driver, partition 174, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.260 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 171.0 in stage 15.0 (TID 386) in 13 ms on 95675304fa2d (executor driver) (172/200)\n",
      "10-20 14:45:01.259 172.17.0.2:54325      7233    (TID 388)  INFO org.apache.spark.executor.Executor: Finished task 173.0 in stage 15.0 (TID 388). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.261 172.17.0.2:54325      7233    (TID 389)  INFO org.apache.spark.executor.Executor: Running task 174.0 in stage 15.0 (TID 389)\n",
      "10-20 14:45:01.259 172.17.0.2:54325      7233    (TID 385)  INFO org.apache.spark.executor.Executor: Finished task 170.0 in stage 15.0 (TID 385). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.261 172.17.0.2:54325      7233    (TID 387)  INFO org.apache.spark.executor.Executor: Finished task 172.0 in stage 15.0 (TID 387). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.261 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 175.0 in stage 15.0 (TID 390) (95675304fa2d, executor driver, partition 175, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.262 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 170.0 in stage 15.0 (TID 385) in 20 ms on 95675304fa2d (executor driver) (173/200)\n",
      "10-20 14:45:01.262 172.17.0.2:54325      7233    (TID 390)  INFO org.apache.spark.executor.Executor: Running task 175.0 in stage 15.0 (TID 390)\n",
      "10-20 14:45:01.265 172.17.0.2:54325      7233    (TID 390)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.266 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 176.0 in stage 15.0 (TID 391) (95675304fa2d, executor driver, partition 176, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.265 172.17.0.2:54325      7233    (TID 389)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.266 172.17.0.2:54325      7233    (TID 389)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.266 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 173.0 in stage 15.0 (TID 388) in 13 ms on 95675304fa2d (executor driver) (174/200)\n",
      "10-20 14:45:01.268 172.17.0.2:54325      7233    (TID 391)  INFO org.apache.spark.executor.Executor: Running task 176.0 in stage 15.0 (TID 391)\n",
      "10-20 14:45:01.268 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 177.0 in stage 15.0 (TID 392) (95675304fa2d, executor driver, partition 177, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.268 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 172.0 in stage 15.0 (TID 387) in 18 ms on 95675304fa2d (executor driver) (175/200)\n",
      "10-20 14:45:01.269 172.17.0.2:54325      7233    (TID 392)  INFO org.apache.spark.executor.Executor: Running task 177.0 in stage 15.0 (TID 392)\n",
      "10-20 14:45:01.270 172.17.0.2:54325      7233    (TID 389)  INFO org.apache.spark.executor.Executor: Finished task 174.0 in stage 15.0 (TID 389). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.266 172.17.0.2:54325      7233    (TID 390)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.271 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 178.0 in stage 15.0 (TID 393) (95675304fa2d, executor driver, partition 178, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.271 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 174.0 in stage 15.0 (TID 389) in 11 ms on 95675304fa2d (executor driver) (176/200)\n",
      "10-20 14:45:01.271 172.17.0.2:54325      7233    (TID 393)  INFO org.apache.spark.executor.Executor: Running task 178.0 in stage 15.0 (TID 393)\n",
      "10-20 14:45:01.273 172.17.0.2:54325      7233    (TID 391)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.273 172.17.0.2:54325      7233    (TID 391)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.275 172.17.0.2:54325      7233    (TID 393)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.275 172.17.0.2:54325      7233    (TID 393)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.275 172.17.0.2:54325      7233    (TID 391)  INFO org.apache.spark.executor.Executor: Finished task 176.0 in stage 15.0 (TID 391). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.276 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 179.0 in stage 15.0 (TID 394) (95675304fa2d, executor driver, partition 179, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.276 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 176.0 in stage 15.0 (TID 391) in 11 ms on 95675304fa2d (executor driver) (177/200)\n",
      "10-20 14:45:01.276 172.17.0.2:54325      7233    (TID 394)  INFO org.apache.spark.executor.Executor: Running task 179.0 in stage 15.0 (TID 394)\n",
      "10-20 14:45:01.278 172.17.0.2:54325      7233    (TID 393)  INFO org.apache.spark.executor.Executor: Finished task 178.0 in stage 15.0 (TID 393). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.278 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 180.0 in stage 15.0 (TID 395) (95675304fa2d, executor driver, partition 180, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.278 172.17.0.2:54325      7233    (TID 395)  INFO org.apache.spark.executor.Executor: Running task 180.0 in stage 15.0 (TID 395)\n",
      "10-20 14:45:01.278 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 178.0 in stage 15.0 (TID 393) in 8 ms on 95675304fa2d (executor driver) (178/200)\n",
      "10-20 14:45:01.280 172.17.0.2:54325      7233    (TID 394)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.280 172.17.0.2:54325      7233    (TID 394)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.282 172.17.0.2:54325      7233    (TID 395)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.282 172.17.0.2:54325      7233    (TID 395)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.283 172.17.0.2:54325      7233    (TID 394)  INFO org.apache.spark.executor.Executor: Finished task 179.0 in stage 15.0 (TID 394). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.284 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 181.0 in stage 15.0 (TID 396) (95675304fa2d, executor driver, partition 181, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.284 172.17.0.2:54325      7233    (TID 396)  INFO org.apache.spark.executor.Executor: Running task 181.0 in stage 15.0 (TID 396)\n",
      "10-20 14:45:01.284 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 179.0 in stage 15.0 (TID 394) in 8 ms on 95675304fa2d (executor driver) (179/200)\n",
      "10-20 14:45:01.285 172.17.0.2:54325      7233    (TID 395)  INFO org.apache.spark.executor.Executor: Finished task 180.0 in stage 15.0 (TID 395). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.287 172.17.0.2:54325      7233    (TID 392)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.288 172.17.0.2:54325      7233    (TID 392)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.288 172.17.0.2:54325      7233    (TID 390)  INFO org.apache.spark.executor.Executor: Finished task 175.0 in stage 15.0 (TID 390). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.287 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 182.0 in stage 15.0 (TID 397) (95675304fa2d, executor driver, partition 182, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.289 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 180.0 in stage 15.0 (TID 395) in 11 ms on 95675304fa2d (executor driver) (180/200)\n",
      "10-20 14:45:01.289 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 183.0 in stage 15.0 (TID 398) (95675304fa2d, executor driver, partition 183, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.290 172.17.0.2:54325      7233    (TID 396)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.290 172.17.0.2:54325      7233    (TID 396)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.290 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 175.0 in stage 15.0 (TID 390) in 29 ms on 95675304fa2d (executor driver) (181/200)\n",
      "10-20 14:45:01.292 172.17.0.2:54325      7233    (TID 398)  INFO org.apache.spark.executor.Executor: Running task 183.0 in stage 15.0 (TID 398)\n",
      "10-20 14:45:01.292 172.17.0.2:54325      7233    (TID 397)  INFO org.apache.spark.executor.Executor: Running task 182.0 in stage 15.0 (TID 397)\n",
      "10-20 14:45:01.292 172.17.0.2:54325      7233    (TID 392)  INFO org.apache.spark.executor.Executor: Finished task 177.0 in stage 15.0 (TID 392). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.293 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 184.0 in stage 15.0 (TID 399) (95675304fa2d, executor driver, partition 184, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.293 172.17.0.2:54325      7233    (TID 396)  INFO org.apache.spark.executor.Executor: Finished task 181.0 in stage 15.0 (TID 396). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.294 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 177.0 in stage 15.0 (TID 392) in 26 ms on 95675304fa2d (executor driver) (182/200)\n",
      "10-20 14:45:01.294 172.17.0.2:54325      7233    (TID 399)  INFO org.apache.spark.executor.Executor: Running task 184.0 in stage 15.0 (TID 399)\n",
      "10-20 14:45:01.295 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 185.0 in stage 15.0 (TID 400) (95675304fa2d, executor driver, partition 185, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.295 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 181.0 in stage 15.0 (TID 396) in 11 ms on 95675304fa2d (executor driver) (183/200)\n",
      "10-20 14:45:01.298 172.17.0.2:54325      7233    (TID 399)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.299 172.17.0.2:54325      7233    (TID 398)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.299 172.17.0.2:54325      7233    (TID 398)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.298 172.17.0.2:54325      7233    (TID 400)  INFO org.apache.spark.executor.Executor: Running task 185.0 in stage 15.0 (TID 400)\n",
      "10-20 14:45:01.299 172.17.0.2:54325      7233    (TID 399)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:01.301 172.17.0.2:54325      7233    (TID 398)  INFO org.apache.spark.executor.Executor: Finished task 183.0 in stage 15.0 (TID 398). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.302 172.17.0.2:54325      7233    (TID 397)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.302 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 186.0 in stage 15.0 (TID 401) (95675304fa2d, executor driver, partition 186, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.302 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 183.0 in stage 15.0 (TID 398) in 13 ms on 95675304fa2d (executor driver) (184/200)\n",
      "10-20 14:45:01.303 172.17.0.2:54325      7233    (TID 401)  INFO org.apache.spark.executor.Executor: Running task 186.0 in stage 15.0 (TID 401)\n",
      "10-20 14:45:01.305 172.17.0.2:54325      7233    (TID 400)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.305 172.17.0.2:54325      7233    (TID 400)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.306 172.17.0.2:54325      7233    (TID 401)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.306 172.17.0.2:54325      7233    (TID 401)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.305 172.17.0.2:54325      7233    (TID 399)  INFO org.apache.spark.executor.Executor: Finished task 184.0 in stage 15.0 (TID 399). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.307 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 187.0 in stage 15.0 (TID 402) (95675304fa2d, executor driver, partition 187, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.307 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 184.0 in stage 15.0 (TID 399) in 14 ms on 95675304fa2d (executor driver) (185/200)\n",
      "10-20 14:45:01.308 172.17.0.2:54325      7233    (TID 402)  INFO org.apache.spark.executor.Executor: Running task 187.0 in stage 15.0 (TID 402)\n",
      "10-20 14:45:01.308 172.17.0.2:54325      7233    (TID 400)  INFO org.apache.spark.executor.Executor: Finished task 185.0 in stage 15.0 (TID 400). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.308 172.17.0.2:54325      7233    (TID 401)  INFO org.apache.spark.executor.Executor: Finished task 186.0 in stage 15.0 (TID 401). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.309 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 188.0 in stage 15.0 (TID 403) (95675304fa2d, executor driver, partition 188, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.309 172.17.0.2:54325      7233    (TID 397)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 14:45:01.309 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 185.0 in stage 15.0 (TID 400) in 15 ms on 95675304fa2d (executor driver) (186/200)\n",
      "10-20 14:45:01.309 172.17.0.2:54325      7233    (TID 403)  INFO org.apache.spark.executor.Executor: Running task 188.0 in stage 15.0 (TID 403)\n",
      "10-20 14:45:01.310 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 189.0 in stage 15.0 (TID 404) (95675304fa2d, executor driver, partition 189, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.311 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 186.0 in stage 15.0 (TID 401) in 9 ms on 95675304fa2d (executor driver) (187/200)\n",
      "10-20 14:45:01.312 172.17.0.2:54325      7233    (TID 404)  INFO org.apache.spark.executor.Executor: Running task 189.0 in stage 15.0 (TID 404)\n",
      "10-20 14:45:01.313 172.17.0.2:54325      7233    (TID 402)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.314 172.17.0.2:54325      7233    (TID 402)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.314 172.17.0.2:54325      7233    (TID 403)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.314 172.17.0.2:54325      7233    (TID 403)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.315 172.17.0.2:54325      7233    (TID 397)  INFO org.apache.spark.executor.Executor: Finished task 182.0 in stage 15.0 (TID 397). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.316 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 190.0 in stage 15.0 (TID 405) (95675304fa2d, executor driver, partition 190, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.317 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 182.0 in stage 15.0 (TID 397) in 31 ms on 95675304fa2d (executor driver) (188/200)\n",
      "10-20 14:45:01.317 172.17.0.2:54325      7233    (TID 405)  INFO org.apache.spark.executor.Executor: Running task 190.0 in stage 15.0 (TID 405)\n",
      "10-20 14:45:01.320 172.17.0.2:54325      7233    (TID 404)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.320 172.17.0.2:54325      7233    (TID 404)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.321 172.17.0.2:54325      7233    (TID 405)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.321 172.17.0.2:54325      7233    (TID 405)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.322 172.17.0.2:54325      7233    (TID 402)  INFO org.apache.spark.executor.Executor: Finished task 187.0 in stage 15.0 (TID 402). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.322 172.17.0.2:54325      7233    (TID 405)  INFO org.apache.spark.executor.Executor: Finished task 190.0 in stage 15.0 (TID 405). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.322 172.17.0.2:54325      7233    (TID 403)  INFO org.apache.spark.executor.Executor: Finished task 188.0 in stage 15.0 (TID 403). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.323 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 192.0 in stage 15.0 (TID 406) (95675304fa2d, executor driver, partition 192, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.335 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 187.0 in stage 15.0 (TID 402) in 28 ms on 95675304fa2d (executor driver) (189/200)\n",
      "10-20 14:45:01.335 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 190.0 in stage 15.0 (TID 405) in 19 ms on 95675304fa2d (executor driver) (190/200)\n",
      "10-20 14:45:01.335 172.17.0.2:54325      7233    (TID 406)  INFO org.apache.spark.executor.Executor: Running task 192.0 in stage 15.0 (TID 406)\n",
      "10-20 14:45:01.336 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 193.0 in stage 15.0 (TID 407) (95675304fa2d, executor driver, partition 193, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.336 172.17.0.2:54325      7233    (TID 404)  INFO org.apache.spark.executor.Executor: Finished task 189.0 in stage 15.0 (TID 404). 3875 bytes result sent to driver\n",
      "10-20 14:45:01.336 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 194.0 in stage 15.0 (TID 408) (95675304fa2d, executor driver, partition 194, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.336 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 195.0 in stage 15.0 (TID 409) (95675304fa2d, executor driver, partition 195, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.336 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 188.0 in stage 15.0 (TID 403) in 27 ms on 95675304fa2d (executor driver) (191/200)\n",
      "10-20 14:45:01.336 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 189.0 in stage 15.0 (TID 404) in 26 ms on 95675304fa2d (executor driver) (192/200)\n",
      "10-20 14:45:01.337 172.17.0.2:54325      7233    (TID 409)  INFO org.apache.spark.executor.Executor: Running task 195.0 in stage 15.0 (TID 409)\n",
      "10-20 14:45:01.338 172.17.0.2:54325      7233    (TID 406)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.338 172.17.0.2:54325      7233    (TID 406)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.338 172.17.0.2:54325      7233    (TID 407)  INFO org.apache.spark.executor.Executor: Running task 193.0 in stage 15.0 (TID 407)\n",
      "10-20 14:45:01.340 172.17.0.2:54325      7233    (TID 406)  INFO org.apache.spark.executor.Executor: Finished task 192.0 in stage 15.0 (TID 406). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.340 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 196.0 in stage 15.0 (TID 410) (95675304fa2d, executor driver, partition 196, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.340 172.17.0.2:54325      7233    (TID 410)  INFO org.apache.spark.executor.Executor: Running task 196.0 in stage 15.0 (TID 410)\n",
      "10-20 14:45:01.341 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 192.0 in stage 15.0 (TID 406) in 18 ms on 95675304fa2d (executor driver) (193/200)\n",
      "10-20 14:45:01.341 172.17.0.2:54325      7233    (TID 409)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.341 172.17.0.2:54325      7233    (TID 409)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.342 172.17.0.2:54325      7233    (TID 409)  INFO org.apache.spark.executor.Executor: Finished task 195.0 in stage 15.0 (TID 409). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.345 172.17.0.2:54325      7233    (TID 410)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.345 172.17.0.2:54325      7233    (TID 410)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.347 172.17.0.2:54325      7233    (TID 410)  INFO org.apache.spark.executor.Executor: Finished task 196.0 in stage 15.0 (TID 410). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.343 172.17.0.2:54325      7233    (TID 407)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.348 172.17.0.2:54325      7233    (TID 407)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:45:01.343 172.17.0.2:54325      7233    (TID 408)  INFO org.apache.spark.executor.Executor: Running task 194.0 in stage 15.0 (TID 408)\n",
      "10-20 14:45:01.345 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 197.0 in stage 15.0 (TID 411) (95675304fa2d, executor driver, partition 197, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.349 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 195.0 in stage 15.0 (TID 409) in 12 ms on 95675304fa2d (executor driver) (194/200)\n",
      "10-20 14:45:01.350 172.17.0.2:54325      7233    (TID 411)  INFO org.apache.spark.executor.Executor: Running task 197.0 in stage 15.0 (TID 411)\n",
      "10-20 14:45:01.352 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 198.0 in stage 15.0 (TID 412) (95675304fa2d, executor driver, partition 198, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.352 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 196.0 in stage 15.0 (TID 410) in 12 ms on 95675304fa2d (executor driver) (195/200)\n",
      "10-20 14:45:01.352 172.17.0.2:54325      7233    (TID 412)  INFO org.apache.spark.executor.Executor: Running task 198.0 in stage 15.0 (TID 412)\n",
      "10-20 14:45:01.354 172.17.0.2:54325      7233    (TID 412)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.354 172.17.0.2:54325      7233    (TID 412)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.355 172.17.0.2:54325      7233    (TID 411)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.355 172.17.0.2:54325      7233    (TID 411)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.356 172.17.0.2:54325      7233    (TID 407)  INFO org.apache.spark.executor.Executor: Finished task 193.0 in stage 15.0 (TID 407). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.356 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 199.0 in stage 15.0 (TID 413) (95675304fa2d, executor driver, partition 199, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:01.356 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 193.0 in stage 15.0 (TID 407) in 20 ms on 95675304fa2d (executor driver) (196/200)\n",
      "10-20 14:45:01.358 172.17.0.2:54325      7233    (TID 408)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.358 172.17.0.2:54325      7233    (TID 408)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.356 172.17.0.2:54325      7233    (TID 412)  INFO org.apache.spark.executor.Executor: Finished task 198.0 in stage 15.0 (TID 412). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.358 172.17.0.2:54325      7233    (TID 413)  INFO org.apache.spark.executor.Executor: Running task 199.0 in stage 15.0 (TID 413)\n",
      "10-20 14:45:01.359 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 198.0 in stage 15.0 (TID 412) in 8 ms on 95675304fa2d (executor driver) (197/200)\n",
      "10-20 14:45:01.358 172.17.0.2:54325      7233    (TID 411)  INFO org.apache.spark.executor.Executor: Finished task 197.0 in stage 15.0 (TID 411). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.360 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 197.0 in stage 15.0 (TID 411) in 15 ms on 95675304fa2d (executor driver) (198/200)\n",
      "10-20 14:45:01.361 172.17.0.2:54325      7233    (TID 408)  INFO org.apache.spark.executor.Executor: Finished task 194.0 in stage 15.0 (TID 408). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.362 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 194.0 in stage 15.0 (TID 408) in 26 ms on 95675304fa2d (executor driver) (199/200)\n",
      "10-20 14:45:01.363 172.17.0.2:54325      7233    (TID 413)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:01.364 172.17.0.2:54325      7233    (TID 413)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:01.365 172.17.0.2:54325      7233    (TID 413)  INFO org.apache.spark.executor.Executor: Finished task 199.0 in stage 15.0 (TID 413). 3832 bytes result sent to driver\n",
      "10-20 14:45:01.366 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 199.0 in stage 15.0 (TID 413) in 10 ms on 95675304fa2d (executor driver) (200/200)\n",
      "10-20 14:45:01.366 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:01.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 15 (toPandas at /tmp/ipykernel_7175/3328129577.py:1) finished in 0.831 s\n",
      "10-20 14:45:01.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:01.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "10-20 14:45:01.367 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 7 finished: toPandas at /tmp/ipykernel_7175/3328129577.py:1, took 1.215274 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0      1   6289\n",
       "1      0  19787"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupBy('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eead67-429f-443a-acfe-f4b3a777e1a3",
   "metadata": {},
   "source": [
    "###ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6499e814-2c77-4da0-b7a4-8d6ec0052e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:03.943 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:03.943 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:03.943 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:03.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 16.948089 ms\n",
      "10-20 14:45:04.055 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 31.345613 ms\n",
      "10-20 14:45:04.059 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:45:04.071 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:04.074 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 14:45:04.074 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:04.075 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 24 from head at Imputer.scala:169\n",
      "10-20 14:45:04.076 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:04.083 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on 95675304fa2d:39429 in memory (size: 17.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:04.116 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:169\n",
      "10-20 14:45:04.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 59 (head at Imputer.scala:169) as input to shuffle 8\n",
      "10-20 14:45:04.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 8 (head at Imputer.scala:169) with 1 output partitions\n",
      "10-20 14:45:04.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 17 (head at Imputer.scala:169)\n",
      "10-20 14:45:04.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "10-20 14:45:04.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 16)\n",
      "10-20 14:45:04.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[59] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 14:45:04.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 54.3 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.123 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 95675304fa2d:39429 (size: 22.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:04.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:04.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[59] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:04.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:04.125 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 414) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.125 172.17.0.2:54325      7233    (TID 414)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 16.0 (TID 414)\n",
      "10-20 14:45:04.135 172.17.0.2:54325      7233    (TID 414)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:04.431 172.17.0.2:54325      7233    (TID 414)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 16.0 (TID 414). 2689 bytes result sent to driver\n",
      "10-20 14:45:04.432 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 414) in 307 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:04.433 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:04.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 16 (head at Imputer.scala:169) finished in 0.314 s\n",
      "10-20 14:45:04.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:04.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:04.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 17)\n",
      "10-20 14:45:04.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:04.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[62] at head at Imputer.scala:169), which has no missing parents\n",
      "10-20 14:45:04.436 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 19.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.446 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 95675304fa2d:39429 (size: 7.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.447 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:04.447 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[62] at head at Imputer.scala:169) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:04.447 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:04.449 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 415) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.449 172.17.0.2:54325      7233    (TID 415)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 17.0 (TID 415)\n",
      "10-20 14:45:04.451 172.17.0.2:54325      7233    (TID 415)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:04.451 172.17.0.2:54325      7233    (TID 415)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:04.455 172.17.0.2:54325      7233    (TID 415)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 17.0 (TID 415). 2681 bytes result sent to driver\n",
      "10-20 14:45:04.456 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 415) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:04.456 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:04.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 17 (head at Imputer.scala:169) finished in 0.022 s\n",
      "10-20 14:45:04.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:04.458 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "10-20 14:45:04.458 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 8 finished: head at Imputer.scala:169, took 0.341928 s\n",
      "10-20 14:45:04.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.263051 ms\n",
      "10-20 14:45:04.536 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.408931 ms\n",
      "10-20 14:45:04.549 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 14:45:04.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 9 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 14:45:04.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 18 (head at Imputer.scala:258)\n",
      "10-20 14:45:04.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:04.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:04.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 14:45:04.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 10.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.574 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.574 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 95675304fa2d:39429 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:04.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:04.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:04.578 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 416) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.578 172.17.0.2:54325      7233    (TID 416)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 18.0 (TID 416)\n",
      "10-20 14:45:04.594 172.17.0.2:54325      7233    (TID 416)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 18.0 (TID 416). 1347 bytes result sent to driver\n",
      "10-20 14:45:04.595 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 416) in 19 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:04.595 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:04.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 18 (head at Imputer.scala:258) finished in 0.042 s\n",
      "10-20 14:45:04.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:04.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished\n",
      "10-20 14:45:04.597 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 9 finished: head at Imputer.scala:258, took 0.047258 s\n",
      "10-20 14:45:04.602 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 14:45:04.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 10 (head at Imputer.scala:258) with 3 output partitions\n",
      "10-20 14:45:04.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 19 (head at Imputer.scala:258)\n",
      "10-20 14:45:04.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:04.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:04.621 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[66] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 14:45:04.623 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 10.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:04.625 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 95675304fa2d:39429 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:04.633 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 3 missing tasks from ResultStage 19 (MapPartitionsRDD[66] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(1, 2, 3))\n",
      "10-20 14:45:04.633 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 19.0 with 3 tasks resource profile 0\n",
      "10-20 14:45:04.634 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 417) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.634 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 19.0 (TID 418) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4485 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.635 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 19.0 (TID 419) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4717 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.636 172.17.0.2:54325      7233    (TID 417)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 19.0 (TID 417)\n",
      "10-20 14:45:04.636 172.17.0.2:54325      7233    (TID 418)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 19.0 (TID 418)\n",
      "10-20 14:45:04.637 172.17.0.2:54325      7233    (TID 419)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 19.0 (TID 419)\n",
      "10-20 14:45:04.640 172.17.0.2:54325      7233    (TID 418)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 19.0 (TID 418). 1347 bytes result sent to driver\n",
      "10-20 14:45:04.641 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 19.0 (TID 418) in 7 ms on 95675304fa2d (executor driver) (1/3)\n",
      "10-20 14:45:04.647 172.17.0.2:54325      7233    (TID 417)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 19.0 (TID 417). 1347 bytes result sent to driver\n",
      "10-20 14:45:04.647 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 417) in 13 ms on 95675304fa2d (executor driver) (2/3)\n",
      "10-20 14:45:04.662 172.17.0.2:54325      7233    (TID 419)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 17.114182 ms\n",
      "10-20 14:45:04.664 172.17.0.2:54325      7233    (TID 419)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 19.0 (TID 419). 1400 bytes result sent to driver\n",
      "10-20 14:45:04.665 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 19.0 (TID 419) in 31 ms on 95675304fa2d (executor driver) (3/3)\n",
      "10-20 14:45:04.665 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:04.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 19 (head at Imputer.scala:258) finished in 0.043 s\n",
      "10-20 14:45:04.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:04.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished\n",
      "10-20 14:45:04.666 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 10 finished: head at Imputer.scala:258, took 0.064057 s\n",
      "10-20 14:45:04.671 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.841751 ms\n",
      "10-20 14:45:04.780 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:04.781 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:04.781 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:04.806 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.583835 ms\n",
      "10-20 14:45:04.809 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:04.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:04.839 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.840 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 29 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:04.841 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:04.864 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on 95675304fa2d:39429 in memory (size: 7.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.870 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:04.871 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 71 (collect at StringIndexer.scala:204) as input to shuffle 9\n",
      "10-20 14:45:04.871 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 11 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:04.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 21 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:04.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)\n",
      "10-20 14:45:04.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 20)\n",
      "10-20 14:45:04.883 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[71] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:04.896 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 14:45:04.897 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 433.8 MiB)\n",
      "10-20 14:45:04.897 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 95675304fa2d:39429 (size: 15.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.898 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:04.898 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[71] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:04.898 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:04.899 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 420) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:04.900 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 20.0 (TID 420)\n",
      "10-20 14:45:04.916 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:04.920 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on 95675304fa2d:39429 in memory (size: 22.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.937 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on 95675304fa2d:39429 in memory (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:04.956 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:04.964 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on 95675304fa2d:39429 in memory (size: 4.8 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:05.208 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.722276 ms\n",
      "10-20 14:45:05.218 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.532118 ms\n",
      "10-20 14:45:05.237 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 11.706969 ms\n",
      "10-20 14:45:05.294 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.354276 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:05.570 172.17.0.2:54325      7233    (TID 420)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 20.0 (TID 420). 2511 bytes result sent to driver\n",
      "10-20 14:45:05.573 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 420) in 674 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:05.574 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:05.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 20 (collect at StringIndexer.scala:204) finished in 0.690 s\n",
      "10-20 14:45:05.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:05.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:05.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 21)\n",
      "10-20 14:45:05.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:05.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[74] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:05.580 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:05.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:05.599 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:05.600 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:05.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[74] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:05.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:05.602 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 21.0 (TID 421) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:05.603 172.17.0.2:54325      7233    (TID 421)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 21.0 (TID 421)\n",
      "10-20 14:45:05.606 172.17.0.2:54325      7233    (TID 421)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:05.606 172.17.0.2:54325      7233    (TID 421)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:05.619 172.17.0.2:54325      7233    (TID 421)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.31609 ms\n",
      "10-20 14:45:05.660 172.17.0.2:54325      7233    (TID 421)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 21.0 (TID 421). 3904 bytes result sent to driver\n",
      "10-20 14:45:05.661 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 21.0 (TID 421) in 59 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:05.661 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:05.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 21 (collect at StringIndexer.scala:204) finished in 0.084 s\n",
      "10-20 14:45:05.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:05.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "10-20 14:45:05.661 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 11 finished: collect at StringIndexer.scala:204, took 0.790901 s\n",
      "10-20 14:45:05.818 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:05.819 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:05.819 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:05.841 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 10.339993 ms\n",
      "10-20 14:45:05.844 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:05.851 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:05.851 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:05.852 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 32 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:05.853 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:05.865 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:05.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 79 (collect at StringIndexer.scala:204) as input to shuffle 10\n",
      "10-20 14:45:05.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 12 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:05.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 23 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:05.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)\n",
      "10-20 14:45:05.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 22)\n",
      "10-20 14:45:05.868 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:05.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 14:45:05.871 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 14:45:05.871 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:05.873 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:05.873 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:05.873 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:05.874 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 422) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:05.874 172.17.0.2:54325      7233    (TID 422)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 22.0 (TID 422)\n",
      "10-20 14:45:05.881 172.17.0.2:54325      7233    (TID 422)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:05.893 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on 95675304fa2d:39429 in memory (size: 15.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:05.906 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:05.930 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.187 172.17.0.2:54325      7233    (TID 422)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 22.0 (TID 422). 2511 bytes result sent to driver\n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 422) in 314 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 22 (collect at StringIndexer.scala:204) finished in 0.319 s\n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 23)\n",
      "10-20 14:45:06.188 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:06.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[82] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:06.191 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:06.202 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:06.202 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:06.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:06.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[82] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:06.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:06.206 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 423) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:06.206 172.17.0.2:54325      7233    (TID 423)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 23.0 (TID 423)\n",
      "10-20 14:45:06.209 172.17.0.2:54325      7233    (TID 423)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:06.209 172.17.0.2:54325      7233    (TID 423)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:06.224 172.17.0.2:54325      7233    (TID 423)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 23.0 (TID 423). 3956 bytes result sent to driver\n",
      "10-20 14:45:06.224 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 423) in 19 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:06.224 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:06.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 23 (collect at StringIndexer.scala:204) finished in 0.035 s\n",
      "10-20 14:45:06.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:06.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished\n",
      "10-20 14:45:06.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 12 finished: collect at StringIndexer.scala:204, took 0.359696 s\n",
      "10-20 14:45:06.295 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:06.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:06.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:06.325 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 16.581998 ms\n",
      "10-20 14:45:06.329 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:06.337 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:06.338 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:06.339 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 35 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:06.340 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:06.383 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:06.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 87 (collect at StringIndexer.scala:204) as input to shuffle 11\n",
      "10-20 14:45:06.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 13 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:06.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 25 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:06.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)\n",
      "10-20 14:45:06.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 24)\n",
      "10-20 14:45:06.388 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[87] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:06.390 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 14:45:06.390 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 14:45:06.391 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:06.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:06.392 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[87] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:06.392 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:06.393 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 424) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:06.393 172.17.0.2:54325      7233    (TID 424)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 24.0 (TID 424)\n",
      "10-20 14:45:06.402 172.17.0.2:54325      7233    (TID 424)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:06.511 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:06.516 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:06.535 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.721 172.17.0.2:54325      7233    (TID 424)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 24.0 (TID 424). 2511 bytes result sent to driver\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 424) in 331 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 24 (collect at StringIndexer.scala:204) finished in 0.335 s\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 25)\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:06.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[90] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:06.725 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 26.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:06.725 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:06.726 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 95675304fa2d:39429 (size: 12.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:06.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:06.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[90] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:06.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:06.727 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 425) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:06.728 172.17.0.2:54325      7233    (TID 425)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 25.0 (TID 425)\n",
      "10-20 14:45:06.731 172.17.0.2:54325      7233    (TID 425)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:06.731 172.17.0.2:54325      7233    (TID 425)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:06.744 172.17.0.2:54325      7233    (TID 425)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 25.0 (TID 425). 3884 bytes result sent to driver\n",
      "10-20 14:45:06.745 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 425) in 18 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:06.745 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:06.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 25 (collect at StringIndexer.scala:204) finished in 0.021 s\n",
      "10-20 14:45:06.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:06.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished\n",
      "10-20 14:45:06.746 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 13 finished: collect at StringIndexer.scala:204, took 0.361938 s\n",
      "10-20 14:45:06.816 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:06.816 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:06.816 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:06.838 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.654613 ms\n",
      "10-20 14:45:06.843 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:06.857 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.859 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on 95675304fa2d:39429 in memory (size: 12.7 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.860 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 14:45:06.862 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.863 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 38 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:06.863 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.864 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:06.877 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:06.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 95 (collect at StringIndexer.scala:204) as input to shuffle 12\n",
      "10-20 14:45:06.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 14 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:06.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 27 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:06.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)\n",
      "10-20 14:45:06.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 26)\n",
      "10-20 14:45:06.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[95] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:06.880 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 35.3 KiB, free 434.2 MiB)\n",
      "10-20 14:45:06.881 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 434.2 MiB)\n",
      "10-20 14:45:06.882 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:06.883 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:06.883 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[95] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:06.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:06.885 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 426) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:06.885 172.17.0.2:54325      7233    (TID 426)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 26.0 (TID 426)\n",
      "10-20 14:45:06.894 172.17.0.2:54325      7233    (TID 426)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:07.171 172.17.0.2:54325      7233    (TID 426)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 26.0 (TID 426). 2468 bytes result sent to driver\n",
      "10-20 14:45:07.172 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 426) in 287 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:07.172 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:07.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 26 (collect at StringIndexer.scala:204) finished in 0.294 s\n",
      "10-20 14:45:07.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:07.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:07.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 27)\n",
      "10-20 14:45:07.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:07.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[98] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:07.175 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:07.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:07.185 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:07.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[98] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:07.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:07.186 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 427) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:07.188 172.17.0.2:54325      7233    (TID 427)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 27.0 (TID 427)\n",
      "10-20 14:45:07.190 172.17.0.2:54325      7233    (TID 427)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (789.0 B) non-empty blocks including 1 (789.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:07.191 172.17.0.2:54325      7233    (TID 427)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:07.203 172.17.0.2:54325      7233    (TID 427)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 27.0 (TID 427). 4046 bytes result sent to driver\n",
      "10-20 14:45:07.203 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 427) in 17 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:07.203 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:07.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 27 (collect at StringIndexer.scala:204) finished in 0.030 s\n",
      "10-20 14:45:07.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:07.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished\n",
      "10-20 14:45:07.205 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 14 finished: collect at StringIndexer.scala:204, took 0.327349 s\n",
      "10-20 14:45:07.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:07.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:07.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:07.319 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.651636 ms\n",
      "10-20 14:45:07.322 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.329 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.329 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.330 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 41 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:07.331 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:07.366 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:07.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 103 (collect at StringIndexer.scala:204) as input to shuffle 13\n",
      "10-20 14:45:07.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 15 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:07.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 29 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:07.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)\n",
      "10-20 14:45:07.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 28)\n",
      "10-20 14:45:07.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[103] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:07.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.371 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.372 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:07.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[103] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:07.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:07.374 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 428) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:07.374 172.17.0.2:54325      7233    (TID 428)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 28.0 (TID 428)\n",
      "10-20 14:45:07.387 172.17.0.2:54325      7233    (TID 428)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:07.608 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.619 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.625 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:07.664 172.17.0.2:54325      7233    (TID 428)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 28.0 (TID 428). 2511 bytes result sent to driver\n",
      "10-20 14:45:07.664 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 428) in 290 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 28 (collect at StringIndexer.scala:204) finished in 0.296 s\n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 29)\n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:07.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[106] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:07.667 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:07.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:07.679 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.680 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:07.680 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[106] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:07.680 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:07.681 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 429) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:07.682 172.17.0.2:54325      7233    (TID 429)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 29.0 (TID 429)\n",
      "10-20 14:45:07.685 172.17.0.2:54325      7233    (TID 429)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:07.686 172.17.0.2:54325      7233    (TID 429)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:07.699 172.17.0.2:54325      7233    (TID 429)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 29.0 (TID 429). 3855 bytes result sent to driver\n",
      "10-20 14:45:07.700 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 429) in 18 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:07.700 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:07.700 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 29 (collect at StringIndexer.scala:204) finished in 0.034 s\n",
      "10-20 14:45:07.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:07.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n",
      "10-20 14:45:07.701 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 15 finished: collect at StringIndexer.scala:204, took 0.334467 s\n",
      "10-20 14:45:07.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:07.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:07.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:07.796 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.673767 ms\n",
      "10-20 14:45:07.799 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.805 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.805 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.806 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 44 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:07.807 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:07.820 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:07.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 111 (collect at StringIndexer.scala:204) as input to shuffle 14\n",
      "10-20 14:45:07.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 16 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:07.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:07.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\n",
      "10-20 14:45:07.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 30)\n",
      "10-20 14:45:07.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[111] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:07.823 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.824 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 14:45:07.824 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:07.825 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:07.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[111] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:07.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:07.847 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 30.0 (TID 430) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:07.847 172.17.0.2:54325      7233    (TID 430)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 30.0 (TID 430)\n",
      "10-20 14:45:07.858 172.17.0.2:54325      7233    (TID 430)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:08.021 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.027 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.028 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.133 172.17.0.2:54325      7233    (TID 430)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 30.0 (TID 430). 2511 bytes result sent to driver\n",
      "10-20 14:45:08.134 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 30.0 (TID 430) in 287 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:08.134 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:08.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 30 (collect at StringIndexer.scala:204) finished in 0.313 s\n",
      "10-20 14:45:08.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:08.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:08.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 31)\n",
      "10-20 14:45:08.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:08.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[114] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:08.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:08.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:08.152 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.156 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:08.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[114] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:08.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:08.158 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 431) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:08.159 172.17.0.2:54325      7233    (TID 431)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 31.0 (TID 431)\n",
      "10-20 14:45:08.162 172.17.0.2:54325      7233    (TID 431)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:08.162 172.17.0.2:54325      7233    (TID 431)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:08.175 172.17.0.2:54325      7233    (TID 431)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 31.0 (TID 431). 3863 bytes result sent to driver\n",
      "10-20 14:45:08.175 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 431) in 17 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:08.175 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:08.176 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 31 (collect at StringIndexer.scala:204) finished in 0.039 s\n",
      "10-20 14:45:08.176 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:08.176 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished\n",
      "10-20 14:45:08.176 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 16 finished: collect at StringIndexer.scala:204, took 0.355321 s\n",
      "10-20 14:45:08.279 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:08.279 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:08.279 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:08.305 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.571983 ms\n",
      "10-20 14:45:08.308 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:08.340 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:08.340 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.341 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 47 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:08.342 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:08.356 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:08.357 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 119 (collect at StringIndexer.scala:204) as input to shuffle 15\n",
      "10-20 14:45:08.357 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 17 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:08.357 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 33 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:08.357 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)\n",
      "10-20 14:45:08.357 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 32)\n",
      "10-20 14:45:08.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[119] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:08.360 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "10-20 14:45:08.361 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 433.9 MiB)\n",
      "10-20 14:45:08.362 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:08.363 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[119] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:08.363 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:08.364 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 432) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:08.364 172.17.0.2:54325      7233    (TID 432)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 32.0 (TID 432)\n",
      "10-20 14:45:08.374 172.17.0.2:54325      7233    (TID 432)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:08.459 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.467 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.469 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.669 172.17.0.2:54325      7233    (TID 432)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 32.0 (TID 432). 2511 bytes result sent to driver\n",
      "10-20 14:45:08.670 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 432) in 307 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:08.670 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:08.671 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 32 (collect at StringIndexer.scala:204) finished in 0.312 s\n",
      "10-20 14:45:08.671 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:08.671 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:08.671 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 33)\n",
      "10-20 14:45:08.671 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:08.671 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[122] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:08.672 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:08.673 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:08.673 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:08.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:08.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[122] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:08.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:08.675 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 433) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:08.676 172.17.0.2:54325      7233    (TID 433)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 33.0 (TID 433)\n",
      "10-20 14:45:08.680 172.17.0.2:54325      7233    (TID 433)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:08.680 172.17.0.2:54325      7233    (TID 433)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:08.691 172.17.0.2:54325      7233    (TID 433)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 33.0 (TID 433). 3768 bytes result sent to driver\n",
      "10-20 14:45:08.692 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 433) in 17 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:08.692 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:08.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 33 (collect at StringIndexer.scala:204) finished in 0.021 s\n",
      "10-20 14:45:08.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:08.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "10-20 14:45:08.693 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 17 finished: collect at StringIndexer.scala:204, took 0.336789 s\n",
      "10-20 14:45:08.769 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:08.769 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:08.770 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:08.797 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.799 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.802 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.807 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 27.084481 ms\n",
      "10-20 14:45:08.809 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 14:45:08.826 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 14:45:08.827 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 50 from collect at StringIndexer.scala:204\n",
      "10-20 14:45:08.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:08.840 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at StringIndexer.scala:204\n",
      "10-20 14:45:08.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 127 (collect at StringIndexer.scala:204) as input to shuffle 16\n",
      "10-20 14:45:08.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 18 (collect at StringIndexer.scala:204) with 1 output partitions\n",
      "10-20 14:45:08.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at StringIndexer.scala:204)\n",
      "10-20 14:45:08.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\n",
      "10-20 14:45:08.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 34)\n",
      "10-20 14:45:08.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[127] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:08.843 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 35.3 KiB, free 434.2 MiB)\n",
      "10-20 14:45:08.844 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 434.2 MiB)\n",
      "10-20 14:45:08.844 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 95675304fa2d:39429 (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:08.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:08.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[127] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:08.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:08.846 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 34.0 (TID 434) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:08.846 172.17.0.2:54325      7233    (TID 434)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 34.0 (TID 434)\n",
      "10-20 14:45:08.855 172.17.0.2:54325      7233    (TID 434)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:09.163 172.17.0.2:54325      7233    (TID 434)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 34.0 (TID 434). 2511 bytes result sent to driver\n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 34.0 (TID 434) in 317 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 34 (collect at StringIndexer.scala:204) finished in 0.322 s\n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 35)\n",
      "10-20 14:45:09.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:09.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[130] at collect at StringIndexer.scala:204), which has no missing parents\n",
      "10-20 14:45:09.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 26.7 KiB, free 434.1 MiB)\n",
      "10-20 14:45:09.176 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.1 MiB)\n",
      "10-20 14:45:09.177 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 95675304fa2d:39429 (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:09.177 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:09.178 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[130] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:09.178 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:09.178 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 435) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:09.179 172.17.0.2:54325      7233    (TID 435)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 35.0 (TID 435)\n",
      "10-20 14:45:09.182 172.17.0.2:54325      7233    (TID 435)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (955.0 B) non-empty blocks including 1 (955.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:09.182 172.17.0.2:54325      7233    (TID 435)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:09.194 172.17.0.2:54325      7233    (TID 435)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 35.0 (TID 435). 4215 bytes result sent to driver\n",
      "10-20 14:45:09.194 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 435) in 16 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:09.194 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:09.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 35 (collect at StringIndexer.scala:204) finished in 0.030 s\n",
      "10-20 14:45:09.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:09.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "10-20 14:45:09.195 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 18 finished: collect at StringIndexer.scala:204, took 0.355520 s\n",
      "10-20 14:45:09.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:09.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:09.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:09.979 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 32.154003 ms\n",
      "10-20 14:45:09.981 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:10.006 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:10.007 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on 95675304fa2d:39429 in memory (size: 15.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:10.008 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:10.009 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on 95675304fa2d:39429 in memory (size: 12.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:10.009 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 53 from rdd at Predictor.scala:81\n",
      "10-20 14:45:10.010 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:10.109 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] Stage class: GBTClassifier\n",
      "10-20 14:45:10.110 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] Stage uid: GBTClassifier_5edea31ab14b\n",
      "10-20 14:45:10.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:45:10.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:45:10.226 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:45:10.344 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 72.449959 ms\n",
      "10-20 14:45:10.347 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:10.362 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:10.367 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 14:45:10.368 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:10.369 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 54 from rdd at Instrumentation.scala:62\n",
      "10-20 14:45:10.370 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:45:10.391 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "10-20 14:45:10.393 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"labelCol\":\"label\",\"featuresCol\":\"features\"}\n",
      "10-20 14:45:10.395 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"numClasses\":2}\n",
      "10-20 14:45:10.519 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: take at DecisionTreeMetadata.scala:119\n",
      "10-20 14:45:10.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 19 (take at DecisionTreeMetadata.scala:119) with 1 output partitions\n",
      "10-20 14:45:10.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 36 (take at DecisionTreeMetadata.scala:119)\n",
      "10-20 14:45:10.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:10.522 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:10.522 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[147] at map at DecisionTreeMetadata.scala:119), which has no missing parents\n",
      "10-20 14:45:10.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 130.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:10.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 42.3 KiB, free 433.8 MiB)\n",
      "10-20 14:45:10.546 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 95675304fa2d:39429 (size: 42.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:10.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:10.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[147] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:10.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:10.554 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 436) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:10.555 172.17.0.2:54325      7233    (TID 436)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 36.0 (TID 436)\n",
      "10-20 14:45:10.930 172.17.0.2:54325      7233    (TID 436)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 28.511842 ms\n",
      "10-20 14:45:10.933 172.17.0.2:54325      7233    (TID 436)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:11.466 172.17.0.2:54325      7233    (TID 436)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.954718 ms\n",
      "10-20 14:45:11.479 172.17.0.2:54325      7233    (TID 436)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.87621 ms\n",
      "10-20 14:45:11.495 172.17.0.2:54325      7233    (TID 436)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 36.0 (TID 436). 1839 bytes result sent to driver\n",
      "10-20 14:45:11.496 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 436) in 942 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:11.496 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:11.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 36 (take at DecisionTreeMetadata.scala:119) finished in 0.973 s\n",
      "10-20 14:45:11.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:11.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n",
      "10-20 14:45:11.497 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 19 finished: take at DecisionTreeMetadata.scala:119, took 0.976979 s\n",
      "10-20 14:45:11.508 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125\n",
      "10-20 14:45:11.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 20 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions\n",
      "10-20 14:45:11.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 37 (aggregate at DecisionTreeMetadata.scala:125)\n",
      "10-20 14:45:11.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:11.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:11.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[146] at retag at GradientBoostedTrees.scala:330), which has no missing parents\n",
      "10-20 14:45:11.512 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 131.1 KiB, free 433.7 MiB)\n",
      "10-20 14:45:11.537 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_55_piece0 on 95675304fa2d:39429 in memory (size: 42.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:11.537 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 42.2 KiB, free 433.7 MiB)\n",
      "10-20 14:45:11.539 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 95675304fa2d:39429 (size: 42.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:11.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:11.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[146] at retag at GradientBoostedTrees.scala:330) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:11.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:11.541 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 437) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:11.541 172.17.0.2:54325      7233    (TID 437)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 37.0 (TID 437)\n",
      "10-20 14:45:11.564 172.17.0.2:54325      7233    (TID 437)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:12.767 172.17.0.2:54325      7233    (TID 437)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 37.0 (TID 437). 1954 bytes result sent to driver\n",
      "10-20 14:45:12.768 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 437) in 1227 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:12.768 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:12.768 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 37 (aggregate at DecisionTreeMetadata.scala:125) finished in 1.259 s\n",
      "10-20 14:45:12.768 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:12.769 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished\n",
      "10-20 14:45:12.769 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 20 finished: aggregate at DecisionTreeMetadata.scala:125, took 1.260811 s\n",
      "10-20 14:45:12.856 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:1054\n",
      "10-20 14:45:12.859 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 149 (flatMap at RandomForest.scala:1039) as input to shuffle 17\n",
      "10-20 14:45:12.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 21 (collectAsMap at RandomForest.scala:1054) with 1 output partitions\n",
      "10-20 14:45:12.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 39 (collectAsMap at RandomForest.scala:1054)\n",
      "10-20 14:45:12.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)\n",
      "10-20 14:45:12.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 38)\n",
      "10-20 14:45:12.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[149] at flatMap at RandomForest.scala:1039), which has no missing parents\n",
      "10-20 14:45:12.868 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 137.6 KiB, free 433.7 MiB)\n",
      "10-20 14:45:12.877 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 433.7 MiB)\n",
      "10-20 14:45:12.878 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_56_piece0 on 95675304fa2d:39429 in memory (size: 42.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:12.879 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 95675304fa2d:39429 (size: 45.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:12.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:12.888 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[149] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:12.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:12.890 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 438) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:12.890 172.17.0.2:54325      7233    (TID 438)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 38.0 (TID 438)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:13.012 172.17.0.2:54325      7233    (TID 438)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:14.301 172.17.0.2:54325      7233    (TID 438)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 38.0 (TID 438). 2133 bytes result sent to driver\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 438) in 1413 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 38 (flatMap at RandomForest.scala:1039) finished in 1.441 s\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 39)\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:14.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[151] at map at RandomForest.scala:1054), which has no missing parents\n",
      "10-20 14:45:14.304 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.3 KiB, free 433.8 MiB)\n",
      "10-20 14:45:14.316 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 433.8 MiB)\n",
      "10-20 14:45:14.316 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 95675304fa2d:39429 (size: 5.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:14.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:14.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[151] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:14.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:14.319 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 39.0 (TID 439) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:14.319 172.17.0.2:54325      7233    (TID 439)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 39.0 (TID 439)\n",
      "10-20 14:45:14.323 172.17.0.2:54325      7233    (TID 439)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (99.6 KiB) non-empty blocks including 1 (99.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:14.323 172.17.0.2:54325      7233    (TID 439)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:14.366 172.17.0.2:54325      7233    (TID 439)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 39.0 (TID 439). 4489 bytes result sent to driver\n",
      "10-20 14:45:14.367 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 39.0 (TID 439) in 49 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:14.367 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:14.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 39 (collectAsMap at RandomForest.scala:1054) finished in 0.065 s\n",
      "10-20 14:45:14.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:14.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished\n",
      "10-20 14:45:14.368 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 21 finished: collectAsMap at RandomForest.scala:1054, took 1.511838 s\n",
      "10-20 14:45:14.371 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 6.4 KiB, free 433.8 MiB)\n",
      "10-20 14:45:14.372 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1030.0 B, free 433.8 MiB)\n",
      "10-20 14:45:14.372 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 95675304fa2d:39429 (size: 1030.0 B, free: 434.3 MiB)\n",
      "10-20 14:45:14.373 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 59 from broadcast at GradientBoostedTrees.scala:339\n",
      "10-20 14:45:14.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"numFeatures\":106}\n",
      "10-20 14:45:14.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"numClasses\":0}\n",
      "10-20 14:45:14.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"numExamples\":26076}\n",
      "10-20 14:45:14.402 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"sumOfWeights\":26076.0}\n",
      "10-20 14:45:14.409 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 40.0 B, free 433.8 MiB)\n",
      "10-20 14:45:14.409 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 101.0 B, free 433.8 MiB)\n",
      "10-20 14:45:14.410 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 434.3 MiB)\n",
      "10-20 14:45:14.410 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 60 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:14.435 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:14.435 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 157 (mapPartitions at RandomForest.scala:644) as input to shuffle 18\n",
      "10-20 14:45:14.436 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 22 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:14.436 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 41 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:14.436 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)\n",
      "10-20 14:45:14.436 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 40)\n",
      "10-20 14:45:14.439 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[157] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:14.448 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 140.5 KiB, free 433.7 MiB)\n",
      "10-20 14:45:14.451 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 46.1 KiB, free 433.6 MiB)\n",
      "10-20 14:45:14.451 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 95675304fa2d:39429 (size: 46.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:14.452 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:14.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[157] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:14.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:14.456 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 440) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5118 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:14.457 172.17.0.2:54325      7233    (TID 440)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 40.0 (TID 440)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:14.537 172.17.0.2:54325      7233    (TID 440)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:45:14.674 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on 95675304fa2d:39429 in memory (size: 45.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:14.675 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_58_piece0 on 95675304fa2d:39429 in memory (size: 5.0 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:15.339 172.17.0.2:54325      7233    (TID 440)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_152_0 stored as values in memory (estimated size 11.8 MiB, free 422.0 MiB)\n",
      "10-20 14:45:15.339 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_152_0 in memory on 95675304fa2d:39429 (size: 11.8 MiB, free: 422.5 MiB)\n",
      "10-20 14:45:15.343 172.17.0.2:54325      7233    (TID 440)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:15.366 172.17.0.2:54325      7233    (TID 440)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_154_0 stored as values in memory (estimated size 101.9 KiB, free 421.9 MiB)\n",
      "10-20 14:45:15.366 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_154_0 in memory on 95675304fa2d:39429 (size: 101.9 KiB, free: 422.4 MiB)\n",
      "10-20 14:45:15.422 172.17.0.2:54325      7233    (TID 440)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 40.0 (TID 440). 2133 bytes result sent to driver\n",
      "10-20 14:45:15.423 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 440) in 969 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.423 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.424 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 40 (mapPartitions at RandomForest.scala:644) finished in 0.984 s\n",
      "10-20 14:45:15.424 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:15.424 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:15.424 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 41)\n",
      "10-20 14:45:15.424 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:15.425 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[159] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:15.427 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 6.0 KiB, free 421.9 MiB)\n",
      "10-20 14:45:15.437 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 421.9 MiB)\n",
      "10-20 14:45:15.438 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 422.4 MiB)\n",
      "10-20 14:45:15.439 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[159] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.442 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 441) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.443 172.17.0.2:54325      7233    (TID 441)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 41.0 (TID 441)\n",
      "10-20 14:45:15.447 172.17.0.2:54325      7233    (TID 441)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (7.6 KiB) non-empty blocks including 1 (7.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:15.447 172.17.0.2:54325      7233    (TID 441)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:15.588 172.17.0.2:54325      7233    (TID 441)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 41.0 (TID 441). 2339 bytes result sent to driver\n",
      "10-20 14:45:15.590 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 441) in 148 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.590 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.591 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 41 (collectAsMap at RandomForest.scala:663) finished in 0.166 s\n",
      "10-20 14:45:15.592 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:15.592 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished\n",
      "10-20 14:45:15.592 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 22 finished: collectAsMap at RandomForest.scala:663, took 1.157035 s\n",
      "10-20 14:45:15.596 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(60) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:15.597 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_60_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 422.4 MiB)\n",
      "10-20 14:45:15.601 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 40.0 B, free 421.9 MiB)\n",
      "10-20 14:45:15.603 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 101.0 B, free 421.9 MiB)\n",
      "10-20 14:45:15.604 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 422.4 MiB)\n",
      "10-20 14:45:15.605 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 63 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:15.622 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:15.623 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 160 (mapPartitions at RandomForest.scala:644) as input to shuffle 19\n",
      "10-20 14:45:15.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 23 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:15.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 43 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:15.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)\n",
      "10-20 14:45:15.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 42)\n",
      "10-20 14:45:15.627 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[160] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:15.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 141.4 KiB, free 421.8 MiB)\n",
      "10-20 14:45:15.636 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 46.6 KiB, free 421.7 MiB)\n",
      "10-20 14:45:15.636 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 95675304fa2d:39429 (size: 46.6 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.638 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[160] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.638 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.640 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 442) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5118 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.641 172.17.0.2:54325      7233    (TID 442)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 42.0 (TID 442)\n",
      "10-20 14:45:15.653 172.17.0.2:54325      7233    (TID 442)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:15.653 172.17.0.2:54325      7233    (TID 442)  INFO org.apache.spark.storage.BlockManager: Found block rdd_154_0 locally\n",
      "10-20 14:45:15.733 172.17.0.2:54325      7233    (TID 442)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 42.0 (TID 442). 2090 bytes result sent to driver\n",
      "10-20 14:45:15.734 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 442) in 94 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.735 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 42 (mapPartitions at RandomForest.scala:644) finished in 0.107 s\n",
      "10-20 14:45:15.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:15.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:15.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 43)\n",
      "10-20 14:45:15.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:15.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[162] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:15.738 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 6.5 KiB, free 421.7 MiB)\n",
      "10-20 14:45:15.739 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 421.7 MiB)\n",
      "10-20 14:45:15.740 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.741 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.741 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[162] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.742 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.743 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 43.0 (TID 443) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.744 172.17.0.2:54325      7233    (TID 443)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 43.0 (TID 443)\n",
      "10-20 14:45:15.747 172.17.0.2:54325      7233    (TID 443)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:15.747 172.17.0.2:54325      7233    (TID 443)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:15.762 172.17.0.2:54325      7233    (TID 443)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 43.0 (TID 443). 2285 bytes result sent to driver\n",
      "10-20 14:45:15.763 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 43.0 (TID 443) in 20 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.763 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 43 (collectAsMap at RandomForest.scala:663) finished in 0.026 s\n",
      "10-20 14:45:15.765 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:15.765 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n",
      "10-20 14:45:15.765 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 23 finished: collectAsMap at RandomForest.scala:663, took 0.142479 s\n",
      "10-20 14:45:15.766 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(63) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:15.767 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 40.0 B, free 421.7 MiB)\n",
      "10-20 14:45:15.767 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_63_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:15.768 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 101.0 B, free 421.7 MiB)\n",
      "10-20 14:45:15.768 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:15.770 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 66 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:15.785 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:15.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 163 (mapPartitions at RandomForest.scala:644) as input to shuffle 20\n",
      "10-20 14:45:15.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 24 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:15.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 45 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:15.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)\n",
      "10-20 14:45:15.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:15.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[163] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:15.794 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 142.0 KiB, free 421.6 MiB)\n",
      "10-20 14:45:15.796 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 46.8 KiB, free 421.5 MiB)\n",
      "10-20 14:45:15.797 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 95675304fa2d:39429 (size: 46.8 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[163] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.800 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 444) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5118 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.800 172.17.0.2:54325      7233    (TID 444)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 44.0 (TID 444)\n",
      "10-20 14:45:15.810 172.17.0.2:54325      7233    (TID 444)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:15.811 172.17.0.2:54325      7233    (TID 444)  INFO org.apache.spark.storage.BlockManager: Found block rdd_154_0 locally\n",
      "10-20 14:45:15.846 172.17.0.2:54325      7233    (TID 444)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 44.0 (TID 444). 2090 bytes result sent to driver\n",
      "10-20 14:45:15.847 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 444) in 47 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.847 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 44 (mapPartitions at RandomForest.scala:644) finished in 0.059 s\n",
      "10-20 14:45:15.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:15.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:15.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 45)\n",
      "10-20 14:45:15.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:15.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[165] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:15.849 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 6.7 KiB, free 421.5 MiB)\n",
      "10-20 14:45:15.858 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 421.5 MiB)\n",
      "10-20 14:45:15.858 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.859 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_65_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[165] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.860 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_64_piece0 on 95675304fa2d:39429 in memory (size: 46.6 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.861 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 445) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.863 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_62_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.863 172.17.0.2:54325      7233    (TID 445)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 45.0 (TID 445)\n",
      "10-20 14:45:15.866 172.17.0.2:54325      7233    (TID 445)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (16.3 KiB) non-empty blocks including 1 (16.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:15.866 172.17.0.2:54325      7233    (TID 445)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:15.880 172.17.0.2:54325      7233    (TID 445)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 45.0 (TID 445). 2702 bytes result sent to driver\n",
      "10-20 14:45:15.881 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 445) in 20 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.881 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.882 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 45 (collectAsMap at RandomForest.scala:663) finished in 0.033 s\n",
      "10-20 14:45:15.882 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:15.882 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "10-20 14:45:15.882 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 24 finished: collectAsMap at RandomForest.scala:663, took 0.096646 s\n",
      "10-20 14:45:15.883 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(66) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:15.884 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_66_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:15.886 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 40.0 B, free 421.7 MiB)\n",
      "10-20 14:45:15.887 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 101.0 B, free 421.7 MiB)\n",
      "10-20 14:45:15.888 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:15.888 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 69 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:15.904 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:15.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 166 (mapPartitions at RandomForest.scala:644) as input to shuffle 21\n",
      "10-20 14:45:15.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 25 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:15.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 47 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:15.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)\n",
      "10-20 14:45:15.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 46)\n",
      "10-20 14:45:15.907 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[166] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:15.912 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 143.2 KiB, free 421.6 MiB)\n",
      "10-20 14:45:15.913 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 421.5 MiB)\n",
      "10-20 14:45:15.913 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 95675304fa2d:39429 (size: 47.3 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.914 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.914 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[166] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.914 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.915 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 446) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5118 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.916 172.17.0.2:54325      7233    (TID 446)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 46.0 (TID 446)\n",
      "10-20 14:45:15.930 172.17.0.2:54325      7233    (TID 446)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:15.930 172.17.0.2:54325      7233    (TID 446)  INFO org.apache.spark.storage.BlockManager: Found block rdd_154_0 locally\n",
      "10-20 14:45:15.962 172.17.0.2:54325      7233    (TID 446)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 46.0 (TID 446). 2090 bytes result sent to driver\n",
      "10-20 14:45:15.964 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 446) in 49 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.964 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 46 (mapPartitions at RandomForest.scala:644) finished in 0.058 s\n",
      "10-20 14:45:15.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:15.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:15.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 47)\n",
      "10-20 14:45:15.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:15.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[168] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:15.967 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 7.1 KiB, free 421.5 MiB)\n",
      "10-20 14:45:15.967 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 421.5 MiB)\n",
      "10-20 14:45:15.968 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 95675304fa2d:39429 (size: 3.7 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:15.969 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:15.969 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[168] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:15.969 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:15.970 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 447) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:15.971 172.17.0.2:54325      7233    (TID 447)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 47.0 (TID 447)\n",
      "10-20 14:45:15.973 172.17.0.2:54325      7233    (TID 447)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (26.2 KiB) non-empty blocks including 1 (26.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:15.973 172.17.0.2:54325      7233    (TID 447)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:15.991 172.17.0.2:54325      7233    (TID 447)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 47.0 (TID 447). 3971 bytes result sent to driver\n",
      "10-20 14:45:15.992 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 447) in 22 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:15.992 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:15.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 47 (collectAsMap at RandomForest.scala:663) finished in 0.027 s\n",
      "10-20 14:45:15.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:15.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "10-20 14:45:15.995 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 25 finished: collectAsMap at RandomForest.scala:663, took 0.090868 s\n",
      "10-20 14:45:15.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(69) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:15.997 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_69_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:16.001 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 40.0 B, free 421.5 MiB)\n",
      "10-20 14:45:16.002 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 101.0 B, free 421.5 MiB)\n",
      "10-20 14:45:16.003 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:16.004 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 72 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.018 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 169 (mapPartitions at RandomForest.scala:644) as input to shuffle 22\n",
      "10-20 14:45:16.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 26 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 49 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "10-20 14:45:16.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 48)\n",
      "10-20 14:45:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[169] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 145.5 KiB, free 421.4 MiB)\n",
      "10-20 14:45:16.029 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 421.3 MiB)\n",
      "10-20 14:45:16.029 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 95675304fa2d:39429 (size: 48.1 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:16.030 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.030 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[169] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.030 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.031 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 48.0 (TID 448) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5118 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.032 172.17.0.2:54325      7233    (TID 448)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 48.0 (TID 448)\n",
      "10-20 14:45:16.054 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_61_piece0 on 95675304fa2d:39429 in memory (size: 46.1 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:16.063 172.17.0.2:54325      7233    (TID 448)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.063 172.17.0.2:54325      7233    (TID 448)  INFO org.apache.spark.storage.BlockManager: Found block rdd_154_0 locally\n",
      "10-20 14:45:16.102 172.17.0.2:54325      7233    (TID 448)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 48.0 (TID 448). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.103 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 48.0 (TID 448) in 71 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.103 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 48 (mapPartitions at RandomForest.scala:644) finished in 0.083 s\n",
      "10-20 14:45:16.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 49)\n",
      "10-20 14:45:16.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[171] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 7.5 KiB, free 421.5 MiB)\n",
      "10-20 14:45:16.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 421.5 MiB)\n",
      "10-20 14:45:16.114 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 422.3 MiB)\n",
      "10-20 14:45:16.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.115 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[171] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.115 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.115 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 449) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.116 172.17.0.2:54325      7233    (TID 449)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 49.0 (TID 449)\n",
      "10-20 14:45:16.118 172.17.0.2:54325      7233    (TID 449)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:16.118 172.17.0.2:54325      7233    (TID 449)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:16.134 172.17.0.2:54325      7233    (TID 449)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 49.0 (TID 449). 4839 bytes result sent to driver\n",
      "10-20 14:45:16.135 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 449) in 20 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.135 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 49 (collectAsMap at RandomForest.scala:663) finished in 0.024 s\n",
      "10-20 14:45:16.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:16.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "10-20 14:45:16.136 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 26 finished: collectAsMap at RandomForest.scala:663, took 0.118369 s\n",
      "10-20 14:45:16.137 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(72) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:16.138 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_72_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 422.3 MiB)\n",
      "10-20 14:45:16.140 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:16.141 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 0.002766918\n",
      "  total: 1.739405691\n",
      "  findBestSplits: 1.730377248\n",
      "  chooseSplits: 1.724503668\n",
      "10-20 14:45:16.147 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 154 from persistence list\n",
      "10-20 14:45:16.153 172.17.0.2:54325      7233   ad-pool-57  INFO org.apache.spark.storage.BlockManager: Removing RDD 154\n",
      "10-20 14:45:16.187 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:16.187 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:16.187 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:16.188 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:16.188 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 40.0 B, free 421.6 MiB)\n",
      "10-20 14:45:16.198 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 101.0 B, free 421.6 MiB)\n",
      "10-20 14:45:16.198 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 422.4 MiB)\n",
      "10-20 14:45:16.199 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 75 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.202 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_70_piece0 on 95675304fa2d:39429 in memory (size: 47.3 KiB, free: 422.4 MiB)\n",
      "10-20 14:45:16.203 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_68_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 422.4 MiB)\n",
      "10-20 14:45:16.206 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_73_piece0 on 95675304fa2d:39429 in memory (size: 48.1 KiB, free: 422.5 MiB)\n",
      "10-20 14:45:16.208 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_74_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 422.5 MiB)\n",
      "10-20 14:45:16.214 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_71_piece0 on 95675304fa2d:39429 in memory (size: 3.7 KiB, free: 422.5 MiB)\n",
      "10-20 14:45:16.216 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_67_piece0 on 95675304fa2d:39429 in memory (size: 46.8 KiB, free: 422.5 MiB)\n",
      "10-20 14:45:16.219 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 178 (mapPartitions at RandomForest.scala:644) as input to shuffle 23\n",
      "10-20 14:45:16.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 27 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 51 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.221 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)\n",
      "10-20 14:45:16.221 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 50)\n",
      "10-20 14:45:16.224 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[178] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 151.9 KiB, free 422.0 MiB)\n",
      "10-20 14:45:16.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 51.7 KiB, free 422.0 MiB)\n",
      "10-20 14:45:16.231 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 95675304fa2d:39429 (size: 51.7 KiB, free: 422.5 MiB)\n",
      "10-20 14:45:16.232 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.232 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[178] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.232 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.234 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 450) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5150 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.234 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 50.0 (TID 450)\n",
      "10-20 14:45:16.251 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.252 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.252 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.297 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_172_0 stored as values in memory (estimated size 1117.5 KiB, free 420.9 MiB)\n",
      "10-20 14:45:16.298 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_172_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 421.4 MiB)\n",
      "10-20 14:45:16.338 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_175_0 stored as values in memory (estimated size 914.4 KiB, free 420.0 MiB)\n",
      "10-20 14:45:16.339 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_175_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.361 172.17.0.2:54325      7233    (TID 450)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 50.0 (TID 450). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 450) in 129 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 50 (mapPartitions at RandomForest.scala:644) finished in 0.138 s\n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 51)\n",
      "10-20 14:45:16.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.363 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[180] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.364 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 6.0 KiB, free 420.0 MiB)\n",
      "10-20 14:45:16.365 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 420.0 MiB)\n",
      "10-20 14:45:16.365 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[180] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.367 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 451) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.368 172.17.0.2:54325      7233    (TID 451)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 51.0 (TID 451)\n",
      "10-20 14:45:16.371 172.17.0.2:54325      7233    (TID 451)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:16.371 172.17.0.2:54325      7233    (TID 451)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:16.375 172.17.0.2:54325      7233    (TID 451)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 51.0 (TID 451). 2296 bytes result sent to driver\n",
      "10-20 14:45:16.376 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 451) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.376 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.376 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 51 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:16.376 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:16.376 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "10-20 14:45:16.376 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 27 finished: collectAsMap at RandomForest.scala:663, took 0.157041 s\n",
      "10-20 14:45:16.377 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(75) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:16.378 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_75_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 420.5 MiB)\n",
      "10-20 14:45:16.378 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 40.0 B, free 420.0 MiB)\n",
      "10-20 14:45:16.384 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.0 MiB)\n",
      "10-20 14:45:16.385 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.5 MiB)\n",
      "10-20 14:45:16.385 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 78 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.425 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 181 (mapPartitions at RandomForest.scala:644) as input to shuffle 24\n",
      "10-20 14:45:16.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 28 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 53 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\n",
      "10-20 14:45:16.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 52)\n",
      "10-20 14:45:16.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[181] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.432 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 152.5 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 52.0 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.433 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 95675304fa2d:39429 (size: 52.0 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[181] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.435 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 52.0 (TID 452) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5150 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.436 172.17.0.2:54325      7233    (TID 452)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 52.0 (TID 452)\n",
      "10-20 14:45:16.445 172.17.0.2:54325      7233    (TID 452)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.446 172.17.0.2:54325      7233    (TID 452)  INFO org.apache.spark.storage.BlockManager: Found block rdd_175_0 locally\n",
      "10-20 14:45:16.472 172.17.0.2:54325      7233    (TID 452)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 52.0 (TID 452). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.472 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 52.0 (TID 452) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.473 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.474 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 52 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:16.474 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.474 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.474 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 53)\n",
      "10-20 14:45:16.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[183] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.476 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 6.5 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.477 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.479 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:16.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[183] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.481 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 453) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.482 172.17.0.2:54325      7233    (TID 453)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 53.0 (TID 453)\n",
      "10-20 14:45:16.485 172.17.0.2:54325      7233    (TID 453)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:16.485 172.17.0.2:54325      7233    (TID 453)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:16.489 172.17.0.2:54325      7233    (TID 453)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 53.0 (TID 453). 2584 bytes result sent to driver\n",
      "10-20 14:45:16.490 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 453) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.490 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.491 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 53 (collectAsMap at RandomForest.scala:663) finished in 0.015 s\n",
      "10-20 14:45:16.491 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:16.491 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "10-20 14:45:16.491 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 28 finished: collectAsMap at RandomForest.scala:663, took 0.066190 s\n",
      "10-20 14:45:16.491 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(78) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:16.492 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_78_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 420.4 MiB)\n",
      "10-20 14:45:16.493 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 40.0 B, free 419.8 MiB)\n",
      "10-20 14:45:16.494 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.8 MiB)\n",
      "10-20 14:45:16.494 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.4 MiB)\n",
      "10-20 14:45:16.495 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 81 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.508 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 184 (mapPartitions at RandomForest.scala:644) as input to shuffle 25\n",
      "10-20 14:45:16.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 29 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 55 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\n",
      "10-20 14:45:16.510 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\n",
      "10-20 14:45:16.511 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[184] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 153.1 KiB, free 419.6 MiB)\n",
      "10-20 14:45:16.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 52.3 KiB, free 419.6 MiB)\n",
      "10-20 14:45:16.524 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 95675304fa2d:39429 (size: 52.3 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:16.524 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.524 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[184] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.524 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.525 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_80_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:16.525 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 454) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5150 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.526 172.17.0.2:54325      7233    (TID 454)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 54.0 (TID 454)\n",
      "10-20 14:45:16.527 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_76_piece0 on 95675304fa2d:39429 in memory (size: 51.7 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.529 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_77_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.530 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_79_piece0 on 95675304fa2d:39429 in memory (size: 52.0 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.539 172.17.0.2:54325      7233    (TID 454)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.539 172.17.0.2:54325      7233    (TID 454)  INFO org.apache.spark.storage.BlockManager: Found block rdd_175_0 locally\n",
      "10-20 14:45:16.565 172.17.0.2:54325      7233    (TID 454)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 54.0 (TID 454). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.565 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 454) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 54 (mapPartitions at RandomForest.scala:644) finished in 0.054 s\n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 55)\n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[186] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 6.7 KiB, free 420.0 MiB)\n",
      "10-20 14:45:16.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 420.0 MiB)\n",
      "10-20 14:45:16.576 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[186] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.577 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.577 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 455) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.579 172.17.0.2:54325      7233    (TID 455)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 55.0 (TID 455)\n",
      "10-20 14:45:16.581 172.17.0.2:54325      7233    (TID 455)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:16.581 172.17.0.2:54325      7233    (TID 455)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:16.587 172.17.0.2:54325      7233    (TID 455)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 55.0 (TID 455). 3033 bytes result sent to driver\n",
      "10-20 14:45:16.587 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 455) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.587 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.588 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 55 (collectAsMap at RandomForest.scala:663) finished in 0.020 s\n",
      "10-20 14:45:16.588 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:16.588 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "10-20 14:45:16.588 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 29 finished: collectAsMap at RandomForest.scala:663, took 0.079349 s\n",
      "10-20 14:45:16.588 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(81) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:16.589 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_81_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 420.5 MiB)\n",
      "10-20 14:45:16.591 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 40.0 B, free 420.0 MiB)\n",
      "10-20 14:45:16.591 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.0 MiB)\n",
      "10-20 14:45:16.592 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.5 MiB)\n",
      "10-20 14:45:16.592 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 84 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.605 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 187 (mapPartitions at RandomForest.scala:644) as input to shuffle 26\n",
      "10-20 14:45:16.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 30 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 57 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)\n",
      "10-20 14:45:16.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 56)\n",
      "10-20 14:45:16.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.611 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 154.3 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.612 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 52.8 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.613 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 95675304fa2d:39429 (size: 52.8 KiB, free: 420.5 MiB)\n",
      "10-20 14:45:16.613 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.614 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.614 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.615 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 456) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5150 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.615 172.17.0.2:54325      7233    (TID 456)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 56.0 (TID 456)\n",
      "10-20 14:45:16.626 172.17.0.2:54325      7233    (TID 456)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.627 172.17.0.2:54325      7233    (TID 456)  INFO org.apache.spark.storage.BlockManager: Found block rdd_175_0 locally\n",
      "10-20 14:45:16.659 172.17.0.2:54325      7233    (TID 456)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 56.0 (TID 456). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.660 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 456) in 46 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.661 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 56 (mapPartitions at RandomForest.scala:644) finished in 0.054 s\n",
      "10-20 14:45:16.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 57)\n",
      "10-20 14:45:16.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.662 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[189] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 7.1 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.665 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:16.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[189] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.667 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 57.0 (TID 457) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.668 172.17.0.2:54325      7233    (TID 457)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 57.0 (TID 457)\n",
      "10-20 14:45:16.672 172.17.0.2:54325      7233    (TID 457)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:16.672 172.17.0.2:54325      7233    (TID 457)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:16.688 172.17.0.2:54325      7233    (TID 457)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 57.0 (TID 457). 3923 bytes result sent to driver\n",
      "10-20 14:45:16.690 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 57.0 (TID 457) in 23 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.690 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 57 (collectAsMap at RandomForest.scala:663) finished in 0.027 s\n",
      "10-20 14:45:16.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:16.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "10-20 14:45:16.691 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 30 finished: collectAsMap at RandomForest.scala:663, took 0.086275 s\n",
      "10-20 14:45:16.692 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(84) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:16.693 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_84_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 420.4 MiB)\n",
      "10-20 14:45:16.694 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 40.0 B, free 419.8 MiB)\n",
      "10-20 14:45:16.695 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.8 MiB)\n",
      "10-20 14:45:16.695 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.4 MiB)\n",
      "10-20 14:45:16.695 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 87 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.711 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 190 (mapPartitions at RandomForest.scala:644) as input to shuffle 27\n",
      "10-20 14:45:16.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 31 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 59 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)\n",
      "10-20 14:45:16.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 58)\n",
      "10-20 14:45:16.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.717 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 156.6 KiB, free 419.6 MiB)\n",
      "10-20 14:45:16.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 53.9 KiB, free 419.6 MiB)\n",
      "10-20 14:45:16.719 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 95675304fa2d:39429 (size: 53.9 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:16.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.721 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 458) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5150 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.722 172.17.0.2:54325      7233    (TID 458)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 58.0 (TID 458)\n",
      "10-20 14:45:16.731 172.17.0.2:54325      7233    (TID 458)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.731 172.17.0.2:54325      7233    (TID 458)  INFO org.apache.spark.storage.BlockManager: Found block rdd_175_0 locally\n",
      "10-20 14:45:16.759 172.17.0.2:54325      7233    (TID 458)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 58.0 (TID 458). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.760 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 458) in 39 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.760 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 58 (mapPartitions at RandomForest.scala:644) finished in 0.048 s\n",
      "10-20 14:45:16.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 59)\n",
      "10-20 14:45:16.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.762 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[192] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 7.9 KiB, free 419.6 MiB)\n",
      "10-20 14:45:16.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 419.6 MiB)\n",
      "10-20 14:45:16.764 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:16.765 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[192] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.767 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 459) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.768 172.17.0.2:54325      7233    (TID 459)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 59.0 (TID 459)\n",
      "10-20 14:45:16.770 172.17.0.2:54325      7233    (TID 459)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:16.770 172.17.0.2:54325      7233    (TID 459)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:16.817 172.17.0.2:54325      7233    (TID 459)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 59.0 (TID 459). 5716 bytes result sent to driver\n",
      "10-20 14:45:16.818 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 459) in 51 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.818 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 59 (collectAsMap at RandomForest.scala:663) finished in 0.056 s\n",
      "10-20 14:45:16.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:16.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n",
      "10-20 14:45:16.819 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 31 finished: collectAsMap at RandomForest.scala:663, took 0.108070 s\n",
      "10-20 14:45:16.819 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(87) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:16.820 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:16.820 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.6485E-5\n",
      "  total: 0.633497989\n",
      "  findBestSplits: 0.630476553\n",
      "  chooseSplits: 0.629694394\n",
      "10-20 14:45:16.821 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_87_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 420.4 MiB)\n",
      "10-20 14:45:16.821 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 175 from persistence list\n",
      "10-20 14:45:16.822 172.17.0.2:54325      7233   ad-pool-43  INFO org.apache.spark.storage.BlockManager: Removing RDD 175\n",
      "10-20 14:45:16.836 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:16.836 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:16.836 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:16.836 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:16.837 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 40.0 B, free 420.5 MiB)\n",
      "10-20 14:45:16.837 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 101.0 B, free 420.5 MiB)\n",
      "10-20 14:45:16.838 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 421.3 MiB)\n",
      "10-20 14:45:16.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 90 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:16.853 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:16.854 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 200 (mapPartitions at RandomForest.scala:644) as input to shuffle 28\n",
      "10-20 14:45:16.854 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 32 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:16.854 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 61 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:16.854 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)\n",
      "10-20 14:45:16.854 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 60)\n",
      "10-20 14:45:16.855 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[200] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:16.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 159.8 KiB, free 420.3 MiB)\n",
      "10-20 14:45:16.873 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_83_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 421.3 MiB)\n",
      "10-20 14:45:16.874 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 56.2 KiB, free 420.3 MiB)\n",
      "10-20 14:45:16.875 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 95675304fa2d:39429 (size: 56.2 KiB, free: 421.2 MiB)\n",
      "10-20 14:45:16.876 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:16.877 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[200] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:16.877 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:16.877 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_88_piece0 on 95675304fa2d:39429 in memory (size: 53.9 KiB, free: 421.3 MiB)\n",
      "10-20 14:45:16.878 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_82_piece0 on 95675304fa2d:39429 in memory (size: 52.3 KiB, free: 421.3 MiB)\n",
      "10-20 14:45:16.880 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_85_piece0 on 95675304fa2d:39429 in memory (size: 52.8 KiB, free: 421.4 MiB)\n",
      "10-20 14:45:16.881 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 460) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5182 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:16.881 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 60.0 (TID 460)\n",
      "10-20 14:45:16.891 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_86_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 421.4 MiB)\n",
      "10-20 14:45:16.893 172.17.0.2:54325      7233   ad-pool-66  INFO org.apache.spark.storage.BlockManager: Removing RDD 175\n",
      "10-20 14:45:16.896 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.898 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.898 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_89_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 421.4 MiB)\n",
      "10-20 14:45:16.900 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:16.900 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.storage.BlockManager: Found block rdd_172_0 locally\n",
      "10-20 14:45:16.932 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_194_0 stored as values in memory (estimated size 1117.5 KiB, free 419.8 MiB)\n",
      "10-20 14:45:16.933 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_194_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:16.964 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_197_0 stored as values in memory (estimated size 914.4 KiB, free 418.9 MiB)\n",
      "10-20 14:45:16.964 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_197_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 419.4 MiB)\n",
      "10-20 14:45:16.987 172.17.0.2:54325      7233    (TID 460)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 60.0 (TID 460). 2090 bytes result sent to driver\n",
      "10-20 14:45:16.987 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 460) in 107 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:16.987 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:16.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 60 (mapPartitions at RandomForest.scala:644) finished in 0.132 s\n",
      "10-20 14:45:16.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:16.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:16.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 61)\n",
      "10-20 14:45:16.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:16.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[202] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:16.989 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 6.0 KiB, free 418.9 MiB)\n",
      "10-20 14:45:16.999 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 418.9 MiB)\n",
      "10-20 14:45:17.000 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 419.4 MiB)\n",
      "10-20 14:45:17.001 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.001 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[202] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.001 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.002 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 61.0 (TID 461) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.002 172.17.0.2:54325      7233    (TID 461)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 61.0 (TID 461)\n",
      "10-20 14:45:17.004 172.17.0.2:54325      7233    (TID 461)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.005 172.17.0.2:54325      7233    (TID 461)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.007 172.17.0.2:54325      7233    (TID 461)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 61.0 (TID 461). 2296 bytes result sent to driver\n",
      "10-20 14:45:17.008 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 61.0 (TID 461) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.008 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.009 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 61 (collectAsMap at RandomForest.scala:663) finished in 0.020 s\n",
      "10-20 14:45:17.009 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n",
      "10-20 14:45:17.010 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 32 finished: collectAsMap at RandomForest.scala:663, took 0.157033 s\n",
      "10-20 14:45:17.011 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(90) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.012 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 40.0 B, free 418.9 MiB)\n",
      "10-20 14:45:17.013 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.9 MiB)\n",
      "10-20 14:45:17.013 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_90_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 419.4 MiB)\n",
      "10-20 14:45:17.013 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 419.4 MiB)\n",
      "10-20 14:45:17.014 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 93 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.031 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.031 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 203 (mapPartitions at RandomForest.scala:644) as input to shuffle 29\n",
      "10-20 14:45:17.031 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 33 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.032 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 63 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.032 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)\n",
      "10-20 14:45:17.032 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 62)\n",
      "10-20 14:45:17.034 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[203] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.038 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 160.3 KiB, free 418.7 MiB)\n",
      "10-20 14:45:17.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 56.5 KiB, free 418.7 MiB)\n",
      "10-20 14:45:17.040 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 95675304fa2d:39429 (size: 56.5 KiB, free: 419.4 MiB)\n",
      "10-20 14:45:17.041 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.041 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[203] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.041 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.045 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 462) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5182 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.045 172.17.0.2:54325      7233    (TID 462)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 62.0 (TID 462)\n",
      "10-20 14:45:17.054 172.17.0.2:54325      7233    (TID 462)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.054 172.17.0.2:54325      7233    (TID 462)  INFO org.apache.spark.storage.BlockManager: Found block rdd_197_0 locally\n",
      "10-20 14:45:17.079 172.17.0.2:54325      7233    (TID 462)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 62.0 (TID 462). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.081 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 462) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.081 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.082 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 62 (mapPartitions at RandomForest.scala:644) finished in 0.048 s\n",
      "10-20 14:45:17.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 63)\n",
      "10-20 14:45:17.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[205] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.086 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 6.5 KiB, free 418.7 MiB)\n",
      "10-20 14:45:17.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 418.7 MiB)\n",
      "10-20 14:45:17.087 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.088 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.089 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[205] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.089 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.090 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 463) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.091 172.17.0.2:54325      7233    (TID 463)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 63.0 (TID 463)\n",
      "10-20 14:45:17.093 172.17.0.2:54325      7233    (TID 463)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.093 172.17.0.2:54325      7233    (TID 463)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.098 172.17.0.2:54325      7233    (TID 463)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 63.0 (TID 463). 2584 bytes result sent to driver\n",
      "10-20 14:45:17.099 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 463) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.099 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 63 (collectAsMap at RandomForest.scala:663) finished in 0.015 s\n",
      "10-20 14:45:17.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished\n",
      "10-20 14:45:17.101 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 33 finished: collectAsMap at RandomForest.scala:663, took 0.070035 s\n",
      "10-20 14:45:17.101 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(93) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.102 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_93_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 419.3 MiB)\n",
      "10-20 14:45:17.103 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 40.0 B, free 418.7 MiB)\n",
      "10-20 14:45:17.104 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.7 MiB)\n",
      "10-20 14:45:17.104 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 419.3 MiB)\n",
      "10-20 14:45:17.105 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 96 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.118 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 206 (mapPartitions at RandomForest.scala:644) as input to shuffle 30\n",
      "10-20 14:45:17.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 34 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 65 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)\n",
      "10-20 14:45:17.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 64)\n",
      "10-20 14:45:17.120 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[206] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 160.9 KiB, free 418.5 MiB)\n",
      "10-20 14:45:17.127 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 56.9 KiB, free 418.5 MiB)\n",
      "10-20 14:45:17.128 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 95675304fa2d:39429 (size: 56.9 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.129 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[206] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.131 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 464) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5182 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.132 172.17.0.2:54325      7233    (TID 464)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 64.0 (TID 464)\n",
      "10-20 14:45:17.142 172.17.0.2:54325      7233    (TID 464)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.143 172.17.0.2:54325      7233    (TID 464)  INFO org.apache.spark.storage.BlockManager: Found block rdd_197_0 locally\n",
      "10-20 14:45:17.172 172.17.0.2:54325      7233    (TID 464)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 64.0 (TID 464). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.173 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 464) in 42 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.173 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 64 (mapPartitions at RandomForest.scala:644) finished in 0.054 s\n",
      "10-20 14:45:17.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 65)\n",
      "10-20 14:45:17.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[208] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.177 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 6.7 KiB, free 418.5 MiB)\n",
      "10-20 14:45:17.178 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 418.5 MiB)\n",
      "10-20 14:45:17.178 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[208] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.180 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 465) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.181 172.17.0.2:54325      7233    (TID 465)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 65.0 (TID 465)\n",
      "10-20 14:45:17.184 172.17.0.2:54325      7233    (TID 465)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.185 172.17.0.2:54325      7233    (TID 465)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.221 172.17.0.2:54325      7233    (TID 465)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 65.0 (TID 465). 3033 bytes result sent to driver\n",
      "10-20 14:45:17.222 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 465) in 42 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.222 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 65 (collectAsMap at RandomForest.scala:663) finished in 0.047 s\n",
      "10-20 14:45:17.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "10-20 14:45:17.223 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 34 finished: collectAsMap at RandomForest.scala:663, took 0.105080 s\n",
      "10-20 14:45:17.224 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(96) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.225 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_96_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 419.3 MiB)\n",
      "10-20 14:45:17.227 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 40.0 B, free 418.5 MiB)\n",
      "10-20 14:45:17.227 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.5 MiB)\n",
      "10-20 14:45:17.228 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 419.3 MiB)\n",
      "10-20 14:45:17.229 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 99 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.243 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.243 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 209 (mapPartitions at RandomForest.scala:644) as input to shuffle 31\n",
      "10-20 14:45:17.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 35 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 67 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "10-20 14:45:17.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 66)\n",
      "10-20 14:45:17.245 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[209] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 162.1 KiB, free 418.3 MiB)\n",
      "10-20 14:45:17.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 57.5 KiB, free 418.2 MiB)\n",
      "10-20 14:45:17.253 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 95675304fa2d:39429 (size: 57.5 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:17.253 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.254 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[209] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.256 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 66.0 (TID 466) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5182 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.256 172.17.0.2:54325      7233    (TID 466)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 66.0 (TID 466)\n",
      "10-20 14:45:17.269 172.17.0.2:54325      7233    (TID 466)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.269 172.17.0.2:54325      7233    (TID 466)  INFO org.apache.spark.storage.BlockManager: Found block rdd_197_0 locally\n",
      "10-20 14:45:17.299 172.17.0.2:54325      7233    (TID 466)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 66.0 (TID 466). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.299 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 66.0 (TID 466) in 43 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.299 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 66 (mapPartitions at RandomForest.scala:644) finished in 0.055 s\n",
      "10-20 14:45:17.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 67)\n",
      "10-20 14:45:17.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.301 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[211] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.301 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.1 KiB, free 418.2 MiB)\n",
      "10-20 14:45:17.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 418.2 MiB)\n",
      "10-20 14:45:17.303 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:17.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.304 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[211] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.304 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.305 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 467) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.306 172.17.0.2:54325      7233    (TID 467)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 67.0 (TID 467)\n",
      "10-20 14:45:17.308 172.17.0.2:54325      7233    (TID 467)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.308 172.17.0.2:54325      7233    (TID 467)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.318 172.17.0.2:54325      7233    (TID 467)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 67.0 (TID 467). 3936 bytes result sent to driver\n",
      "10-20 14:45:17.319 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 467) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.319 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 67 (collectAsMap at RandomForest.scala:663) finished in 0.019 s\n",
      "10-20 14:45:17.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "10-20 14:45:17.321 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 35 finished: collectAsMap at RandomForest.scala:663, took 0.077733 s\n",
      "10-20 14:45:17.321 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(99) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.322 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_99_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 419.2 MiB)\n",
      "10-20 14:45:17.323 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 40.0 B, free 418.2 MiB)\n",
      "10-20 14:45:17.324 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.2 MiB)\n",
      "10-20 14:45:17.324 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 419.2 MiB)\n",
      "10-20 14:45:17.325 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 102 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.343 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 212 (mapPartitions at RandomForest.scala:644) as input to shuffle 32\n",
      "10-20 14:45:17.344 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 36 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.344 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 69 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.344 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)\n",
      "10-20 14:45:17.344 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 68)\n",
      "10-20 14:45:17.344 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[212] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.348 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 164.5 KiB, free 418.1 MiB)\n",
      "10-20 14:45:17.350 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 58.7 KiB, free 418.0 MiB)\n",
      "10-20 14:45:17.351 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 95675304fa2d:39429 (size: 58.7 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:17.359 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.359 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[212] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.359 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.360 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 468) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5182 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.361 172.17.0.2:54325      7233    (TID 468)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 68.0 (TID 468)\n",
      "10-20 14:45:17.380 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_91_piece0 on 95675304fa2d:39429 in memory (size: 56.2 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:17.381 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_101_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:17.382 172.17.0.2:54325      7233    (TID 468)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.382 172.17.0.2:54325      7233    (TID 468)  INFO org.apache.spark.storage.BlockManager: Found block rdd_197_0 locally\n",
      "10-20 14:45:17.382 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_94_piece0 on 95675304fa2d:39429 in memory (size: 56.5 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.384 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_98_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.387 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_95_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.390 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_100_piece0 on 95675304fa2d:39429 in memory (size: 57.5 KiB, free: 419.3 MiB)\n",
      "10-20 14:45:17.391 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_97_piece0 on 95675304fa2d:39429 in memory (size: 56.9 KiB, free: 419.4 MiB)\n",
      "10-20 14:45:17.392 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_92_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 419.4 MiB)\n",
      "10-20 14:45:17.413 172.17.0.2:54325      7233    (TID 468)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 68.0 (TID 468). 2133 bytes result sent to driver\n",
      "10-20 14:45:17.414 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 468) in 54 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.414 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 68 (mapPartitions at RandomForest.scala:644) finished in 0.070 s\n",
      "10-20 14:45:17.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 69)\n",
      "10-20 14:45:17.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[214] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.417 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 7.9 KiB, free 418.9 MiB)\n",
      "10-20 14:45:17.429 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 418.9 MiB)\n",
      "10-20 14:45:17.429 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 419.4 MiB)\n",
      "10-20 14:45:17.430 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.430 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[214] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.430 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.432 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 469) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.432 172.17.0.2:54325      7233    (TID 469)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 69.0 (TID 469)\n",
      "10-20 14:45:17.435 172.17.0.2:54325      7233    (TID 469)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.435 172.17.0.2:54325      7233    (TID 469)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.456 172.17.0.2:54325      7233    (TID 469)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 69.0 (TID 469). 5707 bytes result sent to driver\n",
      "10-20 14:45:17.457 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 469) in 25 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.457 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 69 (collectAsMap at RandomForest.scala:663) finished in 0.041 s\n",
      "10-20 14:45:17.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished\n",
      "10-20 14:45:17.458 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 36 finished: collectAsMap at RandomForest.scala:663, took 0.114435 s\n",
      "10-20 14:45:17.458 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(102) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.459 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:17.459 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.8457E-5\n",
      "  total: 0.62338157\n",
      "  findBestSplits: 0.620456514\n",
      "  chooseSplits: 0.619604689\n",
      "10-20 14:45:17.459 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 197 from persistence list\n",
      "10-20 14:45:17.460 172.17.0.2:54325      7233   ad-pool-40  INFO org.apache.spark.storage.BlockManager: Removing RDD 197\n",
      "10-20 14:45:17.460 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_102_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 420.3 MiB)\n",
      "10-20 14:45:17.472 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:17.472 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:17.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:17.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:17.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 40.0 B, free 419.8 MiB)\n",
      "10-20 14:45:17.474 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.8 MiB)\n",
      "10-20 14:45:17.474 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.3 MiB)\n",
      "10-20 14:45:17.474 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 105 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.487 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 222 (mapPartitions at RandomForest.scala:644) as input to shuffle 33\n",
      "10-20 14:45:17.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 37 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 71 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\n",
      "10-20 14:45:17.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 70)\n",
      "10-20 14:45:17.491 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[222] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 167.4 KiB, free 419.6 MiB)\n",
      "10-20 14:45:17.499 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 60.7 KiB, free 419.6 MiB)\n",
      "10-20 14:45:17.499 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 95675304fa2d:39429 (size: 60.7 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:17.499 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.500 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[222] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.500 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.501 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 70.0 (TID 470) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5214 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.501 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 70.0 (TID 470)\n",
      "10-20 14:45:17.511 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.511 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.511 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.512 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.storage.BlockManager: Found block rdd_194_0 locally\n",
      "10-20 14:45:17.543 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_216_0 stored as values in memory (estimated size 1117.5 KiB, free 418.5 MiB)\n",
      "10-20 14:45:17.543 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_216_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:17.571 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_219_0 stored as values in memory (estimated size 914.4 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.571 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_219_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.593 172.17.0.2:54325      7233    (TID 470)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 70.0 (TID 470). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 70.0 (TID 470) in 94 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 70 (mapPartitions at RandomForest.scala:644) finished in 0.102 s\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 71)\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[224] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.595 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 6.0 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.597 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.597 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[224] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.599 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 471) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.600 172.17.0.2:54325      7233    (TID 471)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 71.0 (TID 471)\n",
      "10-20 14:45:17.602 172.17.0.2:54325      7233    (TID 471)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.602 172.17.0.2:54325      7233    (TID 471)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.605 172.17.0.2:54325      7233    (TID 471)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 71.0 (TID 471). 2076 bytes result sent to driver\n",
      "10-20 14:45:17.606 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 471) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.606 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 71 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:17.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished\n",
      "10-20 14:45:17.607 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 37 finished: collectAsMap at RandomForest.scala:663, took 0.119161 s\n",
      "10-20 14:45:17.607 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(105) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.608 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:17.609 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:17.609 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_105_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:17.609 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:17.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 108 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.671 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_103_piece0 on 95675304fa2d:39429 in memory (size: 58.7 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.674 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.675 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 225 (mapPartitions at RandomForest.scala:644) as input to shuffle 34\n",
      "10-20 14:45:17.675 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 38 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.675 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 73 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.675 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\n",
      "10-20 14:45:17.675 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 72)\n",
      "10-20 14:45:17.677 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[225] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.681 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_106_piece0 on 95675304fa2d:39429 in memory (size: 60.7 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:17.683 172.17.0.2:54325      7233   d-pool-128  INFO org.apache.spark.storage.BlockManager: Removing RDD 197\n",
      "10-20 14:45:17.684 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_107_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:17.686 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_104_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:17.689 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 167.8 KiB, free 417.9 MiB)\n",
      "10-20 14:45:17.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 61.0 KiB, free 417.8 MiB)\n",
      "10-20 14:45:17.691 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 95675304fa2d:39429 (size: 61.0 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[225] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.695 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 472) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5214 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.695 172.17.0.2:54325      7233    (TID 472)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 72.0 (TID 472)\n",
      "10-20 14:45:17.706 172.17.0.2:54325      7233    (TID 472)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.707 172.17.0.2:54325      7233    (TID 472)  INFO org.apache.spark.storage.BlockManager: Found block rdd_219_0 locally\n",
      "10-20 14:45:17.732 172.17.0.2:54325      7233    (TID 472)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 72.0 (TID 472). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.733 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 472) in 39 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 72 (mapPartitions at RandomForest.scala:644) finished in 0.055 s\n",
      "10-20 14:45:17.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 73)\n",
      "10-20 14:45:17.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.734 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[227] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 6.5 KiB, free 417.8 MiB)\n",
      "10-20 14:45:17.735 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.8 MiB)\n",
      "10-20 14:45:17.736 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.737 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.737 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[227] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.737 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.738 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 473) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.739 172.17.0.2:54325      7233    (TID 473)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 73.0 (TID 473)\n",
      "10-20 14:45:17.741 172.17.0.2:54325      7233    (TID 473)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.742 172.17.0.2:54325      7233    (TID 473)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.747 172.17.0.2:54325      7233    (TID 473)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 73.0 (TID 473). 2584 bytes result sent to driver\n",
      "10-20 14:45:17.748 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 473) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.748 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.748 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 73 (collectAsMap at RandomForest.scala:663) finished in 0.014 s\n",
      "10-20 14:45:17.748 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.748 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished\n",
      "10-20 14:45:17.748 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 38 finished: collectAsMap at RandomForest.scala:663, took 0.073848 s\n",
      "10-20 14:45:17.749 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(108) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.749 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 40.0 B, free 417.8 MiB)\n",
      "10-20 14:45:17.750 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.8 MiB)\n",
      "10-20 14:45:17.750 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_108_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:17.750 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:17.751 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 111 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.764 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.765 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 228 (mapPartitions at RandomForest.scala:644) as input to shuffle 35\n",
      "10-20 14:45:17.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 39 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 75 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)\n",
      "10-20 14:45:17.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 74)\n",
      "10-20 14:45:17.767 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[228] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.777 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_112 stored as values in memory (estimated size 168.4 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.778 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 61.3 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.778 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on 95675304fa2d:39429 (size: 61.3 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.779 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.779 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[228] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.779 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.780 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 474) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5214 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.780 172.17.0.2:54325      7233    (TID 474)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 74.0 (TID 474)\n",
      "10-20 14:45:17.788 172.17.0.2:54325      7233    (TID 474)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.789 172.17.0.2:54325      7233    (TID 474)  INFO org.apache.spark.storage.BlockManager: Found block rdd_219_0 locally\n",
      "10-20 14:45:17.814 172.17.0.2:54325      7233    (TID 474)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 74.0 (TID 474). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.814 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 474) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.815 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.815 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 74 (mapPartitions at RandomForest.scala:644) finished in 0.047 s\n",
      "10-20 14:45:17.815 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.815 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.815 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 75)\n",
      "10-20 14:45:17.815 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[230] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_113 stored as values in memory (estimated size 6.7 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.832 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_109_piece0 on 95675304fa2d:39429 in memory (size: 61.0 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.833 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.8 MiB)\n",
      "10-20 14:45:17.833 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.833 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[230] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.834 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_110_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.838 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 75.0 (TID 475) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.838 172.17.0.2:54325      7233    (TID 475)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 75.0 (TID 475)\n",
      "10-20 14:45:17.841 172.17.0.2:54325      7233    (TID 475)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.841 172.17.0.2:54325      7233    (TID 475)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.846 172.17.0.2:54325      7233    (TID 475)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 75.0 (TID 475). 3068 bytes result sent to driver\n",
      "10-20 14:45:17.846 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 75.0 (TID 475) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.847 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 75 (collectAsMap at RandomForest.scala:663) finished in 0.032 s\n",
      "10-20 14:45:17.849 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.849 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished\n",
      "10-20 14:45:17.849 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 39 finished: collectAsMap at RandomForest.scala:663, took 0.084817 s\n",
      "10-20 14:45:17.850 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(111) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.850 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_111_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:17.851 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_114 stored as values in memory (estimated size 40.0 B, free 417.8 MiB)\n",
      "10-20 14:45:17.851 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.8 MiB)\n",
      "10-20 14:45:17.852 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:17.852 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 114 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.864 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 231 (mapPartitions at RandomForest.scala:644) as input to shuffle 36\n",
      "10-20 14:45:17.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 40 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 77 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)\n",
      "10-20 14:45:17.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 76)\n",
      "10-20 14:45:17.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[231] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.869 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_115 stored as values in memory (estimated size 169.7 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 61.9 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.870 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on 95675304fa2d:39429 (size: 61.9 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:17.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.873 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[231] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.873 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.875 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 476) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5214 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.877 172.17.0.2:54325      7233    (TID 476)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 76.0 (TID 476)\n",
      "10-20 14:45:17.888 172.17.0.2:54325      7233    (TID 476)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.888 172.17.0.2:54325      7233    (TID 476)  INFO org.apache.spark.storage.BlockManager: Found block rdd_219_0 locally\n",
      "10-20 14:45:17.915 172.17.0.2:54325      7233    (TID 476)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 76.0 (TID 476). 2090 bytes result sent to driver\n",
      "10-20 14:45:17.916 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 476) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.916 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.917 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 76 (mapPartitions at RandomForest.scala:644) finished in 0.052 s\n",
      "10-20 14:45:17.920 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:17.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:17.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 77)\n",
      "10-20 14:45:17.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:17.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[233] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:17.923 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_116 stored as values in memory (estimated size 7.1 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.924 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.6 MiB)\n",
      "10-20 14:45:17.925 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:17.925 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[233] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.930 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 477) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.931 172.17.0.2:54325      7233    (TID 477)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 77.0 (TID 477)\n",
      "10-20 14:45:17.934 172.17.0.2:54325      7233    (TID 477)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:17.934 172.17.0.2:54325      7233    (TID 477)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:17.943 172.17.0.2:54325      7233    (TID 477)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 77.0 (TID 477). 4006 bytes result sent to driver\n",
      "10-20 14:45:17.944 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 477) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:17.944 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:17.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 77 (collectAsMap at RandomForest.scala:663) finished in 0.021 s\n",
      "10-20 14:45:17.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:17.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished\n",
      "10-20 14:45:17.945 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 40 finished: collectAsMap at RandomForest.scala:663, took 0.080946 s\n",
      "10-20 14:45:17.946 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(114) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:17.946 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_114_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:17.948 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_117 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:17.948 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:17.949 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:17.950 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 117 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:17.963 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:17.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 234 (mapPartitions at RandomForest.scala:644) as input to shuffle 37\n",
      "10-20 14:45:17.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 41 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:17.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 79 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:17.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)\n",
      "10-20 14:45:17.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 78)\n",
      "10-20 14:45:17.966 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[234] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:17.971 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_118 stored as values in memory (estimated size 172.2 KiB, free 417.4 MiB)\n",
      "10-20 14:45:17.972 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 63.0 KiB, free 417.3 MiB)\n",
      "10-20 14:45:17.973 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on 95675304fa2d:39429 (size: 63.0 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:17.973 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:17.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[234] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:17.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:17.975 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 478) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5214 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:17.975 172.17.0.2:54325      7233    (TID 478)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 78.0 (TID 478)\n",
      "10-20 14:45:17.984 172.17.0.2:54325      7233    (TID 478)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:17.984 172.17.0.2:54325      7233    (TID 478)  INFO org.apache.spark.storage.BlockManager: Found block rdd_219_0 locally\n",
      "10-20 14:45:18.011 172.17.0.2:54325      7233    (TID 478)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 78.0 (TID 478). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.011 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 478) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.011 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 78 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:18.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 79)\n",
      "10-20 14:45:18.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[236] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.014 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_119 stored as values in memory (estimated size 7.9 KiB, free 417.3 MiB)\n",
      "10-20 14:45:18.015 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.3 MiB)\n",
      "10-20 14:45:18.015 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.016 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[236] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.045 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 79.0 (TID 479) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.046 172.17.0.2:54325      7233    (TID 479)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 79.0 (TID 479)\n",
      "10-20 14:45:18.048 172.17.0.2:54325      7233    (TID 479)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (82.3 KiB) non-empty blocks including 1 (82.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.048 172.17.0.2:54325      7233    (TID 479)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.068 172.17.0.2:54325      7233    (TID 479)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 79.0 (TID 479). 5847 bytes result sent to driver\n",
      "10-20 14:45:18.069 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 79.0 (TID 479) in 24 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.069 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 79 (collectAsMap at RandomForest.scala:663) finished in 0.057 s\n",
      "10-20 14:45:18.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished\n",
      "10-20 14:45:18.071 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 41 finished: collectAsMap at RandomForest.scala:663, took 0.107085 s\n",
      "10-20 14:45:18.071 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(117) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.073 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_117_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.073 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:18.073 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.3171E-5\n",
      "  total: 0.600544753\n",
      "  findBestSplits: 0.599071108\n",
      "  chooseSplits: 0.598158945\n",
      "10-20 14:45:18.074 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 219 from persistence list\n",
      "10-20 14:45:18.074 172.17.0.2:54325      7233   ad-pool-93  INFO org.apache.spark.storage.BlockManager: Removing RDD 219\n",
      "10-20 14:45:18.080 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 172 from persistence list\n",
      "10-20 14:45:18.081 172.17.0.2:54325      7233   d-pool-100  INFO org.apache.spark.storage.BlockManager: Removing RDD 172\n",
      "10-20 14:45:18.089 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:18.089 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:18.089 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:18.089 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:18.090 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_120 stored as values in memory (estimated size 40.0 B, free 419.3 MiB)\n",
      "10-20 14:45:18.091 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.3 MiB)\n",
      "10-20 14:45:18.091 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:18.091 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 120 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.112 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.113 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_116_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 244 (mapPartitions at RandomForest.scala:644) as input to shuffle 38\n",
      "10-20 14:45:18.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 42 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 81 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)\n",
      "10-20 14:45:18.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 80)\n",
      "10-20 14:45:18.116 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_118_piece0 on 95675304fa2d:39429 in memory (size: 63.0 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[244] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_121 stored as values in memory (estimated size 175.2 KiB, free 419.4 MiB)\n",
      "10-20 14:45:18.122 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_119_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 65.3 KiB, free 419.3 MiB)\n",
      "10-20 14:45:18.122 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on 95675304fa2d:39429 (size: 65.3 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.123 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_113_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[244] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.125 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 480) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.126 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_115_piece0 on 95675304fa2d:39429 in memory (size: 61.9 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.127 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 80.0 (TID 480)\n",
      "10-20 14:45:18.132 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_112_piece0 on 95675304fa2d:39429 in memory (size: 61.3 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:18.133 172.17.0.2:54325      7233   ad-pool-49  INFO org.apache.spark.storage.BlockManager: Removing RDD 219\n",
      "10-20 14:45:18.141 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.141 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.141 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.142 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.storage.BlockManager: Found block rdd_216_0 locally\n",
      "10-20 14:45:18.167 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_238_0 stored as values in memory (estimated size 1117.5 KiB, free 418.7 MiB)\n",
      "10-20 14:45:18.168 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_238_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:18.193 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_241_0 stored as values in memory (estimated size 914.4 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.193 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_241_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.215 172.17.0.2:54325      7233    (TID 480)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 80.0 (TID 480). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.216 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 480) in 91 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.216 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 80 (mapPartitions at RandomForest.scala:644) finished in 0.099 s\n",
      "10-20 14:45:18.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 81)\n",
      "10-20 14:45:18.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[246] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_122 stored as values in memory (estimated size 6.0 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.227 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.227 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.228 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.228 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[246] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.228 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.229 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 481) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.229 172.17.0.2:54325      7233    (TID 481)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 81.0 (TID 481)\n",
      "10-20 14:45:18.231 172.17.0.2:54325      7233    (TID 481)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.231 172.17.0.2:54325      7233    (TID 481)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.234 172.17.0.2:54325      7233    (TID 481)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 81.0 (TID 481). 2076 bytes result sent to driver\n",
      "10-20 14:45:18.235 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 481) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.235 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.235 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 81 (collectAsMap at RandomForest.scala:663) finished in 0.018 s\n",
      "10-20 14:45:18.235 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.236 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished\n",
      "10-20 14:45:18.236 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 42 finished: collectAsMap at RandomForest.scala:663, took 0.123900 s\n",
      "10-20 14:45:18.236 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(120) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.237 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_120_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:18.238 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_123 stored as values in memory (estimated size 40.0 B, free 417.8 MiB)\n",
      "10-20 14:45:18.239 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.8 MiB)\n",
      "10-20 14:45:18.239 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:18.240 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 123 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.251 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 247 (mapPartitions at RandomForest.scala:644) as input to shuffle 39\n",
      "10-20 14:45:18.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 43 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 83 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)\n",
      "10-20 14:45:18.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 82)\n",
      "10-20 14:45:18.253 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[247] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.257 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_124 stored as values in memory (estimated size 175.7 KiB, free 417.6 MiB)\n",
      "10-20 14:45:18.258 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 65.6 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.258 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on 95675304fa2d:39429 (size: 65.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.258 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[247] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.260 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 482) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.260 172.17.0.2:54325      7233    (TID 482)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 82.0 (TID 482)\n",
      "10-20 14:45:18.268 172.17.0.2:54325      7233    (TID 482)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.268 172.17.0.2:54325      7233    (TID 482)  INFO org.apache.spark.storage.BlockManager: Found block rdd_241_0 locally\n",
      "10-20 14:45:18.293 172.17.0.2:54325      7233    (TID 482)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 82.0 (TID 482). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.294 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 482) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.294 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 82 (mapPartitions at RandomForest.scala:644) finished in 0.042 s\n",
      "10-20 14:45:18.296 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.296 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.296 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 83)\n",
      "10-20 14:45:18.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[249] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.298 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_125 stored as values in memory (estimated size 6.5 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.299 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.299 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[249] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.301 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 483) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.302 172.17.0.2:54325      7233    (TID 483)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 83.0 (TID 483)\n",
      "10-20 14:45:18.304 172.17.0.2:54325      7233    (TID 483)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (19.7 KiB) non-empty blocks including 1 (19.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.304 172.17.0.2:54325      7233    (TID 483)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.307 172.17.0.2:54325      7233    (TID 483)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 83.0 (TID 483). 2584 bytes result sent to driver\n",
      "10-20 14:45:18.308 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 483) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.308 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 83 (collectAsMap at RandomForest.scala:663) finished in 0.012 s\n",
      "10-20 14:45:18.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished\n",
      "10-20 14:45:18.309 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 43 finished: collectAsMap at RandomForest.scala:663, took 0.057908 s\n",
      "10-20 14:45:18.310 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(123) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.311 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_126 stored as values in memory (estimated size 40.0 B, free 417.5 MiB)\n",
      "10-20 14:45:18.311 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.5 MiB)\n",
      "10-20 14:45:18.312 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_123_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.312 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.312 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 126 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.328 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.328 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 250 (mapPartitions at RandomForest.scala:644) as input to shuffle 40\n",
      "10-20 14:45:18.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 44 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 85 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\n",
      "10-20 14:45:18.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 84)\n",
      "10-20 14:45:18.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[250] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_127 stored as values in memory (estimated size 176.3 KiB, free 417.4 MiB)\n",
      "10-20 14:45:18.339 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 65.9 KiB, free 417.3 MiB)\n",
      "10-20 14:45:18.340 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on 95675304fa2d:39429 (size: 65.9 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[250] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.342 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 84.0 (TID 484) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.343 172.17.0.2:54325      7233    (TID 484)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 84.0 (TID 484)\n",
      "10-20 14:45:18.359 172.17.0.2:54325      7233    (TID 484)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.359 172.17.0.2:54325      7233    (TID 484)  INFO org.apache.spark.storage.BlockManager: Found block rdd_241_0 locally\n",
      "10-20 14:45:18.390 172.17.0.2:54325      7233    (TID 484)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 84.0 (TID 484). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 84.0 (TID 484) in 49 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 84 (mapPartitions at RandomForest.scala:644) finished in 0.062 s\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 85)\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[252] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.392 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_128 stored as values in memory (estimated size 6.7 KiB, free 417.3 MiB)\n",
      "10-20 14:45:18.393 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.3 MiB)\n",
      "10-20 14:45:18.393 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.394 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[252] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.395 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 485) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.396 172.17.0.2:54325      7233    (TID 485)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 85.0 (TID 485)\n",
      "10-20 14:45:18.399 172.17.0.2:54325      7233    (TID 485)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.399 172.17.0.2:54325      7233    (TID 485)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.404 172.17.0.2:54325      7233    (TID 485)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 85.0 (TID 485). 3033 bytes result sent to driver\n",
      "10-20 14:45:18.405 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 485) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.405 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 85 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:18.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished\n",
      "10-20 14:45:18.406 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 44 finished: collectAsMap at RandomForest.scala:663, took 0.078835 s\n",
      "10-20 14:45:18.407 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(126) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.408 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_129 stored as values in memory (estimated size 40.0 B, free 417.3 MiB)\n",
      "10-20 14:45:18.409 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_126_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.410 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.3 MiB)\n",
      "10-20 14:45:18.410 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.411 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 129 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.442 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 253 (mapPartitions at RandomForest.scala:644) as input to shuffle 41\n",
      "10-20 14:45:18.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 45 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 87 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)\n",
      "10-20 14:45:18.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 86)\n",
      "10-20 14:45:18.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[253] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.452 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_130 stored as values in memory (estimated size 177.5 KiB, free 417.1 MiB)\n",
      "10-20 14:45:18.454 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 66.4 KiB, free 417.1 MiB)\n",
      "10-20 14:45:18.455 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on 95675304fa2d:39429 (size: 66.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:18.456 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.456 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[253] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.456 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.457 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 486) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.458 172.17.0.2:54325      7233    (TID 486)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 86.0 (TID 486)\n",
      "10-20 14:45:18.466 172.17.0.2:54325      7233    (TID 486)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.466 172.17.0.2:54325      7233    (TID 486)  INFO org.apache.spark.storage.BlockManager: Found block rdd_241_0 locally\n",
      "10-20 14:45:18.493 172.17.0.2:54325      7233    (TID 486)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 86.0 (TID 486). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 486) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 86 (mapPartitions at RandomForest.scala:644) finished in 0.047 s\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 87)\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[255] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.496 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_131 stored as values in memory (estimated size 7.1 KiB, free 417.0 MiB)\n",
      "10-20 14:45:18.496 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.0 MiB)\n",
      "10-20 14:45:18.497 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:18.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[255] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.499 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 487) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.500 172.17.0.2:54325      7233    (TID 487)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 87.0 (TID 487)\n",
      "10-20 14:45:18.502 172.17.0.2:54325      7233    (TID 487)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.502 172.17.0.2:54325      7233    (TID 487)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.512 172.17.0.2:54325      7233    (TID 487)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 87.0 (TID 487). 4006 bytes result sent to driver\n",
      "10-20 14:45:18.512 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 487) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.513 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 87 (collectAsMap at RandomForest.scala:663) finished in 0.018 s\n",
      "10-20 14:45:18.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished\n",
      "10-20 14:45:18.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 45 finished: collectAsMap at RandomForest.scala:663, took 0.071072 s\n",
      "10-20 14:45:18.514 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(129) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.515 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_132 stored as values in memory (estimated size 40.0 B, free 417.0 MiB)\n",
      "10-20 14:45:18.516 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.0 MiB)\n",
      "10-20 14:45:18.516 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_129_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:18.516 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:18.516 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 132 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.531 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.532 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 256 (mapPartitions at RandomForest.scala:644) as input to shuffle 42\n",
      "10-20 14:45:18.533 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 46 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.533 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 89 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.533 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n",
      "10-20 14:45:18.533 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 88)\n",
      "10-20 14:45:18.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[256] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.538 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_133 stored as values in memory (estimated size 180.0 KiB, free 416.9 MiB)\n",
      "10-20 14:45:18.539 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 67.5 KiB, free 416.8 MiB)\n",
      "10-20 14:45:18.540 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on 95675304fa2d:39429 (size: 67.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:18.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[256] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.541 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 88.0 (TID 488) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.542 172.17.0.2:54325      7233    (TID 488)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 88.0 (TID 488)\n",
      "10-20 14:45:18.559 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_130_piece0 on 95675304fa2d:39429 in memory (size: 66.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:18.561 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_125_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:18.562 172.17.0.2:54325      7233    (TID 488)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.563 172.17.0.2:54325      7233    (TID 488)  INFO org.apache.spark.storage.BlockManager: Found block rdd_241_0 locally\n",
      "10-20 14:45:18.563 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_121_piece0 on 95675304fa2d:39429 in memory (size: 65.3 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.565 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_131_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.570 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_122_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.572 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_128_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.573 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_124_piece0 on 95675304fa2d:39429 in memory (size: 65.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.575 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_127_piece0 on 95675304fa2d:39429 in memory (size: 65.9 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.595 172.17.0.2:54325      7233    (TID 488)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 88.0 (TID 488). 2133 bytes result sent to driver\n",
      "10-20 14:45:18.596 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 88.0 (TID 488) in 55 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.596 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 88 (mapPartitions at RandomForest.scala:644) finished in 0.062 s\n",
      "10-20 14:45:18.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 89)\n",
      "10-20 14:45:18.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[258] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_134 stored as values in memory (estimated size 7.9 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.608 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.608 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.609 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.609 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[258] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.609 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.610 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 489) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.611 172.17.0.2:54325      7233    (TID 489)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 89.0 (TID 489)\n",
      "10-20 14:45:18.613 172.17.0.2:54325      7233    (TID 489)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.613 172.17.0.2:54325      7233    (TID 489)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.628 172.17.0.2:54325      7233    (TID 489)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 89.0 (TID 489). 5681 bytes result sent to driver\n",
      "10-20 14:45:18.629 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 489) in 19 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.629 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.629 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 89 (collectAsMap at RandomForest.scala:663) finished in 0.032 s\n",
      "10-20 14:45:18.629 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.629 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished\n",
      "10-20 14:45:18.629 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 46 finished: collectAsMap at RandomForest.scala:663, took 0.097800 s\n",
      "10-20 14:45:18.630 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(132) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.630 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:18.630 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.154E-5\n",
      "  total: 0.540888162\n",
      "  findBestSplits: 0.539282344\n",
      "  chooseSplits: 0.538686481\n",
      "10-20 14:45:18.630 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 241 from persistence list\n",
      "10-20 14:45:18.630 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_132_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:18.632 172.17.0.2:54325      7233   ad-pool-97  INFO org.apache.spark.storage.BlockManager: Removing RDD 241\n",
      "10-20 14:45:18.635 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 194 from persistence list\n",
      "10-20 14:45:18.635 172.17.0.2:54325      7233   d-pool-106  INFO org.apache.spark.storage.BlockManager: Removing RDD 194\n",
      "10-20 14:45:18.642 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:18.642 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:18.642 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:18.642 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:18.643 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_135 stored as values in memory (estimated size 40.0 B, free 419.8 MiB)\n",
      "10-20 14:45:18.643 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.8 MiB)\n",
      "10-20 14:45:18.643 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.3 MiB)\n",
      "10-20 14:45:18.644 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 135 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.656 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 266 (mapPartitions at RandomForest.scala:644) as input to shuffle 43\n",
      "10-20 14:45:18.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 47 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 91 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n",
      "10-20 14:45:18.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 90)\n",
      "10-20 14:45:18.658 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[266] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_136 stored as values in memory (estimated size 182.8 KiB, free 419.6 MiB)\n",
      "10-20 14:45:18.667 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 69.3 KiB, free 419.5 MiB)\n",
      "10-20 14:45:18.667 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on 95675304fa2d:39429 (size: 69.3 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:18.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[266] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.669 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.670 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 490) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.670 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 90.0 (TID 490)\n",
      "10-20 14:45:18.680 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.680 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.680 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.680 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.storage.BlockManager: Found block rdd_238_0 locally\n",
      "10-20 14:45:18.711 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_260_0 stored as values in memory (estimated size 1117.5 KiB, free 418.4 MiB)\n",
      "10-20 14:45:18.711 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_260_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:18.740 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_263_0 stored as values in memory (estimated size 914.4 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.741 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_263_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.765 172.17.0.2:54325      7233    (TID 490)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 90.0 (TID 490). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.765 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 490) in 96 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.765 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 90 (mapPartitions at RandomForest.scala:644) finished in 0.108 s\n",
      "10-20 14:45:18.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 91)\n",
      "10-20 14:45:18.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[268] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.767 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_137 stored as values in memory (estimated size 6.0 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.768 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.768 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[268] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.771 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 491) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.772 172.17.0.2:54325      7233    (TID 491)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 91.0 (TID 491)\n",
      "10-20 14:45:18.776 172.17.0.2:54325      7233    (TID 491)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.776 172.17.0.2:54325      7233    (TID 491)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.784 172.17.0.2:54325      7233    (TID 491)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 91.0 (TID 491). 2296 bytes result sent to driver\n",
      "10-20 14:45:18.785 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 491) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.785 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 91 (collectAsMap at RandomForest.scala:663) finished in 0.019 s\n",
      "10-20 14:45:18.787 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.787 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "10-20 14:45:18.787 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 47 finished: collectAsMap at RandomForest.scala:663, took 0.131321 s\n",
      "10-20 14:45:18.789 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(135) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.790 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_138 stored as values in memory (estimated size 40.0 B, free 417.5 MiB)\n",
      "10-20 14:45:18.790 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_135_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.791 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.5 MiB)\n",
      "10-20 14:45:18.791 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.791 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 138 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.828 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 269 (mapPartitions at RandomForest.scala:644) as input to shuffle 44\n",
      "10-20 14:45:18.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 48 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 93 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)\n",
      "10-20 14:45:18.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 92)\n",
      "10-20 14:45:18.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[269] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.844 172.17.0.2:54325      7233   d-pool-110  INFO org.apache.spark.storage.BlockManager: Removing RDD 241\n",
      "10-20 14:45:18.846 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_137_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.847 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_134_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_139 stored as values in memory (estimated size 183.3 KiB, free 417.4 MiB)\n",
      "10-20 14:45:18.849 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_136_piece0 on 95675304fa2d:39429 in memory (size: 69.3 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.850 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 69.6 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.850 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on 95675304fa2d:39429 (size: 69.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.851 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_133_piece0 on 95675304fa2d:39429 in memory (size: 67.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[269] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.852 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 492) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.853 172.17.0.2:54325      7233    (TID 492)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 92.0 (TID 492)\n",
      "10-20 14:45:18.861 172.17.0.2:54325      7233    (TID 492)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.862 172.17.0.2:54325      7233    (TID 492)  INFO org.apache.spark.storage.BlockManager: Found block rdd_263_0 locally\n",
      "10-20 14:45:18.885 172.17.0.2:54325      7233    (TID 492)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 92.0 (TID 492). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.886 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 492) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.886 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 92 (mapPartitions at RandomForest.scala:644) finished in 0.056 s\n",
      "10-20 14:45:18.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 93)\n",
      "10-20 14:45:18.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[271] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.888 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_140 stored as values in memory (estimated size 6.5 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.8 MiB)\n",
      "10-20 14:45:18.889 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:18.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.891 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[271] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.891 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.892 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 93.0 (TID 493) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.892 172.17.0.2:54325      7233    (TID 493)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 93.0 (TID 493)\n",
      "10-20 14:45:18.895 172.17.0.2:54325      7233    (TID 493)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.895 172.17.0.2:54325      7233    (TID 493)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.899 172.17.0.2:54325      7233    (TID 493)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 93.0 (TID 493). 2285 bytes result sent to driver\n",
      "10-20 14:45:18.900 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 93.0 (TID 493) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.900 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 93 (collectAsMap at RandomForest.scala:663) finished in 0.012 s\n",
      "10-20 14:45:18.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "10-20 14:45:18.900 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 48 finished: collectAsMap at RandomForest.scala:663, took 0.072268 s\n",
      "10-20 14:45:18.901 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(138) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.901 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_138_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:18.902 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_141 stored as values in memory (estimated size 40.0 B, free 417.8 MiB)\n",
      "10-20 14:45:18.903 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.8 MiB)\n",
      "10-20 14:45:18.903 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:18.903 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 141 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:18.915 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:18.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 272 (mapPartitions at RandomForest.scala:644) as input to shuffle 45\n",
      "10-20 14:45:18.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 49 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:18.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 95 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:18.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)\n",
      "10-20 14:45:18.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 94)\n",
      "10-20 14:45:18.917 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[272] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:18.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_142 stored as values in memory (estimated size 183.9 KiB, free 417.6 MiB)\n",
      "10-20 14:45:18.923 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 69.9 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.923 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on 95675304fa2d:39429 (size: 69.9 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.924 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.924 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[272] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.924 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.925 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 494) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.925 172.17.0.2:54325      7233    (TID 494)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 94.0 (TID 494)\n",
      "10-20 14:45:18.935 172.17.0.2:54325      7233    (TID 494)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:18.935 172.17.0.2:54325      7233    (TID 494)  INFO org.apache.spark.storage.BlockManager: Found block rdd_263_0 locally\n",
      "10-20 14:45:18.959 172.17.0.2:54325      7233    (TID 494)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 94.0 (TID 494). 2090 bytes result sent to driver\n",
      "10-20 14:45:18.959 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 494) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.959 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 94 (mapPartitions at RandomForest.scala:644) finished in 0.045 s\n",
      "10-20 14:45:18.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:18.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:18.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 95)\n",
      "10-20 14:45:18.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:18.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[274] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:18.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_143 stored as values in memory (estimated size 6.7 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.5 MiB)\n",
      "10-20 14:45:18.965 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:18.966 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:18.966 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[274] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:18.966 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:18.969 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 495) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:18.969 172.17.0.2:54325      7233    (TID 495)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 95.0 (TID 495)\n",
      "10-20 14:45:18.971 172.17.0.2:54325      7233    (TID 495)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:18.971 172.17.0.2:54325      7233    (TID 495)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:18.976 172.17.0.2:54325      7233    (TID 495)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 95.0 (TID 495). 3033 bytes result sent to driver\n",
      "10-20 14:45:18.977 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 495) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:18.977 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:18.978 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 95 (collectAsMap at RandomForest.scala:663) finished in 0.014 s\n",
      "10-20 14:45:18.978 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:18.978 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished\n",
      "10-20 14:45:18.978 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 49 finished: collectAsMap at RandomForest.scala:663, took 0.063228 s\n",
      "10-20 14:45:18.980 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(141) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:18.981 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_141_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.982 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_144 stored as values in memory (estimated size 40.0 B, free 417.5 MiB)\n",
      "10-20 14:45:18.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.5 MiB)\n",
      "10-20 14:45:18.997 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:18.998 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 144 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.000 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_142_piece0 on 95675304fa2d:39429 in memory (size: 69.9 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.003 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_143_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.004 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_140_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.006 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_139_piece0 on 95675304fa2d:39429 in memory (size: 69.6 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:19.020 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 275 (mapPartitions at RandomForest.scala:644) as input to shuffle 46\n",
      "10-20 14:45:19.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 50 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 97 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)\n",
      "10-20 14:45:19.021 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 96)\n",
      "10-20 14:45:19.021 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[275] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.026 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_145 stored as values in memory (estimated size 185.1 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.027 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 70.4 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.028 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on 95675304fa2d:39429 (size: 70.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.028 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.029 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[275] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.029 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.030 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 496) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.031 172.17.0.2:54325      7233    (TID 496)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 96.0 (TID 496)\n",
      "10-20 14:45:19.040 172.17.0.2:54325      7233    (TID 496)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.040 172.17.0.2:54325      7233    (TID 496)  INFO org.apache.spark.storage.BlockManager: Found block rdd_263_0 locally\n",
      "10-20 14:45:19.066 172.17.0.2:54325      7233    (TID 496)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 96.0 (TID 496). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.067 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 496) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.067 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 96 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:19.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 97)\n",
      "10-20 14:45:19.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[277] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.069 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_146 stored as values in memory (estimated size 7.1 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.070 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_146_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[277] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.072 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 97.0 (TID 497) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.072 172.17.0.2:54325      7233    (TID 497)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 97.0 (TID 497)\n",
      "10-20 14:45:19.074 172.17.0.2:54325      7233    (TID 497)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.075 172.17.0.2:54325      7233    (TID 497)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.083 172.17.0.2:54325      7233    (TID 497)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 97.0 (TID 497). 4006 bytes result sent to driver\n",
      "10-20 14:45:19.083 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 97.0 (TID 497) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.083 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 97 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:19.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished\n",
      "10-20 14:45:19.084 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 50 finished: collectAsMap at RandomForest.scala:663, took 0.064661 s\n",
      "10-20 14:45:19.085 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(144) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.086 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_144_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:19.087 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_147 stored as values in memory (estimated size 40.0 B, free 417.8 MiB)\n",
      "10-20 14:45:19.088 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.8 MiB)\n",
      "10-20 14:45:19.088 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_147_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:19.089 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 147 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.102 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 278 (mapPartitions at RandomForest.scala:644) as input to shuffle 47\n",
      "10-20 14:45:19.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 51 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 99 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)\n",
      "10-20 14:45:19.103 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 98)\n",
      "10-20 14:45:19.104 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[278] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.108 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_148 stored as values in memory (estimated size 187.6 KiB, free 417.6 MiB)\n",
      "10-20 14:45:19.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 71.5 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.110 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_148_piece0 in memory on 95675304fa2d:39429 (size: 71.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[278] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.112 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 498) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.113 172.17.0.2:54325      7233    (TID 498)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 98.0 (TID 498)\n",
      "10-20 14:45:19.123 172.17.0.2:54325      7233    (TID 498)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.124 172.17.0.2:54325      7233    (TID 498)  INFO org.apache.spark.storage.BlockManager: Found block rdd_263_0 locally\n",
      "10-20 14:45:19.156 172.17.0.2:54325      7233    (TID 498)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 98.0 (TID 498). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.157 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 498) in 45 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.157 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 98 (mapPartitions at RandomForest.scala:644) finished in 0.054 s\n",
      "10-20 14:45:19.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 99)\n",
      "10-20 14:45:19.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[280] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.159 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_149 stored as values in memory (estimated size 7.9 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.160 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.161 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_149_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.161 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.161 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[280] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.161 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.162 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 499) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.163 172.17.0.2:54325      7233    (TID 499)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 99.0 (TID 499)\n",
      "10-20 14:45:19.166 172.17.0.2:54325      7233    (TID 499)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.166 172.17.0.2:54325      7233    (TID 499)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.213 172.17.0.2:54325      7233    (TID 499)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 99.0 (TID 499). 5764 bytes result sent to driver\n",
      "10-20 14:45:19.214 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 499) in 52 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.215 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 99 (collectAsMap at RandomForest.scala:663) finished in 0.056 s\n",
      "10-20 14:45:19.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished\n",
      "10-20 14:45:19.217 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 51 finished: collectAsMap at RandomForest.scala:663, took 0.114346 s\n",
      "10-20 14:45:19.217 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(147) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.218 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:19.218 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.3994E-5\n",
      "  total: 0.576241983\n",
      "  findBestSplits: 0.574486622\n",
      "  chooseSplits: 0.573394247\n",
      "10-20 14:45:19.218 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_147_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:19.219 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 263 from persistence list\n",
      "10-20 14:45:19.220 172.17.0.2:54325      7233   ad-pool-69  INFO org.apache.spark.storage.BlockManager: Removing RDD 263\n",
      "10-20 14:45:19.227 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 216 from persistence list\n",
      "10-20 14:45:19.231 172.17.0.2:54325      7233   ad-pool-79  INFO org.apache.spark.storage.BlockManager: Removing RDD 216\n",
      "10-20 14:45:19.239 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:19.239 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:19.239 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:19.239 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:19.240 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_150 stored as values in memory (estimated size 40.0 B, free 419.5 MiB)\n",
      "10-20 14:45:19.241 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.5 MiB)\n",
      "10-20 14:45:19.241 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_150_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:19.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 150 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.254 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 288 (mapPartitions at RandomForest.scala:644) as input to shuffle 48\n",
      "10-20 14:45:19.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 52 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 101 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)\n",
      "10-20 14:45:19.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 100)\n",
      "10-20 14:45:19.257 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[288] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_151 stored as values in memory (estimated size 190.5 KiB, free 419.3 MiB)\n",
      "10-20 14:45:19.263 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 73.3 KiB, free 419.2 MiB)\n",
      "10-20 14:45:19.263 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_151_piece0 in memory on 95675304fa2d:39429 (size: 73.3 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:19.264 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.264 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[288] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.264 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.265 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 500) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5310 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.266 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 100.0 (TID 500)\n",
      "10-20 14:45:19.282 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_148_piece0 on 95675304fa2d:39429 in memory (size: 71.5 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:19.283 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_146_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:19.285 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_149_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:19.286 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_145_piece0 on 95675304fa2d:39429 in memory (size: 70.4 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:19.287 172.17.0.2:54325      7233   ad-pool-99  INFO org.apache.spark.storage.BlockManager: Removing RDD 263\n",
      "10-20 14:45:19.291 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.291 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.292 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.292 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.storage.BlockManager: Found block rdd_260_0 locally\n",
      "10-20 14:45:19.317 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_282_0 stored as values in memory (estimated size 1117.5 KiB, free 418.7 MiB)\n",
      "10-20 14:45:19.318 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_282_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:19.339 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_285_0 stored as values in memory (estimated size 914.4 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.340 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_285_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.364 172.17.0.2:54325      7233    (TID 500)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 100.0 (TID 500). 2133 bytes result sent to driver\n",
      "10-20 14:45:19.364 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 500) in 99 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.364 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.364 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 100 (mapPartitions at RandomForest.scala:644) finished in 0.106 s\n",
      "10-20 14:45:19.364 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.365 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.365 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 101)\n",
      "10-20 14:45:19.365 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.365 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[290] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_152 stored as values in memory (estimated size 6.0 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.376 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.8 MiB)\n",
      "10-20 14:45:19.376 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_152_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[290] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.378 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 501) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.379 172.17.0.2:54325      7233    (TID 501)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 101.0 (TID 501)\n",
      "10-20 14:45:19.382 172.17.0.2:54325      7233    (TID 501)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.382 172.17.0.2:54325      7233    (TID 501)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.385 172.17.0.2:54325      7233    (TID 501)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 101.0 (TID 501). 2076 bytes result sent to driver\n",
      "10-20 14:45:19.386 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 501) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.386 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 101 (collectAsMap at RandomForest.scala:663) finished in 0.022 s\n",
      "10-20 14:45:19.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished\n",
      "10-20 14:45:19.387 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 52 finished: collectAsMap at RandomForest.scala:663, took 0.133098 s\n",
      "10-20 14:45:19.390 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(150) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.392 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_153 stored as values in memory (estimated size 40.0 B, free 417.8 MiB)\n",
      "10-20 14:45:19.392 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_150_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:19.393 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.8 MiB)\n",
      "10-20 14:45:19.393 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_153_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:19.394 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 153 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.414 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.414 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 291 (mapPartitions at RandomForest.scala:644) as input to shuffle 49\n",
      "10-20 14:45:19.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 53 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 103 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\n",
      "10-20 14:45:19.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 102)\n",
      "10-20 14:45:19.418 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 102 (MapPartitionsRDD[291] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.425 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_154 stored as values in memory (estimated size 191.0 KiB, free 417.6 MiB)\n",
      "10-20 14:45:19.427 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 73.6 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.427 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_154_piece0 in memory on 95675304fa2d:39429 (size: 73.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[291] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.429 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 102.0 (TID 502) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5310 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.430 172.17.0.2:54325      7233    (TID 502)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 102.0 (TID 502)\n",
      "10-20 14:45:19.441 172.17.0.2:54325      7233    (TID 502)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.441 172.17.0.2:54325      7233    (TID 502)  INFO org.apache.spark.storage.BlockManager: Found block rdd_285_0 locally\n",
      "10-20 14:45:19.471 172.17.0.2:54325      7233    (TID 502)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 102.0 (TID 502). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.472 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 102.0 (TID 502) in 43 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.472 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.472 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 102 (mapPartitions at RandomForest.scala:644) finished in 0.054 s\n",
      "10-20 14:45:19.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 103)\n",
      "10-20 14:45:19.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.473 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[293] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.474 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_155 stored as values in memory (estimated size 6.5 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.474 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.475 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_155_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.476 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.476 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[293] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.476 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.477 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 503) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.478 172.17.0.2:54325      7233    (TID 503)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 103.0 (TID 503)\n",
      "10-20 14:45:19.481 172.17.0.2:54325      7233    (TID 503)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (19.7 KiB) non-empty blocks including 1 (19.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.481 172.17.0.2:54325      7233    (TID 503)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.484 172.17.0.2:54325      7233    (TID 503)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 103.0 (TID 503). 2285 bytes result sent to driver\n",
      "10-20 14:45:19.485 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 503) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.485 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 103 (collectAsMap at RandomForest.scala:663) finished in 0.014 s\n",
      "10-20 14:45:19.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished\n",
      "10-20 14:45:19.488 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 53 finished: collectAsMap at RandomForest.scala:663, took 0.074129 s\n",
      "10-20 14:45:19.488 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(153) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.490 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_156 stored as values in memory (estimated size 40.0 B, free 417.5 MiB)\n",
      "10-20 14:45:19.490 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.5 MiB)\n",
      "10-20 14:45:19.491 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_153_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:19.491 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_156_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:19.491 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 156 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.507 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 294 (mapPartitions at RandomForest.scala:644) as input to shuffle 50\n",
      "10-20 14:45:19.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 54 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 105 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)\n",
      "10-20 14:45:19.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 104)\n",
      "10-20 14:45:19.510 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[294] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_157 stored as values in memory (estimated size 191.6 KiB, free 417.3 MiB)\n",
      "10-20 14:45:19.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 73.9 KiB, free 417.2 MiB)\n",
      "10-20 14:45:19.517 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_157_piece0 in memory on 95675304fa2d:39429 (size: 73.9 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[294] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.519 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 504) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5310 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.523 172.17.0.2:54325      7233    (TID 504)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 104.0 (TID 504)\n",
      "10-20 14:45:19.533 172.17.0.2:54325      7233    (TID 504)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.533 172.17.0.2:54325      7233    (TID 504)  INFO org.apache.spark.storage.BlockManager: Found block rdd_285_0 locally\n",
      "10-20 14:45:19.557 172.17.0.2:54325      7233    (TID 504)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 104.0 (TID 504). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.558 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 504) in 39 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.558 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 104 (mapPartitions at RandomForest.scala:644) finished in 0.049 s\n",
      "10-20 14:45:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 105)\n",
      "10-20 14:45:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[296] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.561 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_158 stored as values in memory (estimated size 6.7 KiB, free 417.2 MiB)\n",
      "10-20 14:45:19.561 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.2 MiB)\n",
      "10-20 14:45:19.562 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_158_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.562 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.563 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[296] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.563 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.564 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 505) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.564 172.17.0.2:54325      7233    (TID 505)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 105.0 (TID 505)\n",
      "10-20 14:45:19.567 172.17.0.2:54325      7233    (TID 505)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.567 172.17.0.2:54325      7233    (TID 505)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.570 172.17.0.2:54325      7233    (TID 505)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 105.0 (TID 505). 3025 bytes result sent to driver\n",
      "10-20 14:45:19.571 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 505) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.571 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.572 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 105 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:19.572 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.572 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "10-20 14:45:19.572 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 54 finished: collectAsMap at RandomForest.scala:663, took 0.064218 s\n",
      "10-20 14:45:19.572 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(156) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.573 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_159 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:19.573 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:19.574 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_156_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:19.574 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_159_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:19.574 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 159 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.609 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 297 (mapPartitions at RandomForest.scala:644) as input to shuffle 51\n",
      "10-20 14:45:19.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 55 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 107 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)\n",
      "10-20 14:45:19.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 106)\n",
      "10-20 14:45:19.612 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[297] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.617 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_160 stored as values in memory (estimated size 192.9 KiB, free 417.0 MiB)\n",
      "10-20 14:45:19.618 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 74.6 KiB, free 417.0 MiB)\n",
      "10-20 14:45:19.619 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_160_piece0 in memory on 95675304fa2d:39429 (size: 74.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.619 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[297] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.620 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 106.0 (TID 506) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5310 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.621 172.17.0.2:54325      7233    (TID 506)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 106.0 (TID 506)\n",
      "10-20 14:45:19.630 172.17.0.2:54325      7233    (TID 506)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.630 172.17.0.2:54325      7233    (TID 506)  INFO org.apache.spark.storage.BlockManager: Found block rdd_285_0 locally\n",
      "10-20 14:45:19.672 172.17.0.2:54325      7233    (TID 506)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 106.0 (TID 506). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.672 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 106.0 (TID 506) in 52 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.673 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.673 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 106 (mapPartitions at RandomForest.scala:644) finished in 0.061 s\n",
      "10-20 14:45:19.673 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 107)\n",
      "10-20 14:45:19.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[299] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.675 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_161 stored as values in memory (estimated size 7.1 KiB, free 417.0 MiB)\n",
      "10-20 14:45:19.676 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.9 MiB)\n",
      "10-20 14:45:19.676 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_161_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.676 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.676 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[299] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.676 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.677 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 507) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.678 172.17.0.2:54325      7233    (TID 507)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 107.0 (TID 507)\n",
      "10-20 14:45:19.680 172.17.0.2:54325      7233    (TID 507)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.680 172.17.0.2:54325      7233    (TID 507)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.686 172.17.0.2:54325      7233    (TID 507)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 107.0 (TID 507). 3866 bytes result sent to driver\n",
      "10-20 14:45:19.687 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 507) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.687 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 107 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:19.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished\n",
      "10-20 14:45:19.688 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 55 finished: collectAsMap at RandomForest.scala:663, took 0.078176 s\n",
      "10-20 14:45:19.688 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(159) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.689 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_159_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:19.689 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_162 stored as values in memory (estimated size 40.0 B, free 416.9 MiB)\n",
      "10-20 14:45:19.689 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.9 MiB)\n",
      "10-20 14:45:19.690 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_162_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:19.690 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 162 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.702 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 300 (mapPartitions at RandomForest.scala:644) as input to shuffle 52\n",
      "10-20 14:45:19.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 56 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 109 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)\n",
      "10-20 14:45:19.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 108)\n",
      "10-20 14:45:19.704 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[300] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_163 stored as values in memory (estimated size 195.2 KiB, free 416.8 MiB)\n",
      "10-20 14:45:19.709 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 75.8 KiB, free 416.7 MiB)\n",
      "10-20 14:45:19.710 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_163_piece0 in memory on 95675304fa2d:39429 (size: 75.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:19.710 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[300] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.712 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 508) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5310 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.712 172.17.0.2:54325      7233    (TID 508)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 108.0 (TID 508)\n",
      "10-20 14:45:19.720 172.17.0.2:54325      7233    (TID 508)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.720 172.17.0.2:54325      7233    (TID 508)  INFO org.apache.spark.storage.BlockManager: Found block rdd_285_0 locally\n",
      "10-20 14:45:19.751 172.17.0.2:54325      7233    (TID 508)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 108.0 (TID 508). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.751 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 508) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.751 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 108 (mapPartitions at RandomForest.scala:644) finished in 0.047 s\n",
      "10-20 14:45:19.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 109)\n",
      "10-20 14:45:19.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[302] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.753 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_164 stored as values in memory (estimated size 7.9 KiB, free 416.7 MiB)\n",
      "10-20 14:45:19.768 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.7 MiB)\n",
      "10-20 14:45:19.769 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_164_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:19.769 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.769 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[302] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.770 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_154_piece0 on 95675304fa2d:39429 in memory (size: 73.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.770 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 509) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.771 172.17.0.2:54325      7233    (TID 509)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 109.0 (TID 509)\n",
      "10-20 14:45:19.772 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_155_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.773 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_161_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.775 172.17.0.2:54325      7233    (TID 509)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.775 172.17.0.2:54325      7233    (TID 509)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.776 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_157_piece0 on 95675304fa2d:39429 in memory (size: 73.9 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.778 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_152_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.780 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_158_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.781 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_151_piece0 on 95675304fa2d:39429 in memory (size: 73.3 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.783 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_160_piece0 on 95675304fa2d:39429 in memory (size: 74.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:19.789 172.17.0.2:54325      7233    (TID 509)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 109.0 (TID 509). 5812 bytes result sent to driver\n",
      "10-20 14:45:19.790 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 509) in 20 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.790 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.791 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 109 (collectAsMap at RandomForest.scala:663) finished in 0.037 s\n",
      "10-20 14:45:19.791 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.791 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished\n",
      "10-20 14:45:19.791 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 56 finished: collectAsMap at RandomForest.scala:663, took 0.089091 s\n",
      "10-20 14:45:19.791 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(162) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.792 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:19.792 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.4683E-5\n",
      "  total: 0.552650195\n",
      "  findBestSplits: 0.55126157\n",
      "  chooseSplits: 0.550490396\n",
      "10-20 14:45:19.793 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 285 from persistence list\n",
      "10-20 14:45:19.793 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_162_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:19.793 172.17.0.2:54325      7233   ad-pool-68  INFO org.apache.spark.storage.BlockManager: Removing RDD 285\n",
      "10-20 14:45:19.800 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 238 from persistence list\n",
      "10-20 14:45:19.801 172.17.0.2:54325      7233   ad-pool-73  INFO org.apache.spark.storage.BlockManager: Removing RDD 238\n",
      "10-20 14:45:19.809 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:19.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:19.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:19.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:19.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_165 stored as values in memory (estimated size 40.0 B, free 419.7 MiB)\n",
      "10-20 14:45:19.812 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.7 MiB)\n",
      "10-20 14:45:19.812 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_165_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.3 MiB)\n",
      "10-20 14:45:19.813 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 165 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 310 (mapPartitions at RandomForest.scala:644) as input to shuffle 53\n",
      "10-20 14:45:19.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 57 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 111 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)\n",
      "10-20 14:45:19.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 110)\n",
      "10-20 14:45:19.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[310] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_166 stored as values in memory (estimated size 198.2 KiB, free 419.5 MiB)\n",
      "10-20 14:45:19.836 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 419.5 MiB)\n",
      "10-20 14:45:19.836 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_166_piece0 in memory on 95675304fa2d:39429 (size: 77.7 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:19.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[310] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.838 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.839 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 510) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5342 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.839 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 110.0 (TID 510)\n",
      "10-20 14:45:19.854 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.855 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.855 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:19.856 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.storage.BlockManager: Found block rdd_282_0 locally\n",
      "10-20 14:45:19.888 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_304_0 stored as values in memory (estimated size 1117.5 KiB, free 418.4 MiB)\n",
      "10-20 14:45:19.889 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_304_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:19.914 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_307_0 stored as values in memory (estimated size 914.4 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.915 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_307_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.939 172.17.0.2:54325      7233    (TID 510)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 110.0 (TID 510). 2090 bytes result sent to driver\n",
      "10-20 14:45:19.940 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 510) in 102 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.940 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 110 (mapPartitions at RandomForest.scala:644) finished in 0.111 s\n",
      "10-20 14:45:19.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:19.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:19.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 111)\n",
      "10-20 14:45:19.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:19.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[312] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:19.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_167 stored as values in memory (estimated size 6.0 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.5 MiB)\n",
      "10-20 14:45:19.944 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_167_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:19.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[312] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.946 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 111.0 (TID 511) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.949 172.17.0.2:54325      7233    (TID 511)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 111.0 (TID 511)\n",
      "10-20 14:45:19.953 172.17.0.2:54325      7233    (TID 511)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:19.953 172.17.0.2:54325      7233    (TID 511)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:19.957 172.17.0.2:54325      7233    (TID 511)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 111.0 (TID 511). 2296 bytes result sent to driver\n",
      "10-20 14:45:19.959 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 111.0 (TID 511) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:19.959 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:19.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 111 (collectAsMap at RandomForest.scala:663) finished in 0.018 s\n",
      "10-20 14:45:19.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:19.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished\n",
      "10-20 14:45:19.960 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 57 finished: collectAsMap at RandomForest.scala:663, took 0.132225 s\n",
      "10-20 14:45:19.961 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(165) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:19.961 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_165_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:19.962 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_168 stored as values in memory (estimated size 40.0 B, free 417.5 MiB)\n",
      "10-20 14:45:19.963 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.5 MiB)\n",
      "10-20 14:45:19.963 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_168_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:19.964 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 168 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:19.978 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:19.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 313 (mapPartitions at RandomForest.scala:644) as input to shuffle 54\n",
      "10-20 14:45:19.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 58 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:19.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 113 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:19.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)\n",
      "10-20 14:45:19.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 112)\n",
      "10-20 14:45:19.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[313] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:19.984 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_169 stored as values in memory (estimated size 198.7 KiB, free 417.3 MiB)\n",
      "10-20 14:45:19.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 78.0 KiB, free 417.2 MiB)\n",
      "10-20 14:45:19.986 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_169_piece0 in memory on 95675304fa2d:39429 (size: 78.0 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:19.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:19.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[313] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:19.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:19.988 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 512) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5342 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:19.989 172.17.0.2:54325      7233    (TID 512)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 112.0 (TID 512)\n",
      "10-20 14:45:20.028 172.17.0.2:54325      7233    (TID 512)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.029 172.17.0.2:54325      7233    (TID 512)  INFO org.apache.spark.storage.BlockManager: Found block rdd_307_0 locally\n",
      "10-20 14:45:20.053 172.17.0.2:54325      7233    (TID 512)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 112.0 (TID 512). 2090 bytes result sent to driver\n",
      "10-20 14:45:20.054 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 512) in 66 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.054 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 112 (mapPartitions at RandomForest.scala:644) finished in 0.075 s\n",
      "10-20 14:45:20.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:20.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:20.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 113)\n",
      "10-20 14:45:20.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:20.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[315] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:20.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_170 stored as values in memory (estimated size 6.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:20.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:20.057 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_170_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:20.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[315] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.058 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 513) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.059 172.17.0.2:54325      7233    (TID 513)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 113.0 (TID 513)\n",
      "10-20 14:45:20.061 172.17.0.2:54325      7233    (TID 513)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:20.062 172.17.0.2:54325      7233    (TID 513)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:20.064 172.17.0.2:54325      7233    (TID 513)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 113.0 (TID 513). 2285 bytes result sent to driver\n",
      "10-20 14:45:20.065 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 513) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.065 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.066 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 113 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:20.066 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:20.066 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished\n",
      "10-20 14:45:20.066 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 58 finished: collectAsMap at RandomForest.scala:663, took 0.088176 s\n",
      "10-20 14:45:20.066 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(168) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:20.067 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_168_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:20.068 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_171 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:20.069 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:20.069 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_171_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:20.070 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 171 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:20.086 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:20.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 316 (mapPartitions at RandomForest.scala:644) as input to shuffle 55\n",
      "10-20 14:45:20.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 59 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:20.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 115 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:20.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 114)\n",
      "10-20 14:45:20.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 114)\n",
      "10-20 14:45:20.088 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[316] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:20.098 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_172 stored as values in memory (estimated size 199.3 KiB, free 417.0 MiB)\n",
      "10-20 14:45:20.099 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 78.3 KiB, free 416.9 MiB)\n",
      "10-20 14:45:20.099 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_172_piece0 in memory on 95675304fa2d:39429 (size: 78.3 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:20.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[316] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.102 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 514) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5342 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.103 172.17.0.2:54325      7233    (TID 514)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 114.0 (TID 514)\n",
      "10-20 14:45:20.114 172.17.0.2:54325      7233    (TID 514)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.115 172.17.0.2:54325      7233    (TID 514)  INFO org.apache.spark.storage.BlockManager: Found block rdd_307_0 locally\n",
      "10-20 14:45:20.142 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_169_piece0 on 95675304fa2d:39429 in memory (size: 78.0 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:20.144 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_166_piece0 on 95675304fa2d:39429 in memory (size: 77.7 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.145 172.17.0.2:54325      7233   ad-pool-98  INFO org.apache.spark.storage.BlockManager: Removing RDD 285\n",
      "10-20 14:45:20.147 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_167_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.148 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_170_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.149 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_163_piece0 on 95675304fa2d:39429 in memory (size: 75.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.151 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_164_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.162 172.17.0.2:54325      7233    (TID 514)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 114.0 (TID 514). 2133 bytes result sent to driver\n",
      "10-20 14:45:20.163 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 514) in 61 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.163 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 114 (mapPartitions at RandomForest.scala:644) finished in 0.074 s\n",
      "10-20 14:45:20.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:20.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:20.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 115)\n",
      "10-20 14:45:20.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:20.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[318] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:20.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_173 stored as values in memory (estimated size 6.7 KiB, free 417.7 MiB)\n",
      "10-20 14:45:20.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.7 MiB)\n",
      "10-20 14:45:20.166 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_173_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[318] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.167 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 115.0 (TID 515) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.168 172.17.0.2:54325      7233    (TID 515)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 115.0 (TID 515)\n",
      "10-20 14:45:20.172 172.17.0.2:54325      7233    (TID 515)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:20.172 172.17.0.2:54325      7233    (TID 515)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:20.178 172.17.0.2:54325      7233    (TID 515)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 115.0 (TID 515). 2998 bytes result sent to driver\n",
      "10-20 14:45:20.179 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 115.0 (TID 515) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.179 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 115 (collectAsMap at RandomForest.scala:663) finished in 0.015 s\n",
      "10-20 14:45:20.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:20.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished\n",
      "10-20 14:45:20.179 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 59 finished: collectAsMap at RandomForest.scala:663, took 0.093016 s\n",
      "10-20 14:45:20.180 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(171) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:20.180 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_171_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:20.180 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_174 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:20.181 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:20.181 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_174_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:20.182 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 174 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:20.195 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:20.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 319 (mapPartitions at RandomForest.scala:644) as input to shuffle 56\n",
      "10-20 14:45:20.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 60 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:20.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 117 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:20.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)\n",
      "10-20 14:45:20.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 116)\n",
      "10-20 14:45:20.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[319] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:20.202 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_175 stored as values in memory (estimated size 200.4 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.204 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_175_piece0 in memory on 95675304fa2d:39429 (size: 78.8 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[319] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.206 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 516) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5342 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.208 172.17.0.2:54325      7233    (TID 516)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 116.0 (TID 516)\n",
      "10-20 14:45:20.220 172.17.0.2:54325      7233    (TID 516)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.220 172.17.0.2:54325      7233    (TID 516)  INFO org.apache.spark.storage.BlockManager: Found block rdd_307_0 locally\n",
      "10-20 14:45:20.247 172.17.0.2:54325      7233    (TID 516)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 116.0 (TID 516). 2090 bytes result sent to driver\n",
      "10-20 14:45:20.248 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 516) in 42 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.248 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 116 (mapPartitions at RandomForest.scala:644) finished in 0.052 s\n",
      "10-20 14:45:20.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:20.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:20.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 117)\n",
      "10-20 14:45:20.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:20.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[321] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:20.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_176 stored as values in memory (estimated size 7.1 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.262 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_176_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.262 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_172_piece0 on 95675304fa2d:39429 in memory (size: 78.3 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.263 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.263 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[321] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.264 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.265 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 517) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.265 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_173_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.265 172.17.0.2:54325      7233    (TID 517)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 117.0 (TID 517)\n",
      "10-20 14:45:20.268 172.17.0.2:54325      7233    (TID 517)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:20.268 172.17.0.2:54325      7233    (TID 517)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:20.274 172.17.0.2:54325      7233    (TID 517)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 117.0 (TID 517). 3971 bytes result sent to driver\n",
      "10-20 14:45:20.275 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 517) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.275 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 117 (collectAsMap at RandomForest.scala:663) finished in 0.034 s\n",
      "10-20 14:45:20.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:20.286 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished\n",
      "10-20 14:45:20.287 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 60 finished: collectAsMap at RandomForest.scala:663, took 0.091403 s\n",
      "10-20 14:45:20.289 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(174) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:20.293 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_177 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:20.294 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_174_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:20.297 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:20.298 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_177_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:20.299 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 177 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:20.339 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:20.342 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 322 (mapPartitions at RandomForest.scala:644) as input to shuffle 57\n",
      "10-20 14:45:20.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 61 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:20.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 119 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:20.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)\n",
      "10-20 14:45:20.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 118)\n",
      "10-20 14:45:20.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[322] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:20.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_178 stored as values in memory (estimated size 202.9 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.372 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 79.9 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.373 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_178_piece0 in memory on 95675304fa2d:39429 (size: 79.9 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.375 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[322] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.379 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 518) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5342 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.381 172.17.0.2:54325      7233    (TID 518)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 118.0 (TID 518)\n",
      "10-20 14:45:20.413 172.17.0.2:54325      7233    (TID 518)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.414 172.17.0.2:54325      7233    (TID 518)  INFO org.apache.spark.storage.BlockManager: Found block rdd_307_0 locally\n",
      "10-20 14:45:20.494 172.17.0.2:54325      7233    (TID 518)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 118.0 (TID 518). 2090 bytes result sent to driver\n",
      "10-20 14:45:20.494 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 518) in 115 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.495 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 118 (mapPartitions at RandomForest.scala:644) finished in 0.150 s\n",
      "10-20 14:45:20.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:20.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:20.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 119)\n",
      "10-20 14:45:20.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:20.498 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[324] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:20.499 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_179 stored as values in memory (estimated size 7.9 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.500 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.500 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_179_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[324] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.503 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 519) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.504 172.17.0.2:54325      7233    (TID 519)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 119.0 (TID 519)\n",
      "10-20 14:45:20.510 172.17.0.2:54325      7233    (TID 519)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:20.511 172.17.0.2:54325      7233    (TID 519)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:20.545 172.17.0.2:54325      7233    (TID 519)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 119.0 (TID 519). 5718 bytes result sent to driver\n",
      "10-20 14:45:20.549 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 519) in 47 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.549 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 119 (collectAsMap at RandomForest.scala:663) finished in 0.055 s\n",
      "10-20 14:45:20.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:20.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished\n",
      "10-20 14:45:20.556 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 61 finished: collectAsMap at RandomForest.scala:663, took 0.216171 s\n",
      "10-20 14:45:20.559 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(177) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:20.564 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_177_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:20.567 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:20.568 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.4167E-5\n",
      "  total: 0.757479535\n",
      "  findBestSplits: 0.755519221\n",
      "  chooseSplits: 0.75274533\n",
      "10-20 14:45:20.570 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 307 from persistence list\n",
      "10-20 14:45:20.578 172.17.0.2:54325      7233   d-pool-127  INFO org.apache.spark.storage.BlockManager: Removing RDD 307\n",
      "10-20 14:45:20.589 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 260 from persistence list\n",
      "10-20 14:45:20.595 172.17.0.2:54325      7233   d-pool-126  INFO org.apache.spark.storage.BlockManager: Removing RDD 260\n",
      "10-20 14:45:20.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:20.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:20.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:20.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:20.612 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_180 stored as values in memory (estimated size 40.0 B, free 419.4 MiB)\n",
      "10-20 14:45:20.613 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.4 MiB)\n",
      "10-20 14:45:20.614 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_180_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:20.616 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 180 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:20.645 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:20.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 332 (mapPartitions at RandomForest.scala:644) as input to shuffle 58\n",
      "10-20 14:45:20.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 62 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:20.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 121 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:20.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)\n",
      "10-20 14:45:20.648 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 120)\n",
      "10-20 14:45:20.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[332] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:20.660 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_181 stored as values in memory (estimated size 205.7 KiB, free 419.2 MiB)\n",
      "10-20 14:45:20.662 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 82.3 KiB, free 419.2 MiB)\n",
      "10-20 14:45:20.695 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_181_piece0 in memory on 95675304fa2d:39429 (size: 82.3 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:20.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[332] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.698 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 120.0 (TID 520) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5374 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.698 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 120.0 (TID 520)\n",
      "10-20 14:45:20.707 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.708 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.708 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.708 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.storage.BlockManager: Found block rdd_304_0 locally\n",
      "10-20 14:45:20.749 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_326_0 stored as values in memory (estimated size 1117.5 KiB, free 418.1 MiB)\n",
      "10-20 14:45:20.751 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_326_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:20.791 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_329_0 stored as values in memory (estimated size 914.4 KiB, free 417.2 MiB)\n",
      "10-20 14:45:20.791 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_329_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:20.813 172.17.0.2:54325      7233    (TID 520)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 120.0 (TID 520). 2090 bytes result sent to driver\n",
      "10-20 14:45:20.813 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 120.0 (TID 520) in 116 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.813 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.814 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 120 (mapPartitions at RandomForest.scala:644) finished in 0.160 s\n",
      "10-20 14:45:20.814 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:20.814 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:20.814 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 121)\n",
      "10-20 14:45:20.814 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:20.814 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[334] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:20.815 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_182 stored as values in memory (estimated size 6.0 KiB, free 417.2 MiB)\n",
      "10-20 14:45:20.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.2 MiB)\n",
      "10-20 14:45:20.816 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_182_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:20.817 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[334] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.819 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 521) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.819 172.17.0.2:54325      7233    (TID 521)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 121.0 (TID 521)\n",
      "10-20 14:45:20.821 172.17.0.2:54325      7233    (TID 521)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:20.822 172.17.0.2:54325      7233    (TID 521)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:20.823 172.17.0.2:54325      7233    (TID 521)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 121.0 (TID 521). 2296 bytes result sent to driver\n",
      "10-20 14:45:20.824 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 521) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.824 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.825 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 121 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:20.825 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:20.825 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished\n",
      "10-20 14:45:20.825 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 62 finished: collectAsMap at RandomForest.scala:663, took 0.179768 s\n",
      "10-20 14:45:20.825 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(180) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:20.826 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_180_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:20.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_183 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:20.828 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:20.828 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_183_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:20.828 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 183 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:20.845 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_178_piece0 on 95675304fa2d:39429 in memory (size: 79.9 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.846 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_181_piece0 on 95675304fa2d:39429 in memory (size: 82.3 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.847 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_176_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.849 172.17.0.2:54325      7233   ad-pool-67  INFO org.apache.spark.storage.BlockManager: Removing RDD 307\n",
      "10-20 14:45:20.850 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_179_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.852 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_175_piece0 on 95675304fa2d:39429 in memory (size: 78.8 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:20.853 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_182_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:20.861 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:20.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 335 (mapPartitions at RandomForest.scala:644) as input to shuffle 59\n",
      "10-20 14:45:20.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 63 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:20.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 123 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:20.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)\n",
      "10-20 14:45:20.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 122)\n",
      "10-20 14:45:20.862 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[335] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:20.868 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_184 stored as values in memory (estimated size 206.2 KiB, free 417.8 MiB)\n",
      "10-20 14:45:20.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 82.6 KiB, free 417.7 MiB)\n",
      "10-20 14:45:20.871 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_184_piece0 in memory on 95675304fa2d:39429 (size: 82.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[335] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.872 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.873 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 522) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5374 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.873 172.17.0.2:54325      7233    (TID 522)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 122.0 (TID 522)\n",
      "10-20 14:45:20.881 172.17.0.2:54325      7233    (TID 522)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.881 172.17.0.2:54325      7233    (TID 522)  INFO org.apache.spark.storage.BlockManager: Found block rdd_329_0 locally\n",
      "10-20 14:45:20.904 172.17.0.2:54325      7233    (TID 522)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 122.0 (TID 522). 2090 bytes result sent to driver\n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 522) in 33 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 122 (mapPartitions at RandomForest.scala:644) finished in 0.042 s\n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 123)\n",
      "10-20 14:45:20.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:20.906 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[337] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:20.906 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_185 stored as values in memory (estimated size 6.5 KiB, free 417.7 MiB)\n",
      "10-20 14:45:20.920 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.7 MiB)\n",
      "10-20 14:45:20.920 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_185_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:20.920 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[337] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.923 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 523) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.927 172.17.0.2:54325      7233    (TID 523)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 123.0 (TID 523)\n",
      "10-20 14:45:20.930 172.17.0.2:54325      7233    (TID 523)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:20.930 172.17.0.2:54325      7233    (TID 523)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:20.934 172.17.0.2:54325      7233    (TID 523)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 123.0 (TID 523). 2584 bytes result sent to driver\n",
      "10-20 14:45:20.935 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 523) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:20.935 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:20.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 123 (collectAsMap at RandomForest.scala:663) finished in 0.030 s\n",
      "10-20 14:45:20.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:20.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished\n",
      "10-20 14:45:20.937 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 63 finished: collectAsMap at RandomForest.scala:663, took 0.076605 s\n",
      "10-20 14:45:20.938 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(183) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:20.938 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_183_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:20.940 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_186 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:20.941 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:20.941 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_186_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:20.942 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 186 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:20.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:20.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 338 (mapPartitions at RandomForest.scala:644) as input to shuffle 60\n",
      "10-20 14:45:20.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 64 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:20.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 125 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:20.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)\n",
      "10-20 14:45:20.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 124)\n",
      "10-20 14:45:20.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[338] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:20.966 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_187 stored as values in memory (estimated size 206.8 KiB, free 417.5 MiB)\n",
      "10-20 14:45:20.967 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 82.9 KiB, free 417.4 MiB)\n",
      "10-20 14:45:20.968 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_187_piece0 in memory on 95675304fa2d:39429 (size: 82.9 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:20.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:20.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[338] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:20.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:20.969 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 124.0 (TID 524) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5374 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:20.970 172.17.0.2:54325      7233    (TID 524)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 124.0 (TID 524)\n",
      "10-20 14:45:20.980 172.17.0.2:54325      7233    (TID 524)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:20.980 172.17.0.2:54325      7233    (TID 524)  INFO org.apache.spark.storage.BlockManager: Found block rdd_329_0 locally\n",
      "10-20 14:45:21.005 172.17.0.2:54325      7233    (TID 524)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 124.0 (TID 524). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.006 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 124.0 (TID 524) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.007 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.007 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 124 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:21.007 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.007 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.007 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 125)\n",
      "10-20 14:45:21.007 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.009 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[340] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_188 stored as values in memory (estimated size 6.7 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.011 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.012 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_188_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:21.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[340] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 125.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.014 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 525) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.014 172.17.0.2:54325      7233    (TID 525)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 125.0 (TID 525)\n",
      "10-20 14:45:21.017 172.17.0.2:54325      7233    (TID 525)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.017 172.17.0.2:54325      7233    (TID 525)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.021 172.17.0.2:54325      7233    (TID 525)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 125.0 (TID 525). 3033 bytes result sent to driver\n",
      "10-20 14:45:21.021 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 525) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.021 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 125 (collectAsMap at RandomForest.scala:663) finished in 0.012 s\n",
      "10-20 14:45:21.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished\n",
      "10-20 14:45:21.022 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 64 finished: collectAsMap at RandomForest.scala:663, took 0.064613 s\n",
      "10-20 14:45:21.023 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(186) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.023 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_186_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:21.024 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_189 stored as values in memory (estimated size 40.0 B, free 417.4 MiB)\n",
      "10-20 14:45:21.025 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.4 MiB)\n",
      "10-20 14:45:21.025 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_189_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:21.026 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 189 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.039 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 341 (mapPartitions at RandomForest.scala:644) as input to shuffle 61\n",
      "10-20 14:45:21.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 65 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 127 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)\n",
      "10-20 14:45:21.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 126)\n",
      "10-20 14:45:21.040 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[341] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_190 stored as values in memory (estimated size 208.0 KiB, free 417.2 MiB)\n",
      "10-20 14:45:21.048 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 83.4 KiB, free 417.2 MiB)\n",
      "10-20 14:45:21.048 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_190_piece0 in memory on 95675304fa2d:39429 (size: 83.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.048 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.049 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[341] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.049 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.050 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 526) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5374 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.051 172.17.0.2:54325      7233    (TID 526)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 126.0 (TID 526)\n",
      "10-20 14:45:21.061 172.17.0.2:54325      7233    (TID 526)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.061 172.17.0.2:54325      7233    (TID 526)  INFO org.apache.spark.storage.BlockManager: Found block rdd_329_0 locally\n",
      "10-20 14:45:21.089 172.17.0.2:54325      7233    (TID 526)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 126.0 (TID 526). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 526) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 126 (mapPartitions at RandomForest.scala:644) finished in 0.049 s\n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 127)\n",
      "10-20 14:45:21.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.091 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[343] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.092 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_191 stored as values in memory (estimated size 7.1 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.093 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.093 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_191_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.093 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[343] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.095 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 527) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.095 172.17.0.2:54325      7233    (TID 527)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 127.0 (TID 527)\n",
      "10-20 14:45:21.097 172.17.0.2:54325      7233    (TID 527)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.098 172.17.0.2:54325      7233    (TID 527)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.103 172.17.0.2:54325      7233    (TID 527)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 127.0 (TID 527). 3901 bytes result sent to driver\n",
      "10-20 14:45:21.104 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 527) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.104 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 127 (collectAsMap at RandomForest.scala:663) finished in 0.014 s\n",
      "10-20 14:45:21.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished\n",
      "10-20 14:45:21.105 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 65 finished: collectAsMap at RandomForest.scala:663, took 0.065706 s\n",
      "10-20 14:45:21.105 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(189) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.106 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_189_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:21.107 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_192 stored as values in memory (estimated size 40.0 B, free 417.1 MiB)\n",
      "10-20 14:45:21.108 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.1 MiB)\n",
      "10-20 14:45:21.108 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_192_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:21.109 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 192 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.147 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 344 (mapPartitions at RandomForest.scala:644) as input to shuffle 62\n",
      "10-20 14:45:21.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 66 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 129 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)\n",
      "10-20 14:45:21.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 128)\n",
      "10-20 14:45:21.149 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[344] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.156 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_193 stored as values in memory (estimated size 210.4 KiB, free 416.9 MiB)\n",
      "10-20 14:45:21.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 84.5 KiB, free 416.9 MiB)\n",
      "10-20 14:45:21.158 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_193_piece0 in memory on 95675304fa2d:39429 (size: 84.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:21.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.159 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[344] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.159 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.160 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 528) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5374 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.160 172.17.0.2:54325      7233    (TID 528)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 128.0 (TID 528)\n",
      "10-20 14:45:21.171 172.17.0.2:54325      7233    (TID 528)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.171 172.17.0.2:54325      7233    (TID 528)  INFO org.apache.spark.storage.BlockManager: Found block rdd_329_0 locally\n",
      "10-20 14:45:21.198 172.17.0.2:54325      7233    (TID 528)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 128.0 (TID 528). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.199 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 528) in 39 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.199 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 128 (mapPartitions at RandomForest.scala:644) finished in 0.050 s\n",
      "10-20 14:45:21.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 129)\n",
      "10-20 14:45:21.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.201 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[346] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.202 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_194 stored as values in memory (estimated size 7.9 KiB, free 416.8 MiB)\n",
      "10-20 14:45:21.203 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.8 MiB)\n",
      "10-20 14:45:21.204 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_194_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:21.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[346] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.206 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 129.0 (TID 529) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.207 172.17.0.2:54325      7233    (TID 529)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 129.0 (TID 529)\n",
      "10-20 14:45:21.208 172.17.0.2:54325      7233    (TID 529)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.209 172.17.0.2:54325      7233    (TID 529)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.217 172.17.0.2:54325      7233    (TID 529)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 129.0 (TID 529). 5812 bytes result sent to driver\n",
      "10-20 14:45:21.218 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 129.0 (TID 529) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.218 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 129 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:21.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished\n",
      "10-20 14:45:21.218 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 66 finished: collectAsMap at RandomForest.scala:663, took 0.071172 s\n",
      "10-20 14:45:21.219 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(192) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.219 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:21.219 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_192_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:21.219 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.8773E-5\n",
      "  total: 0.609435269\n",
      "  findBestSplits: 0.606804963\n",
      "  chooseSplits: 0.606125773\n",
      "10-20 14:45:21.220 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 329 from persistence list\n",
      "10-20 14:45:21.220 172.17.0.2:54325      7233   ad-pool-97  INFO org.apache.spark.storage.BlockManager: Removing RDD 329\n",
      "10-20 14:45:21.224 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 282 from persistence list\n",
      "10-20 14:45:21.224 172.17.0.2:54325      7233   d-pool-102  INFO org.apache.spark.storage.BlockManager: Removing RDD 282\n",
      "10-20 14:45:21.234 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:21.234 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:21.234 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:21.234 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:21.235 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_195 stored as values in memory (estimated size 40.0 B, free 418.8 MiB)\n",
      "10-20 14:45:21.236 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.8 MiB)\n",
      "10-20 14:45:21.236 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_195_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.0 MiB)\n",
      "10-20 14:45:21.236 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 195 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.249 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 354 (mapPartitions at RandomForest.scala:644) as input to shuffle 63\n",
      "10-20 14:45:21.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 67 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 131 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)\n",
      "10-20 14:45:21.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 130)\n",
      "10-20 14:45:21.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[354] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.256 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_196 stored as values in memory (estimated size 213.4 KiB, free 418.6 MiB)\n",
      "10-20 14:45:21.257 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 86.2 KiB, free 418.5 MiB)\n",
      "10-20 14:45:21.257 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_196_piece0 in memory on 95675304fa2d:39429 (size: 86.2 KiB, free: 419.9 MiB)\n",
      "10-20 14:45:21.258 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.258 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[354] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.258 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.259 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 530) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5406 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.260 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 130.0 (TID 530)\n",
      "10-20 14:45:21.273 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.274 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.275 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.275 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.storage.BlockManager: Found block rdd_326_0 locally\n",
      "10-20 14:45:21.292 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_194_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 419.9 MiB)\n",
      "10-20 14:45:21.293 172.17.0.2:54325      7233   ad-pool-26  INFO org.apache.spark.storage.BlockManager: Removing RDD 329\n",
      "10-20 14:45:21.295 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_187_piece0 on 95675304fa2d:39429 in memory (size: 82.9 KiB, free: 420.0 MiB)\n",
      "10-20 14:45:21.296 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_185_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 420.0 MiB)\n",
      "10-20 14:45:21.298 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_190_piece0 on 95675304fa2d:39429 in memory (size: 83.4 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:21.299 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_188_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:21.301 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_191_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:21.303 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_184_piece0 on 95675304fa2d:39429 in memory (size: 82.6 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:21.305 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_193_piece0 on 95675304fa2d:39429 in memory (size: 84.5 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:21.309 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_348_0 stored as values in memory (estimated size 1117.5 KiB, free 418.6 MiB)\n",
      "10-20 14:45:21.309 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_348_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:21.331 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_351_0 stored as values in memory (estimated size 914.4 KiB, free 417.7 MiB)\n",
      "10-20 14:45:21.332 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_351_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:21.354 172.17.0.2:54325      7233    (TID 530)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 130.0 (TID 530). 2133 bytes result sent to driver\n",
      "10-20 14:45:21.354 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 530) in 95 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 130 (mapPartitions at RandomForest.scala:644) finished in 0.103 s\n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 131)\n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[356] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.356 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_197 stored as values in memory (estimated size 6.0 KiB, free 417.7 MiB)\n",
      "10-20 14:45:21.371 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.7 MiB)\n",
      "10-20 14:45:21.371 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_197_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:21.371 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.372 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[356] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.372 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.373 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 131.0 (TID 531) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.374 172.17.0.2:54325      7233    (TID 531)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 131.0 (TID 531)\n",
      "10-20 14:45:21.376 172.17.0.2:54325      7233    (TID 531)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.376 172.17.0.2:54325      7233    (TID 531)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.378 172.17.0.2:54325      7233    (TID 531)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 131.0 (TID 531). 2076 bytes result sent to driver\n",
      "10-20 14:45:21.379 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 131.0 (TID 531) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.379 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 131 (collectAsMap at RandomForest.scala:663) finished in 0.023 s\n",
      "10-20 14:45:21.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished\n",
      "10-20 14:45:21.379 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 67 finished: collectAsMap at RandomForest.scala:663, took 0.130549 s\n",
      "10-20 14:45:21.380 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(195) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.381 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_195_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:21.381 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_198 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:21.382 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:21.382 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_198_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:21.383 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 198 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.395 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 357 (mapPartitions at RandomForest.scala:644) as input to shuffle 64\n",
      "10-20 14:45:21.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 68 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 133 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)\n",
      "10-20 14:45:21.395 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 132)\n",
      "10-20 14:45:21.396 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[357] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_199 stored as values in memory (estimated size 213.8 KiB, free 417.5 MiB)\n",
      "10-20 14:45:21.402 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.402 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_199_piece0 in memory on 95675304fa2d:39429 (size: 86.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:21.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[357] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.404 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 132.0 (TID 532) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5406 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.405 172.17.0.2:54325      7233    (TID 532)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 132.0 (TID 532)\n",
      "10-20 14:45:21.413 172.17.0.2:54325      7233    (TID 532)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.414 172.17.0.2:54325      7233    (TID 532)  INFO org.apache.spark.storage.BlockManager: Found block rdd_351_0 locally\n",
      "10-20 14:45:21.437 172.17.0.2:54325      7233    (TID 532)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 132.0 (TID 532). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.439 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 132.0 (TID 532) in 35 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.439 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 132 (mapPartitions at RandomForest.scala:644) finished in 0.043 s\n",
      "10-20 14:45:21.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 133)\n",
      "10-20 14:45:21.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[359] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.442 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_200 stored as values in memory (estimated size 6.5 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.443 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_200_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:21.444 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[359] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.446 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 133.0 (TID 533) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.447 172.17.0.2:54325      7233    (TID 533)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 133.0 (TID 533)\n",
      "10-20 14:45:21.449 172.17.0.2:54325      7233    (TID 533)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (19.7 KiB) non-empty blocks including 1 (19.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.449 172.17.0.2:54325      7233    (TID 533)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.451 172.17.0.2:54325      7233    (TID 533)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 133.0 (TID 533). 2584 bytes result sent to driver\n",
      "10-20 14:45:21.452 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 133.0 (TID 533) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.453 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.463 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 133 (collectAsMap at RandomForest.scala:663) finished in 0.022 s\n",
      "10-20 14:45:21.464 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.464 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished\n",
      "10-20 14:45:21.464 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 68 finished: collectAsMap at RandomForest.scala:663, took 0.069710 s\n",
      "10-20 14:45:21.465 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(198) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.466 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_198_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:21.469 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_201 stored as values in memory (estimated size 40.0 B, free 417.4 MiB)\n",
      "10-20 14:45:21.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.4 MiB)\n",
      "10-20 14:45:21.472 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_201_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:21.472 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 201 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.485 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 360 (mapPartitions at RandomForest.scala:644) as input to shuffle 65\n",
      "10-20 14:45:21.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 69 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 135 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)\n",
      "10-20 14:45:21.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 134)\n",
      "10-20 14:45:21.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[360] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_202 stored as values in memory (estimated size 214.4 KiB, free 417.2 MiB)\n",
      "10-20 14:45:21.493 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 86.8 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.493 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_202_piece0 in memory on 95675304fa2d:39429 (size: 86.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[360] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.495 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 134.0 (TID 534) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5406 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.495 172.17.0.2:54325      7233    (TID 534)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 134.0 (TID 534)\n",
      "10-20 14:45:21.506 172.17.0.2:54325      7233    (TID 534)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.506 172.17.0.2:54325      7233    (TID 534)  INFO org.apache.spark.storage.BlockManager: Found block rdd_351_0 locally\n",
      "10-20 14:45:21.532 172.17.0.2:54325      7233    (TID 534)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 134.0 (TID 534). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.533 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 134.0 (TID 534) in 38 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.533 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 134 (mapPartitions at RandomForest.scala:644) finished in 0.047 s\n",
      "10-20 14:45:21.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 135)\n",
      "10-20 14:45:21.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.534 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[362] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.535 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_203 stored as values in memory (estimated size 6.7 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.536 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.536 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_203_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.537 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.537 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[362] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.537 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.538 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 135.0 (TID 535) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.538 172.17.0.2:54325      7233    (TID 535)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 135.0 (TID 535)\n",
      "10-20 14:45:21.540 172.17.0.2:54325      7233    (TID 535)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.540 172.17.0.2:54325      7233    (TID 535)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.544 172.17.0.2:54325      7233    (TID 535)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 135.0 (TID 535). 3068 bytes result sent to driver\n",
      "10-20 14:45:21.544 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 135.0 (TID 535) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.544 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 135 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:21.546 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.546 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished\n",
      "10-20 14:45:21.547 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 69 finished: collectAsMap at RandomForest.scala:663, took 0.062083 s\n",
      "10-20 14:45:21.547 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(201) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.548 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_201_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:21.549 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_204 stored as values in memory (estimated size 40.0 B, free 417.1 MiB)\n",
      "10-20 14:45:21.549 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.1 MiB)\n",
      "10-20 14:45:21.550 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_204_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:21.550 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 204 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.589 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.589 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 363 (mapPartitions at RandomForest.scala:644) as input to shuffle 66\n",
      "10-20 14:45:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 70 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 137 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 136)\n",
      "10-20 14:45:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 136)\n",
      "10-20 14:45:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[363] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.595 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_205 stored as values in memory (estimated size 215.7 KiB, free 416.9 MiB)\n",
      "10-20 14:45:21.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 87.3 KiB, free 416.8 MiB)\n",
      "10-20 14:45:21.597 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_205_piece0 in memory on 95675304fa2d:39429 (size: 87.3 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:21.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[363] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.598 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 536) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5406 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.599 172.17.0.2:54325      7233    (TID 536)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 136.0 (TID 536)\n",
      "10-20 14:45:21.607 172.17.0.2:54325      7233    (TID 536)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.608 172.17.0.2:54325      7233    (TID 536)  INFO org.apache.spark.storage.BlockManager: Found block rdd_351_0 locally\n",
      "10-20 14:45:21.633 172.17.0.2:54325      7233    (TID 536)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 136.0 (TID 536). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 536) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 136 (mapPartitions at RandomForest.scala:644) finished in 0.043 s\n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 137)\n",
      "10-20 14:45:21.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.635 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[365] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.635 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_206 stored as values in memory (estimated size 7.1 KiB, free 416.8 MiB)\n",
      "10-20 14:45:21.636 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.8 MiB)\n",
      "10-20 14:45:21.637 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_206_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:21.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[365] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.638 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 537) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.639 172.17.0.2:54325      7233    (TID 537)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 137.0 (TID 537)\n",
      "10-20 14:45:21.642 172.17.0.2:54325      7233    (TID 537)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (38.4 KiB) non-empty blocks including 1 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.642 172.17.0.2:54325      7233    (TID 537)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.648 172.17.0.2:54325      7233    (TID 537)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 137.0 (TID 537). 3901 bytes result sent to driver\n",
      "10-20 14:45:21.649 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 537) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.649 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.649 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 137 (collectAsMap at RandomForest.scala:663) finished in 0.014 s\n",
      "10-20 14:45:21.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished\n",
      "10-20 14:45:21.650 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 70 finished: collectAsMap at RandomForest.scala:663, took 0.061217 s\n",
      "10-20 14:45:21.650 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(204) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.651 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_204_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:21.652 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_207 stored as values in memory (estimated size 40.0 B, free 416.8 MiB)\n",
      "10-20 14:45:21.652 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.8 MiB)\n",
      "10-20 14:45:21.653 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_207_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:21.653 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 207 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.665 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 366 (mapPartitions at RandomForest.scala:644) as input to shuffle 67\n",
      "10-20 14:45:21.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 71 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 139 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)\n",
      "10-20 14:45:21.667 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 138)\n",
      "10-20 14:45:21.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[366] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.674 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_208 stored as values in memory (estimated size 218.0 KiB, free 416.6 MiB)\n",
      "10-20 14:45:21.676 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 88.4 KiB, free 416.5 MiB)\n",
      "10-20 14:45:21.676 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_208_piece0 in memory on 95675304fa2d:39429 (size: 88.4 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:21.677 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.677 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[366] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.677 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.678 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 138.0 (TID 538) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5406 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.679 172.17.0.2:54325      7233    (TID 538)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 138.0 (TID 538)\n",
      "10-20 14:45:21.688 172.17.0.2:54325      7233    (TID 538)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.688 172.17.0.2:54325      7233    (TID 538)  INFO org.apache.spark.storage.BlockManager: Found block rdd_351_0 locally\n",
      "10-20 14:45:21.716 172.17.0.2:54325      7233    (TID 538)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 138.0 (TID 538). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.718 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 138.0 (TID 538) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.718 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 138 (mapPartitions at RandomForest.scala:644) finished in 0.050 s\n",
      "10-20 14:45:21.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 139)\n",
      "10-20 14:45:21.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[368] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.721 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_209 stored as values in memory (estimated size 7.8 KiB, free 416.5 MiB)\n",
      "10-20 14:45:21.739 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.5 MiB)\n",
      "10-20 14:45:21.739 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_200_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:21.739 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_209_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:21.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[368] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.741 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.741 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_202_piece0 on 95675304fa2d:39429 in memory (size: 86.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:21.742 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 539) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.743 172.17.0.2:54325      7233    (TID 539)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 139.0 (TID 539)\n",
      "10-20 14:45:21.744 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_205_piece0 on 95675304fa2d:39429 in memory (size: 87.3 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.745 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_197_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.747 172.17.0.2:54325      7233    (TID 539)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (61.8 KiB) non-empty blocks including 1 (61.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.747 172.17.0.2:54325      7233    (TID 539)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.748 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_203_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.749 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_206_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.750 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_196_piece0 on 95675304fa2d:39429 in memory (size: 86.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:21.752 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_199_piece0 on 95675304fa2d:39429 in memory (size: 86.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:21.757 172.17.0.2:54325      7233    (TID 539)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 139.0 (TID 539). 5640 bytes result sent to driver\n",
      "10-20 14:45:21.758 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 539) in 16 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.758 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.758 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 139 (collectAsMap at RandomForest.scala:663) finished in 0.038 s\n",
      "10-20 14:45:21.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished\n",
      "10-20 14:45:21.759 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 71 finished: collectAsMap at RandomForest.scala:663, took 0.093692 s\n",
      "10-20 14:45:21.759 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(207) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.760 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:21.760 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 4.4286E-5\n",
      "  total: 0.525938668\n",
      "  findBestSplits: 0.52378143\n",
      "  chooseSplits: 0.523002264\n",
      "10-20 14:45:21.760 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_207_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:21.760 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 351 from persistence list\n",
      "10-20 14:45:21.761 172.17.0.2:54325      7233   d-pool-118  INFO org.apache.spark.storage.BlockManager: Removing RDD 351\n",
      "10-20 14:45:21.765 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 304 from persistence list\n",
      "10-20 14:45:21.765 172.17.0.2:54325      7233   ad-pool-29  INFO org.apache.spark.storage.BlockManager: Removing RDD 304\n",
      "10-20 14:45:21.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:21.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:21.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:21.773 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:21.774 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_210 stored as values in memory (estimated size 40.0 B, free 419.7 MiB)\n",
      "10-20 14:45:21.775 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.7 MiB)\n",
      "10-20 14:45:21.775 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_210_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.3 MiB)\n",
      "10-20 14:45:21.775 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 210 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.794 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 376 (mapPartitions at RandomForest.scala:644) as input to shuffle 68\n",
      "10-20 14:45:21.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 72 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 141 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)\n",
      "10-20 14:45:21.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 140)\n",
      "10-20 14:45:21.797 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[376] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.803 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_211 stored as values in memory (estimated size 220.9 KiB, free 419.5 MiB)\n",
      "10-20 14:45:21.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 90.1 KiB, free 419.4 MiB)\n",
      "10-20 14:45:21.805 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_211_piece0 in memory on 95675304fa2d:39429 (size: 90.1 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:21.806 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.806 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[376] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.806 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.807 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 540) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5438 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.808 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 140.0 (TID 540)\n",
      "10-20 14:45:21.816 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.821 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.822 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.822 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.storage.BlockManager: Found block rdd_348_0 locally\n",
      "10-20 14:45:21.845 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_370_0 stored as values in memory (estimated size 1117.5 KiB, free 418.3 MiB)\n",
      "10-20 14:45:21.846 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_370_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:21.868 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_373_0 stored as values in memory (estimated size 914.4 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.869 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_373_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:21.891 172.17.0.2:54325      7233    (TID 540)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 140.0 (TID 540). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 540) in 85 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 140 (mapPartitions at RandomForest.scala:644) finished in 0.094 s\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 141)\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[378] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_212 stored as values in memory (estimated size 6.0 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.4 MiB)\n",
      "10-20 14:45:21.895 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_212_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:21.895 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.895 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[378] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.895 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.896 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 141.0 (TID 541) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.897 172.17.0.2:54325      7233    (TID 541)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 141.0 (TID 541)\n",
      "10-20 14:45:21.899 172.17.0.2:54325      7233    (TID 541)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:21.900 172.17.0.2:54325      7233    (TID 541)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:21.901 172.17.0.2:54325      7233    (TID 541)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 141.0 (TID 541). 2296 bytes result sent to driver\n",
      "10-20 14:45:21.902 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 141.0 (TID 541) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.902 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 141 (collectAsMap at RandomForest.scala:663) finished in 0.009 s\n",
      "10-20 14:45:21.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:21.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished\n",
      "10-20 14:45:21.903 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 72 finished: collectAsMap at RandomForest.scala:663, took 0.108868 s\n",
      "10-20 14:45:21.904 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(210) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:21.905 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_210_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:21.905 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_213 stored as values in memory (estimated size 40.0 B, free 417.4 MiB)\n",
      "10-20 14:45:21.906 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.4 MiB)\n",
      "10-20 14:45:21.906 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_213_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:21.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 213 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:21.920 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:21.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 379 (mapPartitions at RandomForest.scala:644) as input to shuffle 69\n",
      "10-20 14:45:21.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 73 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:21.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 143 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:21.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)\n",
      "10-20 14:45:21.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 142)\n",
      "10-20 14:45:21.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[379] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:21.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_214 stored as values in memory (estimated size 221.4 KiB, free 417.2 MiB)\n",
      "10-20 14:45:21.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 90.4 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.928 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_214_piece0 in memory on 95675304fa2d:39429 (size: 90.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.929 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[379] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.929 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.930 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 142.0 (TID 542) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5438 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.930 172.17.0.2:54325      7233    (TID 542)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 142.0 (TID 542)\n",
      "10-20 14:45:21.961 172.17.0.2:54325      7233    (TID 542)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:21.961 172.17.0.2:54325      7233    (TID 542)  INFO org.apache.spark.storage.BlockManager: Found block rdd_373_0 locally\n",
      "10-20 14:45:21.985 172.17.0.2:54325      7233    (TID 542)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 142.0 (TID 542). 2090 bytes result sent to driver\n",
      "10-20 14:45:21.986 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 142.0 (TID 542) in 57 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:21.987 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:21.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 142 (mapPartitions at RandomForest.scala:644) finished in 0.066 s\n",
      "10-20 14:45:21.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:21.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:21.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 143)\n",
      "10-20 14:45:21.988 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:21.989 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[381] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:21.990 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_215 stored as values in memory (estimated size 6.5 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.1 MiB)\n",
      "10-20 14:45:21.992 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_215_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:21.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:21.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[381] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:21.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 143.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:21.996 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 143.0 (TID 543) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:21.999 172.17.0.2:54325      7233    (TID 543)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 143.0 (TID 543)\n",
      "10-20 14:45:22.002 172.17.0.2:54325      7233    (TID 543)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.002 172.17.0.2:54325      7233    (TID 543)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.007 172.17.0.2:54325      7233    (TID 543)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 143.0 (TID 543). 2584 bytes result sent to driver\n",
      "10-20 14:45:22.008 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 143.0 (TID 543) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.009 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 143 (collectAsMap at RandomForest.scala:663) finished in 0.021 s\n",
      "10-20 14:45:22.011 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.012 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 143: Stage finished\n",
      "10-20 14:45:22.013 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 73 finished: collectAsMap at RandomForest.scala:663, took 0.091961 s\n",
      "10-20 14:45:22.013 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(213) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.015 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_213_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:22.015 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_216 stored as values in memory (estimated size 40.0 B, free 417.1 MiB)\n",
      "10-20 14:45:22.015 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.1 MiB)\n",
      "10-20 14:45:22.016 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_216_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:22.016 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 216 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.035 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.036 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 382 (mapPartitions at RandomForest.scala:644) as input to shuffle 70\n",
      "10-20 14:45:22.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 74 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 145 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)\n",
      "10-20 14:45:22.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 144)\n",
      "10-20 14:45:22.038 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 144 (MapPartitionsRDD[382] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_217 stored as values in memory (estimated size 222.0 KiB, free 416.9 MiB)\n",
      "10-20 14:45:22.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 90.7 KiB, free 416.8 MiB)\n",
      "10-20 14:45:22.048 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_217_piece0 in memory on 95675304fa2d:39429 (size: 90.7 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:22.049 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.049 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 144 (MapPartitionsRDD[382] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.049 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.051 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 144.0 (TID 544) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5438 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.052 172.17.0.2:54325      7233    (TID 544)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 144.0 (TID 544)\n",
      "10-20 14:45:22.068 172.17.0.2:54325      7233    (TID 544)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.068 172.17.0.2:54325      7233    (TID 544)  INFO org.apache.spark.storage.BlockManager: Found block rdd_373_0 locally\n",
      "10-20 14:45:22.081 172.17.0.2:54325      7233   ad-pool-44  INFO org.apache.spark.storage.BlockManager: Removing RDD 351\n",
      "10-20 14:45:22.084 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_212_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:22.086 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_211_piece0 on 95675304fa2d:39429 in memory (size: 90.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:22.089 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_209_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:22.091 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_215_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:22.093 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_214_piece0 on 95675304fa2d:39429 in memory (size: 90.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:22.095 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_208_piece0 on 95675304fa2d:39429 in memory (size: 88.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.121 172.17.0.2:54325      7233    (TID 544)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 144.0 (TID 544). 2133 bytes result sent to driver\n",
      "10-20 14:45:22.123 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 144.0 (TID 544) in 72 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.123 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 144 (mapPartitions at RandomForest.scala:644) finished in 0.084 s\n",
      "10-20 14:45:22.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 145)\n",
      "10-20 14:45:22.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[384] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.126 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_218 stored as values in memory (estimated size 6.7 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.127 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.127 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_218_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[384] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.129 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 145.0 (TID 545) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.130 172.17.0.2:54325      7233    (TID 545)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 145.0 (TID 545)\n",
      "10-20 14:45:22.133 172.17.0.2:54325      7233    (TID 545)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.133 172.17.0.2:54325      7233    (TID 545)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.138 172.17.0.2:54325      7233    (TID 545)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 145.0 (TID 545). 3033 bytes result sent to driver\n",
      "10-20 14:45:22.139 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 145.0 (TID 545) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.139 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.141 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 145 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:22.141 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.141 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished\n",
      "10-20 14:45:22.141 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 74 finished: collectAsMap at RandomForest.scala:663, took 0.106273 s\n",
      "10-20 14:45:22.142 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(216) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.143 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_216_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.144 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_219 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.155 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.156 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_219_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.156 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_218_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.156 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 219 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.157 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_217_piece0 on 95675304fa2d:39429 in memory (size: 90.7 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:22.170 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 385 (mapPartitions at RandomForest.scala:644) as input to shuffle 71\n",
      "10-20 14:45:22.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 75 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 147 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)\n",
      "10-20 14:45:22.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 146)\n",
      "10-20 14:45:22.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[385] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.178 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_220 stored as values in memory (estimated size 223.3 KiB, free 417.8 MiB)\n",
      "10-20 14:45:22.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 91.2 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.179 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_220_piece0 in memory on 95675304fa2d:39429 (size: 91.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[385] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 146.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.180 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 546) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5438 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.180 172.17.0.2:54325      7233    (TID 546)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 146.0 (TID 546)\n",
      "10-20 14:45:22.190 172.17.0.2:54325      7233    (TID 546)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.190 172.17.0.2:54325      7233    (TID 546)  INFO org.apache.spark.storage.BlockManager: Found block rdd_373_0 locally\n",
      "10-20 14:45:22.220 172.17.0.2:54325      7233    (TID 546)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 146.0 (TID 546). 2090 bytes result sent to driver\n",
      "10-20 14:45:22.221 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 546) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.221 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 146 (mapPartitions at RandomForest.scala:644) finished in 0.050 s\n",
      "10-20 14:45:22.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 147)\n",
      "10-20 14:45:22.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[387] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_221 stored as values in memory (estimated size 7.1 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.226 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_221_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.226 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.226 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[387] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.226 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.227 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 147.0 (TID 547) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.228 172.17.0.2:54325      7233    (TID 547)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 147.0 (TID 547)\n",
      "10-20 14:45:22.230 172.17.0.2:54325      7233    (TID 547)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.230 172.17.0.2:54325      7233    (TID 547)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.235 172.17.0.2:54325      7233    (TID 547)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 147.0 (TID 547). 3866 bytes result sent to driver\n",
      "10-20 14:45:22.238 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 147.0 (TID 547) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.238 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.238 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 147 (collectAsMap at RandomForest.scala:663) finished in 0.015 s\n",
      "10-20 14:45:22.238 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.238 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished\n",
      "10-20 14:45:22.239 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 75 finished: collectAsMap at RandomForest.scala:663, took 0.068738 s\n",
      "10-20 14:45:22.240 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(219) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.241 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_219_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_222 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.243 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.243 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_222_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.244 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 222 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.260 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 388 (mapPartitions at RandomForest.scala:644) as input to shuffle 72\n",
      "10-20 14:45:22.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 76 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 149 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 148)\n",
      "10-20 14:45:22.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 148)\n",
      "10-20 14:45:22.263 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 148 (MapPartitionsRDD[388] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.268 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_223 stored as values in memory (estimated size 225.6 KiB, free 417.5 MiB)\n",
      "10-20 14:45:22.269 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 92.4 KiB, free 417.4 MiB)\n",
      "10-20 14:45:22.270 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_223_piece0 in memory on 95675304fa2d:39429 (size: 92.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:22.270 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[388] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.271 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 148.0 (TID 548) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5438 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.272 172.17.0.2:54325      7233    (TID 548)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 148.0 (TID 548)\n",
      "10-20 14:45:22.281 172.17.0.2:54325      7233    (TID 548)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.281 172.17.0.2:54325      7233    (TID 548)  INFO org.apache.spark.storage.BlockManager: Found block rdd_373_0 locally\n",
      "10-20 14:45:22.315 172.17.0.2:54325      7233    (TID 548)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 148.0 (TID 548). 2090 bytes result sent to driver\n",
      "10-20 14:45:22.316 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 148.0 (TID 548) in 45 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.316 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 148 (mapPartitions at RandomForest.scala:644) finished in 0.054 s\n",
      "10-20 14:45:22.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 149)\n",
      "10-20 14:45:22.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[390] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_224 stored as values in memory (estimated size 7.9 KiB, free 417.4 MiB)\n",
      "10-20 14:45:22.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.4 MiB)\n",
      "10-20 14:45:22.319 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_224_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:22.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[390] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 149.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.320 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 149.0 (TID 549) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.321 172.17.0.2:54325      7233    (TID 549)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 149.0 (TID 549)\n",
      "10-20 14:45:22.324 172.17.0.2:54325      7233    (TID 549)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.324 172.17.0.2:54325      7233    (TID 549)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.334 172.17.0.2:54325      7233    (TID 549)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 149.0 (TID 549). 5551 bytes result sent to driver\n",
      "10-20 14:45:22.335 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 149.0 (TID 549) in 15 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.335 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.335 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 149 (collectAsMap at RandomForest.scala:663) finished in 0.018 s\n",
      "10-20 14:45:22.335 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.335 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished\n",
      "10-20 14:45:22.336 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 76 finished: collectAsMap at RandomForest.scala:663, took 0.075606 s\n",
      "10-20 14:45:22.336 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(222) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.336 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:22.336 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_222_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:22.337 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.2039E-5\n",
      "  total: 0.563632838\n",
      "  findBestSplits: 0.562175695\n",
      "  chooseSplits: 0.561329305\n",
      "10-20 14:45:22.337 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 373 from persistence list\n",
      "10-20 14:45:22.338 172.17.0.2:54325      7233   ad-pool-93  INFO org.apache.spark.storage.BlockManager: Removing RDD 373\n",
      "10-20 14:45:22.342 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 326 from persistence list\n",
      "10-20 14:45:22.343 172.17.0.2:54325      7233   ad-pool-98  INFO org.apache.spark.storage.BlockManager: Removing RDD 326\n",
      "10-20 14:45:22.375 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:22.375 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:22.375 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:22.375 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:22.376 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_225 stored as values in memory (estimated size 40.0 B, free 419.4 MiB)\n",
      "10-20 14:45:22.376 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.4 MiB)\n",
      "10-20 14:45:22.376 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_225_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:22.377 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 225 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.390 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 398 (mapPartitions at RandomForest.scala:644) as input to shuffle 73\n",
      "10-20 14:45:22.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 77 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 151 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 150)\n",
      "10-20 14:45:22.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 150)\n",
      "10-20 14:45:22.393 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[398] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_226 stored as values in memory (estimated size 228.1 KiB, free 419.1 MiB)\n",
      "10-20 14:45:22.400 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 94.0 KiB, free 419.1 MiB)\n",
      "10-20 14:45:22.400 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_226_piece0 in memory on 95675304fa2d:39429 (size: 94.0 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:22.400 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[398] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.401 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 150.0 (TID 550) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5470 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.402 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 150.0 (TID 550)\n",
      "10-20 14:45:22.411 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.412 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.412 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.412 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.storage.BlockManager: Found block rdd_370_0 locally\n",
      "10-20 14:45:22.438 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_392_0 stored as values in memory (estimated size 1117.5 KiB, free 418.0 MiB)\n",
      "10-20 14:45:22.438 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_392_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:22.464 172.17.0.2:54325      7233   d-pool-103  INFO org.apache.spark.storage.BlockManager: Removing RDD 373\n",
      "10-20 14:45:22.466 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_221_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:22.468 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_224_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:22.472 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_220_piece0 on 95675304fa2d:39429 in memory (size: 91.2 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:22.473 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_223_piece0 on 95675304fa2d:39429 in memory (size: 92.4 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:22.474 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_395_0 stored as values in memory (estimated size 914.4 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.474 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_395_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.499 172.17.0.2:54325      7233    (TID 550)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 150.0 (TID 550). 2133 bytes result sent to driver\n",
      "10-20 14:45:22.500 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 150.0 (TID 550) in 99 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.500 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.501 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 150 (mapPartitions at RandomForest.scala:644) finished in 0.107 s\n",
      "10-20 14:45:22.501 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.501 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.501 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 151)\n",
      "10-20 14:45:22.501 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[400] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_227 stored as values in memory (estimated size 6.0 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.503 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_227_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[400] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 151.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.504 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 151.0 (TID 551) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.505 172.17.0.2:54325      7233    (TID 551)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 151.0 (TID 551)\n",
      "10-20 14:45:22.508 172.17.0.2:54325      7233    (TID 551)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.509 172.17.0.2:54325      7233    (TID 551)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.511 172.17.0.2:54325      7233    (TID 551)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 151.0 (TID 551). 2296 bytes result sent to driver\n",
      "10-20 14:45:22.512 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 151.0 (TID 551) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.512 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.512 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 151 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:22.512 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.512 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished\n",
      "10-20 14:45:22.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 77 finished: collectAsMap at RandomForest.scala:663, took 0.122232 s\n",
      "10-20 14:45:22.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(225) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.514 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_228 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.515 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.515 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_225_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.515 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_228_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.516 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 228 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.534 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.535 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 401 (mapPartitions at RandomForest.scala:644) as input to shuffle 74\n",
      "10-20 14:45:22.535 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 78 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.535 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 153 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.535 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 152)\n",
      "10-20 14:45:22.535 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 152)\n",
      "10-20 14:45:22.536 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 152 (MapPartitionsRDD[401] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_229 stored as values in memory (estimated size 228.6 KiB, free 417.5 MiB)\n",
      "10-20 14:45:22.553 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_226_piece0 on 95675304fa2d:39429 in memory (size: 94.0 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:22.554 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_227_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:22.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 94.3 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.555 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_229_piece0 in memory on 95675304fa2d:39429 (size: 94.3 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 152 (MapPartitionsRDD[401] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.556 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 152.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.557 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 152.0 (TID 552) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5470 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.557 172.17.0.2:54325      7233    (TID 552)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 152.0 (TID 552)\n",
      "10-20 14:45:22.568 172.17.0.2:54325      7233    (TID 552)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.569 172.17.0.2:54325      7233    (TID 552)  INFO org.apache.spark.storage.BlockManager: Found block rdd_395_0 locally\n",
      "10-20 14:45:22.596 172.17.0.2:54325      7233    (TID 552)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 152.0 (TID 552). 2090 bytes result sent to driver\n",
      "10-20 14:45:22.597 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 152.0 (TID 552) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.598 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.599 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 152 (mapPartitions at RandomForest.scala:644) finished in 0.063 s\n",
      "10-20 14:45:22.599 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.600 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.600 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 153)\n",
      "10-20 14:45:22.600 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.600 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[403] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.603 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_230 stored as values in memory (estimated size 6.5 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.604 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.7 MiB)\n",
      "10-20 14:45:22.604 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_230_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:22.604 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[403] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 153.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.606 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 153.0 (TID 553) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.607 172.17.0.2:54325      7233    (TID 553)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 153.0 (TID 553)\n",
      "10-20 14:45:22.609 172.17.0.2:54325      7233    (TID 553)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.609 172.17.0.2:54325      7233    (TID 553)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.611 172.17.0.2:54325      7233    (TID 553)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 153.0 (TID 553). 2584 bytes result sent to driver\n",
      "10-20 14:45:22.612 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 153.0 (TID 553) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.612 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.612 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 153 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:22.613 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.613 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 153: Stage finished\n",
      "10-20 14:45:22.613 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 78 finished: collectAsMap at RandomForest.scala:663, took 0.079037 s\n",
      "10-20 14:45:22.613 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(228) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.614 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_228_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.615 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_231 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.616 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:22.617 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_231_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:22.617 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 231 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.630 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.631 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 404 (mapPartitions at RandomForest.scala:644) as input to shuffle 75\n",
      "10-20 14:45:22.631 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 79 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.631 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 155 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.631 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 154)\n",
      "10-20 14:45:22.631 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 154)\n",
      "10-20 14:45:22.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[404] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_232 stored as values in memory (estimated size 229.2 KiB, free 417.5 MiB)\n",
      "10-20 14:45:22.639 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 94.6 KiB, free 417.4 MiB)\n",
      "10-20 14:45:22.641 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_232_piece0 in memory on 95675304fa2d:39429 (size: 94.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:22.646 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.646 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[404] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.646 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.651 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 154.0 (TID 554) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5470 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.652 172.17.0.2:54325      7233    (TID 554)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 154.0 (TID 554)\n",
      "10-20 14:45:22.666 172.17.0.2:54325      7233    (TID 554)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.666 172.17.0.2:54325      7233    (TID 554)  INFO org.apache.spark.storage.BlockManager: Found block rdd_395_0 locally\n",
      "10-20 14:45:22.700 172.17.0.2:54325      7233    (TID 554)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 154.0 (TID 554). 2090 bytes result sent to driver\n",
      "10-20 14:45:22.701 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 154.0 (TID 554) in 50 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.701 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 154 (mapPartitions at RandomForest.scala:644) finished in 0.070 s\n",
      "10-20 14:45:22.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 155)\n",
      "10-20 14:45:22.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[406] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.707 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_233 stored as values in memory (estimated size 6.7 KiB, free 417.4 MiB)\n",
      "10-20 14:45:22.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.4 MiB)\n",
      "10-20 14:45:22.708 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_233_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:22.709 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.709 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[406] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.709 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 155.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.710 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 155.0 (TID 555) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.713 172.17.0.2:54325      7233    (TID 555)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 155.0 (TID 555)\n",
      "10-20 14:45:22.715 172.17.0.2:54325      7233    (TID 555)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.715 172.17.0.2:54325      7233    (TID 555)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.718 172.17.0.2:54325      7233    (TID 555)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 155.0 (TID 555). 3068 bytes result sent to driver\n",
      "10-20 14:45:22.719 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 155.0 (TID 555) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.719 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 155 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:22.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 155: Stage finished\n",
      "10-20 14:45:22.720 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 79 finished: collectAsMap at RandomForest.scala:663, took 0.089826 s\n",
      "10-20 14:45:22.720 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(231) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.722 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_231_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:22.722 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_234 stored as values in memory (estimated size 40.0 B, free 417.4 MiB)\n",
      "10-20 14:45:22.723 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.4 MiB)\n",
      "10-20 14:45:22.724 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_234_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:22.724 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 234 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.738 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.739 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 407 (mapPartitions at RandomForest.scala:644) as input to shuffle 76\n",
      "10-20 14:45:22.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 80 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 157 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 156)\n",
      "10-20 14:45:22.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 156)\n",
      "10-20 14:45:22.740 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 156 (MapPartitionsRDD[407] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_235 stored as values in memory (estimated size 230.5 KiB, free 417.1 MiB)\n",
      "10-20 14:45:22.755 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 95.1 KiB, free 417.1 MiB)\n",
      "10-20 14:45:22.756 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_235_piece0 in memory on 95675304fa2d:39429 (size: 95.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:22.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.757 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 156 (MapPartitionsRDD[407] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.757 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.758 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 156.0 (TID 556) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5470 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.759 172.17.0.2:54325      7233    (TID 556)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 156.0 (TID 556)\n",
      "10-20 14:45:22.797 172.17.0.2:54325      7233    (TID 556)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.797 172.17.0.2:54325      7233    (TID 556)  INFO org.apache.spark.storage.BlockManager: Found block rdd_395_0 locally\n",
      "10-20 14:45:22.829 172.17.0.2:54325      7233    (TID 556)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 156.0 (TID 556). 2090 bytes result sent to driver\n",
      "10-20 14:45:22.830 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 156.0 (TID 556) in 72 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.830 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 156 (mapPartitions at RandomForest.scala:644) finished in 0.089 s\n",
      "10-20 14:45:22.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 157)\n",
      "10-20 14:45:22.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[409] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.832 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_236 stored as values in memory (estimated size 7.1 KiB, free 417.0 MiB)\n",
      "10-20 14:45:22.832 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.0 MiB)\n",
      "10-20 14:45:22.833 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_236_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:22.833 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.833 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[409] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.833 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 157.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.836 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 157.0 (TID 557) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.836 172.17.0.2:54325      7233    (TID 557)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 157.0 (TID 557)\n",
      "10-20 14:45:22.839 172.17.0.2:54325      7233    (TID 557)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.839 172.17.0.2:54325      7233    (TID 557)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.845 172.17.0.2:54325      7233    (TID 557)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 157.0 (TID 557). 3901 bytes result sent to driver\n",
      "10-20 14:45:22.846 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 157.0 (TID 557) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.846 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 157 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:22.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished\n",
      "10-20 14:45:22.853 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 80 finished: collectAsMap at RandomForest.scala:663, took 0.114309 s\n",
      "10-20 14:45:22.853 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(234) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.854 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_234_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:22.855 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_237 stored as values in memory (estimated size 40.0 B, free 417.0 MiB)\n",
      "10-20 14:45:22.855 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.0 MiB)\n",
      "10-20 14:45:22.855 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_237_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:22.856 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 237 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.870 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 410 (mapPartitions at RandomForest.scala:644) as input to shuffle 77\n",
      "10-20 14:45:22.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 81 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 159 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 158)\n",
      "10-20 14:45:22.871 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 158)\n",
      "10-20 14:45:22.873 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 158 (MapPartitionsRDD[410] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_238 stored as values in memory (estimated size 232.8 KiB, free 416.8 MiB)\n",
      "10-20 14:45:22.881 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 96.1 KiB, free 416.7 MiB)\n",
      "10-20 14:45:22.881 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_238_piece0 in memory on 95675304fa2d:39429 (size: 96.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:22.882 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.882 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 158 (MapPartitionsRDD[410] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.882 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 158.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.884 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 158.0 (TID 558) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5470 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.884 172.17.0.2:54325      7233    (TID 558)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 158.0 (TID 558)\n",
      "10-20 14:45:22.896 172.17.0.2:54325      7233    (TID 558)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:22.896 172.17.0.2:54325      7233    (TID 558)  INFO org.apache.spark.storage.BlockManager: Found block rdd_395_0 locally\n",
      "10-20 14:45:22.925 172.17.0.2:54325      7233    (TID 558)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 158.0 (TID 558). 2090 bytes result sent to driver\n",
      "10-20 14:45:22.926 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 158.0 (TID 558) in 43 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.926 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.926 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 158 (mapPartitions at RandomForest.scala:644) finished in 0.053 s\n",
      "10-20 14:45:22.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:22.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:22.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 159)\n",
      "10-20 14:45:22.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:22.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[412] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:22.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_239 stored as values in memory (estimated size 7.8 KiB, free 416.7 MiB)\n",
      "10-20 14:45:22.929 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.7 MiB)\n",
      "10-20 14:45:22.929 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_239_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:22.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[412] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 159.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.930 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 159.0 (TID 559) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.931 172.17.0.2:54325      7233    (TID 559)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 159.0 (TID 559)\n",
      "10-20 14:45:22.934 172.17.0.2:54325      7233    (TID 559)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (61.8 KiB) non-empty blocks including 1 (61.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:22.934 172.17.0.2:54325      7233    (TID 559)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:22.942 172.17.0.2:54325      7233    (TID 559)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 159.0 (TID 559). 5508 bytes result sent to driver\n",
      "10-20 14:45:22.943 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 159.0 (TID 559) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:22.943 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:22.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 159 (collectAsMap at RandomForest.scala:663) finished in 0.017 s\n",
      "10-20 14:45:22.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:22.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished\n",
      "10-20 14:45:22.944 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 81 finished: collectAsMap at RandomForest.scala:663, took 0.074508 s\n",
      "10-20 14:45:22.945 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(237) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:22.945 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:22.945 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 4.2142E-5\n",
      "  total: 0.570164546\n",
      "  findBestSplits: 0.568709875\n",
      "  chooseSplits: 0.568131505\n",
      "10-20 14:45:22.945 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_237_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:22.946 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 395 from persistence list\n",
      "10-20 14:45:22.946 172.17.0.2:54325      7233   ad-pool-56  INFO org.apache.spark.storage.BlockManager: Removing RDD 395\n",
      "10-20 14:45:22.950 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 348 from persistence list\n",
      "10-20 14:45:22.951 172.17.0.2:54325      7233   ad-pool-60  INFO org.apache.spark.storage.BlockManager: Removing RDD 348\n",
      "10-20 14:45:22.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:22.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:22.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:22.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:22.959 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_240 stored as values in memory (estimated size 40.0 B, free 418.7 MiB)\n",
      "10-20 14:45:22.968 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.7 MiB)\n",
      "10-20 14:45:22.969 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_240_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.0 MiB)\n",
      "10-20 14:45:22.970 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 240 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:22.971 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_229_piece0 on 95675304fa2d:39429 in memory (size: 94.3 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:22.973 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_238_piece0 on 95675304fa2d:39429 in memory (size: 96.1 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:22.974 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_233_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:22.975 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_239_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:22.975 172.17.0.2:54325      7233   ad-pool-95  INFO org.apache.spark.storage.BlockManager: Removing RDD 395\n",
      "10-20 14:45:22.977 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_235_piece0 on 95675304fa2d:39429 in memory (size: 95.1 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:22.979 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_232_piece0 on 95675304fa2d:39429 in memory (size: 94.6 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:22.981 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_236_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:22.982 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_230_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:22.984 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:22.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 420 (mapPartitions at RandomForest.scala:644) as input to shuffle 78\n",
      "10-20 14:45:22.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 82 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:22.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 161 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:22.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)\n",
      "10-20 14:45:22.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 160)\n",
      "10-20 14:45:22.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 160 (MapPartitionsRDD[420] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:22.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_241 stored as values in memory (estimated size 235.5 KiB, free 419.8 MiB)\n",
      "10-20 14:45:22.993 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 98.1 KiB, free 419.7 MiB)\n",
      "10-20 14:45:22.993 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_241_piece0 in memory on 95675304fa2d:39429 (size: 98.1 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:22.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:22.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 160 (MapPartitionsRDD[420] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:22.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 160.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:22.996 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 160.0 (TID 560) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5502 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:22.996 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 160.0 (TID 560)\n",
      "10-20 14:45:23.006 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.007 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.007 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.008 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.storage.BlockManager: Found block rdd_392_0 locally\n",
      "10-20 14:45:23.033 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_414_0 stored as values in memory (estimated size 1117.5 KiB, free 418.6 MiB)\n",
      "10-20 14:45:23.033 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_414_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:23.057 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_417_0 stored as values in memory (estimated size 914.4 KiB, free 417.7 MiB)\n",
      "10-20 14:45:23.057 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_417_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:23.082 172.17.0.2:54325      7233    (TID 560)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 160.0 (TID 560). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.083 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 160.0 (TID 560) in 87 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.083 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 160 (mapPartitions at RandomForest.scala:644) finished in 0.096 s\n",
      "10-20 14:45:23.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 161)\n",
      "10-20 14:45:23.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[422] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.085 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_242 stored as values in memory (estimated size 6.0 KiB, free 417.7 MiB)\n",
      "10-20 14:45:23.086 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.7 MiB)\n",
      "10-20 14:45:23.086 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_242_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:23.087 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.088 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[422] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.088 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 161.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.089 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 161.0 (TID 561) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.090 172.17.0.2:54325      7233    (TID 561)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 161.0 (TID 561)\n",
      "10-20 14:45:23.093 172.17.0.2:54325      7233    (TID 561)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.093 172.17.0.2:54325      7233    (TID 561)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.096 172.17.0.2:54325      7233    (TID 561)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 161.0 (TID 561). 2076 bytes result sent to driver\n",
      "10-20 14:45:23.096 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 161.0 (TID 561) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.096 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 161 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:23.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished\n",
      "10-20 14:45:23.100 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 82 finished: collectAsMap at RandomForest.scala:663, took 0.115893 s\n",
      "10-20 14:45:23.101 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(240) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.102 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_243 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:23.102 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:23.104 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_240_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:23.104 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_243_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:23.104 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 243 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.119 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.120 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 423 (mapPartitions at RandomForest.scala:644) as input to shuffle 79\n",
      "10-20 14:45:23.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 83 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 163 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)\n",
      "10-20 14:45:23.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 162)\n",
      "10-20 14:45:23.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[423] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.129 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_244 stored as values in memory (estimated size 236.0 KiB, free 417.5 MiB)\n",
      "10-20 14:45:23.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 98.4 KiB, free 417.4 MiB)\n",
      "10-20 14:45:23.131 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_244_piece0 in memory on 95675304fa2d:39429 (size: 98.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[423] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.136 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.137 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 162.0 (TID 562) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5502 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.138 172.17.0.2:54325      7233    (TID 562)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 162.0 (TID 562)\n",
      "10-20 14:45:23.148 172.17.0.2:54325      7233    (TID 562)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.148 172.17.0.2:54325      7233    (TID 562)  INFO org.apache.spark.storage.BlockManager: Found block rdd_417_0 locally\n",
      "10-20 14:45:23.194 172.17.0.2:54325      7233    (TID 562)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 162.0 (TID 562). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.195 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 162.0 (TID 562) in 58 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.195 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 162 (mapPartitions at RandomForest.scala:644) finished in 0.072 s\n",
      "10-20 14:45:23.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 163)\n",
      "10-20 14:45:23.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[425] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_245 stored as values in memory (estimated size 6.5 KiB, free 417.4 MiB)\n",
      "10-20 14:45:23.198 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.4 MiB)\n",
      "10-20 14:45:23.198 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_245_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.198 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.199 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (MapPartitionsRDD[425] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.199 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 163.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.199 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 163.0 (TID 563) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.200 172.17.0.2:54325      7233    (TID 563)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 163.0 (TID 563)\n",
      "10-20 14:45:23.202 172.17.0.2:54325      7233    (TID 563)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.202 172.17.0.2:54325      7233    (TID 563)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.205 172.17.0.2:54325      7233    (TID 563)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 163.0 (TID 563). 2272 bytes result sent to driver\n",
      "10-20 14:45:23.206 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 163.0 (TID 563) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.206 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.206 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 163 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:23.207 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.207 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 163: Stage finished\n",
      "10-20 14:45:23.207 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 83 finished: collectAsMap at RandomForest.scala:663, took 0.087471 s\n",
      "10-20 14:45:23.207 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(243) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.208 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_243_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:23.208 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_246 stored as values in memory (estimated size 40.0 B, free 417.4 MiB)\n",
      "10-20 14:45:23.209 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.4 MiB)\n",
      "10-20 14:45:23.209 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_246_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:23.210 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 246 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.222 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 426 (mapPartitions at RandomForest.scala:644) as input to shuffle 80\n",
      "10-20 14:45:23.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 84 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 165 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 164)\n",
      "10-20 14:45:23.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 164)\n",
      "10-20 14:45:23.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[426] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.230 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_247 stored as values in memory (estimated size 236.5 KiB, free 417.1 MiB)\n",
      "10-20 14:45:23.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 98.6 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.231 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_247_piece0 in memory on 95675304fa2d:39429 (size: 98.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.232 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.232 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[426] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.232 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 164.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.234 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 164.0 (TID 564) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5502 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.235 172.17.0.2:54325      7233    (TID 564)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 164.0 (TID 564)\n",
      "10-20 14:45:23.243 172.17.0.2:54325      7233    (TID 564)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.243 172.17.0.2:54325      7233    (TID 564)  INFO org.apache.spark.storage.BlockManager: Found block rdd_417_0 locally\n",
      "10-20 14:45:23.269 172.17.0.2:54325      7233    (TID 564)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 164.0 (TID 564). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.270 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 164.0 (TID 564) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.270 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 164 (mapPartitions at RandomForest.scala:644) finished in 0.045 s\n",
      "10-20 14:45:23.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 165)\n",
      "10-20 14:45:23.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[428] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_248 stored as values in memory (estimated size 6.7 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.273 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_248_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[428] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 165.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.274 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 165.0 (TID 565) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.275 172.17.0.2:54325      7233    (TID 565)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 165.0 (TID 565)\n",
      "10-20 14:45:23.276 172.17.0.2:54325      7233    (TID 565)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.276 172.17.0.2:54325      7233    (TID 565)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.281 172.17.0.2:54325      7233    (TID 565)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 165.0 (TID 565). 3025 bytes result sent to driver\n",
      "10-20 14:45:23.281 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 165.0 (TID 565) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.281 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.281 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 165 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:23.282 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.282 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 165: Stage finished\n",
      "10-20 14:45:23.282 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 84 finished: collectAsMap at RandomForest.scala:663, took 0.059485 s\n",
      "10-20 14:45:23.282 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(246) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.283 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_249 stored as values in memory (estimated size 40.0 B, free 417.0 MiB)\n",
      "10-20 14:45:23.283 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_246_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:23.283 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.0 MiB)\n",
      "10-20 14:45:23.283 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_249_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:23.284 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 249 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.297 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.298 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 429 (mapPartitions at RandomForest.scala:644) as input to shuffle 81\n",
      "10-20 14:45:23.298 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 85 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.298 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 167 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.298 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 166)\n",
      "10-20 14:45:23.298 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 166)\n",
      "10-20 14:45:23.299 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 166 (MapPartitionsRDD[429] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.304 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_250 stored as values in memory (estimated size 237.8 KiB, free 416.8 MiB)\n",
      "10-20 14:45:23.305 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 99.2 KiB, free 416.7 MiB)\n",
      "10-20 14:45:23.306 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_250_piece0 in memory on 95675304fa2d:39429 (size: 99.2 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:23.306 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.307 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[429] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.307 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 166.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.316 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 166.0 (TID 566) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5502 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.317 172.17.0.2:54325      7233    (TID 566)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 166.0 (TID 566)\n",
      "10-20 14:45:23.318 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_241_piece0 on 95675304fa2d:39429 in memory (size: 98.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.320 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_244_piece0 on 95675304fa2d:39429 in memory (size: 98.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.322 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_242_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.323 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_248_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.324 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_245_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.325 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_247_piece0 on 95675304fa2d:39429 in memory (size: 98.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:23.334 172.17.0.2:54325      7233    (TID 566)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.334 172.17.0.2:54325      7233    (TID 566)  INFO org.apache.spark.storage.BlockManager: Found block rdd_417_0 locally\n",
      "10-20 14:45:23.361 172.17.0.2:54325      7233    (TID 566)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 166.0 (TID 566). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 166.0 (TID 566) in 46 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 166 (mapPartitions at RandomForest.scala:644) finished in 0.063 s\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 167)\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.362 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[431] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.363 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_251 stored as values in memory (estimated size 7.1 KiB, free 417.7 MiB)\n",
      "10-20 14:45:23.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.7 MiB)\n",
      "10-20 14:45:23.373 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_251_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:23.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[431] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 167.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.375 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 167.0 (TID 567) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.376 172.17.0.2:54325      7233    (TID 567)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 167.0 (TID 567)\n",
      "10-20 14:45:23.378 172.17.0.2:54325      7233    (TID 567)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.378 172.17.0.2:54325      7233    (TID 567)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.383 172.17.0.2:54325      7233    (TID 567)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 167.0 (TID 567). 3971 bytes result sent to driver\n",
      "10-20 14:45:23.384 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 167.0 (TID 567) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.384 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 167 (collectAsMap at RandomForest.scala:663) finished in 0.021 s\n",
      "10-20 14:45:23.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished\n",
      "10-20 14:45:23.385 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 85 finished: collectAsMap at RandomForest.scala:663, took 0.087851 s\n",
      "10-20 14:45:23.385 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(249) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.386 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_249_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:23.386 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_252 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:23.387 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:23.387 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_252_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:23.387 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 252 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 432 (mapPartitions at RandomForest.scala:644) as input to shuffle 82\n",
      "10-20 14:45:23.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 86 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 169 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 168)\n",
      "10-20 14:45:23.401 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 168)\n",
      "10-20 14:45:23.402 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[432] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_253 stored as values in memory (estimated size 240.2 KiB, free 417.4 MiB)\n",
      "10-20 14:45:23.409 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 100.2 KiB, free 417.4 MiB)\n",
      "10-20 14:45:23.409 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_253_piece0 in memory on 95675304fa2d:39429 (size: 100.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.409 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.410 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[432] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.410 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 168.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.411 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 168.0 (TID 568) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5502 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.412 172.17.0.2:54325      7233    (TID 568)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 168.0 (TID 568)\n",
      "10-20 14:45:23.422 172.17.0.2:54325      7233    (TID 568)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.422 172.17.0.2:54325      7233    (TID 568)  INFO org.apache.spark.storage.BlockManager: Found block rdd_417_0 locally\n",
      "10-20 14:45:23.451 172.17.0.2:54325      7233    (TID 568)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 168.0 (TID 568). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.452 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 168.0 (TID 568) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.452 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 168 (mapPartitions at RandomForest.scala:644) finished in 0.050 s\n",
      "10-20 14:45:23.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 169)\n",
      "10-20 14:45:23.453 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.454 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[434] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.455 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_254 stored as values in memory (estimated size 7.9 KiB, free 417.3 MiB)\n",
      "10-20 14:45:23.456 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.3 MiB)\n",
      "10-20 14:45:23.456 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_254_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.456 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[434] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 169.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.458 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 169.0 (TID 569) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.458 172.17.0.2:54325      7233    (TID 569)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 169.0 (TID 569)\n",
      "10-20 14:45:23.460 172.17.0.2:54325      7233    (TID 569)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.460 172.17.0.2:54325      7233    (TID 569)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.469 172.17.0.2:54325      7233    (TID 569)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 169.0 (TID 569). 5707 bytes result sent to driver\n",
      "10-20 14:45:23.470 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 169.0 (TID 569) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.471 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.471 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 169 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:23.471 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.471 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished\n",
      "10-20 14:45:23.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 86 finished: collectAsMap at RandomForest.scala:663, took 0.071669 s\n",
      "10-20 14:45:23.472 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(252) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:23.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.1181E-5\n",
      "  total: 0.514514291\n",
      "  findBestSplits: 0.513715944\n",
      "  chooseSplits: 0.513115865\n",
      "10-20 14:45:23.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 417 from persistence list\n",
      "10-20 14:45:23.473 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_252_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:23.473 172.17.0.2:54325      7233   ad-pool-60  INFO org.apache.spark.storage.BlockManager: Removing RDD 417\n",
      "10-20 14:45:23.478 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 370 from persistence list\n",
      "10-20 14:45:23.479 172.17.0.2:54325      7233   ad-pool-64  INFO org.apache.spark.storage.BlockManager: Removing RDD 370\n",
      "10-20 14:45:23.487 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:23.487 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:23.487 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:23.487 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:23.497 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_255 stored as values in memory (estimated size 40.0 B, free 419.3 MiB)\n",
      "10-20 14:45:23.498 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.3 MiB)\n",
      "10-20 14:45:23.498 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_255_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:23.499 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 255 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.512 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 442 (mapPartitions at RandomForest.scala:644) as input to shuffle 83\n",
      "10-20 14:45:23.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 87 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 171 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 170)\n",
      "10-20 14:45:23.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 170)\n",
      "10-20 14:45:23.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 170 (MapPartitionsRDD[442] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_256 stored as values in memory (estimated size 243.1 KiB, free 419.1 MiB)\n",
      "10-20 14:45:23.522 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 102.6 KiB, free 419.0 MiB)\n",
      "10-20 14:45:23.523 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_256_piece0 in memory on 95675304fa2d:39429 (size: 102.6 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:23.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 170 (MapPartitionsRDD[442] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.524 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 170.0 (TID 570) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5534 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.525 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 170.0 (TID 570)\n",
      "10-20 14:45:23.533 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.534 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.534 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.534 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.storage.BlockManager: Found block rdd_414_0 locally\n",
      "10-20 14:45:23.578 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_436_0 stored as values in memory (estimated size 1117.5 KiB, free 417.9 MiB)\n",
      "10-20 14:45:23.579 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_436_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:23.602 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_439_0 stored as values in memory (estimated size 914.4 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.602 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_439_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.624 172.17.0.2:54325      7233    (TID 570)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 170.0 (TID 570). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.625 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 170.0 (TID 570) in 101 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.625 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 170 (mapPartitions at RandomForest.scala:644) finished in 0.111 s\n",
      "10-20 14:45:23.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 171)\n",
      "10-20 14:45:23.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 171 (MapPartitionsRDD[444] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.627 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_257 stored as values in memory (estimated size 6.0 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.628 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.629 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_257_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.629 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.630 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (MapPartitionsRDD[444] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.630 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 171.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.631 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 171.0 (TID 571) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.632 172.17.0.2:54325      7233    (TID 571)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 171.0 (TID 571)\n",
      "10-20 14:45:23.633 172.17.0.2:54325      7233    (TID 571)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.633 172.17.0.2:54325      7233    (TID 571)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.635 172.17.0.2:54325      7233    (TID 571)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 171.0 (TID 571). 2296 bytes result sent to driver\n",
      "10-20 14:45:23.636 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 171.0 (TID 571) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.636 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 171 (collectAsMap at RandomForest.scala:663) finished in 0.009 s\n",
      "10-20 14:45:23.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.637 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 171: Stage finished\n",
      "10-20 14:45:23.637 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 87 finished: collectAsMap at RandomForest.scala:663, took 0.124630 s\n",
      "10-20 14:45:23.638 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(255) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.639 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_255_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:23.639 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_258 stored as values in memory (estimated size 40.0 B, free 417.0 MiB)\n",
      "10-20 14:45:23.640 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.0 MiB)\n",
      "10-20 14:45:23.640 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_258_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:23.641 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 258 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.652 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 445 (mapPartitions at RandomForest.scala:644) as input to shuffle 84\n",
      "10-20 14:45:23.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 88 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 173 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 172)\n",
      "10-20 14:45:23.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 172)\n",
      "10-20 14:45:23.655 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 172 (MapPartitionsRDD[445] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.660 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_259 stored as values in memory (estimated size 243.6 KiB, free 416.8 MiB)\n",
      "10-20 14:45:23.662 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 102.9 KiB, free 416.7 MiB)\n",
      "10-20 14:45:23.662 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_259_piece0 in memory on 95675304fa2d:39429 (size: 102.9 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:23.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 172 (MapPartitionsRDD[445] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.664 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 172.0 (TID 572) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5534 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.665 172.17.0.2:54325      7233    (TID 572)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 172.0 (TID 572)\n",
      "10-20 14:45:23.673 172.17.0.2:54325      7233    (TID 572)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.673 172.17.0.2:54325      7233    (TID 572)  INFO org.apache.spark.storage.BlockManager: Found block rdd_439_0 locally\n",
      "10-20 14:45:23.698 172.17.0.2:54325      7233    (TID 572)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 172.0 (TID 572). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.699 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 172.0 (TID 572) in 35 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.699 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.700 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 172 (mapPartitions at RandomForest.scala:644) finished in 0.045 s\n",
      "10-20 14:45:23.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 173)\n",
      "10-20 14:45:23.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 173 (MapPartitionsRDD[447] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_260 stored as values in memory (estimated size 6.5 KiB, free 416.6 MiB)\n",
      "10-20 14:45:23.713 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 416.6 MiB)\n",
      "10-20 14:45:23.714 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_260_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:23.714 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.715 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 173 (MapPartitionsRDD[447] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.715 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 173.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.715 172.17.0.2:54325      7233   ad-pool-72  INFO org.apache.spark.storage.BlockManager: Removing RDD 417\n",
      "10-20 14:45:23.716 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 173.0 (TID 573) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.716 172.17.0.2:54325      7233    (TID 573)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 173.0 (TID 573)\n",
      "10-20 14:45:23.717 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_251_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:23.718 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_256_piece0 on 95675304fa2d:39429 in memory (size: 102.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.719 172.17.0.2:54325      7233    (TID 573)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.719 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_254_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.719 172.17.0.2:54325      7233    (TID 573)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.727 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_253_piece0 on 95675304fa2d:39429 in memory (size: 100.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.729 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_257_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.730 172.17.0.2:54325      7233    (TID 573)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 173.0 (TID 573). 2541 bytes result sent to driver\n",
      "10-20 14:45:23.731 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 173.0 (TID 573) in 16 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.731 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.732 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_250_piece0 on 95675304fa2d:39429 in memory (size: 99.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:23.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 173 (collectAsMap at RandomForest.scala:663) finished in 0.030 s\n",
      "10-20 14:45:23.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 173: Stage finished\n",
      "10-20 14:45:23.732 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 88 finished: collectAsMap at RandomForest.scala:663, took 0.079881 s\n",
      "10-20 14:45:23.734 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(258) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.734 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_258_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:23.735 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_261 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:23.736 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:23.736 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_261_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:23.736 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 261 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.751 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 448 (mapPartitions at RandomForest.scala:644) as input to shuffle 85\n",
      "10-20 14:45:23.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 89 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 175 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)\n",
      "10-20 14:45:23.753 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 174)\n",
      "10-20 14:45:23.753 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 174 (MapPartitionsRDD[448] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_262 stored as values in memory (estimated size 244.3 KiB, free 417.4 MiB)\n",
      "10-20 14:45:23.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 103.2 KiB, free 417.3 MiB)\n",
      "10-20 14:45:23.761 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_262_piece0 in memory on 95675304fa2d:39429 (size: 103.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.762 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.762 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 174 (MapPartitionsRDD[448] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.762 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 174.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.763 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 174.0 (TID 574) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5534 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.764 172.17.0.2:54325      7233    (TID 574)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 174.0 (TID 574)\n",
      "10-20 14:45:23.773 172.17.0.2:54325      7233    (TID 574)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.773 172.17.0.2:54325      7233    (TID 574)  INFO org.apache.spark.storage.BlockManager: Found block rdd_439_0 locally\n",
      "10-20 14:45:23.798 172.17.0.2:54325      7233    (TID 574)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 174.0 (TID 574). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.799 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 174.0 (TID 574) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.799 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 174 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:23.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 175)\n",
      "10-20 14:45:23.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[450] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.803 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_263 stored as values in memory (estimated size 6.7 KiB, free 417.3 MiB)\n",
      "10-20 14:45:23.804 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.3 MiB)\n",
      "10-20 14:45:23.804 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_263_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:23.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[450] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.806 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 175.0 (TID 575) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.807 172.17.0.2:54325      7233    (TID 575)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 175.0 (TID 575)\n",
      "10-20 14:45:23.809 172.17.0.2:54325      7233    (TID 575)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.809 172.17.0.2:54325      7233    (TID 575)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.812 172.17.0.2:54325      7233    (TID 575)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 175.0 (TID 575). 3025 bytes result sent to driver\n",
      "10-20 14:45:23.813 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 175.0 (TID 575) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.813 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.813 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 175 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:23.813 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.813 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished\n",
      "10-20 14:45:23.814 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 89 finished: collectAsMap at RandomForest.scala:663, took 0.062308 s\n",
      "10-20 14:45:23.814 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(261) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.815 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_261_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:23.815 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_264 stored as values in memory (estimated size 40.0 B, free 417.3 MiB)\n",
      "10-20 14:45:23.816 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.3 MiB)\n",
      "10-20 14:45:23.816 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_264_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:23.817 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 264 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 451 (mapPartitions at RandomForest.scala:644) as input to shuffle 86\n",
      "10-20 14:45:23.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 90 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 177 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 176)\n",
      "10-20 14:45:23.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 176)\n",
      "10-20 14:45:23.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 176 (MapPartitionsRDD[451] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_265 stored as values in memory (estimated size 245.5 KiB, free 417.1 MiB)\n",
      "10-20 14:45:23.838 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 103.8 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.839 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_265_piece0 in memory on 95675304fa2d:39429 (size: 103.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.839 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 265 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 176 (MapPartitionsRDD[451] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.841 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 176.0 (TID 576) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5534 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.841 172.17.0.2:54325      7233    (TID 576)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 176.0 (TID 576)\n",
      "10-20 14:45:23.854 172.17.0.2:54325      7233    (TID 576)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.854 172.17.0.2:54325      7233    (TID 576)  INFO org.apache.spark.storage.BlockManager: Found block rdd_439_0 locally\n",
      "10-20 14:45:23.882 172.17.0.2:54325      7233    (TID 576)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 176.0 (TID 576). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.883 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 176.0 (TID 576) in 42 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.883 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 176 (mapPartitions at RandomForest.scala:644) finished in 0.052 s\n",
      "10-20 14:45:23.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 177)\n",
      "10-20 14:45:23.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.885 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[453] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.886 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_266 stored as values in memory (estimated size 7.1 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.0 MiB)\n",
      "10-20 14:45:23.888 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_266_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:23.888 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[453] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 177.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.890 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 177.0 (TID 577) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.890 172.17.0.2:54325      7233    (TID 577)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 177.0 (TID 577)\n",
      "10-20 14:45:23.893 172.17.0.2:54325      7233    (TID 577)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:23.893 172.17.0.2:54325      7233    (TID 577)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:23.929 172.17.0.2:54325      7233    (TID 577)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 177.0 (TID 577). 3888 bytes result sent to driver\n",
      "10-20 14:45:23.931 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 177.0 (TID 577) in 42 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.931 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 177 (collectAsMap at RandomForest.scala:663) finished in 0.045 s\n",
      "10-20 14:45:23.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:23.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished\n",
      "10-20 14:45:23.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 90 finished: collectAsMap at RandomForest.scala:663, took 0.103003 s\n",
      "10-20 14:45:23.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(264) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:23.933 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_267 stored as values in memory (estimated size 40.0 B, free 417.0 MiB)\n",
      "10-20 14:45:23.934 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.0 MiB)\n",
      "10-20 14:45:23.934 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_267_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:23.935 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 267 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:23.935 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_264_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:23.948 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:23.948 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 454 (mapPartitions at RandomForest.scala:644) as input to shuffle 87\n",
      "10-20 14:45:23.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 91 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:23.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 179 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:23.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)\n",
      "10-20 14:45:23.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 178)\n",
      "10-20 14:45:23.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 178 (MapPartitionsRDD[454] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:23.954 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_268 stored as values in memory (estimated size 247.9 KiB, free 416.7 MiB)\n",
      "10-20 14:45:23.956 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 104.8 KiB, free 416.6 MiB)\n",
      "10-20 14:45:23.956 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_268_piece0 in memory on 95675304fa2d:39429 (size: 104.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:23.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:23.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 178 (MapPartitionsRDD[454] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:23.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:23.958 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 178.0 (TID 578) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5534 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:23.959 172.17.0.2:54325      7233    (TID 578)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 178.0 (TID 578)\n",
      "10-20 14:45:23.968 172.17.0.2:54325      7233    (TID 578)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:23.968 172.17.0.2:54325      7233    (TID 578)  INFO org.apache.spark.storage.BlockManager: Found block rdd_439_0 locally\n",
      "10-20 14:45:23.996 172.17.0.2:54325      7233    (TID 578)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 178.0 (TID 578). 2090 bytes result sent to driver\n",
      "10-20 14:45:23.997 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 178.0 (TID 578) in 39 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:23.997 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:23.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 178 (mapPartitions at RandomForest.scala:644) finished in 0.048 s\n",
      "10-20 14:45:23.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:23.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:23.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 179)\n",
      "10-20 14:45:23.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:23.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[456] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:23.999 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_269 stored as values in memory (estimated size 7.9 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.000 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_269_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 269 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[456] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 179.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.001 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 179.0 (TID 579) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.002 172.17.0.2:54325      7233    (TID 579)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 179.0 (TID 579)\n",
      "10-20 14:45:24.005 172.17.0.2:54325      7233    (TID 579)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.005 172.17.0.2:54325      7233    (TID 579)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.015 172.17.0.2:54325      7233    (TID 579)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 179.0 (TID 579). 5683 bytes result sent to driver\n",
      "10-20 14:45:24.016 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 179.0 (TID 579) in 15 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.016 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 179 (collectAsMap at RandomForest.scala:663) finished in 0.017 s\n",
      "10-20 14:45:24.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 179: Stage finished\n",
      "10-20 14:45:24.017 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 91 finished: collectAsMap at RandomForest.scala:663, took 0.069241 s\n",
      "10-20 14:45:24.018 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(267) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.018 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:24.018 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_267_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:24.018 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 5.4676E-5\n",
      "  total: 0.531046296\n",
      "  findBestSplits: 0.529883034\n",
      "  chooseSplits: 0.528928959\n",
      "10-20 14:45:24.020 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 439 from persistence list\n",
      "10-20 14:45:24.021 172.17.0.2:54325      7233   d-pool-120  INFO org.apache.spark.storage.BlockManager: Removing RDD 439\n",
      "10-20 14:45:24.025 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 392 from persistence list\n",
      "10-20 14:45:24.025 172.17.0.2:54325      7233   ad-pool-29  INFO org.apache.spark.storage.BlockManager: Removing RDD 392\n",
      "10-20 14:45:24.032 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:24.032 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:24.032 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:24.032 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:24.033 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_270 stored as values in memory (estimated size 40.0 B, free 418.6 MiB)\n",
      "10-20 14:45:24.033 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.6 MiB)\n",
      "10-20 14:45:24.033 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_270_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 419.9 MiB)\n",
      "10-20 14:45:24.034 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 270 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.046 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 464 (mapPartitions at RandomForest.scala:644) as input to shuffle 88\n",
      "10-20 14:45:24.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 92 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 181 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)\n",
      "10-20 14:45:24.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 180)\n",
      "10-20 14:45:24.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[464] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.051 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_271 stored as values in memory (estimated size 250.7 KiB, free 418.4 MiB)\n",
      "10-20 14:45:24.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 106.5 KiB, free 418.3 MiB)\n",
      "10-20 14:45:24.053 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_271_piece0 in memory on 95675304fa2d:39429 (size: 106.5 KiB, free: 419.8 MiB)\n",
      "10-20 14:45:24.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 271 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[464] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 180.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.054 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 180.0 (TID 580) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5566 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.054 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 180.0 (TID 580)\n",
      "10-20 14:45:24.064 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.065 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.065 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.065 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.storage.BlockManager: Found block rdd_436_0 locally\n",
      "10-20 14:45:24.093 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_265_piece0 on 95675304fa2d:39429 in memory (size: 103.8 KiB, free: 419.9 MiB)\n",
      "10-20 14:45:24.094 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_266_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 419.9 MiB)\n",
      "10-20 14:45:24.096 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_458_0 stored as values in memory (estimated size 1117.5 KiB, free 417.5 MiB)\n",
      "10-20 14:45:24.096 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_458_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 418.8 MiB)\n",
      "10-20 14:45:24.098 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_269_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.9 MiB)\n",
      "10-20 14:45:24.099 172.17.0.2:54325      7233   d-pool-128  INFO org.apache.spark.storage.BlockManager: Removing RDD 439\n",
      "10-20 14:45:24.101 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_268_piece0 on 95675304fa2d:39429 in memory (size: 104.8 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:24.103 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_262_piece0 on 95675304fa2d:39429 in memory (size: 103.2 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:24.104 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_260_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:24.105 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_263_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:24.107 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_259_piece0 on 95675304fa2d:39429 in memory (size: 102.9 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:24.119 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_461_0 stored as values in memory (estimated size 914.4 KiB, free 417.7 MiB)\n",
      "10-20 14:45:24.120 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_461_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.142 172.17.0.2:54325      7233    (TID 580)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 180.0 (TID 580). 2133 bytes result sent to driver\n",
      "10-20 14:45:24.142 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 180.0 (TID 580) in 88 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.142 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.143 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 180 (mapPartitions at RandomForest.scala:644) finished in 0.096 s\n",
      "10-20 14:45:24.143 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.143 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.143 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 181)\n",
      "10-20 14:45:24.143 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.143 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[466] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.144 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_272 stored as values in memory (estimated size 6.0 KiB, free 417.7 MiB)\n",
      "10-20 14:45:24.156 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.7 MiB)\n",
      "10-20 14:45:24.156 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_272_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 272 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[466] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 181.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.158 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 181.0 (TID 581) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.159 172.17.0.2:54325      7233    (TID 581)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 181.0 (TID 581)\n",
      "10-20 14:45:24.160 172.17.0.2:54325      7233    (TID 581)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.160 172.17.0.2:54325      7233    (TID 581)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.162 172.17.0.2:54325      7233    (TID 581)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 181.0 (TID 581). 2076 bytes result sent to driver\n",
      "10-20 14:45:24.164 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 181.0 (TID 581) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.164 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 181 (collectAsMap at RandomForest.scala:663) finished in 0.020 s\n",
      "10-20 14:45:24.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished\n",
      "10-20 14:45:24.165 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 92 finished: collectAsMap at RandomForest.scala:663, took 0.118943 s\n",
      "10-20 14:45:24.165 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(270) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.166 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_273 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:24.166 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:24.168 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_270_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:24.168 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_273_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:24.169 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 273 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.181 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 467 (mapPartitions at RandomForest.scala:644) as input to shuffle 89\n",
      "10-20 14:45:24.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 93 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 183 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 182)\n",
      "10-20 14:45:24.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 182)\n",
      "10-20 14:45:24.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[467] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.188 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_274 stored as values in memory (estimated size 251.2 KiB, free 417.4 MiB)\n",
      "10-20 14:45:24.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 106.7 KiB, free 417.3 MiB)\n",
      "10-20 14:45:24.190 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_274_piece0 in memory on 95675304fa2d:39429 (size: 106.7 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 274 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.191 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[467] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.191 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.192 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 182.0 (TID 582) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5566 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.192 172.17.0.2:54325      7233    (TID 582)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 182.0 (TID 582)\n",
      "10-20 14:45:24.205 172.17.0.2:54325      7233    (TID 582)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.205 172.17.0.2:54325      7233    (TID 582)  INFO org.apache.spark.storage.BlockManager: Found block rdd_461_0 locally\n",
      "10-20 14:45:24.227 172.17.0.2:54325      7233    (TID 582)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 182.0 (TID 582). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.228 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 182.0 (TID 582) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.228 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 182 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:24.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 183)\n",
      "10-20 14:45:24.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 183 (MapPartitionsRDD[469] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.230 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_275 stored as values in memory (estimated size 6.5 KiB, free 417.3 MiB)\n",
      "10-20 14:45:24.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.3 MiB)\n",
      "10-20 14:45:24.232 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_275_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.233 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 275 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.233 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 183 (MapPartitionsRDD[469] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.233 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 183.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.234 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 183.0 (TID 583) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.234 172.17.0.2:54325      7233    (TID 583)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 183.0 (TID 583)\n",
      "10-20 14:45:24.236 172.17.0.2:54325      7233    (TID 583)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (19.7 KiB) non-empty blocks including 1 (19.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.236 172.17.0.2:54325      7233    (TID 583)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.238 172.17.0.2:54325      7233    (TID 583)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 183.0 (TID 583). 2584 bytes result sent to driver\n",
      "10-20 14:45:24.239 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 183.0 (TID 583) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.239 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.240 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 183 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:24.240 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.240 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 183: Stage finished\n",
      "10-20 14:45:24.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 93 finished: collectAsMap at RandomForest.scala:663, took 0.061174 s\n",
      "10-20 14:45:24.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(273) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.245 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_273_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:24.245 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_276 stored as values in memory (estimated size 40.0 B, free 417.3 MiB)\n",
      "10-20 14:45:24.246 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.3 MiB)\n",
      "10-20 14:45:24.246 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_276_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:24.247 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 276 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.258 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 470 (mapPartitions at RandomForest.scala:644) as input to shuffle 90\n",
      "10-20 14:45:24.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 94 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 185 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 184)\n",
      "10-20 14:45:24.259 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 184)\n",
      "10-20 14:45:24.261 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 184 (MapPartitionsRDD[470] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.266 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_277 stored as values in memory (estimated size 251.8 KiB, free 417.1 MiB)\n",
      "10-20 14:45:24.267 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 107.0 KiB, free 417.0 MiB)\n",
      "10-20 14:45:24.268 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_277_piece0 in memory on 95675304fa2d:39429 (size: 107.0 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:24.268 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 277 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.269 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 184 (MapPartitionsRDD[470] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.269 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 184.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.270 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 184.0 (TID 584) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5566 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.270 172.17.0.2:54325      7233    (TID 584)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 184.0 (TID 584)\n",
      "10-20 14:45:24.279 172.17.0.2:54325      7233    (TID 584)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.279 172.17.0.2:54325      7233    (TID 584)  INFO org.apache.spark.storage.BlockManager: Found block rdd_461_0 locally\n",
      "10-20 14:45:24.302 172.17.0.2:54325      7233    (TID 584)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 184.0 (TID 584). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 184.0 (TID 584) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 184 (mapPartitions at RandomForest.scala:644) finished in 0.042 s\n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 185)\n",
      "10-20 14:45:24.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.304 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[472] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.305 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_278 stored as values in memory (estimated size 6.7 KiB, free 417.0 MiB)\n",
      "10-20 14:45:24.306 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 416.9 MiB)\n",
      "10-20 14:45:24.306 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_278_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:24.307 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.307 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (MapPartitionsRDD[472] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.307 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 185.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.308 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 185.0 (TID 585) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.308 172.17.0.2:54325      7233    (TID 585)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 185.0 (TID 585)\n",
      "10-20 14:45:24.310 172.17.0.2:54325      7233    (TID 585)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.310 172.17.0.2:54325      7233    (TID 585)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.314 172.17.0.2:54325      7233    (TID 585)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 185.0 (TID 585). 3033 bytes result sent to driver\n",
      "10-20 14:45:24.314 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 185.0 (TID 585) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.314 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 185 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:24.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 185: Stage finished\n",
      "10-20 14:45:24.316 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 94 finished: collectAsMap at RandomForest.scala:663, took 0.057267 s\n",
      "10-20 14:45:24.316 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(276) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.317 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_276_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:24.318 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_279 stored as values in memory (estimated size 40.0 B, free 416.9 MiB)\n",
      "10-20 14:45:24.318 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.9 MiB)\n",
      "10-20 14:45:24.319 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_279_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:24.319 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 279 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.357 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 473 (mapPartitions at RandomForest.scala:644) as input to shuffle 91\n",
      "10-20 14:45:24.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 95 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 187 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 186)\n",
      "10-20 14:45:24.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 186)\n",
      "10-20 14:45:24.360 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 186 (MapPartitionsRDD[473] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.365 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_280 stored as values in memory (estimated size 253.0 KiB, free 416.7 MiB)\n",
      "10-20 14:45:24.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 107.5 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.367 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_280_piece0 in memory on 95675304fa2d:39429 (size: 107.5 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:24.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 280 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 186 (MapPartitionsRDD[473] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 186.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.369 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 186.0 (TID 586) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5566 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.369 172.17.0.2:54325      7233    (TID 586)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 186.0 (TID 586)\n",
      "10-20 14:45:24.378 172.17.0.2:54325      7233    (TID 586)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.378 172.17.0.2:54325      7233    (TID 586)  INFO org.apache.spark.storage.BlockManager: Found block rdd_461_0 locally\n",
      "10-20 14:45:24.403 172.17.0.2:54325      7233    (TID 586)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 186.0 (TID 586). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.403 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 186.0 (TID 586) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.404 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.404 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 186 (mapPartitions at RandomForest.scala:644) finished in 0.043 s\n",
      "10-20 14:45:24.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 187)\n",
      "10-20 14:45:24.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 187 (MapPartitionsRDD[475] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_281 stored as values in memory (estimated size 7.1 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.407 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_281_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:24.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 281 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 187 (MapPartitionsRDD[475] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.408 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 187.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.408 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 187.0 (TID 587) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.409 172.17.0.2:54325      7233    (TID 587)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 187.0 (TID 587)\n",
      "10-20 14:45:24.411 172.17.0.2:54325      7233    (TID 587)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.411 172.17.0.2:54325      7233    (TID 587)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.416 172.17.0.2:54325      7233    (TID 587)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 187.0 (TID 587). 4041 bytes result sent to driver\n",
      "10-20 14:45:24.417 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 187.0 (TID 587) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.417 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.417 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 187 (collectAsMap at RandomForest.scala:663) finished in 0.012 s\n",
      "10-20 14:45:24.417 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.418 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 187: Stage finished\n",
      "10-20 14:45:24.418 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 95 finished: collectAsMap at RandomForest.scala:663, took 0.061175 s\n",
      "10-20 14:45:24.419 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(279) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.419 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_279_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 417.9 MiB)\n",
      "10-20 14:45:24.419 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_282 stored as values in memory (estimated size 40.0 B, free 416.6 MiB)\n",
      "10-20 14:45:24.420 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.6 MiB)\n",
      "10-20 14:45:24.420 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_282_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 417.9 MiB)\n",
      "10-20 14:45:24.421 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 282 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.432 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 476 (mapPartitions at RandomForest.scala:644) as input to shuffle 92\n",
      "10-20 14:45:24.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 96 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 189 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 188)\n",
      "10-20 14:45:24.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 188)\n",
      "10-20 14:45:24.435 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 188 (MapPartitionsRDD[476] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_283 stored as values in memory (estimated size 255.4 KiB, free 416.3 MiB)\n",
      "10-20 14:45:24.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 108.6 KiB, free 416.2 MiB)\n",
      "10-20 14:45:24.442 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_283_piece0 in memory on 95675304fa2d:39429 (size: 108.6 KiB, free: 417.8 MiB)\n",
      "10-20 14:45:24.442 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 283 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.442 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 188 (MapPartitionsRDD[476] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.442 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.443 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 188.0 (TID 588) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5566 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.444 172.17.0.2:54325      7233    (TID 588)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 188.0 (TID 588)\n",
      "10-20 14:45:24.452 172.17.0.2:54325      7233    (TID 588)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.452 172.17.0.2:54325      7233    (TID 588)  INFO org.apache.spark.storage.BlockManager: Found block rdd_461_0 locally\n",
      "10-20 14:45:24.480 172.17.0.2:54325      7233    (TID 588)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 188.0 (TID 588). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.480 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 188.0 (TID 588) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.480 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 188 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:24.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 189)\n",
      "10-20 14:45:24.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[478] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.482 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_284 stored as values in memory (estimated size 7.8 KiB, free 416.2 MiB)\n",
      "10-20 14:45:24.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.2 MiB)\n",
      "10-20 14:45:24.492 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_284_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 417.8 MiB)\n",
      "10-20 14:45:24.493 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.493 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[478] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.493 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 189.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.494 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 189.0 (TID 589) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.495 172.17.0.2:54325      7233    (TID 589)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 189.0 (TID 589)\n",
      "10-20 14:45:24.495 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_274_piece0 on 95675304fa2d:39429 in memory (size: 106.7 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:24.497 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_281_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:24.497 172.17.0.2:54325      7233    (TID 589)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (61.8 KiB) non-empty blocks including 1 (61.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.497 172.17.0.2:54325      7233    (TID 589)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.498 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_280_piece0 on 95675304fa2d:39429 in memory (size: 107.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.507 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_277_piece0 on 95675304fa2d:39429 in memory (size: 107.0 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.508 172.17.0.2:54325      7233    (TID 589)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 189.0 (TID 589). 5425 bytes result sent to driver\n",
      "10-20 14:45:24.508 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_278_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.509 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 189.0 (TID 589) in 15 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.509 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.510 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 189 (collectAsMap at RandomForest.scala:663) finished in 0.028 s\n",
      "10-20 14:45:24.510 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.510 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished\n",
      "10-20 14:45:24.510 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 96 finished: collectAsMap at RandomForest.scala:663, took 0.077697 s\n",
      "10-20 14:45:24.511 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(282) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.512 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_275_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.512 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:24.512 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.1951E-5\n",
      "  total: 0.480045779\n",
      "  findBestSplits: 0.479206006\n",
      "  chooseSplits: 0.478629713\n",
      "10-20 14:45:24.513 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_282_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:24.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 461 from persistence list\n",
      "10-20 14:45:24.513 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_271_piece0 on 95675304fa2d:39429 in memory (size: 106.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.513 172.17.0.2:54325      7233   ad-pool-49  INFO org.apache.spark.storage.BlockManager: Removing RDD 461\n",
      "10-20 14:45:24.514 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_272_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:24.528 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 414 from persistence list\n",
      "10-20 14:45:24.529 172.17.0.2:54325      7233   ad-pool-51  INFO org.apache.spark.storage.BlockManager: Removing RDD 414\n",
      "10-20 14:45:24.536 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:24.536 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:24.536 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:24.536 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:24.537 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_285 stored as values in memory (estimated size 40.0 B, free 419.6 MiB)\n",
      "10-20 14:45:24.537 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_285_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.6 MiB)\n",
      "10-20 14:45:24.538 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_285_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:24.539 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 285 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.552 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.553 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 486 (mapPartitions at RandomForest.scala:644) as input to shuffle 93\n",
      "10-20 14:45:24.553 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 97 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.553 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 191 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.553 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 190)\n",
      "10-20 14:45:24.553 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 190)\n",
      "10-20 14:45:24.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 190 (MapPartitionsRDD[486] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.561 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_286 stored as values in memory (estimated size 258.0 KiB, free 419.4 MiB)\n",
      "10-20 14:45:24.563 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_286_piece0 stored as bytes in memory (estimated size 110.2 KiB, free 419.3 MiB)\n",
      "10-20 14:45:24.564 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_286_piece0 in memory on 95675304fa2d:39429 (size: 110.2 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:24.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 286 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 190 (MapPartitionsRDD[486] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 190.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.567 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 190.0 (TID 590) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5598 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.568 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 190.0 (TID 590)\n",
      "10-20 14:45:24.581 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.582 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.582 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.582 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.storage.BlockManager: Found block rdd_458_0 locally\n",
      "10-20 14:45:24.640 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_480_0 stored as values in memory (estimated size 1117.5 KiB, free 418.2 MiB)\n",
      "10-20 14:45:24.641 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_480_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:24.673 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_483_0 stored as values in memory (estimated size 914.4 KiB, free 417.3 MiB)\n",
      "10-20 14:45:24.674 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_483_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.698 172.17.0.2:54325      7233    (TID 590)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 190.0 (TID 590). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.699 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 190.0 (TID 590) in 131 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.699 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 190 (mapPartitions at RandomForest.scala:644) finished in 0.145 s\n",
      "10-20 14:45:24.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.700 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.700 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 191)\n",
      "10-20 14:45:24.700 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.700 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[488] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_287 stored as values in memory (estimated size 6.0 KiB, free 417.3 MiB)\n",
      "10-20 14:45:24.701 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_287_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.3 MiB)\n",
      "10-20 14:45:24.702 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_287_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 287 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (MapPartitionsRDD[488] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 191.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.704 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 191.0 (TID 591) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.704 172.17.0.2:54325      7233    (TID 591)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 191.0 (TID 591)\n",
      "10-20 14:45:24.706 172.17.0.2:54325      7233    (TID 591)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.706 172.17.0.2:54325      7233    (TID 591)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.708 172.17.0.2:54325      7233    (TID 591)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 191.0 (TID 591). 2296 bytes result sent to driver\n",
      "10-20 14:45:24.709 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 191.0 (TID 591) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.709 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.710 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 191 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:24.710 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.710 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 191: Stage finished\n",
      "10-20 14:45:24.710 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 97 finished: collectAsMap at RandomForest.scala:663, took 0.158348 s\n",
      "10-20 14:45:24.711 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(285) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.711 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_285_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:24.712 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_288 stored as values in memory (estimated size 40.0 B, free 417.3 MiB)\n",
      "10-20 14:45:24.712 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_288_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.3 MiB)\n",
      "10-20 14:45:24.712 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_288_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:24.713 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 288 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.725 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.749 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 489 (mapPartitions at RandomForest.scala:644) as input to shuffle 94\n",
      "10-20 14:45:24.750 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 98 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.750 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 193 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.750 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 192)\n",
      "10-20 14:45:24.750 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 192)\n",
      "10-20 14:45:24.751 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 192 (MapPartitionsRDD[489] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_289 stored as values in memory (estimated size 258.5 KiB, free 417.0 MiB)\n",
      "10-20 14:45:24.757 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_289_piece0 stored as bytes in memory (estimated size 110.5 KiB, free 416.9 MiB)\n",
      "10-20 14:45:24.757 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_289_piece0 in memory on 95675304fa2d:39429 (size: 110.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.758 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 289 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 192 (MapPartitionsRDD[489] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 192.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.760 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 192.0 (TID 592) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5598 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.761 172.17.0.2:54325      7233    (TID 592)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 192.0 (TID 592)\n",
      "10-20 14:45:24.775 172.17.0.2:54325      7233    (TID 592)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.775 172.17.0.2:54325      7233    (TID 592)  INFO org.apache.spark.storage.BlockManager: Found block rdd_483_0 locally\n",
      "10-20 14:45:24.798 172.17.0.2:54325      7233    (TID 592)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 192.0 (TID 592). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.798 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 192.0 (TID 592) in 38 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.799 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 192 (mapPartitions at RandomForest.scala:644) finished in 0.048 s\n",
      "10-20 14:45:24.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 193)\n",
      "10-20 14:45:24.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[491] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_290 stored as values in memory (estimated size 6.5 KiB, free 416.9 MiB)\n",
      "10-20 14:45:24.802 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_290_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 416.9 MiB)\n",
      "10-20 14:45:24.803 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_290_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.803 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 290 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.803 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[491] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.803 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 193.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.804 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 193.0 (TID 593) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.804 172.17.0.2:54325      7233    (TID 593)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 193.0 (TID 593)\n",
      "10-20 14:45:24.807 172.17.0.2:54325      7233    (TID 593)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.807 172.17.0.2:54325      7233    (TID 593)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.809 172.17.0.2:54325      7233    (TID 593)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 193.0 (TID 593). 2541 bytes result sent to driver\n",
      "10-20 14:45:24.810 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 193.0 (TID 593) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.810 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.810 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 193 (collectAsMap at RandomForest.scala:663) finished in 0.009 s\n",
      "10-20 14:45:24.811 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.811 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished\n",
      "10-20 14:45:24.811 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 98 finished: collectAsMap at RandomForest.scala:663, took 0.061881 s\n",
      "10-20 14:45:24.811 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(288) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.812 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_288_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:24.812 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_291 stored as values in memory (estimated size 40.0 B, free 416.9 MiB)\n",
      "10-20 14:45:24.813 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_291_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.9 MiB)\n",
      "10-20 14:45:24.813 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_291_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:24.813 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 291 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.825 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 492 (mapPartitions at RandomForest.scala:644) as input to shuffle 95\n",
      "10-20 14:45:24.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 99 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 195 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 194)\n",
      "10-20 14:45:24.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 194)\n",
      "10-20 14:45:24.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 194 (MapPartitionsRDD[492] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_292 stored as values in memory (estimated size 259.2 KiB, free 416.7 MiB)\n",
      "10-20 14:45:24.835 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_292_piece0 stored as bytes in memory (estimated size 110.8 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.836 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_292_piece0 in memory on 95675304fa2d:39429 (size: 110.8 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:24.836 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 292 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 194 (MapPartitionsRDD[492] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 194.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.838 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 194.0 (TID 594) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5598 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.839 172.17.0.2:54325      7233    (TID 594)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 194.0 (TID 594)\n",
      "10-20 14:45:24.847 172.17.0.2:54325      7233    (TID 594)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.847 172.17.0.2:54325      7233    (TID 594)  INFO org.apache.spark.storage.BlockManager: Found block rdd_483_0 locally\n",
      "10-20 14:45:24.875 172.17.0.2:54325      7233    (TID 594)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 194.0 (TID 594). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.886 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 194.0 (TID 594) in 48 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.886 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.887 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_284_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:24.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 194 (mapPartitions at RandomForest.scala:644) finished in 0.060 s\n",
      "10-20 14:45:24.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 195)\n",
      "10-20 14:45:24.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.888 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[494] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_293 stored as values in memory (estimated size 6.7 KiB, free 416.6 MiB)\n",
      "10-20 14:45:24.889 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_283_piece0 on 95675304fa2d:39429 in memory (size: 108.6 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.890 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_293_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 416.9 MiB)\n",
      "10-20 14:45:24.890 172.17.0.2:54325      7233   ad-pool-64  INFO org.apache.spark.storage.BlockManager: Removing RDD 461\n",
      "10-20 14:45:24.891 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_293_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.891 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 293 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.891 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[494] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.891 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 195.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.892 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 195.0 (TID 595) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.892 172.17.0.2:54325      7233    (TID 595)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 195.0 (TID 595)\n",
      "10-20 14:45:24.896 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_290_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:24.897 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_289_piece0 on 95675304fa2d:39429 in memory (size: 110.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:24.898 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_286_piece0 on 95675304fa2d:39429 in memory (size: 110.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.899 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_287_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.900 172.17.0.2:54325      7233    (TID 595)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.900 172.17.0.2:54325      7233    (TID 595)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.903 172.17.0.2:54325      7233    (TID 595)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 195.0 (TID 595). 3033 bytes result sent to driver\n",
      "10-20 14:45:24.904 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 195.0 (TID 595) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.904 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 195 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:24.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished\n",
      "10-20 14:45:24.905 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 99 finished: collectAsMap at RandomForest.scala:663, took 0.079850 s\n",
      "10-20 14:45:24.906 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(291) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.906 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_291_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:24.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_294 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:24.917 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_294_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:24.917 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_294_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:24.917 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 294 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:24.918 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_292_piece0 on 95675304fa2d:39429 in memory (size: 110.8 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:24.918 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_293_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:24.930 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:24.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 495 (mapPartitions at RandomForest.scala:644) as input to shuffle 96\n",
      "10-20 14:45:24.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 100 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:24.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 197 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:24.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 196)\n",
      "10-20 14:45:24.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 196)\n",
      "10-20 14:45:24.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 196 (MapPartitionsRDD[495] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:24.938 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_295 stored as values in memory (estimated size 260.4 KiB, free 417.8 MiB)\n",
      "10-20 14:45:24.940 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_295_piece0 stored as bytes in memory (estimated size 111.4 KiB, free 417.7 MiB)\n",
      "10-20 14:45:24.940 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_295_piece0 in memory on 95675304fa2d:39429 (size: 111.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.940 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 295 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 196 (MapPartitionsRDD[495] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 196.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.941 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 196.0 (TID 596) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5598 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.941 172.17.0.2:54325      7233    (TID 596)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 196.0 (TID 596)\n",
      "10-20 14:45:24.950 172.17.0.2:54325      7233    (TID 596)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:24.950 172.17.0.2:54325      7233    (TID 596)  INFO org.apache.spark.storage.BlockManager: Found block rdd_483_0 locally\n",
      "10-20 14:45:24.976 172.17.0.2:54325      7233    (TID 596)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 196.0 (TID 596). 2090 bytes result sent to driver\n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 196.0 (TID 596) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 196 (mapPartitions at RandomForest.scala:644) finished in 0.044 s\n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 197)\n",
      "10-20 14:45:24.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:24.978 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[497] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:24.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_296 stored as values in memory (estimated size 7.1 KiB, free 417.7 MiB)\n",
      "10-20 14:45:24.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_296_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.7 MiB)\n",
      "10-20 14:45:24.980 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_296_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:24.980 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 296 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:24.981 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[497] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:24.981 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 197.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:24.982 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 197.0 (TID 597) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:24.983 172.17.0.2:54325      7233    (TID 597)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 197.0 (TID 597)\n",
      "10-20 14:45:24.985 172.17.0.2:54325      7233    (TID 597)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:24.985 172.17.0.2:54325      7233    (TID 597)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:24.990 172.17.0.2:54325      7233    (TID 597)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 197.0 (TID 597). 4041 bytes result sent to driver\n",
      "10-20 14:45:24.991 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 197.0 (TID 597) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:24.991 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:24.991 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 197 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:24.991 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:24.991 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished\n",
      "10-20 14:45:24.991 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 100 finished: collectAsMap at RandomForest.scala:663, took 0.060925 s\n",
      "10-20 14:45:24.992 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(294) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:24.992 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_294_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:24.993 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_297 stored as values in memory (estimated size 40.0 B, free 417.7 MiB)\n",
      "10-20 14:45:24.993 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_297_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.7 MiB)\n",
      "10-20 14:45:24.994 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_297_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:24.994 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 297 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.009 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 498 (mapPartitions at RandomForest.scala:644) as input to shuffle 97\n",
      "10-20 14:45:25.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 101 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 199 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 198)\n",
      "10-20 14:45:25.010 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 198)\n",
      "10-20 14:45:25.011 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 198 (MapPartitionsRDD[498] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.021 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_298 stored as values in memory (estimated size 262.9 KiB, free 417.4 MiB)\n",
      "10-20 14:45:25.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_298_piece0 stored as bytes in memory (estimated size 112.4 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.023 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_298_piece0 in memory on 95675304fa2d:39429 (size: 112.4 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:25.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 298 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 198 (MapPartitionsRDD[498] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.024 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 198.0 (TID 598) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5598 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.025 172.17.0.2:54325      7233    (TID 598)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 198.0 (TID 598)\n",
      "10-20 14:45:25.034 172.17.0.2:54325      7233    (TID 598)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.035 172.17.0.2:54325      7233    (TID 598)  INFO org.apache.spark.storage.BlockManager: Found block rdd_483_0 locally\n",
      "10-20 14:45:25.063 172.17.0.2:54325      7233    (TID 598)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 198.0 (TID 598). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.064 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 198.0 (TID 598) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.064 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 198 (mapPartitions at RandomForest.scala:644) finished in 0.052 s\n",
      "10-20 14:45:25.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 199)\n",
      "10-20 14:45:25.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.066 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[500] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_299 stored as values in memory (estimated size 7.9 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_299_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.068 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_299_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.069 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 299 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.069 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 199 (MapPartitionsRDD[500] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.069 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 199.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.071 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 199.0 (TID 599) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.072 172.17.0.2:54325      7233    (TID 599)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 199.0 (TID 599)\n",
      "10-20 14:45:25.077 172.17.0.2:54325      7233    (TID 599)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.077 172.17.0.2:54325      7233    (TID 599)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.088 172.17.0.2:54325      7233    (TID 599)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 199.0 (TID 599). 5812 bytes result sent to driver\n",
      "10-20 14:45:25.089 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 199.0 (TID 599) in 19 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.089 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 199 (collectAsMap at RandomForest.scala:663) finished in 0.024 s\n",
      "10-20 14:45:25.090 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.091 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 199: Stage finished\n",
      "10-20 14:45:25.091 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 101 finished: collectAsMap at RandomForest.scala:663, took 0.082324 s\n",
      "10-20 14:45:25.092 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(297) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.092 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:25.092 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.246E-5\n",
      "  total: 0.556184826\n",
      "  findBestSplits: 0.555301238\n",
      "  chooseSplits: 0.554559352\n",
      "10-20 14:45:25.093 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 483 from persistence list\n",
      "10-20 14:45:25.092 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_297_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:25.097 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 436 from persistence list\n",
      "10-20 14:45:25.099 172.17.0.2:54325      7233   ad-pool-13  INFO org.apache.spark.storage.BlockManager: Removing RDD 483\n",
      "10-20 14:45:25.099 172.17.0.2:54325      7233   d-pool-105  INFO org.apache.spark.storage.BlockManager: Removing RDD 436\n",
      "10-20 14:45:25.106 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:25.106 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:25.106 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:25.106 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:25.107 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_300 stored as values in memory (estimated size 40.0 B, free 419.3 MiB)\n",
      "10-20 14:45:25.108 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_300_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.3 MiB)\n",
      "10-20 14:45:25.108 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_300_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.1 MiB)\n",
      "10-20 14:45:25.109 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 300 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.122 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 508 (mapPartitions at RandomForest.scala:644) as input to shuffle 98\n",
      "10-20 14:45:25.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 102 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 201 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 200)\n",
      "10-20 14:45:25.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 200)\n",
      "10-20 14:45:25.129 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 200 (MapPartitionsRDD[508] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.168 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_301 stored as values in memory (estimated size 265.9 KiB, free 419.0 MiB)\n",
      "10-20 14:45:25.170 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_301_piece0 stored as bytes in memory (estimated size 114.4 KiB, free 418.9 MiB)\n",
      "10-20 14:45:25.170 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_301_piece0 in memory on 95675304fa2d:39429 (size: 114.4 KiB, free: 420.0 MiB)\n",
      "10-20 14:45:25.170 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 301 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 200 (MapPartitionsRDD[508] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 200.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.173 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 200.0 (TID 600) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5630 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.173 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 200.0 (TID 600)\n",
      "10-20 14:45:25.182 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.182 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.183 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.183 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.storage.BlockManager: Found block rdd_480_0 locally\n",
      "10-20 14:45:25.212 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_502_0 stored as values in memory (estimated size 1117.5 KiB, free 417.8 MiB)\n",
      "10-20 14:45:25.212 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_502_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 418.9 MiB)\n",
      "10-20 14:45:25.237 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_299_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 418.9 MiB)\n",
      "10-20 14:45:25.244 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_505_0 stored as values in memory (estimated size 914.4 KiB, free 416.9 MiB)\n",
      "10-20 14:45:25.245 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_505_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:25.245 172.17.0.2:54325      7233   ad-pool-42  INFO org.apache.spark.storage.BlockManager: Removing RDD 483\n",
      "10-20 14:45:25.248 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_295_piece0 on 95675304fa2d:39429 in memory (size: 111.4 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.249 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_296_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:25.251 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_298_piece0 on 95675304fa2d:39429 in memory (size: 112.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:25.268 172.17.0.2:54325      7233    (TID 600)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 200.0 (TID 600). 2133 bytes result sent to driver\n",
      "10-20 14:45:25.269 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 200.0 (TID 600) in 97 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.269 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.269 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 200 (mapPartitions at RandomForest.scala:644) finished in 0.139 s\n",
      "10-20 14:45:25.269 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.270 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.270 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 201)\n",
      "10-20 14:45:25.270 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.270 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 201 (MapPartitionsRDD[510] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_302 stored as values in memory (estimated size 6.0 KiB, free 417.6 MiB)\n",
      "10-20 14:45:25.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_302_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.6 MiB)\n",
      "10-20 14:45:25.272 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_302_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:25.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 302 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 201 (MapPartitionsRDD[510] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 201.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.273 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 201.0 (TID 601) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.274 172.17.0.2:54325      7233    (TID 601)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 201.0 (TID 601)\n",
      "10-20 14:45:25.275 172.17.0.2:54325      7233    (TID 601)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.275 172.17.0.2:54325      7233    (TID 601)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.277 172.17.0.2:54325      7233    (TID 601)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 201.0 (TID 601). 2076 bytes result sent to driver\n",
      "10-20 14:45:25.278 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 201.0 (TID 601) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.278 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 201 (collectAsMap at RandomForest.scala:663) finished in 0.009 s\n",
      "10-20 14:45:25.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 201: Stage finished\n",
      "10-20 14:45:25.279 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 102 finished: collectAsMap at RandomForest.scala:663, took 0.156852 s\n",
      "10-20 14:45:25.280 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(300) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.281 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_300_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:25.281 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_303 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:25.281 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_303_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:25.282 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_303_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:25.282 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 303 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.294 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 511 (mapPartitions at RandomForest.scala:644) as input to shuffle 99\n",
      "10-20 14:45:25.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 103 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 203 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 202)\n",
      "10-20 14:45:25.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 202)\n",
      "10-20 14:45:25.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 202 (MapPartitionsRDD[511] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_304 stored as values in memory (estimated size 266.4 KiB, free 417.4 MiB)\n",
      "10-20 14:45:25.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_304_piece0 stored as bytes in memory (estimated size 114.7 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.302 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_304_piece0 in memory on 95675304fa2d:39429 (size: 114.7 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 304 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 202 (MapPartitionsRDD[511] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 202.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.304 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 202.0 (TID 602) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5630 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.304 172.17.0.2:54325      7233    (TID 602)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 202.0 (TID 602)\n",
      "10-20 14:45:25.314 172.17.0.2:54325      7233    (TID 602)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.314 172.17.0.2:54325      7233    (TID 602)  INFO org.apache.spark.storage.BlockManager: Found block rdd_505_0 locally\n",
      "10-20 14:45:25.339 172.17.0.2:54325      7233    (TID 602)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 202.0 (TID 602). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 202.0 (TID 602) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 202 (mapPartitions at RandomForest.scala:644) finished in 0.044 s\n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 203)\n",
      "10-20 14:45:25.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 203 (MapPartitionsRDD[513] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.342 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_305 stored as values in memory (estimated size 6.5 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.353 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_305_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.353 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_305_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.353 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 305 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 203 (MapPartitionsRDD[513] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 203.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.354 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_302_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.355 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 203.0 (TID 603) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.356 172.17.0.2:54325      7233    (TID 603)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 203.0 (TID 603)\n",
      "10-20 14:45:25.356 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_301_piece0 on 95675304fa2d:39429 in memory (size: 114.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:25.359 172.17.0.2:54325      7233    (TID 603)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (19.7 KiB) non-empty blocks including 1 (19.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.359 172.17.0.2:54325      7233    (TID 603)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.363 172.17.0.2:54325      7233    (TID 603)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 203.0 (TID 603). 2584 bytes result sent to driver\n",
      "10-20 14:45:25.364 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 203.0 (TID 603) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.364 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.364 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 203 (collectAsMap at RandomForest.scala:663) finished in 0.023 s\n",
      "10-20 14:45:25.364 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.364 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 203: Stage finished\n",
      "10-20 14:45:25.365 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 103 finished: collectAsMap at RandomForest.scala:663, took 0.070798 s\n",
      "10-20 14:45:25.365 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(303) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.366 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_303_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:25.366 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_306 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:25.367 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_306_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:25.367 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_306_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:25.368 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 306 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.383 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 514 (mapPartitions at RandomForest.scala:644) as input to shuffle 100\n",
      "10-20 14:45:25.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 104 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 205 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 204)\n",
      "10-20 14:45:25.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 204)\n",
      "10-20 14:45:25.388 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 204 (MapPartitionsRDD[514] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.396 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_307 stored as values in memory (estimated size 267.0 KiB, free 417.4 MiB)\n",
      "10-20 14:45:25.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_307_piece0 stored as bytes in memory (estimated size 115.0 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.398 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_307_piece0 in memory on 95675304fa2d:39429 (size: 115.0 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 307 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 204 (MapPartitionsRDD[514] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 204.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.400 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 204.0 (TID 604) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5630 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.401 172.17.0.2:54325      7233    (TID 604)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 204.0 (TID 604)\n",
      "10-20 14:45:25.412 172.17.0.2:54325      7233    (TID 604)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.412 172.17.0.2:54325      7233    (TID 604)  INFO org.apache.spark.storage.BlockManager: Found block rdd_505_0 locally\n",
      "10-20 14:45:25.443 172.17.0.2:54325      7233    (TID 604)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 204.0 (TID 604). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.444 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 204.0 (TID 604) in 44 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.444 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 204 (mapPartitions at RandomForest.scala:644) finished in 0.056 s\n",
      "10-20 14:45:25.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 205)\n",
      "10-20 14:45:25.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[516] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.448 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_308 stored as values in memory (estimated size 6.7 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.449 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_308_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.3 MiB)\n",
      "10-20 14:45:25.449 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_308_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.449 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 308 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 205 (MapPartitionsRDD[516] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 205.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.451 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 205.0 (TID 605) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.451 172.17.0.2:54325      7233    (TID 605)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 205.0 (TID 605)\n",
      "10-20 14:45:25.454 172.17.0.2:54325      7233    (TID 605)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.454 172.17.0.2:54325      7233    (TID 605)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.459 172.17.0.2:54325      7233    (TID 605)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 205.0 (TID 605). 3068 bytes result sent to driver\n",
      "10-20 14:45:25.459 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 205.0 (TID 605) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.459 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.460 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 205 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:25.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 205: Stage finished\n",
      "10-20 14:45:25.465 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 104 finished: collectAsMap at RandomForest.scala:663, took 0.082048 s\n",
      "10-20 14:45:25.466 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(306) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.467 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_306_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:25.467 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_309 stored as values in memory (estimated size 40.0 B, free 417.3 MiB)\n",
      "10-20 14:45:25.468 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_309_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.3 MiB)\n",
      "10-20 14:45:25.468 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_309_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:25.469 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 309 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.486 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 517 (mapPartitions at RandomForest.scala:644) as input to shuffle 101\n",
      "10-20 14:45:25.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 105 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 207 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 206)\n",
      "10-20 14:45:25.487 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 206)\n",
      "10-20 14:45:25.490 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 206 (MapPartitionsRDD[517] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.499 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_310 stored as values in memory (estimated size 268.2 KiB, free 417.0 MiB)\n",
      "10-20 14:45:25.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_310_piece0 stored as bytes in memory (estimated size 115.5 KiB, free 416.9 MiB)\n",
      "10-20 14:45:25.503 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_310_piece0 in memory on 95675304fa2d:39429 (size: 115.5 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:25.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 310 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 206 (MapPartitionsRDD[517] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 206.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.505 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 206.0 (TID 606) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5630 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.506 172.17.0.2:54325      7233    (TID 606)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 206.0 (TID 606)\n",
      "10-20 14:45:25.523 172.17.0.2:54325      7233    (TID 606)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.523 172.17.0.2:54325      7233    (TID 606)  INFO org.apache.spark.storage.BlockManager: Found block rdd_505_0 locally\n",
      "10-20 14:45:25.570 172.17.0.2:54325      7233    (TID 606)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 206.0 (TID 606). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.571 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 206.0 (TID 606) in 66 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.571 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 206 (mapPartitions at RandomForest.scala:644) finished in 0.082 s\n",
      "10-20 14:45:25.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 207)\n",
      "10-20 14:45:25.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.574 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[519] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_311 stored as values in memory (estimated size 7.1 KiB, free 416.9 MiB)\n",
      "10-20 14:45:25.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_311_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.9 MiB)\n",
      "10-20 14:45:25.576 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_311_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:25.578 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 311 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.578 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 207 (MapPartitionsRDD[519] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.578 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 207.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.580 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 207.0 (TID 607) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.580 172.17.0.2:54325      7233    (TID 607)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 207.0 (TID 607)\n",
      "10-20 14:45:25.583 172.17.0.2:54325      7233    (TID 607)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (51.1 KiB) non-empty blocks including 1 (51.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.583 172.17.0.2:54325      7233    (TID 607)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.592 172.17.0.2:54325      7233    (TID 607)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 207.0 (TID 607). 4041 bytes result sent to driver\n",
      "10-20 14:45:25.593 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 207.0 (TID 607) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.593 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 207 (collectAsMap at RandomForest.scala:663) finished in 0.020 s\n",
      "10-20 14:45:25.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished\n",
      "10-20 14:45:25.594 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 105 finished: collectAsMap at RandomForest.scala:663, took 0.108448 s\n",
      "10-20 14:45:25.594 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(309) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.596 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_312 stored as values in memory (estimated size 40.0 B, free 416.9 MiB)\n",
      "10-20 14:45:25.597 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_312_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.9 MiB)\n",
      "10-20 14:45:25.598 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_309_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:25.599 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_312_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:25.599 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 312 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.649 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 520 (mapPartitions at RandomForest.scala:644) as input to shuffle 102\n",
      "10-20 14:45:25.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 106 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 209 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 208)\n",
      "10-20 14:45:25.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 208)\n",
      "10-20 14:45:25.655 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 208 (MapPartitionsRDD[520] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_313 stored as values in memory (estimated size 270.7 KiB, free 416.6 MiB)\n",
      "10-20 14:45:25.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_313_piece0 stored as bytes in memory (estimated size 116.5 KiB, free 416.5 MiB)\n",
      "10-20 14:45:25.665 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_313_piece0 in memory on 95675304fa2d:39429 (size: 116.5 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:25.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 313 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 208 (MapPartitionsRDD[520] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 208.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.667 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 208.0 (TID 608) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5630 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.668 172.17.0.2:54325      7233    (TID 608)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 208.0 (TID 608)\n",
      "10-20 14:45:25.679 172.17.0.2:54325      7233    (TID 608)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.679 172.17.0.2:54325      7233    (TID 608)  INFO org.apache.spark.storage.BlockManager: Found block rdd_505_0 locally\n",
      "10-20 14:45:25.707 172.17.0.2:54325      7233    (TID 608)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 208.0 (TID 608). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.707 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 208.0 (TID 608) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.707 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 208 (mapPartitions at RandomForest.scala:644) finished in 0.052 s\n",
      "10-20 14:45:25.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 209)\n",
      "10-20 14:45:25.708 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.709 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[522] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.710 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_314 stored as values in memory (estimated size 7.8 KiB, free 416.5 MiB)\n",
      "10-20 14:45:25.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_314_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.5 MiB)\n",
      "10-20 14:45:25.711 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_314_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:25.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 314 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (MapPartitionsRDD[522] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 209.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.713 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 209.0 (TID 609) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.714 172.17.0.2:54325      7233    (TID 609)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 209.0 (TID 609)\n",
      "10-20 14:45:25.716 172.17.0.2:54325      7233    (TID 609)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.716 172.17.0.2:54325      7233    (TID 609)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.724 172.17.0.2:54325      7233    (TID 609)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 209.0 (TID 609). 5471 bytes result sent to driver\n",
      "10-20 14:45:25.725 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 209.0 (TID 609) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.725 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 209 (collectAsMap at RandomForest.scala:663) finished in 0.016 s\n",
      "10-20 14:45:25.726 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 209: Stage finished\n",
      "10-20 14:45:25.726 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 106 finished: collectAsMap at RandomForest.scala:663, took 0.077518 s\n",
      "10-20 14:45:25.727 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(312) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.728 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:25.728 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 7.3216E-5\n",
      "  total: 0.621570131\n",
      "  findBestSplits: 0.62015817\n",
      "  chooseSplits: 0.619483901\n",
      "10-20 14:45:25.728 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_312_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 417.9 MiB)\n",
      "10-20 14:45:25.728 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 505 from persistence list\n",
      "10-20 14:45:25.729 172.17.0.2:54325      7233   ad-pool-72  INFO org.apache.spark.storage.BlockManager: Removing RDD 505\n",
      "10-20 14:45:25.734 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 458 from persistence list\n",
      "10-20 14:45:25.734 172.17.0.2:54325      7233   ad-pool-76  INFO org.apache.spark.storage.BlockManager: Removing RDD 458\n",
      "10-20 14:45:25.743 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:25.743 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:25.743 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:25.743 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:25.743 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_315 stored as values in memory (estimated size 40.0 B, free 418.5 MiB)\n",
      "10-20 14:45:25.744 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_315_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.5 MiB)\n",
      "10-20 14:45:25.744 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_315_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 419.9 MiB)\n",
      "10-20 14:45:25.745 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 315 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.770 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_313_piece0 on 95675304fa2d:39429 in memory (size: 116.5 KiB, free: 420.0 MiB)\n",
      "10-20 14:45:25.771 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_304_piece0 on 95675304fa2d:39429 in memory (size: 114.7 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:25.772 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_307_piece0 on 95675304fa2d:39429 in memory (size: 115.0 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:25.776 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_310_piece0 on 95675304fa2d:39429 in memory (size: 115.5 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:25.777 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_305_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 420.3 MiB)\n",
      "10-20 14:45:25.791 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_308_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:25.796 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_311_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:25.796 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 530 (mapPartitions at RandomForest.scala:644) as input to shuffle 103\n",
      "10-20 14:45:25.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 107 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 211 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 210)\n",
      "10-20 14:45:25.798 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 210)\n",
      "10-20 14:45:25.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 210 (MapPartitionsRDD[530] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.802 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_314_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:25.804 172.17.0.2:54325      7233   ad-pool-43  INFO org.apache.spark.storage.BlockManager: Removing RDD 505\n",
      "10-20 14:45:25.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_316 stored as values in memory (estimated size 273.2 KiB, free 419.7 MiB)\n",
      "10-20 14:45:25.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_316_piece0 stored as bytes in memory (estimated size 118.5 KiB, free 419.6 MiB)\n",
      "10-20 14:45:25.818 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_316_piece0 in memory on 95675304fa2d:39429 (size: 118.5 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:25.819 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 316 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.819 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 210 (MapPartitionsRDD[530] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.819 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 210.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.821 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 210.0 (TID 610) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5662 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.823 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 210.0 (TID 610)\n",
      "10-20 14:45:25.833 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.833 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.834 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.834 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.storage.BlockManager: Found block rdd_502_0 locally\n",
      "10-20 14:45:25.856 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_524_0 stored as values in memory (estimated size 1117.5 KiB, free 418.5 MiB)\n",
      "10-20 14:45:25.857 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_524_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.2 MiB)\n",
      "10-20 14:45:25.880 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_527_0 stored as values in memory (estimated size 914.4 KiB, free 417.6 MiB)\n",
      "10-20 14:45:25.880 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_527_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:25.906 172.17.0.2:54325      7233    (TID 610)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 210.0 (TID 610). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.907 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 210.0 (TID 610) in 86 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.907 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 210 (mapPartitions at RandomForest.scala:644) finished in 0.109 s\n",
      "10-20 14:45:25.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 211)\n",
      "10-20 14:45:25.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[532] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_317 stored as values in memory (estimated size 6.0 KiB, free 417.6 MiB)\n",
      "10-20 14:45:25.910 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_317_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.6 MiB)\n",
      "10-20 14:45:25.910 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_317_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:25.911 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 317 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.911 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 211 (MapPartitionsRDD[532] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.911 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 211.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.912 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 211.0 (TID 611) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.912 172.17.0.2:54325      7233    (TID 611)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 211.0 (TID 611)\n",
      "10-20 14:45:25.914 172.17.0.2:54325      7233    (TID 611)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.914 172.17.0.2:54325      7233    (TID 611)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.916 172.17.0.2:54325      7233    (TID 611)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 211.0 (TID 611). 2076 bytes result sent to driver\n",
      "10-20 14:45:25.917 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 211.0 (TID 611) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.917 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 211 (collectAsMap at RandomForest.scala:663) finished in 0.009 s\n",
      "10-20 14:45:25.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 211: Stage finished\n",
      "10-20 14:45:25.918 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 107 finished: collectAsMap at RandomForest.scala:663, took 0.120963 s\n",
      "10-20 14:45:25.919 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(315) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.919 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_318 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:25.920 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_315_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:25.920 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_318_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:25.920 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_318_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:25.921 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 318 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:25.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:25.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 533 (mapPartitions at RandomForest.scala:644) as input to shuffle 104\n",
      "10-20 14:45:25.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 108 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:25.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 213 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:25.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 212)\n",
      "10-20 14:45:25.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 212)\n",
      "10-20 14:45:25.934 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 212 (MapPartitionsRDD[533] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:25.940 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_319 stored as values in memory (estimated size 273.7 KiB, free 417.4 MiB)\n",
      "10-20 14:45:25.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_319_piece0 stored as bytes in memory (estimated size 118.8 KiB, free 417.2 MiB)\n",
      "10-20 14:45:25.942 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_319_piece0 in memory on 95675304fa2d:39429 (size: 118.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 319 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 212 (MapPartitionsRDD[533] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 212.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.944 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 212.0 (TID 612) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5662 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.944 172.17.0.2:54325      7233    (TID 612)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 212.0 (TID 612)\n",
      "10-20 14:45:25.953 172.17.0.2:54325      7233    (TID 612)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:25.953 172.17.0.2:54325      7233    (TID 612)  INFO org.apache.spark.storage.BlockManager: Found block rdd_527_0 locally\n",
      "10-20 14:45:25.975 172.17.0.2:54325      7233    (TID 612)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 212.0 (TID 612). 2090 bytes result sent to driver\n",
      "10-20 14:45:25.976 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 212.0 (TID 612) in 33 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.976 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 212 (mapPartitions at RandomForest.scala:644) finished in 0.041 s\n",
      "10-20 14:45:25.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:25.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:25.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 213)\n",
      "10-20 14:45:25.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:25.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 213 (MapPartitionsRDD[535] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:25.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_320 stored as values in memory (estimated size 6.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:25.978 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_320_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:25.978 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_320_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:25.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 320 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:25.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 213 (MapPartitionsRDD[535] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:25.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 213.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:25.980 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 213.0 (TID 613) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:25.980 172.17.0.2:54325      7233    (TID 613)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 213.0 (TID 613)\n",
      "10-20 14:45:25.982 172.17.0.2:54325      7233    (TID 613)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:25.982 172.17.0.2:54325      7233    (TID 613)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:25.984 172.17.0.2:54325      7233    (TID 613)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 213.0 (TID 613). 2285 bytes result sent to driver\n",
      "10-20 14:45:25.985 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 213.0 (TID 613) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:25.985 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:25.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 213 (collectAsMap at RandomForest.scala:663) finished in 0.009 s\n",
      "10-20 14:45:25.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:25.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 213: Stage finished\n",
      "10-20 14:45:25.986 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 108 finished: collectAsMap at RandomForest.scala:663, took 0.053465 s\n",
      "10-20 14:45:25.986 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(318) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:25.987 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_321 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:25.988 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_321_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:25.988 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_318_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:25.988 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_321_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:25.989 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 321 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.034 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 536 (mapPartitions at RandomForest.scala:644) as input to shuffle 105\n",
      "10-20 14:45:26.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 109 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 215 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 214)\n",
      "10-20 14:45:26.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 214)\n",
      "10-20 14:45:26.036 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 214 (MapPartitionsRDD[536] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_322 stored as values in memory (estimated size 274.3 KiB, free 417.0 MiB)\n",
      "10-20 14:45:26.044 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_322_piece0 stored as bytes in memory (estimated size 119.1 KiB, free 416.9 MiB)\n",
      "10-20 14:45:26.045 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_322_piece0 in memory on 95675304fa2d:39429 (size: 119.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:26.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 322 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 214 (MapPartitionsRDD[536] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 214.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.046 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 214.0 (TID 614) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5662 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.046 172.17.0.2:54325      7233    (TID 614)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 214.0 (TID 614)\n",
      "10-20 14:45:26.055 172.17.0.2:54325      7233    (TID 614)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.055 172.17.0.2:54325      7233    (TID 614)  INFO org.apache.spark.storage.BlockManager: Found block rdd_527_0 locally\n",
      "10-20 14:45:26.079 172.17.0.2:54325      7233    (TID 614)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 214.0 (TID 614). 2090 bytes result sent to driver\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 214.0 (TID 614) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 214 (mapPartitions at RandomForest.scala:644) finished in 0.043 s\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 215)\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 215 (MapPartitionsRDD[538] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.081 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_323 stored as values in memory (estimated size 6.7 KiB, free 416.8 MiB)\n",
      "10-20 14:45:26.082 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_323_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 416.8 MiB)\n",
      "10-20 14:45:26.082 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_323_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:26.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 323 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 215 (MapPartitionsRDD[538] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 215.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.084 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 215.0 (TID 615) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.085 172.17.0.2:54325      7233    (TID 615)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 215.0 (TID 615)\n",
      "10-20 14:45:26.087 172.17.0.2:54325      7233    (TID 615)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.087 172.17.0.2:54325      7233    (TID 615)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.091 172.17.0.2:54325      7233    (TID 615)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 215.0 (TID 615). 3033 bytes result sent to driver\n",
      "10-20 14:45:26.092 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 215.0 (TID 615) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.092 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.092 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 215 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:26.093 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.093 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 215: Stage finished\n",
      "10-20 14:45:26.093 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 109 finished: collectAsMap at RandomForest.scala:663, took 0.058657 s\n",
      "10-20 14:45:26.093 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(321) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.094 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_324 stored as values in memory (estimated size 40.0 B, free 416.8 MiB)\n",
      "10-20 14:45:26.094 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_324_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.8 MiB)\n",
      "10-20 14:45:26.094 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_321_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:26.095 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_324_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:26.095 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 324 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.116 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 539 (mapPartitions at RandomForest.scala:644) as input to shuffle 106\n",
      "10-20 14:45:26.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 110 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 217 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 216)\n",
      "10-20 14:45:26.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 216)\n",
      "10-20 14:45:26.120 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 216 (MapPartitionsRDD[539] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.126 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_325 stored as values in memory (estimated size 275.5 KiB, free 416.6 MiB)\n",
      "10-20 14:45:26.127 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_325_piece0 stored as bytes in memory (estimated size 119.6 KiB, free 416.5 MiB)\n",
      "10-20 14:45:26.127 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_325_piece0 in memory on 95675304fa2d:39429 (size: 119.6 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:26.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 325 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.129 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 216 (MapPartitionsRDD[539] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.129 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 216.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.131 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 216.0 (TID 616) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5662 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.132 172.17.0.2:54325      7233    (TID 616)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 216.0 (TID 616)\n",
      "10-20 14:45:26.144 172.17.0.2:54325      7233    (TID 616)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.144 172.17.0.2:54325      7233    (TID 616)  INFO org.apache.spark.storage.BlockManager: Found block rdd_527_0 locally\n",
      "10-20 14:45:26.166 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_322_piece0 on 95675304fa2d:39429 in memory (size: 119.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:26.168 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_319_piece0 on 95675304fa2d:39429 in memory (size: 118.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.170 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_316_piece0 on 95675304fa2d:39429 in memory (size: 118.5 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:26.173 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_320_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.175 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_323_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.178 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_317_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.183 172.17.0.2:54325      7233    (TID 616)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 216.0 (TID 616). 2133 bytes result sent to driver\n",
      "10-20 14:45:26.184 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 216.0 (TID 616) in 54 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.184 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 216 (mapPartitions at RandomForest.scala:644) finished in 0.064 s\n",
      "10-20 14:45:26.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 217)\n",
      "10-20 14:45:26.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.186 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[541] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.186 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_326 stored as values in memory (estimated size 7.1 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_326_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.197 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_326_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 326 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 217 (MapPartitionsRDD[541] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 217.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.198 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 217.0 (TID 617) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.199 172.17.0.2:54325      7233    (TID 617)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 217.0 (TID 617)\n",
      "10-20 14:45:26.201 172.17.0.2:54325      7233    (TID 617)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.201 172.17.0.2:54325      7233    (TID 617)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.206 172.17.0.2:54325      7233    (TID 617)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 217.0 (TID 617). 3947 bytes result sent to driver\n",
      "10-20 14:45:26.207 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 217.0 (TID 617) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.207 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.207 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 217 (collectAsMap at RandomForest.scala:663) finished in 0.021 s\n",
      "10-20 14:45:26.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 217: Stage finished\n",
      "10-20 14:45:26.208 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 110 finished: collectAsMap at RandomForest.scala:663, took 0.091298 s\n",
      "10-20 14:45:26.208 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(324) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.209 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_327 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:26.210 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_327_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:26.210 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_324_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:26.210 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_327_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:26.210 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 327 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.222 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 542 (mapPartitions at RandomForest.scala:644) as input to shuffle 107\n",
      "10-20 14:45:26.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 111 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 219 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 218)\n",
      "10-20 14:45:26.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 218)\n",
      "10-20 14:45:26.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 218 (MapPartitionsRDD[542] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_328 stored as values in memory (estimated size 277.7 KiB, free 417.4 MiB)\n",
      "10-20 14:45:26.230 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_328_piece0 stored as bytes in memory (estimated size 120.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.231 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_328_piece0 in memory on 95675304fa2d:39429 (size: 120.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 328 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 218 (MapPartitionsRDD[542] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 218.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.232 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 218.0 (TID 618) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5662 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.233 172.17.0.2:54325      7233    (TID 618)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 218.0 (TID 618)\n",
      "10-20 14:45:26.245 172.17.0.2:54325      7233    (TID 618)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.245 172.17.0.2:54325      7233    (TID 618)  INFO org.apache.spark.storage.BlockManager: Found block rdd_527_0 locally\n",
      "10-20 14:45:26.271 172.17.0.2:54325      7233    (TID 618)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 218.0 (TID 618). 2090 bytes result sent to driver\n",
      "10-20 14:45:26.272 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 218.0 (TID 618) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.272 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 218 (mapPartitions at RandomForest.scala:644) finished in 0.048 s\n",
      "10-20 14:45:26.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 219)\n",
      "10-20 14:45:26.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 219 (MapPartitionsRDD[544] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.275 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_329 stored as values in memory (estimated size 7.7 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.276 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_329_piece0 stored as bytes in memory (estimated size 4.0 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.276 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_329_piece0 in memory on 95675304fa2d:39429 (size: 4.0 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 329 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 219 (MapPartitionsRDD[544] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.278 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 219.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.278 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 219.0 (TID 619) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.278 172.17.0.2:54325      7233    (TID 619)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 219.0 (TID 619)\n",
      "10-20 14:45:26.280 172.17.0.2:54325      7233    (TID 619)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.280 172.17.0.2:54325      7233    (TID 619)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.287 172.17.0.2:54325      7233    (TID 619)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 219.0 (TID 619). 5275 bytes result sent to driver\n",
      "10-20 14:45:26.288 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 219.0 (TID 619) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.288 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.289 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 219 (collectAsMap at RandomForest.scala:663) finished in 0.014 s\n",
      "10-20 14:45:26.289 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.289 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 219: Stage finished\n",
      "10-20 14:45:26.289 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 111 finished: collectAsMap at RandomForest.scala:663, took 0.067545 s\n",
      "10-20 14:45:26.289 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(327) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.290 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:26.290 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_327_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:26.290 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 3.0542E-5\n",
      "  total: 0.54753246\n",
      "  findBestSplits: 0.546753644\n",
      "  chooseSplits: 0.546204061\n",
      "10-20 14:45:26.291 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 527 from persistence list\n",
      "10-20 14:45:26.291 172.17.0.2:54325      7233   ad-pool-85  INFO org.apache.spark.storage.BlockManager: Removing RDD 527\n",
      "10-20 14:45:26.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 480 from persistence list\n",
      "10-20 14:45:26.297 172.17.0.2:54325      7233   ad-pool-86  INFO org.apache.spark.storage.BlockManager: Removing RDD 480\n",
      "10-20 14:45:26.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:26.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:26.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:26.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:26.305 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_330 stored as values in memory (estimated size 40.0 B, free 419.2 MiB)\n",
      "10-20 14:45:26.306 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_330_piece0 stored as bytes in memory (estimated size 101.0 B, free 419.2 MiB)\n",
      "10-20 14:45:26.306 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_330_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.1 MiB)\n",
      "10-20 14:45:26.306 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 330 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.318 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 552 (mapPartitions at RandomForest.scala:644) as input to shuffle 108\n",
      "10-20 14:45:26.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 112 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 221 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 220)\n",
      "10-20 14:45:26.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 220)\n",
      "10-20 14:45:26.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 220 (MapPartitionsRDD[552] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.327 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_331 stored as values in memory (estimated size 280.1 KiB, free 418.9 MiB)\n",
      "10-20 14:45:26.328 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_331_piece0 stored as bytes in memory (estimated size 122.0 KiB, free 418.8 MiB)\n",
      "10-20 14:45:26.328 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_331_piece0 in memory on 95675304fa2d:39429 (size: 122.0 KiB, free: 420.0 MiB)\n",
      "10-20 14:45:26.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 331 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 220 (MapPartitionsRDD[552] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 220.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.330 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 220.0 (TID 620) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5694 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.330 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 220.0 (TID 620)\n",
      "10-20 14:45:26.339 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.339 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.339 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.339 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.storage.BlockManager: Found block rdd_524_0 locally\n",
      "10-20 14:45:26.363 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_546_0 stored as values in memory (estimated size 1117.5 KiB, free 417.7 MiB)\n",
      "10-20 14:45:26.364 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_546_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 418.9 MiB)\n",
      "10-20 14:45:26.427 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_325_piece0 on 95675304fa2d:39429 in memory (size: 119.6 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:26.428 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_326_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 419.0 MiB)\n",
      "10-20 14:45:26.430 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_328_piece0 on 95675304fa2d:39429 in memory (size: 120.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:26.431 172.17.0.2:54325      7233   d-pool-108  INFO org.apache.spark.storage.BlockManager: Removing RDD 527\n",
      "10-20 14:45:26.434 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_329_piece0 on 95675304fa2d:39429 in memory (size: 4.0 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:26.438 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_549_0 stored as values in memory (estimated size 914.4 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.439 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_549_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.464 172.17.0.2:54325      7233    (TID 620)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 220.0 (TID 620). 2133 bytes result sent to driver\n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 220.0 (TID 620) in 135 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 220 (mapPartitions at RandomForest.scala:644) finished in 0.144 s\n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 221)\n",
      "10-20 14:45:26.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[554] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.467 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_332 stored as values in memory (estimated size 6.0 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.468 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_332_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.468 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_332_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.469 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 332 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.469 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 221 (MapPartitionsRDD[554] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.469 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 221.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.469 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 221.0 (TID 621) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.470 172.17.0.2:54325      7233    (TID 621)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 221.0 (TID 621)\n",
      "10-20 14:45:26.471 172.17.0.2:54325      7233    (TID 621)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.471 172.17.0.2:54325      7233    (TID 621)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.473 172.17.0.2:54325      7233    (TID 621)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 221.0 (TID 621). 2296 bytes result sent to driver\n",
      "10-20 14:45:26.474 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 221.0 (TID 621) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.474 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 221 (collectAsMap at RandomForest.scala:663) finished in 0.008 s\n",
      "10-20 14:45:26.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished\n",
      "10-20 14:45:26.477 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 112 finished: collectAsMap at RandomForest.scala:663, took 0.159425 s\n",
      "10-20 14:45:26.478 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(330) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.478 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_333 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:26.479 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_333_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:26.480 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_333_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:26.480 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_330_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:26.480 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 333 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.491 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 555 (mapPartitions at RandomForest.scala:644) as input to shuffle 109\n",
      "10-20 14:45:26.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 113 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 223 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 222)\n",
      "10-20 14:45:26.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 222)\n",
      "10-20 14:45:26.495 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 222 (MapPartitionsRDD[555] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_334 stored as values in memory (estimated size 280.6 KiB, free 417.3 MiB)\n",
      "10-20 14:45:26.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_334_piece0 stored as bytes in memory (estimated size 122.3 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.507 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_334_piece0 in memory on 95675304fa2d:39429 (size: 122.3 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 334 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 222 (MapPartitionsRDD[555] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.509 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 222.0 (TID 622) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5694 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.510 172.17.0.2:54325      7233    (TID 622)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 222.0 (TID 622)\n",
      "10-20 14:45:26.518 172.17.0.2:54325      7233    (TID 622)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.518 172.17.0.2:54325      7233    (TID 622)  INFO org.apache.spark.storage.BlockManager: Found block rdd_549_0 locally\n",
      "10-20 14:45:26.540 172.17.0.2:54325      7233    (TID 622)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 222.0 (TID 622). 2090 bytes result sent to driver\n",
      "10-20 14:45:26.541 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 222.0 (TID 622) in 32 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.541 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 222 (mapPartitions at RandomForest.scala:644) finished in 0.046 s\n",
      "10-20 14:45:26.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 223)\n",
      "10-20 14:45:26.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.542 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 223 (MapPartitionsRDD[557] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.543 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_335 stored as values in memory (estimated size 6.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.543 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_335_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.543 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_335_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.544 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 335 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.544 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 223 (MapPartitionsRDD[557] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.544 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 223.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.545 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 223.0 (TID 623) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.550 172.17.0.2:54325      7233    (TID 623)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 223.0 (TID 623)\n",
      "10-20 14:45:26.552 172.17.0.2:54325      7233    (TID 623)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.552 172.17.0.2:54325      7233    (TID 623)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.556 172.17.0.2:54325      7233    (TID 623)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 223.0 (TID 623). 2541 bytes result sent to driver\n",
      "10-20 14:45:26.557 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 223.0 (TID 623) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.557 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.557 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 223 (collectAsMap at RandomForest.scala:663) finished in 0.015 s\n",
      "10-20 14:45:26.558 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.558 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 223: Stage finished\n",
      "10-20 14:45:26.563 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 113 finished: collectAsMap at RandomForest.scala:663, took 0.071718 s\n",
      "10-20 14:45:26.564 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(333) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.564 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_333_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:26.566 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_336 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:26.580 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_336_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:26.580 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_336_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:26.581 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 336 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.581 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_335_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.582 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_334_piece0 on 95675304fa2d:39429 in memory (size: 122.3 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.585 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_332_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.586 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_331_piece0 on 95675304fa2d:39429 in memory (size: 122.0 KiB, free: 418.4 MiB)\n",
      "10-20 14:45:26.596 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 558 (mapPartitions at RandomForest.scala:644) as input to shuffle 110\n",
      "10-20 14:45:26.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 114 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 225 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 224)\n",
      "10-20 14:45:26.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 224)\n",
      "10-20 14:45:26.600 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 224 (MapPartitionsRDD[558] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_337 stored as values in memory (estimated size 281.3 KiB, free 417.7 MiB)\n",
      "10-20 14:45:26.608 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_337_piece0 stored as bytes in memory (estimated size 122.5 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.609 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_337_piece0 in memory on 95675304fa2d:39429 (size: 122.5 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.609 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 337 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 224 (MapPartitionsRDD[558] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.610 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 224.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.611 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 224.0 (TID 624) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5694 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.611 172.17.0.2:54325      7233    (TID 624)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 224.0 (TID 624)\n",
      "10-20 14:45:26.620 172.17.0.2:54325      7233    (TID 624)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.621 172.17.0.2:54325      7233    (TID 624)  INFO org.apache.spark.storage.BlockManager: Found block rdd_549_0 locally\n",
      "10-20 14:45:26.646 172.17.0.2:54325      7233    (TID 624)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 224.0 (TID 624). 2090 bytes result sent to driver\n",
      "10-20 14:45:26.646 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 224.0 (TID 624) in 35 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 224 (mapPartitions at RandomForest.scala:644) finished in 0.047 s\n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 225)\n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[560] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.649 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_338 stored as values in memory (estimated size 6.7 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_338_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.656 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_338_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:26.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 338 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 225 (MapPartitionsRDD[560] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.657 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 225.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.657 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 225.0 (TID 625) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.658 172.17.0.2:54325      7233    (TID 625)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 225.0 (TID 625)\n",
      "10-20 14:45:26.660 172.17.0.2:54325      7233    (TID 625)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.660 172.17.0.2:54325      7233    (TID 625)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.663 172.17.0.2:54325      7233    (TID 625)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 225.0 (TID 625). 3033 bytes result sent to driver\n",
      "10-20 14:45:26.664 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 225.0 (TID 625) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.664 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 225 (collectAsMap at RandomForest.scala:663) finished in 0.017 s\n",
      "10-20 14:45:26.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.665 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished\n",
      "10-20 14:45:26.665 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 114 finished: collectAsMap at RandomForest.scala:663, took 0.068950 s\n",
      "10-20 14:45:26.665 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(336) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.666 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_339 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:26.667 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_336_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:26.667 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_339_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:26.668 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_339_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.3 MiB)\n",
      "10-20 14:45:26.668 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 339 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.682 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.683 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 561 (mapPartitions at RandomForest.scala:644) as input to shuffle 111\n",
      "10-20 14:45:26.683 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 115 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.683 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 227 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.683 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 226)\n",
      "10-20 14:45:26.683 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 226)\n",
      "10-20 14:45:26.684 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 226 (MapPartitionsRDD[561] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.690 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_340 stored as values in memory (estimated size 282.5 KiB, free 417.3 MiB)\n",
      "10-20 14:45:26.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_340_piece0 stored as bytes in memory (estimated size 123.1 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.692 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_340_piece0 in memory on 95675304fa2d:39429 (size: 123.1 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 340 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 226 (MapPartitionsRDD[561] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 226.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.694 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 226.0 (TID 626) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5694 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.694 172.17.0.2:54325      7233    (TID 626)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 226.0 (TID 626)\n",
      "10-20 14:45:26.703 172.17.0.2:54325      7233    (TID 626)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.703 172.17.0.2:54325      7233    (TID 626)  INFO org.apache.spark.storage.BlockManager: Found block rdd_549_0 locally\n",
      "10-20 14:45:26.730 172.17.0.2:54325      7233    (TID 626)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 226.0 (TID 626). 2090 bytes result sent to driver\n",
      "10-20 14:45:26.731 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 226.0 (TID 626) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.731 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 226 (mapPartitions at RandomForest.scala:644) finished in 0.047 s\n",
      "10-20 14:45:26.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 227)\n",
      "10-20 14:45:26.732 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[563] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.733 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_341 stored as values in memory (estimated size 7.1 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.734 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_341_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.2 MiB)\n",
      "10-20 14:45:26.734 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_341_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:26.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 341 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[563] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 227.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.736 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 227.0 (TID 627) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.737 172.17.0.2:54325      7233    (TID 627)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 227.0 (TID 627)\n",
      "10-20 14:45:26.739 172.17.0.2:54325      7233    (TID 627)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.739 172.17.0.2:54325      7233    (TID 627)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:26.744 172.17.0.2:54325      7233    (TID 627)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 227.0 (TID 627). 3971 bytes result sent to driver\n",
      "10-20 14:45:26.745 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 227.0 (TID 627) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.745 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 227 (collectAsMap at RandomForest.scala:663) finished in 0.012 s\n",
      "10-20 14:45:26.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 227: Stage finished\n",
      "10-20 14:45:26.746 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 115 finished: collectAsMap at RandomForest.scala:663, took 0.063884 s\n",
      "10-20 14:45:26.747 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(339) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.748 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_339_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:26.749 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_342 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:26.749 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_342_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:26.750 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_342_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:26.750 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 342 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.763 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 564 (mapPartitions at RandomForest.scala:644) as input to shuffle 112\n",
      "10-20 14:45:26.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 116 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 229 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 228)\n",
      "10-20 14:45:26.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 228)\n",
      "10-20 14:45:26.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 228 (MapPartitionsRDD[564] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.771 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_343 stored as values in memory (estimated size 284.9 KiB, free 416.9 MiB)\n",
      "10-20 14:45:26.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_343_piece0 stored as bytes in memory (estimated size 124.2 KiB, free 416.8 MiB)\n",
      "10-20 14:45:26.774 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_343_piece0 in memory on 95675304fa2d:39429 (size: 124.2 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:26.775 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 343 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.775 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 228 (MapPartitionsRDD[564] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.775 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 228.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.776 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 228.0 (TID 628) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5694 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.804 172.17.0.2:54325      7233    (TID 628)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 228.0 (TID 628)\n",
      "10-20 14:45:26.813 172.17.0.2:54325      7233    (TID 628)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.813 172.17.0.2:54325      7233    (TID 628)  INFO org.apache.spark.storage.BlockManager: Found block rdd_549_0 locally\n",
      "10-20 14:45:26.845 172.17.0.2:54325      7233    (TID 628)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 228.0 (TID 628). 2090 bytes result sent to driver\n",
      "10-20 14:45:26.846 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 228.0 (TID 628) in 70 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.846 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 228 (mapPartitions at RandomForest.scala:644) finished in 0.082 s\n",
      "10-20 14:45:26.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:26.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:26.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 229)\n",
      "10-20 14:45:26.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:26.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[566] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:26.850 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_344 stored as values in memory (estimated size 7.8 KiB, free 416.8 MiB)\n",
      "10-20 14:45:26.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_344_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 416.8 MiB)\n",
      "10-20 14:45:26.851 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_344_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:26.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 344 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 229 (MapPartitionsRDD[566] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 229.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.853 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 229.0 (TID 629) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.854 172.17.0.2:54325      7233    (TID 629)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 229.0 (TID 629)\n",
      "10-20 14:45:26.857 172.17.0.2:54325      7233    (TID 629)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:26.859 172.17.0.2:54325      7233    (TID 629)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:45:26.869 172.17.0.2:54325      7233    (TID 629)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 229.0 (TID 629). 5605 bytes result sent to driver\n",
      "10-20 14:45:26.870 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 229.0 (TID 629) in 17 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:26.870 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:26.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 229 (collectAsMap at RandomForest.scala:663) finished in 0.021 s\n",
      "10-20 14:45:26.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 116 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:26.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 229: Stage finished\n",
      "10-20 14:45:26.870 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 116 finished: collectAsMap at RandomForest.scala:663, took 0.107646 s\n",
      "10-20 14:45:26.871 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(342) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:26.871 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:26.871 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 2.9953E-5\n",
      "  total: 0.56810355\n",
      "  findBestSplits: 0.566595531\n",
      "  chooseSplits: 0.566148572\n",
      "10-20 14:45:26.871 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 549 from persistence list\n",
      "10-20 14:45:26.871 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_342_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:26.872 172.17.0.2:54325      7233   ad-pool-50  INFO org.apache.spark.storage.BlockManager: Removing RDD 549\n",
      "10-20 14:45:26.876 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 502 from persistence list\n",
      "10-20 14:45:26.877 172.17.0.2:54325      7233   d-pool-128  INFO org.apache.spark.storage.BlockManager: Removing RDD 502\n",
      "10-20 14:45:26.885 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numFeatures: 106\n",
      "10-20 14:45:26.885 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numClasses: 0\n",
      "10-20 14:45:26.891 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: numExamples: 26076\n",
      "10-20 14:45:26.891 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: weightedNumExamples: 26076.0\n",
      "10-20 14:45:26.892 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_345 stored as values in memory (estimated size 40.0 B, free 418.8 MiB)\n",
      "10-20 14:45:26.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_345_piece0 stored as bytes in memory (estimated size 101.0 B, free 418.8 MiB)\n",
      "10-20 14:45:26.908 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_345_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 420.0 MiB)\n",
      "10-20 14:45:26.910 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 345 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:26.910 172.17.0.2:54325      7233   ad-pool-67  INFO org.apache.spark.storage.BlockManager: Removing RDD 549\n",
      "10-20 14:45:26.912 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_337_piece0 on 95675304fa2d:39429 in memory (size: 122.5 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:26.914 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_338_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:26.916 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_340_piece0 on 95675304fa2d:39429 in memory (size: 123.1 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:26.918 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_341_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:26.921 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_343_piece0 on 95675304fa2d:39429 in memory (size: 124.2 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:26.922 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_344_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 420.4 MiB)\n",
      "10-20 14:45:26.935 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:26.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 574 (mapPartitions at RandomForest.scala:644) as input to shuffle 113\n",
      "10-20 14:45:26.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 117 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:26.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 231 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:26.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 230)\n",
      "10-20 14:45:26.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 230)\n",
      "10-20 14:45:26.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 230 (MapPartitionsRDD[574] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:26.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_346 stored as values in memory (estimated size 287.8 KiB, free 419.7 MiB)\n",
      "10-20 14:45:26.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_346_piece0 stored as bytes in memory (estimated size 126.0 KiB, free 419.6 MiB)\n",
      "10-20 14:45:26.945 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_346_piece0 in memory on 95675304fa2d:39429 (size: 126.0 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:26.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 346 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:26.946 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 230 (MapPartitionsRDD[574] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:26.946 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 230.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:26.947 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 230.0 (TID 630) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5726 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:26.947 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 230.0 (TID 630)\n",
      "10-20 14:45:26.956 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.956 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.956 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:26.956 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.storage.BlockManager: Found block rdd_546_0 locally\n",
      "10-20 14:45:26.979 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_568_0 stored as values in memory (estimated size 1117.5 KiB, free 418.5 MiB)\n",
      "10-20 14:45:26.979 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_568_0 in memory on 95675304fa2d:39429 (size: 1117.5 KiB, free: 419.1 MiB)\n",
      "10-20 14:45:26.999 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_571_0 stored as values in memory (estimated size 914.4 KiB, free 417.6 MiB)\n",
      "10-20 14:45:26.999 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_571_0 in memory on 95675304fa2d:39429 (size: 914.4 KiB, free: 418.3 MiB)\n",
      "10-20 14:45:27.021 172.17.0.2:54325      7233    (TID 630)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 230.0 (TID 630). 2090 bytes result sent to driver\n",
      "10-20 14:45:27.022 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 230.0 (TID 630) in 76 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.022 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 230 (mapPartitions at RandomForest.scala:644) finished in 0.085 s\n",
      "10-20 14:45:27.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:27.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:27.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 231)\n",
      "10-20 14:45:27.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:27.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[576] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:27.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_347 stored as values in memory (estimated size 6.0 KiB, free 417.6 MiB)\n",
      "10-20 14:45:27.034 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_347_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 417.6 MiB)\n",
      "10-20 14:45:27.034 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_347_piece0 in memory on 95675304fa2d:39429 (size: 3.2 KiB, free: 418.2 MiB)\n",
      "10-20 14:45:27.034 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 347 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[576] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.035 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 231.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.036 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 231.0 (TID 631) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.037 172.17.0.2:54325      7233    (TID 631)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 231.0 (TID 631)\n",
      "10-20 14:45:27.040 172.17.0.2:54325      7233    (TID 631)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (11.1 KiB) non-empty blocks including 1 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:27.040 172.17.0.2:54325      7233    (TID 631)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:27.043 172.17.0.2:54325      7233    (TID 631)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 231.0 (TID 631). 2296 bytes result sent to driver\n",
      "10-20 14:45:27.043 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 231.0 (TID 631) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.043 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.044 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 231 (collectAsMap at RandomForest.scala:663) finished in 0.020 s\n",
      "10-20 14:45:27.044 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:27.044 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished\n",
      "10-20 14:45:27.045 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 117 finished: collectAsMap at RandomForest.scala:663, took 0.109904 s\n",
      "10-20 14:45:27.045 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(345) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:27.046 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_348 stored as values in memory (estimated size 40.0 B, free 417.6 MiB)\n",
      "10-20 14:45:27.046 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_345_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:27.047 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_348_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.6 MiB)\n",
      "10-20 14:45:27.047 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_348_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.2 MiB)\n",
      "10-20 14:45:27.047 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 348 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:27.060 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:27.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 577 (mapPartitions at RandomForest.scala:644) as input to shuffle 114\n",
      "10-20 14:45:27.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 118 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:27.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 233 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:27.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 232)\n",
      "10-20 14:45:27.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 232)\n",
      "10-20 14:45:27.062 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 232 (MapPartitionsRDD[577] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:27.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_349 stored as values in memory (estimated size 288.3 KiB, free 417.3 MiB)\n",
      "10-20 14:45:27.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_349_piece0 stored as bytes in memory (estimated size 126.3 KiB, free 417.2 MiB)\n",
      "10-20 14:45:27.070 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_349_piece0 in memory on 95675304fa2d:39429 (size: 126.3 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:27.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 349 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 232 (MapPartitionsRDD[577] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 232.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.071 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 232.0 (TID 632) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5726 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.072 172.17.0.2:54325      7233    (TID 632)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 232.0 (TID 632)\n",
      "10-20 14:45:27.083 172.17.0.2:54325      7233    (TID 632)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:27.083 172.17.0.2:54325      7233    (TID 632)  INFO org.apache.spark.storage.BlockManager: Found block rdd_571_0 locally\n",
      "10-20 14:45:27.106 172.17.0.2:54325      7233    (TID 632)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 232.0 (TID 632). 2090 bytes result sent to driver\n",
      "10-20 14:45:27.106 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 232.0 (TID 632) in 35 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.106 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 232 (mapPartitions at RandomForest.scala:644) finished in 0.044 s\n",
      "10-20 14:45:27.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:27.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:27.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 233)\n",
      "10-20 14:45:27.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:27.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[579] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:27.108 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_350 stored as values in memory (estimated size 6.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:27.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_350_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 417.2 MiB)\n",
      "10-20 14:45:27.109 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_350_piece0 in memory on 95675304fa2d:39429 (size: 3.5 KiB, free: 418.1 MiB)\n",
      "10-20 14:45:27.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 350 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 233 (MapPartitionsRDD[579] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 233.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.111 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 233.0 (TID 633) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.111 172.17.0.2:54325      7233    (TID 633)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 233.0 (TID 633)\n",
      "10-20 14:45:27.114 172.17.0.2:54325      7233    (TID 633)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (17.9 KiB) non-empty blocks including 1 (17.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:27.114 172.17.0.2:54325      7233    (TID 633)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:27.116 172.17.0.2:54325      7233    (TID 633)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 233.0 (TID 633). 2541 bytes result sent to driver\n",
      "10-20 14:45:27.117 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 233.0 (TID 633) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.117 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 233 (collectAsMap at RandomForest.scala:663) finished in 0.011 s\n",
      "10-20 14:45:27.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:27.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 233: Stage finished\n",
      "10-20 14:45:27.120 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 118 finished: collectAsMap at RandomForest.scala:663, took 0.059380 s\n",
      "10-20 14:45:27.120 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(348) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:27.121 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_348_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:27.121 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_351 stored as values in memory (estimated size 40.0 B, free 417.2 MiB)\n",
      "10-20 14:45:27.122 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_351_piece0 stored as bytes in memory (estimated size 101.0 B, free 417.2 MiB)\n",
      "10-20 14:45:27.122 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_351_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.1 MiB)\n",
      "10-20 14:45:27.122 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 351 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:27.133 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:27.134 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 580 (mapPartitions at RandomForest.scala:644) as input to shuffle 115\n",
      "10-20 14:45:27.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 119 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:27.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 235 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:27.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 234)\n",
      "10-20 14:45:27.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 234)\n",
      "10-20 14:45:27.139 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 234 (MapPartitionsRDD[580] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:27.145 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_352 stored as values in memory (estimated size 288.9 KiB, free 416.9 MiB)\n",
      "10-20 14:45:27.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_352_piece0 stored as bytes in memory (estimated size 126.8 KiB, free 416.8 MiB)\n",
      "10-20 14:45:27.147 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_352_piece0 in memory on 95675304fa2d:39429 (size: 126.8 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:27.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 352 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 234 (MapPartitionsRDD[580] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 234.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.148 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 234.0 (TID 634) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5726 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.149 172.17.0.2:54325      7233    (TID 634)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 234.0 (TID 634)\n",
      "10-20 14:45:27.158 172.17.0.2:54325      7233    (TID 634)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:27.158 172.17.0.2:54325      7233    (TID 634)  INFO org.apache.spark.storage.BlockManager: Found block rdd_571_0 locally\n",
      "10-20 14:45:27.182 172.17.0.2:54325      7233    (TID 634)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 234.0 (TID 634). 2090 bytes result sent to driver\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 234.0 (TID 634) in 35 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 234 (mapPartitions at RandomForest.scala:644) finished in 0.044 s\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 235)\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:27.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 235 (MapPartitionsRDD[582] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:27.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_353 stored as values in memory (estimated size 6.7 KiB, free 416.8 MiB)\n",
      "10-20 14:45:27.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_353_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 416.8 MiB)\n",
      "10-20 14:45:27.185 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_353_piece0 in memory on 95675304fa2d:39429 (size: 3.6 KiB, free: 418.0 MiB)\n",
      "10-20 14:45:27.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 353 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 235 (MapPartitionsRDD[582] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.186 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 235.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.186 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 235.0 (TID 635) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.187 172.17.0.2:54325      7233    (TID 635)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 235.0 (TID 635)\n",
      "10-20 14:45:27.190 172.17.0.2:54325      7233    (TID 635)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:27.190 172.17.0.2:54325      7233    (TID 635)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:27.195 172.17.0.2:54325      7233    (TID 635)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 235.0 (TID 635). 3068 bytes result sent to driver\n",
      "10-20 14:45:27.196 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 235.0 (TID 635) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.196 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 235 (collectAsMap at RandomForest.scala:663) finished in 0.013 s\n",
      "10-20 14:45:27.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:27.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 235: Stage finished\n",
      "10-20 14:45:27.201 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 119 finished: collectAsMap at RandomForest.scala:663, took 0.067656 s\n",
      "10-20 14:45:27.202 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(351) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:27.203 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_351_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:27.203 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_354 stored as values in memory (estimated size 40.0 B, free 416.8 MiB)\n",
      "10-20 14:45:27.204 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_354_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.8 MiB)\n",
      "10-20 14:45:27.204 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_354_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 418.0 MiB)\n",
      "10-20 14:45:27.204 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 354 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:27.246 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:27.246 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 583 (mapPartitions at RandomForest.scala:644) as input to shuffle 116\n",
      "10-20 14:45:27.246 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 120 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:27.247 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 237 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:27.247 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 236)\n",
      "10-20 14:45:27.247 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 236)\n",
      "10-20 14:45:27.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 236 (MapPartitionsRDD[583] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:27.254 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_355 stored as values in memory (estimated size 290.1 KiB, free 416.5 MiB)\n",
      "10-20 14:45:27.255 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_355_piece0 stored as bytes in memory (estimated size 127.3 KiB, free 416.4 MiB)\n",
      "10-20 14:45:27.256 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_355_piece0 in memory on 95675304fa2d:39429 (size: 127.3 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:27.257 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 355 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.257 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 236 (MapPartitionsRDD[583] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.257 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 236.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.257 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 236.0 (TID 636) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5726 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.258 172.17.0.2:54325      7233    (TID 636)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 236.0 (TID 636)\n",
      "10-20 14:45:27.266 172.17.0.2:54325      7233    (TID 636)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:27.266 172.17.0.2:54325      7233    (TID 636)  INFO org.apache.spark.storage.BlockManager: Found block rdd_571_0 locally\n",
      "10-20 14:45:27.293 172.17.0.2:54325      7233    (TID 636)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 236.0 (TID 636). 2090 bytes result sent to driver\n",
      "10-20 14:45:27.293 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 236.0 (TID 636) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 236 (mapPartitions at RandomForest.scala:644) finished in 0.045 s\n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 237)\n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:27.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 237 (MapPartitionsRDD[585] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:27.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_356 stored as values in memory (estimated size 7.1 KiB, free 416.4 MiB)\n",
      "10-20 14:45:27.296 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_356_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.4 MiB)\n",
      "10-20 14:45:27.296 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_356_piece0 in memory on 95675304fa2d:39429 (size: 3.8 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:27.296 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 356 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 237 (MapPartitionsRDD[585] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 237.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.297 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 237.0 (TID 637) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.298 172.17.0.2:54325      7233    (TID 637)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 237.0 (TID 637)\n",
      "10-20 14:45:27.300 172.17.0.2:54325      7233    (TID 637)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:27.300 172.17.0.2:54325      7233    (TID 637)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:27.304 172.17.0.2:54325      7233    (TID 637)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 237.0 (TID 637). 3912 bytes result sent to driver\n",
      "10-20 14:45:27.305 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 237.0 (TID 637) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.305 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.306 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 237 (collectAsMap at RandomForest.scala:663) finished in 0.010 s\n",
      "10-20 14:45:27.306 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:27.306 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 237: Stage finished\n",
      "10-20 14:45:27.306 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 120 finished: collectAsMap at RandomForest.scala:663, took 0.059993 s\n",
      "10-20 14:45:27.306 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(354) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:27.307 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_354_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 417.9 MiB)\n",
      "10-20 14:45:27.307 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_357 stored as values in memory (estimated size 40.0 B, free 416.4 MiB)\n",
      "10-20 14:45:27.307 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_357_piece0 stored as bytes in memory (estimated size 101.0 B, free 416.4 MiB)\n",
      "10-20 14:45:27.308 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_357_piece0 in memory on 95675304fa2d:39429 (size: 101.0 B, free: 417.9 MiB)\n",
      "10-20 14:45:27.308 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 357 from broadcast at RandomForest.scala:622\n",
      "10-20 14:45:27.320 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "10-20 14:45:27.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 586 (mapPartitions at RandomForest.scala:644) as input to shuffle 117\n",
      "10-20 14:45:27.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 121 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "10-20 14:45:27.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 239 (collectAsMap at RandomForest.scala:663)\n",
      "10-20 14:45:27.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 238)\n",
      "10-20 14:45:27.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 238)\n",
      "10-20 14:45:27.322 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 238 (MapPartitionsRDD[586] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "10-20 14:45:27.327 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_358 stored as values in memory (estimated size 292.3 KiB, free 416.1 MiB)\n",
      "10-20 14:45:27.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_358_piece0 stored as bytes in memory (estimated size 128.4 KiB, free 416.0 MiB)\n",
      "10-20 14:45:27.329 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_358_piece0 in memory on 95675304fa2d:39429 (size: 128.4 KiB, free: 417.7 MiB)\n",
      "10-20 14:45:27.329 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 358 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.330 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 238 (MapPartitionsRDD[586] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.330 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 238.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.331 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 238.0 (TID 638) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5726 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.331 172.17.0.2:54325      7233    (TID 638)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 238.0 (TID 638)\n",
      "10-20 14:45:27.340 172.17.0.2:54325      7233    (TID 638)  INFO org.apache.spark.storage.BlockManager: Found block rdd_152_0 locally\n",
      "10-20 14:45:27.340 172.17.0.2:54325      7233    (TID 638)  INFO org.apache.spark.storage.BlockManager: Found block rdd_571_0 locally\n",
      "10-20 14:45:27.368 172.17.0.2:54325      7233    (TID 638)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 238.0 (TID 638). 2090 bytes result sent to driver\n",
      "10-20 14:45:27.369 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 238.0 (TID 638) in 38 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.369 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 238 (mapPartitions at RandomForest.scala:644) finished in 0.048 s\n",
      "10-20 14:45:27.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:27.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:27.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 239)\n",
      "10-20 14:45:27.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:27.371 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[588] at map at RandomForest.scala:663), which has no missing parents\n",
      "10-20 14:45:27.371 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_359 stored as values in memory (estimated size 7.7 KiB, free 415.9 MiB)\n",
      "10-20 14:45:27.372 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_359_piece0 stored as bytes in memory (estimated size 4.0 KiB, free 415.9 MiB)\n",
      "10-20 14:45:27.372 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_359_piece0 in memory on 95675304fa2d:39429 (size: 4.0 KiB, free: 417.7 MiB)\n",
      "10-20 14:45:27.372 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 359 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 239 (MapPartitionsRDD[588] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 239.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.373 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 239.0 (TID 639) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.374 172.17.0.2:54325      7233    (TID 639)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 239.0 (TID 639)\n",
      "10-20 14:45:27.376 172.17.0.2:54325      7233    (TID 639)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (61.8 KiB) non-empty blocks including 1 (61.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:27.376 172.17.0.2:54325      7233    (TID 639)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:27.394 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_347_piece0 on 95675304fa2d:39429 in memory (size: 3.2 KiB, free: 417.7 MiB)\n",
      "10-20 14:45:27.396 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_358_piece0 on 95675304fa2d:39429 in memory (size: 128.4 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:27.397 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_350_piece0 on 95675304fa2d:39429 in memory (size: 3.5 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:27.398 172.17.0.2:54325      7233    (TID 639)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 239.0 (TID 639). 5272 bytes result sent to driver\n",
      "10-20 14:45:27.399 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 239.0 (TID 639) in 26 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.399 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 239 (collectAsMap at RandomForest.scala:663) finished in 0.028 s\n",
      "10-20 14:45:27.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:27.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 239: Stage finished\n",
      "10-20 14:45:27.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 121 finished: collectAsMap at RandomForest.scala:663, took 0.078987 s\n",
      "10-20 14:45:27.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(357) (from destroy at RandomForest.scala:674)\n",
      "10-20 14:45:27.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest: Internal timing for DecisionTree:\n",
      "10-20 14:45:27.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.RandomForest:   init: 4.35E-5\n",
      "  total: 0.515090859\n",
      "  findBestSplits: 0.507709007\n",
      "  chooseSplits: 0.506606602\n",
      "10-20 14:45:27.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 571 from persistence list\n",
      "10-20 14:45:27.400 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_356_piece0 on 95675304fa2d:39429 in memory (size: 3.8 KiB, free: 417.9 MiB)\n",
      "10-20 14:45:27.401 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_357_piece0 on 95675304fa2d:39429 in memory (size: 101.0 B, free: 417.9 MiB)\n",
      "10-20 14:45:27.401 172.17.0.2:54325      7233   ad-pool-31  INFO org.apache.spark.storage.BlockManager: Removing RDD 571\n",
      "10-20 14:45:27.405 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 524 from persistence list\n",
      "10-20 14:45:27.406 172.17.0.2:54325      7233   d-pool-127  INFO org.apache.spark.storage.BlockManager: Removing RDD 524\n",
      "10-20 14:45:27.406 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_352_piece0 on 95675304fa2d:39429 in memory (size: 126.8 KiB, free: 420.0 MiB)\n",
      "10-20 14:45:27.406 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.GradientBoostedTrees: Internal timing for DecisionTree:\n",
      "10-20 14:45:27.407 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.tree.impl.GradientBoostedTrees:   building tree 4: 0.548673822\n",
      "  buildMetadata: 2.324538173\n",
      "  init: 0.004677218\n",
      "  building tree 14: 0.488201048\n",
      "  total: 16.978653082\n",
      "  building tree 17: 0.557557051\n",
      "  building tree 3: 0.610591613\n",
      "  building tree 11: 0.602873645\n",
      "  building tree 6: 0.56240126\n",
      "  building tree 0: 5.743604274\n",
      "  building tree 9: 0.536558367\n",
      "  building tree 13: 0.541500383\n",
      "  building tree 8: 0.628446961\n",
      "  building tree 16: 0.632005719\n",
      "  building tree 2: 0.633471824\n",
      "  building tree 10: 0.572568809\n",
      "  building tree 19: 0.523623698\n",
      "  building tree 5: 0.585841334\n",
      "  findSplits: 1.598185496\n",
      "  building tree 18: 0.575256593\n",
      "  building tree 12: 0.522278073\n",
      "  building tree 7: 0.771175254\n",
      "  building tree 15: 0.564501147\n",
      "  building tree 1: 0.645230421\n",
      "10-20 14:45:27.407 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_346_piece0 on 95675304fa2d:39429 in memory (size: 126.0 KiB, free: 420.1 MiB)\n",
      "10-20 14:45:27.407 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.broadcast.TorrentBroadcast: Destroying Broadcast(59) (from destroy at GradientBoostedTrees.scala:482)\n",
      "10-20 14:45:27.409 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_349_piece0 on 95675304fa2d:39429 in memory (size: 126.3 KiB, free: 420.2 MiB)\n",
      "10-20 14:45:27.409 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 152 from persistence list\n",
      "10-20 14:45:27.410 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_59_piece0 on 95675304fa2d:39429 in memory (size: 1030.0 B, free: 420.2 MiB)\n",
      "10-20 14:45:27.411 172.17.0.2:54325      7233   ad-pool-52  INFO org.apache.spark.storage.BlockManager: Removing RDD 152\n",
      "10-20 14:45:27.411 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_353_piece0 on 95675304fa2d:39429 in memory (size: 3.6 KiB, free: 432.0 MiB)\n",
      "10-20 14:45:27.412 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 546 from persistence list\n",
      "10-20 14:45:27.412 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_355_piece0 on 95675304fa2d:39429 in memory (size: 127.3 KiB, free: 432.2 MiB)\n",
      "10-20 14:45:27.413 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 568 from persistence list\n",
      "10-20 14:45:27.413 172.17.0.2:54325      7233   d-pool-130  INFO org.apache.spark.storage.BlockManager: Removing RDD 546\n",
      "10-20 14:45:27.413 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 590 from persistence list\n",
      "10-20 14:45:27.414 172.17.0.2:54325      7233   ad-pool-77  INFO org.apache.spark.storage.BlockManager: Removing RDD 568\n",
      "10-20 14:45:27.414 172.17.0.2:54325      7233   ad-pool-82  INFO org.apache.spark.storage.BlockManager: Removing RDD 590\n",
      "10-20 14:45:27.421 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] {\"numFeatures\":106}\n",
      "10-20 14:45:27.430 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [bd5e1338] training finished\n",
      "10-20 14:45:27.752 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:27.820 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:27.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 122 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:27.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 240 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:27.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:27.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:27.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 240 (MapPartitionsRDD[592] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:27.829 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_360 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:27.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_360_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:27.846 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_360_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:27.846 172.17.0.2:54325      7233   ad-pool-86  INFO org.apache.spark.storage.BlockManager: Removing RDD 571\n",
      "10-20 14:45:27.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 360 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:27.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 240 (MapPartitionsRDD[592] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:27.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 240.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:27.854 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 240.0 (TID 640) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:27.854 172.17.0.2:54325      7233    (TID 640)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 240.0 (TID 640)\n",
      "10-20 14:45:27.860 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_359_piece0 on 95675304fa2d:39429 in memory (size: 4.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:27.891 172.17.0.2:54325      7233    (TID 640)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:27.966 172.17.0.2:54325      7233    (TID 640)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_20231020144527848920035412147046_0592_m_000000_0: Committed\n",
      "10-20 14:45:27.968 172.17.0.2:54325      7233    (TID 640)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 240.0 (TID 640). 1158 bytes result sent to driver\n",
      "10-20 14:45:27.975 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 240.0 (TID 640) in 121 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:27.975 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:27.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 240 (runJob at SparkHadoopWriter.scala:83) finished in 0.153 s\n",
      "10-20 14:45:27.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:27.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 240: Stage finished\n",
      "10-20 14:45:27.976 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 122 finished: runJob at SparkHadoopWriter.scala:83, took 0.155528 s\n",
      "10-20 14:45:27.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_20231020144527848920035412147046_0592 committed.\n",
      "10-20 14:45:28.005 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:28.046 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:28.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 123 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:28.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 241 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:28.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:28.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:28.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 241 (MapPartitionsRDD[594] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:28.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_361 stored as values in memory (estimated size 83.9 KiB, free 433.8 MiB)\n",
      "10-20 14:45:28.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_361_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.8 MiB)\n",
      "10-20 14:45:28.056 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_361_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 361 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:28.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 241 (MapPartitionsRDD[594] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:28.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 241.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:28.057 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 241.0 (TID 641) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.058 172.17.0.2:54325      7233    (TID 641)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 241.0 (TID 641)\n",
      "10-20 14:45:28.064 172.17.0.2:54325      7233    (TID 641)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:28.110 172.17.0.2:54325      7233    (TID 641)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445281906043533627819986_0594_m_000000_0: Committed\n",
      "10-20 14:45:28.111 172.17.0.2:54325      7233    (TID 641)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 241.0 (TID 641). 1158 bytes result sent to driver\n",
      "10-20 14:45:28.112 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 241.0 (TID 641) in 55 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:28.112 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 241.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:28.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 241 (runJob at SparkHadoopWriter.scala:83) finished in 0.065 s\n",
      "10-20 14:45:28.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:28.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 241: Stage finished\n",
      "10-20 14:45:28.113 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 123 finished: runJob at SparkHadoopWriter.scala:83, took 0.067158 s\n",
      "10-20 14:45:28.128 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445281906043533627819986_0594 committed.\n",
      "10-20 14:45:28.211 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_54_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.212 172.17.0.2:54325      7233   d-pool-101  INFO org.apache.spark.storage.BlockManager: Removing RDD 154\n",
      "10-20 14:45:28.248 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:28.269 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:28.270 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:28.307 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at Imputer.scala:309\n",
      "10-20 14:45:28.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 596 (parquet at Imputer.scala:309) as input to shuffle 118\n",
      "10-20 14:45:28.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 124 (parquet at Imputer.scala:309) with 1 output partitions\n",
      "10-20 14:45:28.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 243 (parquet at Imputer.scala:309)\n",
      "10-20 14:45:28.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 242)\n",
      "10-20 14:45:28.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 242)\n",
      "10-20 14:45:28.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 242 (MapPartitionsRDD[596] at parquet at Imputer.scala:309), which has no missing parents\n",
      "10-20 14:45:28.311 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_362 stored as values in memory (estimated size 13.6 KiB, free 434.0 MiB)\n",
      "10-20 14:45:28.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_362_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.0 MiB)\n",
      "10-20 14:45:28.313 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_362_piece0 in memory on 95675304fa2d:39429 (size: 6.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 362 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:28.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 242 (MapPartitionsRDD[596] at parquet at Imputer.scala:309) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:45:28.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 242.0 with 4 tasks resource profile 0\n",
      "10-20 14:45:28.315 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 242.0 (TID 642) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4474 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.315 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 242.0 (TID 643) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4474 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.315 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 242.0 (TID 644) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4474 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.315 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 242.0 (TID 645) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4706 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.316 172.17.0.2:54325      7233    (TID 643)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 242.0 (TID 643)\n",
      "10-20 14:45:28.316 172.17.0.2:54325      7233    (TID 644)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 242.0 (TID 644)\n",
      "10-20 14:45:28.316 172.17.0.2:54325      7233    (TID 642)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 242.0 (TID 642)\n",
      "10-20 14:45:28.319 172.17.0.2:54325      7233    (TID 643)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 242.0 (TID 643). 1560 bytes result sent to driver\n",
      "10-20 14:45:28.319 172.17.0.2:54325      7233    (TID 645)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 242.0 (TID 645)\n",
      "10-20 14:45:28.321 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 242.0 (TID 643) in 6 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:45:28.322 172.17.0.2:54325      7233    (TID 644)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 242.0 (TID 644). 1560 bytes result sent to driver\n",
      "10-20 14:45:28.322 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 242.0 (TID 644) in 7 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:45:28.323 172.17.0.2:54325      7233    (TID 642)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 242.0 (TID 642). 1560 bytes result sent to driver\n",
      "10-20 14:45:28.323 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 242.0 (TID 642) in 8 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:45:28.325 172.17.0.2:54325      7233    (TID 645)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 242.0 (TID 645). 1689 bytes result sent to driver\n",
      "10-20 14:45:28.325 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 242.0 (TID 645) in 10 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 242 (parquet at Imputer.scala:309) finished in 0.017 s\n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 243)\n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:28.326 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 243 (ShuffledRowRDD[597] at parquet at Imputer.scala:309), which has no missing parents\n",
      "10-20 14:45:28.339 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_363 stored as values in memory (estimated size 171.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:28.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_363_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.7 MiB)\n",
      "10-20 14:45:28.340 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_363_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:28.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 363 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:28.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 243 (ShuffledRowRDD[597] at parquet at Imputer.scala:309) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:28.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 243.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:28.342 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 243.0 (TID 646) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.342 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 243.0 (TID 646)\n",
      "10-20 14:45:28.363 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:28.363 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:28.365 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:28.368 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:28.374 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:28.376 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:28.388 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:28.419 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"fnlwgt\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"age\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"capital_gain\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"capital_loss\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"hours_per_week\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required double fnlwgt;\n",
      "  required double age;\n",
      "  required double capital_gain;\n",
      "  required double capital_loss;\n",
      "  required double hours_per_week;\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:28.492 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_360_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.493 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_361_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.495 172.17.0.2:54325      7233   d-pool-110  INFO org.apache.spark.storage.BlockManager: Removing RDD 546\n",
      "10-20 14:45:28.498 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_362_piece0 on 95675304fa2d:39429 in memory (size: 6.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.499 172.17.0.2:54325      7233   d-pool-113  INFO org.apache.spark.storage.BlockManager: Removing RDD 590\n",
      "10-20 14:45:28.500 172.17.0.2:54325      7233   d-pool-114  INFO org.apache.spark.storage.BlockManager: Removing RDD 568\n",
      "10-20 14:45:28.532 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 60\n",
      "10-20 14:45:28.713 172.17.0.2:54325      7233   d-pool-118  INFO org.apache.spark.storage.BlockManager: Removing RDD 502\n",
      "10-20 14:45:28.715 172.17.0.2:54325      7233   ad-pool-35  INFO org.apache.spark.storage.BlockManager: Removing RDD 524\n",
      "10-20 14:45:28.887 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445287765593961245181320_0243_m_000000_646: Committed\n",
      "10-20 14:45:28.891 172.17.0.2:54325      7233    (TID 646)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 243.0 (TID 646). 3450 bytes result sent to driver\n",
      "10-20 14:45:28.892 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 243.0 (TID 646) in 550 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:28.892 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:28.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 243 (parquet at Imputer.scala:309) finished in 0.566 s\n",
      "10-20 14:45:28.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:28.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 243: Stage finished\n",
      "10-20 14:45:28.895 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 124 finished: parquet at Imputer.scala:309, took 0.587284 s\n",
      "10-20 14:45:28.908 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job e30d7b68-05da-4628-8afc-56f0ff3ff33d committed.\n",
      "10-20 14:45:28.912 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job e30d7b68-05da-4628-8afc-56f0ff3ff33d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:45:28.923 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:28.957 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:28.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 125 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:28.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 244 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:28.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:28.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:28.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 244 (MapPartitionsRDD[601] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:28.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_364 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:28.979 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_364_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:28.980 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_364_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.980 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_363_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:28.981 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 364 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:28.982 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 244 (MapPartitionsRDD[601] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:28.982 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 244.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:28.983 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 244.0 (TID 647) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4836 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:28.984 172.17.0.2:54325      7233    (TID 647)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 244.0 (TID 647)\n",
      "10-20 14:45:28.992 172.17.0.2:54325      7233    (TID 647)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.015 172.17.0.2:54325      7233    (TID 647)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445285264084035618281930_0601_m_000000_0: Committed\n",
      "10-20 14:45:29.015 172.17.0.2:54325      7233    (TID 647)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 244.0 (TID 647). 1158 bytes result sent to driver\n",
      "10-20 14:45:29.016 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 244.0 (TID 647) in 33 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.016 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 244 (runJob at SparkHadoopWriter.scala:83) finished in 0.058 s\n",
      "10-20 14:45:29.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 244: Stage finished\n",
      "10-20 14:45:29.018 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 125 finished: runJob at SparkHadoopWriter.scala:83, took 0.060356 s\n",
      "10-20 14:45:29.030 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445285264084035618281930_0601 committed.\n",
      "10-20 14:45:29.067 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.069 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.069 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.089 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.601832 ms\n",
      "10-20 14:45:29.108 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:29.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 604 (parquet at StringIndexer.scala:499) as input to shuffle 119\n",
      "10-20 14:45:29.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 126 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:29.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 246 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:29.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 245)\n",
      "10-20 14:45:29.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 245)\n",
      "10-20 14:45:29.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 245 (MapPartitionsRDD[604] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.111 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_365 stored as values in memory (estimated size 7.6 KiB, free 434.1 MiB)\n",
      "10-20 14:45:29.112 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_365_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 434.1 MiB)\n",
      "10-20 14:45:29.113 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_365_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 365 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 245 (MapPartitionsRDD[604] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.113 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 245.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.115 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 245.0 (TID 648) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4893 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.115 172.17.0.2:54325      7233    (TID 648)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 245.0 (TID 648)\n",
      "10-20 14:45:29.120 172.17.0.2:54325      7233    (TID 648)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 245.0 (TID 648). 1617 bytes result sent to driver\n",
      "10-20 14:45:29.121 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 245.0 (TID 648) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.121 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 245 (parquet at StringIndexer.scala:499) finished in 0.012 s\n",
      "10-20 14:45:29.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:29.125 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:29.126 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 246)\n",
      "10-20 14:45:29.126 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:29.127 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 246 (ShuffledRowRDD[605] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.145 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_366 stored as values in memory (estimated size 170.8 KiB, free 433.9 MiB)\n",
      "10-20 14:45:29.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_366_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.9 MiB)\n",
      "10-20 14:45:29.147 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_366_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 366 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 246 (ShuffledRowRDD[605] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.149 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 246.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.150 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 246.0 (TID 649) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.150 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 246.0 (TID 649)\n",
      "10-20 14:45:29.173 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:29.174 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:29.176 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.177 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.177 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.177 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:29.184 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:29.187 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:29.226 172.17.0.2:54325      7233   ad-pool-48  INFO org.apache.spark.storage.BlockManager: Removing RDD 480\n",
      "10-20 14:45:29.232 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 233\n",
      "10-20 14:45:29.238 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445294650157078895057126_0246_m_000000_649: Committed\n",
      "10-20 14:45:29.238 172.17.0.2:54325      7233    (TID 649)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 246.0 (TID 649). 3364 bytes result sent to driver\n",
      "10-20 14:45:29.239 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 246.0 (TID 649) in 89 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.240 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 246.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.240 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 246 (parquet at StringIndexer.scala:499) finished in 0.112 s\n",
      "10-20 14:45:29.240 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.240 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 246: Stage finished\n",
      "10-20 14:45:29.240 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 126 finished: parquet at StringIndexer.scala:499, took 0.132679 s\n",
      "10-20 14:45:29.251 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 1232e4d6-25cd-4930-8b61-1e8b1dc85376 committed.\n",
      "10-20 14:45:29.252 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 1232e4d6-25cd-4930-8b61-1e8b1dc85376.\n",
      "10-20 14:45:29.257 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.279 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:29.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 127 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:29.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 247 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:29.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:29.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:29.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 247 (MapPartitionsRDD[609] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:29.287 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_367 stored as values in memory (estimated size 83.9 KiB, free 433.8 MiB)\n",
      "10-20 14:45:29.287 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_367_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.7 MiB)\n",
      "10-20 14:45:29.288 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_367_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.288 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 367 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.289 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 247 (MapPartitionsRDD[609] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.289 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 247.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.290 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 247.0 (TID 650) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4836 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.290 172.17.0.2:54325      7233    (TID 650)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 247.0 (TID 650)\n",
      "10-20 14:45:29.295 172.17.0.2:54325      7233    (TID 650)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.310 172.17.0.2:54325      7233    (TID 650)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445296560337284715171379_0609_m_000000_0: Committed\n",
      "10-20 14:45:29.311 172.17.0.2:54325      7233    (TID 650)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 247.0 (TID 650). 1158 bytes result sent to driver\n",
      "10-20 14:45:29.311 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 247.0 (TID 650) in 21 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.311 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 247.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.312 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 247 (runJob at SparkHadoopWriter.scala:83) finished in 0.031 s\n",
      "10-20 14:45:29.312 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.312 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 247: Stage finished\n",
      "10-20 14:45:29.313 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 127 finished: runJob at SparkHadoopWriter.scala:83, took 0.033722 s\n",
      "10-20 14:45:29.322 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445296560337284715171379_0609 committed.\n",
      "10-20 14:45:29.339 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.340 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.340 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.366 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:29.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 612 (parquet at StringIndexer.scala:499) as input to shuffle 120\n",
      "10-20 14:45:29.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 128 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:29.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 249 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:29.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 248)\n",
      "10-20 14:45:29.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 248)\n",
      "10-20 14:45:29.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 248 (MapPartitionsRDD[612] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_368 stored as values in memory (estimated size 7.6 KiB, free 433.7 MiB)\n",
      "10-20 14:45:29.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_368_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.7 MiB)\n",
      "10-20 14:45:29.379 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_368_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:29.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 368 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[612] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 248.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.380 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_365_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.381 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 248.0 (TID 651) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4997 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.381 172.17.0.2:54325      7233    (TID 651)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 248.0 (TID 651)\n",
      "10-20 14:45:29.382 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_366_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.382 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_367_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.384 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_364_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:29.384 172.17.0.2:54325      7233    (TID 651)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 248.0 (TID 651). 1617 bytes result sent to driver\n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 248.0 (TID 651) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 248 (parquet at StringIndexer.scala:499) finished in 0.017 s\n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 249)\n",
      "10-20 14:45:29.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:29.386 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 249 (ShuffledRowRDD[613] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.396 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_369 stored as values in memory (estimated size 170.8 KiB, free 434.0 MiB)\n",
      "10-20 14:45:29.397 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_369_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 434.0 MiB)\n",
      "10-20 14:45:29.398 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_369_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 369 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 249 (ShuffledRowRDD[613] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 249.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.399 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 249.0 (TID 652) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.400 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 249.0 (TID 652)\n",
      "10-20 14:45:29.408 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:29.408 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:29.409 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:29.410 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:29.411 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:29.429 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 327\n",
      "10-20 14:45:29.431 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445295272799334426608758_0249_m_000000_652: Committed\n",
      "10-20 14:45:29.432 172.17.0.2:54325      7233    (TID 652)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 249.0 (TID 652). 3364 bytes result sent to driver\n",
      "10-20 14:45:29.433 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 249.0 (TID 652) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.434 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 249.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.435 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 249 (parquet at StringIndexer.scala:499) finished in 0.049 s\n",
      "10-20 14:45:29.435 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.435 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 249: Stage finished\n",
      "10-20 14:45:29.435 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 128 finished: parquet at StringIndexer.scala:499, took 0.069011 s\n",
      "10-20 14:45:29.451 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job d7060138-6db8-4ff5-8233-b917151819e4 committed.\n",
      "10-20 14:45:29.451 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job d7060138-6db8-4ff5-8233-b917151819e4.\n",
      "10-20 14:45:29.458 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.477 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:29.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 129 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:29.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 250 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:29.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:29.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:29.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 250 (MapPartitionsRDD[617] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:29.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_370 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:29.485 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_370_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:29.485 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_370_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 370 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 250 (MapPartitionsRDD[617] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.486 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 250.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.487 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 250.0 (TID 653) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4846 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.487 172.17.0.2:54325      7233    (TID 653)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 250.0 (TID 653)\n",
      "10-20 14:45:29.493 172.17.0.2:54325      7233    (TID 653)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.525 172.17.0.2:54325      7233    (TID 653)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445291287947521833294610_0617_m_000000_0: Committed\n",
      "10-20 14:45:29.526 172.17.0.2:54325      7233    (TID 653)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 250.0 (TID 653). 1158 bytes result sent to driver\n",
      "10-20 14:45:29.527 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 250.0 (TID 653) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.527 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 250 (runJob at SparkHadoopWriter.scala:83) finished in 0.050 s\n",
      "10-20 14:45:29.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 129 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.529 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 250: Stage finished\n",
      "10-20 14:45:29.530 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 129 finished: runJob at SparkHadoopWriter.scala:83, took 0.053009 s\n",
      "10-20 14:45:29.548 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445291287947521833294610_0617 committed.\n",
      "10-20 14:45:29.572 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.573 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.573 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.598 172.17.0.2:54325      7233   d-pool-129  INFO org.apache.spark.storage.BlockManager: Removing RDD 458\n",
      "10-20 14:45:29.621 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:29.621 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 620 (parquet at StringIndexer.scala:499) as input to shuffle 121\n",
      "10-20 14:45:29.622 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 130 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:29.622 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 252 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:29.622 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 251)\n",
      "10-20 14:45:29.622 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 251)\n",
      "10-20 14:45:29.622 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 251 (MapPartitionsRDD[620] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_371 stored as values in memory (estimated size 7.6 KiB, free 433.8 MiB)\n",
      "10-20 14:45:29.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_371_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:29.625 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_371_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 371 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 251 (MapPartitionsRDD[620] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 251.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.627 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 251.0 (TID 654) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.627 172.17.0.2:54325      7233    (TID 654)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 251.0 (TID 654)\n",
      "10-20 14:45:29.630 172.17.0.2:54325      7233    (TID 654)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 251.0 (TID 654). 1617 bytes result sent to driver\n",
      "10-20 14:45:29.631 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 251.0 (TID 654) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.631 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 251 (parquet at StringIndexer.scala:499) finished in 0.008 s\n",
      "10-20 14:45:29.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:29.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:29.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 252)\n",
      "10-20 14:45:29.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:29.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 252 (ShuffledRowRDD[621] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.644 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_372 stored as values in memory (estimated size 170.8 KiB, free 433.7 MiB)\n",
      "10-20 14:45:29.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_372_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.6 MiB)\n",
      "10-20 14:45:29.646 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_372_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:29.646 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 372 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 252 (ShuffledRowRDD[621] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 252.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.648 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 252.0 (TID 655) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.648 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 252.0 (TID 655)\n",
      "10-20 14:45:29.660 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:29.660 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:29.661 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.662 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.662 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.662 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:29.663 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:29.664 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:29.683 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 156\n",
      "10-20 14:45:29.684 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445297683784209132276489_0252_m_000000_655: Committed\n",
      "10-20 14:45:29.685 172.17.0.2:54325      7233    (TID 655)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 252.0 (TID 655). 3364 bytes result sent to driver\n",
      "10-20 14:45:29.687 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 252.0 (TID 655) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.689 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.689 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 252 (parquet at StringIndexer.scala:499) finished in 0.057 s\n",
      "10-20 14:45:29.689 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.689 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished\n",
      "10-20 14:45:29.690 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 130 finished: parquet at StringIndexer.scala:499, took 0.068736 s\n",
      "10-20 14:45:29.704 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 39d4cf9a-d5aa-4b91-8cc4-9d8444396e00 committed.\n",
      "10-20 14:45:29.705 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 39d4cf9a-d5aa-4b91-8cc4-9d8444396e00.\n",
      "10-20 14:45:29.714 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.737 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:29.737 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 131 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:29.738 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 253 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:29.738 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:29.738 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:29.738 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 253 (MapPartitionsRDD[625] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:29.743 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_373 stored as values in memory (estimated size 83.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:29.744 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_373_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:29.744 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_373_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:29.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 373 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 253 (MapPartitionsRDD[625] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 253.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.749 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 253.0 (TID 656) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4838 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.749 172.17.0.2:54325      7233    (TID 656)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 253.0 (TID 656)\n",
      "10-20 14:45:29.755 172.17.0.2:54325      7233    (TID 656)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.772 172.17.0.2:54325      7233    (TID 656)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445298836431719164091238_0625_m_000000_0: Committed\n",
      "10-20 14:45:29.773 172.17.0.2:54325      7233    (TID 656)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 253.0 (TID 656). 1158 bytes result sent to driver\n",
      "10-20 14:45:29.774 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 253.0 (TID 656) in 25 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.774 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.775 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 253 (runJob at SparkHadoopWriter.scala:83) finished in 0.037 s\n",
      "10-20 14:45:29.775 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.775 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 253: Stage finished\n",
      "10-20 14:45:29.775 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 131 finished: runJob at SparkHadoopWriter.scala:83, took 0.037828 s\n",
      "10-20 14:45:29.783 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445298836431719164091238_0625 committed.\n",
      "10-20 14:45:29.805 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.806 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.806 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.830 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:29.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 628 (parquet at StringIndexer.scala:499) as input to shuffle 122\n",
      "10-20 14:45:29.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 132 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:29.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 255 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:29.832 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 254)\n",
      "10-20 14:45:29.832 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 254)\n",
      "10-20 14:45:29.832 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 254 (MapPartitionsRDD[628] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.833 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_374 stored as values in memory (estimated size 7.6 KiB, free 433.5 MiB)\n",
      "10-20 14:45:29.843 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_374_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.5 MiB)\n",
      "10-20 14:45:29.844 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_374_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:29.844 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_369_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:29.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 374 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.845 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_370_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 254 (MapPartitionsRDD[628] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 254.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.846 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_371_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.848 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 254.0 (TID 657) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5053 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.848 172.17.0.2:54325      7233    (TID 657)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 254.0 (TID 657)\n",
      "10-20 14:45:29.851 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_372_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.852 172.17.0.2:54325      7233    (TID 657)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 254.0 (TID 657). 1617 bytes result sent to driver\n",
      "10-20 14:45:29.852 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_373_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 254.0 (TID 657) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 254 (parquet at StringIndexer.scala:499) finished in 0.021 s\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 255)\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:29.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 255 (ShuffledRowRDD[629] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:29.855 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_368_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:29.868 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_375 stored as values in memory (estimated size 170.8 KiB, free 434.0 MiB)\n",
      "10-20 14:45:29.869 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_375_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 434.0 MiB)\n",
      "10-20 14:45:29.869 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_375_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.869 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 375 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 255 (ShuffledRowRDD[629] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.870 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 255.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.871 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 255.0 (TID 658) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.872 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 255.0 (TID 658)\n",
      "10-20 14:45:29.879 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:29.879 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:29.880 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:29.881 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:29.881 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:29.881 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:29.881 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:29.881 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:29.901 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 390\n",
      "10-20 14:45:29.903 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445298253164623608551893_0255_m_000000_658: Committed\n",
      "10-20 14:45:29.904 172.17.0.2:54325      7233    (TID 658)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 255.0 (TID 658). 3364 bytes result sent to driver\n",
      "10-20 14:45:29.904 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 255.0 (TID 658) in 33 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.905 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.906 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 255 (parquet at StringIndexer.scala:499) finished in 0.051 s\n",
      "10-20 14:45:29.906 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.906 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 255: Stage finished\n",
      "10-20 14:45:29.906 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 132 finished: parquet at StringIndexer.scala:499, took 0.075732 s\n",
      "10-20 14:45:29.915 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 64ba31b5-a636-4f57-b5bf-ad4c0295a434 committed.\n",
      "10-20 14:45:29.915 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 64ba31b5-a636-4f57-b5bf-ad4c0295a434.\n",
      "10-20 14:45:29.922 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.942 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:29.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 133 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:29.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 256 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:29.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:29.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:29.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 256 (MapPartitionsRDD[633] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:29.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_376 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:29.950 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_376_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:29.951 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_376_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:29.951 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 376 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:29.951 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 256 (MapPartitionsRDD[633] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:29.952 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 256.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:29.952 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 256.0 (TID 659) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4842 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:29.953 172.17.0.2:54325      7233    (TID 659)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 256.0 (TID 659)\n",
      "10-20 14:45:29.957 172.17.0.2:54325      7233    (TID 659)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:29.973 172.17.0.2:54325      7233    (TID 659)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445298863371448863085028_0633_m_000000_0: Committed\n",
      "10-20 14:45:29.974 172.17.0.2:54325      7233    (TID 659)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 256.0 (TID 659). 1158 bytes result sent to driver\n",
      "10-20 14:45:29.974 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 256.0 (TID 659) in 22 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:29.975 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:29.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 256 (runJob at SparkHadoopWriter.scala:83) finished in 0.031 s\n",
      "10-20 14:45:29.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:29.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 256: Stage finished\n",
      "10-20 14:45:29.975 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 133 finished: runJob at SparkHadoopWriter.scala:83, took 0.032906 s\n",
      "10-20 14:45:29.984 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445298863371448863085028_0633 committed.\n",
      "10-20 14:45:30.004 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.006 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.007 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.042 172.17.0.2:54325      7233   ad-pool-76  INFO org.apache.spark.storage.BlockManager: Removing RDD 436\n",
      "10-20 14:45:30.054 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:30.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 636 (parquet at StringIndexer.scala:499) as input to shuffle 123\n",
      "10-20 14:45:30.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 134 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:30.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 258 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:30.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 257)\n",
      "10-20 14:45:30.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 257)\n",
      "10-20 14:45:30.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 257 (MapPartitionsRDD[636] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_377 stored as values in memory (estimated size 7.6 KiB, free 433.8 MiB)\n",
      "10-20 14:45:30.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_377_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:30.057 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_377_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 377 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 257 (MapPartitionsRDD[636] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 257.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.060 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 257.0 (TID 660) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4810 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.061 172.17.0.2:54325      7233    (TID 660)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 257.0 (TID 660)\n",
      "10-20 14:45:30.065 172.17.0.2:54325      7233    (TID 660)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 257.0 (TID 660). 1617 bytes result sent to driver\n",
      "10-20 14:45:30.066 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 257.0 (TID 660) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.066 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.066 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 257 (parquet at StringIndexer.scala:499) finished in 0.010 s\n",
      "10-20 14:45:30.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:30.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:30.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 258)\n",
      "10-20 14:45:30.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:30.067 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 258 (ShuffledRowRDD[637] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.078 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_378 stored as values in memory (estimated size 170.8 KiB, free 433.7 MiB)\n",
      "10-20 14:45:30.079 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_378_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.6 MiB)\n",
      "10-20 14:45:30.080 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_378_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.080 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 378 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.081 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 258 (ShuffledRowRDD[637] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.081 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 258.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.082 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 258.0 (TID 661) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.082 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 258.0 (TID 661)\n",
      "10-20 14:45:30.089 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:30.089 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:30.092 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.092 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.093 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.093 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.093 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:30.094 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:30.094 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:30.094 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:30.094 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:30.094 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:30.095 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:30.095 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:30.095 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:30.095 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:30.097 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:30.122 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 110\n",
      "10-20 14:45:30.127 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445303191110543360671009_0258_m_000000_661: Committed\n",
      "10-20 14:45:30.128 172.17.0.2:54325      7233    (TID 661)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 258.0 (TID 661). 3364 bytes result sent to driver\n",
      "10-20 14:45:30.129 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 258.0 (TID 661) in 47 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.130 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 258 (parquet at StringIndexer.scala:499) finished in 0.063 s\n",
      "10-20 14:45:30.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 258: Stage finished\n",
      "10-20 14:45:30.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 134 finished: parquet at StringIndexer.scala:499, took 0.075706 s\n",
      "10-20 14:45:30.139 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 0f08688e-d681-4513-b5a2-f3792a250734 committed.\n",
      "10-20 14:45:30.139 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 0f08688e-d681-4513-b5a2-f3792a250734.\n",
      "10-20 14:45:30.151 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.181 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:30.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 135 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:30.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 259 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:30.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:30.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:30.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[641] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:30.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_379 stored as values in memory (estimated size 83.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:30.202 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_374_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.202 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_379_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 433.5 MiB)\n",
      "10-20 14:45:30.202 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_377_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.203 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_379_piece0 in memory on 95675304fa2d:39429 (size: 30.0 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.203 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 379 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.203 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 259 (MapPartitionsRDD[641] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.203 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 259.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.204 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_375_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.204 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 259.0 (TID 662) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4826 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.205 172.17.0.2:54325      7233    (TID 662)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 259.0 (TID 662)\n",
      "10-20 14:45:30.205 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_378_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.209 172.17.0.2:54325      7233    (TID 662)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.210 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_376_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.227 172.17.0.2:54325      7233    (TID 662)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_2023102014453045496682048956953_0641_m_000000_0: Committed\n",
      "10-20 14:45:30.228 172.17.0.2:54325      7233    (TID 662)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 259.0 (TID 662). 1158 bytes result sent to driver\n",
      "10-20 14:45:30.229 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 259.0 (TID 662) in 25 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.229 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.230 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 259 (runJob at SparkHadoopWriter.scala:83) finished in 0.047 s\n",
      "10-20 14:45:30.230 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.230 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 259: Stage finished\n",
      "10-20 14:45:30.230 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 135 finished: runJob at SparkHadoopWriter.scala:83, took 0.048653 s\n",
      "10-20 14:45:30.238 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_2023102014453045496682048956953_0641 committed.\n",
      "10-20 14:45:30.252 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.254 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.254 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.276 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:30.276 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 644 (parquet at StringIndexer.scala:499) as input to shuffle 124\n",
      "10-20 14:45:30.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 136 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:30.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 261 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:30.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 260)\n",
      "10-20 14:45:30.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 260)\n",
      "10-20 14:45:30.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 260 (MapPartitionsRDD[644] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.278 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_380 stored as values in memory (estimated size 7.6 KiB, free 434.1 MiB)\n",
      "10-20 14:45:30.278 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_380_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 434.1 MiB)\n",
      "10-20 14:45:30.278 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_380_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 380 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 260 (MapPartitionsRDD[644] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 260.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.280 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 260.0 (TID 663) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4794 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.281 172.17.0.2:54325      7233    (TID 663)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 260.0 (TID 663)\n",
      "10-20 14:45:30.284 172.17.0.2:54325      7233    (TID 663)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 260.0 (TID 663). 1617 bytes result sent to driver\n",
      "10-20 14:45:30.284 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 260.0 (TID 663) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.284 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 260 (parquet at StringIndexer.scala:499) finished in 0.008 s\n",
      "10-20 14:45:30.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:30.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:30.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 261)\n",
      "10-20 14:45:30.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:30.285 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 261 (ShuffledRowRDD[645] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_381 stored as values in memory (estimated size 170.8 KiB, free 433.9 MiB)\n",
      "10-20 14:45:30.296 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_381_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.9 MiB)\n",
      "10-20 14:45:30.297 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_381_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 381 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 261 (ShuffledRowRDD[645] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 261.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.301 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 261.0 (TID 664) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.301 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 261.0 (TID 664)\n",
      "10-20 14:45:30.308 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:30.308 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:30.309 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:30.310 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:30.329 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 96\n",
      "10-20 14:45:30.331 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445301835464665426516048_0261_m_000000_664: Committed\n",
      "10-20 14:45:30.332 172.17.0.2:54325      7233    (TID 664)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 261.0 (TID 664). 3364 bytes result sent to driver\n",
      "10-20 14:45:30.332 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 261.0 (TID 664) in 31 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.333 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.333 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 261 (parquet at StringIndexer.scala:499) finished in 0.048 s\n",
      "10-20 14:45:30.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 261: Stage finished\n",
      "10-20 14:45:30.334 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 136 finished: parquet at StringIndexer.scala:499, took 0.058104 s\n",
      "10-20 14:45:30.343 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 71e2e5a4-1feb-4886-9bc1-47ce3cec5f9f committed.\n",
      "10-20 14:45:30.343 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 71e2e5a4-1feb-4886-9bc1-47ce3cec5f9f.\n",
      "10-20 14:45:30.351 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.369 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:30.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 137 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:30.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 262 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:30.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:30.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:30.370 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[649] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:30.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_382 stored as values in memory (estimated size 83.9 KiB, free 433.8 MiB)\n",
      "10-20 14:45:30.405 172.17.0.2:54325      7233   d-pool-102  INFO org.apache.spark.storage.BlockManager: Removing RDD 414\n",
      "10-20 14:45:30.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_382_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.7 MiB)\n",
      "10-20 14:45:30.407 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_382_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 382 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 262 (MapPartitionsRDD[649] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 262.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.408 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 262.0 (TID 665) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4824 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.409 172.17.0.2:54325      7233    (TID 665)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 262.0 (TID 665)\n",
      "10-20 14:45:30.415 172.17.0.2:54325      7233    (TID 665)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.442 172.17.0.2:54325      7233    (TID 665)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445308451830575686515732_0649_m_000000_0: Committed\n",
      "10-20 14:45:30.444 172.17.0.2:54325      7233    (TID 665)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 262.0 (TID 665). 1158 bytes result sent to driver\n",
      "10-20 14:45:30.445 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 262.0 (TID 665) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.445 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 262 (runJob at SparkHadoopWriter.scala:83) finished in 0.075 s\n",
      "10-20 14:45:30.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished\n",
      "10-20 14:45:30.446 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 137 finished: runJob at SparkHadoopWriter.scala:83, took 0.077078 s\n",
      "10-20 14:45:30.459 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445308451830575686515732_0649 committed.\n",
      "10-20 14:45:30.480 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.481 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.482 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.515 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:30.516 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 652 (parquet at StringIndexer.scala:499) as input to shuffle 125\n",
      "10-20 14:45:30.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 138 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:30.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 264 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:30.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 263)\n",
      "10-20 14:45:30.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 263)\n",
      "10-20 14:45:30.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 263 (MapPartitionsRDD[652] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.519 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_383 stored as values in memory (estimated size 7.6 KiB, free 433.7 MiB)\n",
      "10-20 14:45:30.520 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_383_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.7 MiB)\n",
      "10-20 14:45:30.525 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_383_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.527 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 383 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.527 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 263 (MapPartitionsRDD[652] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.527 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 263.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.528 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 263.0 (TID 666) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.529 172.17.0.2:54325      7233    (TID 666)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 263.0 (TID 666)\n",
      "10-20 14:45:30.535 172.17.0.2:54325      7233    (TID 666)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 263.0 (TID 666). 1617 bytes result sent to driver\n",
      "10-20 14:45:30.536 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 263.0 (TID 666) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.536 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.537 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 263 (parquet at StringIndexer.scala:499) finished in 0.019 s\n",
      "10-20 14:45:30.537 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:30.538 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:30.538 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 264)\n",
      "10-20 14:45:30.538 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:30.538 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 264 (ShuffledRowRDD[653] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_384 stored as values in memory (estimated size 170.8 KiB, free 433.6 MiB)\n",
      "10-20 14:45:30.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_384_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.5 MiB)\n",
      "10-20 14:45:30.554 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_384_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.554 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 384 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 264 (ShuffledRowRDD[653] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 264.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.555 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 264.0 (TID 667) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.556 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 264.0 (TID 667)\n",
      "10-20 14:45:30.564 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:30.564 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:30.565 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.566 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.566 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.566 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.566 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:30.567 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:30.594 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 28\n",
      "10-20 14:45:30.594 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_382_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.596 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_381_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.597 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445303206015147167491541_0264_m_000000_667: Committed\n",
      "10-20 14:45:30.597 172.17.0.2:54325      7233    (TID 667)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 264.0 (TID 667). 3407 bytes result sent to driver\n",
      "10-20 14:45:30.598 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_379_piece0 on 95675304fa2d:39429 in memory (size: 30.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.598 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 264.0 (TID 667) in 43 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.598 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.599 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 264 (parquet at StringIndexer.scala:499) finished in 0.060 s\n",
      "10-20 14:45:30.599 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 138 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.599 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 264: Stage finished\n",
      "10-20 14:45:30.599 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 138 finished: parquet at StringIndexer.scala:499, took 0.083856 s\n",
      "10-20 14:45:30.600 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_383_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.610 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_380_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.635 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 69873347-6285-46f2-89dc-8f10a3c6631a committed.\n",
      "10-20 14:45:30.635 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 69873347-6285-46f2-89dc-8f10a3c6631a.\n",
      "10-20 14:45:30.648 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.691 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:30.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 139 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:30.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 265 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:30.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:30.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:30.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 265 (MapPartitionsRDD[657] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:30.702 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_385 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:30.703 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_385_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:30.704 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_385_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.704 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 385 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.705 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 265 (MapPartitionsRDD[657] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.705 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 265.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.706 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 265.0 (TID 668) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4846 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.706 172.17.0.2:54325      7233    (TID 668)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 265.0 (TID 668)\n",
      "10-20 14:45:30.714 172.17.0.2:54325      7233    (TID 668)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.733 172.17.0.2:54325      7233    (TID 668)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445304578822929365025257_0657_m_000000_0: Committed\n",
      "10-20 14:45:30.734 172.17.0.2:54325      7233    (TID 668)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 265.0 (TID 668). 1158 bytes result sent to driver\n",
      "10-20 14:45:30.735 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 265.0 (TID 668) in 29 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.735 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 265 (runJob at SparkHadoopWriter.scala:83) finished in 0.042 s\n",
      "10-20 14:45:30.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 265: Stage finished\n",
      "10-20 14:45:30.737 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 139 finished: runJob at SparkHadoopWriter.scala:83, took 0.044983 s\n",
      "10-20 14:45:30.748 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445304578822929365025257_0657 committed.\n",
      "10-20 14:45:30.807 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:499\n",
      "10-20 14:45:30.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 660 (parquet at StringIndexer.scala:499) as input to shuffle 126\n",
      "10-20 14:45:30.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 140 (parquet at StringIndexer.scala:499) with 1 output partitions\n",
      "10-20 14:45:30.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 267 (parquet at StringIndexer.scala:499)\n",
      "10-20 14:45:30.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 266)\n",
      "10-20 14:45:30.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 266)\n",
      "10-20 14:45:30.840 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 266 (MapPartitionsRDD[660] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_386 stored as values in memory (estimated size 7.6 KiB, free 433.9 MiB)\n",
      "10-20 14:45:30.842 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_386_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:30.842 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_386_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:30.842 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 386 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.842 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 266 (MapPartitionsRDD[660] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.842 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 266.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.843 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 266.0 (TID 669) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5493 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.844 172.17.0.2:54325      7233    (TID 669)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 266.0 (TID 669)\n",
      "10-20 14:45:30.846 172.17.0.2:54325      7233    (TID 669)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 266.0 (TID 669). 1617 bytes result sent to driver\n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 266.0 (TID 669) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 266.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 266 (parquet at StringIndexer.scala:499) finished in 0.007 s\n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 267)\n",
      "10-20 14:45:30.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:30.848 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 267 (ShuffledRowRDD[661] at parquet at StringIndexer.scala:499), which has no missing parents\n",
      "10-20 14:45:30.858 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_387 stored as values in memory (estimated size 170.8 KiB, free 433.7 MiB)\n",
      "10-20 14:45:30.859 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_387_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.6 MiB)\n",
      "10-20 14:45:30.859 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_387_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 387 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 267 (ShuffledRowRDD[661] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.860 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 267.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.861 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 267.0 (TID 670) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.862 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 267.0 (TID 670)\n",
      "10-20 14:45:30.888 172.17.0.2:54325      7233   ad-pool-38  INFO org.apache.spark.storage.BlockManager: Removing RDD 392\n",
      "10-20 14:45:30.894 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (789.0 B) non-empty blocks including 1 (789.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:30.894 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:30.895 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.895 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:30.895 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.895 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:30.896 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"labelsArray\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : {\n",
      "        \"type\" : \"array\",\n",
      "        \"elementType\" : \"string\",\n",
      "        \"containsNull\" : true\n",
      "      },\n",
      "      \"containsNull\" : true\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group labelsArray (LIST) {\n",
      "    repeated group list {\n",
      "      optional group element (LIST) {\n",
      "        repeated group list {\n",
      "          optional binary element (UTF8);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:30.910 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 750\n",
      "10-20 14:45:30.912 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445309153229266336846687_0267_m_000000_670: Committed\n",
      "10-20 14:45:30.912 172.17.0.2:54325      7233    (TID 670)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 267.0 (TID 670). 3364 bytes result sent to driver\n",
      "10-20 14:45:30.917 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 267.0 (TID 670) in 56 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.918 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 267 (parquet at StringIndexer.scala:499) finished in 0.070 s\n",
      "10-20 14:45:30.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 140 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 267: Stage finished\n",
      "10-20 14:45:30.919 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 140 finished: parquet at StringIndexer.scala:499, took 0.079611 s\n",
      "10-20 14:45:30.926 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 55ac55fb-de54-4133-8911-42419f591538 committed.\n",
      "10-20 14:45:30.926 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 55ac55fb-de54-4133-8911-42419f591538.\n",
      "10-20 14:45:30.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.948 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:30.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 141 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:30.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 268 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:30.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:30.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:30.949 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 268 (MapPartitionsRDD[665] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:30.955 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_388 stored as values in memory (estimated size 83.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:30.956 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_388_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:30.956 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_388_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:30.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 388 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:30.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 268 (MapPartitionsRDD[665] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:30.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 268.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:30.958 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 268.0 (TID 671) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4805 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:30.958 172.17.0.2:54325      7233    (TID 671)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 268.0 (TID 671)\n",
      "10-20 14:45:30.961 172.17.0.2:54325      7233    (TID 671)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:30.974 172.17.0.2:54325      7233    (TID 671)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445307902819918520155309_0665_m_000000_0: Committed\n",
      "10-20 14:45:30.974 172.17.0.2:54325      7233    (TID 671)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 268.0 (TID 671). 1158 bytes result sent to driver\n",
      "10-20 14:45:30.975 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 268.0 (TID 671) in 17 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:30.975 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:30.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 268 (runJob at SparkHadoopWriter.scala:83) finished in 0.025 s\n",
      "10-20 14:45:30.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:30.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 268: Stage finished\n",
      "10-20 14:45:30.975 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 141 finished: runJob at SparkHadoopWriter.scala:83, took 0.026905 s\n",
      "10-20 14:45:30.997 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445307902819918520155309_0665 committed.\n",
      "10-20 14:45:31.013 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.014 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.014 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.031 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.117887 ms\n",
      "10-20 14:45:31.045 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:31.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 668 (parquet at OneHotEncoder.scala:407) as input to shuffle 127\n",
      "10-20 14:45:31.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 142 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:31.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 270 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:31.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 269)\n",
      "10-20 14:45:31.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 269)\n",
      "10-20 14:45:31.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 269 (MapPartitionsRDD[668] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.048 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_389 stored as values in memory (estimated size 7.6 KiB, free 433.5 MiB)\n",
      "10-20 14:45:31.063 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_389_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.5 MiB)\n",
      "10-20 14:45:31.063 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_389_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 389 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 269 (MapPartitionsRDD[668] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 269.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.065 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_387_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.066 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 269.0 (TID 672) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.066 172.17.0.2:54325      7233    (TID 672)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 269.0 (TID 672)\n",
      "10-20 14:45:31.070 172.17.0.2:54325      7233    (TID 672)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 269.0 (TID 672). 1617 bytes result sent to driver\n",
      "10-20 14:45:31.070 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 269.0 (TID 672) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.070 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.070 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_388_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.072 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_385_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 269 (parquet at OneHotEncoder.scala:407) finished in 0.027 s\n",
      "10-20 14:45:31.074 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_384_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:31.076 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:31.076 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:31.076 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 270)\n",
      "10-20 14:45:31.076 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:31.076 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 270 (ShuffledRowRDD[669] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.076 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_386_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:31.088 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_390 stored as values in memory (estimated size 170.8 KiB, free 434.0 MiB)\n",
      "10-20 14:45:31.089 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_390_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 434.0 MiB)\n",
      "10-20 14:45:31.090 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_390_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.091 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 390 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.091 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 270 (ShuffledRowRDD[669] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.091 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 270.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.093 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 270.0 (TID 673) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.093 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 270.0 (TID 673)\n",
      "10-20 14:45:31.102 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:31.102 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:31.103 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.103 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.104 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.104 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.104 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:31.105 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:31.106 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:31.128 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:31.132 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445311398014222581517156_0270_m_000000_673: Committed\n",
      "10-20 14:45:31.133 172.17.0.2:54325      7233    (TID 673)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 270.0 (TID 673). 3364 bytes result sent to driver\n",
      "10-20 14:45:31.133 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 270.0 (TID 673) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.134 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 270 (parquet at OneHotEncoder.scala:407) finished in 0.057 s\n",
      "10-20 14:45:31.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 142 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.135 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished\n",
      "10-20 14:45:31.135 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 142 finished: parquet at OneHotEncoder.scala:407, took 0.089798 s\n",
      "10-20 14:45:31.142 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 9837b1bd-b0de-41ce-8ba3-4c3ea5828c87 committed.\n",
      "10-20 14:45:31.143 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 9837b1bd-b0de-41ce-8ba3-4c3ea5828c87.\n",
      "10-20 14:45:31.148 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:31.164 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:31.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 143 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:31.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 271 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:31.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:31.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:31.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[673] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:31.170 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_391 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:31.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_391_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:31.172 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_391_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 391 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[673] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 271.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.173 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 271.0 (TID 674) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4805 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.173 172.17.0.2:54325      7233    (TID 674)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 271.0 (TID 674)\n",
      "10-20 14:45:31.176 172.17.0.2:54325      7233    (TID 674)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:31.188 172.17.0.2:54325      7233    (TID 674)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445311888116264047832728_0673_m_000000_0: Committed\n",
      "10-20 14:45:31.189 172.17.0.2:54325      7233    (TID 674)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 271.0 (TID 674). 1158 bytes result sent to driver\n",
      "10-20 14:45:31.189 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 271.0 (TID 674) in 17 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.189 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 271 (runJob at SparkHadoopWriter.scala:83) finished in 0.025 s\n",
      "10-20 14:45:31.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 143 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished\n",
      "10-20 14:45:31.190 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 143 finished: runJob at SparkHadoopWriter.scala:83, took 0.025717 s\n",
      "10-20 14:45:31.211 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445311888116264047832728_0673 committed.\n",
      "10-20 14:45:31.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.226 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.268 172.17.0.2:54325      7233   ad-pool-53  INFO org.apache.spark.storage.BlockManager: Removing RDD 370\n",
      "10-20 14:45:31.271 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:31.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 676 (parquet at OneHotEncoder.scala:407) as input to shuffle 128\n",
      "10-20 14:45:31.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 144 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:31.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 273 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:31.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 272)\n",
      "10-20 14:45:31.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 272)\n",
      "10-20 14:45:31.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 272 (MapPartitionsRDD[676] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.274 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_392 stored as values in memory (estimated size 7.6 KiB, free 433.8 MiB)\n",
      "10-20 14:45:31.276 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_392_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:31.276 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_392_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 392 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 272 (MapPartitionsRDD[676] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.277 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 272.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.278 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 272.0 (TID 675) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.279 172.17.0.2:54325      7233    (TID 675)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 272.0 (TID 675)\n",
      "10-20 14:45:31.281 172.17.0.2:54325      7233    (TID 675)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 272.0 (TID 675). 1617 bytes result sent to driver\n",
      "10-20 14:45:31.282 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 272.0 (TID 675) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.282 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 272 (parquet at OneHotEncoder.scala:407) finished in 0.010 s\n",
      "10-20 14:45:31.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:31.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:31.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 273)\n",
      "10-20 14:45:31.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:31.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 273 (ShuffledRowRDD[677] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.293 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_393 stored as values in memory (estimated size 170.8 KiB, free 433.7 MiB)\n",
      "10-20 14:45:31.294 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_393_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.6 MiB)\n",
      "10-20 14:45:31.294 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_393_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 393 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 273 (ShuffledRowRDD[677] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.295 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 273.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.295 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 273.0 (TID 676) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.296 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 273.0 (TID 676)\n",
      "10-20 14:45:31.303 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:31.303 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:31.304 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.304 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:31.305 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:31.306 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:31.326 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:31.331 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445316395033857380267396_0273_m_000000_676: Committed\n",
      "10-20 14:45:31.331 172.17.0.2:54325      7233    (TID 676)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 273.0 (TID 676). 3364 bytes result sent to driver\n",
      "10-20 14:45:31.332 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 273.0 (TID 676) in 37 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.333 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.333 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 273 (parquet at OneHotEncoder.scala:407) finished in 0.049 s\n",
      "10-20 14:45:31.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 144 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 273: Stage finished\n",
      "10-20 14:45:31.334 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 144 finished: parquet at OneHotEncoder.scala:407, took 0.062232 s\n",
      "10-20 14:45:31.358 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 919fe51a-5039-4b1c-a9f6-83cc55aac9ae committed.\n",
      "10-20 14:45:31.358 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 919fe51a-5039-4b1c-a9f6-83cc55aac9ae.\n",
      "10-20 14:45:31.365 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:31.384 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:31.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 145 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:31.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 274 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:31.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:31.384 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:31.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 274 (MapPartitionsRDD[681] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:31.392 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_394 stored as values in memory (estimated size 83.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:31.418 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_394_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:31.419 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_394_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.419 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_389_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.420 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 394 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.420 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 274 (MapPartitionsRDD[681] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.420 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 274.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.420 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_393_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.424 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 274.0 (TID 677) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4815 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.424 172.17.0.2:54325      7233    (TID 677)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 274.0 (TID 677)\n",
      "10-20 14:45:31.426 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_391_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.431 172.17.0.2:54325      7233    (TID 677)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:31.435 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_392_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.437 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_390_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.485 172.17.0.2:54325      7233    (TID 677)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445313045328974842025498_0681_m_000000_0: Committed\n",
      "10-20 14:45:31.485 172.17.0.2:54325      7233    (TID 677)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 274.0 (TID 677). 1158 bytes result sent to driver\n",
      "10-20 14:45:31.487 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 274.0 (TID 677) in 63 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.488 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 274 (runJob at SparkHadoopWriter.scala:83) finished in 0.104 s\n",
      "10-20 14:45:31.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 274: Stage finished\n",
      "10-20 14:45:31.490 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 145 finished: runJob at SparkHadoopWriter.scala:83, took 0.106125 s\n",
      "10-20 14:45:31.506 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445313045328974842025498_0681 committed.\n",
      "10-20 14:45:31.532 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.534 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.534 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.582 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:31.583 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 684 (parquet at OneHotEncoder.scala:407) as input to shuffle 129\n",
      "10-20 14:45:31.583 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 146 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:31.584 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 276 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:31.584 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 275)\n",
      "10-20 14:45:31.584 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 275)\n",
      "10-20 14:45:31.585 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 275 (MapPartitionsRDD[684] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.586 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_395 stored as values in memory (estimated size 7.6 KiB, free 434.1 MiB)\n",
      "10-20 14:45:31.587 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_395_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 434.1 MiB)\n",
      "10-20 14:45:31.588 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_395_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.588 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 395 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.588 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 275 (MapPartitionsRDD[684] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.588 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 275.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.589 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 275.0 (TID 678) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.590 172.17.0.2:54325      7233    (TID 678)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 275.0 (TID 678)\n",
      "10-20 14:45:31.599 172.17.0.2:54325      7233    (TID 678)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 275.0 (TID 678). 1617 bytes result sent to driver\n",
      "10-20 14:45:31.600 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 275.0 (TID 678) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 275 (parquet at OneHotEncoder.scala:407) finished in 0.015 s\n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 276)\n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:31.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 276 (ShuffledRowRDD[685] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.615 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_396 stored as values in memory (estimated size 170.8 KiB, free 433.9 MiB)\n",
      "10-20 14:45:31.616 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_396_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.9 MiB)\n",
      "10-20 14:45:31.617 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_396_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.618 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 396 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.618 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 276 (ShuffledRowRDD[685] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.618 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 276.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.620 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 276.0 (TID 679) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.620 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 276.0 (TID 679)\n",
      "10-20 14:45:31.630 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:31.630 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:31.632 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.633 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.633 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.633 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:31.634 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:31.637 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:31.662 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:31.664 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445318808723187485858628_0276_m_000000_679: Committed\n",
      "10-20 14:45:31.665 172.17.0.2:54325      7233    (TID 679)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 276.0 (TID 679). 3364 bytes result sent to driver\n",
      "10-20 14:45:31.666 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 276.0 (TID 679) in 46 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.667 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 276 (parquet at OneHotEncoder.scala:407) finished in 0.066 s\n",
      "10-20 14:45:31.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 276: Stage finished\n",
      "10-20 14:45:31.668 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 146 finished: parquet at OneHotEncoder.scala:407, took 0.085804 s\n",
      "10-20 14:45:31.680 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job b443ae6c-32b6-491c-b444-b9c47b2d9c70 committed.\n",
      "10-20 14:45:31.680 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job b443ae6c-32b6-491c-b444-b9c47b2d9c70.\n",
      "10-20 14:45:31.688 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:31.743 172.17.0.2:54325      7233   ad-pool-74  INFO org.apache.spark.storage.BlockManager: Removing RDD 348\n",
      "10-20 14:45:31.745 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:31.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 147 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:31.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 277 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:31.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:31.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:31.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 277 (MapPartitionsRDD[689] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:31.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_397 stored as values in memory (estimated size 83.9 KiB, free 433.8 MiB)\n",
      "10-20 14:45:31.757 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_397_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.7 MiB)\n",
      "10-20 14:45:31.758 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_397_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 397 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 277 (MapPartitionsRDD[689] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 277.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.760 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 277.0 (TID 680) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.761 172.17.0.2:54325      7233    (TID 680)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 277.0 (TID 680)\n",
      "10-20 14:45:31.767 172.17.0.2:54325      7233    (TID 680)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:31.786 172.17.0.2:54325      7233    (TID 680)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445314038170216673743798_0689_m_000000_0: Committed\n",
      "10-20 14:45:31.787 172.17.0.2:54325      7233    (TID 680)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 277.0 (TID 680). 1158 bytes result sent to driver\n",
      "10-20 14:45:31.788 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 277.0 (TID 680) in 28 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.788 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 277.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.789 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 277 (runJob at SparkHadoopWriter.scala:83) finished in 0.042 s\n",
      "10-20 14:45:31.790 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 147 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.790 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 277: Stage finished\n",
      "10-20 14:45:31.790 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 147 finished: runJob at SparkHadoopWriter.scala:83, took 0.044472 s\n",
      "10-20 14:45:31.803 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445314038170216673743798_0689 committed.\n",
      "10-20 14:45:31.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.863 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:31.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 692 (parquet at OneHotEncoder.scala:407) as input to shuffle 130\n",
      "10-20 14:45:31.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 148 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:31.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 279 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:31.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 278)\n",
      "10-20 14:45:31.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 278)\n",
      "10-20 14:45:31.866 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 278 (MapPartitionsRDD[692] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_398 stored as values in memory (estimated size 7.6 KiB, free 433.7 MiB)\n",
      "10-20 14:45:31.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_398_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.7 MiB)\n",
      "10-20 14:45:31.868 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_398_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.868 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 398 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.869 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 278 (MapPartitionsRDD[692] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.869 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 278.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.870 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 278.0 (TID 681) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.870 172.17.0.2:54325      7233    (TID 681)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 278.0 (TID 681)\n",
      "10-20 14:45:31.874 172.17.0.2:54325      7233    (TID 681)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 278.0 (TID 681). 1617 bytes result sent to driver\n",
      "10-20 14:45:31.887 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 278.0 (TID 681) in 18 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.887 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 278 (parquet at OneHotEncoder.scala:407) finished in 0.021 s\n",
      "10-20 14:45:31.888 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:31.888 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:31.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 279)\n",
      "10-20 14:45:31.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:31.889 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 279 (ShuffledRowRDD[693] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:31.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_399 stored as values in memory (estimated size 170.8 KiB, free 433.6 MiB)\n",
      "10-20 14:45:31.910 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_399_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.5 MiB)\n",
      "10-20 14:45:31.910 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_399_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.911 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 399 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:31.912 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 279 (ShuffledRowRDD[693] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:31.912 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 279.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:31.913 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 279.0 (TID 682) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:31.914 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 279.0 (TID 682)\n",
      "10-20 14:45:31.926 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:31.926 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:31.928 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.928 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:31.928 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:31.929 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:31.930 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:31.979 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:31.980 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_20231020144531952947361313664289_0279_m_000000_682: Committed\n",
      "10-20 14:45:31.981 172.17.0.2:54325      7233    (TID 682)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 279.0 (TID 682). 3407 bytes result sent to driver\n",
      "10-20 14:45:31.982 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 279.0 (TID 682) in 69 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:31.982 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 279.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:31.983 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 279 (parquet at OneHotEncoder.scala:407) finished in 0.093 s\n",
      "10-20 14:45:31.983 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 148 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:31.983 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 279: Stage finished\n",
      "10-20 14:45:31.983 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 148 finished: parquet at OneHotEncoder.scala:407, took 0.120229 s\n",
      "10-20 14:45:31.988 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_396_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:31.990 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_395_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:31.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job cccbd83a-c807-42be-9a7d-e1914b2f5bb8 committed.\n",
      "10-20 14:45:31.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job cccbd83a-c807-42be-9a7d-e1914b2f5bb8.\n",
      "10-20 14:45:31.997 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_397_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.006 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_398_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.008 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_394_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.009 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.036 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:32.036 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 149 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:32.036 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 280 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:32.036 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:32.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:32.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 280 (MapPartitionsRDD[697] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:32.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_400 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:32.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_400_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:32.047 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_400_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.048 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 400 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.048 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 280 (MapPartitionsRDD[697] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.048 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 280.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.049 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 280.0 (TID 683) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4811 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.049 172.17.0.2:54325      7233    (TID 683)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 280.0 (TID 683)\n",
      "10-20 14:45:32.053 172.17.0.2:54325      7233    (TID 683)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.068 172.17.0.2:54325      7233    (TID 683)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_20231020144532443633188757564314_0697_m_000000_0: Committed\n",
      "10-20 14:45:32.069 172.17.0.2:54325      7233    (TID 683)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 280.0 (TID 683). 1158 bytes result sent to driver\n",
      "10-20 14:45:32.070 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 280.0 (TID 683) in 22 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.070 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 280.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 280 (runJob at SparkHadoopWriter.scala:83) finished in 0.032 s\n",
      "10-20 14:45:32.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 149 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:32.071 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 280: Stage finished\n",
      "10-20 14:45:32.071 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 149 finished: runJob at SparkHadoopWriter.scala:83, took 0.035105 s\n",
      "10-20 14:45:32.081 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_20231020144532443633188757564314_0697 committed.\n",
      "10-20 14:45:32.108 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.114 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.115 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.152 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:32.152 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 700 (parquet at OneHotEncoder.scala:407) as input to shuffle 131\n",
      "10-20 14:45:32.152 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 150 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:32.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 282 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:32.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 281)\n",
      "10-20 14:45:32.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 281)\n",
      "10-20 14:45:32.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 281 (MapPartitionsRDD[700] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:32.154 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_401 stored as values in memory (estimated size 7.6 KiB, free 433.9 MiB)\n",
      "10-20 14:45:32.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_401_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.9 MiB)\n",
      "10-20 14:45:32.156 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_401_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 401 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 281 (MapPartitionsRDD[700] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.158 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 281.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.159 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 281.0 (TID 684) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.160 172.17.0.2:54325      7233    (TID 684)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 281.0 (TID 684)\n",
      "10-20 14:45:32.163 172.17.0.2:54325      7233    (TID 684)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 281.0 (TID 684). 1617 bytes result sent to driver\n",
      "10-20 14:45:32.164 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 281.0 (TID 684) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.164 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.167 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 281 (parquet at OneHotEncoder.scala:407) finished in 0.013 s\n",
      "10-20 14:45:32.167 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:32.167 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:32.168 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 282)\n",
      "10-20 14:45:32.168 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:32.168 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 282 (ShuffledRowRDD[701] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:32.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_402 stored as values in memory (estimated size 170.8 KiB, free 433.7 MiB)\n",
      "10-20 14:45:32.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_402_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.6 MiB)\n",
      "10-20 14:45:32.184 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_402_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:32.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 402 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (ShuffledRowRDD[701] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 282.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.186 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 282.0 (TID 685) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.187 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 282.0 (TID 685)\n",
      "10-20 14:45:32.195 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:32.195 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:32.196 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.196 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.196 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:32.196 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:32.197 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:32.198 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:32.240 172.17.0.2:54325      7233   d-pool-104  INFO org.apache.spark.storage.BlockManager: Removing RDD 326\n",
      "10-20 14:45:32.249 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:32.255 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445321387091467336163984_0282_m_000000_685: Committed\n",
      "10-20 14:45:32.256 172.17.0.2:54325      7233    (TID 685)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 282.0 (TID 685). 3364 bytes result sent to driver\n",
      "10-20 14:45:32.257 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 282.0 (TID 685) in 71 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.258 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.262 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 282 (parquet at OneHotEncoder.scala:407) finished in 0.093 s\n",
      "10-20 14:45:32.263 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 150 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:32.263 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 282: Stage finished\n",
      "10-20 14:45:32.263 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 150 finished: parquet at OneHotEncoder.scala:407, took 0.111653 s\n",
      "10-20 14:45:32.277 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 17e195a0-5bce-4461-a4a1-1159edf1f0c7 committed.\n",
      "10-20 14:45:32.277 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 17e195a0-5bce-4461-a4a1-1159edf1f0c7.\n",
      "10-20 14:45:32.286 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.314 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:32.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 151 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:32.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 283 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:32.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:32.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:32.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 283 (MapPartitionsRDD[705] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:32.322 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_403 stored as values in memory (estimated size 83.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:32.323 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_403_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:32.324 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_403_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:32.324 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 403 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.325 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 283 (MapPartitionsRDD[705] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.325 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 283.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.326 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 283.0 (TID 686) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4795 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.326 172.17.0.2:54325      7233    (TID 686)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 283.0 (TID 686)\n",
      "10-20 14:45:32.331 172.17.0.2:54325      7233    (TID 686)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.350 172.17.0.2:54325      7233    (TID 686)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445326052461157678298703_0705_m_000000_0: Committed\n",
      "10-20 14:45:32.351 172.17.0.2:54325      7233    (TID 686)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 283.0 (TID 686). 1158 bytes result sent to driver\n",
      "10-20 14:45:32.353 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 283.0 (TID 686) in 27 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.353 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 283 (runJob at SparkHadoopWriter.scala:83) finished in 0.038 s\n",
      "10-20 14:45:32.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:32.356 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 283: Stage finished\n",
      "10-20 14:45:32.356 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 151 finished: runJob at SparkHadoopWriter.scala:83, took 0.042024 s\n",
      "10-20 14:45:32.368 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445326052461157678298703_0705 committed.\n",
      "10-20 14:45:32.403 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.404 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.405 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.438 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:32.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 708 (parquet at OneHotEncoder.scala:407) as input to shuffle 132\n",
      "10-20 14:45:32.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 152 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:32.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 285 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:32.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 284)\n",
      "10-20 14:45:32.441 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 284)\n",
      "10-20 14:45:32.442 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 284 (MapPartitionsRDD[708] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:32.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_404 stored as values in memory (estimated size 7.6 KiB, free 433.5 MiB)\n",
      "10-20 14:45:32.462 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_404_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.5 MiB)\n",
      "10-20 14:45:32.463 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_399_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.463 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_404_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:32.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 404 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.465 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_400_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 284 (MapPartitionsRDD[708] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 284.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.466 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 284.0 (TID 687) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.467 172.17.0.2:54325      7233    (TID 687)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 284.0 (TID 687)\n",
      "10-20 14:45:32.471 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_403_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.474 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_402_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:32.475 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_401_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:32.476 172.17.0.2:54325      7233    (TID 687)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 284.0 (TID 687). 1617 bytes result sent to driver\n",
      "10-20 14:45:32.477 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 284.0 (TID 687) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.477 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 284.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 284 (parquet at OneHotEncoder.scala:407) finished in 0.036 s\n",
      "10-20 14:45:32.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:32.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:32.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 285)\n",
      "10-20 14:45:32.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:32.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 285 (ShuffledRowRDD[709] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:32.499 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_405 stored as values in memory (estimated size 170.8 KiB, free 434.0 MiB)\n",
      "10-20 14:45:32.501 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_405_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 434.0 MiB)\n",
      "10-20 14:45:32.502 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_405_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.502 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 405 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 285 (ShuffledRowRDD[709] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 285.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.505 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 285.0 (TID 688) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.505 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 285.0 (TID 688)\n",
      "10-20 14:45:32.519 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:32.522 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:45:32.523 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.524 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.524 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:32.525 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:32.525 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:32.525 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:32.526 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:32.526 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:32.526 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:32.526 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:32.527 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:32.527 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:32.528 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:32.528 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:32.530 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:32.572 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:32.577 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445324981580546507973983_0285_m_000000_688: Committed\n",
      "10-20 14:45:32.579 172.17.0.2:54325      7233    (TID 688)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 285.0 (TID 688). 3364 bytes result sent to driver\n",
      "10-20 14:45:32.582 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 285.0 (TID 688) in 77 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.584 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 285.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.585 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 285 (parquet at OneHotEncoder.scala:407) finished in 0.107 s\n",
      "10-20 14:45:32.585 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:32.585 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 285: Stage finished\n",
      "10-20 14:45:32.586 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 152 finished: parquet at OneHotEncoder.scala:407, took 0.147047 s\n",
      "10-20 14:45:32.604 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job e413aad4-eda4-4ad2-9df0-bcf38ea97c55 committed.\n",
      "10-20 14:45:32.604 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job e413aad4-eda4-4ad2-9df0-bcf38ea97c55.\n",
      "10-20 14:45:32.617 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.641 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:32.642 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 153 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:32.642 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 286 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:32.642 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:32.642 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:32.643 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 286 (MapPartitionsRDD[713] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:32.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_406 stored as values in memory (estimated size 83.9 KiB, free 433.9 MiB)\n",
      "10-20 14:45:32.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_406_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 433.9 MiB)\n",
      "10-20 14:45:32.655 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_406_piece0 in memory on 95675304fa2d:39429 (size: 30.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.655 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 406 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.656 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 286 (MapPartitionsRDD[713] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.656 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 286.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.657 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 286.0 (TID 689) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4793 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.658 172.17.0.2:54325      7233    (TID 689)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 286.0 (TID 689)\n",
      "10-20 14:45:32.664 172.17.0.2:54325      7233    (TID 689)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.705 172.17.0.2:54325      7233    (TID 689)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445324586945584344783864_0713_m_000000_0: Committed\n",
      "10-20 14:45:32.706 172.17.0.2:54325      7233    (TID 689)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 286.0 (TID 689). 1158 bytes result sent to driver\n",
      "10-20 14:45:32.706 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 286.0 (TID 689) in 49 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.706 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 286.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.707 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 286 (runJob at SparkHadoopWriter.scala:83) finished in 0.064 s\n",
      "10-20 14:45:32.707 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 153 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:32.707 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 286: Stage finished\n",
      "10-20 14:45:32.708 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 153 finished: runJob at SparkHadoopWriter.scala:83, took 0.066246 s\n",
      "10-20 14:45:32.717 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445324586945584344783864_0713 committed.\n",
      "10-20 14:45:32.780 172.17.0.2:54325      7233   d-pool-115  INFO org.apache.spark.storage.BlockManager: Removing RDD 304\n",
      "10-20 14:45:32.793 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.795 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.796 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.829 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:32.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 716 (parquet at OneHotEncoder.scala:407) as input to shuffle 133\n",
      "10-20 14:45:32.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 154 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:32.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 288 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:32.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 287)\n",
      "10-20 14:45:32.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 287)\n",
      "10-20 14:45:32.830 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 287 (MapPartitionsRDD[716] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:32.831 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_407 stored as values in memory (estimated size 7.6 KiB, free 433.8 MiB)\n",
      "10-20 14:45:32.832 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_407_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:32.833 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_407_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:32.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 407 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 287 (MapPartitionsRDD[716] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.835 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 287.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.836 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 287.0 (TID 690) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.836 172.17.0.2:54325      7233    (TID 690)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 287.0 (TID 690)\n",
      "10-20 14:45:32.840 172.17.0.2:54325      7233    (TID 690)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 287.0 (TID 690). 1617 bytes result sent to driver\n",
      "10-20 14:45:32.840 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 287.0 (TID 690) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.840 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 287.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 287 (parquet at OneHotEncoder.scala:407) finished in 0.015 s\n",
      "10-20 14:45:32.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:32.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:32.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 288)\n",
      "10-20 14:45:32.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:32.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 288 (ShuffledRowRDD[717] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:32.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_408 stored as values in memory (estimated size 170.8 KiB, free 433.7 MiB)\n",
      "10-20 14:45:32.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_408_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.6 MiB)\n",
      "10-20 14:45:32.864 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_408_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:32.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 408 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:32.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 288 (ShuffledRowRDD[717] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:32.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 288.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:32.866 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 288.0 (TID 691) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:32.867 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 288.0 (TID 691)\n",
      "10-20 14:45:32.877 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:32.877 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:45:32.879 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.879 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:32.880 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:32.880 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:32.881 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:32.882 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:32.882 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:32.882 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:32.883 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:32.899 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:32.900 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445323174903836508567009_0288_m_000000_691: Committed\n",
      "10-20 14:45:32.901 172.17.0.2:54325      7233    (TID 691)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 288.0 (TID 691). 3364 bytes result sent to driver\n",
      "10-20 14:45:32.902 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 288.0 (TID 691) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:32.903 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 288.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:32.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 288 (parquet at OneHotEncoder.scala:407) finished in 0.058 s\n",
      "10-20 14:45:32.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 154 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:32.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 288: Stage finished\n",
      "10-20 14:45:32.905 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 154 finished: parquet at OneHotEncoder.scala:407, took 0.076087 s\n",
      "10-20 14:45:32.928 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 56729da4-d3b9-4b28-a9d7-e66a278d81a8 committed.\n",
      "10-20 14:45:32.931 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 56729da4-d3b9-4b28-a9d7-e66a278d81a8.\n",
      "10-20 14:45:32.938 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:32.964 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:32.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 155 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:32.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 289 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:32.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:32.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:32.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 289 (MapPartitionsRDD[721] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:32.972 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_409 stored as values in memory (estimated size 83.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:33.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_409_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.5 MiB)\n",
      "10-20 14:45:33.000 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_407_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:33.005 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_409_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:33.006 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_404_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:33.008 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 409 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.008 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 289 (MapPartitionsRDD[721] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:33.008 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 289.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:33.010 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 289.0 (TID 692) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4815 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.010 172.17.0.2:54325      7233    (TID 692)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 289.0 (TID 692)\n",
      "10-20 14:45:33.011 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_405_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.013 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_408_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.015 172.17.0.2:54325      7233    (TID 692)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:33.016 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_406_piece0 on 95675304fa2d:39429 in memory (size: 30.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.035 172.17.0.2:54325      7233    (TID 692)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445329055272848495127033_0721_m_000000_0: Committed\n",
      "10-20 14:45:33.035 172.17.0.2:54325      7233    (TID 692)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 289.0 (TID 692). 1158 bytes result sent to driver\n",
      "10-20 14:45:33.036 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 289.0 (TID 692) in 27 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:33.036 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 289.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 289 (runJob at SparkHadoopWriter.scala:83) finished in 0.071 s\n",
      "10-20 14:45:33.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 155 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:33.037 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 289: Stage finished\n",
      "10-20 14:45:33.037 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 155 finished: runJob at SparkHadoopWriter.scala:83, took 0.073022 s\n",
      "10-20 14:45:33.046 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445329055272848495127033_0721 committed.\n",
      "10-20 14:45:33.062 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.063 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.063 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:407\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 724 (parquet at OneHotEncoder.scala:407) as input to shuffle 134\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 156 (parquet at OneHotEncoder.scala:407) with 1 output partitions\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 291 (parquet at OneHotEncoder.scala:407)\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 290)\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 290)\n",
      "10-20 14:45:33.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 290 (MapPartitionsRDD[724] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:33.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_410 stored as values in memory (estimated size 7.6 KiB, free 434.1 MiB)\n",
      "10-20 14:45:33.096 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_410_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 434.1 MiB)\n",
      "10-20 14:45:33.096 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_410_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 410 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 290 (MapPartitionsRDD[724] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:33.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 290.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:33.098 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 290.0 (TID 693) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4666 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.098 172.17.0.2:54325      7233    (TID 693)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 290.0 (TID 693)\n",
      "10-20 14:45:33.101 172.17.0.2:54325      7233    (TID 693)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 290.0 (TID 693). 1617 bytes result sent to driver\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 290.0 (TID 693) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 290.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 290 (parquet at OneHotEncoder.scala:407) finished in 0.007 s\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 291)\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:45:33.102 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 291 (ShuffledRowRDD[725] at parquet at OneHotEncoder.scala:407), which has no missing parents\n",
      "10-20 14:45:33.114 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_411 stored as values in memory (estimated size 170.8 KiB, free 433.9 MiB)\n",
      "10-20 14:45:33.115 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_411_piece0 stored as bytes in memory (estimated size 61.2 KiB, free 433.9 MiB)\n",
      "10-20 14:45:33.115 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_411_piece0 in memory on 95675304fa2d:39429 (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.115 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 411 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 291 (ShuffledRowRDD[725] at parquet at OneHotEncoder.scala:407) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:33.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 291.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:33.117 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 291.0 (TID 694) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.117 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 291.0 (TID 694)\n",
      "10-20 14:45:33.124 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:45:33.124 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:45:33.125 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.125 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.125 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.125 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.126 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.127 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"categorySizes\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"array\",\n",
      "      \"elementType\" : \"integer\",\n",
      "      \"containsNull\" : false\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group categorySizes (LIST) {\n",
      "    repeated group list {\n",
      "      required int32 element;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.145 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\n",
      "10-20 14:45:33.147 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_2023102014453360933722467743717_0291_m_000000_694: Committed\n",
      "10-20 14:45:33.148 172.17.0.2:54325      7233    (TID 694)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 291.0 (TID 694). 3364 bytes result sent to driver\n",
      "10-20 14:45:33.149 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 291.0 (TID 694) in 33 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:33.150 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 291.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 291 (parquet at OneHotEncoder.scala:407) finished in 0.047 s\n",
      "10-20 14:45:33.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:33.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 291: Stage finished\n",
      "10-20 14:45:33.151 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 156 finished: parquet at OneHotEncoder.scala:407, took 0.056918 s\n",
      "10-20 14:45:33.158 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 27fc2971-359e-461d-ba9e-37f436998d6a committed.\n",
      "10-20 14:45:33.159 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 27fc2971-359e-461d-ba9e-37f436998d6a.\n",
      "10-20 14:45:33.166 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:33.209 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:33.209 172.17.0.2:54325      7233   ad-pool-45  INFO org.apache.spark.storage.BlockManager: Removing RDD 282\n",
      "10-20 14:45:33.210 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 157 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:33.210 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 292 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:33.210 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:33.210 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:33.210 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 292 (MapPartitionsRDD[729] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:33.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_412 stored as values in memory (estimated size 83.9 KiB, free 433.8 MiB)\n",
      "10-20 14:45:33.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_412_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.7 MiB)\n",
      "10-20 14:45:33.217 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_412_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 412 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 292 (MapPartitionsRDD[729] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:33.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 292.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:33.218 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 292.0 (TID 695) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.219 172.17.0.2:54325      7233    (TID 695)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 292.0 (TID 695)\n",
      "10-20 14:45:33.222 172.17.0.2:54325      7233    (TID 695)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:33.234 172.17.0.2:54325      7233    (TID 695)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445331588852687152629682_0729_m_000000_0: Committed\n",
      "10-20 14:45:33.235 172.17.0.2:54325      7233    (TID 695)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 292.0 (TID 695). 1158 bytes result sent to driver\n",
      "10-20 14:45:33.236 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 292.0 (TID 695) in 18 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:33.236 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 292.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.236 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 292 (runJob at SparkHadoopWriter.scala:83) finished in 0.025 s\n",
      "10-20 14:45:33.237 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 157 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:33.237 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 292: Stage finished\n",
      "10-20 14:45:33.237 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 157 finished: runJob at SparkHadoopWriter.scala:83, took 0.027779 s\n",
      "10-20 14:45:33.246 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445331588852687152629682_0729 committed.\n",
      "10-20 14:45:33.257 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:33.282 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "10-20 14:45:33.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 158 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions\n",
      "10-20 14:45:33.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 293 (runJob at SparkHadoopWriter.scala:83)\n",
      "10-20 14:45:33.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:33.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:33.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 293 (MapPartitionsRDD[731] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\n",
      "10-20 14:45:33.288 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_413 stored as values in memory (estimated size 83.9 KiB, free 433.7 MiB)\n",
      "10-20 14:45:33.290 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_413_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.6 MiB)\n",
      "10-20 14:45:33.290 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_413_piece0 in memory on 95675304fa2d:39429 (size: 29.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:33.290 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 413 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.290 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 293 (MapPartitionsRDD[731] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:45:33.290 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 293.0 with 1 tasks resource profile 0\n",
      "10-20 14:45:33.291 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 293.0 (TID 696) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5230 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.291 172.17.0.2:54325      7233    (TID 696)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 293.0 (TID 696)\n",
      "10-20 14:45:33.295 172.17.0.2:54325      7233    (TID 696)  INFO org.apache.spark.internal.io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "10-20 14:45:33.311 172.17.0.2:54325      7233    (TID 696)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445331797166002984338391_0731_m_000000_0: Committed\n",
      "10-20 14:45:33.312 172.17.0.2:54325      7233    (TID 696)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 293.0 (TID 696). 1158 bytes result sent to driver\n",
      "10-20 14:45:33.312 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 293.0 (TID 696) in 21 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:45:33.312 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 293.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 293 (runJob at SparkHadoopWriter.scala:83) finished in 0.030 s\n",
      "10-20 14:45:33.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 158 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:33.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 293: Stage finished\n",
      "10-20 14:45:33.313 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 158 finished: runJob at SparkHadoopWriter.scala:83, took 0.030561 s\n",
      "10-20 14:45:33.321 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.internal.io.SparkHadoopWriter: Job job_202310201445331797166002984338391_0731 committed.\n",
      "10-20 14:45:33.360 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.360 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.360 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.377 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.071421 ms\n",
      "10-20 14:45:33.388 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:473\n",
      "10-20 14:45:33.388 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 159 (parquet at treeModels.scala:473) with 4 output partitions\n",
      "10-20 14:45:33.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 294 (parquet at treeModels.scala:473)\n",
      "10-20 14:45:33.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:33.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:33.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 294 (MapPartitionsRDD[733] at parquet at treeModels.scala:473), which has no missing parents\n",
      "10-20 14:45:33.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_414 stored as values in memory (estimated size 169.7 KiB, free 433.5 MiB)\n",
      "10-20 14:45:33.411 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_410_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:33.412 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_411_piece0 on 95675304fa2d:39429 in memory (size: 61.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.413 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_414_piece0 stored as bytes in memory (estimated size 60.7 KiB, free 433.6 MiB)\n",
      "10-20 14:45:33.414 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_412_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.414 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_414_piece0 in memory on 95675304fa2d:39429 (size: 60.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 414 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 294 (MapPartitionsRDD[733] at parquet at treeModels.scala:473) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:45:33.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 294.0 with 4 tasks resource profile 0\n",
      "10-20 14:45:33.415 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_409_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.416 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 294.0 (TID 697) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 7480 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.416 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 294.0 (TID 698) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 7480 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.416 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 294.0 (TID 699) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 7480 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.416 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 294.0 (TID 700) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 7480 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.416 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 294.0 (TID 698)\n",
      "10-20 14:45:33.416 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 294.0 (TID 700)\n",
      "10-20 14:45:33.417 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 294.0 (TID 699)\n",
      "10-20 14:45:33.419 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 294.0 (TID 697)\n",
      "10-20 14:45:33.423 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_413_piece0 on 95675304fa2d:39429 in memory (size: 29.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:33.435 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.437 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.438 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.436 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.435 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.438 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.438 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.438 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.441 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.438 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.442 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.441 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.445 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.444 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.445 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.445 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.445 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.446 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.447 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"metadata\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"weights\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional binary metadata (UTF8);\n",
      "  required double weights;\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.445 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.448 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.448 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.445 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.449 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"metadata\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"weights\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional binary metadata (UTF8);\n",
      "  required double weights;\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.455 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.455 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.456 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.457 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"metadata\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"weights\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional binary metadata (UTF8);\n",
      "  required double weights;\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.458 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"metadata\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"weights\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional binary metadata (UTF8);\n",
      "  required double weights;\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.477 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 2708\n",
      "10-20 14:45:33.488 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_20231020144533477279770912737766_0294_m_000003_700: Committed\n",
      "10-20 14:45:33.490 172.17.0.2:54325      7233    (TID 700)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 294.0 (TID 700). 2281 bytes result sent to driver\n",
      "10-20 14:45:33.491 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 294.0 (TID 700) in 75 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:45:33.493 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 2716\n",
      "10-20 14:45:33.495 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 2708\n",
      "10-20 14:45:33.498 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445337350277679442423129_0294_m_000001_698: Committed\n",
      "10-20 14:45:33.499 172.17.0.2:54325      7233    (TID 698)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 294.0 (TID 698). 2281 bytes result sent to driver\n",
      "10-20 14:45:33.500 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 294.0 (TID 698) in 84 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:45:33.500 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 2708\n",
      "10-20 14:45:33.502 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445337961603469533998349_0294_m_000002_699: Committed\n",
      "10-20 14:45:33.503 172.17.0.2:54325      7233    (TID 699)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 294.0 (TID 699). 2281 bytes result sent to driver\n",
      "10-20 14:45:33.503 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445337204546356324627664_0294_m_000000_697: Committed\n",
      "10-20 14:45:33.504 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 294.0 (TID 699) in 88 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:45:33.505 172.17.0.2:54325      7233    (TID 697)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 294.0 (TID 697). 2281 bytes result sent to driver\n",
      "10-20 14:45:33.506 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 294.0 (TID 697) in 90 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:45:33.506 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 294.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 294 (parquet at treeModels.scala:473) finished in 0.117 s\n",
      "10-20 14:45:33.507 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 159 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:33.507 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 294: Stage finished\n",
      "10-20 14:45:33.507 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 159 finished: parquet at treeModels.scala:473, took 0.118736 s\n",
      "10-20 14:45:33.522 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job c7a9c431-aa02-4bd4-ad6b-d041333cceca committed.\n",
      "10-20 14:45:33.523 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job c7a9c431-aa02-4bd4-ad6b-d041333cceca.\n",
      "10-20 14:45:33.603 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.605 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.605 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.649 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 22.230121 ms\n",
      "10-20 14:45:33.690 172.17.0.2:54325      7233   ad-pool-68  INFO org.apache.spark.storage.BlockManager: Removing RDD 260\n",
      "10-20 14:45:33.698 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:478\n",
      "10-20 14:45:33.698 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 160 (parquet at treeModels.scala:478) with 4 output partitions\n",
      "10-20 14:45:33.698 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 295 (parquet at treeModels.scala:478)\n",
      "10-20 14:45:33.698 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:45:33.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:45:33.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 295 (MapPartitionsRDD[739] at parquet at treeModels.scala:478), which has no missing parents\n",
      "10-20 14:45:33.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_415 stored as values in memory (estimated size 204.1 KiB, free 433.8 MiB)\n",
      "10-20 14:45:33.721 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_415_piece0 stored as bytes in memory (estimated size 68.5 KiB, free 433.7 MiB)\n",
      "10-20 14:45:33.721 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_415_piece0 in memory on 95675304fa2d:39429 (size: 68.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:45:33.722 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 415 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:45:33.722 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 295 (MapPartitionsRDD[739] at parquet at treeModels.scala:478) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:45:33.722 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 295.0 with 4 tasks resource profile 0\n",
      "10-20 14:45:33.723 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 295.0 (TID 701) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 47367 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.724 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 295.0 (TID 702) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 47926 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.725 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 295.0 (TID 703) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 46895 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.726 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 295.0 (TID 704) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 46595 bytes) taskResourceAssignments Map()\n",
      "10-20 14:45:33.727 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 295.0 (TID 702)\n",
      "10-20 14:45:33.727 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 295.0 (TID 701)\n",
      "10-20 14:45:33.727 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 295.0 (TID 703)\n",
      "10-20 14:45:33.735 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 295.0 (TID 704)\n",
      "10-20 14:45:33.750 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.750 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.754 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.756 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.757 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.758 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.761 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"nodeData\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"struct\",\n",
      "      \"fields\" : [ {\n",
      "        \"name\" : \"id\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"prediction\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurity\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurityStats\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"array\",\n",
      "          \"elementType\" : \"double\",\n",
      "          \"containsNull\" : false\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rawCount\",\n",
      "        \"type\" : \"long\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"gain\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"leftChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rightChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"split\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"struct\",\n",
      "          \"fields\" : [ {\n",
      "            \"name\" : \"featureIndex\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"leftCategoriesOrThreshold\",\n",
      "            \"type\" : {\n",
      "              \"type\" : \"array\",\n",
      "              \"elementType\" : \"double\",\n",
      "              \"containsNull\" : false\n",
      "            },\n",
      "            \"nullable\" : true,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"numCategories\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          } ]\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      } ]\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional group nodeData {\n",
      "    required int32 id;\n",
      "    required double prediction;\n",
      "    required double impurity;\n",
      "    optional group impurityStats (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "    required int64 rawCount;\n",
      "    required double gain;\n",
      "    required int32 leftChild;\n",
      "    required int32 rightChild;\n",
      "    optional group split {\n",
      "      required int32 featureIndex;\n",
      "      optional group leftCategoriesOrThreshold (LIST) {\n",
      "        repeated group list {\n",
      "          required double element;\n",
      "        }\n",
      "      }\n",
      "      required int32 numCategories;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.762 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:45:33.763 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:45:33.762 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"nodeData\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"struct\",\n",
      "      \"fields\" : [ {\n",
      "        \"name\" : \"id\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"prediction\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurity\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurityStats\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"array\",\n",
      "          \"elementType\" : \"double\",\n",
      "          \"containsNull\" : false\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rawCount\",\n",
      "        \"type\" : \"long\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"gain\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"leftChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rightChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"split\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"struct\",\n",
      "          \"fields\" : [ {\n",
      "            \"name\" : \"featureIndex\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"leftCategoriesOrThreshold\",\n",
      "            \"type\" : {\n",
      "              \"type\" : \"array\",\n",
      "              \"elementType\" : \"double\",\n",
      "              \"containsNull\" : false\n",
      "            },\n",
      "            \"nullable\" : true,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"numCategories\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          } ]\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      } ]\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional group nodeData {\n",
      "    required int32 id;\n",
      "    required double prediction;\n",
      "    required double impurity;\n",
      "    optional group impurityStats (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "    required int64 rawCount;\n",
      "    required double gain;\n",
      "    required int32 leftChild;\n",
      "    required int32 rightChild;\n",
      "    optional group split {\n",
      "      required int32 featureIndex;\n",
      "      optional group leftCategoriesOrThreshold (LIST) {\n",
      "        repeated group list {\n",
      "          required double element;\n",
      "        }\n",
      "      }\n",
      "      required int32 numCategories;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.762 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"nodeData\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"struct\",\n",
      "      \"fields\" : [ {\n",
      "        \"name\" : \"id\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"prediction\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurity\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurityStats\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"array\",\n",
      "          \"elementType\" : \"double\",\n",
      "          \"containsNull\" : false\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rawCount\",\n",
      "        \"type\" : \"long\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"gain\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"leftChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rightChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"split\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"struct\",\n",
      "          \"fields\" : [ {\n",
      "            \"name\" : \"featureIndex\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"leftCategoriesOrThreshold\",\n",
      "            \"type\" : {\n",
      "              \"type\" : \"array\",\n",
      "              \"elementType\" : \"double\",\n",
      "              \"containsNull\" : false\n",
      "            },\n",
      "            \"nullable\" : true,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"numCategories\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          } ]\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      } ]\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional group nodeData {\n",
      "    required int32 id;\n",
      "    required double prediction;\n",
      "    required double impurity;\n",
      "    optional group impurityStats (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "    required int64 rawCount;\n",
      "    required double gain;\n",
      "    required int32 leftChild;\n",
      "    required int32 rightChild;\n",
      "    optional group split {\n",
      "      required int32 featureIndex;\n",
      "      optional group leftCategoriesOrThreshold (LIST) {\n",
      "        repeated group list {\n",
      "          required double element;\n",
      "        }\n",
      "      }\n",
      "      required int32 numCategories;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.766 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"treeID\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"nodeData\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"struct\",\n",
      "      \"fields\" : [ {\n",
      "        \"name\" : \"id\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"prediction\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurity\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"impurityStats\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"array\",\n",
      "          \"elementType\" : \"double\",\n",
      "          \"containsNull\" : false\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rawCount\",\n",
      "        \"type\" : \"long\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"gain\",\n",
      "        \"type\" : \"double\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"leftChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"rightChild\",\n",
      "        \"type\" : \"integer\",\n",
      "        \"nullable\" : false,\n",
      "        \"metadata\" : { }\n",
      "      }, {\n",
      "        \"name\" : \"split\",\n",
      "        \"type\" : {\n",
      "          \"type\" : \"struct\",\n",
      "          \"fields\" : [ {\n",
      "            \"name\" : \"featureIndex\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"leftCategoriesOrThreshold\",\n",
      "            \"type\" : {\n",
      "              \"type\" : \"array\",\n",
      "              \"elementType\" : \"double\",\n",
      "              \"containsNull\" : false\n",
      "            },\n",
      "            \"nullable\" : true,\n",
      "            \"metadata\" : { }\n",
      "          }, {\n",
      "            \"name\" : \"numCategories\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"nullable\" : false,\n",
      "            \"metadata\" : { }\n",
      "          } ]\n",
      "        },\n",
      "        \"nullable\" : true,\n",
      "        \"metadata\" : { }\n",
      "      } ]\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required int32 treeID;\n",
      "  optional group nodeData {\n",
      "    required int32 id;\n",
      "    required double prediction;\n",
      "    required double impurity;\n",
      "    optional group impurityStats (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "    required int64 rawCount;\n",
      "    required double gain;\n",
      "    required int32 leftChild;\n",
      "    required int32 rightChild;\n",
      "    optional group split {\n",
      "      required int32 featureIndex;\n",
      "      optional group leftCategoriesOrThreshold (LIST) {\n",
      "        repeated group list {\n",
      "          required double element;\n",
      "        }\n",
      "      }\n",
      "      required int32 numCategories;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:45:33.841 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 32748\n",
      "10-20 14:45:33.847 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 31744\n",
      "10-20 14:45:33.848 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 31684\n",
      "10-20 14:45:33.861 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445337285281331449536566_0295_m_000001_702: Committed\n",
      "10-20 14:45:33.861 172.17.0.2:54325      7233    (TID 702)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 295.0 (TID 702). 2353 bytes result sent to driver\n",
      "10-20 14:45:33.863 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 295.0 (TID 702) in 138 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:45:33.864 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 30844\n",
      "10-20 14:45:33.869 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445337131679996906121940_0295_m_000000_701: Committed\n",
      "10-20 14:45:33.870 172.17.0.2:54325      7233    (TID 701)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 295.0 (TID 701). 2353 bytes result sent to driver\n",
      "10-20 14:45:33.871 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445333174457221672795047_0295_m_000002_703: Committed\n",
      "10-20 14:45:33.871 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 295.0 (TID 701) in 149 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:45:33.872 172.17.0.2:54325      7233    (TID 703)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 295.0 (TID 703). 2353 bytes result sent to driver\n",
      "10-20 14:45:33.873 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 295.0 (TID 703) in 149 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:45:33.874 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201445334867824756032057515_0295_m_000003_704: Committed\n",
      "10-20 14:45:33.875 172.17.0.2:54325      7233    (TID 704)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 295.0 (TID 704). 2353 bytes result sent to driver\n",
      "10-20 14:45:33.876 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 295.0 (TID 704) in 151 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:45:33.876 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 295.0, whose tasks have all completed, from pool \n",
      "10-20 14:45:33.876 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 295 (parquet at treeModels.scala:478) finished in 0.177 s\n",
      "10-20 14:45:33.876 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 160 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:45:33.876 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 295: Stage finished\n",
      "10-20 14:45:33.876 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 160 finished: parquet at treeModels.scala:478, took 0.178316 s\n",
      "10-20 14:45:33.887 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 60de414f-e637-4ce5-894b-24bfb3db3257 committed.\n",
      "10-20 14:45:33.888 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 60de414f-e637-4ce5-894b-24bfb3db3257.\n",
      "10-20 14:45:33.888 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [97697d99] training finished\n",
      "10-20 14:45:33.889 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [d92215c1] training finished\n",
      "10-20 14:45:49.697 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_415_piece0 on 95675304fa2d:39429 in memory (size: 68.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:45:49.699 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_414_piece0 on 95675304fa2d:39429 in memory (size: 60.7 KiB, free: 434.4 MiB)\n",
      "10-20 14:45:50.167 172.17.0.2:54325      7233   ad-pool-70  INFO org.apache.spark.storage.BlockManager: Removing RDD 238\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    VectorAssembler,\n",
    "    OneHotEncoder,\n",
    "    Imputer,\n",
    ")\n",
    "from pyspark.ml import (\n",
    "    Pipeline\n",
    ")\n",
    "from pyspark.ml.classification import(\n",
    "    GBTClassifier,\n",
    ")\n",
    "\n",
    "cols_to_impute = ['fnlwgt', 'age', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "cat_cols = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "imputed_cols = [f'{x}_IMPUTED' for x in cols_to_impute]\n",
    "imputer = Imputer(strategy='mean', inputCols=cols_to_impute, outputCols=imputed_cols)\n",
    "string_indexers = []\n",
    "ohe_indexers = []\n",
    "for cat_col in cat_cols:\n",
    "    si = StringIndexer(inputCol=cat_col, outputCol=f'{cat_col}_idx').setHandleInvalid('keep')\n",
    "    enc = OneHotEncoder(inputCols=[si.getOutputCol()], outputCols=[f'{cat_col}_vec'])\n",
    "    string_indexers.append(si)\n",
    "    ohe_indexers.append(enc)\n",
    "\n",
    "assembler_cols = [f'{c}_vec' for c in cat_cols] + imputed_cols\n",
    "vector_assembler = VectorAssembler(inputCols=assembler_cols, outputCol='features')\n",
    "gbt = GBTClassifier(labelCol='label', featuresCol='features')\n",
    "gbt_stages = [imputer] + string_indexers + ohe_indexers + [vector_assembler] + [gbt]\n",
    "pipeline = Pipeline().setStages(gbt_stages)\n",
    "gbt_model = pipeline.fit(train_df)\n",
    "gbt_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f90f4-dec8-4e8b-bc9a-74e72cd09149",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e775a201-b769-412a-9841-5535dba8fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:47:11.541 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_416 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:11.579 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_416_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:11.581 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_416_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:11.582 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 416 from textFile at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:47:11.667 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at PythonRDD.scala:166\n",
      "10-20 14:47:11.669 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 161 (runJob at PythonRDD.scala:166) with 1 output partitions\n",
      "10-20 14:47:11.669 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 296 (runJob at PythonRDD.scala:166)\n",
      "10-20 14:47:11.669 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:11.669 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:11.670 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 296 (PythonRDD[744] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "10-20 14:47:11.680 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_417 stored as values in memory (estimated size 6.7 KiB, free 434.0 MiB)\n",
      "10-20 14:47:11.681 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_417_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:11.681 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_417_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:11.681 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 417 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:11.682 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 296 (PythonRDD[744] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:11.682 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 296.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:11.691 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 296.0 (TID 705) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4541 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:11.693 172.17.0.2:54325      7233    (TID 705)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 296.0 (TID 705)\n",
      "10-20 14:47:11.718 172.17.0.2:54325      7233    (TID 705)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/metadata/part-00000:0+725\n",
      "10-20 14:47:11.804 172.17.0.2:54325      7233   d-pool-132  INFO org.apache.spark.storage.BlockManager: Removing RDD 172\n",
      "10-20 14:47:11.814 172.17.0.2:54325      7233   d-pool-135  INFO org.apache.spark.storage.BlockManager: Removing RDD 194\n",
      "10-20 14:47:11.818 172.17.0.2:54325      7233   d-pool-138  INFO org.apache.spark.storage.BlockManager: Removing RDD 216\n",
      "10-20 14:47:11.838 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_53_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:11.847 172.17.0.2:54325      7233   d-pool-144  INFO org.apache.spark.storage.BlockManager: Removing RDD 152\n",
      "10-20 14:47:12.204 172.17.0.2:54325      7233    (TID 705)  INFO org.apache.spark.api.python.PythonRunner: Times: total = 479, boot = 466, init = 13, finish = 0\n",
      "10-20 14:47:12.205 172.17.0.2:54325      7233    (TID 705)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 296.0 (TID 705). 2128 bytes result sent to driver\n",
      "10-20 14:47:12.206 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 296.0 (TID 705) in 523 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.206 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 296.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.api.python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 48231\n",
      "10-20 14:47:12.209 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 296 (runJob at PythonRDD.scala:166) finished in 0.537 s\n",
      "10-20 14:47:12.209 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 161 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.209 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 296: Stage finished\n",
      "10-20 14:47:12.210 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 161 finished: runJob at PythonRDD.scala:166, took 0.542755 s\n",
      "10-20 14:47:12.220 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_418 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:12.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_418_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:12.225 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_418_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 418 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.242 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 162 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.243 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 297 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.243 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.243 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.243 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 297 (outputs/income_gbt_spark/metadata MapPartitionsRDD[746] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.243 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_419 stored as values in memory (estimated size 4.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:12.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_419_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:12.244 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_419_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.245 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 419 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.245 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 297 (outputs/income_gbt_spark/metadata MapPartitionsRDD[746] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.245 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 297.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.246 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 297.0 (TID 706) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4541 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.246 172.17.0.2:54325      7233    (TID 706)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 297.0 (TID 706)\n",
      "10-20 14:47:12.248 172.17.0.2:54325      7233    (TID 706)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/metadata/part-00000:0+725\n",
      "10-20 14:47:12.249 172.17.0.2:54325      7233    (TID 706)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 297.0 (TID 706). 1653 bytes result sent to driver\n",
      "10-20 14:47:12.249 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 297.0 (TID 706) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.249 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 297.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 297 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:12.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 162 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 297: Stage finished\n",
      "10-20 14:47:12.252 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 162 finished: first at ReadWrite.scala:587, took 0.009483 s\n",
      "10-20 14:47:12.289 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_420 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:12.294 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_420_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:12.294 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_420_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.295 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 420 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.313 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 163 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 298 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 298 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[748] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.315 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_421 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:12.316 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_421_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:12.316 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_421_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.316 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 421 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 298 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[748] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.317 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 298.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.317 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 298.0 (TID 707) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4572 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.318 172.17.0.2:54325      7233    (TID 707)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 298.0 (TID 707)\n",
      "10-20 14:47:12.319 172.17.0.2:54325      7233    (TID 707)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata/part-00000:0+479\n",
      "10-20 14:47:12.320 172.17.0.2:54325      7233    (TID 707)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 298.0 (TID 707). 1407 bytes result sent to driver\n",
      "10-20 14:47:12.321 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 298.0 (TID 707) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.321 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 298.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 298 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:12.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 163 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.322 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 298: Stage finished\n",
      "10-20 14:47:12.324 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 163 finished: first at ReadWrite.scala:587, took 0.011152 s\n",
      "10-20 14:47:12.328 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_422 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:12.333 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_422_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:12.334 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_422_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.334 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 422 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.351 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 164 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 299 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 299 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[750] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.353 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_423 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:12.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_423_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:12.354 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_423_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 423 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 299 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[750] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 299.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.355 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 299.0 (TID 708) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4572 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.355 172.17.0.2:54325      7233    (TID 708)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 299.0 (TID 708)\n",
      "10-20 14:47:12.356 172.17.0.2:54325      7233    (TID 708)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata/part-00000:0+479\n",
      "10-20 14:47:12.358 172.17.0.2:54325      7233    (TID 708)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 299.0 (TID 708). 1364 bytes result sent to driver\n",
      "10-20 14:47:12.358 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 299.0 (TID 708) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.358 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 299.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.359 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 299 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:12.359 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 164 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.359 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 299: Stage finished\n",
      "10-20 14:47:12.359 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 164 finished: first at ReadWrite.scala:587, took 0.007667 s\n",
      "10-20 14:47:12.367 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:12.396 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at Imputer.scala:320\n",
      "10-20 14:47:12.396 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 165 (parquet at Imputer.scala:320) with 1 output partitions\n",
      "10-20 14:47:12.396 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 300 (parquet at Imputer.scala:320)\n",
      "10-20 14:47:12.396 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.397 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.397 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 300 (MapPartitionsRDD[752] at parquet at Imputer.scala:320), which has no missing parents\n",
      "10-20 14:47:12.402 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_424 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.402 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_424_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.403 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_424_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 424 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 300 (MapPartitionsRDD[752] at parquet at Imputer.scala:320) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 300.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.404 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 300.0 (TID 709) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4732 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.404 172.17.0.2:54325      7233    (TID 709)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 300.0 (TID 709)\n",
      "10-20 14:47:12.443 172.17.0.2:54325      7233    (TID 709)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 300.0 (TID 709). 1774 bytes result sent to driver\n",
      "10-20 14:47:12.444 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 300.0 (TID 709) in 40 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.444 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 300.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.444 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 300 (parquet at Imputer.scala:320) finished in 0.047 s\n",
      "10-20 14:47:12.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 165 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 300: Stage finished\n",
      "10-20 14:47:12.445 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 165 finished: parquet at Imputer.scala:320, took 0.048993 s\n",
      "10-20 14:47:12.455 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_425 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.468 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_422_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_425_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.471 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_425_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 425 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.491 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_417_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.506 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 166 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 301 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 301 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[754] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.507 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_426 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.507 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_426_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.508 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_426_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 426 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 301 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[754] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 301.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.509 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 301.0 (TID 710) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.509 172.17.0.2:54325      7233    (TID 710)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 301.0 (TID 710)\n",
      "10-20 14:47:12.510 172.17.0.2:54325      7233    (TID 710)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata/part-00000:0+357\n",
      "10-20 14:47:12.512 172.17.0.2:54325      7233    (TID 710)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 301.0 (TID 710). 1285 bytes result sent to driver\n",
      "10-20 14:47:12.512 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 301.0 (TID 710) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.512 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 301.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 301 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:12.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 166 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 301: Stage finished\n",
      "10-20 14:47:12.514 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 166 finished: first at ReadWrite.scala:587, took 0.008317 s\n",
      "10-20 14:47:12.517 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_427 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.519 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_423_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.522 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_427_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.522 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_427_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:12.522 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 427 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.524 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_424_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.526 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_419_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.529 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_418_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.533 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_420_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.536 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_421_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.539 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.539 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 167 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.539 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 302 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.539 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.539 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 302 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[756] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.540 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_428 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:12.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_428_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:12.541 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_428_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 428 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 302 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[756] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 302.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.542 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 302.0 (TID 711) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.542 172.17.0.2:54325      7233    (TID 711)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 302.0 (TID 711)\n",
      "10-20 14:47:12.544 172.17.0.2:54325      7233    (TID 711)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata/part-00000:0+357\n",
      "10-20 14:47:12.545 172.17.0.2:54325      7233    (TID 711)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 302.0 (TID 711). 1242 bytes result sent to driver\n",
      "10-20 14:47:12.545 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 302.0 (TID 711) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.545 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 302.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 302 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:12.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 167 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 302: Stage finished\n",
      "10-20 14:47:12.546 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 167 finished: first at ReadWrite.scala:587, took 0.006448 s\n",
      "10-20 14:47:12.552 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:12.569 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:12.569 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 168 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:12.569 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 303 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:12.569 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.569 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.569 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 303 (MapPartitionsRDD[758] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:12.573 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_429 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:12.574 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_429_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:12.575 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_429_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.575 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 429 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 303 (MapPartitionsRDD[758] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.576 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 303.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.577 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 303.0 (TID 712) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.578 172.17.0.2:54325      7233    (TID 712)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 303.0 (TID 712)\n",
      "10-20 14:47:12.586 172.17.0.2:54325      7233    (TID 712)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 303.0 (TID 712). 1709 bytes result sent to driver\n",
      "10-20 14:47:12.587 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 303.0 (TID 712) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.587 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 303.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.587 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 303 (parquet at StringIndexer.scala:523) finished in 0.017 s\n",
      "10-20 14:47:12.587 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 168 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.587 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 303: Stage finished\n",
      "10-20 14:47:12.587 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 168 finished: parquet at StringIndexer.scala:523, took 0.018467 s\n",
      "10-20 14:47:12.603 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:12.604 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:12.604 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:12.609 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_430 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.615 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_430_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.616 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_430_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.616 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 430 from head at StringIndexer.scala:524\n",
      "10-20 14:47:12.619 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:12.625 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:12.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 169 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:12.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 304 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:12.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[761] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:12.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_431 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_431_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.653 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_431_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 431 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 304 (MapPartitionsRDD[761] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 304.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.655 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 304.0 (TID 713) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.656 172.17.0.2:54325      7233    (TID 713)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 304.0 (TID 713)\n",
      "10-20 14:47:12.671 172.17.0.2:54325      7233    (TID 713)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/data/part-00000-312667f8-74ef-4c63-9330-da0e1d70ebe1-c000.snappy.parquet, range: 0-750, partition values: [empty row]\n",
      "10-20 14:47:12.735 172.17.0.2:54325      7233    (TID 713)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:12.736 172.17.0.2:54325      7233    (TID 713)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:12.741 172.17.0.2:54325      7233    (TID 713)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 5 ms. row count = 1\n",
      "10-20 14:47:12.758 172.17.0.2:54325      7233    (TID 713)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 304.0 (TID 713). 1804 bytes result sent to driver\n",
      "10-20 14:47:12.759 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 304.0 (TID 713) in 104 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.759 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 304 (head at StringIndexer.scala:524) finished in 0.134 s\n",
      "10-20 14:47:12.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 169 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished\n",
      "10-20 14:47:12.759 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 169 finished: head at StringIndexer.scala:524, took 0.134576 s\n",
      "10-20 14:47:12.775 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 13.376022 ms\n",
      "10-20 14:47:12.778 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_432 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.782 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_432_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.782 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_432_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:12.783 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 432 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.799 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 170 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 305 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 305 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[763] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_433 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_433_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.801 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_433_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:12.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 433 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.802 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 305 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[763] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.802 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 305.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.802 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 305.0 (TID 714) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.802 172.17.0.2:54325      7233    (TID 714)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 305.0 (TID 714)\n",
      "10-20 14:47:12.804 172.17.0.2:54325      7233    (TID 714)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata/part-00000:0+357\n",
      "10-20 14:47:12.805 172.17.0.2:54325      7233    (TID 714)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 305.0 (TID 714). 1242 bytes result sent to driver\n",
      "10-20 14:47:12.805 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 305.0 (TID 714) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.805 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 305 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:12.806 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 170 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.806 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 305: Stage finished\n",
      "10-20 14:47:12.806 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 170 finished: first at ReadWrite.scala:587, took 0.007236 s\n",
      "10-20 14:47:12.807 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_434 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:12.823 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_432_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.826 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_434_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.826 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_434_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:12.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 434 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.836 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_427_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.839 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_426_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.844 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_428_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.844 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 171 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 306 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 306 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[765] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.845 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_435 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.846 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_435_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.846 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_435_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 435 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 306 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[765] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.847 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 306.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.848 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 306.0 (TID 715) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.848 172.17.0.2:54325      7233    (TID 715)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 306.0 (TID 715)\n",
      "10-20 14:47:12.849 172.17.0.2:54325      7233    (TID 715)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata/part-00000:0+357\n",
      "10-20 14:47:12.851 172.17.0.2:54325      7233    (TID 715)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 306.0 (TID 715). 1285 bytes result sent to driver\n",
      "10-20 14:47:12.851 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 306.0 (TID 715) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.851 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 306 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:12.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 171 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 306: Stage finished\n",
      "10-20 14:47:12.852 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 171 finished: first at ReadWrite.scala:587, took 0.007999 s\n",
      "10-20 14:47:12.858 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_431_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.859 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:12.867 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_429_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.870 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_433_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.879 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:12.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 172 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:12.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 307 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:12.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.880 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[767] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:12.884 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_436 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.885 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_436_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.885 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_425_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.886 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_436_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.886 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 436 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 307 (MapPartitionsRDD[767] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 307.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.888 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 307.0 (TID 716) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.888 172.17.0.2:54325      7233    (TID 716)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 307.0 (TID 716)\n",
      "10-20 14:47:12.897 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_430_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.906 172.17.0.2:54325      7233    (TID 716)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 307.0 (TID 716). 1709 bytes result sent to driver\n",
      "10-20 14:47:12.908 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 307.0 (TID 716) in 20 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.908 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 307 (parquet at StringIndexer.scala:523) finished in 0.028 s\n",
      "10-20 14:47:12.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 172 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.908 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 307: Stage finished\n",
      "10-20 14:47:12.909 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 172 finished: parquet at StringIndexer.scala:523, took 0.030010 s\n",
      "10-20 14:47:12.916 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:12.916 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:12.916 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:12.921 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_437 stored as values in memory (estimated size 177.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:12.925 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_437_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.7 MiB)\n",
      "10-20 14:47:12.926 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_437_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.926 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 437 from head at StringIndexer.scala:524\n",
      "10-20 14:47:12.927 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:12.930 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:12.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 173 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:12.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 308 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:12.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.930 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 308 (MapPartitionsRDD[770] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:12.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_438 stored as values in memory (estimated size 8.9 KiB, free 433.7 MiB)\n",
      "10-20 14:47:12.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_438_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.7 MiB)\n",
      "10-20 14:47:12.933 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_438_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.934 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 438 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.934 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 308 (MapPartitionsRDD[770] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.934 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 308.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.935 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 308.0 (TID 717) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.935 172.17.0.2:54325      7233    (TID 717)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 308.0 (TID 717)\n",
      "10-20 14:47:12.937 172.17.0.2:54325      7233    (TID 717)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/data/part-00000-d3728cbd-b627-4118-bc76-8c4f3fd84feb-c000.snappy.parquet, range: 0-813, partition values: [empty row]\n",
      "10-20 14:47:12.940 172.17.0.2:54325      7233    (TID 717)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:12.940 172.17.0.2:54325      7233    (TID 717)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:12.941 172.17.0.2:54325      7233    (TID 717)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:12.942 172.17.0.2:54325      7233    (TID 717)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 308.0 (TID 717). 1888 bytes result sent to driver\n",
      "10-20 14:47:12.942 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 308.0 (TID 717) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.942 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 308 (head at StringIndexer.scala:524) finished in 0.011 s\n",
      "10-20 14:47:12.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 173 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 308: Stage finished\n",
      "10-20 14:47:12.943 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 173 finished: head at StringIndexer.scala:524, took 0.012691 s\n",
      "10-20 14:47:12.947 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_439 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.951 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_439_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.951 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_439_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.952 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 439 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:12.967 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:12.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 174 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:12.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 309 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:12.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:12.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:12.968 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 309 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[772] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:12.969 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_440 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.969 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_440_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:12.970 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_440_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:12.970 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 440 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:12.970 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 309 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[772] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:12.970 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 309.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:12.970 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 309.0 (TID 718) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:12.971 172.17.0.2:54325      7233    (TID 718)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 309.0 (TID 718)\n",
      "10-20 14:47:12.972 172.17.0.2:54325      7233    (TID 718)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata/part-00000:0+367\n",
      "10-20 14:47:12.974 172.17.0.2:54325      7233    (TID 718)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 309.0 (TID 718). 1295 bytes result sent to driver\n",
      "10-20 14:47:12.974 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 309.0 (TID 718) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:12.974 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:12.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 309 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:12.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 174 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:12.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 309: Stage finished\n",
      "10-20 14:47:12.975 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 174 finished: first at ReadWrite.scala:587, took 0.007829 s\n",
      "10-20 14:47:12.976 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_441 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.981 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_441_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:12.981 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_441_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:12.981 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 441 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.019 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 175 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 310 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 310 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[774] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.021 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_442 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_442_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.022 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_442_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 442 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 310 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[774] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 310.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.023 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 310.0 (TID 719) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.024 172.17.0.2:54325      7233    (TID 719)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 310.0 (TID 719)\n",
      "10-20 14:47:13.025 172.17.0.2:54325      7233    (TID 719)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata/part-00000:0+367\n",
      "10-20 14:47:13.026 172.17.0.2:54325      7233    (TID 719)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 310.0 (TID 719). 1295 bytes result sent to driver\n",
      "10-20 14:47:13.027 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 310.0 (TID 719) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.027 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 310.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.027 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 310 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:13.027 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 175 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.027 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 310: Stage finished\n",
      "10-20 14:47:13.027 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 175 finished: first at ReadWrite.scala:587, took 0.008670 s\n",
      "10-20 14:47:13.037 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:13.056 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:13.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 176 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:13.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 311 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:13.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 311 (MapPartitionsRDD[776] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:13.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_443 stored as values in memory (estimated size 84.5 KiB, free 433.2 MiB)\n",
      "10-20 14:47:13.062 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_443_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.062 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_443_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.062 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 443 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.063 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 311 (MapPartitionsRDD[776] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.063 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 311.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.064 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 311.0 (TID 720) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.064 172.17.0.2:54325      7233    (TID 720)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 311.0 (TID 720)\n",
      "10-20 14:47:13.072 172.17.0.2:54325      7233    (TID 720)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 311.0 (TID 720). 1709 bytes result sent to driver\n",
      "10-20 14:47:13.073 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 311.0 (TID 720) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.073 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 311.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 311 (parquet at StringIndexer.scala:523) finished in 0.017 s\n",
      "10-20 14:47:13.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 176 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 311: Stage finished\n",
      "10-20 14:47:13.074 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 176 finished: parquet at StringIndexer.scala:523, took 0.018707 s\n",
      "10-20 14:47:13.085 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:13.085 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:13.086 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:13.094 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_444 stored as values in memory (estimated size 177.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:13.099 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_444_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.100 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_444_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.100 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 444 from head at StringIndexer.scala:524\n",
      "10-20 14:47:13.100 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:13.105 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:13.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 177 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:13.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 312 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:13.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.105 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 312 (MapPartitionsRDD[779] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:13.109 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_445 stored as values in memory (estimated size 8.9 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_445_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.110 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_445_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 445 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 312 (MapPartitionsRDD[779] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.110 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 312.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.111 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 312.0 (TID 721) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.111 172.17.0.2:54325      7233    (TID 721)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 312.0 (TID 721)\n",
      "10-20 14:47:13.113 172.17.0.2:54325      7233    (TID 721)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/data/part-00000-b3761344-b391-40fd-946a-f95f69844a3d-c000.snappy.parquet, range: 0-743, partition values: [empty row]\n",
      "10-20 14:47:13.117 172.17.0.2:54325      7233    (TID 721)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:13.118 172.17.0.2:54325      7233    (TID 721)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:13.118 172.17.0.2:54325      7233    (TID 721)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:13.120 172.17.0.2:54325      7233    (TID 721)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 312.0 (TID 721). 1786 bytes result sent to driver\n",
      "10-20 14:47:13.120 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 312.0 (TID 721) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.120 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 312.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.120 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 312 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:47:13.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 177 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.121 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 312: Stage finished\n",
      "10-20 14:47:13.121 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 177 finished: head at StringIndexer.scala:524, took 0.016483 s\n",
      "10-20 14:47:13.125 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_446 stored as values in memory (estimated size 176.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:13.132 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_446_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.133 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_446_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.133 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 446 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.155 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 178 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 313 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 313 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[781] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_447 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_447_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.171 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_447_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 447 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 313 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[781] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 313.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.173 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 313.0 (TID 722) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.173 172.17.0.2:54325      7233    (TID 722)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 313.0 (TID 722)\n",
      "10-20 14:47:13.175 172.17.0.2:54325      7233    (TID 722)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata/part-00000:0+359\n",
      "10-20 14:47:13.177 172.17.0.2:54325      7233    (TID 722)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 313.0 (TID 722). 1287 bytes result sent to driver\n",
      "10-20 14:47:13.178 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 313.0 (TID 722) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.178 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 313.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 313 (first at ReadWrite.scala:587) finished in 0.022 s\n",
      "10-20 14:47:13.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 178 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.179 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_437_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.179 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 313: Stage finished\n",
      "10-20 14:47:13.180 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 178 finished: first at ReadWrite.scala:587, took 0.025782 s\n",
      "10-20 14:47:13.183 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_448 stored as values in memory (estimated size 176.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:13.189 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_436_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.190 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_448_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:13.191 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_448_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.192 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 448 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.197 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_442_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.199 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_438_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.204 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_445_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.213 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_439_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.214 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 179 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 314 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 314 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[783] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_449 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_449_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.216 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_449_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 449 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 314 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[783] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 314.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.217 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 314.0 (TID 723) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.217 172.17.0.2:54325      7233    (TID 723)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 314.0 (TID 723)\n",
      "10-20 14:47:13.218 172.17.0.2:54325      7233    (TID 723)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata/part-00000:0+359\n",
      "10-20 14:47:13.219 172.17.0.2:54325      7233    (TID 723)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 314.0 (TID 723). 1244 bytes result sent to driver\n",
      "10-20 14:47:13.220 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 314.0 (TID 723) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.220 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 314.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 314 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:13.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 179 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 314: Stage finished\n",
      "10-20 14:47:13.221 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 179 finished: first at ReadWrite.scala:587, took 0.006413 s\n",
      "10-20 14:47:13.235 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:13.241 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_444_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.250 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_440_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.252 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_443_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.265 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:13.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 180 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:13.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 315 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:13.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.266 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.266 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 315 (MapPartitionsRDD[785] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:13.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_450 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_450_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.273 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_450_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 450 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.274 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 315 (MapPartitionsRDD[785] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.274 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 315.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.274 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 315.0 (TID 724) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.275 172.17.0.2:54325      7233    (TID 724)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 315.0 (TID 724)\n",
      "10-20 14:47:13.281 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_435_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.287 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_441_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.289 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_434_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.290 172.17.0.2:54325      7233    (TID 724)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 315.0 (TID 724). 1709 bytes result sent to driver\n",
      "10-20 14:47:13.290 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 315.0 (TID 724) in 16 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.290 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 315.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.291 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 315 (parquet at StringIndexer.scala:523) finished in 0.024 s\n",
      "10-20 14:47:13.291 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 180 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.291 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 315: Stage finished\n",
      "10-20 14:47:13.291 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 180 finished: parquet at StringIndexer.scala:523, took 0.026264 s\n",
      "10-20 14:47:13.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:13.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:13.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:13.310 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_451 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:13.314 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_451_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:13.314 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_451_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.315 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 451 from head at StringIndexer.scala:524\n",
      "10-20 14:47:13.315 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:13.319 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:13.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 181 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:13.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 316 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:13.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 316 (MapPartitionsRDD[788] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:13.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_452 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:13.322 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_452_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:13.322 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_452_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.322 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 452 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.323 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 316 (MapPartitionsRDD[788] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.323 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 316.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.323 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 316.0 (TID 725) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.323 172.17.0.2:54325      7233    (TID 725)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 316.0 (TID 725)\n",
      "10-20 14:47:13.326 172.17.0.2:54325      7233    (TID 725)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/data/part-00000-be55257c-30ef-4e25-9b6e-6999c6391b1c-c000.snappy.parquet, range: 0-873, partition values: [empty row]\n",
      "10-20 14:47:13.330 172.17.0.2:54325      7233    (TID 725)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:13.331 172.17.0.2:54325      7233    (TID 725)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:13.332 172.17.0.2:54325      7233    (TID 725)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:13.333 172.17.0.2:54325      7233    (TID 725)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 316.0 (TID 725). 1969 bytes result sent to driver\n",
      "10-20 14:47:13.334 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 316.0 (TID 725) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.334 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 316.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 316 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:47:13.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 181 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.334 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 316: Stage finished\n",
      "10-20 14:47:13.335 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 181 finished: head at StringIndexer.scala:524, took 0.015319 s\n",
      "10-20 14:47:13.339 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_453 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.346 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_453_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.346 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_453_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.346 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 453 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.366 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 182 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 317 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 317 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[790] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.367 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_454 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_454_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.368 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_454_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.368 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 454 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 317 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[790] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 317.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.369 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 317.0 (TID 726) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.370 172.17.0.2:54325      7233    (TID 726)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 317.0 (TID 726)\n",
      "10-20 14:47:13.371 172.17.0.2:54325      7233    (TID 726)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata/part-00000:0+363\n",
      "10-20 14:47:13.372 172.17.0.2:54325      7233    (TID 726)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 317.0 (TID 726). 1248 bytes result sent to driver\n",
      "10-20 14:47:13.372 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 317.0 (TID 726) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.373 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 317.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 317 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:13.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 182 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 317: Stage finished\n",
      "10-20 14:47:13.374 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 182 finished: first at ReadWrite.scala:587, took 0.007125 s\n",
      "10-20 14:47:13.375 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_455 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.405 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_455_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.406 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_455_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.407 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 455 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.426 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 183 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 318 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.427 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 318 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[792] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.427 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_456 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_456_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.428 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_456_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 456 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.429 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 318 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[792] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.429 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 318.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.429 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 318.0 (TID 727) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.429 172.17.0.2:54325      7233    (TID 727)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 318.0 (TID 727)\n",
      "10-20 14:47:13.431 172.17.0.2:54325      7233    (TID 727)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata/part-00000:0+363\n",
      "10-20 14:47:13.432 172.17.0.2:54325      7233    (TID 727)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 318.0 (TID 727). 1248 bytes result sent to driver\n",
      "10-20 14:47:13.433 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 318.0 (TID 727) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.433 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 318.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 318 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:13.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 183 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 318: Stage finished\n",
      "10-20 14:47:13.433 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 183 finished: first at ReadWrite.scala:587, took 0.007355 s\n",
      "10-20 14:47:13.440 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:13.465 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:13.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 184 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:13.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 319 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:13.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 319 (MapPartitionsRDD[794] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:13.470 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_457 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:13.471 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_457_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.471 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_457_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.471 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 457 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.472 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 319 (MapPartitionsRDD[794] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.472 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 319.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.475 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 319.0 (TID 728) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.476 172.17.0.2:54325      7233    (TID 728)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 319.0 (TID 728)\n",
      "10-20 14:47:13.483 172.17.0.2:54325      7233    (TID 728)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 319.0 (TID 728). 1709 bytes result sent to driver\n",
      "10-20 14:47:13.484 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 319.0 (TID 728) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.484 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 319.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.484 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 319 (parquet at StringIndexer.scala:523) finished in 0.018 s\n",
      "10-20 14:47:13.484 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 184 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.484 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 319: Stage finished\n",
      "10-20 14:47:13.484 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 184 finished: parquet at StringIndexer.scala:523, took 0.019045 s\n",
      "10-20 14:47:13.492 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:13.492 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:13.492 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:13.497 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_458 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:13.502 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_458_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.503 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_458_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.503 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 458 from head at StringIndexer.scala:524\n",
      "10-20 14:47:13.504 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:13.508 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:13.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 185 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:13.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 320 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:13.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.508 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.509 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 320 (MapPartitionsRDD[797] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:13.512 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_459 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.512 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_459_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.513 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_459_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 459 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 320 (MapPartitionsRDD[797] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.513 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 320.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.514 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 320.0 (TID 729) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.515 172.17.0.2:54325      7233    (TID 729)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 320.0 (TID 729)\n",
      "10-20 14:47:13.518 172.17.0.2:54325      7233    (TID 729)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/data/part-00000-f5acbe82-b313-45fe-b7c1-42a0b5e492bd-c000.snappy.parquet, range: 0-712, partition values: [empty row]\n",
      "10-20 14:47:13.522 172.17.0.2:54325      7233    (TID 729)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:13.523 172.17.0.2:54325      7233    (TID 729)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:13.523 172.17.0.2:54325      7233    (TID 729)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:13.524 172.17.0.2:54325      7233    (TID 729)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 320.0 (TID 729). 1758 bytes result sent to driver\n",
      "10-20 14:47:13.525 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 320.0 (TID 729) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.525 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 320.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.526 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 320 (head at StringIndexer.scala:524) finished in 0.016 s\n",
      "10-20 14:47:13.526 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 185 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.527 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 320: Stage finished\n",
      "10-20 14:47:13.527 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 185 finished: head at StringIndexer.scala:524, took 0.018632 s\n",
      "10-20 14:47:13.529 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_460 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:13.542 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_459_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.543 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_446_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.545 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_460_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.546 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_460_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.546 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 460 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.551 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_454_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.553 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_450_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.554 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_451_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.559 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_455_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.560 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_457_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.562 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_447_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.566 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_452_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.567 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_453_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.569 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_449_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.571 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_456_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.579 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.580 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 186 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.580 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 321 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.580 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.580 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.581 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 321 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[799] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.582 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_461 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.582 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_461_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.583 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_461_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.583 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 461 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.583 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 321 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[799] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.583 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 321.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.584 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 321.0 (TID 730) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.584 172.17.0.2:54325      7233    (TID 730)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 321.0 (TID 730)\n",
      "10-20 14:47:13.586 172.17.0.2:54325      7233    (TID 730)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata/part-00000:0+347\n",
      "10-20 14:47:13.587 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_448_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.588 172.17.0.2:54325      7233    (TID 730)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 321.0 (TID 730). 1275 bytes result sent to driver\n",
      "10-20 14:47:13.589 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 321.0 (TID 730) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.589 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 321.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.589 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 321 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:13.589 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 186 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.589 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 321: Stage finished\n",
      "10-20 14:47:13.590 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 186 finished: first at ReadWrite.scala:587, took 0.010308 s\n",
      "10-20 14:47:13.592 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_462 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.601 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_462_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.601 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_462_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.602 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 462 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.623 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 187 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 322 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.624 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 322 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[801] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_463 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_463_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.625 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_463_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 463 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 322 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[801] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.626 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 322.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.627 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 322.0 (TID 731) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.627 172.17.0.2:54325      7233    (TID 731)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 322.0 (TID 731)\n",
      "10-20 14:47:13.630 172.17.0.2:54325      7233    (TID 731)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata/part-00000:0+347\n",
      "10-20 14:47:13.632 172.17.0.2:54325      7233    (TID 731)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 322.0 (TID 731). 1275 bytes result sent to driver\n",
      "10-20 14:47:13.632 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 322.0 (TID 731) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.632 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 322.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 322 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:13.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 187 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.633 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 322: Stage finished\n",
      "10-20 14:47:13.633 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 187 finished: first at ReadWrite.scala:587, took 0.009869 s\n",
      "10-20 14:47:13.640 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:13.661 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:13.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 188 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:13.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 323 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:13.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.661 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 323 (MapPartitionsRDD[803] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:13.666 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_464 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:13.667 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_464_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:13.668 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_464_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 464 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.668 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 323 (MapPartitionsRDD[803] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.669 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 323.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.669 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 323.0 (TID 732) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.670 172.17.0.2:54325      7233    (TID 732)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 323.0 (TID 732)\n",
      "10-20 14:47:13.676 172.17.0.2:54325      7233    (TID 732)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 323.0 (TID 732). 1709 bytes result sent to driver\n",
      "10-20 14:47:13.677 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 323.0 (TID 732) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.677 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 323.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.678 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 323 (parquet at StringIndexer.scala:523) finished in 0.016 s\n",
      "10-20 14:47:13.678 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 188 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.678 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 323: Stage finished\n",
      "10-20 14:47:13.678 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 188 finished: parquet at StringIndexer.scala:523, took 0.017393 s\n",
      "10-20 14:47:13.686 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:13.686 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:13.686 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:13.692 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_465 stored as values in memory (estimated size 177.5 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.699 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_465_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.700 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_465_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.701 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 465 from head at StringIndexer.scala:524\n",
      "10-20 14:47:13.701 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:13.705 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:13.706 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 189 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:13.706 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 324 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:13.706 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.706 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.707 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 324 (MapPartitionsRDD[806] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:13.709 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_466 stored as values in memory (estimated size 8.9 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.710 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_466_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:47:13.710 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_466_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 466 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 324 (MapPartitionsRDD[806] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.712 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 324.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.713 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 324.0 (TID 733) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.714 172.17.0.2:54325      7233    (TID 733)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 324.0 (TID 733)\n",
      "10-20 14:47:13.716 172.17.0.2:54325      7233    (TID 733)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/data/part-00000-76b01275-3eb3-43f1-9a99-203ad286956c-c000.snappy.parquet, range: 0-725, partition values: [empty row]\n",
      "10-20 14:47:13.719 172.17.0.2:54325      7233    (TID 733)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:13.720 172.17.0.2:54325      7233    (TID 733)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:13.721 172.17.0.2:54325      7233    (TID 733)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:13.723 172.17.0.2:54325      7233    (TID 733)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 324.0 (TID 733). 1735 bytes result sent to driver\n",
      "10-20 14:47:13.723 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 324.0 (TID 733) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.723 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 324.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.723 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 324 (head at StringIndexer.scala:524) finished in 0.016 s\n",
      "10-20 14:47:13.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 189 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 324: Stage finished\n",
      "10-20 14:47:13.724 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 189 finished: head at StringIndexer.scala:524, took 0.018546 s\n",
      "10-20 14:47:13.728 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_467 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.765 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_467_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.765 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_467_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.765 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 467 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.787 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 190 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 325 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 325 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[808] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.789 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_468 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.790 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_468_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:13.790 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_468_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.791 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 468 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.791 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 325 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[808] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.791 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 325.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.791 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 325.0 (TID 734) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.792 172.17.0.2:54325      7233    (TID 734)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 325.0 (TID 734)\n",
      "10-20 14:47:13.793 172.17.0.2:54325      7233    (TID 734)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata/part-00000:0+345\n",
      "10-20 14:47:13.794 172.17.0.2:54325      7233    (TID 734)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 325.0 (TID 734). 1230 bytes result sent to driver\n",
      "10-20 14:47:13.795 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 325.0 (TID 734) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.795 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 325.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 325 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:13.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 190 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 325: Stage finished\n",
      "10-20 14:47:13.795 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 190 finished: first at ReadWrite.scala:587, took 0.007920 s\n",
      "10-20 14:47:13.797 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_469 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.801 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_469_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.801 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_469_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.802 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 469 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.817 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 191 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 326 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 326 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[810] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.819 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_470 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.820 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_470_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.820 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_470_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.820 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 470 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.820 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 326 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[810] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.820 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 326.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.821 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 326.0 (TID 735) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.825 172.17.0.2:54325      7233    (TID 735)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 326.0 (TID 735)\n",
      "10-20 14:47:13.826 172.17.0.2:54325      7233    (TID 735)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata/part-00000:0+345\n",
      "10-20 14:47:13.827 172.17.0.2:54325      7233    (TID 735)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 326.0 (TID 735). 1187 bytes result sent to driver\n",
      "10-20 14:47:13.827 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 326.0 (TID 735) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.827 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 326.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 326 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:13.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 191 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 326: Stage finished\n",
      "10-20 14:47:13.833 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 191 finished: first at ReadWrite.scala:587, took 0.016065 s\n",
      "10-20 14:47:13.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:13.856 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:13.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 192 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:13.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 327 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:13.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 327 (MapPartitionsRDD[812] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:13.861 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_471 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:13.862 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_471_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:47:13.862 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_471_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:13.862 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 471 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 327 (MapPartitionsRDD[812] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 327.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.863 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 327.0 (TID 736) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.864 172.17.0.2:54325      7233    (TID 736)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 327.0 (TID 736)\n",
      "10-20 14:47:13.873 172.17.0.2:54325      7233    (TID 736)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 327.0 (TID 736). 1709 bytes result sent to driver\n",
      "10-20 14:47:13.875 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 327.0 (TID 736) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.875 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 327.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.875 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 327 (parquet at StringIndexer.scala:523) finished in 0.018 s\n",
      "10-20 14:47:13.876 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 192 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.876 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 327: Stage finished\n",
      "10-20 14:47:13.876 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 192 finished: parquet at StringIndexer.scala:523, took 0.020042 s\n",
      "10-20 14:47:13.884 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:13.884 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:13.884 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:13.889 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_472 stored as values in memory (estimated size 177.5 KiB, free 432.6 MiB)\n",
      "10-20 14:47:13.903 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_465_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.904 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_470_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.906 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_467_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_472_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.9 MiB)\n",
      "10-20 14:47:13.907 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_472_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.908 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_464_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.909 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 472 from head at StringIndexer.scala:524\n",
      "10-20 14:47:13.909 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:13.910 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_471_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.911 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_466_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:13.913 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_462_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.915 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_468_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.916 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_469_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.916 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:13.917 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_458_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.917 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 193 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:13.917 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 328 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:13.917 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.917 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.918 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 328 (MapPartitionsRDD[815] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:13.920 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_473 stored as values in memory (estimated size 8.9 KiB, free 433.8 MiB)\n",
      "10-20 14:47:13.920 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_461_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_473_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.8 MiB)\n",
      "10-20 14:47:13.921 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_473_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 473 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 328 (MapPartitionsRDD[815] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 328.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.923 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 328.0 (TID 737) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.923 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_463_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.923 172.17.0.2:54325      7233    (TID 737)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 328.0 (TID 737)\n",
      "10-20 14:47:13.925 172.17.0.2:54325      7233    (TID 737)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/data/part-00000-9a6ab6f3-10b1-4191-8775-7785c9296706-c000.snappy.parquet, range: 0-648, partition values: [empty row]\n",
      "10-20 14:47:13.928 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_460_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.929 172.17.0.2:54325      7233    (TID 737)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:13.930 172.17.0.2:54325      7233    (TID 737)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:13.930 172.17.0.2:54325      7233    (TID 737)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:13.931 172.17.0.2:54325      7233    (TID 737)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 328.0 (TID 737). 1670 bytes result sent to driver\n",
      "10-20 14:47:13.932 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 328.0 (TID 737) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.932 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 328.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 328 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:47:13.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 193 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.932 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 328: Stage finished\n",
      "10-20 14:47:13.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 193 finished: head at StringIndexer.scala:524, took 0.015862 s\n",
      "10-20 14:47:13.937 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_474 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:13.941 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_474_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:13.941 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_474_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.942 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 474 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.958 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 194 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 329 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 329 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[817] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_475 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:13.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_475_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:13.960 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_475_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 475 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 329 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[817] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 329.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.961 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 329.0 (TID 738) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.961 172.17.0.2:54325      7233    (TID 738)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 329.0 (TID 738)\n",
      "10-20 14:47:13.962 172.17.0.2:54325      7233    (TID 738)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata/part-00000:0+367\n",
      "10-20 14:47:13.963 172.17.0.2:54325      7233    (TID 738)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 329.0 (TID 738). 1252 bytes result sent to driver\n",
      "10-20 14:47:13.964 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 329.0 (TID 738) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.964 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 329.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 329 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:13.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 194 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.964 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 329: Stage finished\n",
      "10-20 14:47:13.964 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 194 finished: first at ReadWrite.scala:587, took 0.006315 s\n",
      "10-20 14:47:13.966 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_476 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.970 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_476_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.970 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_476_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.970 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 476 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:13.985 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:13.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 195 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:13.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 330 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:13.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:13.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:13.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 330 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[819] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:13.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_477 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_477_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:13.987 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_477_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:13.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 477 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:13.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 330 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[819] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:13.987 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 330.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:13.988 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 330.0 (TID 739) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:13.988 172.17.0.2:54325      7233    (TID 739)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 330.0 (TID 739)\n",
      "10-20 14:47:13.989 172.17.0.2:54325      7233    (TID 739)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata/part-00000:0+367\n",
      "10-20 14:47:13.990 172.17.0.2:54325      7233    (TID 739)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 330.0 (TID 739). 1209 bytes result sent to driver\n",
      "10-20 14:47:13.991 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 330.0 (TID 739) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:13.991 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 330.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:13.991 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 330 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:13.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 195 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:13.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 330: Stage finished\n",
      "10-20 14:47:13.993 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 195 finished: first at ReadWrite.scala:587, took 0.007012 s\n",
      "10-20 14:47:14.000 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:14.017 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:14.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 196 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:14.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 331 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:14.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 331 (MapPartitionsRDD[821] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:14.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_478 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_478_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.024 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_478_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 478 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 331 (MapPartitionsRDD[821] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 331.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.025 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 331.0 (TID 740) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.025 172.17.0.2:54325      7233    (TID 740)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 331.0 (TID 740)\n",
      "10-20 14:47:14.031 172.17.0.2:54325      7233    (TID 740)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 331.0 (TID 740). 1709 bytes result sent to driver\n",
      "10-20 14:47:14.032 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 331.0 (TID 740) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.032 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 331.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.032 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 331 (parquet at StringIndexer.scala:523) finished in 0.014 s\n",
      "10-20 14:47:14.033 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 196 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.033 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 331: Stage finished\n",
      "10-20 14:47:14.033 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 196 finished: parquet at StringIndexer.scala:523, took 0.015404 s\n",
      "10-20 14:47:14.040 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:14.041 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:14.041 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:14.046 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_479 stored as values in memory (estimated size 177.5 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.050 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_479_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.050 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_479_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.051 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 479 from head at StringIndexer.scala:524\n",
      "10-20 14:47:14.051 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:14.055 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:14.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 197 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:14.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 332 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:14.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.055 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 332 (MapPartitionsRDD[824] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:14.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_480 stored as values in memory (estimated size 8.9 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_480_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.058 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_480_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 480 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 332 (MapPartitionsRDD[824] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 332.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.059 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 332.0 (TID 741) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.060 172.17.0.2:54325      7233    (TID 741)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 332.0 (TID 741)\n",
      "10-20 14:47:14.062 172.17.0.2:54325      7233    (TID 741)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/data/part-00000-f1dc2679-0fa6-4a7a-a645-cc4070496429-c000.snappy.parquet, range: 0-1080, partition values: [empty row]\n",
      "10-20 14:47:14.066 172.17.0.2:54325      7233    (TID 741)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:14.067 172.17.0.2:54325      7233    (TID 741)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:14.067 172.17.0.2:54325      7233    (TID 741)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:14.068 172.17.0.2:54325      7233    (TID 741)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 332.0 (TID 741). 2291 bytes result sent to driver\n",
      "10-20 14:47:14.069 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 332.0 (TID 741) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.069 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 332 (head at StringIndexer.scala:524) finished in 0.015 s\n",
      "10-20 14:47:14.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 197 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.070 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 332: Stage finished\n",
      "10-20 14:47:14.070 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 197 finished: head at StringIndexer.scala:524, took 0.015259 s\n",
      "10-20 14:47:14.095 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_481 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:14.101 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_481_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:14.101 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_481_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.101 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 481 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.121 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 198 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 333 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.122 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 333 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[826] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_482 stored as values in memory (estimated size 4.2 KiB, free 433.0 MiB)\n",
      "10-20 14:47:14.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_482_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.0 MiB)\n",
      "10-20 14:47:14.123 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_482_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 482 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 333 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[826] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 333.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.125 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 333.0 (TID 742) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.125 172.17.0.2:54325      7233    (TID 742)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 333.0 (TID 742)\n",
      "10-20 14:47:14.126 172.17.0.2:54325      7233    (TID 742)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata/part-00000:0+326\n",
      "10-20 14:47:14.127 172.17.0.2:54325      7233    (TID 742)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 333.0 (TID 742). 1168 bytes result sent to driver\n",
      "10-20 14:47:14.128 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 333.0 (TID 742) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.128 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 333 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:14.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 198 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.128 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 333: Stage finished\n",
      "10-20 14:47:14.129 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 198 finished: first at ReadWrite.scala:587, took 0.007732 s\n",
      "10-20 14:47:14.132 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_483 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:14.137 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_483_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.137 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_483_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.138 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 483 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.163 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.163 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 199 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.163 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 334 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.163 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.163 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.163 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 334 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[828] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_484 stored as values in memory (estimated size 4.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.164 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_484_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.165 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_484_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 484 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 334 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[828] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.165 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.166 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 334.0 (TID 743) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.166 172.17.0.2:54325      7233    (TID 743)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 334.0 (TID 743)\n",
      "10-20 14:47:14.168 172.17.0.2:54325      7233    (TID 743)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata/part-00000:0+326\n",
      "10-20 14:47:14.170 172.17.0.2:54325      7233    (TID 743)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 334.0 (TID 743). 1254 bytes result sent to driver\n",
      "10-20 14:47:14.170 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 334.0 (TID 743) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.170 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 334 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:14.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 199 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 334: Stage finished\n",
      "10-20 14:47:14.171 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 199 finished: first at ReadWrite.scala:587, took 0.008220 s\n",
      "10-20 14:47:14.180 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:14.197 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:14.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 200 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:14.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 335 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:14.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.197 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 335 (MapPartitionsRDD[830] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:14.202 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_485 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.203 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_485_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:47:14.203 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_485_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:14.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 485 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 335 (MapPartitionsRDD[830] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.205 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 335.0 (TID 744) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.205 172.17.0.2:54325      7233    (TID 744)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 335.0 (TID 744)\n",
      "10-20 14:47:14.210 172.17.0.2:54325      7233    (TID 744)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 335.0 (TID 744). 1705 bytes result sent to driver\n",
      "10-20 14:47:14.211 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 335.0 (TID 744) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.211 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.211 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 335 (parquet at OneHotEncoder.scala:418) finished in 0.013 s\n",
      "10-20 14:47:14.211 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 200 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.211 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 335: Stage finished\n",
      "10-20 14:47:14.212 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 200 finished: parquet at OneHotEncoder.scala:418, took 0.014925 s\n",
      "10-20 14:47:14.221 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:14.221 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:14.221 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:14.225 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_486 stored as values in memory (estimated size 177.4 KiB, free 432.6 MiB)\n",
      "10-20 14:47:14.240 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_477_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:14.241 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_479_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_486_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:14.242 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_486_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:14.243 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_481_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.243 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 486 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.243 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:14.244 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_485_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.245 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_474_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.246 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_478_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.247 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_476_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.247 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_482_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.248 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.248 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_483_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 201 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:14.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 336 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:14.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 336 (MapPartitionsRDD[833] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:14.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_487 stored as values in memory (estimated size 8.9 KiB, free 433.8 MiB)\n",
      "10-20 14:47:14.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_487_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.252 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_487_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 487 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 336 (MapPartitionsRDD[833] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.252 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.253 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_480_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.253 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 336.0 (TID 745) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.253 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 336.0 (TID 745)\n",
      "10-20 14:47:14.261 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.294466 ms\n",
      "10-20 14:47:14.263 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_475_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.264 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_473_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.265 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_472_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.266 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_484_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.270 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/data/part-00000-42e52091-7539-4578-8dce-562d4a27fde9-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:14.276 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:14.276 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:14.277 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:14.279 172.17.0.2:54325      7233    (TID 745)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 336.0 (TID 745). 1633 bytes result sent to driver\n",
      "10-20 14:47:14.279 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 336.0 (TID 745) in 26 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.279 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 336 (head at OneHotEncoder.scala:419) finished in 0.030 s\n",
      "10-20 14:47:14.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 201 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 336: Stage finished\n",
      "10-20 14:47:14.281 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 201 finished: head at OneHotEncoder.scala:419, took 0.032207 s\n",
      "10-20 14:47:14.290 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.230498 ms\n",
      "10-20 14:47:14.293 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_488 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:14.297 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_488_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:14.298 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_488_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.298 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 488 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.317 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 202 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 337 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.318 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 337 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[835] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_489 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:14.319 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_489_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:14.320 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_489_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 489 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.320 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 337 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[835] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.321 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 337.0 (TID 746) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.322 172.17.0.2:54325      7233    (TID 746)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 337.0 (TID 746)\n",
      "10-20 14:47:14.324 172.17.0.2:54325      7233    (TID 746)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata/part-00000:0+326\n",
      "10-20 14:47:14.326 172.17.0.2:54325      7233    (TID 746)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 337.0 (TID 746). 1254 bytes result sent to driver\n",
      "10-20 14:47:14.326 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 337.0 (TID 746) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.327 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.327 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 337 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:14.327 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 202 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.327 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 337: Stage finished\n",
      "10-20 14:47:14.328 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 202 finished: first at ReadWrite.scala:587, took 0.009947 s\n",
      "10-20 14:47:14.329 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_490 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:14.333 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_490_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:14.333 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_490_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.334 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 490 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.351 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.351 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 203 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.351 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 338 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.351 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.351 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 338 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[837] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.352 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_491 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:14.353 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_491_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:14.353 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_491_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 491 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 338 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[837] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.354 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 338.0 (TID 747) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.355 172.17.0.2:54325      7233    (TID 747)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 338.0 (TID 747)\n",
      "10-20 14:47:14.356 172.17.0.2:54325      7233    (TID 747)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata/part-00000:0+326\n",
      "10-20 14:47:14.357 172.17.0.2:54325      7233    (TID 747)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 338.0 (TID 747). 1211 bytes result sent to driver\n",
      "10-20 14:47:14.357 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 338.0 (TID 747) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.357 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 338 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:14.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 203 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.358 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 338: Stage finished\n",
      "10-20 14:47:14.358 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 203 finished: first at ReadWrite.scala:587, took 0.007140 s\n",
      "10-20 14:47:14.365 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:14.384 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:14.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 204 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:14.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 339 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:14.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 339 (MapPartitionsRDD[839] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:14.390 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_492 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.390 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_492_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.390 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_492_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 492 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 339 (MapPartitionsRDD[839] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.391 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.392 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 339.0 (TID 748) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.392 172.17.0.2:54325      7233    (TID 748)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 339.0 (TID 748)\n",
      "10-20 14:47:14.398 172.17.0.2:54325      7233    (TID 748)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 339.0 (TID 748). 1705 bytes result sent to driver\n",
      "10-20 14:47:14.398 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 339.0 (TID 748) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.399 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 339 (parquet at OneHotEncoder.scala:418) finished in 0.014 s\n",
      "10-20 14:47:14.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 204 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 339: Stage finished\n",
      "10-20 14:47:14.399 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 204 finished: parquet at OneHotEncoder.scala:418, took 0.014391 s\n",
      "10-20 14:47:14.406 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:14.407 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:14.407 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:14.412 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_493 stored as values in memory (estimated size 177.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.417 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_493_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.417 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_493_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.417 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 493 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.418 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:14.445 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 205 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:14.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 340 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:14.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.446 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 340 (MapPartitionsRDD[842] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:14.448 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_494 stored as values in memory (estimated size 8.9 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.449 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_494_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:47:14.450 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_494_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 494 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.451 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 340 (MapPartitionsRDD[842] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.451 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.451 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 340.0 (TID 749) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.452 172.17.0.2:54325      7233    (TID 749)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 340.0 (TID 749)\n",
      "10-20 14:47:14.454 172.17.0.2:54325      7233    (TID 749)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/data/part-00000-99370af6-9865-44b6-9157-c7746f517dd6-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:14.458 172.17.0.2:54325      7233    (TID 749)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:14.459 172.17.0.2:54325      7233    (TID 749)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:14.459 172.17.0.2:54325      7233    (TID 749)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:14.460 172.17.0.2:54325      7233    (TID 749)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 340.0 (TID 749). 1633 bytes result sent to driver\n",
      "10-20 14:47:14.461 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 340.0 (TID 749) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.461 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 340 (head at OneHotEncoder.scala:419) finished in 0.015 s\n",
      "10-20 14:47:14.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 205 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 340: Stage finished\n",
      "10-20 14:47:14.462 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 205 finished: head at OneHotEncoder.scala:419, took 0.016973 s\n",
      "10-20 14:47:14.465 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_495 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:14.470 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_495_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:14.474 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_495_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.475 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 495 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.502 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 206 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 341 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.503 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 341 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[844] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.504 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_496 stored as values in memory (estimated size 4.2 KiB, free 433.0 MiB)\n",
      "10-20 14:47:14.505 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_496_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.0 MiB)\n",
      "10-20 14:47:14.505 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_496_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 496 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 341 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[844] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.506 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 341.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.507 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 341.0 (TID 750) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.507 172.17.0.2:54325      7233    (TID 750)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 341.0 (TID 750)\n",
      "10-20 14:47:14.509 172.17.0.2:54325      7233    (TID 750)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata/part-00000:0+336\n",
      "10-20 14:47:14.510 172.17.0.2:54325      7233    (TID 750)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 341.0 (TID 750). 1264 bytes result sent to driver\n",
      "10-20 14:47:14.511 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 341.0 (TID 750) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.511 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.511 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 341 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:14.511 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 206 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.511 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 341: Stage finished\n",
      "10-20 14:47:14.511 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 206 finished: first at ReadWrite.scala:587, took 0.009042 s\n",
      "10-20 14:47:14.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_497 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:14.517 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_497_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.517 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_497_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.518 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 497 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.543 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 207 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 342 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.546 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 342 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[846] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.546 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_498 stored as values in memory (estimated size 4.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.547 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_498_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.547 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_498_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 498 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 342 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[846] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.551 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 342.0 (TID 751) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.551 172.17.0.2:54325      7233    (TID 751)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 342.0 (TID 751)\n",
      "10-20 14:47:14.553 172.17.0.2:54325      7233    (TID 751)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata/part-00000:0+336\n",
      "10-20 14:47:14.554 172.17.0.2:54325      7233    (TID 751)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 342.0 (TID 751). 1264 bytes result sent to driver\n",
      "10-20 14:47:14.558 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 342.0 (TID 751) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.558 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.560 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 342 (first at ReadWrite.scala:587) finished in 0.014 s\n",
      "10-20 14:47:14.560 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 207 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.560 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 342: Stage finished\n",
      "10-20 14:47:14.565 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 207 finished: first at ReadWrite.scala:587, took 0.021890 s\n",
      "10-20 14:47:14.576 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:14.594 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:14.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 208 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:14.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 343 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:14.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.594 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.595 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 343 (MapPartitionsRDD[848] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:14.599 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_499 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.611 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_486_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.611 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_499_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.611 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_499_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.611 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 499 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.611 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 343 (MapPartitionsRDD[848] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.611 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 343.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.612 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_498_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.612 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 343.0 (TID 752) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.612 172.17.0.2:54325      7233    (TID 752)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 343.0 (TID 752)\n",
      "10-20 14:47:14.613 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_494_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.614 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_487_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.615 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_493_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.616 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_489_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.616 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_492_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.617 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_495_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.620 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_496_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.621 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_497_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.622 172.17.0.2:54325      7233    (TID 752)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 343.0 (TID 752). 1705 bytes result sent to driver\n",
      "10-20 14:47:14.622 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_488_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.623 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 343.0 (TID 752) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.623 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.623 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 343 (parquet at OneHotEncoder.scala:418) finished in 0.028 s\n",
      "10-20 14:47:14.623 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 208 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.623 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 343: Stage finished\n",
      "10-20 14:47:14.623 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 208 finished: parquet at OneHotEncoder.scala:418, took 0.029142 s\n",
      "10-20 14:47:14.628 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_491_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.631 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_490_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.633 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:14.636 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:14.636 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:14.642 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_500 stored as values in memory (estimated size 177.4 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.647 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_500_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.647 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_500_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.648 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 500 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.648 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:14.652 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 209 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:14.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 344 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:14.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[851] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:14.654 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_501 stored as values in memory (estimated size 8.9 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.655 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_501_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.655 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_501_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.655 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 501 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.655 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[851] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.656 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 344.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.656 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 344.0 (TID 753) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.656 172.17.0.2:54325      7233    (TID 753)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 344.0 (TID 753)\n",
      "10-20 14:47:14.658 172.17.0.2:54325      7233    (TID 753)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/data/part-00000-9bdca204-87b1-4a49-b951-2984a719ee3e-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:14.661 172.17.0.2:54325      7233    (TID 753)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:14.662 172.17.0.2:54325      7233    (TID 753)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:14.662 172.17.0.2:54325      7233    (TID 753)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:14.663 172.17.0.2:54325      7233    (TID 753)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 344.0 (TID 753). 1633 bytes result sent to driver\n",
      "10-20 14:47:14.663 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 344.0 (TID 753) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.663 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.664 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 344 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:14.664 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 209 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.664 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 344: Stage finished\n",
      "10-20 14:47:14.664 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 209 finished: head at OneHotEncoder.scala:419, took 0.012058 s\n",
      "10-20 14:47:14.667 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_502 stored as values in memory (estimated size 176.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.671 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_502_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.672 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_502_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.672 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 502 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.690 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 210 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 345 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 345 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[853] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_503 stored as values in memory (estimated size 4.2 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_503_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.693 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_503_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 503 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.694 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 345 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[853] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.694 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 345.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.695 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 345.0 (TID 754) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.696 172.17.0.2:54325      7233    (TID 754)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 345.0 (TID 754)\n",
      "10-20 14:47:14.697 172.17.0.2:54325      7233    (TID 754)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata/part-00000:0+328\n",
      "10-20 14:47:14.698 172.17.0.2:54325      7233    (TID 754)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 345.0 (TID 754). 1256 bytes result sent to driver\n",
      "10-20 14:47:14.699 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 345.0 (TID 754) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.699 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 345 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:14.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 210 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 345: Stage finished\n",
      "10-20 14:47:14.700 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 210 finished: first at ReadWrite.scala:587, took 0.009469 s\n",
      "10-20 14:47:14.702 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_504 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.706 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_504_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.707 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_504_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.707 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 504 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.723 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 211 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 346 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 346 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[855] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.725 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_505 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_505_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:14.726 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_505_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 505 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 346 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[855] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.726 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 346.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.727 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 346.0 (TID 755) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.727 172.17.0.2:54325      7233    (TID 755)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 346.0 (TID 755)\n",
      "10-20 14:47:14.729 172.17.0.2:54325      7233    (TID 755)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata/part-00000:0+328\n",
      "10-20 14:47:14.730 172.17.0.2:54325      7233    (TID 755)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 346.0 (TID 755). 1256 bytes result sent to driver\n",
      "10-20 14:47:14.730 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 346.0 (TID 755) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.730 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.731 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 346 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:14.731 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 211 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.731 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 346: Stage finished\n",
      "10-20 14:47:14.732 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 211 finished: first at ReadWrite.scala:587, took 0.008385 s\n",
      "10-20 14:47:14.738 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:14.756 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:14.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 212 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:14.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 347 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:14.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.756 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 347 (MapPartitionsRDD[857] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:14.761 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_506 stored as values in memory (estimated size 84.5 KiB, free 433.4 MiB)\n",
      "10-20 14:47:14.762 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_506_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.4 MiB)\n",
      "10-20 14:47:14.762 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_506_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 506 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 347 (MapPartitionsRDD[857] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 347.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.764 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 347.0 (TID 756) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.764 172.17.0.2:54325      7233    (TID 756)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 347.0 (TID 756)\n",
      "10-20 14:47:14.770 172.17.0.2:54325      7233    (TID 756)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 347.0 (TID 756). 1705 bytes result sent to driver\n",
      "10-20 14:47:14.771 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 347.0 (TID 756) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.771 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 347.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.772 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 347 (parquet at OneHotEncoder.scala:418) finished in 0.015 s\n",
      "10-20 14:47:14.772 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 212 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.772 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 347: Stage finished\n",
      "10-20 14:47:14.774 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 212 finished: parquet at OneHotEncoder.scala:418, took 0.018104 s\n",
      "10-20 14:47:14.780 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:14.780 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:14.780 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:14.804 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_507 stored as values in memory (estimated size 177.4 KiB, free 433.2 MiB)\n",
      "10-20 14:47:14.810 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_507_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.2 MiB)\n",
      "10-20 14:47:14.811 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_507_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.811 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 507 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.812 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:14.816 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 213 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:14.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 348 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:14.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 348 (MapPartitionsRDD[860] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:14.818 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_508 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:47:14.819 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_508_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:47:14.819 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_508_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.819 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 508 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.820 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 348 (MapPartitionsRDD[860] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.820 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 348.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.820 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 348.0 (TID 757) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.820 172.17.0.2:54325      7233    (TID 757)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 348.0 (TID 757)\n",
      "10-20 14:47:14.822 172.17.0.2:54325      7233    (TID 757)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/data/part-00000-cfffee53-1ee6-4583-89d6-907e29892dc5-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:14.825 172.17.0.2:54325      7233    (TID 757)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:14.825 172.17.0.2:54325      7233    (TID 757)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:14.825 172.17.0.2:54325      7233    (TID 757)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:14.826 172.17.0.2:54325      7233    (TID 757)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 348.0 (TID 757). 1629 bytes result sent to driver\n",
      "10-20 14:47:14.827 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 348.0 (TID 757) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.827 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 348.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 348 (head at OneHotEncoder.scala:419) finished in 0.010 s\n",
      "10-20 14:47:14.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 213 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 348: Stage finished\n",
      "10-20 14:47:14.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 213 finished: head at OneHotEncoder.scala:419, took 0.011472 s\n",
      "10-20 14:47:14.830 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_509 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 14:47:14.835 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_509_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:14.835 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_509_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.835 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 509 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.850 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 214 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 349 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.851 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 349 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[862] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.852 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_510 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:14.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_510_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:47:14.853 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_510_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 510 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.853 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 349 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[862] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.854 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 349.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.854 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 349.0 (TID 758) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.854 172.17.0.2:54325      7233    (TID 758)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 349.0 (TID 758)\n",
      "10-20 14:47:14.855 172.17.0.2:54325      7233    (TID 758)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata/part-00000:0+332\n",
      "10-20 14:47:14.856 172.17.0.2:54325      7233    (TID 758)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 349.0 (TID 758). 1174 bytes result sent to driver\n",
      "10-20 14:47:14.857 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 349.0 (TID 758) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.857 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 349.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 349 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:14.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 214 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 349: Stage finished\n",
      "10-20 14:47:14.858 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 214 finished: first at ReadWrite.scala:587, took 0.007197 s\n",
      "10-20 14:47:14.859 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_511 stored as values in memory (estimated size 176.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:14.864 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_511_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:14.864 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_511_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:14.864 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 511 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:14.878 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:14.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 215 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:14.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 350 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:14.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 350 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[864] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:14.880 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_512 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:14.880 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_512_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:47:14.881 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_512_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:14.881 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 512 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.881 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 350 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[864] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.881 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 350.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.882 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 350.0 (TID 759) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.882 172.17.0.2:54325      7233    (TID 759)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 350.0 (TID 759)\n",
      "10-20 14:47:14.883 172.17.0.2:54325      7233    (TID 759)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata/part-00000:0+332\n",
      "10-20 14:47:14.884 172.17.0.2:54325      7233    (TID 759)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 350.0 (TID 759). 1217 bytes result sent to driver\n",
      "10-20 14:47:14.885 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 350.0 (TID 759) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.885 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 350.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.885 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 350 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:14.885 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 215 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.885 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 350: Stage finished\n",
      "10-20 14:47:14.885 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 215 finished: first at ReadWrite.scala:587, took 0.007047 s\n",
      "10-20 14:47:14.891 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:14.908 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:14.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 216 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:14.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 351 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:14.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 351 (MapPartitionsRDD[866] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:14.914 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_513 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:47:14.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_513_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:14.927 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_509_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.927 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_513_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:14.927 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 513 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.928 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_504_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 351 (MapPartitionsRDD[866] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.928 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 351.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.928 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_511_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.929 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 351.0 (TID 760) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.929 172.17.0.2:54325      7233    (TID 760)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 351.0 (TID 760)\n",
      "10-20 14:47:14.930 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_501_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.931 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_510_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.935 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_500_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.936 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_506_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:14.938 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_502_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.939 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_503_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.940 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_508_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.941 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_512_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.942 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_499_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.944 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_505_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.945 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_507_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.946 172.17.0.2:54325      7233    (TID 760)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 351.0 (TID 760). 1705 bytes result sent to driver\n",
      "10-20 14:47:14.947 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 351.0 (TID 760) in 18 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.947 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 351.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.948 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 351 (parquet at OneHotEncoder.scala:418) finished in 0.039 s\n",
      "10-20 14:47:14.948 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 216 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.948 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 351: Stage finished\n",
      "10-20 14:47:14.948 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 216 finished: parquet at OneHotEncoder.scala:418, took 0.040135 s\n",
      "10-20 14:47:14.956 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:14.956 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:14.956 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:14.961 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_514 stored as values in memory (estimated size 177.4 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.967 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_514_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.967 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_514_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.968 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 514 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.969 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:14.973 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:14.973 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 217 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:14.973 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 352 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:14.973 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:14.973 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:14.973 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 352 (MapPartitionsRDD[869] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:14.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_515 stored as values in memory (estimated size 8.9 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_515_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.9 MiB)\n",
      "10-20 14:47:14.976 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_515_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 515 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:14.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 352 (MapPartitionsRDD[869] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:14.976 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 352.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:14.977 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 352.0 (TID 761) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:14.977 172.17.0.2:54325      7233    (TID 761)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 352.0 (TID 761)\n",
      "10-20 14:47:14.980 172.17.0.2:54325      7233    (TID 761)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/data/part-00000-41b1fa50-4a26-48ef-bf43-3158cce827ba-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:14.983 172.17.0.2:54325      7233    (TID 761)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:14.983 172.17.0.2:54325      7233    (TID 761)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:14.984 172.17.0.2:54325      7233    (TID 761)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:14.985 172.17.0.2:54325      7233    (TID 761)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 352.0 (TID 761). 1633 bytes result sent to driver\n",
      "10-20 14:47:14.985 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 352.0 (TID 761) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:14.985 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 352.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:14.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 352 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:14.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 217 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:14.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 352: Stage finished\n",
      "10-20 14:47:14.986 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 217 finished: head at OneHotEncoder.scala:419, took 0.013536 s\n",
      "10-20 14:47:14.989 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_516 stored as values in memory (estimated size 176.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.994 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_516_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.7 MiB)\n",
      "10-20 14:47:14.994 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_516_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:14.995 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 516 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.012 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 218 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 353 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.013 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 353 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[871] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.014 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_517 stored as values in memory (estimated size 4.2 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.014 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_517_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.014 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_517_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.015 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 517 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.015 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 353 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[871] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.015 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 353.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.015 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 353.0 (TID 762) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.015 172.17.0.2:54325      7233    (TID 762)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 353.0 (TID 762)\n",
      "10-20 14:47:15.017 172.17.0.2:54325      7233    (TID 762)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata/part-00000:0+316\n",
      "10-20 14:47:15.018 172.17.0.2:54325      7233    (TID 762)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 353.0 (TID 762). 1201 bytes result sent to driver\n",
      "10-20 14:47:15.019 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 353.0 (TID 762) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.019 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 353.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 353 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:15.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 218 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 353: Stage finished\n",
      "10-20 14:47:15.020 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 218 finished: first at ReadWrite.scala:587, took 0.007242 s\n",
      "10-20 14:47:15.022 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_518 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.027 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_518_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.027 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_518_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.028 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 518 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.044 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 219 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 354 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 354 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[873] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_519 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_519_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.047 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_519_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 519 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 354 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[873] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.047 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 354.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.048 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 354.0 (TID 763) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.048 172.17.0.2:54325      7233    (TID 763)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 354.0 (TID 763)\n",
      "10-20 14:47:15.050 172.17.0.2:54325      7233    (TID 763)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata/part-00000:0+316\n",
      "10-20 14:47:15.051 172.17.0.2:54325      7233    (TID 763)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 354.0 (TID 763). 1201 bytes result sent to driver\n",
      "10-20 14:47:15.052 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 354.0 (TID 763) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.052 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 354.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.052 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 354 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:15.052 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 219 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.052 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 354: Stage finished\n",
      "10-20 14:47:15.053 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 219 finished: first at ReadWrite.scala:587, took 0.008196 s\n",
      "10-20 14:47:15.060 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:15.078 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:15.078 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 220 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:15.078 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 355 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:15.078 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.078 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.079 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 355 (MapPartitionsRDD[875] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:15.083 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_520 stored as values in memory (estimated size 84.5 KiB, free 433.4 MiB)\n",
      "10-20 14:47:15.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_520_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.4 MiB)\n",
      "10-20 14:47:15.084 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_520_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.084 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 520 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.085 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 355 (MapPartitionsRDD[875] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.085 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 355.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.085 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 355.0 (TID 764) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.086 172.17.0.2:54325      7233    (TID 764)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 355.0 (TID 764)\n",
      "10-20 14:47:15.094 172.17.0.2:54325      7233    (TID 764)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 355.0 (TID 764). 1705 bytes result sent to driver\n",
      "10-20 14:47:15.096 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 355.0 (TID 764) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.096 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 355.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 355 (parquet at OneHotEncoder.scala:418) finished in 0.018 s\n",
      "10-20 14:47:15.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 220 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 355: Stage finished\n",
      "10-20 14:47:15.097 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 220 finished: parquet at OneHotEncoder.scala:418, took 0.019308 s\n",
      "10-20 14:47:15.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:15.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:15.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:15.138 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_521 stored as values in memory (estimated size 177.4 KiB, free 433.2 MiB)\n",
      "10-20 14:47:15.145 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_521_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.2 MiB)\n",
      "10-20 14:47:15.146 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_521_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.146 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 521 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:15.147 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:15.150 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:15.151 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 221 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:15.151 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 356 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:15.151 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.151 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.151 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 356 (MapPartitionsRDD[878] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:15.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_522 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:47:15.153 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_522_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:47:15.154 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_522_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.154 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 522 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.154 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 356 (MapPartitionsRDD[878] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.154 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 356.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.155 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 356.0 (TID 765) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.155 172.17.0.2:54325      7233    (TID 765)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 356.0 (TID 765)\n",
      "10-20 14:47:15.157 172.17.0.2:54325      7233    (TID 765)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/data/part-00000-2cdd5380-9478-48a4-bcb4-09175a733687-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:15.160 172.17.0.2:54325      7233    (TID 765)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:15.160 172.17.0.2:54325      7233    (TID 765)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:15.161 172.17.0.2:54325      7233    (TID 765)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:15.161 172.17.0.2:54325      7233    (TID 765)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 356.0 (TID 765). 1633 bytes result sent to driver\n",
      "10-20 14:47:15.162 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 356.0 (TID 765) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.162 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 356.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.162 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 356 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:15.162 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 221 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.162 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 356: Stage finished\n",
      "10-20 14:47:15.163 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 221 finished: head at OneHotEncoder.scala:419, took 0.012268 s\n",
      "10-20 14:47:15.165 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_523 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 14:47:15.170 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_523_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:15.170 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_523_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.171 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 523 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.188 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 222 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 357 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.189 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 357 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[880] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_524 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:15.190 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_524_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:47:15.190 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_524_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.191 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 524 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.191 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 357 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[880] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.191 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 357.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.192 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 357.0 (TID 766) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.192 172.17.0.2:54325      7233    (TID 766)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 357.0 (TID 766)\n",
      "10-20 14:47:15.193 172.17.0.2:54325      7233    (TID 766)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata/part-00000:0+314\n",
      "10-20 14:47:15.194 172.17.0.2:54325      7233    (TID 766)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 357.0 (TID 766). 1199 bytes result sent to driver\n",
      "10-20 14:47:15.195 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 357.0 (TID 766) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.195 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 357.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 357 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:15.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 222 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 357: Stage finished\n",
      "10-20 14:47:15.195 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 222 finished: first at ReadWrite.scala:587, took 0.007024 s\n",
      "10-20 14:47:15.197 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_525 stored as values in memory (estimated size 176.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:15.201 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_525_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:15.201 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_525_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.202 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 525 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.218 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 223 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 358 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 358 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[882] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.219 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_526 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:15.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_526_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:47:15.220 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_526_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 526 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 358 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[882] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 358.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.221 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 358.0 (TID 767) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.226 172.17.0.2:54325      7233    (TID 767)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 358.0 (TID 767)\n",
      "10-20 14:47:15.227 172.17.0.2:54325      7233    (TID 767)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata/part-00000:0+314\n",
      "10-20 14:47:15.228 172.17.0.2:54325      7233    (TID 767)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 358.0 (TID 767). 1156 bytes result sent to driver\n",
      "10-20 14:47:15.229 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 358.0 (TID 767) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.229 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 358.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 358 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:47:15.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 223 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.229 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 358: Stage finished\n",
      "10-20 14:47:15.229 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 223 finished: first at ReadWrite.scala:587, took 0.011408 s\n",
      "10-20 14:47:15.235 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:15.253 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:15.253 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 224 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:15.253 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 359 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:15.253 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.253 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.254 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 359 (MapPartitionsRDD[884] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:15.258 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_527 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:47:15.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_527_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:15.271 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_513_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.272 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_527_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 527 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 359 (MapPartitionsRDD[884] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.273 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_525_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 359.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.273 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 359.0 (TID 768) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.274 172.17.0.2:54325      7233    (TID 768)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 359.0 (TID 768)\n",
      "10-20 14:47:15.277 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_519_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.278 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_514_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.279 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_526_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.280 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_517_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.281 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_516_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.282 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_523_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.283 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_515_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.283 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_522_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.284 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_524_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.285 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_520_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.286 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_521_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.287 172.17.0.2:54325      7233    (TID 768)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 359.0 (TID 768). 1705 bytes result sent to driver\n",
      "10-20 14:47:15.287 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 359.0 (TID 768) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.288 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 359.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.288 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 359 (parquet at OneHotEncoder.scala:418) finished in 0.034 s\n",
      "10-20 14:47:15.288 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 224 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.288 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 359: Stage finished\n",
      "10-20 14:47:15.288 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_518_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.288 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 224 finished: parquet at OneHotEncoder.scala:418, took 0.035325 s\n",
      "10-20 14:47:15.294 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:15.295 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:15.295 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:15.299 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_528 stored as values in memory (estimated size 177.4 KiB, free 433.9 MiB)\n",
      "10-20 14:47:15.304 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_528_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.9 MiB)\n",
      "10-20 14:47:15.304 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_528_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.305 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 528 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:15.305 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:15.309 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:15.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 225 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:15.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 360 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:15.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.310 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 360 (MapPartitionsRDD[887] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:15.311 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_529 stored as values in memory (estimated size 8.9 KiB, free 433.9 MiB)\n",
      "10-20 14:47:15.312 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_529_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.9 MiB)\n",
      "10-20 14:47:15.312 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_529_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 529 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 360 (MapPartitionsRDD[887] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 360.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.314 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 360.0 (TID 769) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.314 172.17.0.2:54325      7233    (TID 769)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 360.0 (TID 769)\n",
      "10-20 14:47:15.317 172.17.0.2:54325      7233    (TID 769)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/data/part-00000-aa5a59a3-4580-4b9c-93dd-31b922f0da7e-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:15.319 172.17.0.2:54325      7233    (TID 769)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:15.319 172.17.0.2:54325      7233    (TID 769)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:15.319 172.17.0.2:54325      7233    (TID 769)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:15.320 172.17.0.2:54325      7233    (TID 769)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 360.0 (TID 769). 1633 bytes result sent to driver\n",
      "10-20 14:47:15.321 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 360.0 (TID 769) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.321 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 360.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 360 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:15.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 225 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.321 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 360: Stage finished\n",
      "10-20 14:47:15.322 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 225 finished: head at OneHotEncoder.scala:419, took 0.012810 s\n",
      "10-20 14:47:15.325 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_530 stored as values in memory (estimated size 176.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.330 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_530_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.330 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_530_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.330 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 530 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.346 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.347 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 226 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.347 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 361 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.347 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.347 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.348 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 361 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[889] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.348 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_531 stored as values in memory (estimated size 4.2 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.349 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_531_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.349 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_531_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.349 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 531 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.350 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 361 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[889] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.350 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 361.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.350 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 361.0 (TID 770) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.350 172.17.0.2:54325      7233    (TID 770)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 361.0 (TID 770)\n",
      "10-20 14:47:15.352 172.17.0.2:54325      7233    (TID 770)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata/part-00000:0+336\n",
      "10-20 14:47:15.353 172.17.0.2:54325      7233    (TID 770)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 361.0 (TID 770). 1221 bytes result sent to driver\n",
      "10-20 14:47:15.353 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 361.0 (TID 770) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.353 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 361.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 361 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:15.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 226 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 361: Stage finished\n",
      "10-20 14:47:15.354 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 226 finished: first at ReadWrite.scala:587, took 0.007928 s\n",
      "10-20 14:47:15.356 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_532 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.361 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_532_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.361 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_532_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.362 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 532 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.379 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 227 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 362 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 362 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[891] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.381 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_533 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.381 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_533_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.381 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_533_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.382 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 533 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.382 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 362 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[891] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.382 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 362.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.383 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 362.0 (TID 771) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.383 172.17.0.2:54325      7233    (TID 771)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 362.0 (TID 771)\n",
      "10-20 14:47:15.385 172.17.0.2:54325      7233    (TID 771)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata/part-00000:0+336\n",
      "10-20 14:47:15.386 172.17.0.2:54325      7233    (TID 771)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 362.0 (TID 771). 1264 bytes result sent to driver\n",
      "10-20 14:47:15.386 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 362.0 (TID 771) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.387 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 362.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 362 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:15.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 227 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 362: Stage finished\n",
      "10-20 14:47:15.388 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 227 finished: first at ReadWrite.scala:587, took 0.008815 s\n",
      "10-20 14:47:15.394 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:15.412 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:15.413 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 228 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:15.413 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 363 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:15.413 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.413 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.413 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 363 (MapPartitionsRDD[893] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:15.418 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_534 stored as values in memory (estimated size 84.5 KiB, free 433.4 MiB)\n",
      "10-20 14:47:15.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_534_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.4 MiB)\n",
      "10-20 14:47:15.419 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_534_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 534 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.420 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 363 (MapPartitionsRDD[893] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.420 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 363.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.420 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 363.0 (TID 772) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.421 172.17.0.2:54325      7233    (TID 772)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 363.0 (TID 772)\n",
      "10-20 14:47:15.426 172.17.0.2:54325      7233    (TID 772)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 363.0 (TID 772). 1705 bytes result sent to driver\n",
      "10-20 14:47:15.427 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 363.0 (TID 772) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.427 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 363.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 363 (parquet at OneHotEncoder.scala:418) finished in 0.014 s\n",
      "10-20 14:47:15.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 228 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.428 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 363: Stage finished\n",
      "10-20 14:47:15.429 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 228 finished: parquet at OneHotEncoder.scala:418, took 0.016614 s\n",
      "10-20 14:47:15.436 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:15.437 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:15.437 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:15.466 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_535 stored as values in memory (estimated size 177.4 KiB, free 433.2 MiB)\n",
      "10-20 14:47:15.473 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_535_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.2 MiB)\n",
      "10-20 14:47:15.474 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_535_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.475 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 535 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:15.475 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:15.479 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:15.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 229 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:15.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 364 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:15.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.480 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 364 (MapPartitionsRDD[896] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:15.482 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_536 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:47:15.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_536_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:47:15.483 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_536_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 536 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.484 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 364 (MapPartitionsRDD[896] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.484 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 364.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.484 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 364.0 (TID 773) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.485 172.17.0.2:54325      7233    (TID 773)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 364.0 (TID 773)\n",
      "10-20 14:47:15.487 172.17.0.2:54325      7233    (TID 773)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/data/part-00000-bbb39d30-1fcc-479e-b345-fb72012c6c23-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:15.491 172.17.0.2:54325      7233    (TID 773)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:15.492 172.17.0.2:54325      7233    (TID 773)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:15.492 172.17.0.2:54325      7233    (TID 773)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:15.493 172.17.0.2:54325      7233    (TID 773)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 364.0 (TID 773). 1633 bytes result sent to driver\n",
      "10-20 14:47:15.494 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 364.0 (TID 773) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.494 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 364.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 364 (head at OneHotEncoder.scala:419) finished in 0.013 s\n",
      "10-20 14:47:15.495 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 229 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.495 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 364: Stage finished\n",
      "10-20 14:47:15.495 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 229 finished: head at OneHotEncoder.scala:419, took 0.015287 s\n",
      "10-20 14:47:15.502 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_537 stored as values in memory (estimated size 176.1 KiB, free 433.0 MiB)\n",
      "10-20 14:47:15.511 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_537_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:15.511 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_537_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.511 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 537 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.548 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 230 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 365 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 365 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[898] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.550 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_538 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:15.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_538_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:47:15.551 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_538_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.551 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 538 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 365 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[898] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 365.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.553 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 365.0 (TID 774) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4580 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.554 172.17.0.2:54325      7233    (TID 774)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 365.0 (TID 774)\n",
      "10-20 14:47:15.555 172.17.0.2:54325      7233    (TID 774)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata/part-00000:0+520\n",
      "10-20 14:47:15.557 172.17.0.2:54325      7233    (TID 774)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 365.0 (TID 774). 1448 bytes result sent to driver\n",
      "10-20 14:47:15.557 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 365.0 (TID 774) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.557 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 365.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.558 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 365 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:15.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 230 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 365: Stage finished\n",
      "10-20 14:47:15.559 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 230 finished: first at ReadWrite.scala:587, took 0.010656 s\n",
      "10-20 14:47:15.561 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_539 stored as values in memory (estimated size 176.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:15.568 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_539_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:15.569 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_539_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.570 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 539 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.612 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.616 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 231 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.616 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 366 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.616 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.616 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.617 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 366 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[900] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.618 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_540 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:15.619 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_540_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:47:15.619 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_540_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.619 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 540 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 366 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[900] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.620 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 366.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.620 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 366.0 (TID 775) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4580 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.621 172.17.0.2:54325      7233    (TID 775)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 366.0 (TID 775)\n",
      "10-20 14:47:15.622 172.17.0.2:54325      7233    (TID 775)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata/part-00000:0+520\n",
      "10-20 14:47:15.624 172.17.0.2:54325      7233    (TID 775)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 366.0 (TID 775). 1448 bytes result sent to driver\n",
      "10-20 14:47:15.624 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 366.0 (TID 775) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.624 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 366.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 366 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:15.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 231 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.625 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 366: Stage finished\n",
      "10-20 14:47:15.626 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 231 finished: first at ReadWrite.scala:587, took 0.012478 s\n",
      "10-20 14:47:15.636 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_541 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:15.652 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_541_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:47:15.652 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_541_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.653 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 541 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.690 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 232 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 367 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.691 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 367 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[902] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_542 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:47:15.715 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_542_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:47:15.715 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_542_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.716 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 542 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.716 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 367 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[902] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.716 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 367.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.716 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_528_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.717 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 367.0 (TID 776) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.717 172.17.0.2:54325      7233    (TID 776)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 367.0 (TID 776)\n",
      "10-20 14:47:15.719 172.17.0.2:54325      7233    (TID 776)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata/part-00000:0+751\n",
      "10-20 14:47:15.720 172.17.0.2:54325      7233    (TID 776)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 367.0 (TID 776). 1636 bytes result sent to driver\n",
      "10-20 14:47:15.724 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 367.0 (TID 776) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.724 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 367.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 367 (first at ReadWrite.scala:587) finished in 0.033 s\n",
      "10-20 14:47:15.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 232 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.724 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 367: Stage finished\n",
      "10-20 14:47:15.724 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 232 finished: first at ReadWrite.scala:587, took 0.034115 s\n",
      "10-20 14:47:15.725 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_540_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.725 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_531_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:15.726 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_537_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.727 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_538_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.729 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_543 stored as values in memory (estimated size 176.1 KiB, free 432.8 MiB)\n",
      "10-20 14:47:15.729 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_530_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.730 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_539_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.731 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_529_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.732 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_532_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.733 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_535_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.735 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_543_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:15.737 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_543_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.743 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_527_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.743 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 543 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:15.744 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_536_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.745 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_533_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.749 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_534_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.763 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:15.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 233 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:15.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 368 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:15.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 368 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[904] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:15.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_544 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:15.765 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_544_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:15.765 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_544_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 544 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[904] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.766 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 368.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.767 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 368.0 (TID 777) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.767 172.17.0.2:54325      7233    (TID 777)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 368.0 (TID 777)\n",
      "10-20 14:47:15.768 172.17.0.2:54325      7233    (TID 777)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata/part-00000:0+751\n",
      "10-20 14:47:15.770 172.17.0.2:54325      7233    (TID 777)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 368.0 (TID 777). 1636 bytes result sent to driver\n",
      "10-20 14:47:15.771 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 368.0 (TID 777) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.771 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.771 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 368 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:15.771 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 233 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.772 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 368: Stage finished\n",
      "10-20 14:47:15.772 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 233 finished: first at ReadWrite.scala:587, took 0.009026 s\n",
      "10-20 14:47:15.779 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:15.799 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:507\n",
      "10-20 14:47:15.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 234 (parquet at treeModels.scala:507) with 1 output partitions\n",
      "10-20 14:47:15.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 369 (parquet at treeModels.scala:507)\n",
      "10-20 14:47:15.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 369 (MapPartitionsRDD[906] at parquet at treeModels.scala:507), which has no missing parents\n",
      "10-20 14:47:15.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_545 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.806 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_545_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:15.806 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_545_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.807 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 545 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.807 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 369 (MapPartitionsRDD[906] at parquet at treeModels.scala:507) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:15.807 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 369.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:15.808 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 369.0 (TID 778) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4747 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.808 172.17.0.2:54325      7233    (TID 778)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 369.0 (TID 778)\n",
      "10-20 14:47:15.815 172.17.0.2:54325      7233    (TID 778)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 369.0 (TID 778). 1787 bytes result sent to driver\n",
      "10-20 14:47:15.816 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 369.0 (TID 778) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:15.816 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 369.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:15.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 369 (parquet at treeModels.scala:507) finished in 0.016 s\n",
      "10-20 14:47:15.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 234 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:15.816 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 369: Stage finished\n",
      "10-20 14:47:15.816 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 234 finished: parquet at treeModels.scala:507, took 0.017620 s\n",
      "10-20 14:47:15.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:15.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:15.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, metadata: string, weights: double ... 1 more fields>\n",
      "10-20 14:47:15.862 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.423617 ms\n",
      "10-20 14:47:15.864 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_546 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.870 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_546_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.870 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_546_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:15.870 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 546 from rdd at treeModels.scala:509\n",
      "10-20 14:47:15.871 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4198039 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:15.900 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:514\n",
      "10-20 14:47:15.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 235 (sortByKey at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:47:15.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 370 (sortByKey at treeModels.scala:514)\n",
      "10-20 14:47:15.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:15.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:15.901 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 370 (MapPartitionsRDD[915] at sortByKey at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:47:15.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_547 stored as values in memory (estimated size 20.0 KiB, free 433.5 MiB)\n",
      "10-20 14:47:15.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_547_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 433.4 MiB)\n",
      "10-20 14:47:15.903 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_547_piece0 in memory on 95675304fa2d:39429 (size: 8.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:15.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 547 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:15.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 370 (MapPartitionsRDD[915] at sortByKey at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:15.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 370.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:15.904 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 370.0 (TID 779) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.904 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 370.0 (TID 780) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.904 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 370.0 (TID 781) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.904 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 370.0 (TID 782) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:15.905 172.17.0.2:54325      7233    (TID 779)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 370.0 (TID 779)\n",
      "10-20 14:47:15.909 172.17.0.2:54325      7233    (TID 780)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 370.0 (TID 780)\n",
      "10-20 14:47:15.916 172.17.0.2:54325      7233    (TID 781)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 370.0 (TID 781)\n",
      "10-20 14:47:15.929 172.17.0.2:54325      7233    (TID 782)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 370.0 (TID 782)\n",
      "10-20 14:47:15.967 172.17.0.2:54325      7233    (TID 782)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 32.873055 ms\n",
      "10-20 14:47:15.970 172.17.0.2:54325      7233    (TID 781)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00000-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3726, partition values: [empty row]\n",
      "10-20 14:47:15.974 172.17.0.2:54325      7233    (TID 779)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00001-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3756, partition values: [empty row]\n",
      "10-20 14:47:15.974 172.17.0.2:54325      7233    (TID 780)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00002-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3747, partition values: [empty row]\n",
      "10-20 14:47:15.974 172.17.0.2:54325      7233    (TID 782)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00003-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3712, partition values: [empty row]\n",
      "10-20 14:47:15.998 172.17.0.2:54325      7233    (TID 780)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 370.0 (TID 780). 1953 bytes result sent to driver\n",
      "10-20 14:47:15.999 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 370.0 (TID 780) in 95 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.000 172.17.0.2:54325      7233    (TID 781)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 370.0 (TID 781). 1953 bytes result sent to driver\n",
      "10-20 14:47:16.000 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 370.0 (TID 781) in 96 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.001 172.17.0.2:54325      7233    (TID 782)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 370.0 (TID 782). 1953 bytes result sent to driver\n",
      "10-20 14:47:16.001 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 370.0 (TID 782) in 97 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.002 172.17.0.2:54325      7233    (TID 779)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 370.0 (TID 779). 1953 bytes result sent to driver\n",
      "10-20 14:47:16.003 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 370.0 (TID 779) in 99 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.003 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 370.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.003 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 370 (sortByKey at treeModels.scala:514) finished in 0.102 s\n",
      "10-20 14:47:16.003 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 235 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:16.003 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 370: Stage finished\n",
      "10-20 14:47:16.003 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 235 finished: sortByKey at treeModels.scala:514, took 0.103296 s\n",
      "10-20 14:47:16.019 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:514\n",
      "10-20 14:47:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 913 (map at treeModels.scala:510) as input to shuffle 135\n",
      "10-20 14:47:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 236 (collect at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:47:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 372 (collect at treeModels.scala:514)\n",
      "10-20 14:47:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 371)\n",
      "10-20 14:47:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 371)\n",
      "10-20 14:47:16.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 371 (MapPartitionsRDD[913] at map at treeModels.scala:510), which has no missing parents\n",
      "10-20 14:47:16.021 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_548 stored as values in memory (estimated size 20.7 KiB, free 433.4 MiB)\n",
      "10-20 14:47:16.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_548_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.4 MiB)\n",
      "10-20 14:47:16.022 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_548_piece0 in memory on 95675304fa2d:39429 (size: 9.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:16.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 548 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 371 (MapPartitionsRDD[913] at map at treeModels.scala:510) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:16.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 371.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:16.023 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 371.0 (TID 783) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.024 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 371.0 (TID 784) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.024 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 371.0 (TID 785) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.024 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 371.0 (TID 786) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.024 172.17.0.2:54325      7233    (TID 786)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 371.0 (TID 786)\n",
      "10-20 14:47:16.024 172.17.0.2:54325      7233    (TID 785)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 371.0 (TID 785)\n",
      "10-20 14:47:16.025 172.17.0.2:54325      7233    (TID 783)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 371.0 (TID 783)\n",
      "10-20 14:47:16.025 172.17.0.2:54325      7233    (TID 784)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 371.0 (TID 784)\n",
      "10-20 14:47:16.031 172.17.0.2:54325      7233    (TID 785)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00000-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3726, partition values: [empty row]\n",
      "10-20 14:47:16.039 172.17.0.2:54325      7233    (TID 786)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00003-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3712, partition values: [empty row]\n",
      "10-20 14:47:16.042 172.17.0.2:54325      7233    (TID 783)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00001-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3756, partition values: [empty row]\n",
      "10-20 14:47:16.044 172.17.0.2:54325      7233    (TID 784)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00002-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3747, partition values: [empty row]\n",
      "10-20 14:47:16.052 172.17.0.2:54325      7233    (TID 786)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 371.0 (TID 786). 1906 bytes result sent to driver\n",
      "10-20 14:47:16.052 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 371.0 (TID 786) in 28 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.055 172.17.0.2:54325      7233    (TID 783)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 371.0 (TID 783). 1906 bytes result sent to driver\n",
      "10-20 14:47:16.056 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 371.0 (TID 783) in 33 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.056 172.17.0.2:54325      7233    (TID 785)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 371.0 (TID 785). 1906 bytes result sent to driver\n",
      "10-20 14:47:16.057 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 371.0 (TID 785) in 33 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.059 172.17.0.2:54325      7233    (TID 784)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 371.0 (TID 784). 1906 bytes result sent to driver\n",
      "10-20 14:47:16.059 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 371.0 (TID 784) in 36 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.059 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 371.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 371 (map at treeModels.scala:510) finished in 0.038 s\n",
      "10-20 14:47:16.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:16.060 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:16.060 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 372)\n",
      "10-20 14:47:16.060 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:16.060 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 372 (MapPartitionsRDD[917] at values at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:47:16.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_549 stored as values in memory (estimated size 4.6 KiB, free 433.4 MiB)\n",
      "10-20 14:47:16.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_549_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.4 MiB)\n",
      "10-20 14:47:16.064 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_549_piece0 in memory on 95675304fa2d:39429 (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:16.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 549 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 372 (MapPartitionsRDD[917] at values at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:16.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 372.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:16.065 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 372.0 (TID 787) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.065 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 372.0 (TID 788) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.065 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 372.0 (TID 789) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.065 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 372.0 (TID 790) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.065 172.17.0.2:54325      7233    (TID 787)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 372.0 (TID 787)\n",
      "10-20 14:47:16.066 172.17.0.2:54325      7233    (TID 790)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 372.0 (TID 790)\n",
      "10-20 14:47:16.067 172.17.0.2:54325      7233    (TID 789)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 372.0 (TID 789)\n",
      "10-20 14:47:16.073 172.17.0.2:54325      7233    (TID 788)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 372.0 (TID 788)\n",
      "10-20 14:47:16.074 172.17.0.2:54325      7233    (TID 787)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.074 172.17.0.2:54325      7233    (TID 787)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.074 172.17.0.2:54325      7233    (TID 790)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.074 172.17.0.2:54325      7233    (TID 790)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.076 172.17.0.2:54325      7233    (TID 788)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.076 172.17.0.2:54325      7233    (TID 788)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.079 172.17.0.2:54325      7233    (TID 789)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.079 172.17.0.2:54325      7233    (TID 789)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.091 172.17.0.2:54325      7233    (TID 788)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 372.0 (TID 788). 9974 bytes result sent to driver\n",
      "10-20 14:47:16.092 172.17.0.2:54325      7233    (TID 789)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 372.0 (TID 789). 9974 bytes result sent to driver\n",
      "10-20 14:47:16.092 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 372.0 (TID 788) in 27 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.093 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 372.0 (TID 789) in 28 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.094 172.17.0.2:54325      7233    (TID 790)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 372.0 (TID 790). 10017 bytes result sent to driver\n",
      "10-20 14:47:16.095 172.17.0.2:54325      7233    (TID 787)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 372.0 (TID 787). 9974 bytes result sent to driver\n",
      "10-20 14:47:16.095 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 372.0 (TID 790) in 30 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.096 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 372.0 (TID 787) in 31 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.096 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.096 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 372 (collect at treeModels.scala:514) finished in 0.036 s\n",
      "10-20 14:47:16.096 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 236 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:16.097 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 372: Stage finished\n",
      "10-20 14:47:16.097 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 236 finished: collect at treeModels.scala:514, took 0.077502 s\n",
      "10-20 14:47:16.102 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:16.118 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:519\n",
      "10-20 14:47:16.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 237 (parquet at treeModels.scala:519) with 1 output partitions\n",
      "10-20 14:47:16.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 373 (parquet at treeModels.scala:519)\n",
      "10-20 14:47:16.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:16.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:16.119 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 373 (MapPartitionsRDD[919] at parquet at treeModels.scala:519), which has no missing parents\n",
      "10-20 14:47:16.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_550 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:47:16.124 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_550_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:16.125 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_550_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:16.125 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 550 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.125 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 373 (MapPartitionsRDD[919] at parquet at treeModels.scala:519) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:16.125 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 373.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:16.126 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 373.0 (TID 791) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.126 172.17.0.2:54325      7233    (TID 791)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 373.0 (TID 791)\n",
      "10-20 14:47:16.132 172.17.0.2:54325      7233    (TID 791)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 373.0 (TID 791). 2376 bytes result sent to driver\n",
      "10-20 14:47:16.133 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 373.0 (TID 791) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:16.133 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 373.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.133 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 373 (parquet at treeModels.scala:519) finished in 0.014 s\n",
      "10-20 14:47:16.134 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 237 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:16.134 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 373: Stage finished\n",
      "10-20 14:47:16.134 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 237 finished: parquet at treeModels.scala:519, took 0.015208 s\n",
      "10-20 14:47:16.184 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:16.184 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:16.184 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, nodeData: struct<id: int, prediction: double, impurity: double, impurityStats: array<double>, rawCount: bigint ... 7 more fields>>\n",
      "10-20 14:47:16.186 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_551 stored as values in memory (estimated size 179.3 KiB, free 433.1 MiB)\n",
      "10-20 14:47:16.200 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_544_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:16.202 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_547_piece0 on 95675304fa2d:39429 in memory (size: 8.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:16.203 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_543_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:16.204 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_541_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.205 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_545_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.207 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_542_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.208 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_548_piece0 on 95675304fa2d:39429 in memory (size: 9.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.209 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_549_piece0 on 95675304fa2d:39429 in memory (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.210 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_550_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.212 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_551_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:16.212 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_551_piece0 in memory on 95675304fa2d:39429 (size: 29.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.213 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 551 from rdd at treeModels.scala:530\n",
      "10-20 14:47:16.213 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4214077 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:16.243 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:536\n",
      "10-20 14:47:16.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 925 (map at treeModels.scala:531) as input to shuffle 136\n",
      "10-20 14:47:16.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 238 (sortByKey at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:47:16.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 375 (sortByKey at treeModels.scala:536)\n",
      "10-20 14:47:16.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 374)\n",
      "10-20 14:47:16.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 374)\n",
      "10-20 14:47:16.244 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 374 (MapPartitionsRDD[925] at map at treeModels.scala:531), which has no missing parents\n",
      "10-20 14:47:16.245 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_552 stored as values in memory (estimated size 25.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:16.246 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_552_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 433.8 MiB)\n",
      "10-20 14:47:16.246 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_552_piece0 in memory on 95675304fa2d:39429 (size: 9.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.247 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 552 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.247 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 374 (MapPartitionsRDD[925] at map at treeModels.scala:531) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:16.247 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 374.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:16.248 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 374.0 (TID 792) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.248 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 374.0 (TID 793) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.248 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 374.0 (TID 794) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.248 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 374.0 (TID 795) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.248 172.17.0.2:54325      7233    (TID 792)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 374.0 (TID 792)\n",
      "10-20 14:47:16.248 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 374.0 (TID 795)\n",
      "10-20 14:47:16.251 172.17.0.2:54325      7233    (TID 793)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 374.0 (TID 793)\n",
      "10-20 14:47:16.253 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 374.0 (TID 794)\n",
      "10-20 14:47:16.270 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 11.179808 ms\n",
      "10-20 14:47:16.293 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 16.835583 ms\n",
      "10-20 14:47:16.295 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00002-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-19765, partition values: [empty row]\n",
      "10-20 14:47:16.295 172.17.0.2:54325      7233    (TID 792)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00000-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-20045, partition values: [empty row]\n",
      "10-20 14:47:16.295 172.17.0.2:54325      7233    (TID 793)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00001-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-20009, partition values: [empty row]\n",
      "10-20 14:47:16.297 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00003-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-19276, partition values: [empty row]\n",
      "10-20 14:47:16.299 172.17.0.2:54325      7233    (TID 792)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 307 records.\n",
      "10-20 14:47:16.301 172.17.0.2:54325      7233    (TID 792)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:16.304 172.17.0.2:54325      7233    (TID 793)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 311 records.\n",
      "10-20 14:47:16.312 172.17.0.2:54325      7233    (TID 792)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 10 ms. row count = 307\n",
      "10-20 14:47:16.313 172.17.0.2:54325      7233    (TID 793)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:16.314 172.17.0.2:54325      7233    (TID 793)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 311\n",
      "10-20 14:47:16.314 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 289 records.\n",
      "10-20 14:47:16.316 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:16.316 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 289\n",
      "10-20 14:47:16.329 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 301 records.\n",
      "10-20 14:47:16.341 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:16.343 172.17.0.2:54325      7233    (TID 795)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 374.0 (TID 795). 1624 bytes result sent to driver\n",
      "10-20 14:47:16.344 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 374.0 (TID 795) in 96 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.344 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 301\n",
      "10-20 14:47:16.358 172.17.0.2:54325      7233    (TID 792)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 374.0 (TID 792). 1624 bytes result sent to driver\n",
      "10-20 14:47:16.359 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 374.0 (TID 792) in 111 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.370 172.17.0.2:54325      7233    (TID 794)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 374.0 (TID 794). 1624 bytes result sent to driver\n",
      "10-20 14:47:16.371 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 374.0 (TID 794) in 123 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.373 172.17.0.2:54325      7233    (TID 793)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 374.0 (TID 793). 1624 bytes result sent to driver\n",
      "10-20 14:47:16.373 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 374.0 (TID 793) in 125 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.373 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 374.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 374 (map at treeModels.scala:531) finished in 0.129 s\n",
      "10-20 14:47:16.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:16.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:16.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 375)\n",
      "10-20 14:47:16.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:16.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 375 (MapPartitionsRDD[929] at sortByKey at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:47:16.375 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_553 stored as values in memory (estimated size 27.4 KiB, free 433.7 MiB)\n",
      "10-20 14:47:16.376 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_553_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:16.376 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_553_piece0 in memory on 95675304fa2d:39429 (size: 10.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 553 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.378 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 375 (MapPartitionsRDD[929] at sortByKey at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:16.378 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 375.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:16.378 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 375.0 (TID 796) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.378 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 375.0 (TID 797) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.378 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 375.0 (TID 798) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.379 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 375.0 (TID 799) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.379 172.17.0.2:54325      7233    (TID 798)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 375.0 (TID 798)\n",
      "10-20 14:47:16.379 172.17.0.2:54325      7233    (TID 799)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 375.0 (TID 799)\n",
      "10-20 14:47:16.380 172.17.0.2:54325      7233    (TID 797)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 375.0 (TID 797)\n",
      "10-20 14:47:16.382 172.17.0.2:54325      7233    (TID 796)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 375.0 (TID 796)\n",
      "10-20 14:47:16.385 172.17.0.2:54325      7233    (TID 799)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.8 KiB) non-empty blocks including 4 (23.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.385 172.17.0.2:54325      7233    (TID 799)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.387 172.17.0.2:54325      7233    (TID 798)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (24.3 KiB) non-empty blocks including 4 (24.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.387 172.17.0.2:54325      7233    (TID 798)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.387 172.17.0.2:54325      7233    (TID 797)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.388 172.17.0.2:54325      7233    (TID 797)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.389 172.17.0.2:54325      7233    (TID 796)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.389 172.17.0.2:54325      7233    (TID 796)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.442 172.17.0.2:54325      7233    (TID 798)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 375.0 (TID 798). 2015 bytes result sent to driver\n",
      "10-20 14:47:16.444 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 375.0 (TID 798) in 66 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.444 172.17.0.2:54325      7233    (TID 796)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 375.0 (TID 796). 2015 bytes result sent to driver\n",
      "10-20 14:47:16.445 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 375.0 (TID 796) in 67 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.442 172.17.0.2:54325      7233    (TID 799)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 375.0 (TID 799). 2015 bytes result sent to driver\n",
      "10-20 14:47:16.447 172.17.0.2:54325      7233    (TID 797)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 375.0 (TID 797). 2015 bytes result sent to driver\n",
      "10-20 14:47:16.448 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 375.0 (TID 799) in 70 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.448 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 375.0 (TID 797) in 70 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.449 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 375 (sortByKey at treeModels.scala:536) finished in 0.075 s\n",
      "10-20 14:47:16.449 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 375.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.449 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 238 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:16.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 375: Stage finished\n",
      "10-20 14:47:16.450 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 238 finished: sortByKey at treeModels.scala:536, took 0.206336 s\n",
      "10-20 14:47:16.456 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:536\n",
      "10-20 14:47:16.456 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 927 (map at treeModels.scala:533) as input to shuffle 137\n",
      "10-20 14:47:16.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 239 (collect at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:47:16.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 378 (collect at treeModels.scala:536)\n",
      "10-20 14:47:16.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 377)\n",
      "10-20 14:47:16.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 377)\n",
      "10-20 14:47:16.457 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 377 (MapPartitionsRDD[927] at map at treeModels.scala:533), which has no missing parents\n",
      "10-20 14:47:16.460 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_554 stored as values in memory (estimated size 26.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:16.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_554_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 433.7 MiB)\n",
      "10-20 14:47:16.461 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_554_piece0 in memory on 95675304fa2d:39429 (size: 10.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.461 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 554 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.462 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 377 (MapPartitionsRDD[927] at map at treeModels.scala:533) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:16.462 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 377.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:16.463 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 377.0 (TID 800) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.463 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 377.0 (TID 801) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.463 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 377.0 (TID 802) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.463 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 377.0 (TID 803) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.464 172.17.0.2:54325      7233    (TID 802)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 377.0 (TID 802)\n",
      "10-20 14:47:16.465 172.17.0.2:54325      7233    (TID 801)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 377.0 (TID 801)\n",
      "10-20 14:47:16.467 172.17.0.2:54325      7233    (TID 802)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (24.3 KiB) non-empty blocks including 4 (24.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.467 172.17.0.2:54325      7233    (TID 802)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.470 172.17.0.2:54325      7233    (TID 803)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 377.0 (TID 803)\n",
      "10-20 14:47:16.472 172.17.0.2:54325      7233    (TID 800)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 377.0 (TID 800)\n",
      "10-20 14:47:16.472 172.17.0.2:54325      7233    (TID 801)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.472 172.17.0.2:54325      7233    (TID 801)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.474 172.17.0.2:54325      7233    (TID 800)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.474 172.17.0.2:54325      7233    (TID 800)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.475 172.17.0.2:54325      7233    (TID 803)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.8 KiB) non-empty blocks including 4 (23.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.475 172.17.0.2:54325      7233    (TID 803)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.483 172.17.0.2:54325      7233    (TID 800)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 377.0 (TID 800). 1968 bytes result sent to driver\n",
      "10-20 14:47:16.484 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 377.0 (TID 800) in 21 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.485 172.17.0.2:54325      7233    (TID 801)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 377.0 (TID 801). 1968 bytes result sent to driver\n",
      "10-20 14:47:16.486 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 377.0 (TID 801) in 23 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.490 172.17.0.2:54325      7233    (TID 803)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 377.0 (TID 803). 1968 bytes result sent to driver\n",
      "10-20 14:47:16.490 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 377.0 (TID 803) in 27 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.492 172.17.0.2:54325      7233    (TID 802)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 377.0 (TID 802). 1968 bytes result sent to driver\n",
      "10-20 14:47:16.493 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 377.0 (TID 802) in 30 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.493 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 377.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 377 (map at treeModels.scala:533) finished in 0.034 s\n",
      "10-20 14:47:16.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:16.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:16.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 378)\n",
      "10-20 14:47:16.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:16.494 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 378 (MapPartitionsRDD[931] at values at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:47:16.495 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_555 stored as values in memory (estimated size 4.7 KiB, free 433.7 MiB)\n",
      "10-20 14:47:16.496 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_555_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.7 MiB)\n",
      "10-20 14:47:16.496 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_555_piece0 in memory on 95675304fa2d:39429 (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.496 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 555 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 378 (MapPartitionsRDD[931] at values at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:16.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 378.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:16.497 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 378.0 (TID 804) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.498 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 378.0 (TID 805) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.498 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 378.0 (TID 806) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.498 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 378.0 (TID 807) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.498 172.17.0.2:54325      7233    (TID 806)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 378.0 (TID 806)\n",
      "10-20 14:47:16.498 172.17.0.2:54325      7233    (TID 807)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 378.0 (TID 807)\n",
      "10-20 14:47:16.498 172.17.0.2:54325      7233    (TID 805)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 378.0 (TID 805)\n",
      "10-20 14:47:16.500 172.17.0.2:54325      7233    (TID 805)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (22.5 KiB) non-empty blocks including 4 (22.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.500 172.17.0.2:54325      7233    (TID 805)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.500 172.17.0.2:54325      7233    (TID 807)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (21.6 KiB) non-empty blocks including 4 (21.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.500 172.17.0.2:54325      7233    (TID 807)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.500 172.17.0.2:54325      7233    (TID 804)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 378.0 (TID 804)\n",
      "10-20 14:47:16.502 172.17.0.2:54325      7233    (TID 804)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (21.7 KiB) non-empty blocks including 4 (21.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.505 172.17.0.2:54325      7233    (TID 807)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 378.0 (TID 807). 29759 bytes result sent to driver\n",
      "10-20 14:47:16.507 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 378.0 (TID 807) in 9 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:16.505 172.17.0.2:54325      7233    (TID 804)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:47:16.508 172.17.0.2:54325      7233    (TID 806)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (21.7 KiB) non-empty blocks including 4 (21.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:16.508 172.17.0.2:54325      7233    (TID 806)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:16.510 172.17.0.2:54325      7233    (TID 805)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 378.0 (TID 805). 31102 bytes result sent to driver\n",
      "10-20 14:47:16.511 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 378.0 (TID 805) in 14 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:16.512 172.17.0.2:54325      7233    (TID 804)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 378.0 (TID 804). 30636 bytes result sent to driver\n",
      "10-20 14:47:16.513 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 378.0 (TID 804) in 16 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:16.513 172.17.0.2:54325      7233    (TID 806)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 378.0 (TID 806). 30092 bytes result sent to driver\n",
      "10-20 14:47:16.514 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 378.0 (TID 806) in 16 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:16.514 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 378.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 378 (collect at treeModels.scala:536) finished in 0.021 s\n",
      "10-20 14:47:16.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 239 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:16.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 378: Stage finished\n",
      "10-20 14:47:16.515 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 239 finished: collect at treeModels.scala:536, took 0.059537 s\n",
      "10-20 14:47:16.528 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [3c782ad5] training finished\n",
      "10-20 14:47:16.529 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [609a3e68] training finished\n",
      "10-20 14:47:16.896 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:16.896 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:16.896 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<fnlwgt: double, age: double, capital_gain: double, capital_loss: double, hours_per_week: double ... 3 more fields>\n",
      "10-20 14:47:16.905 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.271523 ms\n",
      "10-20 14:47:16.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_556 stored as values in memory (estimated size 177.8 KiB, free 433.5 MiB)\n",
      "10-20 14:47:16.911 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_556_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:16.911 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_556_piece0 in memory on 95675304fa2d:39429 (size: 28.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.912 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 556 from head at Imputer.scala:258\n",
      "10-20 14:47:16.912 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:16.916 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 14:47:16.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 240 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 14:47:16.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 379 (head at Imputer.scala:258)\n",
      "10-20 14:47:16.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:16.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:16.916 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 379 (MapPartitionsRDD[935] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 14:47:16.920 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_557 stored as values in memory (estimated size 14.0 KiB, free 433.5 MiB)\n",
      "10-20 14:47:16.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_557_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:16.921 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_557_piece0 in memory on 95675304fa2d:39429 (size: 5.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:16.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 557 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:16.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 379 (MapPartitionsRDD[935] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:16.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 379.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:16.922 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 379.0 (TID 808) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4983 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:16.922 172.17.0.2:54325      7233    (TID 808)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 379.0 (TID 808)\n",
      "10-20 14:47:16.926 172.17.0.2:54325      7233    (TID 808)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/data/part-00000-00523588-2aad-476c-bf4a-827327bc5b66-c000.snappy.parquet, range: 0-1479, partition values: [empty row]\n",
      "10-20 14:47:16.930 172.17.0.2:54325      7233    (TID 808)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 379.0 (TID 808). 1700 bytes result sent to driver\n",
      "10-20 14:47:16.931 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 379.0 (TID 808) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:16.931 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:16.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 379 (head at Imputer.scala:258) finished in 0.015 s\n",
      "10-20 14:47:16.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 240 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:16.931 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 379: Stage finished\n",
      "10-20 14:47:16.932 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 240 finished: head at Imputer.scala:258, took 0.015926 s\n",
      "10-20 14:47:17.643 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_557_piece0 on 95675304fa2d:39429 in memory (size: 5.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.643 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_552_piece0 on 95675304fa2d:39429 in memory (size: 9.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.644 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_553_piece0 on 95675304fa2d:39429 in memory (size: 10.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.646 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_551_piece0 on 95675304fa2d:39429 in memory (size: 29.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.647 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_546_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.648 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_554_piece0 on 95675304fa2d:39429 in memory (size: 10.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.649 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_416_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:17.649 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_555_piece0 on 95675304fa2d:39429 in memory (size: 2.6 KiB, free: 434.4 MiB)\n",
      "Metric name: areaUnderROC\n",
      "10-20 14:47:17.787 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:17.787 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:17.788 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:47:17.840 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 27.647766 ms\n",
      "10-20 14:47:17.841 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_558 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:17.845 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_558_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 14:47:17.845 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_558_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:17.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 558 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 14:47:17.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 943 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 139\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 944 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 138\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 241 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 382 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 381)\n",
      "10-20 14:47:17.894 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 381)\n",
      "10-20 14:47:17.895 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 380 (MapPartitionsRDD[943] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 14:47:17.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_559 stored as values in memory (estimated size 291.4 KiB, free 433.7 MiB)\n",
      "10-20 14:47:17.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_559_piece0 stored as bytes in memory (estimated size 128.9 KiB, free 433.6 MiB)\n",
      "10-20 14:47:17.903 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_559_piece0 in memory on 95675304fa2d:39429 (size: 128.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:17.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 559 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:17.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 380 (MapPartitionsRDD[943] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:17.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 380.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:17.905 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 380.0 (TID 809) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:17.905 172.17.0.2:54325      7233    (TID 809)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 380.0 (TID 809)\n",
      "10-20 14:47:17.937 172.17.0.2:54325      7233    (TID 809)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.228804 ms\n",
      "10-20 14:47:17.938 172.17.0.2:54325      7233    (TID 809)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:47:18.170 172.17.0.2:54325      7233    (TID 809)  WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "10-20 14:47:18.170 172.17.0.2:54325      7233    (TID 809)  WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "10-20 14:47:18.374 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_556_piece0 on 95675304fa2d:39429 in memory (size: 28.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.540 172.17.0.2:54325      7233    (TID 809)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 380.0 (TID 809). 2133 bytes result sent to driver\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 380.0 (TID 809) in 636 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 380.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 380 (map at BinaryClassificationMetrics.scala:48) finished in 0.646 s\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 381, ResultStage 382)\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:18.541 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 381 (ShuffledRDD[944] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 14:47:18.543 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_560 stored as values in memory (estimated size 5.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.544 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_560_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.544 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_560_piece0 in memory on 95675304fa2d:39429 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 560 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 381 (ShuffledRDD[944] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 381.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.545 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 381.0 (TID 810) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.546 172.17.0.2:54325      7233    (TID 810)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 381.0 (TID 810)\n",
      "10-20 14:47:18.548 172.17.0.2:54325      7233    (TID 810)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:18.548 172.17.0.2:54325      7233    (TID 810)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:18.563 172.17.0.2:54325      7233    (TID 810)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 381.0 (TID 810). 1462 bytes result sent to driver\n",
      "10-20 14:47:18.564 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 381.0 (TID 810) in 19 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.564 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 381.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 381 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.022 s\n",
      "10-20 14:47:18.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:18.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:18.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 382)\n",
      "10-20 14:47:18.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:18.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 382 (ShuffledRDD[945] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 14:47:18.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_561 stored as values in memory (estimated size 3.9 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_561_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.567 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_561_piece0 in memory on 95675304fa2d:39429 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 561 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 382 (ShuffledRDD[945] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 382.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.568 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 382.0 (TID 811) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.568 172.17.0.2:54325      7233    (TID 811)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 382.0 (TID 811)\n",
      "10-20 14:47:18.570 172.17.0.2:54325      7233    (TID 811)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:18.570 172.17.0.2:54325      7233    (TID 811)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:18.594 172.17.0.2:54325      7233    (TID 811)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 382.0 (TID 811). 1305 bytes result sent to driver\n",
      "10-20 14:47:18.595 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 382.0 (TID 811) in 27 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.595 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 382.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 382 (count at BinaryClassificationMetrics.scala:197) finished in 0.030 s\n",
      "10-20 14:47:18.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 241 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:18.596 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 382: Stage finished\n",
      "10-20 14:47:18.596 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 241 finished: count at BinaryClassificationMetrics.scala:197, took 0.702139 s\n",
      "10-20 14:47:18.604 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 14:47:18.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 242 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 14:47:18.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 385 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 14:47:18.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 384)\n",
      "10-20 14:47:18.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:18.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 385 (MapPartitionsRDD[948] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 14:47:18.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_562 stored as values in memory (estimated size 5.6 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_562_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.607 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_562_piece0 in memory on 95675304fa2d:39429 (size: 3.0 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 562 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 385 (MapPartitionsRDD[948] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 385.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.608 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 385.0 (TID 812) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.608 172.17.0.2:54325      7233    (TID 812)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 385.0 (TID 812)\n",
      "10-20 14:47:18.611 172.17.0.2:54325      7233    (TID 812)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:18.611 172.17.0.2:54325      7233    (TID 812)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:18.633 172.17.0.2:54325      7233    (TID 812)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 385.0 (TID 812). 1448 bytes result sent to driver\n",
      "10-20 14:47:18.633 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 385.0 (TID 812) in 25 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.633 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 385 (collect at BinaryClassificationMetrics.scala:237) finished in 0.029 s\n",
      "10-20 14:47:18.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 242 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:18.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 385: Stage finished\n",
      "10-20 14:47:18.634 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 242 finished: collect at BinaryClassificationMetrics.scala:237, took 0.029661 s\n",
      "10-20 14:47:18.635 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 1552.0, numNeg: 4933.0}\n",
      "10-20 14:47:18.646 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 14:47:18.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 243 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 14:47:18.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 388 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 14:47:18.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 387)\n",
      "10-20 14:47:18.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:18.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 388 (MapPartitionsRDD[953] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 14:47:18.649 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_563 stored as values in memory (estimated size 7.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.649 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_563_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.649 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_563_piece0 in memory on 95675304fa2d:39429 (size: 3.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 563 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 388 (MapPartitionsRDD[953] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 388.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.650 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 388.0 (TID 813) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.651 172.17.0.2:54325      7233    (TID 813)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 388.0 (TID 813)\n",
      "10-20 14:47:18.655 172.17.0.2:54325      7233    (TID 813)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:18.655 172.17.0.2:54325      7233    (TID 813)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:18.685 172.17.0.2:54325      7233    (TID 813)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_949_0 stored as values in memory (estimated size 98.8 KiB, free 433.7 MiB)\n",
      "10-20 14:47:18.686 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_949_0 in memory on 95675304fa2d:39429 (size: 98.8 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:18.693 172.17.0.2:54325      7233    (TID 813)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 388.0 (TID 813). 1524 bytes result sent to driver\n",
      "10-20 14:47:18.694 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 388.0 (TID 813) in 44 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.694 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.695 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 388 (collect at AreaUnderCurve.scala:44) finished in 0.047 s\n",
      "10-20 14:47:18.695 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 243 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:18.695 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 388: Stage finished\n",
      "10-20 14:47:18.695 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 243 finished: collect at AreaUnderCurve.scala:44, took 0.049259 s\n",
      "10-20 14:47:18.697 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 949 from persistence list\n",
      "Metric value: 0.8998987854779826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:47:18.697 172.17.0.2:54325      7233   d-pool-185  INFO org.apache.spark.storage.BlockManager: Removing RDD 949\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import (\n",
    "    PipelineModel\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "pipeline_model = PipelineModel.load(model_path)\n",
    "train_df_pred = pipeline_model.transform(train_df)\n",
    "val_df_pred = pipeline_model.transform(val_df)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'Metric name: {evaluator.getMetricName()}')\n",
    "print(f'Metric value: {evaluator.evaluate(val_df_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13502a6-0691-4aae-8c29-52b80a5e6ca1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27c08dc4-f8f9-40ca-89e6-4b7e8f935c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:47:18.730 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:18.786 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_564 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:18.790 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_564_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:18.790 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_564_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.791 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 564 from textFile at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:47:18.827 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at PythonRDD.scala:166\n",
      "10-20 14:47:18.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 244 (runJob at PythonRDD.scala:166) with 1 output partitions\n",
      "10-20 14:47:18.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 389 (runJob at PythonRDD.scala:166)\n",
      "10-20 14:47:18.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:18.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:18.834 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 389 (PythonRDD[956] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "10-20 14:47:18.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_565 stored as values in memory (estimated size 6.7 KiB, free 433.6 MiB)\n",
      "10-20 14:47:18.838 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_565_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:18.839 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_565_piece0 in memory on 95675304fa2d:39429 (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 565 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 389 (PythonRDD[956] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.841 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 389.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.842 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 389.0 (TID 814) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4541 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.842 172.17.0.2:54325      7233    (TID 814)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 389.0 (TID 814)\n",
      "10-20 14:47:18.850 172.17.0.2:54325      7233    (TID 814)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/metadata/part-00000:0+725\n",
      "10-20 14:47:18.862 172.17.0.2:54325      7233    (TID 814)  INFO org.apache.spark.api.python.PythonRunner: Times: total = 9, boot = 5, init = 4, finish = 0\n",
      "10-20 14:47:18.864 172.17.0.2:54325      7233    (TID 814)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 389.0 (TID 814). 2128 bytes result sent to driver\n",
      "10-20 14:47:18.864 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 389.0 (TID 814) in 23 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.865 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 389 (runJob at PythonRDD.scala:166) finished in 0.030 s\n",
      "10-20 14:47:18.866 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 244 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:18.866 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 389: Stage finished\n",
      "10-20 14:47:18.866 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 244 finished: runJob at PythonRDD.scala:166, took 0.038175 s\n",
      "10-20 14:47:18.875 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_566 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:47:18.902 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_566_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:18.902 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_566_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:18.903 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 566 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:18.903 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_559_piece0 on 95675304fa2d:39429 in memory (size: 128.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.904 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_563_piece0 on 95675304fa2d:39429 in memory (size: 3.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.905 172.17.0.2:54325      7233   d-pool-199  INFO org.apache.spark.storage.BlockManager: Removing RDD 949\n",
      "10-20 14:47:18.906 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_562_piece0 on 95675304fa2d:39429 in memory (size: 3.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.908 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_565_piece0 on 95675304fa2d:39429 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.909 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_561_piece0 on 95675304fa2d:39429 in memory (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.910 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_560_piece0 on 95675304fa2d:39429 in memory (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.912 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_558_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.940 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:18.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 245 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:18.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 390 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:18.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:18.941 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:18.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 390 (outputs/income_gbt_spark/metadata MapPartitionsRDD[958] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:18.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_567 stored as values in memory (estimated size 4.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:18.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_567_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:18.944 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_567_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.944 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 567 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 390 (outputs/income_gbt_spark/metadata MapPartitionsRDD[958] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.945 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 390.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.946 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 390.0 (TID 815) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4541 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.946 172.17.0.2:54325      7233    (TID 815)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 390.0 (TID 815)\n",
      "10-20 14:47:18.949 172.17.0.2:54325      7233    (TID 815)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/metadata/part-00000:0+725\n",
      "10-20 14:47:18.950 172.17.0.2:54325      7233    (TID 815)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 390.0 (TID 815). 1653 bytes result sent to driver\n",
      "10-20 14:47:18.951 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 390.0 (TID 815) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.951 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 390.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.951 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 390 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:18.951 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 245 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:18.951 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 390: Stage finished\n",
      "10-20 14:47:18.952 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 245 finished: first at ReadWrite.scala:587, took 0.011245 s\n",
      "10-20 14:47:18.953 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_568 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.958 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_568_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.959 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_568_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.959 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 568 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:18.982 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:18.982 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 246 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:18.982 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 391 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:18.982 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:18.982 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:18.983 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 391 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[960] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:18.984 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_569 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_569_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:18.985 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_569_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 569 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:18.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 391 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[960] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:18.986 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 391.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:18.987 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 391.0 (TID 816) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4572 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:18.987 172.17.0.2:54325      7233    (TID 816)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 391.0 (TID 816)\n",
      "10-20 14:47:18.989 172.17.0.2:54325      7233    (TID 816)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata/part-00000:0+479\n",
      "10-20 14:47:18.991 172.17.0.2:54325      7233    (TID 816)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 391.0 (TID 816). 1407 bytes result sent to driver\n",
      "10-20 14:47:18.991 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 391.0 (TID 816) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:18.991 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 391.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:18.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 391 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:18.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 246 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:18.992 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 391: Stage finished\n",
      "10-20 14:47:18.993 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 246 finished: first at ReadWrite.scala:587, took 0.010728 s\n",
      "10-20 14:47:18.994 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_570 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:18.998 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_570_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:18.999 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_570_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:18.999 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 570 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.016 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 247 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 392 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 392 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[962] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_571 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:19.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_571_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:19.019 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_571_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 571 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata MapPartitionsRDD[962] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.020 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 392.0 (TID 817) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4572 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.020 172.17.0.2:54325      7233    (TID 817)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 392.0 (TID 817)\n",
      "10-20 14:47:19.022 172.17.0.2:54325      7233    (TID 817)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/metadata/part-00000:0+479\n",
      "10-20 14:47:19.024 172.17.0.2:54325      7233    (TID 817)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 392.0 (TID 817). 1407 bytes result sent to driver\n",
      "10-20 14:47:19.024 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 392.0 (TID 817) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.024 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.025 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 392 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:19.025 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 247 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.025 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 392: Stage finished\n",
      "10-20 14:47:19.025 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 247 finished: first at ReadWrite.scala:587, took 0.009005 s\n",
      "10-20 14:47:19.039 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:19.058 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at Imputer.scala:320\n",
      "10-20 14:47:19.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 248 (parquet at Imputer.scala:320) with 1 output partitions\n",
      "10-20 14:47:19.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 393 (parquet at Imputer.scala:320)\n",
      "10-20 14:47:19.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 393 (MapPartitionsRDD[964] at parquet at Imputer.scala:320), which has no missing parents\n",
      "10-20 14:47:19.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_572 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_572_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.065 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_572_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 572 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 393 (MapPartitionsRDD[964] at parquet at Imputer.scala:320) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.065 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 393.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.066 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 393.0 (TID 818) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4732 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.066 172.17.0.2:54325      7233    (TID 818)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 393.0 (TID 818)\n",
      "10-20 14:47:19.072 172.17.0.2:54325      7233    (TID 818)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 393.0 (TID 818). 1774 bytes result sent to driver\n",
      "10-20 14:47:19.072 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 393.0 (TID 818) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.072 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 393.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 393 (parquet at Imputer.scala:320) finished in 0.015 s\n",
      "10-20 14:47:19.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 248 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.074 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 393: Stage finished\n",
      "10-20 14:47:19.075 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 248 finished: parquet at Imputer.scala:320, took 0.017161 s\n",
      "10-20 14:47:19.088 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_573 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.125 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_573_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.126 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_573_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.126 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 573 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.146 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 249 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 394 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.147 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 394 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[966] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_574 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.149 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_574_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.149 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_574_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 574 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 394 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[966] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 394.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.150 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 394.0 (TID 819) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.151 172.17.0.2:54325      7233    (TID 819)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 394.0 (TID 819)\n",
      "10-20 14:47:19.152 172.17.0.2:54325      7233    (TID 819)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata/part-00000:0+357\n",
      "10-20 14:47:19.153 172.17.0.2:54325      7233    (TID 819)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 394.0 (TID 819). 1242 bytes result sent to driver\n",
      "10-20 14:47:19.154 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 394.0 (TID 819) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.154 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 394.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 394 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:19.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 249 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.157 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 394: Stage finished\n",
      "10-20 14:47:19.158 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 249 finished: first at ReadWrite.scala:587, took 0.011620 s\n",
      "10-20 14:47:19.159 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_575 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.165 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_575_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.165 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_575_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.165 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 575 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.180 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 250 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 395 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.181 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 395 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[968] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.182 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_576 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_576_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.183 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_576_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 576 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 395 (outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata MapPartitionsRDD[968] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.183 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 395.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.184 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 395.0 (TID 820) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.184 172.17.0.2:54325      7233    (TID 820)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 395.0 (TID 820)\n",
      "10-20 14:47:19.185 172.17.0.2:54325      7233    (TID 820)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/metadata/part-00000:0+357\n",
      "10-20 14:47:19.186 172.17.0.2:54325      7233    (TID 820)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 395.0 (TID 820). 1199 bytes result sent to driver\n",
      "10-20 14:47:19.187 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 395.0 (TID 820) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.187 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 395.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.187 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 395 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:19.187 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 250 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.187 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 395: Stage finished\n",
      "10-20 14:47:19.187 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 250 finished: first at ReadWrite.scala:587, took 0.007211 s\n",
      "10-20 14:47:19.192 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:19.208 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:19.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 251 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:19.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 396 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:19.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.208 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.209 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 396 (MapPartitionsRDD[970] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:19.213 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_577 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:19.213 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_577_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:47:19.213 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_577_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 577 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 396 (MapPartitionsRDD[970] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 396.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.214 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 396.0 (TID 821) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.214 172.17.0.2:54325      7233    (TID 821)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 396.0 (TID 821)\n",
      "10-20 14:47:19.220 172.17.0.2:54325      7233    (TID 821)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 396.0 (TID 821). 1709 bytes result sent to driver\n",
      "10-20 14:47:19.220 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 396.0 (TID 821) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.220 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 396 (parquet at StringIndexer.scala:523) finished in 0.011 s\n",
      "10-20 14:47:19.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 251 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.220 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 396: Stage finished\n",
      "10-20 14:47:19.223 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 251 finished: parquet at StringIndexer.scala:523, took 0.015236 s\n",
      "10-20 14:47:19.233 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:19.233 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:19.233 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:19.237 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_578 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.244 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_578_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.244 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_578_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.244 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 578 from head at StringIndexer.scala:524\n",
      "10-20 14:47:19.245 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:19.248 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:19.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 252 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:19.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 397 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:19.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 397 (MapPartitionsRDD[973] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:19.251 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_579 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.272 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_579_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.273 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_579_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.273 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_568_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 579 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 397 (MapPartitionsRDD[973] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.273 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 397.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.274 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 397.0 (TID 822) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.274 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_576_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.274 172.17.0.2:54325      7233    (TID 822)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 397.0 (TID 822)\n",
      "10-20 14:47:19.275 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_574_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.276 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_566_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.276 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_575_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.277 172.17.0.2:54325      7233    (TID 822)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/01_StringIndexer_953b10f1ecdf/data/part-00000-312667f8-74ef-4c63-9330-da0e1d70ebe1-c000.snappy.parquet, range: 0-750, partition values: [empty row]\n",
      "10-20 14:47:19.278 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_573_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.278 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_577_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.279 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_569_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.280 172.17.0.2:54325      7233    (TID 822)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:19.280 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_571_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.281 172.17.0.2:54325      7233    (TID 822)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:19.281 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_567_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.281 172.17.0.2:54325      7233    (TID 822)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:19.282 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_570_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.282 172.17.0.2:54325      7233    (TID 822)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 397.0 (TID 822). 1804 bytes result sent to driver\n",
      "10-20 14:47:19.283 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 397.0 (TID 822) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.283 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 397.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 397 (head at StringIndexer.scala:524) finished in 0.034 s\n",
      "10-20 14:47:19.283 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 252 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.284 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 397: Stage finished\n",
      "10-20 14:47:19.284 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_572_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.285 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 252 finished: head at StringIndexer.scala:524, took 0.036386 s\n",
      "10-20 14:47:19.287 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_580 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.292 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_580_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.292 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_580_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.292 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 580 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.307 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.307 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 253 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 398 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 398 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[975] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.308 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_581 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.309 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_581_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.309 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_581_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.310 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 581 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.310 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 398 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[975] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.310 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 398.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.310 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 398.0 (TID 823) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.311 172.17.0.2:54325      7233    (TID 823)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 398.0 (TID 823)\n",
      "10-20 14:47:19.312 172.17.0.2:54325      7233    (TID 823)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata/part-00000:0+357\n",
      "10-20 14:47:19.313 172.17.0.2:54325      7233    (TID 823)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 398.0 (TID 823). 1285 bytes result sent to driver\n",
      "10-20 14:47:19.313 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 398.0 (TID 823) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.313 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 398 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:19.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 253 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 398: Stage finished\n",
      "10-20 14:47:19.314 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 253 finished: first at ReadWrite.scala:587, took 0.007416 s\n",
      "10-20 14:47:19.316 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_582 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:47:19.320 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_582_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:19.320 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_582_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.321 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 582 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.336 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 254 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 399 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.337 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 399 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[977] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.337 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_583 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:19.337 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_583_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:19.338 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_583_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 583 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 399 (outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata MapPartitionsRDD[977] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 399.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.339 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 399.0 (TID 824) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.339 172.17.0.2:54325      7233    (TID 824)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 399.0 (TID 824)\n",
      "10-20 14:47:19.340 172.17.0.2:54325      7233    (TID 824)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/metadata/part-00000:0+357\n",
      "10-20 14:47:19.341 172.17.0.2:54325      7233    (TID 824)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 399.0 (TID 824). 1242 bytes result sent to driver\n",
      "10-20 14:47:19.342 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 399.0 (TID 824) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.342 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.342 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 399 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:19.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 254 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.343 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 399: Stage finished\n",
      "10-20 14:47:19.343 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 254 finished: first at ReadWrite.scala:587, took 0.006787 s\n",
      "10-20 14:47:19.348 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:19.365 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:19.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 255 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:19.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 400 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:19.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.366 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 400 (MapPartitionsRDD[979] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:19.371 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_584 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_584_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.373 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_584_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 584 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 400 (MapPartitionsRDD[979] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 400.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.374 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 400.0 (TID 825) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.374 172.17.0.2:54325      7233    (TID 825)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 400.0 (TID 825)\n",
      "10-20 14:47:19.379 172.17.0.2:54325      7233    (TID 825)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 400.0 (TID 825). 1709 bytes result sent to driver\n",
      "10-20 14:47:19.380 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 400.0 (TID 825) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.380 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 400 (parquet at StringIndexer.scala:523) finished in 0.013 s\n",
      "10-20 14:47:19.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 255 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 400: Stage finished\n",
      "10-20 14:47:19.381 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 255 finished: parquet at StringIndexer.scala:523, took 0.015744 s\n",
      "10-20 14:47:19.389 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:19.389 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:19.389 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:19.394 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_585 stored as values in memory (estimated size 177.5 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.398 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_585_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.399 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_585_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.399 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 585 from head at StringIndexer.scala:524\n",
      "10-20 14:47:19.399 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:19.403 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:19.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 256 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:19.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 401 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:19.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.403 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 401 (MapPartitionsRDD[982] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:19.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_586 stored as values in memory (estimated size 8.9 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.405 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_586_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.406 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_586_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 586 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 401 (MapPartitionsRDD[982] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.406 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 401.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.407 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 401.0 (TID 826) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.407 172.17.0.2:54325      7233    (TID 826)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 401.0 (TID 826)\n",
      "10-20 14:47:19.409 172.17.0.2:54325      7233    (TID 826)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/02_StringIndexer_316a5d8f5bda/data/part-00000-d3728cbd-b627-4118-bc76-8c4f3fd84feb-c000.snappy.parquet, range: 0-813, partition values: [empty row]\n",
      "10-20 14:47:19.412 172.17.0.2:54325      7233    (TID 826)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:19.413 172.17.0.2:54325      7233    (TID 826)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:19.413 172.17.0.2:54325      7233    (TID 826)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:19.414 172.17.0.2:54325      7233    (TID 826)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 401.0 (TID 826). 1888 bytes result sent to driver\n",
      "10-20 14:47:19.415 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 401.0 (TID 826) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.415 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 401 (head at StringIndexer.scala:524) finished in 0.011 s\n",
      "10-20 14:47:19.415 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 256 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.416 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 401: Stage finished\n",
      "10-20 14:47:19.416 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 256 finished: head at StringIndexer.scala:524, took 0.013091 s\n",
      "10-20 14:47:19.419 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_587 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.423 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_587_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.424 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_587_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.424 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 587 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.488 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 257 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 402 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.489 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 402 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[984] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.490 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_588 stored as values in memory (estimated size 4.2 KiB, free 433.0 MiB)\n",
      "10-20 14:47:19.491 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_588_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.0 MiB)\n",
      "10-20 14:47:19.491 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_588_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.491 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 588 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 402 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[984] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.492 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.493 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 402.0 (TID 827) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.493 172.17.0.2:54325      7233    (TID 827)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 402.0 (TID 827)\n",
      "10-20 14:47:19.495 172.17.0.2:54325      7233    (TID 827)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata/part-00000:0+367\n",
      "10-20 14:47:19.496 172.17.0.2:54325      7233    (TID 827)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 402.0 (TID 827). 1295 bytes result sent to driver\n",
      "10-20 14:47:19.497 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 402.0 (TID 827) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.497 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 402 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:19.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 257 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.497 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished\n",
      "10-20 14:47:19.498 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 257 finished: first at ReadWrite.scala:587, took 0.009992 s\n",
      "10-20 14:47:19.499 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_589 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:19.504 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_589_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.504 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_589_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.505 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 589 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.520 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 258 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 403 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.521 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 403 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[986] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.522 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_590 stored as values in memory (estimated size 4.2 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.522 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_590_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.523 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_590_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 590 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 403 (outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata MapPartitionsRDD[986] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 403.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.524 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 403.0 (TID 828) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.524 172.17.0.2:54325      7233    (TID 828)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 403.0 (TID 828)\n",
      "10-20 14:47:19.525 172.17.0.2:54325      7233    (TID 828)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/metadata/part-00000:0+367\n",
      "10-20 14:47:19.526 172.17.0.2:54325      7233    (TID 828)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 403.0 (TID 828). 1295 bytes result sent to driver\n",
      "10-20 14:47:19.527 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 403.0 (TID 828) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.527 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 403 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:19.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 258 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.528 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 403: Stage finished\n",
      "10-20 14:47:19.528 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 258 finished: first at ReadWrite.scala:587, took 0.007790 s\n",
      "10-20 14:47:19.533 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:19.552 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:19.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 259 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:19.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 404 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:19.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.552 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 404 (MapPartitionsRDD[988] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:19.557 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_591 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.558 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_591_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.558 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_591_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 591 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 404 (MapPartitionsRDD[988] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 404.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.560 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 404.0 (TID 829) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.560 172.17.0.2:54325      7233    (TID 829)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 404.0 (TID 829)\n",
      "10-20 14:47:19.567 172.17.0.2:54325      7233    (TID 829)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 404.0 (TID 829). 1709 bytes result sent to driver\n",
      "10-20 14:47:19.567 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 404.0 (TID 829) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.567 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.568 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 404 (parquet at StringIndexer.scala:523) finished in 0.016 s\n",
      "10-20 14:47:19.568 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 259 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.568 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 404: Stage finished\n",
      "10-20 14:47:19.568 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 259 finished: parquet at StringIndexer.scala:523, took 0.016147 s\n",
      "10-20 14:47:19.578 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:19.578 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:19.578 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:19.583 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_592 stored as values in memory (estimated size 177.5 KiB, free 432.6 MiB)\n",
      "10-20 14:47:19.588 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_592_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.5 MiB)\n",
      "10-20 14:47:19.588 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_592_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.588 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 592 from head at StringIndexer.scala:524\n",
      "10-20 14:47:19.589 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:19.592 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:19.593 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 260 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:19.593 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 405 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:19.593 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.593 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.593 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 405 (MapPartitionsRDD[991] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:19.595 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_593 stored as values in memory (estimated size 8.9 KiB, free 432.5 MiB)\n",
      "10-20 14:47:19.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_593_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.5 MiB)\n",
      "10-20 14:47:19.597 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_593_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.597 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 593 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 405 (MapPartitionsRDD[991] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.598 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 405.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.598 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 405.0 (TID 830) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.598 172.17.0.2:54325      7233    (TID 830)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 405.0 (TID 830)\n",
      "10-20 14:47:19.601 172.17.0.2:54325      7233    (TID 830)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/03_StringIndexer_1dda4039763d/data/part-00000-b3761344-b391-40fd-946a-f95f69844a3d-c000.snappy.parquet, range: 0-743, partition values: [empty row]\n",
      "10-20 14:47:19.603 172.17.0.2:54325      7233    (TID 830)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:19.604 172.17.0.2:54325      7233    (TID 830)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:19.604 172.17.0.2:54325      7233    (TID 830)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:19.605 172.17.0.2:54325      7233    (TID 830)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 405.0 (TID 830). 1786 bytes result sent to driver\n",
      "10-20 14:47:19.606 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 405.0 (TID 830) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.606 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 405.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 405 (head at StringIndexer.scala:524) finished in 0.013 s\n",
      "10-20 14:47:19.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 260 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 405: Stage finished\n",
      "10-20 14:47:19.607 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 260 finished: head at StringIndexer.scala:524, took 0.014251 s\n",
      "10-20 14:47:19.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_594 stored as values in memory (estimated size 176.1 KiB, free 432.3 MiB)\n",
      "10-20 14:47:19.626 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_588_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.627 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_592_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.628 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_582_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.628 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_594_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.628 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_594_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.628 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_584_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.629 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 594 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.629 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_587_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.630 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_589_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.631 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_581_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.631 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_580_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.632 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_591_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.633 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_585_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.633 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_586_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.634 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_593_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.635 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_583_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.635 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_579_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.636 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_590_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.637 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_578_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.649 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 261 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 406 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 406 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[993] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_595 stored as values in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:19.651 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_595_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:19.651 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_595_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 595 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 406 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[993] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 406.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.652 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 406.0 (TID 831) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.653 172.17.0.2:54325      7233    (TID 831)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 406.0 (TID 831)\n",
      "10-20 14:47:19.654 172.17.0.2:54325      7233    (TID 831)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata/part-00000:0+359\n",
      "10-20 14:47:19.655 172.17.0.2:54325      7233    (TID 831)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 406.0 (TID 831). 1244 bytes result sent to driver\n",
      "10-20 14:47:19.656 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 406.0 (TID 831) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.656 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 406.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.656 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 406 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:19.656 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 261 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.656 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 406: Stage finished\n",
      "10-20 14:47:19.657 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 261 finished: first at ReadWrite.scala:587, took 0.007235 s\n",
      "10-20 14:47:19.658 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_596 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.662 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_596_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.663 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_596_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.663 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 596 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.679 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 262 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 407 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 407 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[995] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.680 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_597 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.682 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_597_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.682 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_597_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.682 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 597 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.682 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 407 (outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata MapPartitionsRDD[995] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.682 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 407.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.683 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 407.0 (TID 832) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.683 172.17.0.2:54325      7233    (TID 832)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 407.0 (TID 832)\n",
      "10-20 14:47:19.684 172.17.0.2:54325      7233    (TID 832)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/metadata/part-00000:0+359\n",
      "10-20 14:47:19.685 172.17.0.2:54325      7233    (TID 832)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 407.0 (TID 832). 1201 bytes result sent to driver\n",
      "10-20 14:47:19.686 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 407.0 (TID 832) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.686 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 407.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 407 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:19.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 262 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 407: Stage finished\n",
      "10-20 14:47:19.687 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 262 finished: first at ReadWrite.scala:587, took 0.008564 s\n",
      "10-20 14:47:19.693 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:19.710 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 263 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 408 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.711 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 408 (MapPartitionsRDD[997] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:19.716 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_598 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:19.718 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_598_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:19.719 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_598_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 598 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 408 (MapPartitionsRDD[997] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.721 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 408.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.721 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 408.0 (TID 833) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.721 172.17.0.2:54325      7233    (TID 833)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 408.0 (TID 833)\n",
      "10-20 14:47:19.730 172.17.0.2:54325      7233    (TID 833)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 408.0 (TID 833). 1709 bytes result sent to driver\n",
      "10-20 14:47:19.730 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 408.0 (TID 833) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.730 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 408.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.730 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 408 (parquet at StringIndexer.scala:523) finished in 0.019 s\n",
      "10-20 14:47:19.731 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 263 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.731 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 408: Stage finished\n",
      "10-20 14:47:19.731 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 263 finished: parquet at StringIndexer.scala:523, took 0.020249 s\n",
      "10-20 14:47:19.739 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:19.740 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:19.740 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:19.749 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_599 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.753 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_599_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.754 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_599_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.754 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 599 from head at StringIndexer.scala:524\n",
      "10-20 14:47:19.755 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:19.759 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:19.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 264 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:19.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 409 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:19.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.759 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 409 (MapPartitionsRDD[1000] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:19.762 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_600 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.763 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_600_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:19.764 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_600_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 600 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 409 (MapPartitionsRDD[1000] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.764 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 409.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.765 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 409.0 (TID 834) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.765 172.17.0.2:54325      7233    (TID 834)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 409.0 (TID 834)\n",
      "10-20 14:47:19.768 172.17.0.2:54325      7233    (TID 834)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/04_StringIndexer_831cdbbbf3e6/data/part-00000-be55257c-30ef-4e25-9b6e-6999c6391b1c-c000.snappy.parquet, range: 0-873, partition values: [empty row]\n",
      "10-20 14:47:19.771 172.17.0.2:54325      7233    (TID 834)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:19.771 172.17.0.2:54325      7233    (TID 834)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:19.771 172.17.0.2:54325      7233    (TID 834)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:19.772 172.17.0.2:54325      7233    (TID 834)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 409.0 (TID 834). 1969 bytes result sent to driver\n",
      "10-20 14:47:19.773 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 409.0 (TID 834) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.773 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 409.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 409 (head at StringIndexer.scala:524) finished in 0.013 s\n",
      "10-20 14:47:19.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 264 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 409: Stage finished\n",
      "10-20 14:47:19.774 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 264 finished: head at StringIndexer.scala:524, took 0.014786 s\n",
      "10-20 14:47:19.776 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_601 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.781 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_601_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.781 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_601_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.782 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 601 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.798 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 265 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 410 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.799 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 410 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[1002] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_602 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.800 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_602_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:19.800 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_602_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 602 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 410 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[1002] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.801 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 410.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.802 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 410.0 (TID 835) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.802 172.17.0.2:54325      7233    (TID 835)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 410.0 (TID 835)\n",
      "10-20 14:47:19.803 172.17.0.2:54325      7233    (TID 835)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata/part-00000:0+363\n",
      "10-20 14:47:19.804 172.17.0.2:54325      7233    (TID 835)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 410.0 (TID 835). 1291 bytes result sent to driver\n",
      "10-20 14:47:19.805 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 410.0 (TID 835) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.805 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 410.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 410 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:19.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 265 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.805 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 410: Stage finished\n",
      "10-20 14:47:19.805 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 265 finished: first at ReadWrite.scala:587, took 0.007033 s\n",
      "10-20 14:47:19.807 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_603 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.811 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_603_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.811 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_603_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.812 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 603 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.855 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.856 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 266 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.856 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 411 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.856 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.856 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.856 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 411 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[1004] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.856 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_604 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.857 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_604_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:19.857 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_604_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.858 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 604 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.859 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 411 (outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata MapPartitionsRDD[1004] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.859 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 411.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.859 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 411.0 (TID 836) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.860 172.17.0.2:54325      7233    (TID 836)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 411.0 (TID 836)\n",
      "10-20 14:47:19.861 172.17.0.2:54325      7233    (TID 836)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/metadata/part-00000:0+363\n",
      "10-20 14:47:19.862 172.17.0.2:54325      7233    (TID 836)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 411.0 (TID 836). 1248 bytes result sent to driver\n",
      "10-20 14:47:19.863 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 411.0 (TID 836) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.863 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 411.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 411 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:19.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 266 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 411: Stage finished\n",
      "10-20 14:47:19.864 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 266 finished: first at ReadWrite.scala:587, took 0.008296 s\n",
      "10-20 14:47:19.869 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:19.886 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:19.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 267 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:19.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 412 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:19.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.887 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 412 (MapPartitionsRDD[1006] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:19.891 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_605 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:19.892 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_605_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:19.892 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_605_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 605 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 412 (MapPartitionsRDD[1006] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.893 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 412.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.894 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 412.0 (TID 837) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.894 172.17.0.2:54325      7233    (TID 837)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 412.0 (TID 837)\n",
      "10-20 14:47:19.899 172.17.0.2:54325      7233    (TID 837)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 412.0 (TID 837). 1709 bytes result sent to driver\n",
      "10-20 14:47:19.900 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 412.0 (TID 837) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.900 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 412.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.900 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 412 (parquet at StringIndexer.scala:523) finished in 0.013 s\n",
      "10-20 14:47:19.901 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 267 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.901 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 412: Stage finished\n",
      "10-20 14:47:19.901 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 267 finished: parquet at StringIndexer.scala:523, took 0.014634 s\n",
      "10-20 14:47:19.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:19.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:19.907 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:19.912 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_606 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:19.917 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_606_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.917 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_606_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.917 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 606 from head at StringIndexer.scala:524\n",
      "10-20 14:47:19.917 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:19.921 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:19.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 268 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:19.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 413 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:19.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.921 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 413 (MapPartitionsRDD[1009] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:19.922 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_607 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.923 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_607_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:19.923 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_607_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.923 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 607 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.924 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 413 (MapPartitionsRDD[1009] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.924 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 413.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.924 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 413.0 (TID 838) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.925 172.17.0.2:54325      7233    (TID 838)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 413.0 (TID 838)\n",
      "10-20 14:47:19.928 172.17.0.2:54325      7233    (TID 838)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/05_StringIndexer_9b6468bf3c7c/data/part-00000-f5acbe82-b313-45fe-b7c1-42a0b5e492bd-c000.snappy.parquet, range: 0-712, partition values: [empty row]\n",
      "10-20 14:47:19.931 172.17.0.2:54325      7233    (TID 838)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:19.933 172.17.0.2:54325      7233    (TID 838)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:19.933 172.17.0.2:54325      7233    (TID 838)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:19.934 172.17.0.2:54325      7233    (TID 838)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 413.0 (TID 838). 1758 bytes result sent to driver\n",
      "10-20 14:47:19.935 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 413.0 (TID 838) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.935 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 413.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 413 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:47:19.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 268 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 413: Stage finished\n",
      "10-20 14:47:19.936 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 268 finished: head at StringIndexer.scala:524, took 0.015037 s\n",
      "10-20 14:47:19.938 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_608 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:19.943 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_608_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:47:19.943 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_608_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.944 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 608 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:19.961 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:19.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 269 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:19.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 414 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:19.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:19.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:19.961 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 414 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[1011] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:19.962 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_609 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:47:19.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_609_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:47:19.976 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_609_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.977 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_596_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 609 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:19.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 414 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[1011] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:19.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 414.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:19.978 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_607_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.978 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 414.0 (TID 839) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:19.979 172.17.0.2:54325      7233    (TID 839)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 414.0 (TID 839)\n",
      "10-20 14:47:19.979 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_595_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:19.980 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_603_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.981 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_604_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.982 172.17.0.2:54325      7233    (TID 839)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata/part-00000:0+347\n",
      "10-20 14:47:19.982 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_599_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.984 172.17.0.2:54325      7233    (TID 839)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 414.0 (TID 839). 1275 bytes result sent to driver\n",
      "10-20 14:47:19.984 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_600_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.984 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 414.0 (TID 839) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:19.984 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 414.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:19.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 414 (first at ReadWrite.scala:587) finished in 0.023 s\n",
      "10-20 14:47:19.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 269 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:19.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 414: Stage finished\n",
      "10-20 14:47:19.985 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 269 finished: first at ReadWrite.scala:587, took 0.024273 s\n",
      "10-20 14:47:19.986 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_601_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:19.987 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_606_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.987 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_610 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:47:19.988 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_597_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.989 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_594_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.990 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_602_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.992 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_605_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.993 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_598_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.994 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_610_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:19.994 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_610_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:19.995 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 610 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.022 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 270 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 415 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.022 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 415 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[1013] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_611 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.024 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_611_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.025 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_611_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.025 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 611 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.025 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 415 (outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata MapPartitionsRDD[1013] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.025 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 415.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.026 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 415.0 (TID 840) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.026 172.17.0.2:54325      7233    (TID 840)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 415.0 (TID 840)\n",
      "10-20 14:47:20.027 172.17.0.2:54325      7233    (TID 840)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/metadata/part-00000:0+347\n",
      "10-20 14:47:20.028 172.17.0.2:54325      7233    (TID 840)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 415.0 (TID 840). 1275 bytes result sent to driver\n",
      "10-20 14:47:20.029 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 415.0 (TID 840) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.029 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 415.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.029 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 415 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:20.029 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 270 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.029 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 415: Stage finished\n",
      "10-20 14:47:20.031 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 270 finished: first at ReadWrite.scala:587, took 0.008637 s\n",
      "10-20 14:47:20.036 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:20.053 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:20.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 271 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:20.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 416 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:20.054 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.054 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.054 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 416 (MapPartitionsRDD[1015] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:20.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_612 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:20.059 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_612_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:20.060 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_612_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.060 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 612 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 416 (MapPartitionsRDD[1015] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.061 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 416.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.061 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 416.0 (TID 841) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.062 172.17.0.2:54325      7233    (TID 841)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 416.0 (TID 841)\n",
      "10-20 14:47:20.067 172.17.0.2:54325      7233    (TID 841)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 416.0 (TID 841). 1709 bytes result sent to driver\n",
      "10-20 14:47:20.067 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 416.0 (TID 841) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.067 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 416.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 416 (parquet at StringIndexer.scala:523) finished in 0.014 s\n",
      "10-20 14:47:20.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 271 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.068 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 416: Stage finished\n",
      "10-20 14:47:20.068 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 271 finished: parquet at StringIndexer.scala:523, took 0.015189 s\n",
      "10-20 14:47:20.075 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:20.075 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:20.075 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:20.082 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_613 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.086 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_613_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.087 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_613_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.087 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 613 from head at StringIndexer.scala:524\n",
      "10-20 14:47:20.088 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:20.091 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:20.091 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 272 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:20.092 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 417 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:20.092 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.092 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.092 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 417 (MapPartitionsRDD[1018] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:20.093 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_614 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_614_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.094 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_614_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.094 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 614 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 417 (MapPartitionsRDD[1018] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.095 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 417.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.095 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 417.0 (TID 842) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.096 172.17.0.2:54325      7233    (TID 842)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 417.0 (TID 842)\n",
      "10-20 14:47:20.098 172.17.0.2:54325      7233    (TID 842)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/06_StringIndexer_e813f86872fb/data/part-00000-76b01275-3eb3-43f1-9a99-203ad286956c-c000.snappy.parquet, range: 0-725, partition values: [empty row]\n",
      "10-20 14:47:20.101 172.17.0.2:54325      7233    (TID 842)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:20.103 172.17.0.2:54325      7233    (TID 842)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:20.103 172.17.0.2:54325      7233    (TID 842)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:20.104 172.17.0.2:54325      7233    (TID 842)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 417.0 (TID 842). 1735 bytes result sent to driver\n",
      "10-20 14:47:20.105 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 417.0 (TID 842) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.105 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.106 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 417 (head at StringIndexer.scala:524) finished in 0.013 s\n",
      "10-20 14:47:20.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 272 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.107 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 417: Stage finished\n",
      "10-20 14:47:20.107 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 272 finished: head at StringIndexer.scala:524, took 0.015770 s\n",
      "10-20 14:47:20.110 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_615 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.116 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_615_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.117 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_615_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.117 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 615 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.139 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 273 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 418 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 418 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[1020] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.140 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_616 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.141 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_616_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.141 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_616_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.141 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 616 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.142 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 418 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[1020] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.142 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 418.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.143 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 418.0 (TID 843) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.143 172.17.0.2:54325      7233    (TID 843)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 418.0 (TID 843)\n",
      "10-20 14:47:20.144 172.17.0.2:54325      7233    (TID 843)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata/part-00000:0+345\n",
      "10-20 14:47:20.145 172.17.0.2:54325      7233    (TID 843)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 418.0 (TID 843). 1230 bytes result sent to driver\n",
      "10-20 14:47:20.145 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 418.0 (TID 843) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.145 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 418.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 418 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:20.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 273 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.146 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 418: Stage finished\n",
      "10-20 14:47:20.146 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 273 finished: first at ReadWrite.scala:587, took 0.007049 s\n",
      "10-20 14:47:20.148 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_617 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.197 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_617_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.198 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_617_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.198 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 617 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.222 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 274 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 419 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.222 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 419 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[1022] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.223 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_618 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.224 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_618_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.225 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_618_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.225 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 618 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.226 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 419 (outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata MapPartitionsRDD[1022] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.226 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 419.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.227 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 419.0 (TID 844) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.227 172.17.0.2:54325      7233    (TID 844)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 419.0 (TID 844)\n",
      "10-20 14:47:20.229 172.17.0.2:54325      7233    (TID 844)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/metadata/part-00000:0+345\n",
      "10-20 14:47:20.230 172.17.0.2:54325      7233    (TID 844)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 419.0 (TID 844). 1273 bytes result sent to driver\n",
      "10-20 14:47:20.230 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 419.0 (TID 844) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.231 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 419.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 419 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:20.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 274 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 419: Stage finished\n",
      "10-20 14:47:20.241 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 274 finished: first at ReadWrite.scala:587, took 0.019101 s\n",
      "10-20 14:47:20.247 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:20.264 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:20.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 275 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:20.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 420 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:20.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.265 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.266 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 420 (MapPartitionsRDD[1024] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:20.270 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_619 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:20.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_619_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:20.271 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_619_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 619 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 420 (MapPartitionsRDD[1024] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.271 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 420.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.272 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 420.0 (TID 845) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.272 172.17.0.2:54325      7233    (TID 845)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 420.0 (TID 845)\n",
      "10-20 14:47:20.277 172.17.0.2:54325      7233    (TID 845)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 420.0 (TID 845). 1709 bytes result sent to driver\n",
      "10-20 14:47:20.277 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 420.0 (TID 845) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.277 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 420.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.278 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 420 (parquet at StringIndexer.scala:523) finished in 0.012 s\n",
      "10-20 14:47:20.278 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 275 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.278 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 420: Stage finished\n",
      "10-20 14:47:20.278 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 275 finished: parquet at StringIndexer.scala:523, took 0.013859 s\n",
      "10-20 14:47:20.286 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:20.286 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:20.286 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:20.290 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_620 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:20.295 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_620_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:20.295 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_620_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:20.296 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 620 from head at StringIndexer.scala:524\n",
      "10-20 14:47:20.297 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:20.300 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:20.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 276 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:20.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 421 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:20.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.301 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 421 (MapPartitionsRDD[1027] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:20.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_621 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:20.302 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_621_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:20.302 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_621_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:20.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 621 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 421 (MapPartitionsRDD[1027] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.303 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 421.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.303 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 421.0 (TID 846) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.304 172.17.0.2:54325      7233    (TID 846)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 421.0 (TID 846)\n",
      "10-20 14:47:20.306 172.17.0.2:54325      7233    (TID 846)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/07_StringIndexer_29345e9a6a45/data/part-00000-9a6ab6f3-10b1-4191-8775-7785c9296706-c000.snappy.parquet, range: 0-648, partition values: [empty row]\n",
      "10-20 14:47:20.309 172.17.0.2:54325      7233    (TID 846)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:20.310 172.17.0.2:54325      7233    (TID 846)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:20.311 172.17.0.2:54325      7233    (TID 846)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:20.312 172.17.0.2:54325      7233    (TID 846)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 421.0 (TID 846). 1670 bytes result sent to driver\n",
      "10-20 14:47:20.312 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 421.0 (TID 846) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.312 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 421.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 421 (head at StringIndexer.scala:524) finished in 0.012 s\n",
      "10-20 14:47:20.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 276 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.313 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 421: Stage finished\n",
      "10-20 14:47:20.313 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 276 finished: head at StringIndexer.scala:524, took 0.013476 s\n",
      "10-20 14:47:20.317 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_622 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:20.332 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_620_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.332 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_618_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.333 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_617_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.334 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_609_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.334 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_622_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:20.335 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_622_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.335 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 622 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.335 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_621_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.336 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_613_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.337 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_616_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.338 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_612_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.340 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_614_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.341 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_615_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.341 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_610_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.342 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_611_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.343 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_608_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.344 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_619_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.354 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 277 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 422 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.354 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 422 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[1029] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_623 stored as values in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:20.355 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_623_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:20.355 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_623_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.356 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 623 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.356 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 422 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[1029] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.356 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 422.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.356 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 422.0 (TID 847) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.357 172.17.0.2:54325      7233    (TID 847)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 422.0 (TID 847)\n",
      "10-20 14:47:20.358 172.17.0.2:54325      7233    (TID 847)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata/part-00000:0+367\n",
      "10-20 14:47:20.359 172.17.0.2:54325      7233    (TID 847)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 422.0 (TID 847). 1252 bytes result sent to driver\n",
      "10-20 14:47:20.360 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 422.0 (TID 847) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.360 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 422.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.360 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 422 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:20.360 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 277 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.361 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 422: Stage finished\n",
      "10-20 14:47:20.361 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 277 finished: first at ReadWrite.scala:587, took 0.007106 s\n",
      "10-20 14:47:20.363 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_624 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.367 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_624_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.368 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_624_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.368 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 624 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.386 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 278 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 423 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.387 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 423 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[1031] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.388 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_625 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.388 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_625_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.389 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_625_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 625 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 423 (outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata MapPartitionsRDD[1031] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.389 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 423.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.390 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 423.0 (TID 848) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.390 172.17.0.2:54325      7233    (TID 848)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 423.0 (TID 848)\n",
      "10-20 14:47:20.392 172.17.0.2:54325      7233    (TID 848)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/metadata/part-00000:0+367\n",
      "10-20 14:47:20.393 172.17.0.2:54325      7233    (TID 848)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 423.0 (TID 848). 1295 bytes result sent to driver\n",
      "10-20 14:47:20.393 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 423.0 (TID 848) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.393 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 423.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.394 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 423 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:20.394 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 278 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.394 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 423: Stage finished\n",
      "10-20 14:47:20.394 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 278 finished: first at ReadWrite.scala:587, took 0.007711 s\n",
      "10-20 14:47:20.400 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:20.418 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:47:20.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 279 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:47:20.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 424 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:47:20.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 424 (MapPartitionsRDD[1033] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:47:20.424 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_626 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:20.425 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_626_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:20.425 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_626_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.425 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 626 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 424 (MapPartitionsRDD[1033] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.426 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 424.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.426 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 424.0 (TID 849) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.427 172.17.0.2:54325      7233    (TID 849)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 424.0 (TID 849)\n",
      "10-20 14:47:20.436 172.17.0.2:54325      7233    (TID 849)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 424.0 (TID 849). 1709 bytes result sent to driver\n",
      "10-20 14:47:20.436 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 424.0 (TID 849) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.437 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 424.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.437 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 424 (parquet at StringIndexer.scala:523) finished in 0.018 s\n",
      "10-20 14:47:20.437 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 279 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.437 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 424: Stage finished\n",
      "10-20 14:47:20.437 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 279 finished: parquet at StringIndexer.scala:523, took 0.018779 s\n",
      "10-20 14:47:20.446 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:20.446 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:20.446 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:47:20.454 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_627 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.459 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_627_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.459 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_627_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.460 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 627 from head at StringIndexer.scala:524\n",
      "10-20 14:47:20.460 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:20.464 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:47:20.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 280 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:47:20.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 425 (head at StringIndexer.scala:524)\n",
      "10-20 14:47:20.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.465 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 425 (MapPartitionsRDD[1036] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:47:20.466 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_628 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.467 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_628_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.468 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_628_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.468 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 628 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.469 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 425 (MapPartitionsRDD[1036] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.469 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 425.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.469 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 425.0 (TID 850) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.469 172.17.0.2:54325      7233    (TID 850)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 425.0 (TID 850)\n",
      "10-20 14:47:20.472 172.17.0.2:54325      7233    (TID 850)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/08_StringIndexer_20bc68757c09/data/part-00000-f1dc2679-0fa6-4a7a-a645-cc4070496429-c000.snappy.parquet, range: 0-1080, partition values: [empty row]\n",
      "10-20 14:47:20.475 172.17.0.2:54325      7233    (TID 850)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:20.476 172.17.0.2:54325      7233    (TID 850)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:20.476 172.17.0.2:54325      7233    (TID 850)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:20.477 172.17.0.2:54325      7233    (TID 850)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 425.0 (TID 850). 2291 bytes result sent to driver\n",
      "10-20 14:47:20.480 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 425.0 (TID 850) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 425 (head at StringIndexer.scala:524) finished in 0.016 s\n",
      "10-20 14:47:20.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 280 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.481 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 425.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 425: Stage finished\n",
      "10-20 14:47:20.481 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 280 finished: head at StringIndexer.scala:524, took 0.017318 s\n",
      "10-20 14:47:20.486 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_629 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.492 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_629_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.492 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_629_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.493 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 629 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.558 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 281 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 426 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.559 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 426 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[1038] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.560 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_630 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.561 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_630_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.561 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_630_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.562 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 630 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.562 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 426 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[1038] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.562 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 426.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.562 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 426.0 (TID 851) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.563 172.17.0.2:54325      7233    (TID 851)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 426.0 (TID 851)\n",
      "10-20 14:47:20.564 172.17.0.2:54325      7233    (TID 851)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata/part-00000:0+326\n",
      "10-20 14:47:20.565 172.17.0.2:54325      7233    (TID 851)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 426.0 (TID 851). 1211 bytes result sent to driver\n",
      "10-20 14:47:20.566 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 426.0 (TID 851) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.566 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 426.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.566 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 426 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:20.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 281 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.567 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 426: Stage finished\n",
      "10-20 14:47:20.567 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 281 finished: first at ReadWrite.scala:587, took 0.008633 s\n",
      "10-20 14:47:20.569 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_631 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.577 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_631_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.577 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_631_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.578 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 631 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.604 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 282 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 427 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.605 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 427 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[1040] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_632 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.606 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_632_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.606 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_632_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 632 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.607 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 427 (outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata MapPartitionsRDD[1040] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.608 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 427.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.610 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 427.0 (TID 852) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.610 172.17.0.2:54325      7233    (TID 852)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 427.0 (TID 852)\n",
      "10-20 14:47:20.612 172.17.0.2:54325      7233    (TID 852)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/metadata/part-00000:0+326\n",
      "10-20 14:47:20.614 172.17.0.2:54325      7233    (TID 852)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 427.0 (TID 852). 1254 bytes result sent to driver\n",
      "10-20 14:47:20.614 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 427.0 (TID 852) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.614 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 427.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.614 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 427 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:20.615 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 282 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.615 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 427: Stage finished\n",
      "10-20 14:47:20.615 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 282 finished: first at ReadWrite.scala:587, took 0.010393 s\n",
      "10-20 14:47:20.622 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:20.644 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:20.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 283 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:20.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 428 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:20.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 428 (MapPartitionsRDD[1042] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:20.650 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_633 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:20.651 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_633_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:20.652 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_633_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.652 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 633 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 428 (MapPartitionsRDD[1042] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.653 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 428.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.654 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 428.0 (TID 853) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.654 172.17.0.2:54325      7233    (TID 853)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 428.0 (TID 853)\n",
      "10-20 14:47:20.661 172.17.0.2:54325      7233    (TID 853)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 428.0 (TID 853). 1705 bytes result sent to driver\n",
      "10-20 14:47:20.663 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 428.0 (TID 853) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.663 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 428.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 428 (parquet at OneHotEncoder.scala:418) finished in 0.018 s\n",
      "10-20 14:47:20.663 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 283 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.664 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 428: Stage finished\n",
      "10-20 14:47:20.664 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 283 finished: parquet at OneHotEncoder.scala:418, took 0.019709 s\n",
      "10-20 14:47:20.672 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:20.672 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:20.672 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:20.677 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_634 stored as values in memory (estimated size 177.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:20.682 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_634_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:20.682 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_634_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:20.683 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 634 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:20.684 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:20.687 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:20.688 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 284 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:20.688 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 429 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:20.688 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.688 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.688 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 429 (MapPartitionsRDD[1045] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:20.689 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_635 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:20.690 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_635_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:20.692 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_635_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:20.692 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 635 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 429 (MapPartitionsRDD[1045] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.693 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 429.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.693 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 429.0 (TID 854) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.693 172.17.0.2:54325      7233    (TID 854)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 429.0 (TID 854)\n",
      "10-20 14:47:20.695 172.17.0.2:54325      7233    (TID 854)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/09_OneHotEncoder_8644ccc55499/data/part-00000-42e52091-7539-4578-8dce-562d4a27fde9-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:20.697 172.17.0.2:54325      7233    (TID 854)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:20.698 172.17.0.2:54325      7233    (TID 854)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:20.698 172.17.0.2:54325      7233    (TID 854)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:20.698 172.17.0.2:54325      7233    (TID 854)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 429.0 (TID 854). 1633 bytes result sent to driver\n",
      "10-20 14:47:20.699 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 429.0 (TID 854) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.699 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 429.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 429 (head at OneHotEncoder.scala:419) finished in 0.010 s\n",
      "10-20 14:47:20.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 284 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 429: Stage finished\n",
      "10-20 14:47:20.699 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 284 finished: head at OneHotEncoder.scala:419, took 0.011950 s\n",
      "10-20 14:47:20.702 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_636 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:20.718 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_633_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.719 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_629_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.719 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_630_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.720 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_623_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.721 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_636_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:20.721 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_635_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.721 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_636_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.722 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_627_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.722 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_628_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.723 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 636 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.723 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_631_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.724 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_622_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.725 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_626_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.726 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_632_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.726 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_624_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.727 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_634_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.728 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_625_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.745 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 285 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 430 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.745 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 430 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[1047] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.746 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_637 stored as values in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:20.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_637_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:20.747 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_637_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 637 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 430 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[1047] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.747 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 430.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.748 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 430.0 (TID 855) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.748 172.17.0.2:54325      7233    (TID 855)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 430.0 (TID 855)\n",
      "10-20 14:47:20.749 172.17.0.2:54325      7233    (TID 855)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata/part-00000:0+326\n",
      "10-20 14:47:20.750 172.17.0.2:54325      7233    (TID 855)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 430.0 (TID 855). 1211 bytes result sent to driver\n",
      "10-20 14:47:20.751 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 430.0 (TID 855) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.751 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 430.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.751 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 430 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:20.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 285 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.752 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 430: Stage finished\n",
      "10-20 14:47:20.752 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 285 finished: first at ReadWrite.scala:587, took 0.006828 s\n",
      "10-20 14:47:20.754 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_638 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.766 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_638_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.766 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_638_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.766 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 638 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.783 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.783 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 286 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.783 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 431 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.783 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.783 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.783 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 431 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[1049] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.784 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_639 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.785 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_639_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:20.786 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_639_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 639 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 431 (outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata MapPartitionsRDD[1049] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.786 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 431.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.787 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 431.0 (TID 856) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.791 172.17.0.2:54325      7233    (TID 856)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 431.0 (TID 856)\n",
      "10-20 14:47:20.793 172.17.0.2:54325      7233    (TID 856)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/metadata/part-00000:0+326\n",
      "10-20 14:47:20.794 172.17.0.2:54325      7233    (TID 856)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 431.0 (TID 856). 1254 bytes result sent to driver\n",
      "10-20 14:47:20.795 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 431.0 (TID 856) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.795 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 431.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 431 (first at ReadWrite.scala:587) finished in 0.011 s\n",
      "10-20 14:47:20.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 286 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.795 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 431: Stage finished\n",
      "10-20 14:47:20.795 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 286 finished: first at ReadWrite.scala:587, took 0.012585 s\n",
      "10-20 14:47:20.801 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:20.820 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:20.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 287 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:20.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 432 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:20.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.821 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 432 (MapPartitionsRDD[1051] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:20.825 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_640 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:20.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_640_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:20.827 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_640_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 640 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 432 (MapPartitionsRDD[1051] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 432.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.828 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 432.0 (TID 857) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.828 172.17.0.2:54325      7233    (TID 857)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 432.0 (TID 857)\n",
      "10-20 14:47:20.834 172.17.0.2:54325      7233    (TID 857)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 432.0 (TID 857). 1705 bytes result sent to driver\n",
      "10-20 14:47:20.835 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 432.0 (TID 857) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.835 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 432.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.839 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 432 (parquet at OneHotEncoder.scala:418) finished in 0.018 s\n",
      "10-20 14:47:20.839 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 287 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.839 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 432: Stage finished\n",
      "10-20 14:47:20.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 287 finished: parquet at OneHotEncoder.scala:418, took 0.018384 s\n",
      "10-20 14:47:20.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:20.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:20.846 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:20.851 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_641 stored as values in memory (estimated size 177.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.856 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_641_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.856 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_641_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.857 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 641 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:20.857 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:20.862 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:20.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 288 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:20.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 433 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:20.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.863 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.864 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 433 (MapPartitionsRDD[1054] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:20.865 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_642 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.866 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_642_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:20.866 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_642_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:20.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 642 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 433 (MapPartitionsRDD[1054] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.867 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 433.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.868 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 433.0 (TID 858) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.869 172.17.0.2:54325      7233    (TID 858)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 433.0 (TID 858)\n",
      "10-20 14:47:20.872 172.17.0.2:54325      7233    (TID 858)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/10_OneHotEncoder_e3bbadd9692b/data/part-00000-99370af6-9865-44b6-9157-c7746f517dd6-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:20.875 172.17.0.2:54325      7233    (TID 858)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:20.876 172.17.0.2:54325      7233    (TID 858)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:20.876 172.17.0.2:54325      7233    (TID 858)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:20.877 172.17.0.2:54325      7233    (TID 858)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 433.0 (TID 858). 1633 bytes result sent to driver\n",
      "10-20 14:47:20.877 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 433.0 (TID 858) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.877 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 433.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 433 (head at OneHotEncoder.scala:419) finished in 0.014 s\n",
      "10-20 14:47:20.878 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 288 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.879 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 433: Stage finished\n",
      "10-20 14:47:20.879 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 288 finished: head at OneHotEncoder.scala:419, took 0.016216 s\n",
      "10-20 14:47:20.881 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_643 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.886 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_643_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.886 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_643_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.887 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 643 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.934 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.935 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 289 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.935 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 434 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.935 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.935 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.935 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 434 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[1056] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_644 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.936 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_644_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:20.937 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_644_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 644 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 434 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[1056] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.937 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 434.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.938 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 434.0 (TID 859) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.938 172.17.0.2:54325      7233    (TID 859)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 434.0 (TID 859)\n",
      "10-20 14:47:20.939 172.17.0.2:54325      7233    (TID 859)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata/part-00000:0+336\n",
      "10-20 14:47:20.941 172.17.0.2:54325      7233    (TID 859)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 434.0 (TID 859). 1264 bytes result sent to driver\n",
      "10-20 14:47:20.941 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 434.0 (TID 859) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.941 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 434 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:20.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 289 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.942 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 434: Stage finished\n",
      "10-20 14:47:20.942 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 289 finished: first at ReadWrite.scala:587, took 0.007484 s\n",
      "10-20 14:47:20.944 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_645 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.949 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_645_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.949 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_645_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.949 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 645 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:20.964 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:20.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 290 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:20.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 435 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:20.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 435 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[1058] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:20.965 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_646 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.966 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_646_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:20.966 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_646_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:20.967 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 646 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:20.967 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 435 (outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata MapPartitionsRDD[1058] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:20.967 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 435.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:20.967 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 435.0 (TID 860) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:20.967 172.17.0.2:54325      7233    (TID 860)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 435.0 (TID 860)\n",
      "10-20 14:47:20.968 172.17.0.2:54325      7233    (TID 860)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/metadata/part-00000:0+336\n",
      "10-20 14:47:20.970 172.17.0.2:54325      7233    (TID 860)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 435.0 (TID 860). 1221 bytes result sent to driver\n",
      "10-20 14:47:20.970 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 435.0 (TID 860) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:20.970 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 435.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:20.971 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 435 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:20.971 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 290 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:20.971 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 435: Stage finished\n",
      "10-20 14:47:20.971 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 290 finished: first at ReadWrite.scala:587, took 0.006447 s\n",
      "10-20 14:47:20.976 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:20.993 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:20.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 291 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:20.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 436 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:20.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:20.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:20.994 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 436 (MapPartitionsRDD[1060] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:20.998 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_647 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:20.999 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_647_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:20.999 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_647_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 647 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 436 (MapPartitionsRDD[1060] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.000 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 436.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.004 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 436.0 (TID 861) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.004 172.17.0.2:54325      7233    (TID 861)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 436.0 (TID 861)\n",
      "10-20 14:47:21.016 172.17.0.2:54325      7233    (TID 861)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 436.0 (TID 861). 1705 bytes result sent to driver\n",
      "10-20 14:47:21.017 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 436.0 (TID 861) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.017 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 436 (parquet at OneHotEncoder.scala:418) finished in 0.023 s\n",
      "10-20 14:47:21.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 291 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.017 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 436: Stage finished\n",
      "10-20 14:47:21.018 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 291 finished: parquet at OneHotEncoder.scala:418, took 0.024550 s\n",
      "10-20 14:47:21.026 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:21.026 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:21.027 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:21.032 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_648 stored as values in memory (estimated size 177.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:21.038 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_648_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.038 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_648_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.038 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 648 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.039 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:21.042 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 292 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:21.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 437 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:21.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 437 (MapPartitionsRDD[1063] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:21.043 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_649 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.045 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_649_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.045 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_649_piece0 in memory on 95675304fa2d:39429 (size: 4.8 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 649 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 437 (MapPartitionsRDD[1063] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.046 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 437.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.046 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 437.0 (TID 862) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.047 172.17.0.2:54325      7233    (TID 862)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 437.0 (TID 862)\n",
      "10-20 14:47:21.048 172.17.0.2:54325      7233    (TID 862)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/11_OneHotEncoder_5c76a0270a04/data/part-00000-9bdca204-87b1-4a49-b951-2984a719ee3e-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:21.051 172.17.0.2:54325      7233    (TID 862)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:21.051 172.17.0.2:54325      7233    (TID 862)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:21.051 172.17.0.2:54325      7233    (TID 862)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:21.052 172.17.0.2:54325      7233    (TID 862)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 437.0 (TID 862). 1590 bytes result sent to driver\n",
      "10-20 14:47:21.052 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 437.0 (TID 862) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.052 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 437.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 437 (head at OneHotEncoder.scala:419) finished in 0.010 s\n",
      "10-20 14:47:21.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 292 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.053 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 437: Stage finished\n",
      "10-20 14:47:21.053 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 292 finished: head at OneHotEncoder.scala:419, took 0.010740 s\n",
      "10-20 14:47:21.056 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_650 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:21.073 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_649_piece0 on 95675304fa2d:39429 in memory (size: 4.8 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.074 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_637_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.075 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_641_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.076 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_639_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.077 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_636_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.077 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_650_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:47:21.078 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_648_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.078 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_650_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.078 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_646_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.078 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 650 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.079 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_644_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.080 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_642_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.082 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_643_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.083 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_647_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.084 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_645_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.085 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_638_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.085 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_640_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.098 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.098 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 293 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.098 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 438 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.098 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.098 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.098 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 438 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[1065] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.099 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_651 stored as values in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:21.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_651_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:21.100 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_651_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.100 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 651 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.101 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 438 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[1065] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.101 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 438.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.102 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 438.0 (TID 863) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.102 172.17.0.2:54325      7233    (TID 863)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 438.0 (TID 863)\n",
      "10-20 14:47:21.103 172.17.0.2:54325      7233    (TID 863)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata/part-00000:0+328\n",
      "10-20 14:47:21.105 172.17.0.2:54325      7233    (TID 863)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 438.0 (TID 863). 1213 bytes result sent to driver\n",
      "10-20 14:47:21.106 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 438.0 (TID 863) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.106 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 438.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.106 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 438 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:21.106 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 293 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.106 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 438: Stage finished\n",
      "10-20 14:47:21.106 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 293 finished: first at ReadWrite.scala:587, took 0.008460 s\n",
      "10-20 14:47:21.108 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_652 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.112 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_652_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.113 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_652_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.113 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 652 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 294 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 439 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.130 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 439 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[1067] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.131 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_653 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.131 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_653_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.132 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_653_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.132 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 653 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.132 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 439 (outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata MapPartitionsRDD[1067] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.132 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 439.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.132 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 439.0 (TID 864) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.138 172.17.0.2:54325      7233    (TID 864)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 439.0 (TID 864)\n",
      "10-20 14:47:21.139 172.17.0.2:54325      7233    (TID 864)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/metadata/part-00000:0+328\n",
      "10-20 14:47:21.140 172.17.0.2:54325      7233    (TID 864)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 439.0 (TID 864). 1213 bytes result sent to driver\n",
      "10-20 14:47:21.141 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 439.0 (TID 864) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.141 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 439.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.141 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 439 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:47:21.142 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 294 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.142 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 439: Stage finished\n",
      "10-20 14:47:21.142 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 294 finished: first at ReadWrite.scala:587, took 0.012249 s\n",
      "10-20 14:47:21.148 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:21.166 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:21.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 295 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:21.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 440 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:21.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.166 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.167 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 440 (MapPartitionsRDD[1069] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:21.171 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_654 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.172 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_654_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.172 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_654_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.173 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 654 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 440 (MapPartitionsRDD[1069] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.174 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 440.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.175 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 440.0 (TID 865) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.175 172.17.0.2:54325      7233    (TID 865)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 440.0 (TID 865)\n",
      "10-20 14:47:21.183 172.17.0.2:54325      7233    (TID 865)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 440.0 (TID 865). 1705 bytes result sent to driver\n",
      "10-20 14:47:21.184 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 440.0 (TID 865) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.184 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 440.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 440 (parquet at OneHotEncoder.scala:418) finished in 0.017 s\n",
      "10-20 14:47:21.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 295 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 440: Stage finished\n",
      "10-20 14:47:21.185 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 295 finished: parquet at OneHotEncoder.scala:418, took 0.019069 s\n",
      "10-20 14:47:21.194 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:21.194 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:21.194 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:21.200 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_655 stored as values in memory (estimated size 177.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.207 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_655_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.207 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_655_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.208 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 655 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.208 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:21.213 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 296 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:21.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 441 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:21.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.214 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 441 (MapPartitionsRDD[1072] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:21.216 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_656 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.217 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_656_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.217 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_656_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 656 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 441 (MapPartitionsRDD[1072] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.218 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 441.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.219 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 441.0 (TID 866) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.219 172.17.0.2:54325      7233    (TID 866)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 441.0 (TID 866)\n",
      "10-20 14:47:21.221 172.17.0.2:54325      7233    (TID 866)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/12_OneHotEncoder_f4bcae2c03fd/data/part-00000-cfffee53-1ee6-4583-89d6-907e29892dc5-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:21.225 172.17.0.2:54325      7233    (TID 866)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:21.226 172.17.0.2:54325      7233    (TID 866)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:21.227 172.17.0.2:54325      7233    (TID 866)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:21.228 172.17.0.2:54325      7233    (TID 866)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 441.0 (TID 866). 1629 bytes result sent to driver\n",
      "10-20 14:47:21.230 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 441.0 (TID 866) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.230 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 441.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 441 (head at OneHotEncoder.scala:419) finished in 0.016 s\n",
      "10-20 14:47:21.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 296 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.231 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 441: Stage finished\n",
      "10-20 14:47:21.231 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 296 finished: head at OneHotEncoder.scala:419, took 0.017465 s\n",
      "10-20 14:47:21.233 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_657 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.240 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_657_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.241 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_657_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.242 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 657 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.297 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 297 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 442 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.297 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 442 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[1074] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.299 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_658 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_658_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.300 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_658_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.300 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 658 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.301 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 442 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[1074] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.301 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 442.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.302 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 442.0 (TID 867) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.302 172.17.0.2:54325      7233    (TID 867)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 442.0 (TID 867)\n",
      "10-20 14:47:21.304 172.17.0.2:54325      7233    (TID 867)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata/part-00000:0+332\n",
      "10-20 14:47:21.306 172.17.0.2:54325      7233    (TID 867)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 442.0 (TID 867). 1260 bytes result sent to driver\n",
      "10-20 14:47:21.307 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 442.0 (TID 867) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.307 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 442.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 442 (first at ReadWrite.scala:587) finished in 0.016 s\n",
      "10-20 14:47:21.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 297 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.314 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 442: Stage finished\n",
      "10-20 14:47:21.314 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 297 finished: first at ReadWrite.scala:587, took 0.017542 s\n",
      "10-20 14:47:21.316 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_659 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.320 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_659_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.321 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_659_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.322 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 659 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.337 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 298 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 443 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.338 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 443 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[1076] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.339 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_660 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.340 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_660_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.340 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_660_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 660 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 443 (outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata MapPartitionsRDD[1076] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.341 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 443.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.342 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 443.0 (TID 868) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.342 172.17.0.2:54325      7233    (TID 868)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 443.0 (TID 868)\n",
      "10-20 14:47:21.343 172.17.0.2:54325      7233    (TID 868)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/metadata/part-00000:0+332\n",
      "10-20 14:47:21.344 172.17.0.2:54325      7233    (TID 868)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 443.0 (TID 868). 1174 bytes result sent to driver\n",
      "10-20 14:47:21.344 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 443.0 (TID 868) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.344 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 443.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 443 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:21.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 298 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 443: Stage finished\n",
      "10-20 14:47:21.346 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 298 finished: first at ReadWrite.scala:587, took 0.008351 s\n",
      "10-20 14:47:21.350 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:21.368 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:21.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 299 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:21.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 444 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:21.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.369 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 444 (MapPartitionsRDD[1078] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:21.373 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_661 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:21.374 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_661_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:21.377 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_661_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 661 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 444 (MapPartitionsRDD[1078] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 444.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.378 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 444.0 (TID 869) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.378 172.17.0.2:54325      7233    (TID 869)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 444.0 (TID 869)\n",
      "10-20 14:47:21.384 172.17.0.2:54325      7233    (TID 869)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 444.0 (TID 869). 1705 bytes result sent to driver\n",
      "10-20 14:47:21.385 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 444.0 (TID 869) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.385 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 444.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 444 (parquet at OneHotEncoder.scala:418) finished in 0.016 s\n",
      "10-20 14:47:21.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 299 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.385 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 444: Stage finished\n",
      "10-20 14:47:21.386 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 299 finished: parquet at OneHotEncoder.scala:418, took 0.017144 s\n",
      "10-20 14:47:21.392 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:21.392 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:21.392 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:21.396 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_662 stored as values in memory (estimated size 177.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:21.401 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_662_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.401 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_662_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.402 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 662 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.402 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:21.406 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 300 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:21.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 445 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:21.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.407 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 445 (MapPartitionsRDD[1081] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:21.408 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_663 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.408 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_663_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.409 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_663_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.409 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 663 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.409 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 445 (MapPartitionsRDD[1081] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.409 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 445.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.410 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 445.0 (TID 870) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.410 172.17.0.2:54325      7233    (TID 870)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 445.0 (TID 870)\n",
      "10-20 14:47:21.413 172.17.0.2:54325      7233    (TID 870)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/13_OneHotEncoder_055d190327dd/data/part-00000-41b1fa50-4a26-48ef-bf43-3158cce827ba-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:21.417 172.17.0.2:54325      7233    (TID 870)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:21.417 172.17.0.2:54325      7233    (TID 870)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:21.418 172.17.0.2:54325      7233    (TID 870)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:21.418 172.17.0.2:54325      7233    (TID 870)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 445.0 (TID 870). 1633 bytes result sent to driver\n",
      "10-20 14:47:21.419 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 445.0 (TID 870) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.419 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 445.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 445 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:21.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 300 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.419 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 445: Stage finished\n",
      "10-20 14:47:21.420 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 300 finished: head at OneHotEncoder.scala:419, took 0.013546 s\n",
      "10-20 14:47:21.423 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_664 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:21.440 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_654_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.441 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_652_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.442 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_662_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.443 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_659_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.444 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_653_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.445 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_651_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.446 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_664_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.447 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_664_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.447 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_663_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.447 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 664 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.450 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_657_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.452 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_656_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.453 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_660_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.454 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_650_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.455 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_658_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.456 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_661_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.459 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_655_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.481 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 301 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 446 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.481 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 446 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[1083] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.482 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_665 stored as values in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:21.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_665_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:21.483 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_665_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 665 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 446 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[1083] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.483 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 446.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.484 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 446.0 (TID 871) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.484 172.17.0.2:54325      7233    (TID 871)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 446.0 (TID 871)\n",
      "10-20 14:47:21.485 172.17.0.2:54325      7233    (TID 871)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata/part-00000:0+316\n",
      "10-20 14:47:21.486 172.17.0.2:54325      7233    (TID 871)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 446.0 (TID 871). 1158 bytes result sent to driver\n",
      "10-20 14:47:21.487 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 446.0 (TID 871) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.487 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 446.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 446 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:47:21.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 301 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.488 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 446: Stage finished\n",
      "10-20 14:47:21.489 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 301 finished: first at ReadWrite.scala:587, took 0.007724 s\n",
      "10-20 14:47:21.490 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_666 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.495 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_666_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.495 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_666_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.496 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 666 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.514 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 302 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 447 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.515 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 447 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[1085] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.516 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_667 stored as values in memory (estimated size 4.2 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.517 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_667_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.8 MiB)\n",
      "10-20 14:47:21.517 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_667_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 667 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 447 (outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata MapPartitionsRDD[1085] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.518 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 447.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.518 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 447.0 (TID 872) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.519 172.17.0.2:54325      7233    (TID 872)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 447.0 (TID 872)\n",
      "10-20 14:47:21.520 172.17.0.2:54325      7233    (TID 872)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/metadata/part-00000:0+316\n",
      "10-20 14:47:21.522 172.17.0.2:54325      7233    (TID 872)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 447.0 (TID 872). 1244 bytes result sent to driver\n",
      "10-20 14:47:21.522 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 447.0 (TID 872) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.522 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 447.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.522 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 447 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:21.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 302 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.523 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 447: Stage finished\n",
      "10-20 14:47:21.523 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 302 finished: first at ReadWrite.scala:587, took 0.008826 s\n",
      "10-20 14:47:21.529 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:21.548 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:21.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 303 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:21.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 448 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:21.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.549 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 448 (MapPartitionsRDD[1087] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:21.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_668 stored as values in memory (estimated size 84.5 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.555 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_668_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.556 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_668_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.557 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 668 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.557 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 448 (MapPartitionsRDD[1087] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.557 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 448.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.557 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 448.0 (TID 873) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.558 172.17.0.2:54325      7233    (TID 873)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 448.0 (TID 873)\n",
      "10-20 14:47:21.564 172.17.0.2:54325      7233    (TID 873)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 448.0 (TID 873). 1705 bytes result sent to driver\n",
      "10-20 14:47:21.564 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 448.0 (TID 873) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.564 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 448.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 448 (parquet at OneHotEncoder.scala:418) finished in 0.015 s\n",
      "10-20 14:47:21.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 303 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.565 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 448: Stage finished\n",
      "10-20 14:47:21.565 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 303 finished: parquet at OneHotEncoder.scala:418, took 0.016432 s\n",
      "10-20 14:47:21.572 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:21.572 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:21.572 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:21.576 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_669 stored as values in memory (estimated size 177.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.583 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_669_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.583 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_669_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.584 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 669 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.584 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:21.589 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.589 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 304 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 449 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 449 (MapPartitionsRDD[1090] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:21.590 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_670 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.591 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_670_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.591 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_670_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.591 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 670 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.592 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 449 (MapPartitionsRDD[1090] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.592 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 449.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.592 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 449.0 (TID 874) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.592 172.17.0.2:54325      7233    (TID 874)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 449.0 (TID 874)\n",
      "10-20 14:47:21.595 172.17.0.2:54325      7233    (TID 874)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/14_OneHotEncoder_d00d39a3a6ee/data/part-00000-2cdd5380-9478-48a4-bcb4-09175a733687-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:21.598 172.17.0.2:54325      7233    (TID 874)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:21.598 172.17.0.2:54325      7233    (TID 874)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:21.599 172.17.0.2:54325      7233    (TID 874)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:47:21.600 172.17.0.2:54325      7233    (TID 874)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 449.0 (TID 874). 1633 bytes result sent to driver\n",
      "10-20 14:47:21.600 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 449.0 (TID 874) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.600 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 449.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 449 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:21.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 304 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.601 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 449: Stage finished\n",
      "10-20 14:47:21.601 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 304 finished: head at OneHotEncoder.scala:419, took 0.012249 s\n",
      "10-20 14:47:21.605 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_671 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.610 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_671_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.611 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_671_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.611 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 671 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.632 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 305 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 450 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.632 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 450 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[1092] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.633 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_672 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.634 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_672_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:21.634 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_672_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.635 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 672 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.635 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 450 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[1092] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.635 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 450.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.635 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 450.0 (TID 875) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.635 172.17.0.2:54325      7233    (TID 875)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 450.0 (TID 875)\n",
      "10-20 14:47:21.636 172.17.0.2:54325      7233    (TID 875)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata/part-00000:0+314\n",
      "10-20 14:47:21.637 172.17.0.2:54325      7233    (TID 875)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 450.0 (TID 875). 1199 bytes result sent to driver\n",
      "10-20 14:47:21.638 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 450.0 (TID 875) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.638 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 450.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.639 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 450 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:47:21.639 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 305 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.639 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 450: Stage finished\n",
      "10-20 14:47:21.639 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 305 finished: first at ReadWrite.scala:587, took 0.007074 s\n",
      "10-20 14:47:21.640 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_673 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.646 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_673_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.646 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_673_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.647 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 673 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.695 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 306 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 451 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.696 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 451 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[1094] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.697 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_674 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.698 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_674_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:21.698 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_674_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.698 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 674 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 451 (outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata MapPartitionsRDD[1094] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.699 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 451.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.699 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 451.0 (TID 876) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.700 172.17.0.2:54325      7233    (TID 876)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 451.0 (TID 876)\n",
      "10-20 14:47:21.701 172.17.0.2:54325      7233    (TID 876)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/metadata/part-00000:0+314\n",
      "10-20 14:47:21.703 172.17.0.2:54325      7233    (TID 876)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 451.0 (TID 876). 1242 bytes result sent to driver\n",
      "10-20 14:47:21.703 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 451.0 (TID 876) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.703 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 451.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.704 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 451 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:47:21.704 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 306 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.704 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 451: Stage finished\n",
      "10-20 14:47:21.705 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 306 finished: first at ReadWrite.scala:587, took 0.009961 s\n",
      "10-20 14:47:21.711 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:21.729 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:21.730 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 307 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:21.730 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 452 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:21.730 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.730 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.730 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 452 (MapPartitionsRDD[1096] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:21.734 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_675 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:47:21.735 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_675_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:21.735 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_675_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 675 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 452 (MapPartitionsRDD[1096] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.736 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 452.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.737 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 452.0 (TID 877) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.737 172.17.0.2:54325      7233    (TID 877)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 452.0 (TID 877)\n",
      "10-20 14:47:21.743 172.17.0.2:54325      7233    (TID 877)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 452.0 (TID 877). 1705 bytes result sent to driver\n",
      "10-20 14:47:21.744 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 452.0 (TID 877) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.744 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 452.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.744 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 452 (parquet at OneHotEncoder.scala:418) finished in 0.014 s\n",
      "10-20 14:47:21.744 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 307 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.744 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 452: Stage finished\n",
      "10-20 14:47:21.745 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 307 finished: parquet at OneHotEncoder.scala:418, took 0.015254 s\n",
      "10-20 14:47:21.753 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:21.753 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:21.753 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:21.758 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_676 stored as values in memory (estimated size 177.4 KiB, free 432.8 MiB)\n",
      "10-20 14:47:21.763 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_676_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.764 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_676_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.765 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 676 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.765 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:21.769 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 308 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:21.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 453 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:21.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.770 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 453 (MapPartitionsRDD[1099] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:21.771 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_677 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_677_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:47:21.773 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_677_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 677 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 453 (MapPartitionsRDD[1099] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.773 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 453.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.774 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 453.0 (TID 878) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.774 172.17.0.2:54325      7233    (TID 878)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 453.0 (TID 878)\n",
      "10-20 14:47:21.776 172.17.0.2:54325      7233    (TID 878)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/15_OneHotEncoder_6e04255bec9a/data/part-00000-aa5a59a3-4580-4b9c-93dd-31b922f0da7e-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:21.780 172.17.0.2:54325      7233    (TID 878)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:21.781 172.17.0.2:54325      7233    (TID 878)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:21.782 172.17.0.2:54325      7233    (TID 878)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:21.784 172.17.0.2:54325      7233    (TID 878)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 453.0 (TID 878). 1633 bytes result sent to driver\n",
      "10-20 14:47:21.785 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 453.0 (TID 878) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.785 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 453.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 453 (head at OneHotEncoder.scala:419) finished in 0.017 s\n",
      "10-20 14:47:21.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 308 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.788 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 453: Stage finished\n",
      "10-20 14:47:21.788 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 308 finished: head at OneHotEncoder.scala:419, took 0.018671 s\n",
      "10-20 14:47:21.792 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_678 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:47:21.800 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_678_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:47:21.801 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_678_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.801 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 678 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.825 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 309 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 454 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.826 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 454 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[1101] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.827 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_679 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:47:21.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_679_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:47:21.828 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_679_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 679 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 454 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[1101] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.828 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 454.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.829 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 454.0 (TID 879) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.830 172.17.0.2:54325      7233    (TID 879)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 454.0 (TID 879)\n",
      "10-20 14:47:21.834 172.17.0.2:54325      7233    (TID 879)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata/part-00000:0+336\n",
      "10-20 14:47:21.835 172.17.0.2:54325      7233    (TID 879)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 454.0 (TID 879). 1264 bytes result sent to driver\n",
      "10-20 14:47:21.836 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 454.0 (TID 879) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.836 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.836 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 454 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:21.837 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 309 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.839 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 454: Stage finished\n",
      "10-20 14:47:21.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 309 finished: first at ReadWrite.scala:587, took 0.013716 s\n",
      "10-20 14:47:21.841 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_680 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:47:21.866 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_680_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:47:21.867 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_680_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.867 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 680 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:21.868 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_673_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.869 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_670_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.870 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_665_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.871 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_679_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.872 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_674_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.874 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_675_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:21.877 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_677_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.879 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_666_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.882 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_676_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.884 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_671_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.886 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_672_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:21.887 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_669_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.888 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_667_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.889 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_678_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.891 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_668_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.893 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_664_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.901 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:21.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 310 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:21.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 455 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:21.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.902 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 455 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[1103] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:21.903 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_681 stored as values in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "10-20 14:47:21.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_681_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 434.0 MiB)\n",
      "10-20 14:47:21.904 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_681_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.904 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 681 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 455 (outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata MapPartitionsRDD[1103] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.905 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 455.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.906 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 455.0 (TID 880) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.906 172.17.0.2:54325      7233    (TID 880)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 455.0 (TID 880)\n",
      "10-20 14:47:21.907 172.17.0.2:54325      7233    (TID 880)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/metadata/part-00000:0+336\n",
      "10-20 14:47:21.908 172.17.0.2:54325      7233    (TID 880)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 455.0 (TID 880). 1221 bytes result sent to driver\n",
      "10-20 14:47:21.908 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 455.0 (TID 880) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.908 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 455 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:21.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 310 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.909 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 455: Stage finished\n",
      "10-20 14:47:21.909 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 310 finished: first at ReadWrite.scala:587, took 0.008016 s\n",
      "10-20 14:47:21.914 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:21.933 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:47:21.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 311 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:47:21.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 456 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:47:21.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.933 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 456 (MapPartitionsRDD[1105] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:47:21.938 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_682 stored as values in memory (estimated size 84.5 KiB, free 433.9 MiB)\n",
      "10-20 14:47:21.939 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_682_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.9 MiB)\n",
      "10-20 14:47:21.939 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_682_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.939 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 682 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.939 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 456 (MapPartitionsRDD[1105] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.939 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 456.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.940 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 456.0 (TID 881) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.940 172.17.0.2:54325      7233    (TID 881)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 456.0 (TID 881)\n",
      "10-20 14:47:21.946 172.17.0.2:54325      7233    (TID 881)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 456.0 (TID 881). 1705 bytes result sent to driver\n",
      "10-20 14:47:21.946 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 456.0 (TID 881) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.947 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.947 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 456 (parquet at OneHotEncoder.scala:418) finished in 0.013 s\n",
      "10-20 14:47:21.947 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 311 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.947 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 456: Stage finished\n",
      "10-20 14:47:21.948 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 311 finished: parquet at OneHotEncoder.scala:418, took 0.014936 s\n",
      "10-20 14:47:21.955 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:21.955 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:21.955 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:47:21.960 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_683 stored as values in memory (estimated size 177.4 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.966 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_683_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.966 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_683_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.967 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 683 from head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.967 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:21.973 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:47:21.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 312 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:47:21.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 457 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:47:21.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:21.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:21.974 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 457 (MapPartitionsRDD[1108] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:47:21.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_684 stored as values in memory (estimated size 8.9 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.975 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_684_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.7 MiB)\n",
      "10-20 14:47:21.976 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_684_piece0 in memory on 95675304fa2d:39429 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 684 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:21.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 457 (MapPartitionsRDD[1108] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:21.977 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 457.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:21.978 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 457.0 (TID 882) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:21.978 172.17.0.2:54325      7233    (TID 882)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 457.0 (TID 882)\n",
      "10-20 14:47:21.980 172.17.0.2:54325      7233    (TID 882)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/16_OneHotEncoder_ec75adb54506/data/part-00000-bbb39d30-1fcc-479e-b345-fb72012c6c23-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:47:21.982 172.17.0.2:54325      7233    (TID 882)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:47:21.983 172.17.0.2:54325      7233    (TID 882)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:21.983 172.17.0.2:54325      7233    (TID 882)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:47:21.983 172.17.0.2:54325      7233    (TID 882)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 457.0 (TID 882). 1633 bytes result sent to driver\n",
      "10-20 14:47:21.984 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 457.0 (TID 882) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:21.984 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 457.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:21.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 457 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:47:21.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 312 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:21.985 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 457: Stage finished\n",
      "10-20 14:47:21.986 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 312 finished: head at OneHotEncoder.scala:419, took 0.013044 s\n",
      "10-20 14:47:21.989 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_685 stored as values in memory (estimated size 176.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.995 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_685_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:21.995 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_685_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:21.996 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 685 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:22.017 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:22.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 313 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:22.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 458 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:22.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.018 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 458 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[1110] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:22.019 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_686 stored as values in memory (estimated size 4.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.020 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_686_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.020 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_686_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 686 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 458 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[1110] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:22.023 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 458.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:22.023 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 458.0 (TID 883) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4580 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.024 172.17.0.2:54325      7233    (TID 883)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 458.0 (TID 883)\n",
      "10-20 14:47:22.026 172.17.0.2:54325      7233    (TID 883)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata/part-00000:0+520\n",
      "10-20 14:47:22.027 172.17.0.2:54325      7233    (TID 883)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 458.0 (TID 883). 1448 bytes result sent to driver\n",
      "10-20 14:47:22.027 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 458.0 (TID 883) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:22.027 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 458.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.028 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 458 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:47:22.028 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 313 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.028 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 458: Stage finished\n",
      "10-20 14:47:22.029 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 313 finished: first at ReadWrite.scala:587, took 0.011053 s\n",
      "10-20 14:47:22.031 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_687 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:47:22.036 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_687_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:22.037 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_687_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.038 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 687 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:22.055 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:22.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 314 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:22.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 459 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:22.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 459 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[1112] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:22.056 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_688 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:22.057 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_688_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:47:22.057 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_688_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 688 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 459 (outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata MapPartitionsRDD[1112] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:22.058 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 459.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:22.059 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 459.0 (TID 884) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4580 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.059 172.17.0.2:54325      7233    (TID 884)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 459.0 (TID 884)\n",
      "10-20 14:47:22.061 172.17.0.2:54325      7233    (TID 884)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/17_VectorAssembler_dadd509d9810/metadata/part-00000:0+520\n",
      "10-20 14:47:22.062 172.17.0.2:54325      7233    (TID 884)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 459.0 (TID 884). 1448 bytes result sent to driver\n",
      "10-20 14:47:22.063 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 459.0 (TID 884) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:22.063 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 459.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 459 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:22.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 314 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.064 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 459: Stage finished\n",
      "10-20 14:47:22.064 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 314 finished: first at ReadWrite.scala:587, took 0.008932 s\n",
      "10-20 14:47:22.066 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_689 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:47:22.071 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_689_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:22.098 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_689_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.098 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 689 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:22.115 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:22.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 315 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:22.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 460 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:22.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 460 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[1114] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:22.116 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_690 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:47:22.117 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_690_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:47:22.117 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_690_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 690 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 460 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[1114] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:22.118 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 460.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:22.119 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 460.0 (TID 885) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.119 172.17.0.2:54325      7233    (TID 885)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 460.0 (TID 885)\n",
      "10-20 14:47:22.120 172.17.0.2:54325      7233    (TID 885)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata/part-00000:0+751\n",
      "10-20 14:47:22.122 172.17.0.2:54325      7233    (TID 885)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 460.0 (TID 885). 1636 bytes result sent to driver\n",
      "10-20 14:47:22.122 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 460.0 (TID 885) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:22.123 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 460.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 460 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:22.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 315 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.123 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 460: Stage finished\n",
      "10-20 14:47:22.123 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 315 finished: first at ReadWrite.scala:587, took 0.008398 s\n",
      "10-20 14:47:22.125 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_691 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:47:22.129 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_691_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:22.130 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_691_piece0 in memory on 95675304fa2d:39429 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.130 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 691 from textFile at ReadWrite.scala:587\n",
      "10-20 14:47:22.147 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:47:22.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 316 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:47:22.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 461 (first at ReadWrite.scala:587)\n",
      "10-20 14:47:22.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.148 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 461 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[1116] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:47:22.149 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_692 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:47:22.149 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_692_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:47:22.150 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_692_piece0 in memory on 95675304fa2d:39429 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 692 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.150 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 461 (outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata MapPartitionsRDD[1116] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:22.151 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 461.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:22.151 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 461.0 (TID 886) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4578 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.151 172.17.0.2:54325      7233    (TID 886)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 461.0 (TID 886)\n",
      "10-20 14:47:22.153 172.17.0.2:54325      7233    (TID 886)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/metadata/part-00000:0+751\n",
      "10-20 14:47:22.154 172.17.0.2:54325      7233    (TID 886)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 461.0 (TID 886). 1636 bytes result sent to driver\n",
      "10-20 14:47:22.154 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 461.0 (TID 886) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:22.154 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 461.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 461 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:47:22.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 316 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.155 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 461: Stage finished\n",
      "10-20 14:47:22.155 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 316 finished: first at ReadWrite.scala:587, took 0.007817 s\n",
      "10-20 14:47:22.161 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:22.184 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:507\n",
      "10-20 14:47:22.184 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 317 (parquet at treeModels.scala:507) with 1 output partitions\n",
      "10-20 14:47:22.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 462 (parquet at treeModels.scala:507)\n",
      "10-20 14:47:22.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.185 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 462 (MapPartitionsRDD[1118] at parquet at treeModels.scala:507), which has no missing parents\n",
      "10-20 14:47:22.194 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_693 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:47:22.195 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_693_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:47:22.195 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_693_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 693 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 462 (MapPartitionsRDD[1118] at parquet at treeModels.scala:507) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:22.196 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 462.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:22.197 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 462.0 (TID 887) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4747 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.198 172.17.0.2:54325      7233    (TID 887)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 462.0 (TID 887)\n",
      "10-20 14:47:22.204 172.17.0.2:54325      7233    (TID 887)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 462.0 (TID 887). 1787 bytes result sent to driver\n",
      "10-20 14:47:22.205 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 462.0 (TID 887) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:22.205 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 462.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 462 (parquet at treeModels.scala:507) finished in 0.020 s\n",
      "10-20 14:47:22.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 317 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 462: Stage finished\n",
      "10-20 14:47:22.206 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 317 finished: parquet at treeModels.scala:507, took 0.021765 s\n",
      "10-20 14:47:22.224 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:22.224 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:22.224 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, metadata: string, weights: double ... 1 more fields>\n",
      "10-20 14:47:22.227 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_694 stored as values in memory (estimated size 177.5 KiB, free 432.6 MiB)\n",
      "10-20 14:47:22.233 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_694_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.5 MiB)\n",
      "10-20 14:47:22.233 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_694_piece0 in memory on 95675304fa2d:39429 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.234 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 694 from rdd at treeModels.scala:509\n",
      "10-20 14:47:22.235 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4198039 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:22.248 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:514\n",
      "10-20 14:47:22.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 318 (sortByKey at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:47:22.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 463 (sortByKey at treeModels.scala:514)\n",
      "10-20 14:47:22.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.249 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 463 (MapPartitionsRDD[1127] at sortByKey at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:47:22.250 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_695 stored as values in memory (estimated size 20.0 KiB, free 432.5 MiB)\n",
      "10-20 14:47:22.276 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_695_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 432.5 MiB)\n",
      "10-20 14:47:22.276 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_695_piece0 in memory on 95675304fa2d:39429 (size: 9.0 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.278 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_686_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.278 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_690_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.279 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 695 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 463 (MapPartitionsRDD[1127] at sortByKey at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.280 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 463.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.280 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_683_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.281 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 463.0 (TID 888) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.281 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 463.0 (TID 889) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.282 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 463.0 (TID 890) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.282 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 463.0 (TID 891) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4998 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.282 172.17.0.2:54325      7233    (TID 889)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 463.0 (TID 889)\n",
      "10-20 14:47:22.282 172.17.0.2:54325      7233    (TID 891)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 463.0 (TID 891)\n",
      "10-20 14:47:22.282 172.17.0.2:54325      7233    (TID 888)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 463.0 (TID 888)\n",
      "10-20 14:47:22.283 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_692_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:22.283 172.17.0.2:54325      7233    (TID 890)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 463.0 (TID 890)\n",
      "10-20 14:47:22.285 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_685_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.286 172.17.0.2:54325      7233    (TID 890)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00000-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3726, partition values: [empty row]\n",
      "10-20 14:47:22.288 172.17.0.2:54325      7233    (TID 891)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00003-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3712, partition values: [empty row]\n",
      "10-20 14:47:22.289 172.17.0.2:54325      7233    (TID 888)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00001-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3756, partition values: [empty row]\n",
      "10-20 14:47:22.303 172.17.0.2:54325      7233    (TID 889)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00002-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3747, partition values: [empty row]\n",
      "10-20 14:47:22.312 172.17.0.2:54325      7233    (TID 888)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 463.0 (TID 888). 1953 bytes result sent to driver\n",
      "10-20 14:47:22.323 172.17.0.2:54325      7233    (TID 889)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 463.0 (TID 889). 1953 bytes result sent to driver\n",
      "10-20 14:47:22.319 172.17.0.2:54325      7233    (TID 891)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 463.0 (TID 891). 1953 bytes result sent to driver\n",
      "10-20 14:47:22.314 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_684_piece0 on 95675304fa2d:39429 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.325 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 463.0 (TID 888) in 44 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.325 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 463.0 (TID 889) in 44 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.325 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 463.0 (TID 891) in 43 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.326 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_688_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.328 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_680_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.330 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_691_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.331 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_693_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.332 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_682_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.333 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_689_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.334 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_681_piece0 on 95675304fa2d:39429 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.335 172.17.0.2:54325      7233    (TID 890)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 463.0 (TID 890). 1953 bytes result sent to driver\n",
      "10-20 14:47:22.335 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 463.0 (TID 890) in 53 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.335 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 463.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 463 (sortByKey at treeModels.scala:514) finished in 0.086 s\n",
      "10-20 14:47:22.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 318 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.336 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 463: Stage finished\n",
      "10-20 14:47:22.336 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 318 finished: sortByKey at treeModels.scala:514, took 0.087580 s\n",
      "10-20 14:47:22.344 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:514\n",
      "10-20 14:47:22.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 1125 (map at treeModels.scala:510) as input to shuffle 140\n",
      "10-20 14:47:22.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 319 (collect at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:47:22.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 465 (collect at treeModels.scala:514)\n",
      "10-20 14:47:22.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 464)\n",
      "10-20 14:47:22.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 464)\n",
      "10-20 14:47:22.345 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 464 (MapPartitionsRDD[1125] at map at treeModels.scala:510), which has no missing parents\n",
      "10-20 14:47:22.346 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_696 stored as values in memory (estimated size 20.7 KiB, free 434.0 MiB)\n",
      "10-20 14:47:22.347 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_696_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.9 MiB)\n",
      "10-20 14:47:22.347 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_687_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.347 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_696_piece0 in memory on 95675304fa2d:39429 (size: 9.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.348 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 696 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.348 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 464 (MapPartitionsRDD[1125] at map at treeModels.scala:510) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.348 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 464.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.348 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 464.0 (TID 892) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.349 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 464.0 (TID 893) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.349 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 464.0 (TID 894) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.349 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 464.0 (TID 895) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4987 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.349 172.17.0.2:54325      7233    (TID 892)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 464.0 (TID 892)\n",
      "10-20 14:47:22.349 172.17.0.2:54325      7233    (TID 893)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 464.0 (TID 893)\n",
      "10-20 14:47:22.353 172.17.0.2:54325      7233    (TID 893)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00002-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3747, partition values: [empty row]\n",
      "10-20 14:47:22.354 172.17.0.2:54325      7233    (TID 894)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 464.0 (TID 894)\n",
      "10-20 14:47:22.356 172.17.0.2:54325      7233    (TID 895)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 464.0 (TID 895)\n",
      "10-20 14:47:22.361 172.17.0.2:54325      7233    (TID 895)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00003-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3712, partition values: [empty row]\n",
      "10-20 14:47:22.365 172.17.0.2:54325      7233    (TID 893)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 464.0 (TID 893). 1906 bytes result sent to driver\n",
      "10-20 14:47:22.366 172.17.0.2:54325      7233    (TID 894)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00000-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3726, partition values: [empty row]\n",
      "10-20 14:47:22.368 172.17.0.2:54325      7233    (TID 892)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/treesMetadata/part-00001-06689fce-9897-4453-9651-ccf1827b39cb-c000.snappy.parquet, range: 0-3756, partition values: [empty row]\n",
      "10-20 14:47:22.371 172.17.0.2:54325      7233    (TID 894)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 464.0 (TID 894). 1906 bytes result sent to driver\n",
      "10-20 14:47:22.371 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 464.0 (TID 893) in 22 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.372 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 464.0 (TID 894) in 23 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.373 172.17.0.2:54325      7233    (TID 895)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 464.0 (TID 895). 1906 bytes result sent to driver\n",
      "10-20 14:47:22.374 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 464.0 (TID 895) in 25 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.376 172.17.0.2:54325      7233    (TID 892)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 464.0 (TID 892). 1906 bytes result sent to driver\n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 464.0 (TID 892) in 29 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 464.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 464 (map at treeModels.scala:510) finished in 0.031 s\n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 465)\n",
      "10-20 14:47:22.377 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:22.378 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 465 (MapPartitionsRDD[1129] at values at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:47:22.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_697 stored as values in memory (estimated size 4.6 KiB, free 433.9 MiB)\n",
      "10-20 14:47:22.379 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_697_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.9 MiB)\n",
      "10-20 14:47:22.380 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_697_piece0 in memory on 95675304fa2d:39429 (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 697 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 465 (MapPartitionsRDD[1129] at values at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.380 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 465.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.381 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 465.0 (TID 896) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.381 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 465.0 (TID 897) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.381 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 465.0 (TID 898) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.381 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 465.0 (TID 899) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.382 172.17.0.2:54325      7233    (TID 897)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 465.0 (TID 897)\n",
      "10-20 14:47:22.382 172.17.0.2:54325      7233    (TID 899)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 465.0 (TID 899)\n",
      "10-20 14:47:22.382 172.17.0.2:54325      7233    (TID 896)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 465.0 (TID 896)\n",
      "10-20 14:47:22.383 172.17.0.2:54325      7233    (TID 898)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 465.0 (TID 898)\n",
      "10-20 14:47:22.384 172.17.0.2:54325      7233    (TID 899)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.384 172.17.0.2:54325      7233    (TID 899)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.384 172.17.0.2:54325      7233    (TID 898)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.384 172.17.0.2:54325      7233    (TID 898)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.384 172.17.0.2:54325      7233    (TID 896)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.386 172.17.0.2:54325      7233    (TID 896)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:47:22.386 172.17.0.2:54325      7233    (TID 897)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.386 172.17.0.2:54325      7233    (TID 897)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.388 172.17.0.2:54325      7233    (TID 898)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 465.0 (TID 898). 9931 bytes result sent to driver\n",
      "10-20 14:47:22.388 172.17.0.2:54325      7233    (TID 899)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 465.0 (TID 899). 9974 bytes result sent to driver\n",
      "10-20 14:47:22.389 172.17.0.2:54325      7233    (TID 896)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 465.0 (TID 896). 9974 bytes result sent to driver\n",
      "10-20 14:47:22.391 172.17.0.2:54325      7233    (TID 897)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 465.0 (TID 897). 9974 bytes result sent to driver\n",
      "10-20 14:47:22.396 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 465.0 (TID 896) in 15 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.396 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 465.0 (TID 897) in 15 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.396 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 465.0 (TID 899) in 15 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.397 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 465.0 (TID 898) in 16 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.397 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 465.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 465 (collect at treeModels.scala:514) finished in 0.020 s\n",
      "10-20 14:47:22.398 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 319 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.399 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 465: Stage finished\n",
      "10-20 14:47:22.399 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 319 finished: collect at treeModels.scala:514, took 0.054171 s\n",
      "10-20 14:47:22.408 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:22.433 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:519\n",
      "10-20 14:47:22.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 320 (parquet at treeModels.scala:519) with 1 output partitions\n",
      "10-20 14:47:22.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 466 (parquet at treeModels.scala:519)\n",
      "10-20 14:47:22.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:22.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:22.434 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 466 (MapPartitionsRDD[1131] at parquet at treeModels.scala:519), which has no missing parents\n",
      "10-20 14:47:22.442 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_698 stored as values in memory (estimated size 84.5 KiB, free 433.9 MiB)\n",
      "10-20 14:47:22.443 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_698_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.8 MiB)\n",
      "10-20 14:47:22.443 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_698_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.444 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 698 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 466 (MapPartitionsRDD[1131] at parquet at treeModels.scala:519) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:22.445 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 466.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:22.446 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 466.0 (TID 900) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4738 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.446 172.17.0.2:54325      7233    (TID 900)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 466.0 (TID 900)\n",
      "10-20 14:47:22.453 172.17.0.2:54325      7233    (TID 900)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 466.0 (TID 900). 2376 bytes result sent to driver\n",
      "10-20 14:47:22.454 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 466.0 (TID 900) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:22.454 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 466.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.454 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 466 (parquet at treeModels.scala:519) finished in 0.020 s\n",
      "10-20 14:47:22.455 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 320 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.455 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 466: Stage finished\n",
      "10-20 14:47:22.456 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 320 finished: parquet at treeModels.scala:519, took 0.022586 s\n",
      "10-20 14:47:22.509 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:22.510 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:22.510 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, nodeData: struct<id: int, prediction: double, impurity: double, impurityStats: array<double>, rawCount: bigint ... 7 more fields>>\n",
      "10-20 14:47:22.513 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_699 stored as values in memory (estimated size 179.3 KiB, free 433.6 MiB)\n",
      "10-20 14:47:22.520 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_699_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:22.520 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_699_piece0 in memory on 95675304fa2d:39429 (size: 29.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.521 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 699 from rdd at treeModels.scala:530\n",
      "10-20 14:47:22.522 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4214077 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:536\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 1137 (map at treeModels.scala:531) as input to shuffle 141\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 321 (sortByKey at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 468 (sortByKey at treeModels.scala:536)\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 467)\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 467)\n",
      "10-20 14:47:22.545 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 467 (MapPartitionsRDD[1137] at map at treeModels.scala:531), which has no missing parents\n",
      "10-20 14:47:22.547 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_700 stored as values in memory (estimated size 25.2 KiB, free 433.6 MiB)\n",
      "10-20 14:47:22.547 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_700_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 433.6 MiB)\n",
      "10-20 14:47:22.547 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_700_piece0 in memory on 95675304fa2d:39429 (size: 9.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:22.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 700 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 467 (MapPartitionsRDD[1137] at map at treeModels.scala:531) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.548 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 467.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.549 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 467.0 (TID 901) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.549 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 467.0 (TID 902) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.549 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 467.0 (TID 903) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.550 172.17.0.2:54325      7233   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 467.0 (TID 904) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4978 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.550 172.17.0.2:54325      7233    (TID 901)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 467.0 (TID 901)\n",
      "10-20 14:47:22.550 172.17.0.2:54325      7233    (TID 903)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 467.0 (TID 903)\n",
      "10-20 14:47:22.551 172.17.0.2:54325      7233    (TID 902)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 467.0 (TID 902)\n",
      "10-20 14:47:22.553 172.17.0.2:54325      7233    (TID 904)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 467.0 (TID 904)\n",
      "10-20 14:47:22.563 172.17.0.2:54325      7233    (TID 902)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00001-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-20009, partition values: [empty row]\n",
      "10-20 14:47:22.568 172.17.0.2:54325      7233    (TID 901)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00000-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-20045, partition values: [empty row]\n",
      "10-20 14:47:22.563 172.17.0.2:54325      7233    (TID 903)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00002-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-19765, partition values: [empty row]\n",
      "10-20 14:47:22.574 172.17.0.2:54325      7233    (TID 903)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 301 records.\n",
      "10-20 14:47:22.578 172.17.0.2:54325      7233    (TID 902)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 311 records.\n",
      "10-20 14:47:22.575 172.17.0.2:54325      7233    (TID 904)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/18_GBTClassifier_5edea31ab14b/data/part-00003-d6587c46-2c43-4f15-b970-c8f1d364b988-c000.snappy.parquet, range: 0-19276, partition values: [empty row]\n",
      "10-20 14:47:22.574 172.17.0.2:54325      7233    (TID 901)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 307 records.\n",
      "10-20 14:47:22.580 172.17.0.2:54325      7233    (TID 903)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:22.581 172.17.0.2:54325      7233    (TID 902)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:22.581 172.17.0.2:54325      7233    (TID 901)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:22.583 172.17.0.2:54325      7233    (TID 902)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 311\n",
      "10-20 14:47:22.585 172.17.0.2:54325      7233    (TID 903)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 4 ms. row count = 301\n",
      "10-20 14:47:22.596 172.17.0.2:54325      7233    (TID 902)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 467.0 (TID 902). 1624 bytes result sent to driver\n",
      "10-20 14:47:22.597 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 467.0 (TID 902) in 48 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.601 172.17.0.2:54325      7233    (TID 904)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 289 records.\n",
      "10-20 14:47:22.601 172.17.0.2:54325      7233    (TID 901)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 17 ms. row count = 307\n",
      "10-20 14:47:22.604 172.17.0.2:54325      7233    (TID 904)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:22.608 172.17.0.2:54325      7233    (TID 903)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 467.0 (TID 903). 1624 bytes result sent to driver\n",
      "10-20 14:47:22.608 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 467.0 (TID 903) in 59 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.610 172.17.0.2:54325      7233    (TID 904)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 6 ms. row count = 289\n",
      "10-20 14:47:22.643 172.17.0.2:54325      7233    (TID 901)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 467.0 (TID 901). 1624 bytes result sent to driver\n",
      "10-20 14:47:22.644 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 467.0 (TID 901) in 95 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.644 172.17.0.2:54325      7233    (TID 904)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 467.0 (TID 904). 1624 bytes result sent to driver\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 467.0 (TID 904) in 96 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 467.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 467 (map at treeModels.scala:531) finished in 0.099 s\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 468)\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:22.645 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 468 (MapPartitionsRDD[1141] at sortByKey at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:47:22.647 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_701 stored as values in memory (estimated size 27.4 KiB, free 433.6 MiB)\n",
      "10-20 14:47:22.648 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_701_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.648 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_701_piece0 in memory on 95675304fa2d:39429 (size: 10.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.648 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 701 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.649 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 468 (MapPartitionsRDD[1141] at sortByKey at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.649 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 468.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.650 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 468.0 (TID 905) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.651 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 468.0 (TID 906) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.651 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 468.0 (TID 907) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.651 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 468.0 (TID 908) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.651 172.17.0.2:54325      7233    (TID 908)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 468.0 (TID 908)\n",
      "10-20 14:47:22.651 172.17.0.2:54325      7233    (TID 906)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 468.0 (TID 906)\n",
      "10-20 14:47:22.652 172.17.0.2:54325      7233    (TID 907)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 468.0 (TID 907)\n",
      "10-20 14:47:22.652 172.17.0.2:54325      7233    (TID 905)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 468.0 (TID 905)\n",
      "10-20 14:47:22.658 172.17.0.2:54325      7233    (TID 907)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (24.3 KiB) non-empty blocks including 4 (24.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.658 172.17.0.2:54325      7233    (TID 907)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.659 172.17.0.2:54325      7233    (TID 908)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.8 KiB) non-empty blocks including 4 (23.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.659 172.17.0.2:54325      7233    (TID 908)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.664 172.17.0.2:54325      7233    (TID 908)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 468.0 (TID 908). 2015 bytes result sent to driver\n",
      "10-20 14:47:22.665 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 468.0 (TID 908) in 14 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.665 172.17.0.2:54325      7233    (TID 906)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.665 172.17.0.2:54325      7233    (TID 906)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.666 172.17.0.2:54325      7233    (TID 907)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 468.0 (TID 907). 2015 bytes result sent to driver\n",
      "10-20 14:47:22.666 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 468.0 (TID 907) in 15 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.669 172.17.0.2:54325      7233    (TID 905)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.669 172.17.0.2:54325      7233    (TID 905)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.677 172.17.0.2:54325      7233    (TID 905)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 468.0 (TID 905). 2015 bytes result sent to driver\n",
      "10-20 14:47:22.677 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 468.0 (TID 905) in 27 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.678 172.17.0.2:54325      7233    (TID 906)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 468.0 (TID 906). 2015 bytes result sent to driver\n",
      "10-20 14:47:22.678 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 468.0 (TID 906) in 28 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.679 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 468.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 468 (sortByKey at treeModels.scala:536) finished in 0.033 s\n",
      "10-20 14:47:22.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 321 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.679 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 468: Stage finished\n",
      "10-20 14:47:22.680 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 321 finished: sortByKey at treeModels.scala:536, took 0.134783 s\n",
      "10-20 14:47:22.687 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:536\n",
      "10-20 14:47:22.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 1139 (map at treeModels.scala:533) as input to shuffle 142\n",
      "10-20 14:47:22.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 322 (collect at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:47:22.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 471 (collect at treeModels.scala:536)\n",
      "10-20 14:47:22.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 470)\n",
      "10-20 14:47:22.687 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 470)\n",
      "10-20 14:47:22.688 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 470 (MapPartitionsRDD[1139] at map at treeModels.scala:533), which has no missing parents\n",
      "10-20 14:47:22.689 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_702 stored as values in memory (estimated size 26.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.690 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_702_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.690 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_702_piece0 in memory on 95675304fa2d:39429 (size: 10.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.690 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 702 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.690 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 470 (MapPartitionsRDD[1139] at map at treeModels.scala:533) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.690 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 470.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.691 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 470.0 (TID 909) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.691 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 470.0 (TID 910) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.691 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 470.0 (TID 911) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.692 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 470.0 (TID 912) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.692 172.17.0.2:54325      7233    (TID 909)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 470.0 (TID 909)\n",
      "10-20 14:47:22.692 172.17.0.2:54325      7233    (TID 912)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 470.0 (TID 912)\n",
      "10-20 14:47:22.692 172.17.0.2:54325      7233    (TID 911)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 470.0 (TID 911)\n",
      "10-20 14:47:22.693 172.17.0.2:54325      7233    (TID 910)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 470.0 (TID 910)\n",
      "10-20 14:47:22.695 172.17.0.2:54325      7233    (TID 912)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.8 KiB) non-empty blocks including 4 (23.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.695 172.17.0.2:54325      7233    (TID 912)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.696 172.17.0.2:54325      7233    (TID 910)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.696 172.17.0.2:54325      7233    (TID 910)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.697 172.17.0.2:54325      7233    (TID 909)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (23.4 KiB) non-empty blocks including 4 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.697 172.17.0.2:54325      7233    (TID 909)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.703 172.17.0.2:54325      7233    (TID 912)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 470.0 (TID 912). 1968 bytes result sent to driver\n",
      "10-20 14:47:22.704 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 470.0 (TID 912) in 12 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.706 172.17.0.2:54325      7233    (TID 911)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (24.3 KiB) non-empty blocks including 4 (24.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.706 172.17.0.2:54325      7233    (TID 911)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.712 172.17.0.2:54325      7233    (TID 910)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 470.0 (TID 910). 1968 bytes result sent to driver\n",
      "10-20 14:47:22.715 172.17.0.2:54325      7233    (TID 911)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 470.0 (TID 911). 1968 bytes result sent to driver\n",
      "10-20 14:47:22.715 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 470.0 (TID 910) in 24 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.716 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 470.0 (TID 911) in 25 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.717 172.17.0.2:54325      7233    (TID 909)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 470.0 (TID 909). 1968 bytes result sent to driver\n",
      "10-20 14:47:22.718 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 470.0 (TID 909) in 27 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.718 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 470.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 470 (map at treeModels.scala:533) finished in 0.031 s\n",
      "10-20 14:47:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:47:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:47:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 471)\n",
      "10-20 14:47:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:47:22.719 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 471 (MapPartitionsRDD[1143] at values at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:47:22.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_703 stored as values in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.720 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_703_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.5 MiB)\n",
      "10-20 14:47:22.720 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_703_piece0 in memory on 95675304fa2d:39429 (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:22.721 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 703 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:22.721 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 471 (MapPartitionsRDD[1143] at values at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:47:22.721 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 471.0 with 4 tasks resource profile 0\n",
      "10-20 14:47:22.722 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 471.0 (TID 913) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.722 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 471.0 (TID 914) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.722 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 471.0 (TID 915) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.722 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 471.0 (TID 916) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:22.723 172.17.0.2:54325      7233    (TID 915)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 471.0 (TID 915)\n",
      "10-20 14:47:22.723 172.17.0.2:54325      7233    (TID 916)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 471.0 (TID 916)\n",
      "10-20 14:47:22.723 172.17.0.2:54325      7233    (TID 913)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 471.0 (TID 913)\n",
      "10-20 14:47:22.726 172.17.0.2:54325      7233    (TID 916)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (21.6 KiB) non-empty blocks including 4 (21.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.726 172.17.0.2:54325      7233    (TID 916)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.726 172.17.0.2:54325      7233    (TID 913)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (21.7 KiB) non-empty blocks including 4 (21.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.726 172.17.0.2:54325      7233    (TID 913)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.729 172.17.0.2:54325      7233    (TID 913)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 471.0 (TID 913). 30593 bytes result sent to driver\n",
      "10-20 14:47:22.729 172.17.0.2:54325      7233    (TID 915)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (21.7 KiB) non-empty blocks including 4 (21.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.729 172.17.0.2:54325      7233    (TID 915)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.730 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 471.0 (TID 913) in 8 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:47:22.730 172.17.0.2:54325      7233    (TID 916)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 471.0 (TID 916). 29759 bytes result sent to driver\n",
      "10-20 14:47:22.731 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 471.0 (TID 916) in 9 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:47:22.733 172.17.0.2:54325      7233    (TID 915)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 471.0 (TID 915). 30092 bytes result sent to driver\n",
      "10-20 14:47:22.733 172.17.0.2:54325      7233    (TID 914)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 471.0 (TID 914)\n",
      "10-20 14:47:22.734 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 471.0 (TID 915) in 12 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:47:22.735 172.17.0.2:54325      7233    (TID 914)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (22.5 KiB) non-empty blocks including 4 (22.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:47:22.735 172.17.0.2:54325      7233    (TID 914)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:47:22.737 172.17.0.2:54325      7233    (TID 914)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 471.0 (TID 914). 31102 bytes result sent to driver\n",
      "10-20 14:47:22.738 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 471.0 (TID 914) in 16 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:47:22.738 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 471.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:22.739 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 471 (collect at treeModels.scala:536) finished in 0.020 s\n",
      "10-20 14:47:22.739 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 322 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:22.739 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 471: Stage finished\n",
      "10-20 14:47:22.740 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 322 finished: collect at treeModels.scala:536, took 0.053442 s\n",
      "10-20 14:47:22.747 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [c36f8eac] training finished\n",
      "10-20 14:47:22.747 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [35e4f37d] training finished\n",
      "10-20 14:47:23.152 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:23.152 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:23.152 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<fnlwgt: double, age: double, capital_gain: double, capital_loss: double, hours_per_week: double ... 3 more fields>\n",
      "10-20 14:47:23.158 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_704 stored as values in memory (estimated size 177.8 KiB, free 433.3 MiB)\n",
      "10-20 14:47:23.178 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_694_piece0 on 95675304fa2d:39429 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.179 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_702_piece0 on 95675304fa2d:39429 in memory (size: 10.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.180 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_698_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.181 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_696_piece0 on 95675304fa2d:39429 in memory (size: 9.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.182 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_697_piece0 on 95675304fa2d:39429 in memory (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.183 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_699_piece0 on 95675304fa2d:39429 in memory (size: 29.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.185 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_703_piece0 on 95675304fa2d:39429 in memory (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.186 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_564_piece0 on 95675304fa2d:39429 in memory (size: 27.2 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:23.188 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_701_piece0 on 95675304fa2d:39429 in memory (size: 10.5 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:23.189 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_700_piece0 on 95675304fa2d:39429 in memory (size: 9.6 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:23.190 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_695_piece0 on 95675304fa2d:39429 in memory (size: 9.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:23.193 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_704_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 434.2 MiB)\n",
      "10-20 14:47:23.193 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_704_piece0 in memory on 95675304fa2d:39429 (size: 28.7 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:23.194 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 704 from head at Imputer.scala:258\n",
      "10-20 14:47:23.195 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:23.199 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 14:47:23.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 323 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 14:47:23.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 472 (head at Imputer.scala:258)\n",
      "10-20 14:47:23.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:23.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:23.200 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 472 (MapPartitionsRDD[1147] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 14:47:23.204 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_705 stored as values in memory (estimated size 14.0 KiB, free 434.2 MiB)\n",
      "10-20 14:47:23.205 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_705_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)\n",
      "10-20 14:47:23.205 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_705_piece0 in memory on 95675304fa2d:39429 (size: 5.7 KiB, free: 434.4 MiB)\n",
      "10-20 14:47:23.206 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 705 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:23.206 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 472 (MapPartitionsRDD[1147] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:23.206 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 472.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:23.207 172.17.0.2:54325      7233   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 472.0 (TID 917) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4983 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:23.207 172.17.0.2:54325      7233    (TID 917)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 472.0 (TID 917)\n",
      "10-20 14:47:23.209 172.17.0.2:54325      7233    (TID 917)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_gbt_spark/stages/00_Imputer_5f47cad80ae8/data/part-00000-00523588-2aad-476c-bf4a-827327bc5b66-c000.snappy.parquet, range: 0-1479, partition values: [empty row]\n",
      "10-20 14:47:23.213 172.17.0.2:54325      7233    (TID 917)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 472.0 (TID 917). 1700 bytes result sent to driver\n",
      "10-20 14:47:23.214 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 472.0 (TID 917) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:23.214 172.17.0.2:54325      7233   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 472.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:23.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 472 (head at Imputer.scala:258) finished in 0.015 s\n",
      "10-20 14:47:23.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 323 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:23.215 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 472: Stage finished\n",
      "10-20 14:47:23.216 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 323 finished: head at Imputer.scala:258, took 0.016128 s\n",
      "10-20 14:47:23.790 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:23.790 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:23.790 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 11 more fields>\n",
      "10-20 14:47:23.798 172.17.0.2:54325      7233     Thread-4  WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "10-20 14:47:23.806 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:47:23.808 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:47:23.808 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:47:23.839 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 15.848968 ms\n",
      "10-20 14:47:23.885 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 26.89792 ms\n",
      "10-20 14:47:23.886 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_706 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:47:23.890 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_706_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 14:47:23.891 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_706_piece0 in memory on 95675304fa2d:39429 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:47:23.891 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 706 from parquet at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:47:23.892 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:23.943 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:47:23.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 324 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:47:23.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 473 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:47:23.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:23.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:23.943 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 473 (MapPartitionsRDD[1153] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:47:23.957 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_707 stored as values in memory (estimated size 461.2 KiB, free 433.5 MiB)\n",
      "10-20 14:47:23.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_707_piece0 stored as bytes in memory (estimated size 188.0 KiB, free 433.3 MiB)\n",
      "10-20 14:47:23.959 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_707_piece0 in memory on 95675304fa2d:39429 (size: 188.0 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:23.959 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 707 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:23.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 473 (MapPartitionsRDD[1153] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:23.960 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 473.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:23.960 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 473.0 (TID 918) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4865 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:23.961 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 473.0 (TID 918)\n",
      "10-20 14:47:23.996 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.521884 ms\n",
      "10-20 14:47:24.011 172.17.0.2:54325      7233   bin/python  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n",
      "10-20 14:47:24.020 172.17.0.2:54325      7233   bin/python  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.364917 ms\n",
      "10-20 14:47:24.021 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.203786 ms\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:47:24.026 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:47:24.030 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"rawPrediction\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"udt\",\n",
      "      \"class\" : \"org.apache.spark.ml.linalg.VectorUDT\",\n",
      "      \"pyClass\" : \"pyspark.ml.linalg.VectorUDT\",\n",
      "      \"sqlType\" : {\n",
      "        \"type\" : \"struct\",\n",
      "        \"fields\" : [ {\n",
      "          \"name\" : \"type\",\n",
      "          \"type\" : \"byte\",\n",
      "          \"nullable\" : false,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"size\",\n",
      "          \"type\" : \"integer\",\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"indices\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"integer\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"values\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"double\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        } ]\n",
      "      }\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"ml_attr\" : {\n",
      "        \"num_attrs\" : 2\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"probability\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"udt\",\n",
      "      \"class\" : \"org.apache.spark.ml.linalg.VectorUDT\",\n",
      "      \"pyClass\" : \"pyspark.ml.linalg.VectorUDT\",\n",
      "      \"sqlType\" : {\n",
      "        \"type\" : \"struct\",\n",
      "        \"fields\" : [ {\n",
      "          \"name\" : \"type\",\n",
      "          \"type\" : \"byte\",\n",
      "          \"nullable\" : false,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"size\",\n",
      "          \"type\" : \"integer\",\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"indices\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"integer\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"values\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"double\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        } ]\n",
      "      }\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"ml_attr\" : {\n",
      "        \"num_attrs\" : 2\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"prediction\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"ml_attr\" : {\n",
      "        \"type\" : \"nominal\",\n",
      "        \"num_vals\" : 2\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"prob\",\n",
      "    \"type\" : \"float\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group rawPrediction {\n",
      "    required int32 type (INT_8);\n",
      "    optional int32 size;\n",
      "    optional group indices (LIST) {\n",
      "      repeated group list {\n",
      "        required int32 element;\n",
      "      }\n",
      "    }\n",
      "    optional group values (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group probability {\n",
      "    required int32 type (INT_8);\n",
      "    optional int32 size;\n",
      "    optional group indices (LIST) {\n",
      "      repeated group list {\n",
      "        required int32 element;\n",
      "      }\n",
      "    }\n",
      "    optional group values (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  required double prediction;\n",
      "  optional float prob;\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 14:47:24.051 172.17.0.2:54325      7233   bin/python  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 3.806788 ms\n",
      "10-20 14:47:24.250 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_704_piece0 on 95675304fa2d:39429 in memory (size: 28.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:24.253 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_705_piece0 on 95675304fa2d:39429 in memory (size: 5.7 KiB, free: 434.2 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 473:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:47:25.183 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.sql.execution.python.PythonUDFRunner: Times: total = 934, boot = 4, init = 149, finish = 781\n",
      "10-20 14:47:25.187 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 713904\n",
      "10-20 14:47:25.231 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201447239074903291050190556_0473_m_000000_918: Committed\n",
      "10-20 14:47:25.232 172.17.0.2:54325      7233    (TID 918)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 473.0 (TID 918). 3211 bytes result sent to driver\n",
      "10-20 14:47:25.233 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 473.0 (TID 918) in 1273 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:25.233 172.17.0.2:54325      7233   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 473.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:25.234 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 473 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.290 s\n",
      "10-20 14:47:25.234 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 324 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:25.234 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 473: Stage finished\n",
      "10-20 14:47:25.234 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 324 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.291760 s\n",
      "10-20 14:47:25.244 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 6ad21ef6-6af8-4986-85b9-c74506719965 committed.\n",
      "10-20 14:47:25.244 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 6ad21ef6-6af8-4986-85b9-c74506719965.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml import (\n",
    "    PipelineModel\n",
    ")\n",
    "\n",
    " \n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "test_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(test_path)\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('education_num', 'income_level', 'label')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")\n",
    "\n",
    "pipeline_model = PipelineModel.load(model_path)\n",
    "udf_pos_prob = udf(lambda v: float(v[1]), FloatType())\n",
    "test_df_pred = pipeline_model.transform(test_df)\n",
    "test_df_pred = test_df_pred.withColumn('prob', udf_pos_prob(col('probability')))\n",
    "cols = ['rawPrediction', 'probability', 'prediction', 'prob']\n",
    "test_df_pred.select(*cols).write.parquet(pred_path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fd2d3b4-57be-4264-83d1-fe62a9faeff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:47:27.402 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:47:27.432 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:47:27.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 325 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:47:27.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 474 (load at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:47:27.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:27.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:27.433 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 474 (MapPartitionsRDD[1157] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:47:27.438 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_708 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:47:27.439 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_708_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:47:27.439 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_708_piece0 in memory on 95675304fa2d:39429 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:47:27.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 708 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:27.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 474 (MapPartitionsRDD[1157] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:27.440 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 474.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:27.441 172.17.0.2:54325      7233   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 474.0 (TID 919) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4700 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:27.442 172.17.0.2:54325      7233    (TID 919)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 474.0 (TID 919)\n",
      "10-20 14:47:27.449 172.17.0.2:54325      7233    (TID 919)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 474.0 (TID 919). 2794 bytes result sent to driver\n",
      "10-20 14:47:27.450 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 474.0 (TID 919) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:27.450 172.17.0.2:54325      7233   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 474.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:27.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 474 (load at NativeMethodAccessorImpl.java:0) finished in 0.017 s\n",
      "10-20 14:47:27.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 325 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:27.450 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 474: Stage finished\n",
      "10-20 14:47:27.451 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 325 finished: load at NativeMethodAccessorImpl.java:0, took 0.018613 s\n",
      "10-20 14:47:27.462 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:47:27.463 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:47:27.463 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<rawPrediction: vector, probability: vector, prediction: double, prob: float ... 2 more fields>\n",
      "10-20 14:47:27.465 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_709 stored as values in memory (estimated size 179.8 KiB, free 433.3 MiB)\n",
      "10-20 14:47:27.470 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_709_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 433.3 MiB)\n",
      "10-20 14:47:27.470 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_709_piece0 in memory on 95675304fa2d:39429 (size: 29.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:27.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 709 from toPandas at /tmp/ipykernel_7175/2714203179.py:1\n",
      "10-20 14:47:27.471 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:47:27.474 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.SparkContext: Starting job: toPandas at /tmp/ipykernel_7175/2714203179.py:1\n",
      "10-20 14:47:27.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 326 (toPandas at /tmp/ipykernel_7175/2714203179.py:1) with 1 output partitions\n",
      "10-20 14:47:27.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 475 (toPandas at /tmp/ipykernel_7175/2714203179.py:1)\n",
      "10-20 14:47:27.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:47:27.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:47:27.475 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 475 (MapPartitionsRDD[1160] at toPandas at /tmp/ipykernel_7175/2714203179.py:1), which has no missing parents\n",
      "10-20 14:47:27.476 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_710 stored as values in memory (estimated size 10.1 KiB, free 433.2 MiB)\n",
      "10-20 14:47:27.477 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_710_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 433.2 MiB)\n",
      "10-20 14:47:27.477 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_710_piece0 in memory on 95675304fa2d:39429 (size: 5.3 KiB, free: 434.1 MiB)\n",
      "10-20 14:47:27.477 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 710 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:47:27.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 475 (MapPartitionsRDD[1160] at toPandas at /tmp/ipykernel_7175/2714203179.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:47:27.478 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 475.0 with 1 tasks resource profile 0\n",
      "10-20 14:47:27.478 172.17.0.2:54325      7233   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 475.0 (TID 920) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()\n",
      "10-20 14:47:27.479 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 475.0 (TID 920)\n",
      "10-20 14:47:27.491 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 9.132137 ms\n",
      "10-20 14:47:27.493 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark_pred/part-00000-dc0e79c5-633e-4f04-85de-5c522a931a95-c000.snappy.parquet, range: 0-243443, partition values: [empty row]\n",
      "10-20 14:47:27.499 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 16282 records.\n",
      "10-20 14:47:27.501 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:47:27.505 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 16282\n",
      "10-20 14:47:27.513 172.17.0.2:54325      7233    (TID 920)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 475.0 (TID 920). 2122 bytes result sent to driver\n",
      "10-20 14:47:27.514 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 475.0 (TID 920) in 36 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:47:27.514 172.17.0.2:54325      7233   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 475.0, whose tasks have all completed, from pool \n",
      "10-20 14:47:27.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 475 (toPandas at /tmp/ipykernel_7175/2714203179.py:1) finished in 0.038 s\n",
      "10-20 14:47:27.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 326 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:47:27.514 172.17.0.2:54325      7233   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 475: Stage finished\n",
      "10-20 14:47:27.514 172.17.0.2:54325      7233     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 326 finished: toPandas at /tmp/ipykernel_7175/2714203179.py:1, took 0.039779 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[16.37736275283466, 3.622637247165343]</td>\n",
       "      <td>[0.8188681376417328, 0.18113186235826712]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[19.010115101836554, 0.9898848981634504]</td>\n",
       "      <td>[0.9505057550918276, 0.04949424490817251]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[13.375161764175118, 6.624838235824885]</td>\n",
       "      <td>[0.6687580882087558, 0.33124191179124424]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13.326906456552484, 6.673093543447515]</td>\n",
       "      <td>[0.6663453228276242, 0.33365467717237574]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[8.207082112497687, 11.792917887502313]</td>\n",
       "      <td>[0.4103541056248844, 0.5896458943751156]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[19.021352795491893, 0.9786472045081104]</td>\n",
       "      <td>[0.9510676397745945, 0.04893236022540551]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[18.497068651104033, 1.5029313488959692]</td>\n",
       "      <td>[0.9248534325552015, 0.07514656744479845]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[18.23298354762287, 1.7670164523771308]</td>\n",
       "      <td>[0.9116491773811435, 0.08835082261885654]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[10.331123697187872, 9.668876302812127]</td>\n",
       "      <td>[0.5165561848593936, 0.4834438151406063]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[18.87149111861569, 1.1285088813843114]</td>\n",
       "      <td>[0.9435745559307845, 0.05642544406921557]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              rawPrediction  \\\n",
       "0    [16.37736275283466, 3.622637247165343]   \n",
       "1  [19.010115101836554, 0.9898848981634504]   \n",
       "2   [13.375161764175118, 6.624838235824885]   \n",
       "3   [13.326906456552484, 6.673093543447515]   \n",
       "4   [8.207082112497687, 11.792917887502313]   \n",
       "5  [19.021352795491893, 0.9786472045081104]   \n",
       "6  [18.497068651104033, 1.5029313488959692]   \n",
       "7   [18.23298354762287, 1.7670164523771308]   \n",
       "8   [10.331123697187872, 9.668876302812127]   \n",
       "9   [18.87149111861569, 1.1285088813843114]   \n",
       "\n",
       "                                 probability  prediction      prob  \n",
       "0  [0.8188681376417328, 0.18113186235826712]         0.0  0.181132  \n",
       "1  [0.9505057550918276, 0.04949424490817251]         0.0  0.049494  \n",
       "2  [0.6687580882087558, 0.33124191179124424]         0.0  0.331242  \n",
       "3  [0.6663453228276242, 0.33365467717237574]         0.0  0.333655  \n",
       "4   [0.4103541056248844, 0.5896458943751156]         1.0  0.589646  \n",
       "5  [0.9510676397745945, 0.04893236022540551]         0.0  0.048932  \n",
       "6  [0.9248534325552015, 0.07514656744479845]         0.0  0.075147  \n",
       "7  [0.9116491773811435, 0.08835082261885654]         0.0  0.088351  \n",
       "8   [0.5165561848593936, 0.4834438151406063]         0.0  0.483444  \n",
       "9  [0.9435745559307845, 0.05642544406921557]         0.0  0.056425  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:50:51.657 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_708_piece0 on 95675304fa2d:39429 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:50:51.720 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_710_piece0 on 95675304fa2d:39429 in memory (size: 5.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:50:51.788 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_706_piece0 on 95675304fa2d:39429 in memory (size: 28.0 KiB, free: 434.2 MiB)\n",
      "10-20 14:50:51.860 172.17.0.2:54325      7233   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_707_piece0 on 95675304fa2d:39429 in memory (size: 188.0 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "spark.read.load('outputs/income_rf_spark_pred').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eac30-5a4b-4d9f-b9f9-639949917577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
