{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3fd977-3107-4150-b241-c18247ac2d48",
   "metadata": {},
   "source": [
    "## Income Prediction with H2O AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b019947-3e52-4742-9a33-8dc33d9f32a3",
   "metadata": {},
   "source": [
    "### Install findspark and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0156047-cfe9-47e1-9622-74666342340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.9/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c38bc1-77fa-400a-b944-44e1d20757aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1712a2-81a4-459c-8e36-c7317a52a07c",
   "metadata": {},
   "source": [
    "### Get spark and h2o sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3e1e6-51bf-41ad-ab4a-d08c1ef14cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/10/20 18:24:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:24:25.421 172.17.0.2:54321      22766    Thread-4  INFO water.default: ----- H2O started  -----\n",
      "10-20 18:24:25.421 172.17.0.2:54321      22766    Thread-4  INFO water.default: Build git branch: rel-zz_kurka\n",
      "10-20 18:24:25.421 172.17.0.2:54321      22766    Thread-4  INFO water.default: Build git hash: 5ff8870f912c6110d7b6988f577c020de10496ec\n",
      "10-20 18:24:25.421 172.17.0.2:54321      22766    Thread-4  INFO water.default: Build git describe: jenkins-3.40.0.3-122-g5ff8870\n",
      "10-20 18:24:25.422 172.17.0.2:54321      22766    Thread-4  INFO water.default: Build project version: 3.40.0.4\n",
      "10-20 18:24:25.422 172.17.0.2:54321      22766    Thread-4  INFO water.default: Build age: 5 months and 22 days\n",
      "10-20 18:24:25.422 172.17.0.2:54321      22766    Thread-4  INFO water.default: Built by: 'jenkins'\n",
      "10-20 18:24:25.422 172.17.0.2:54321      22766    Thread-4  INFO water.default: Built on: '2023-04-28 12:08:23'\n",
      "10-20 18:24:25.422 172.17.0.2:54321      22766    Thread-4  WARN water.default: \n",
      "10-20 18:24:25.423 172.17.0.2:54321      22766    Thread-4  WARN water.default: *** Your H2O version is over 100 days old. Please download the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html ***\n",
      "10-20 18:24:25.423 172.17.0.2:54321      22766    Thread-4  WARN water.default: \n",
      "10-20 18:24:25.423 172.17.0.2:54321      22766    Thread-4  INFO water.default: Found H2O Core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 18:24:25.423 172.17.0.2:54321      22766    Thread-4  INFO water.default: Processed H2O arguments: [-internal_security_conf_rel_paths, -name, sparkling-water-root_local-1697826259251, -port_offset, 1, -hdfs_config, /tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/userFiles-539097db-4242-4bbe-b122-a239e5f7b603/hdfs_conf3011765124621775529.xml, -log_level, INFO, -embedded, -baseport, 54321, -log_dir, /home/jovyan/notebooks/h2ologs/local-1697826259251, -quiet, -flatfile, /tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/sparkling-water-04fd7788-2107-43d5-b640-6b96e2b1a7e0/flatfile.txt]\n",
      "10-20 18:24:25.423 172.17.0.2:54321      22766    Thread-4  INFO water.default: Java availableProcessors: 4\n",
      "10-20 18:24:25.424 172.17.0.2:54321      22766    Thread-4  INFO water.default: Java heap totalMemory: 126.0 MB\n",
      "10-20 18:24:25.424 172.17.0.2:54321      22766    Thread-4  INFO water.default: Java heap maxMemory: 1.00 GB\n",
      "10-20 18:24:25.424 172.17.0.2:54321      22766    Thread-4  INFO water.default: Java version: Java 11.0.11 (from Ubuntu)\n",
      "10-20 18:24:25.424 172.17.0.2:54321      22766    Thread-4  INFO water.default: JVM launch parameters: [-Xmx1g, -Dio.netty.tryReflectionSetAccessible=true]\n",
      "10-20 18:24:25.425 172.17.0.2:54321      22766    Thread-4  INFO water.default: JVM process id: 22766@95675304fa2d\n",
      "10-20 18:24:25.425 172.17.0.2:54321      22766    Thread-4  INFO water.default: OS version: Linux 5.15.49-linuxkit-pr (amd64)\n",
      "10-20 18:24:25.425 172.17.0.2:54321      22766    Thread-4  INFO water.default: Machine physical memory: 5.80 GB\n",
      "10-20 18:24:25.425 172.17.0.2:54321      22766    Thread-4  INFO water.default: Machine locale: en_US\n",
      "10-20 18:24:25.425 172.17.0.2:54321      22766    Thread-4  INFO water.default: X-h2o-cluster-id: 1697826262527\n",
      "10-20 18:24:25.425 172.17.0.2:54321      22766    Thread-4  INFO water.default: User name: 'root'\n",
      "10-20 18:24:25.426 172.17.0.2:54321      22766    Thread-4  INFO water.default: IPv6 stack selected: false\n",
      "10-20 18:24:25.426 172.17.0.2:54321      22766    Thread-4  INFO water.default: Possible IP Address: eth0 (eth0), 172.17.0.2\n",
      "10-20 18:24:25.426 172.17.0.2:54321      22766    Thread-4  INFO water.default: Possible IP Address: lo (lo), 127.0.0.1\n",
      "10-20 18:24:25.426 172.17.0.2:54321      22766    Thread-4  INFO water.default: H2O node running in unencrypted mode.\n",
      "10-20 18:24:25.428 172.17.0.2:54321      22766    Thread-4  INFO water.default: Internal communication uses port: 54322\n",
      "10-20 18:24:25.429 172.17.0.2:54321      22766    Thread-4  INFO water.default: Listening for HTTP and REST traffic on http://172.17.0.2:54321/\n",
      "10-20 18:24:25.430 172.17.0.2:54321      22766    Thread-4  WARN water.default: Flatfile configuration does not include self: /172.17.0.2:54321, but contains []\n",
      "10-20 18:24:25.430 172.17.0.2:54321      22766    Thread-4  INFO water.default: H2O cloud name: 'sparkling-water-root_local-1697826259251' on /172.17.0.2:54321, static configuration based on -flatfile /tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/sparkling-water-04fd7788-2107-43d5-b640-6b96e2b1a7e0/flatfile.txt\n",
      "10-20 18:24:25.430 172.17.0.2:54321      22766    Thread-4  INFO water.default: If you have trouble connecting, try SSH tunneling from your local machine (e.g., via port 55555):\n",
      "10-20 18:24:25.430 172.17.0.2:54321      22766    Thread-4  INFO water.default:   1. Open a terminal and run 'ssh -L 55555:localhost:54321 root@172.17.0.2'\n",
      "10-20 18:24:25.431 172.17.0.2:54321      22766    Thread-4  INFO water.default:   2. Point your browser to http://localhost:55555\n",
      "10-20 18:24:25.872 172.17.0.2:54321      22766    Thread-4  INFO water.default: Log dir: '/home/jovyan/notebooks/h2ologs/local-1697826259251'\n",
      "10-20 18:24:25.873 172.17.0.2:54321      22766    Thread-4  INFO water.default: Cur dir: '/home/jovyan/notebooks'\n",
      "10-20 18:24:25.884 172.17.0.2:54321      22766    Thread-4  INFO water.default: Distributed HTTP import not available (import from HTTP/HTTPS will be eager)\n",
      "10-20 18:24:25.902 172.17.0.2:54321      22766    Thread-4  INFO water.default: HDFS subsystem successfully initialized\n",
      "10-20 18:24:25.908 172.17.0.2:54321      22766    Thread-4  INFO water.default: S3 subsystem successfully initialized\n",
      "10-20 18:24:25.932 172.17.0.2:54321      22766    Thread-4  INFO water.default: GCS subsystem successfully initialized\n",
      "10-20 18:24:25.933 172.17.0.2:54321      22766    Thread-4  INFO water.default: Drive subsystem not available\n",
      "10-20 18:24:25.933 172.17.0.2:54321      22766    Thread-4  INFO water.default: Flow dir: '/root/h2oflows'\n",
      "10-20 18:24:25.945 172.17.0.2:54321      22766    Thread-4  INFO water.default: Cloud of size 1 formed [95675304fa2d/172.17.0.2:54321]\n",
      "10-20 18:24:25.961 172.17.0.2:54321      22766    Thread-4  INFO water.default: Registered parsers: [GUESS, ARFF, XLS, SVMLight, AVRO, PARQUET, ORC, CSV]\n",
      "10-20 18:24:25.963 172.17.0.2:54321      22766    Thread-4  INFO water.default: HiveTableImporter extension initialized\n",
      "10-20 18:24:25.963 172.17.0.2:54321      22766    Thread-4  INFO water.default: StackTraceCollector extension initialized\n",
      "10-20 18:24:25.964 172.17.0.2:54321      22766    Thread-4  INFO water.default: MojoPipeline extension initialized\n",
      "10-20 18:24:25.964 172.17.0.2:54321      22766    Thread-4  INFO water.default: HiveFrameSaver extension initialized\n",
      "10-20 18:24:25.964 172.17.0.2:54321      22766    Thread-4  INFO water.default: XGBoost extension initialized\n",
      "10-20 18:24:25.965 172.17.0.2:54321      22766    Thread-4  INFO water.default: Registered 5 core extensions in: 2583ms\n",
      "10-20 18:24:25.965 172.17.0.2:54321      22766    Thread-4  INFO water.default: Registered H2O core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 18:24:26.404 172.17.0.2:54321      22766    Thread-4  INFO hex.tree.xgboost.XGBoostExtension: Found XGBoost backend with library: xgboost4j_gpu\n",
      "10-20 18:24:26.405 172.17.0.2:54321      22766    Thread-4  INFO hex.tree.xgboost.XGBoostExtension: XGBoost supported backends: [WITH_GPU, WITH_OMP]\n",
      "10-20 18:24:26.549 172.17.0.2:54321      22766    Thread-4  INFO water.default: Registered: 280 REST APIs in: 584ms\n",
      "10-20 18:24:26.550 172.17.0.2:54321      22766    Thread-4  INFO water.default: Registered REST API extensions: [XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4]\n",
      "10-20 18:24:26.745 172.17.0.2:54321      22766    Thread-4  INFO water.default: Registered: 329 schemas in 194ms\n",
      "10-20 18:24:26.746 172.17.0.2:54321      22766    Thread-4  INFO water.default: H2O started in 4248ms\n",
      "10-20 18:24:26.747 172.17.0.2:54321      22766    Thread-4  INFO water.default: \n",
      "10-20 18:24:26.747 172.17.0.2:54321      22766    Thread-4  INFO water.default: Open H2O Flow in your web browser: http://172.17.0.2:54321\n",
      "10-20 18:24:26.748 172.17.0.2:54321      22766    Thread-4  INFO water.default: \n",
      "10-20 18:24:26.753 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OContext: Connecting to H2O cluster.\n",
      "10-20 18:24:26.754 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OContext: Trying to lock H2O cluster 172.17.0.2:54321 - sparkling-water-root_local-1697826259251.\n",
      "10-20 18:24:26.838 172.17.0.2:54321      22766  4648757-69  INFO water.default: POST /3/CloudLock, parms: {reason=Locked from Sparkling Water.}\n",
      "10-20 18:24:26.849 172.17.0.2:54321      22766  4648757-69  INFO water.default: Locking cloud to new members, because requested via REST api. Reason: Locked from Sparkling Water.\n",
      "10-20 18:24:26.907 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/CloudLock successfully responded for the POST.\n",
      "10-20 18:24:26.928 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /3/verifyWebOpen, parms: {}\n",
      "10-20 18:24:27.018 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/verifyWebOpen successfully responded for the GET.\n",
      "10-20 18:24:27.022 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /3/verifyVersion, parms: {referenced_version=3.40.0.4}\n",
      "10-20 18:24:27.041 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/verifyVersion?referenced_version=3.40.0.4 successfully responded for the GET.\n",
      "10-20 18:24:27.082 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 18:24:27.089 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /3/LogLevel, parms: {}\n",
      "10-20 18:24:27.105 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/LogLevel successfully responded for the GET.\n",
      "10-20 18:24:27.107 172.17.0.2:54321      22766  4648757-68  INFO water.default: POST /99/Rapids, parms: {ast=(setTimeZone \"UTC\")}\n",
      "10-20 18:24:27.258 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/99/Rapids successfully responded for the POST.\n",
      "10-20 18:24:27.273 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.ProxyStarter: Trying to bind on port 54323 using wildcard ip address\n",
      "10-20 18:24:27.470 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.util.SignalUtils: Registering signal handler for INT\n",
      "10-20 18:24:36.616 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: jetty-9.4.z-SNAPSHOT; built: 2018-06-05T18:24:03.829Z; git: d5fc0523cfa96bfebfbda19606cad384d772f04c; jvm 11.0.11+9-Ubuntu-0ubuntu2.20.04\n",
      "10-20 18:24:36.670 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.handler.ContextHandler: Started a.h.o.e.j.s.ServletContextHandler@6931c97d{/,null,AVAILABLE}\n",
      "10-20 18:24:36.671 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@5958d838{HTTP/1.1,[http/1.1]}{0.0.0.0:54323}\n",
      "10-20 18:24:36.672 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: Started @20739ms\n",
      "10-20 18:24:36.682 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 18:24:36.745 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OContext: Sparkling Water 3.40.0.4-1-3.1 started, status of context: \n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697826259251\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://95675304fa2d:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "     \n",
      "Connecting to H2O server at http://95675304fa2d:54323 ...10-20 18:24:36.845 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /3/Metadata/schemas/CloudV3, parms: {}\n",
      "10-20 18:24:36.910 172.17.0.2:54321      22766  4648757-68  INFO water.default: GET /3/Metadata/schemas/H2OErrorV3, parms: {}\n",
      "10-20 18:24:36.918 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /3/Metadata/schemas/H2OModelBuilderErrorV3, parms: {}\n",
      " successful.\n",
      "Warning: Your H2O cluster version is (5 months and 22 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>11 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-root_local-1697826259251</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://95675304fa2d:54323</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O_cluster_uptime:         11 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    5 months and 22 days\n",
       "H2O_cluster_name:           sparkling-water-root_local-1697826259251\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://95675304fa2d:54323\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697826259251\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://95675304fa2d:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import H2OContext\n",
    "import h2o\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.appName('cognetix-spark-nb')\n",
    "    .config('spark.dynamicAllocation.enabled', 'false')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "sc = spark.sparkContext\n",
    "hc = H2OContext.getOrCreate()\n",
    "h2o_cluster = h2o.cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b11a08-e309-4d12-a74d-56eeb12f1757",
   "metadata": {},
   "source": [
    "### Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d26e8b22-875e-49cc-ae40-499d37ab4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "learning_rate = 0.01\n",
    "train_rate = 0.8\n",
    "seed = 42\n",
    "\n",
    "train_path = '../data/census-train.csv'\n",
    "test_path = '../data/census-test.csv'\n",
    "model_path = 'outputs/income_automl_h2o'\n",
    "pred_path = 'outputs/income_automl_h2o_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c63fd9-3e8a-43ba-b0ae-c4048ce8e233",
   "metadata": {},
   "source": [
    "### Load data and basic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c40cb-18a9-4faa-897b-bdd2a3b33274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:24:37.484 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 35 ms to list leaf files for 1 paths.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "train_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(train_path)\n",
    "    .drop('education_num')\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('income_level')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dfb6c-b722-4fd7-ab7d-f9269e7b6a39",
   "metadata": {},
   "source": [
    "### Explore train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa121b-ad53-48ee-83aa-e6930ef42cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:24:38.584 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 18:24:38.598 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 18:24:38.603 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<>\n",
      "10-20 18:24:39.202 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 195.207898 ms\n",
      "10-20 18:24:39.227 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.612382 ms\n",
      "10-20 18:24:39.294 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 18:24:39.361 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 18:24:39.364 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 95675304fa2d:41565 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 18:24:39.366 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 0 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 18:24:39.405 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 18:24:39.604 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 18:24:39.620 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "10-20 18:24:39.624 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 18:24:39.625 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 1 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 18:24:39.626 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\n",
      "10-20 18:24:39.628 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)\n",
      "10-20 18:24:39.633 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 18:24:39.699 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.9 KiB, free 434.2 MiB)\n",
      "10-20 18:24:39.715 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.2 MiB)\n",
      "10-20 18:24:39.716 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 95675304fa2d:41565 (size: 8.1 KiB, free: 434.4 MiB)\n",
      "10-20 18:24:39.717 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:24:39.731 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:24:39.733 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "10-20 18:24:39.789 172.17.0.2:54321      22766  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 18:24:39.820 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "10-20 18:24:39.826 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Fetching file:/tmp/sparkling-water-7414130473929221804-hash-login.conf with timestamp 1697826262469\n",
      "10-20 18:24:39.861 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.util.Utils: /tmp/sparkling-water-7414130473929221804-hash-login.conf has been previously copied to /tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/userFiles-539097db-4242-4bbe-b122-a239e5f7b603/sparkling-water-7414130473929221804-hash-login.conf\n",
      "10-20 18:24:39.874 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Fetching file:/tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/hdfs_conf3011765124621775529.xml with timestamp 1697826262400\n",
      "10-20 18:24:39.877 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.util.Utils: /tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/hdfs_conf3011765124621775529.xml has been previously copied to /tmp/spark-c2b7a6ee-3242-4b5d-8dc1-708a545c9e8d/userFiles-539097db-4242-4bbe-b122-a239e5f7b603/hdfs_conf3011765124621775529.xml\n",
      "10-20 18:24:40.096 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 18:24:40.113 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 11.391672 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:===========================================================(1 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:24:40.322 172.17.0.2:54321      22766  .0 (TID 0)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2008 bytes result sent to driver\n",
      "10-20 18:24:40.331 172.17.0.2:54321      22766  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 556 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:24:40.334 172.17.0.2:54321      22766  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "10-20 18:24:40.345 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 0.698 s\n",
      "10-20 18:24:40.346 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 18:24:40.347 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 18:24:40.348 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 1)\n",
      "10-20 18:24:40.349 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 18:24:40.351 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 18:24:40.361 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 434.2 MiB)\n",
      "10-20 18:24:40.374 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.2 MiB)\n",
      "10-20 18:24:40.376 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 95675304fa2d:41565 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 18:24:40.378 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:24:40.381 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:24:40.381 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "10-20 18:24:40.390 172.17.0.2:54321      22766  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 18:24:40.392 172.17.0.2:54321      22766  .0 (TID 1)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "10-20 18:24:40.436 172.17.0.2:54321      22766  .0 (TID 1)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 18:24:40.438 172.17.0.2:54321      22766  .0 (TID 1)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 18:24:40.451 172.17.0.2:54321      22766  .0 (TID 1)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 2691 bytes result sent to driver\n",
      "10-20 18:24:40.463 172.17.0.2:54321      22766  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 76 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:24:40.464 172.17.0.2:54321      22766  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "10-20 18:24:40.465 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.105 s\n",
      "10-20 18:24:40.469 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:24:40.469 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "10-20 18:24:40.474 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 0 finished: count at NativeMethodAccessorImpl.java:0, took 0.869275 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c419a47-23f1-424c-9638-b2ce82e32c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_per_week',\n",
       " 'native_country',\n",
       " 'label']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afae865-b5c3-4e52-9f76-c28235e7c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n",
      "10-20 18:24:45.005 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on 95675304fa2d:41565 in memory (size: 8.1 KiB, free: 434.4 MiB)\n",
      "10-20 18:24:45.042 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on 95675304fa2d:41565 in memory (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 18:24:45.192 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on 95675304fa2d:41565 in memory (size: 28.0 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93430319-4f83-4946-a7ea-77e7362e8abd",
   "metadata": {},
   "source": [
    "### H2O Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f97377-33f2-494a-8018-e77e9273765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:25:16.778 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 18:25:16.779 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 18:25:16.779 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 18:25:16.850 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 39.8679 ms\n",
      "10-20 18:25:16.858 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 18:25:16.878 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 18:25:16.879 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 95675304fa2d:41565 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 18:25:16.881 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 3 from rdd at SparkDataFrameConverter.scala:53\n",
      "10-20 18:25:16.882 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 18:25:17.013 172.17.0.2:54321      22766  4648757-71  INFO water.default: POST /3/InitializeFrame, parms: {columns=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\"native_country\",\"label\"], key=frame_rdd_12598461418}\n",
      "10-20 18:25:17.135 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/InitializeFrame successfully responded for the POST.\n",
      "10-20 18:25:17.151 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: fold at PartitionStatsGenerator.scala:35\n",
      "10-20 18:25:17.158 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 1 (fold at PartitionStatsGenerator.scala:35) with 1 output partitions\n",
      "10-20 18:25:17.158 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 2 (fold at PartitionStatsGenerator.scala:35)\n",
      "10-20 18:25:17.159 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:25:17.163 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:25:17.166 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at mapPartitionsWithIndex at PartitionStatsGenerator.scala:29), which has no missing parents\n",
      "10-20 18:25:17.227 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 27.5 KiB, free 434.2 MiB)\n",
      "10-20 18:25:17.241 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 434.2 MiB)\n",
      "10-20 18:25:17.242 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 95675304fa2d:41565 (size: 11.8 KiB, free: 434.4 MiB)\n",
      "10-20 18:25:17.245 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:25:17.248 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at mapPartitionsWithIndex at PartitionStatsGenerator.scala:29) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:25:17.249 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "10-20 18:25:17.251 172.17.0.2:54321      22766  ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (95675304fa2d, executor driver, partition 0, ANY, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 18:25:17.252 172.17.0.2:54321      22766  .0 (TID 2)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "10-20 18:25:17.361 172.17.0.2:54321      22766  .0 (TID 2)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 56.682483 ms\n",
      "10-20 18:25:17.373 172.17.0.2:54321      22766  .0 (TID 2)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 18:25:17.467 172.17.0.2:54321      22766  .0 (TID 2)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 81.544356 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:25:17.825 172.17.0.2:54321      22766  .0 (TID 2)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 1787 bytes result sent to driver\n",
      "10-20 18:25:17.827 172.17.0.2:54321      22766  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 576 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:25:17.827 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 2 (fold at PartitionStatsGenerator.scala:35) finished in 0.657 s\n",
      "10-20 18:25:17.827 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:25:17.828 172.17.0.2:54321      22766  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "10-20 18:25:17.828 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "10-20 18:25:17.828 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 1 finished: fold at PartitionStatsGenerator.scala:35, took 0.676214 s\n",
      "10-20 18:25:17.831 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /3/UploadPlan, parms: {number_of_chunks=1}\n",
      "10-20 18:25:17.841 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/UploadPlan?number_of_chunks=1 successfully responded for the GET.\n",
      "10-20 18:25:17.866 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at Writer.scala:104\n",
      "10-20 18:25:17.867 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 2 (runJob at Writer.scala:104) with 1 output partitions\n",
      "10-20 18:25:17.867 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 3 (runJob at Writer.scala:104)\n",
      "10-20 18:25:17.867 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:25:17.867 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:25:17.868 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 3 (H2OAwareRDD[13] at RDD at H2OAwareBaseRDD.scala:29), which has no missing parents\n",
      "10-20 18:25:17.871 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 30.6 KiB, free 434.1 MiB)\n",
      "10-20 18:25:17.879 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 434.1 MiB)\n",
      "10-20 18:25:17.880 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 95675304fa2d:41565 (size: 13.7 KiB, free: 434.3 MiB)\n",
      "10-20 18:25:17.882 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:25:17.882 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (H2OAwareRDD[13] at RDD at H2OAwareBaseRDD.scala:29) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:25:17.882 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "10-20 18:25:17.884 172.17.0.2:54321      22766  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (95675304fa2d, executor driver, partition 0, ANY, 4866 bytes) taskResourceAssignments Map()\n",
      "10-20 18:25:17.884 172.17.0.2:54321      22766  .0 (TID 3)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "10-20 18:25:17.891 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on 95675304fa2d:41565 in memory (size: 11.8 KiB, free: 434.4 MiB)\n",
      "10-20 18:25:17.944 172.17.0.2:54321      22766  .0 (TID 3)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 18:25:18.409 172.17.0.2:54321      22766  .0 (TID 3)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/Chunk?frame_name=frame_rdd_12598461418&num_rows=32561&compression=SNAPPY&maximum_vector_sizes=&expected_types=BAsHCwsLCwsLBwcHCwQ%3D&chunk_id=0 successfully responded for the PUT.\n",
      "10-20 18:25:18.417 172.17.0.2:54321      22766  .0 (TID 3)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/ChunkCategoricalDomains?frame_name=frame_rdd_12598461418&chunk_id=0&compression=SNAPPY successfully responded for the PUT.\n",
      "10-20 18:25:18.417 172.17.0.2:54321      22766  .0 (TID 3)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/ChunkCategoricalDomains?frame_name=frame_rdd_12598461418&chunk_id=0&compression=SNAPPY successfully responded for the PUT.\n",
      "10-20 18:25:18.419 172.17.0.2:54321      22766  .0 (TID 3)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 1635 bytes result sent to driver\n",
      "10-20 18:25:18.422 172.17.0.2:54321      22766  t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 539 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:25:18.423 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 3 (runJob at Writer.scala:104) finished in 0.554 s\n",
      "10-20 18:25:18.423 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:25:18.425 172.17.0.2:54321      22766  t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "10-20 18:25:18.425 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "10-20 18:25:18.425 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 2 finished: runJob at Writer.scala:104, took 0.558968 s\n",
      "10-20 18:25:18.427 172.17.0.2:54321      22766  4648757-71  INFO water.default: POST /3/FinalizeFrame, parms: {column_types=AwQDBAQEBAQEAwMDBAM=, rows_per_chunk=MX8AAAAAAAA=, key=frame_rdd_12598461418}\n",
      "10-20 18:25:18.647 172.17.0.2:54321      22766  4648757-71  INFO water.default: Parse result for frame_rdd_12598461418 (32561 rows, 14 columns):\n",
      "10-20 18:25:18.680 172.17.0.2:54321      22766  4648757-71  INFO water.default:           ColV2    type          min          max         mean        sigma         NAs constant cardinality\n",
      "10-20 18:25:18.680 172.17.0.2:54321      22766  4648757-71  INFO water.default:             age: numeric      17.0000      90.0000      38.5816      13.6404                            \n",
      "10-20 18:25:18.680 172.17.0.2:54321      22766  4648757-71  INFO water.default:       workclass:  factor  Federal-gov           NA                                                     9\n",
      "10-20 18:25:18.680 172.17.0.2:54321      22766  4648757-71  INFO water.default:          fnlwgt: numeric      12285.0  1.48471e+06       189778       105550                            \n",
      "10-20 18:25:18.680 172.17.0.2:54321      22766  4648757-71  INFO water.default:       education:  factor         10th  Some-colleg                                                    16\n",
      "10-20 18:25:18.680 172.17.0.2:54321      22766  4648757-71  INFO water.default:  marital_status:  factor     Divorced      Widowed                                                     7\n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:      occupation:  factor  Adm-clerica           NA                                                    15\n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:    relationship:  factor      Husband         Wife                                                     6\n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:            race:  factor  Amer-Indian        White                                                     5\n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:             sex:  factor       Female         Male                                                     2\n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:    capital_gain: numeric      0.00000      99999.0      1077.65      7385.29                            \n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:    capital_loss: numeric      0.00000      4356.00      87.3038      402.960                            \n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:  hours_per_week: numeric      1.00000      99.0000      40.4375      12.3474                            \n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:  native_country:  factor     Cambodia           NA                                                    42\n",
      "10-20 18:25:18.681 172.17.0.2:54321      22766  4648757-71  INFO water.default:           label: numeric      0.00000      1.00000     0.240810     0.427581                            \n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default: Chunk compression summary:\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:   Chunk Type                 Chunk Name       Count  Count Percentage        Size  Size Percentage\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:          CBS                     Binary           2          14.286 %      8.1 KB          1.800 %\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:          CXI            Sparse Integers           2          14.286 %     27.3 KB          6.068 %\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:          C1N  1-Byte Integers (w/o NAs)           9          64.286 %    286.8 KB         63.815 %\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:           C4            4-Byte Integers           1           7.143 %    127.3 KB         28.318 %\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default: Frame distribution summary:\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:                         Size  Number of Rows  Number of Chunks per Column  Number of Chunks\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default: 172.17.0.2:54321    449.4 KB           32561                            1                14\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:             mean    449.4 KB    32561.000000                     1.000000         14.000000\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:              min    449.4 KB    32561.000000                     1.000000         14.000000\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:              max    449.4 KB    32561.000000                     1.000000         14.000000\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:           stddev        0  B        0.000000                     0.000000          0.000000\n",
      "10-20 18:25:18.694 172.17.0.2:54321      22766  4648757-71  INFO water.default:            total    449.4 KB           32561                            1                14\n",
      "10-20 18:25:18.699 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/FinalizeFrame successfully responded for the POST.\n",
      "10-20 18:25:18.701 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /3/Frames/frame_rdd_12598461418/light, parms: {full_column_count=0, row_count=0}\n",
      "10-20 18:25:18.729 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/Frames/frame_rdd_12598461418/light?row_count=0&full_column_count=0 successfully responded for the GET.\n",
      "10-20 18:25:18.738 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 18:25:18.741 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /3/FrameChunks/frame_rdd_12598461418, parms: {}\n",
      "10-20 18:25:18.747 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/FrameChunks/frame_rdd_12598461418 successfully responded for the GET.\n",
      "10-20 18:25:18.755 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 12 from persistence list\n",
      "10-20 18:25:18.765 172.17.0.2:54321      22766  ad-pool-15  INFO org.apache.spark.storage.BlockManager: Removing RDD 12\n",
      "10-20 18:25:18.774 172.17.0.2:54321      22766  4648757-68  INFO water.default: GET /3/Frames/frame_rdd_12598461418/light, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n"
     ]
    }
   ],
   "source": [
    "train_hdf = hc.asH2OFrame(train_df)\n",
    "train_hdf['label'] = train_hdf['label'].asfactor()\n",
    "train_hdf['workclass'] = train_hdf['workclass'].asfactor()\n",
    "train_hdf['education'] = train_hdf['education'].asfactor()\n",
    "train_hdf['marital_status'] = train_hdf['marital_status'].asfactor()\n",
    "train_hdf['occupation'] = train_hdf['occupation'].asfactor()\n",
    "train_hdf['relationship'] = train_hdf['relationship'].asfactor()\n",
    "train_hdf['race'] = train_hdf['race'].asfactor()\n",
    "train_hdf['sex'] = train_hdf['sex'].asfactor()\n",
    "train_hdf['native_country'] = train_hdf['native_country'].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df909d-7075-4529-8600-455e41994ca4",
   "metadata": {},
   "source": [
    "### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f42e7b5-1c58-42ce-b120-7180cd5ba25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:26:57.917 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /3/Metadata/schemas/AutoMLV99, parms: {}\n",
      "10-20 18:26:58.085 172.17.0.2:54321      22766  4648757-65  INFO water.default: POST /4/sessions, parms: {}\n",
      "10-20 18:26:58.514 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_9_sid_88b4 (:= (tmp= py_8_sid_88b4 (:= (tmp= py_7_sid_88b4 (:= (tmp= py_6_sid_88b4 (:= (tmp= py_5_sid_88b4 (:= (tmp= py_4_sid_88b4 (:= (tmp= py_3_sid_88b4 (:= (tmp= py_2_sid_88b4 (:= (tmp= py_1_sid_88b4 (:= frame_rdd_12598461418 (as.factor (cols_py frame_rdd_12598461418 'label')) 13 [])) (as.factor (cols_py py_1_sid_88b4 'workclass')) 1 [])) (as.factor (cols_py py_2_sid_88b4 'education')) 3 [])) (as.factor (cols_py py_3_sid_88b4 'marital_status')) 4 [])) (as.factor (cols_py py_4_sid_88b4 'occupation')) 5 [])) (as.factor (cols_py py_5_sid_88b4 'relationship')) 6 [])) (as.factor (cols_py py_6_sid_88b4 'race')) 7 [])) (as.factor (cols_py py_7_sid_88b4 'sex')) 8 [])) (as.factor (cols_py py_8_sid_88b4 'native_country')) 12 [])), session_id=_sid_88b4}\n",
      "10-20 18:26:58.577 172.17.0.2:54321      22766  4648757-65  INFO water.default: POST /99/AutoMLBuilder, parms: {}\n",
      "10-20 18:26:58.630 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: Project: AutoML_1_20231020_182658\n",
      "10-20 18:26:58.649 172.17.0.2:54321      22766  4648757-65  INFO water.default: Validation: Setting stopping tolerance adaptively based on the training frame: 0.005541803630764712\n",
      "10-20 18:26:58.649 172.17.0.2:54321      22766  4648757-65  INFO water.default: Validation: Build control seed: 42\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: training frame: Frame key: AutoML_1_20231020_182658_training_py_9_sid_88b4    cols: 14    rows: 32561  chunks: 1    size: 472097  checksum: 2962903763109092816\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: validation frame: NULL\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: leaderboard frame: NULL\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: blending frame: NULL\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: response column: label\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: fold column: null\n",
      "10-20 18:26:58.650 172.17.0.2:54321      22766  4648757-65  INFO water.default: DataImport: weights column: null\n",
      "10-20 18:26:58.668 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "10-20 18:26:58.703 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: Disabling Algo: StackedEnsemble as requested by the user.\n",
      "10-20 18:26:58.703 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: Disabling Algo: DRF as requested by the user.\n",
      "10-20 18:26:58.703 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: Disabling Algo: GLM as requested by the user.\n",
      "10-20 18:26:58.703 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: Disabling Algo: DeepLearning as requested by the user.\n",
      "10-20 18:26:58.710 172.17.0.2:54321      22766  4648757-65  INFO water.default: Workflow: AutoML job created: 2023.10.20 18:26:58.588\n",
      "10-20 18:26:58.718 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Workflow: AutoML build started: 2023.10.20 18:26:58.718\n",
      "10-20 18:26:58.756 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: AutoML: starting XGBoost_1_AutoML_1_20231020_182658 model training\n",
      "10-20 18:26:58.787 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Creating 5 cross-validation splits with random number seed: 42\n",
      "AutoML progress: |10-20 18:26:58.984 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 1 / 5.\n",
      "10-20 18:26:58.986 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 2 / 5.\n",
      "10-20 18:26:58.986 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 3 / 5.\n",
      "10-20 18:26:58.986 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 4 / 5.\n",
      "10-20 18:26:58.987 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:26:58.987 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:26:58.987 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:26:58.988 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:26:59.019 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: {\"_train\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_2_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":42,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":15,\"_min_rows\":10.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:26:59.019 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: {\"_train\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_4_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":42,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":3,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":15,\"_min_rows\":10.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:26:59.019 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: {\"_train\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_1_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":42,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":0,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":15,\"_min_rows\":10.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:26:59.022 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_3_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":42,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":2,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":15,\"_min_rows\":10.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:26:59.021 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:26:59.021 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:26:59.030 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:26:59.030 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:26:59.091 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:26:59.110 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "\n",
      "18:26:58.631: Project: AutoML_1_20231020_182658\n",
      "18:26:58.649: Setting stopping tolerance adaptively based on the training frame: 0.005541803630764712\n",
      "18:26:58.649: Build control seed: 42\n",
      "18:26:58.650: training frame: Frame key: AutoML_1_20231020_182658_training_py_9_sid_88b4    cols: 14    rows: 32561  chunks: 1    size: 472097  checksum: 2962903763109092816\n",
      "18:26:58.650: validation frame: NULL\n",
      "18:26:58.650: leaderboard frame: NULL\n",
      "18:26:58.650: blending frame: NULL\n",
      "18:26:58.650: response column: label\n",
      "18:26:58.650: fold column: null\n",
      "18:26:58.650: weights column: null\n",
      "18:26:58.668: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "18:26:58.703: Disabling Algo: StackedEnsemble as requested by the user.\n",
      "18:26:58.703: Disabling Algo: DRF as requested by the user.\n",
      "18:26:58.703: Disabling Algo: GLM as requested by the user.\n",
      "18:26:58.703: Disabling Algo: DeepLearning as requested by the user.\n",
      "18:26:58.703: Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{resume_best_grids, virtual, Dynamic, group=6, weight=60}, Work{lr_search, XGBoost, Selection, group=7, weight=30}, Work{lr_annealing, GBM, Selection, group=7, weight=10}]\n",
      "18:26:58.703: Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{resume_best_grids, virtual, Dynamic, group=6, weight=60}, Work{lr_search, XGBoost, Selection, group=7, weight=30}, Work{lr_annealing, GBM, Selection, group=7, weight=10}]\n",
      "18:26:58.710: AutoML job created: 2023.10.20 18:26:58.588\n",
      "18:26:58.724: AutoML build started: 2023.10.20 18:26:58.718\n",
      "18:26:58.756: No time limitation for XGBoost_1_AutoML_1_20231020_182658\n",
      "18:26:58.756: AutoML: starting XGBoost_1_AutoML_1_20231020_182658 model training\n",
      "18:26:58.770: XGBoost_1_AutoML_1_20231020_182658 [XGBoost def_2] started\n",
      "\n",
      "10-20 18:26:59.117 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing valid dataset into 4 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:26:58] WARNING: /dot/src/gbm/gbtree.cc:73: DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using`tree_method` parameter instead.\n",
      "[18:26:58] WARNING: /dot/src/learner.cc:207: No visible GPU is found, setting `gpu_id` to -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:26:59.126 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:26:59.154 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:26:59.223 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:26:59.224 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Starting model XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:26:59.243 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:26:59.244 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:26:59.246 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:26:59.246 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:26:59.255 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:26:59.255 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:26:59.284 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:26:59.288 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:26:59.292 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:26:59.293 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:26:59.293 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:26:59.293 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:26:59.284 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:26:59.294 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:26:59.295 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:26:59.295 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:26:59.295 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:26:59.295 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:26:59.295 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:26:59.296 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:26:59.296 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:26:59.296 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:26:59.297 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:26:59.297 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  seed = 42\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 15\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 10.0\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:26:59.298 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  seed = 42\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 15\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:26:59.299 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  seed = 42\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 15\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 10.0\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:26:59.301 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:26:59.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 10.0\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:26:59.302 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  seed = 42\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 15\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:26:59.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 10.0\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:26:59.335 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:26:59.329 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:26:59.495 172.17.0.2:54321      22766  82658_cv_4  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:26:59.495 172.17.0.2:54321      22766  82658_cv_3  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:26:59.499 172.17.0.2:54321      22766  82658_cv_2  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:26:59.496 172.17.0.2:54321      22766  82658_cv_1  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:26:59.555 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:26:59.692 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_3\n",
      "10-20 18:26:59.693 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_4\n",
      "10-20 18:26:59.697 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_5\n",
      "10-20 18:26:59.710 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_2\n",
      "10-20 18:26:59.771 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_5\n",
      "10-20 18:26:59.774 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_2\n",
      "10-20 18:26:59.777 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:26:59.789 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_4\n",
      "10-20 18:26:59.789 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_3\n",
      "10-20 18:26:59.867 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_6\n",
      "10-20 18:26:59.875 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_6\n",
      "10-20 18:26:59.879 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_7\n",
      "10-20 18:26:59.880 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23859797\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19833  1.0000  19,833 / 19,833\n",
      "     1  0   6215  0.0000        0 / 6,215\n",
      "Totals  0  26048  0.7614  19,833 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.238598  0.500000                  0.238598          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24965453\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4887  1.0000  4,887 / 4,887\n",
      "     1  0  1626  0.0000      0 / 1,626\n",
      "Totals  0  6513  0.7503  4,887 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.249655  0.500000                  0.249655          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      "\n",
      "10-20 18:26:59.895 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_7\n",
      "10-20 18:26:59.900 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_8\n",
      "10-20 18:26:59.909 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_9\n",
      "10-20 18:26:59.910 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24200545\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19745  1.0000  19,745 / 19,745\n",
      "     1  0   6304  0.0000        0 / 6,304\n",
      "Totals  0  26049  0.7580  19,745 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.242005  0.500000                  0.242005          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2360258\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4975  1.0000  4,975 / 4,975\n",
      "     1  0  1537  0.0000      0 / 1,537\n",
      "Totals  0  6512  0.7640  4,975 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.236026  0.500000                  0.236026          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      "\n",
      "10-20 18:26:59.911 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_8\n",
      "10-20 18:26:59.915 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_9\n",
      "10-20 18:26:59.923 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2411225\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19768  1.0000  19,768 / 19,768\n",
      "     1  0   6281  0.0000        0 / 6,281\n",
      "Totals  0  26049  0.7589  19,768 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.241122  0.500000                  0.241122          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23955774\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4952  1.0000  4,952 / 4,952\n",
      "     1  0  1560  0.0000      0 / 1,560\n",
      "Totals  0  6512  0.7604  4,952 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.239558  0.500000                  0.239558          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      "\n",
      "10-20 18:26:59.925 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24227418\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19738  1.0000  19,738 / 19,738\n",
      "     1  0   6311  0.0000        0 / 6,311\n",
      "Totals  0  26049  0.7577  19,738 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.242274  0.500000                  0.242274          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23495086\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4982  1.0000  4,982 / 4,982\n",
      "     1  0  1530  0.0000      0 / 1,530\n",
      "Totals  0  6512  0.7650  4,982 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.234951  0.500000                  0.234951          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      "\n",
      "10-20 18:26:59.970 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.078 (Wall: 20-Oct 18:26:59.968) \n",
      "10-20 18:27:00.011 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:00.012 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.087 (Wall: 20-Oct 18:27:00.012) \n",
      "10-20 18:27:00.012 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.099 (Wall: 20-Oct 18:27:00.012) \n",
      "10-20 18:27:00.012 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.084 (Wall: 20-Oct 18:27:00.011) \n",
      "10-20 18:27:00.023 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:00.023) \n",
      "10-20 18:27:00.060 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:00.060) \n",
      "10-20 18:27:00.061 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:00.061) \n",
      "10-20 18:27:00.065 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:00.064) \n",
      "10-20 18:27:00.069 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:00.069) \n",
      "10-20 18:27:00.103 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:00.103) \n",
      "10-20 18:27:00.113 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:00.113) \n",
      "10-20 18:27:00.115 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:00.115) \n",
      "10-20 18:27:00.116 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:00.116) \n",
      "10-20 18:27:00.140 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:00.140) \n",
      "10-20 18:27:00.154 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:00.153) \n",
      "10-20 18:27:00.265 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:00.337 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.220 (Wall: 20-Oct 18:27:00.337) \n",
      "10-20 18:27:00.338 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.198 (Wall: 20-Oct 18:27:00.338) \n",
      "10-20 18:27:00.342 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.228 (Wall: 20-Oct 18:27:00.341) \n",
      "10-20 18:27:00.375 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:00.419 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:00.419) \n",
      "10-20 18:27:00.422 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:00.422) \n",
      "10-20 18:27:00.610 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_10\n",
      "10-20 18:27:00.630 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_11\n",
      "10-20 18:27:00.632 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_13\n",
      "10-20 18:27:00.633 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_12\n",
      "10-20 18:27:00.716 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:00.755 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_11\n",
      "10-20 18:27:00.767 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_13\n",
      "10-20 18:27:00.774 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_10\n",
      "10-20 18:27:00.790 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_12\n",
      "10-20 18:27:00.826 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_14\n",
      "10-20 18:27:00.833 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_15\n",
      "10-20 18:27:00.843 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_15\n",
      "10-20 18:27:00.848 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_14\n",
      "10-20 18:27:00.849 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_16\n",
      "10-20 18:27:00.860 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_16\n",
      "10-20 18:27:00.879 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.09873638\n",
      " RMSE: 0.31422347\n",
      " AUC: 0.92576766\n",
      " pr_auc: 0.82436717\n",
      " logloss: 0.33853123\n",
      " mean_per_class_error: 0.16559403\n",
      " default threshold: 0.36108505725860596\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17290  2455  0.1243  2,455 / 19,745\n",
      "     1   1304  5000  0.2069   1,304 / 6,304\n",
      "Totals  18594  7455  0.1443  3,759 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 29.35 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02848478         0.895419  4.132138         4.132138       1.000000  0.895522                  1.000000          0.895522      0.117703                 0.117703  313.213832       313.213832            0.117703\n",
      "      2                0.03121041         0.885415  4.073939         4.127056       0.985915  0.886593                  0.998770          0.894742      0.011104                 0.128807  307.393919       312.705574            0.128756\n",
      "      3                0.04000154         0.868277  4.078006         4.116276       0.986900  0.877833                  0.996161          0.891026      0.035850                 0.164657  307.800551       311.627599            0.164455\n",
      "      4                0.05052017         0.850734  3.996411         4.091319       0.967153  0.858803                  0.990122          0.884317      0.042037                 0.206694  299.641115       309.131933            0.206036\n",
      "      5                0.10000384         0.676810  3.638462         3.867237       0.880528  0.750295                  0.935893          0.818000      0.180044                 0.386739  263.846160       286.723733            0.378281\n",
      "      6                0.15002495         0.560925  2.863638         3.532619       0.693016  0.617515                  0.854913          0.751155      0.143242                 0.529981  186.363846       253.261877            0.501265\n",
      "      7                0.20000768         0.467879  2.323138         3.230365       0.562212  0.513267                  0.781766          0.691706      0.116117                 0.646098  132.313768       223.036457            0.588514\n",
      "      8                0.30442627         0.347591  1.616395         2.676771       0.391176  0.399112                  0.647793          0.591346      0.168782                 0.814879   61.639529       167.677107            0.673426\n",
      "      9                0.40001536         0.263409  1.007312         2.277831       0.243775  0.305611                  0.551248          0.523066      0.096288                 0.911168    0.731244       127.783134            0.674348\n",
      "     10                0.50009597         0.196989  0.504035         1.922854       0.121979  0.227962                  0.465341          0.464009      0.050444                 0.961612  -49.596472        92.285427            0.608864\n",
      "     11                0.60002303         0.139127  0.231768         1.641223       0.056089  0.167765                  0.397185          0.414672      0.023160                 0.984772  -76.823196        64.122295            0.507587\n",
      "     12                0.76033629         0.113529  0.078170         1.311661       0.018918  0.120496                  0.317429          0.352647      0.012532                 0.997303  -92.182976        31.166079            0.312624\n",
      "     13                0.81365887         0.108550  0.020824         1.227067       0.005040  0.110503                  0.296957          0.336778      0.001110                 0.998414  -97.917569        22.706670            0.243742\n",
      "     14                0.94802104         0.103924  0.009445         1.054494       0.002286  0.105253                  0.255193          0.303964      0.001269                 0.999683  -99.055511         5.449426            0.068156\n",
      "     15                1.00000000         0.103222  0.006104         1.000000       0.001477  0.103222                  0.242005          0.293530      0.000317                 1.000000  -99.389640         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.10575748\n",
      " RMSE: 0.32520375\n",
      " AUC: 0.904798\n",
      " pr_auc: 0.7821805\n",
      " logloss: 0.35512847\n",
      " mean_per_class_error: 0.1998432\n",
      " default threshold: 0.3930809497833252\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error           Rate\n",
      "     0  4414   561  0.1128    561 / 4,975\n",
      "     1   441  1096  0.2869    441 / 1,537\n",
      "Totals  4855  1657  0.1539  1,002 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 29.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02687346         0.895419  4.236825         4.236825       1.000000  0.895520                  1.000000          0.895520      0.113858                 0.113858  323.682498       323.682498            0.113858\n",
      "      2                0.03316953         0.879028  4.236825         4.236825       1.000000  0.881020                  1.000000          0.892768      0.026675                 0.140534  323.682498       323.682498            0.140534\n",
      "      3                0.04069410         0.865895  4.236825         4.236825       1.000000  0.869411                  1.000000          0.888449      0.031880                 0.172414  323.682498       323.682498            0.172414\n",
      "      4                0.05006143         0.821152  4.028457         4.197836       0.950820  0.847650                  0.990798          0.880815      0.037736                 0.210150  302.845654       319.783580            0.209547\n",
      "      5                0.10012285         0.667526  3.444045         3.820940       0.812883  0.733280                  0.901840          0.807047      0.172414                 0.382563  244.404485       282.094032            0.369699\n",
      "      6                0.15018428         0.558069  2.573286         3.405056       0.607362  0.613370                  0.803681          0.742488      0.128822                 0.511386  157.328634       240.505566            0.472793\n",
      "      7                0.20009214         0.463770  2.151003         3.092264       0.507692  0.511183                  0.729854          0.684795      0.107352                 0.618738  115.100345       209.226444            0.547984\n",
      "      8                0.30006143         0.347828  1.555455         2.580257       0.367127  0.403333                  0.609007          0.591022      0.155498                 0.774236   55.545495       158.025677            0.620668\n",
      "      9                0.40003071         0.269791  1.034801         2.194041       0.244240  0.309771                  0.517850          0.520737      0.103448                 0.877684    3.480057       119.404104            0.625221\n",
      "     10                0.50000000         0.197985  0.709392         1.897202       0.167435  0.230917                  0.447789          0.462790      0.070917                 0.948601  -29.060841        89.720234            0.587194\n",
      "     11                0.59996929         0.139119  0.253819         1.623375       0.059908  0.167349                  0.383158          0.413563      0.025374                 0.973975  -74.618099        62.337522            0.489553\n",
      "     12                0.75783170         0.113529  0.119521         1.310110       0.028210  0.120400                  0.309220          0.352495      0.018868                 0.992843  -88.047867        31.011042            0.307617\n",
      "     13                0.80221130         0.109388  0.043981         1.240066       0.010381  0.111256                  0.292688          0.339149      0.001952                 0.994795  -95.601912        24.006612            0.252081\n",
      "     14                0.94717445         0.103924  0.031417         1.055085       0.007415  0.105641                  0.249027          0.303411      0.004554                 0.999349  -96.858287         5.508482            0.068294\n",
      "     15                1.00000000         0.103222  0.012316         1.000000       0.002907  0.103222                  0.236026          0.292836      0.000651                 1.000000  -98.768365         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3876.094238          1.000000   0.291561\n",
      "                      capital_gain         2743.222412          0.707729   0.206346\n",
      "marital_status. Married-civ-spouse         1151.105591          0.296976   0.086586\n",
      "                               age          733.998779          0.189366   0.055212\n",
      "                      capital_loss          721.797241          0.186218   0.054294\n",
      "                    hours_per_week          613.463989          0.158269   0.046145\n",
      "              education. Bachelors          585.858459          0.151147   0.044068\n",
      "       occupation. Exec-managerial          418.204773          0.107893   0.031457\n",
      "        occupation. Prof-specialty          415.337097          0.107154   0.031242\n",
      "                            fnlwgt          352.984314          0.091067   0.026552\n",
      "---\n",
      "                         sex. Male            7.835391          0.002021   0.000589\n",
      "                     occupation.NA            7.819288          0.002017   0.000588\n",
      "                education. 7th-8th            7.090088          0.001829   0.000533\n",
      "           relationship. Unmarried            6.687212          0.001725   0.000503\n",
      "     occupation. Machine-op-inspct            4.809687          0.001241   0.000362\n",
      "       relationship. Not-in-family            4.182880          0.001079   0.000315\n",
      "          marital_status. Divorced            4.082458          0.001053   0.000307\n",
      "           relationship. Own-child            2.919067          0.000753   0.000220\n",
      "          race. Asian-Pac-Islander            0.537106          0.000139   0.000040\n",
      "                       race. Black            0.522644          0.000135   0.000039\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        18330.566406          1.000000   0.119348\n",
      "                      capital_gain        17439.615234          0.951395   0.113548\n",
      "                    hours_per_week        13741.404297          0.749644   0.089469\n",
      "             relationship. Husband        13673.282227          0.745928   0.089025\n",
      "              education. Bachelors         8770.883789          0.478484   0.057106\n",
      "                            fnlwgt         8398.412109          0.458164   0.054681\n",
      "                      capital_loss         8256.520508          0.450424   0.053757\n",
      "        occupation. Prof-specialty         7502.964844          0.409314   0.048851\n",
      "marital_status. Married-civ-spouse         7167.990723          0.391040   0.046670\n",
      "       occupation. Exec-managerial         6380.821289          0.348097   0.041545\n",
      "---\n",
      "              workclass. Local-gov          309.542847          0.016887   0.002015\n",
      "             education. Assoc-acdm          293.000000          0.015984   0.001908\n",
      "                education. 7th-8th          249.500000          0.013611   0.001624\n",
      "           relationship. Unmarried          162.571426          0.008869   0.001058\n",
      "                     occupation.NA           98.981148          0.005400   0.000644\n",
      "     occupation. Machine-op-inspct           84.007446          0.004583   0.000547\n",
      "                       race. Black           74.878906          0.004085   0.000488\n",
      "          marital_status. Divorced           58.262047          0.003178   0.000379\n",
      "       relationship. Not-in-family           55.603855          0.003033   0.000362\n",
      "          race. Asian-Pac-Islander           49.246716          0.002687   0.000321\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          150.000000          1.000000   0.285171\n",
      "                        age          105.000000          0.700000   0.199620\n",
      "             hours_per_week           48.000000          0.320000   0.091255\n",
      "       education. Bachelors           23.000000          0.153333   0.043726\n",
      "occupation. Exec-managerial           19.000000          0.126667   0.036122\n",
      " occupation. Prof-specialty           17.000000          0.113333   0.032319\n",
      "               capital_gain           16.000000          0.106667   0.030418\n",
      "               capital_loss           14.000000          0.093333   0.026616\n",
      "         education. HS-grad           12.000000          0.080000   0.022814\n",
      "         workclass. Private           11.000000          0.073333   0.020913\n",
      "---\n",
      "    relationship. Own-child            1.000000          0.006667   0.001901\n",
      "     workclass. Federal-gov            1.000000          0.006667   0.001901\n",
      "            education. 11th            1.000000          0.006667   0.001901\n",
      "      education. Assoc-acdm            1.000000          0.006667   0.001901\n",
      "              occupation.NA            1.000000          0.006667   0.001901\n",
      "         education. 7th-8th            1.000000          0.006667   0.001901\n",
      "   race. Asian-Pac-Islander            1.000000          0.006667   0.001901\n",
      "     native_country. Mexico            1.000000          0.006667   0.001901\n",
      "                race. Black            1.000000          0.006667   0.001901\n",
      "occupation. Protective-serv            1.000000          0.006667   0.001901\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      "\n",
      "10-20 18:27:00.866 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.09877504\n",
      " RMSE: 0.31428495\n",
      " AUC: 0.9248599\n",
      " pr_auc: 0.8241018\n",
      " logloss: 0.33884582\n",
      " mean_per_class_error: 0.16685864\n",
      " default threshold: 0.35505491495132446\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17294  2474  0.1252  2,474 / 19,768\n",
      "     1   1310  4971  0.2086   1,310 / 6,281\n",
      "Totals  18604  7445  0.1453  3,784 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 29.30 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01946332         0.895595  4.147270         4.147270       1.000000  0.895650                  1.000000          0.895650      0.080720                 0.080720   314.726954       314.726954            0.080720\n",
      "      2                0.02813928         0.895048  4.147270         4.147270       1.000000  0.895048                  1.000000          0.895464      0.035982                 0.116701   314.726954       314.726954            0.116701\n",
      "      3                0.03124880         0.887394  4.147270         4.147270       1.000000  0.887517                  1.000000          0.894674      0.012896                 0.129597   314.726954       314.726954            0.129597\n",
      "      4                0.04257361         0.880409  4.091035         4.132311       0.986441  0.881409                  0.996393          0.891145      0.046330                 0.175927   309.103538       313.231095            0.175725\n",
      "      5                0.05002111         0.849925  4.125892         4.131355       0.994845  0.866134                  0.996163          0.887421      0.030728                 0.206655   312.589187       313.135523            0.206402\n",
      "      6                0.10004223         0.680258  3.612549         3.871952       0.871067  0.753329                  0.933615          0.820375      0.180704                 0.387359   261.254868       287.195196            0.378607\n",
      "      7                0.15002495         0.557655  2.965521         3.569963       0.715054  0.615324                  0.860798          0.752060      0.148225                 0.535584   196.552069       256.996283            0.508064\n",
      "      8                0.20000768         0.461950  2.188306         3.224681       0.527650  0.508952                  0.777543          0.691306      0.109377                 0.644961   118.830582       222.468117            0.586331\n",
      "      9                0.30024185         0.339528  1.663038         2.703335       0.400996  0.394090                  0.651835          0.592082      0.166693                 0.811654    66.303761       170.333463            0.673906\n",
      "     10                0.40001536         0.265357  0.943069         2.264282       0.227395  0.300863                  0.545969          0.519445      0.094093                 0.905747    -5.693101       126.428181            0.666421\n",
      "     11                0.50021114         0.199893  0.567270         1.924359       0.136782  0.231861                  0.464006          0.461840      0.056838                 0.962586   -43.272980        92.435853            0.609287\n",
      "     12                0.60006142         0.142943  0.220040         1.640760       0.053057  0.169258                  0.395624          0.413154      0.021971                 0.984557   -77.996032        64.075970            0.506663\n",
      "     13                0.70033399         0.115981  0.098442         1.419933       0.023737  0.127306                  0.342378          0.372227      0.009871                 0.994428   -90.155792        41.993343            0.387538\n",
      "     14                0.80160467         0.110304  0.036159         1.245114       0.008719  0.112876                  0.300225          0.339462      0.003662                 0.998089   -96.384109        24.511435            0.258915\n",
      "     15                0.99412645         0.104920  0.009924         1.005908       0.002393  0.105531                  0.242547          0.294159      0.001911                 1.000000   -99.007632         0.590825            0.007740\n",
      "     16                1.00000000         0.104754  0.000000         1.000000       0.000000  0.104754                  0.241122          0.293047      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.10404715\n",
      " RMSE: 0.3225634\n",
      " AUC: 0.9131091\n",
      " pr_auc: 0.7917198\n",
      " logloss: 0.3503897\n",
      " mean_per_class_error: 0.1850322\n",
      " default threshold: 0.3669736385345459\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error           Rate\n",
      "     0  4313   639  0.1290    639 / 4,952\n",
      "     1   376  1184  0.2410    376 / 1,560\n",
      "Totals  4689  1823  0.1559  1,015 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 29.40 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02042383         0.895595  4.174359         4.174359       1.000000  0.895658                  1.000000          0.895658      0.085256                 0.085256   317.435897       317.435897            0.085256\n",
      "      2                0.03148034         0.887394  4.116382         4.153996       0.986111  0.892745                  0.995122          0.894635      0.045513                 0.130769   311.638177       315.399625            0.130567\n",
      "      3                0.04146192         0.880409  4.110138         4.143438       0.984615  0.881192                  0.992593          0.891399      0.041026                 0.171795   311.013807       314.343780            0.171391\n",
      "      4                0.05052211         0.850508  4.032855         4.123607       0.966102  0.863977                  0.987842          0.886481      0.036538                 0.208333   303.285528       312.360689            0.207526\n",
      "      5                0.10012285         0.682944  3.347241         3.738996       0.801858  0.758195                  0.895706          0.822928      0.166026                 0.374359   234.724141       273.899638            0.360627\n",
      "      6                0.15003071         0.566551  2.735811         3.405286       0.655385  0.623107                  0.815763          0.756458      0.136538                 0.510897   173.581065       240.528567            0.474548\n",
      "      7                0.20024570         0.473227  2.106328         3.079550       0.504587  0.518380                  0.737730          0.696756      0.105769                 0.616667   110.632792       207.955010            0.547604\n",
      "      8                0.30006143         0.344936  1.644055         2.602031       0.393846  0.400333                  0.623337          0.598150      0.164103                 0.780769    64.405523       160.203134            0.632142\n",
      "      9                0.40003071         0.262259  1.173437         2.245020       0.281106  0.301462                  0.537812          0.524007      0.117308                 0.898077    17.343732       124.501993            0.654943\n",
      "     10                0.50000000         0.196234  0.551451         1.906410       0.132104  0.229536                  0.456695          0.465131      0.055128                 0.953205   -44.854858        90.641026            0.595976\n",
      "     11                0.60181204         0.139791  0.321105         1.638215       0.076923  0.164392                  0.392447          0.414253      0.032692                 0.985897   -67.889546        63.821488            0.505082\n",
      "     12                0.73771499         0.114201  0.066035         1.348586       0.015819  0.122560                  0.323064          0.360517      0.008974                 0.994872   -93.396494        34.858558            0.338167\n",
      "     13                0.80251843         0.110253  0.049459         1.243681       0.011848  0.111692                  0.297933          0.340424      0.003205                 0.998077   -95.054077        24.368100            0.257164\n",
      "     14                0.99308968         0.104920  0.010091         1.006958       0.002417  0.105434                  0.241225          0.295330      0.001923                 1.000000   -98.990888         0.695840            0.009087\n",
      "     15                1.00000000         0.104754  0.000000         1.000000       0.000000  0.104754                  0.239558          0.294013      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3689.513184          1.000000   0.279214\n",
      "                      capital_gain         2806.399902          0.760642   0.212382\n",
      "marital_status. Married-civ-spouse         1172.201294          0.317712   0.088710\n",
      "                      capital_loss          754.257202          0.204433   0.057080\n",
      "                               age          722.323120          0.195777   0.054664\n",
      "              education. Bachelors          590.945129          0.160169   0.044721\n",
      "                    hours_per_week          573.778870          0.155516   0.043422\n",
      "        occupation. Prof-specialty          467.543732          0.126722   0.035383\n",
      "       occupation. Exec-managerial          466.995148          0.126574   0.035341\n",
      "                            fnlwgt          380.911560          0.103242   0.028827\n",
      "---\n",
      "          occupation. Craft-repair           11.223287          0.003042   0.000849\n",
      "              workclass. Local-gov            8.353992          0.002264   0.000632\n",
      "                education. 7th-8th            8.342926          0.002261   0.000631\n",
      "     occupation. Machine-op-inspct            6.213318          0.001684   0.000470\n",
      "      occupation. Transport-moving            6.043449          0.001638   0.000457\n",
      "             education. Assoc-acdm            5.565247          0.001508   0.000421\n",
      "            native_country. Mexico            5.300106          0.001437   0.000401\n",
      "       relationship. Not-in-family            4.072979          0.001104   0.000308\n",
      "                       race. Black            3.577114          0.000970   0.000271\n",
      "          marital_status. Divorced            1.543025          0.000418   0.000117\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        18224.312500          1.000000   0.118294\n",
      "                      capital_gain        17776.167969          0.975410   0.115385\n",
      "             relationship. Husband        13770.552734          0.755614   0.089385\n",
      "                    hours_per_week        13661.512695          0.749631   0.088677\n",
      "                      capital_loss         9093.836914          0.498995   0.059028\n",
      "                            fnlwgt         8715.257813          0.478221   0.056571\n",
      "        occupation. Prof-specialty         8455.067383          0.463944   0.054882\n",
      "              education. Bachelors         8028.906250          0.440560   0.052116\n",
      "       occupation. Exec-managerial         7326.874512          0.402038   0.047559\n",
      "marital_status. Married-civ-spouse         7166.199707          0.393222   0.046516\n",
      "---\n",
      "                       race. White          269.269012          0.014775   0.001748\n",
      "                education. 7th-8th          266.500000          0.014623   0.001730\n",
      "                       race. Black          249.475723          0.013689   0.001619\n",
      "             education. Assoc-acdm          221.050674          0.012129   0.001435\n",
      "          occupation. Craft-repair          212.081665          0.011637   0.001377\n",
      "     occupation. Machine-op-inspct          211.813400          0.011623   0.001375\n",
      "      occupation. Transport-moving          208.463562          0.011439   0.001353\n",
      "          marital_status. Divorced           64.609795          0.003545   0.000419\n",
      "       relationship. Not-in-family           60.063637          0.003296   0.000390\n",
      "              workclass. Local-gov           23.601507          0.001295   0.000153\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          156.000000          1.000000   0.284153\n",
      "                         age          105.000000          0.673077   0.191257\n",
      "              hours_per_week           53.000000          0.339744   0.096539\n",
      "        education. Bachelors           20.000000          0.128205   0.036430\n",
      "          education. HS-grad           20.000000          0.128205   0.036430\n",
      "  occupation. Prof-specialty           18.000000          0.115385   0.032787\n",
      "                capital_gain           17.000000          0.108974   0.030965\n",
      "                capital_loss           15.000000          0.096154   0.027322\n",
      " occupation. Exec-managerial           15.000000          0.096154   0.027322\n",
      "          workclass. Private           13.000000          0.083333   0.023679\n",
      "---\n",
      "     workclass. Self-emp-inc            2.000000          0.012821   0.003643\n",
      "      workclass. Federal-gov            2.000000          0.012821   0.003643\n",
      "occupation. Transport-moving            2.000000          0.012821   0.003643\n",
      "    occupation. Craft-repair            2.000000          0.012821   0.003643\n",
      "                 race. Black            2.000000          0.012821   0.003643\n",
      " relationship. Not-in-family            1.000000          0.006410   0.001821\n",
      "       education. Assoc-acdm            1.000000          0.006410   0.001821\n",
      "          education. 7th-8th            1.000000          0.006410   0.001821\n",
      "      native_country. Mexico            1.000000          0.006410   0.001821\n",
      "        workclass. Local-gov            1.000000          0.006410   0.001821\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      "\n",
      "10-20 18:27:00.898 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_17\n",
      "10-20 18:27:00.870 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.10027077\n",
      " RMSE: 0.3166556\n",
      " AUC: 0.9233128\n",
      " pr_auc: 0.8174124\n",
      " logloss: 0.34352013\n",
      " mean_per_class_error: 0.18105076\n",
      " default threshold: 0.4214456081390381\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18003  1830  0.0923  1,830 / 19,833\n",
      "     1   1677  4538  0.2698   1,677 / 6,215\n",
      "Totals  19680  6368  0.1346  3,507 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 29.14 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005835         0.863681  4.191150         4.191150       1.000000  0.877606                  1.000000          0.877606      0.042156                 0.042156  319.115044       319.115044            0.042156\n",
      "      2                0.02003993         0.835247  4.191150         4.191150       1.000000  0.850304                  1.000000          0.864007      0.041834                 0.083990  319.115044       319.115044            0.083990\n",
      "      3                0.03025184         0.812956  4.175394         4.185832       0.996241  0.823323                  0.998731          0.850274      0.042639                 0.126629  317.539424       318.583172            0.126579\n",
      "      4                0.04000307         0.798568  4.009644         4.142884       0.956693  0.807089                  0.988484          0.839747      0.039099                 0.165728  300.964393       314.288383            0.165123\n",
      "      5                0.05002303         0.777227  4.159034         4.146119       0.992337  0.787587                  0.989256          0.829299      0.041673                 0.207401  315.903435       314.611890            0.206696\n",
      "      6                0.10000768         0.670210  3.618167         3.882244       0.863287  0.721208                  0.926296          0.775274      0.180853                 0.388254  261.816674       288.224415            0.378573\n",
      "      7                0.15003071         0.566658  2.862720         3.542316       0.683039  0.618337                  0.845189          0.722948      0.143202                 0.531456  186.271980       254.231574            0.500951\n",
      "      8                0.20005375         0.482032  2.299825         3.231634       0.548734  0.523801                  0.771061          0.673152      0.115044                 0.646500  129.982545       223.163356            0.586348\n",
      "      9                0.30017660         0.362082  1.605429         2.689219       0.383052  0.416061                  0.641642          0.587400      0.160740                 0.807241   60.542918       168.921880            0.665961\n",
      "     10                0.40006910         0.265777  1.014767         2.271128       0.242121  0.311879                  0.541887          0.518606      0.101368                 0.908608    1.476740       127.112816            0.667898\n",
      "     11                0.50011517         0.193338  0.541987         1.925220       0.129317  0.227844                  0.459354          0.460440      0.054224                 0.962832  -45.801316        92.522025            0.607717\n",
      "     12                0.60035319         0.138881  0.226332         1.641565       0.054002  0.162667                  0.391674          0.410722      0.022687                 0.985519  -77.366824        64.156519            0.505864\n",
      "     13                0.70158937         0.117342  0.087415         1.417308       0.020857  0.125602                  0.338167          0.369581      0.008850                 0.994368  -91.258503        41.730833            0.384526\n",
      "     14                0.80889128         0.107126  0.034489         1.233873       0.008229  0.112311                  0.294400          0.335453      0.003701                 0.998069  -96.551111        23.387310            0.248460\n",
      "     15                1.00000000         0.105045  0.010103         1.000000       0.002411  0.105147                  0.238598          0.291440      0.001931                 1.000000  -98.989678         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.10437058\n",
      " RMSE: 0.32306436\n",
      " AUC: 0.9156717\n",
      " pr_auc: 0.8129066\n",
      " logloss: 0.3536757\n",
      " mean_per_class_error: 0.1903561\n",
      " default threshold: 0.4068343937397003\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4406   481  0.0984  481 / 4,887\n",
      "     1   459  1167  0.2823  459 / 1,626\n",
      "Totals  4865  1648  0.1443  940 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 29.17 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01044066         0.856964  4.005535         4.005535       1.000000  0.871148                  1.000000          0.871148      0.041820                 0.041820  300.553506       300.553506            0.041820\n",
      "      2                0.02011362         0.832950  4.005535         4.005535       1.000000  0.844611                  1.000000          0.858386      0.038745                 0.080566  300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.813587  4.005535         4.005535       1.000000  0.824092                  1.000000          0.847013      0.039975                 0.120541  300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.800125  3.697417         3.928801       0.923077  0.808455                  0.980843          0.837410      0.036900                 0.157442  269.741697       292.880067            0.156418\n",
      "      5                0.05005374         0.781661  3.820664         3.907240       0.953846  0.790572                  0.975460          0.828072      0.038130                 0.195572  282.066421       290.723972            0.193935\n",
      "      6                0.10010748         0.675388  3.563206         3.735223       0.889571  0.725755                  0.932515          0.776913      0.178352                 0.373924  256.320603       273.522287            0.364920\n",
      "      7                0.15000768         0.569572  2.933284         3.468457       0.732308  0.623521                  0.865916          0.725887      0.146371                 0.520295  193.328413       246.845717            0.493489\n",
      "      8                0.20006142         0.477566  2.236219         3.160161       0.558282  0.523721                  0.788949          0.675307      0.111931                 0.632226  123.621896       216.016119            0.575955\n",
      "      9                0.30001535         0.359962  1.458236         2.593143       0.364055  0.411899                  0.647390          0.587549      0.145756                 0.777983   45.823626       159.314322            0.636996\n",
      "     10                0.40012283         0.264823  1.081249         2.214880       0.269939  0.311302                  0.552955          0.518435      0.108241                 0.886224    8.124873       121.487951            0.647836\n",
      "     11                0.50038385         0.194624  0.631807         1.897682       0.157734  0.227983                  0.473765          0.460237      0.063346                 0.949569  -36.819279        89.768215            0.598638\n",
      "     12                0.60003071         0.140863  0.308593         1.633783       0.077042  0.165042                  0.407881          0.411214      0.030750                 0.980320  -69.140716        63.378272            0.506819\n",
      "     13                0.70090588         0.117342  0.091451         1.411809       0.022831  0.126283                  0.352464          0.370207      0.009225                 0.989545  -90.854943        41.180852            0.384675\n",
      "     14                0.80101336         0.108675  0.079865         1.245347       0.019939  0.112932                  0.310907          0.338054      0.007995                 0.997540  -92.013504        24.534749            0.261915\n",
      "     15                1.00000000         0.105045  0.012363         1.000000       0.003086  0.105256                  0.249655          0.291730      0.002460                 1.000000  -98.763724         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         3549.506836          1.000000   0.282002\n",
      "                      capital_gain         2201.707764          0.620286   0.174922\n",
      "             relationship. Husband         1770.602783          0.498831   0.140671\n",
      "                               age          801.993713          0.225945   0.063717\n",
      "                    hours_per_week          684.918579          0.192962   0.054416\n",
      "                      capital_loss          667.951904          0.188182   0.053068\n",
      "        occupation. Prof-specialty          501.372375          0.141251   0.039833\n",
      "              education. Bachelors          450.510040          0.126922   0.035792\n",
      "       occupation. Exec-managerial          390.660339          0.110060   0.031037\n",
      "                education. Masters          184.394150          0.051949   0.014650\n",
      "---\n",
      "                relationship. Wife           10.466252          0.002949   0.000832\n",
      "       relationship. Not-in-family            9.329191          0.002628   0.000741\n",
      "                      workclass.NA            8.340279          0.002350   0.000663\n",
      "          occupation. Craft-repair            6.905871          0.001946   0.000549\n",
      "     marital_status. Never-married            6.286213          0.001771   0.000499\n",
      "          marital_status. Divorced            6.231579          0.001756   0.000495\n",
      "                         sex. Male            5.729040          0.001614   0.000455\n",
      "              workclass. Local-gov            5.265556          0.001483   0.000418\n",
      "       occupation. Protective-serv            1.436890          0.000405   0.000114\n",
      "           marital_status. Widowed            0.747231          0.000211   0.000059\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        23840.437500          1.000000   0.160911\n",
      "                    hours_per_week        17506.968750          0.734339   0.118163\n",
      "marital_status. Married-civ-spouse        15144.037109          0.635225   0.102215\n",
      "                      capital_gain        12933.619141          0.542508   0.087296\n",
      "        occupation. Prof-specialty         8645.708008          0.362649   0.058354\n",
      "                      capital_loss         8325.177734          0.349204   0.056191\n",
      "              education. Bachelors         7096.983398          0.297687   0.047901\n",
      "       occupation. Exec-managerial         6859.504883          0.287726   0.046298\n",
      "                            fnlwgt         5104.409180          0.214107   0.034452\n",
      "             relationship. Husband         3978.827148          0.166894   0.026855\n",
      "---\n",
      "                       race. White          527.095520          0.022109   0.003558\n",
      "          occupation. Craft-repair          525.191040          0.022029   0.003545\n",
      "                relationship. Wife          428.836456          0.017988   0.002894\n",
      "            workclass. Federal-gov          413.138428          0.017329   0.002788\n",
      "                      workclass.NA          335.362122          0.014067   0.002264\n",
      "              workclass. Local-gov          332.482758          0.013946   0.002244\n",
      "          marital_status. Divorced          227.095230          0.009526   0.001533\n",
      "     marital_status. Never-married          114.450790          0.004801   0.000772\n",
      "           marital_status. Widowed           86.806030          0.003641   0.000586\n",
      "                         sex. Male           27.500000          0.001154   0.000186\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          152.000000          1.000000   0.293436\n",
      "               hours_per_week           69.000000          0.453947   0.133205\n",
      "                       fnlwgt           64.000000          0.421053   0.123552\n",
      "           education. HS-grad           22.000000          0.144737   0.042471\n",
      "         education. Bachelors           19.000000          0.125000   0.036680\n",
      "           workclass. Private           19.000000          0.125000   0.036680\n",
      "   occupation. Prof-specialty           13.000000          0.085526   0.025097\n",
      "                 capital_loss           11.000000          0.072368   0.021236\n",
      "      education. Some-college           11.000000          0.072368   0.021236\n",
      "                 capital_gain           11.000000          0.072368   0.021236\n",
      "---\n",
      "      marital_status. Widowed            1.000000          0.006579   0.001931\n",
      "occupation. Machine-op-inspct            1.000000          0.006579   0.001931\n",
      "occupation. Handlers-cleaners            1.000000          0.006579   0.001931\n",
      "              education. 10th            1.000000          0.006579   0.001931\n",
      "       workclass. Federal-gov            1.000000          0.006579   0.001931\n",
      "                    sex. Male            1.000000          0.006579   0.001931\n",
      "       native_country. Mexico            1.000000          0.006579   0.001931\n",
      "               education. 9th            1.000000          0.006579   0.001931\n",
      "  occupation. Protective-serv            1.000000          0.006579   0.001931\n",
      "         workclass. Local-gov            1.000000          0.006579   0.001931\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      "\n",
      "10-20 18:27:00.921 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_17\n",
      "10-20 18:27:00.930 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.09905256\n",
      " RMSE: 0.31472617\n",
      " AUC: 0.9247252\n",
      " pr_auc: 0.8235642\n",
      " logloss: 0.33932889\n",
      " mean_per_class_error: 0.17341605\n",
      " default threshold: 0.40056371688842773\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17815  1923  0.0974  1,923 / 19,738\n",
      "     1   1574  4737  0.2494   1,574 / 6,311\n",
      "Totals  19389  6660  0.1342  3,497 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 29.45 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02836961         0.895479  4.127555         4.127555       1.000000  0.895713                  1.000000          0.895713      0.117097                 0.117097  312.755506       312.755506            0.117097\n",
      "      2                0.03827402         0.883182  4.079560         4.115135       0.988372  0.883492                  0.996991          0.892550      0.040406                 0.157503  307.956024       311.513514            0.157351\n",
      "      3                0.04222811         0.882953  4.047408         4.108793       0.980583  0.882953                  0.995455          0.891652      0.016004                 0.173507  304.740836       310.879345            0.173253\n",
      "      4                0.05094245         0.839620  4.091189         4.105782       0.991189  0.861125                  0.994725          0.886430      0.035652                 0.209159  309.118894       310.578198            0.208804\n",
      "      5                0.10000384         0.674719  3.597884         3.856610       0.871674  0.752029                  0.934357          0.820493      0.176517                 0.385676  259.788446       285.660999            0.377012\n",
      "      6                0.15002495         0.560955  2.860462         3.524476       0.693016  0.615564                  0.853889          0.752166      0.143084                 0.528759  186.046218       252.447575            0.499830\n",
      "      7                0.20000768         0.472647  2.273008         3.211729       0.550691  0.514665                  0.778119          0.692814      0.113611                 0.642370  127.300843       221.172903            0.583803\n",
      "      8                0.30001152         0.348300  1.665282         2.696247       0.403455  0.407188                  0.653231          0.597605      0.166535                 0.808905   66.528229       169.624678            0.671606\n",
      "      9                0.40001536         0.266325  0.993465         2.270551       0.240691  0.305191                  0.550096          0.524501      0.099350                 0.908255   -0.653473       127.055140            0.670744\n",
      "     10                0.50001919         0.195155  0.530799         1.922601       0.128599  0.228434                  0.465797          0.465288      0.053082                 0.961337  -46.920117        92.260089            0.608819\n",
      "     11                0.60009981         0.142490  0.229572         1.640249       0.055619  0.167966                  0.397390          0.415703      0.022976                 0.984313  -77.042751        64.024898            0.507061\n",
      "     12                0.70018043         0.116556  0.101329         1.420283       0.024549  0.126438                  0.344098          0.374356      0.010141                 0.994454  -89.867145        42.028267            0.388364\n",
      "     13                0.80022266         0.110098  0.030093         1.246484       0.007291  0.112583                  0.301991          0.341630      0.003011                 0.997465  -96.990654        24.648401            0.260308\n",
      "     14                1.00000000         0.105198  0.012690         1.000000       0.003075  0.105568                  0.242274          0.294470      0.002535                 1.000000  -98.730959         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.10230142\n",
      " RMSE: 0.31984594\n",
      " AUC: 0.9137816\n",
      " pr_auc: 0.7954498\n",
      " logloss: 0.34667584\n",
      " mean_per_class_error: 0.19175607\n",
      " default threshold: 0.3942154049873352\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4465   517  0.1038  517 / 4,982\n",
      "     1   428  1102  0.2797  428 / 1,530\n",
      "Totals  4893  1619  0.1451  945 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 29.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03009828         0.895479  4.256209         4.256209       1.000000  0.895707                  1.000000          0.895707      0.128105                 0.128105   325.620915       325.620915            0.128105\n",
      "      2                0.03009828         0.892980  0.000000         4.256209       0.000000  0.000000                  1.000000          0.895707      0.000000                 0.128105  -100.000000       325.620915            0.128105\n",
      "      3                0.04176904         0.882953  4.088201         4.209266       0.960526  0.883258                  0.988971          0.892229      0.047712                 0.175817   308.820089       320.926567            0.175215\n",
      "      4                0.05006143         0.849505  4.177390         4.203986       0.981481  0.866596                  0.987730          0.887983      0.034641                 0.210458   317.739046       320.398573            0.209655\n",
      "      5                0.10012285         0.664976  3.538137         3.871061       0.831288  0.754647                  0.909509          0.821315      0.177124                 0.387582   253.813705       287.106139            0.375739\n",
      "      6                0.15003071         0.554730  2.750166         3.498194       0.646154  0.607600                  0.821904          0.750222      0.137255                 0.524837   175.016591       249.819442            0.489911\n",
      "      7                0.20024570         0.453008  2.212708         3.175837       0.519878  0.500635                  0.746166          0.687634      0.111111                 0.635948   121.270812       217.583704            0.569509\n",
      "      8                0.30006143         0.343295  1.473303         2.609487       0.346154  0.392415                  0.613101          0.589429      0.147059                 0.783007    47.330317       160.948749            0.631260\n",
      "      9                0.40003071         0.265093  1.032997         2.215516       0.242704  0.301505                  0.520537          0.517476      0.103268                 0.886275     3.299700       121.551616            0.635572\n",
      "     10                0.50000000         0.198091  0.706099         1.913725       0.165899  0.229692                  0.449631          0.459936      0.070588                 0.956863   -29.390079        91.372549            0.597168\n",
      "     11                0.60012285         0.141229  0.287229         1.642365       0.067485  0.168310                  0.385875          0.411282      0.028758                 0.985621   -71.277116        64.236525            0.503887\n",
      "     12                0.69993857         0.115896  0.085124         1.420293       0.020000  0.125098                  0.333699          0.370471      0.008497                 0.994118   -91.487582        42.029270            0.384523\n",
      "     13                0.80067568         0.109119  0.038929         1.246496       0.009146  0.112388                  0.292865          0.338000      0.003922                 0.998039   -96.107126        24.649624            0.257975\n",
      "     14                1.00000000         0.105198  0.009837         1.000000       0.002311  0.105459                  0.234951          0.291649      0.001961                 1.000000   -99.016284         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3797.782227          1.000000   0.285291\n",
      "                      capital_gain         2766.588379          0.728475   0.207828\n",
      "marital_status. Married-civ-spouse         1186.176758          0.312334   0.089106\n",
      "                               age          862.293945          0.227052   0.064776\n",
      "                      capital_loss          729.633179          0.192121   0.054810\n",
      "                    hours_per_week          565.103821          0.148798   0.042451\n",
      "              education. Bachelors          530.134460          0.139591   0.039824\n",
      "        occupation. Prof-specialty          465.807404          0.122652   0.034992\n",
      "       occupation. Exec-managerial          465.714142          0.122628   0.034985\n",
      "                            fnlwgt          401.988037          0.105848   0.030198\n",
      "---\n",
      "                       race. White            8.370571          0.002204   0.000629\n",
      "       relationship. Not-in-family            5.774185          0.001520   0.000434\n",
      "          marital_status. Divorced            4.844057          0.001275   0.000364\n",
      "              workclass. Local-gov            4.836140          0.001273   0.000363\n",
      "     occupation. Machine-op-inspct            3.877010          0.001021   0.000291\n",
      "           relationship. Own-child            3.680519          0.000969   0.000276\n",
      "                education. 7th-8th            2.604904          0.000686   0.000196\n",
      "                     occupation.NA            2.316963          0.000610   0.000174\n",
      "                       race. Black            1.153244          0.000304   0.000087\n",
      "           relationship. Unmarried            0.749263          0.000197   0.000056\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        20435.828125          1.000000   0.133173\n",
      "                      capital_gain        17802.570313          0.871145   0.116013\n",
      "             relationship. Husband        13685.109375          0.669663   0.089181\n",
      "                    hours_per_week        13041.314453          0.638159   0.084986\n",
      "                            fnlwgt        10035.300781          0.491064   0.065396\n",
      "        occupation. Prof-specialty         8484.856445          0.415195   0.055293\n",
      "              education. Bachelors         8440.992188          0.413049   0.055007\n",
      "                      capital_loss         8212.453125          0.401865   0.053518\n",
      "       occupation. Exec-managerial         7195.437500          0.352099   0.046890\n",
      "marital_status. Married-civ-spouse         7190.225586          0.351844   0.046856\n",
      "---\n",
      "                       race. Black          215.875839          0.010564   0.001407\n",
      "             education. Assoc-acdm          215.412369          0.010541   0.001404\n",
      "          marital_status. Divorced          207.524185          0.010155   0.001352\n",
      "              workclass. Local-gov          191.645599          0.009378   0.001249\n",
      "     occupation. Machine-op-inspct          161.328186          0.007894   0.001051\n",
      "       relationship. Not-in-family          128.745972          0.006300   0.000839\n",
      "           relationship. Own-child          124.821968          0.006108   0.000813\n",
      "                     occupation.NA           72.605545          0.003553   0.000473\n",
      "                education. 7th-8th           62.500000          0.003058   0.000407\n",
      "           relationship. Unmarried           32.815861          0.001606   0.000214\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          165.000000          1.000000   0.292553\n",
      "                          age          124.000000          0.751515   0.219858\n",
      "               hours_per_week           45.000000          0.272727   0.079787\n",
      "         education. Bachelors           23.000000          0.139394   0.040780\n",
      "           education. HS-grad           20.000000          0.121212   0.035461\n",
      "   occupation. Prof-specialty           17.000000          0.103030   0.030142\n",
      "                 capital_loss           16.000000          0.096970   0.028369\n",
      "  occupation. Exec-managerial           15.000000          0.090909   0.026596\n",
      "                 capital_gain           15.000000          0.090909   0.026596\n",
      "           workclass. Private           12.000000          0.072727   0.021277\n",
      "---\n",
      "       workclass. Federal-gov            2.000000          0.012121   0.003546\n",
      "         education. Doctorate            2.000000          0.012121   0.003546\n",
      "      relationship. Unmarried            1.000000          0.006061   0.001773\n",
      "occupation. Machine-op-inspct            1.000000          0.006061   0.001773\n",
      "      relationship. Own-child            1.000000          0.006061   0.001773\n",
      "        education. Assoc-acdm            1.000000          0.006061   0.001773\n",
      "                occupation.NA            1.000000          0.006061   0.001773\n",
      "           education. 7th-8th            1.000000          0.006061   0.001773\n",
      "                  race. Black            1.000000          0.006061   0.001773\n",
      "         workclass. Local-gov            1.000000          0.006061   0.001773\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      "\n",
      "10-20 18:27:00.942 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:00.942) \n",
      "10-20 18:27:00.961 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:00.961) \n",
      "10-20 18:27:00.987 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.091 (Wall: 20-Oct 18:27:00.987) \n",
      "10-20 18:27:00.988 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:00.988) \n",
      "10-20 18:27:00.997 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:00.997) \n",
      "10-20 18:27:01.004 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:01.004) \n",
      "10-20 18:27:01.047 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:01.047) \n",
      "10-20 18:27:01.061 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:01.060) \n",
      "10-20 18:27:01.071 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:01.071) \n",
      "10-20 18:27:01.081 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:01.081) \n",
      "10-20 18:27:01.108 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:01.108) \n",
      "10-20 18:27:01.114 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:01.114) \n",
      "10-20 18:27:01.129 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:01.129) \n",
      "10-20 18:27:01.143 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:01.143) \n",
      "10-20 18:27:01.149 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:01.149) \n",
      "10-20 18:27:01.175 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:01.175) \n",
      "10-20 18:27:01.224 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:01.224) \n",
      "10-20 18:27:01.224 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.095 (Wall: 20-Oct 18:27:01.224) \n",
      "10-20 18:27:01.233 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_18\n",
      "10-20 18:27:01.252 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_18\n",
      "10-20 18:27:01.268 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_19\n",
      "10-20 18:27:01.286 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_19\n",
      "10-20 18:27:01.287 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:01.287) \n",
      "10-20 18:27:01.290 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:01.290) \n",
      "10-20 18:27:01.350 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:01.359 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_20\n",
      "10-20 18:27:01.380 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_21\n",
      "10-20 18:27:01.392 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_20\n",
      "10-20 18:27:01.394 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_21\n",
      "10-20 18:27:01.417 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_22\n",
      "10-20 18:27:01.422 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_22\n",
      "10-20 18:27:01.442 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.086562\n",
      " RMSE: 0.29421422\n",
      " AUC: 0.9330517\n",
      " pr_auc: 0.84160095\n",
      " logloss: 0.28371617\n",
      " mean_per_class_error: 0.15962256\n",
      " default threshold: 0.34901952743530273\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17621  2147  0.1086  2,147 / 19,768\n",
      "     1   1323  4958  0.2106   1,323 / 6,281\n",
      "Totals  18944  7105  0.1332  3,470 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 25.36 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005797         0.963785  4.147270         4.147270       1.000000  0.967209                  1.000000          0.967209      0.041713                 0.041713   314.726954       314.726954            0.041713\n",
      "      2                0.02003916         0.956539  4.147270         4.147270       1.000000  0.959922                  1.000000          0.963580      0.041395                 0.083108   314.726954       314.726954            0.083108\n",
      "      3                0.03002035         0.948607  4.147270         4.147270       1.000000  0.952828                  1.000000          0.960005      0.041395                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.932456  4.131319         4.143289       0.996154  0.941352                  0.999040          0.955351      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05002111         0.906713  4.131380         4.140904       0.996169  0.920602                  0.998465          0.948390      0.041395                 0.207133   313.137962       314.090382            0.207031\n",
      "      6                0.10019578         0.742851  3.753803         3.947057       0.905126  0.821294                  0.951724          0.884745      0.188346                 0.395478   275.380250       294.705653            0.389104\n",
      "      7                0.15002495         0.598781  2.968269         3.621963       0.715716  0.670688                  0.873337          0.813648      0.147906                 0.543385   196.826919       262.196288            0.518344\n",
      "      8                0.20000768         0.479658  2.395351         3.315428       0.577573  0.539425                  0.799424          0.745119      0.119726                 0.663111   139.535077       231.542757            0.610248\n",
      "      9                0.30001152         0.312029  1.614331         2.748395       0.389251  0.386667                  0.662700          0.625635      0.161439                 0.824550    61.433064       174.839526            0.691203\n",
      "     10                0.40001536         0.205172  0.969554         2.303685       0.233781  0.256222                  0.555470          0.533282      0.096959                 0.921509    -3.044639       130.368485            0.687191\n",
      "     11                0.50001919         0.123807  0.461692         1.935286       0.111324  0.162330                  0.466641          0.459091      0.046171                 0.967680   -53.830781        93.528632            0.616254\n",
      "     12                0.59998464         0.069178  0.197489         1.645746       0.047619  0.093921                  0.396826          0.398249      0.019742                 0.987422   -80.251097        64.574609            0.510541\n",
      "     13                0.70002687         0.044360  0.084346         1.422603       0.020338  0.054884                  0.343022          0.349178      0.008438                 0.995861   -91.565415        42.260329            0.389831\n",
      "     14                0.80018427         0.032816  0.028613         1.248120       0.006899  0.038174                  0.300950          0.310250      0.002866                 0.998726   -97.138718        24.812041            0.261626\n",
      "     15                0.99969289         0.025135  0.006384         1.000307       0.001539  0.026521                  0.241197          0.253626      0.001274                 1.000000   -99.361590         0.030721            0.000405\n",
      "     16                1.00000000         0.024999  0.000000         1.000000       0.000000  0.025013                  0.241122          0.253556      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09529733\n",
      " RMSE: 0.30870265\n",
      " AUC: 0.91773564\n",
      " pr_auc: 0.80259717\n",
      " logloss: 0.30500194\n",
      " mean_per_class_error: 0.18156403\n",
      " default threshold: 0.35506880283355713\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4341   611  0.1234  611 / 4,952\n",
      "     1   374  1186  0.2397  374 / 1,560\n",
      "Totals  4715  1797  0.1513  985 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 25.49 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.964296  4.174359         4.174359       1.000000  0.968258                  1.000000          0.968258      0.042308                 0.042308   317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.957088  4.174359         4.174359       1.000000  0.960597                  1.000000          0.964457      0.041667                 0.083974   317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.946566  4.174359         4.174359       1.000000  0.952187                  1.000000          0.960388      0.041667                 0.125641   317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.932186  4.110138         4.158365       0.984615  0.940295                  0.996169          0.955384      0.041026                 0.166667   311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.910343  4.045917         4.135945       0.969231  0.922121                  0.990798          0.948752      0.040385                 0.207051   304.591716       313.594463            0.206445\n",
      "      6                0.10012285         0.747540  3.444486         3.790216       0.825153  0.826885                  0.907975          0.887818      0.172436                 0.379487   244.448639       279.021551            0.367371\n",
      "      7                0.15003071         0.616691  2.684434         3.422376       0.643077  0.677060                  0.819857          0.817709      0.133974                 0.513462   168.443393       242.237619            0.477920\n",
      "      8                0.20009214         0.492204  2.343275         3.152394       0.561350  0.552676                  0.755180          0.751400      0.117308                 0.630769   134.327513       215.239388            0.566351\n",
      "      9                0.30006143         0.317081  1.609469         2.638349       0.385561  0.397821                  0.632037          0.633601      0.160897                 0.791667    60.946867       163.834869            0.646473\n",
      "     10                0.40003071         0.202976  1.173437         2.272261       0.281106  0.254627                  0.544338          0.538894      0.117308                 0.908974    17.343732       127.226143            0.669273\n",
      "     11                0.50000000         0.118965  0.455268         1.908974       0.109063  0.157596                  0.457310          0.462658      0.045513                 0.954487   -54.473197        90.897436            0.597662\n",
      "     12                0.59996929         0.068875  0.301375         1.641110       0.072197  0.090729                  0.393141          0.400685      0.030128                 0.984615   -69.862539        64.110965            0.505819\n",
      "     13                0.69993857         0.044111  0.096183         1.420454       0.023041  0.054405                  0.340281          0.351228      0.009615                 0.994231   -90.381661        42.045432            0.387001\n",
      "     14                0.80006143         0.032803  0.032012         1.246699       0.007669  0.037966                  0.298656          0.312025      0.003205                 0.997436   -96.798804        24.669915            0.259552\n",
      "     15                0.99969287         0.025135  0.012844         1.000307       0.003077  0.026498                  0.239631          0.255007      0.002564                 1.000000   -98.715582         0.030722            0.000404\n",
      "     16                1.00000000         0.024999  0.000000         1.000000       0.000000  0.024999                  0.239558          0.254936      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3771.930664          1.000000   0.229103\n",
      "                      capital_gain         3159.970947          0.837760   0.191934\n",
      "marital_status. Married-civ-spouse         1464.052124          0.388144   0.088925\n",
      "                               age         1332.144897          0.353173   0.080913\n",
      "                      capital_loss          931.784485          0.247031   0.056596\n",
      "                    hours_per_week          770.040283          0.204150   0.046771\n",
      "                            fnlwgt          726.343445          0.192565   0.044117\n",
      "              education. Bachelors          675.014282          0.178957   0.041000\n",
      "        occupation. Prof-specialty          517.561035          0.137214   0.031436\n",
      "       occupation. Exec-managerial          511.784729          0.135682   0.031085\n",
      "---\n",
      "      occupation. Transport-moving           16.328186          0.004329   0.000992\n",
      "       relationship. Not-in-family           14.178253          0.003759   0.000861\n",
      "                       race. Black           13.677677          0.003626   0.000831\n",
      "             education. Assoc-acdm           12.305281          0.003262   0.000747\n",
      "              workclass. Local-gov           10.530926          0.002792   0.000640\n",
      "          marital_status. Divorced            5.871243          0.001557   0.000357\n",
      "            native_country. Mexico            5.300106          0.001405   0.000322\n",
      "              workclass. State-gov            3.853467          0.001022   0.000234\n",
      "           relationship. Unmarried            1.949538          0.000517   0.000118\n",
      "           marital_status. Widowed            1.146667          0.000304   0.000070\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        34872.148438          1.000000   0.131031\n",
      "                      capital_gain        28889.142578          0.828430   0.108550\n",
      "                    hours_per_week        21429.525391          0.614517   0.080521\n",
      "                            fnlwgt        19750.488281          0.566369   0.074212\n",
      "             relationship. Husband        17585.197266          0.504276   0.066076\n",
      "                      capital_loss        14930.307617          0.428144   0.056100\n",
      "marital_status. Married-civ-spouse        12953.064453          0.371444   0.048671\n",
      "              education. Bachelors        11258.878906          0.322862   0.042305\n",
      "        occupation. Prof-specialty         9935.866211          0.284923   0.037334\n",
      "       occupation. Exec-managerial         9339.730469          0.267828   0.035094\n",
      "---\n",
      "             education. Assoc-acdm          597.902588          0.017146   0.002247\n",
      "          occupation. Craft-repair          551.404236          0.015812   0.002072\n",
      "       relationship. Not-in-family          524.741821          0.015048   0.001972\n",
      "           relationship. Own-child          463.859741          0.013302   0.001743\n",
      "            native_country. Mexico          292.034058          0.008374   0.001097\n",
      "              workclass. State-gov          243.183578          0.006974   0.000914\n",
      "              workclass. Local-gov          176.965439          0.005075   0.000665\n",
      "          marital_status. Divorced          174.850677          0.005014   0.000657\n",
      "           marital_status. Widowed          100.987144          0.002896   0.000379\n",
      "           relationship. Unmarried           38.517387          0.001105   0.000145\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          297.000000          1.000000   0.297297\n",
      "                        age          211.000000          0.710438   0.211211\n",
      "             hours_per_week           85.000000          0.286195   0.085085\n",
      " occupation. Prof-specialty           29.000000          0.097643   0.029029\n",
      "         education. HS-grad           29.000000          0.097643   0.029029\n",
      "               capital_gain           29.000000          0.097643   0.029029\n",
      "       education. Bachelors           28.000000          0.094276   0.028028\n",
      "occupation. Exec-managerial           25.000000          0.084175   0.025025\n",
      "         workclass. Private           24.000000          0.080808   0.024024\n",
      "               capital_loss           23.000000          0.077441   0.023023\n",
      "---\n",
      "       workclass. Local-gov            2.000000          0.006734   0.002002\n",
      "    relationship. Own-child            2.000000          0.006734   0.002002\n",
      "      education. Assoc-acdm            2.000000          0.006734   0.002002\n",
      "             education. 9th            2.000000          0.006734   0.002002\n",
      "    relationship. Unmarried            1.000000          0.003367   0.001001\n",
      "    marital_status. Widowed            1.000000          0.003367   0.001001\n",
      "            education. 10th            1.000000          0.003367   0.001001\n",
      "     native_country. Mexico            1.000000          0.003367   0.001001\n",
      "       workclass. State-gov            1.000000          0.003367   0.001001\n",
      "            education. 11th            1.000000          0.003367   0.001001\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      "\n",
      "10-20 18:27:01.494 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_23\n",
      "10-20 18:27:01.496 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:01.498 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_23\n",
      "10-20 18:27:01.500 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_24\n",
      "10-20 18:27:01.505 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.08818608\n",
      " RMSE: 0.29696143\n",
      " AUC: 0.9304738\n",
      " pr_auc: 0.8326632\n",
      " logloss: 0.28907585\n",
      " mean_per_class_error: 0.1658349\n",
      " default threshold: 0.3722324073314667\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17796  2037  0.1027  2,037 / 19,833\n",
      "     1   1423  4792  0.2290   1,423 / 6,215\n",
      "Totals  19219  6829  0.1328  3,460 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 25.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005835         0.942760  4.191150         4.191150       1.000000  0.951377                  1.000000          0.951377      0.042156                 0.042156  319.115044       319.115044            0.042156\n",
      "      2                0.02000154         0.926628  4.174968         4.183106       0.996139  0.935016                  0.998081          0.943244      0.041512                 0.083669  317.496839       318.310601            0.083618\n",
      "      3                0.03002150         0.904926  4.175092         4.180431       0.996169  0.915399                  0.997442          0.933950      0.041834                 0.125503  317.509239       318.043139            0.125402\n",
      "      4                0.04000307         0.885402  4.175031         4.179084       0.996154  0.894896                  0.997121          0.924205      0.041673                 0.167176  317.503063       317.908379            0.167025\n",
      "      5                0.05002303         0.862121  4.094802         4.162202       0.977011  0.872714                  0.993093          0.913891      0.041030                 0.208206  309.480216       316.220159            0.207752\n",
      "      6                0.10000768         0.724238  3.701861         3.932120       0.883257  0.795468                  0.938196          0.854703      0.185036                 0.393242  270.186099       293.211965            0.385124\n",
      "      7                0.15003071         0.593729  3.039629         3.634547       0.725249  0.656611                  0.867195          0.788655      0.152051                 0.545294  203.962945       263.454679            0.519125\n",
      "      8                0.20001536         0.478595  2.311249         3.303849       0.551459  0.534927                  0.788292          0.725247      0.115527                 0.660821  131.124886       230.384930            0.605206\n",
      "      9                0.30002303         0.319789  1.607278         2.738326       0.383493  0.391918                  0.653359          0.614138      0.160740                 0.821561   60.727804       173.832555            0.684970\n",
      "     10                0.39999232         0.204029  0.968922         2.296102       0.231183  0.260547                  0.547845          0.525765      0.096862                 0.918423   -3.107812       129.610200            0.680890\n",
      "     11                0.50000000         0.120322  0.479448         1.932743       0.114395  0.160218                  0.461149          0.452650      0.047949                 0.966372  -52.055170        93.274336            0.612517\n",
      "     12                0.60000768         0.067761  0.210764         1.645728       0.050288  0.092241                  0.392667          0.392578      0.021078                 0.987450  -78.923581        64.572847            0.508853\n",
      "     13                0.69997697         0.042815  0.086913         1.423102       0.020737  0.052988                  0.339549          0.344079      0.008689                 0.996138  -91.308674        42.310165            0.388969\n",
      "     14                0.80079085         0.032255  0.028728         1.247560       0.006855  0.036942                  0.297665          0.305412      0.002896                 0.999035  -97.127163        24.755995            0.260367\n",
      "     15                0.90878378         0.026029  0.007450         1.100195       0.001777  0.028377                  0.262504          0.272491      0.000805                 0.999839  -99.255039        10.019470            0.119589\n",
      "     16                1.00000000         0.025010  0.001764         1.000000       0.000421  0.025427                  0.238598          0.249955      0.000161                 1.000000  -99.823605         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09451285\n",
      " RMSE: 0.30742943\n",
      " AUC: 0.9215447\n",
      " pr_auc: 0.8227323\n",
      " logloss: 0.30597267\n",
      " mean_per_class_error: 0.18031478\n",
      " default threshold: 0.3755747973918915\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4426   461  0.0943  461 / 4,887\n",
      "     1   433  1193  0.2663  433 / 1,626\n",
      "Totals  4859  1654  0.1373  894 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 25.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.940194  4.005535         4.005535       1.000000  0.949273                  1.000000          0.949273      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.920011  4.005535         4.005535       1.000000  0.931348                  1.000000          0.940379      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.904549  4.005535         4.005535       1.000000  0.912610                  1.000000          0.931170      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.884903  3.882288         3.974841       0.969231  0.895463                  0.992337          0.922277      0.038745                 0.159287   288.228782       297.484130            0.158877\n",
      "      5                0.05005374         0.861289  3.759041         3.931814       0.938462  0.872118                  0.981595          0.912276      0.037515                 0.196802   275.904059       293.181355            0.195574\n",
      "      6                0.10026102         0.734445  3.576808         3.754039       0.892966  0.802989                  0.937213          0.857549      0.179582                 0.376384   257.680806       275.403898            0.367994\n",
      "      7                0.15000768         0.598591  2.880524         3.464357       0.719136  0.665659                  0.864893          0.793913      0.143296                 0.519680   188.052367       246.435734            0.492670\n",
      "      8                0.20006142         0.478080  2.322227         3.178606       0.579755  0.536465                  0.793553          0.729502      0.116236                 0.635916   132.222738       217.860572            0.580872\n",
      "      9                0.30001535         0.314845  1.562835         2.640291       0.390169  0.388086                  0.659161          0.615755      0.156212                 0.792128    56.283549       164.029127            0.655848\n",
      "     10                0.39996929         0.203503  1.033686         2.238794       0.258065  0.257557                  0.558925          0.526240      0.103321                 0.895449     3.368647       123.879426            0.660335\n",
      "     11                0.50007677         0.124090  0.583629         1.907456       0.145706  0.161343                  0.476205          0.453193      0.058426                 0.953875   -41.637143        90.745621            0.604785\n",
      "     12                0.60003071         0.068578  0.283033         1.636858       0.070661  0.094921                  0.408649          0.393512      0.028290                 0.982165   -71.696680        63.685760            0.509278\n",
      "     13                0.69998465         0.042494  0.116905         1.419817       0.029186  0.053215                  0.354464          0.344919      0.011685                 0.993850   -88.309498        41.981677            0.391640\n",
      "     14                0.79993858         0.032589  0.049223         1.248558       0.012289  0.036721                  0.311708          0.306409      0.004920                 0.998770   -95.077683        24.855834            0.264986\n",
      "     15                0.90772302         0.026029  0.011412         1.101658       0.002849  0.028680                  0.275034          0.273431      0.001230                 1.000000   -98.858822        10.165765            0.122979\n",
      "     16                1.00000000         0.025010  0.000000         1.000000       0.000000  0.025427                  0.249655          0.250546      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4078.375244          1.000000   0.259490\n",
      "                      capital_gain         2684.890625          0.658324   0.170828\n",
      "             relationship. Husband         1810.029541          0.443811   0.115165\n",
      "                               age         1200.285156          0.294305   0.076369\n",
      "                      capital_loss          917.841003          0.225051   0.058398\n",
      "                    hours_per_week          851.233154          0.208719   0.054160\n",
      "        occupation. Prof-specialty          562.838013          0.138005   0.035811\n",
      "              education. Bachelors          497.038361          0.121872   0.031624\n",
      "                            fnlwgt          496.799927          0.121813   0.031609\n",
      "       occupation. Exec-managerial          474.515808          0.116349   0.030191\n",
      "---\n",
      "       occupation. Protective-serv           11.654331          0.002858   0.000742\n",
      "          occupation. Craft-repair            8.373713          0.002053   0.000533\n",
      "                      workclass.NA            8.340279          0.002045   0.000531\n",
      "          marital_status. Divorced            8.100668          0.001986   0.000515\n",
      "                education. 5th-6th            7.998797          0.001961   0.000509\n",
      "           workclass. Self-emp-inc            7.468068          0.001831   0.000475\n",
      "                     occupation.NA            4.577152          0.001122   0.000291\n",
      "             education. Assoc-acdm            4.119922          0.001010   0.000262\n",
      "           marital_status. Widowed            0.747231          0.000183   0.000048\n",
      "           relationship. Unmarried            0.133739          0.000033   0.000009\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        38441.757813          1.000000   0.147404\n",
      "                    hours_per_week        24133.873047          0.627804   0.092541\n",
      "marital_status. Married-civ-spouse        23316.445313          0.606540   0.089406\n",
      "                      capital_gain        22413.751953          0.583057   0.085945\n",
      "                      capital_loss        18201.236328          0.473476   0.069792\n",
      "                            fnlwgt        17576.277344          0.457218   0.067396\n",
      "        occupation. Prof-specialty        11066.909180          0.287888   0.042436\n",
      "       occupation. Exec-managerial        10871.905273          0.282815   0.041688\n",
      "              education. Bachelors        10442.463867          0.271644   0.040041\n",
      "             relationship. Husband         5737.513184          0.149252   0.022000\n",
      "---\n",
      "            native_country. Mexico          821.691650          0.021375   0.003151\n",
      "          occupation. Craft-repair          817.171875          0.021257   0.003133\n",
      "           relationship. Own-child          780.368774          0.020300   0.002992\n",
      "                         sex. Male          622.688049          0.016198   0.002388\n",
      "          marital_status. Divorced          419.028625          0.010900   0.001607\n",
      "                      workclass.NA          335.362122          0.008724   0.001286\n",
      "             education. Assoc-acdm          320.501740          0.008337   0.001229\n",
      "           workclass. Self-emp-inc          293.914734          0.007646   0.001127\n",
      "           relationship. Unmarried           88.143829          0.002293   0.000338\n",
      "           marital_status. Widowed           86.806030          0.002258   0.000333\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                        age          238.000000          1.000000   0.254818\n",
      "                     fnlwgt          203.000000          0.852941   0.217345\n",
      "             hours_per_week           99.000000          0.415966   0.105996\n",
      "         workclass. Private           31.000000          0.130252   0.033191\n",
      "         education. HS-grad           29.000000          0.121849   0.031049\n",
      "       education. Bachelors           27.000000          0.113445   0.028908\n",
      "               capital_loss           25.000000          0.105042   0.026767\n",
      " occupation. Prof-specialty           25.000000          0.105042   0.026767\n",
      "               capital_gain           19.000000          0.079832   0.020343\n",
      "occupation. Exec-managerial           18.000000          0.075630   0.019272\n",
      "---\n",
      "     workclass. Federal-gov            2.000000          0.008403   0.002141\n",
      "               workclass.NA            2.000000          0.008403   0.002141\n",
      "             education. 9th            2.000000          0.008403   0.002141\n",
      "    relationship. Unmarried            1.000000          0.004202   0.001071\n",
      "    marital_status. Widowed            1.000000          0.004202   0.001071\n",
      "              occupation.NA            1.000000          0.004202   0.001071\n",
      "     native_country. Mexico            1.000000          0.004202   0.001071\n",
      "    workclass. Self-emp-inc            1.000000          0.004202   0.001071\n",
      "      education. Assoc-acdm            1.000000          0.004202   0.001071\n",
      "         education. 5th-6th            1.000000          0.004202   0.001071\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      "\n",
      "10-20 18:27:01.519 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_24\n",
      "10-20 18:27:01.538 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.084 (Wall: 20-Oct 18:27:01.537) \n",
      "10-20 18:27:01.533 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.08627764\n",
      " RMSE: 0.29373056\n",
      " AUC: 0.9339336\n",
      " pr_auc: 0.8424824\n",
      " logloss: 0.28251797\n",
      " mean_per_class_error: 0.161943\n",
      " default threshold: 0.3780534565448761\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17904  1841  0.0932  1,841 / 19,745\n",
      "     1   1454  4850  0.2306   1,454 / 6,304\n",
      "Totals  19358  6691  0.1265  3,295 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 25.40 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01009636         0.963760  4.132138         4.132138       1.000000  0.967617                  1.000000          0.967617      0.041720                 0.041720  313.213832       313.213832            0.041720\n",
      "      2                0.02000077         0.958302  4.132138         4.132138       1.000000  0.960889                  1.000000          0.964285      0.040926                 0.082646  313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.949875  4.132138         4.132138       1.000000  0.954615                  1.000000          0.961058      0.041402                 0.124048  313.213832       313.213832            0.124048\n",
      "      4                0.04007831         0.935589  4.100595         4.124222       0.992366  0.943260                  0.998084          0.956591      0.041244                 0.165292  310.059528       312.422235            0.165191\n",
      "      5                0.05002111         0.910118  4.084276         4.116282       0.988417  0.924050                  0.996163          0.950123      0.040609                 0.205901  308.427572       311.628208            0.205648\n",
      "      6                0.10004223         0.744557  3.716705         3.916493       0.899463  0.826350                  0.947813          0.888236      0.185914                 0.391815  271.670462       291.649335            0.384927\n",
      "      7                0.15002495         0.608219  3.002306         3.611920       0.726575  0.675391                  0.874104          0.817324      0.150063                 0.541878  200.230634       261.192030            0.516960\n",
      "      8                0.20000768         0.483195  2.412001         3.312056       0.583717  0.544975                  0.801536          0.749263      0.120558                 0.662437  141.200087       231.205559            0.610069\n",
      "      9                0.30039541         0.319553  1.656016         2.758631       0.400765  0.392529                  0.667604          0.630048      0.166244                 0.828680   65.601567       175.863139            0.696951\n",
      "     10                0.40005374         0.201803  0.934347         2.304180       0.226117  0.258318                  0.557624          0.537445      0.093115                 0.921796   -6.565285       130.417962            0.688319\n",
      "     11                0.50001919         0.119786  0.466532         1.936791       0.112903  0.158321                  0.468714          0.461650      0.046637                 0.968433  -53.346825        93.679113            0.617964\n",
      "     12                0.59998464         0.067491  0.193595         1.646351       0.046851  0.091091                  0.398426          0.399910      0.019353                 0.987786  -80.640519        64.635136            0.511614\n",
      "     13                0.70002687         0.041359  0.087209         1.423531       0.021105  0.052080                  0.344502          0.350200      0.008725                 0.996510  -91.279063        42.353128            0.391142\n",
      "     14                0.80095205         0.031204  0.026720         1.247524       0.006466  0.035998                  0.301908          0.310609      0.002697                 0.999207  -97.328020        24.752393            0.261552\n",
      "     15                0.90844178         0.025738  0.004427         1.100437       0.001071  0.027911                  0.266312          0.277159      0.000476                 0.999683  -99.557271        10.043677            0.120372\n",
      "     16                1.00000000         0.024496  0.003465         1.000000       0.000839  0.024649                  0.242005          0.254040      0.000317                 1.000000  -99.653489         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.097122744\n",
      " RMSE: 0.31164524\n",
      " AUC: 0.9099564\n",
      " pr_auc: 0.792593\n",
      " logloss: 0.31116575\n",
      " mean_per_class_error: 0.19198819\n",
      " default threshold: 0.3820169270038605\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4408   567  0.1140  567 / 4,975\n",
      "     1   415  1122  0.2700  415 / 1,537\n",
      "Totals  4823  1689  0.1508  982 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 25.32 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01028870         0.963760  4.236825         4.236825       1.000000  0.967164                  1.000000          0.967164      0.043591                 0.043591  323.682498       323.682498            0.043591\n",
      "      2                0.02011671         0.956905  4.236825         4.236825       1.000000  0.960137                  1.000000          0.963731      0.041640                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.948067  4.236825         4.236825       1.000000  0.952848                  1.000000          0.960122      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.929086  4.236825         4.236825       1.000000  0.940760                  1.000000          0.955300      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.890201  4.106461         4.210832       0.969231  0.911417                  0.993865          0.946550      0.040989                 0.210800  310.646114       321.083219            0.210398\n",
      "      6                0.10012285         0.737261  3.483034         3.846933       0.822086  0.809211                  0.907975          0.877881      0.174366                 0.385166  248.303404       284.693311            0.373106\n",
      "      7                0.15003071         0.599209  2.685495         3.460580       0.633846  0.665064                  0.816786          0.807087      0.134027                 0.519193  168.549522       246.057967            0.483213\n",
      "      8                0.20009214         0.479087  2.157402         3.134535       0.509202  0.537317                  0.739831          0.739593      0.108003                 0.627196  115.740168       213.453514            0.559055\n",
      "      9                0.30006143         0.324409  1.535930         2.601940       0.362519  0.396379                  0.614125          0.625247      0.153546                 0.780742   53.593041       160.193960            0.629184\n",
      "     10                0.40003071         0.206154  1.112899         2.229822       0.262673  0.264349                  0.526296          0.535057      0.111256                 0.891997   11.289873       122.982229            0.643957\n",
      "     11                0.50000000         0.117773  0.611769         1.906311       0.144393  0.160871                  0.449939          0.460243      0.061158                 0.953155  -38.823111        90.631100            0.593155\n",
      "     12                0.59996929         0.064914  0.234294         1.627713       0.055300  0.089612                  0.384182          0.398487      0.023422                 0.976578  -76.570553        62.771290            0.492960\n",
      "     13                0.70009214         0.041506  0.110469         1.410726       0.026074  0.051285                  0.332968          0.348832      0.011061                 0.987638  -88.953064        41.072611            0.376382\n",
      "     14                0.79990786         0.031699  0.084736         1.245264       0.020000  0.036451                  0.293914          0.309852      0.008458                 0.996096  -91.526350        24.526378            0.256800\n",
      "     15                0.91139435         0.025738  0.029179         1.096506       0.006887  0.028073                  0.258804          0.275383      0.003253                 0.999349  -97.082076         9.650601            0.115128\n",
      "     16                1.00000000         0.024496  0.007343         1.000000       0.001733  0.024647                  0.236026          0.253167      0.000651                 1.000000  -99.265715         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4126.395508          1.000000   0.248890\n",
      "                      capital_gain         3138.858643          0.760678   0.189325\n",
      "marital_status. Married-civ-spouse         1389.636230          0.336768   0.083818\n",
      "                               age         1336.767334          0.323955   0.080629\n",
      "                      capital_loss          935.536682          0.226720   0.056428\n",
      "                    hours_per_week          833.491821          0.201990   0.050273\n",
      "              education. Bachelors          672.250671          0.162915   0.040548\n",
      "                            fnlwgt          648.822266          0.157237   0.039135\n",
      "       occupation. Exec-managerial          462.881592          0.112176   0.027919\n",
      "        occupation. Prof-specialty          451.628357          0.109449   0.027241\n",
      "---\n",
      "     occupation. Machine-op-inspct           14.117762          0.003421   0.000852\n",
      "          occupation. Craft-repair           10.906755          0.002643   0.000658\n",
      "                     occupation.NA            7.819288          0.001895   0.000472\n",
      "           relationship. Unmarried            6.914627          0.001676   0.000417\n",
      "      occupation. Transport-moving            6.904303          0.001673   0.000416\n",
      "          marital_status. Divorced            6.540195          0.001585   0.000394\n",
      "              workclass. State-gov            4.530758          0.001098   0.000273\n",
      "           relationship. Own-child            2.919067          0.000707   0.000176\n",
      "          race. Asian-Pac-Islander            0.537106          0.000130   0.000032\n",
      "                       race. Black            0.522644          0.000127   0.000032\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        35468.367188          1.000000   0.133559\n",
      "                      capital_gain        30786.994141          0.868013   0.115931\n",
      "                    hours_per_week        22575.177734          0.636488   0.085009\n",
      "                            fnlwgt        18641.074219          0.525569   0.070195\n",
      "             relationship. Husband        17878.521484          0.504069   0.067323\n",
      "                      capital_loss        14194.130859          0.400191   0.053449\n",
      "marital_status. Married-civ-spouse        12667.969727          0.357162   0.047702\n",
      "              education. Bachelors        12104.384766          0.341273   0.045580\n",
      "        occupation. Prof-specialty         9468.437500          0.266954   0.035654\n",
      "                education. Masters         9009.466797          0.254014   0.033926\n",
      "---\n",
      "       relationship. Not-in-family          518.473267          0.014618   0.001952\n",
      "      occupation. Transport-moving          444.068848          0.012520   0.001672\n",
      "              workclass. State-gov          433.376862          0.012219   0.001632\n",
      "          occupation. Craft-repair          346.850342          0.009779   0.001306\n",
      "              workclass. Local-gov          309.542847          0.008727   0.001166\n",
      "           relationship. Unmarried          207.565292          0.005852   0.000782\n",
      "          marital_status. Divorced          122.128723          0.003443   0.000460\n",
      "                     occupation.NA           98.981148          0.002791   0.000373\n",
      "                       race. Black           74.878906          0.002111   0.000282\n",
      "          race. Asian-Pac-Islander           49.246716          0.001388   0.000185\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          287.000000          1.000000   0.297101\n",
      "                          age          203.000000          0.707317   0.210145\n",
      "               hours_per_week           93.000000          0.324042   0.096273\n",
      "         education. Bachelors           36.000000          0.125436   0.037267\n",
      "                 capital_gain           30.000000          0.104530   0.031056\n",
      "   occupation. Prof-specialty           27.000000          0.094077   0.027950\n",
      "  occupation. Exec-managerial           26.000000          0.090592   0.026915\n",
      "           workclass. Private           26.000000          0.090592   0.026915\n",
      "                 capital_loss           24.000000          0.083624   0.024845\n",
      "           education. HS-grad           19.000000          0.066202   0.019669\n",
      "---\n",
      "occupation. Machine-op-inspct            2.000000          0.006969   0.002070\n",
      "        education. Assoc-acdm            2.000000          0.006969   0.002070\n",
      "              education. 10th            1.000000          0.003484   0.001035\n",
      "                occupation.NA            1.000000          0.003484   0.001035\n",
      "     race. Asian-Pac-Islander            1.000000          0.003484   0.001035\n",
      "                  race. Black            1.000000          0.003484   0.001035\n",
      "         workclass. State-gov            1.000000          0.003484   0.001035\n",
      "      relationship. Own-child            1.000000          0.003484   0.001035\n",
      " occupation. Transport-moving            1.000000          0.003484   0.001035\n",
      "               education. 9th            1.000000          0.003484   0.001035\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      "\n",
      "10-20 18:27:01.567 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_25\n",
      "10-20 18:27:01.568 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:01.568) \n",
      "10-20 18:27:01.573 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_25\n",
      "10-20 18:27:01.580 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.08695139\n",
      " RMSE: 0.2948752\n",
      " AUC: 0.93285614\n",
      " pr_auc: 0.84070987\n",
      " logloss: 0.28423867\n",
      " mean_per_class_error: 0.15987588\n",
      " default threshold: 0.37456026673316956\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17724  2014  0.1020  2,014 / 19,738\n",
      "     1   1374  4937  0.2177   1,374 / 6,311\n",
      "Totals  19098  6951  0.1301  3,388 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 25.40 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.962946  4.127555         4.127555       1.000000  0.967453                  1.000000          0.967453      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02073016         0.958749  4.127555         4.127555       1.000000  0.960087                  1.000000          0.963647      0.044209                 0.085565  312.755506       312.755506            0.085565\n",
      "      3                0.03002035         0.950004  4.127555         4.127555       1.000000  0.954007                  1.000000          0.960664      0.038346                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.935761  4.111680         4.123594       0.996154  0.943696                  0.999040          0.956430      0.041039                 0.164950  311.167985       312.359388            0.164899\n",
      "      5                0.05002111         0.910529  4.095926         4.118052       0.992337  0.923689                  0.997698          0.949872      0.041039                 0.205990  309.592629       311.805187            0.205838\n",
      "      6                0.10004223         0.735293  3.703079         3.910565       0.897160  0.820208                  0.947429          0.885040      0.185232                 0.391222  270.307895       291.056541            0.384281\n",
      "      7                0.15002495         0.602399  2.970445         3.597352       0.719662  0.665086                  0.871546          0.811760      0.148471                 0.539693  197.044477       259.735224            0.514259\n",
      "      8                0.20000768         0.487602  2.409326         3.300460       0.583717  0.542775                  0.799616          0.744539      0.120425                 0.660117  140.932554       230.045958            0.607224\n",
      "      9                0.30001152         0.325658  1.663698         2.754872       0.403071  0.401431                  0.667434          0.630170      0.166376                 0.826493   66.369782       175.487232            0.694818\n",
      "     10                0.40009213         0.204382  0.932539         2.299027       0.225930  0.260400                  0.556995          0.537674      0.093329                 0.919823   -6.746071       129.902678            0.685908\n",
      "     11                0.50001919         0.117612  0.480465         1.935594       0.116404  0.157378                  0.468944          0.461673      0.048011                 0.967834  -51.953547        93.559358            0.617393\n",
      "     12                0.59998464         0.066822  0.196550         1.645846       0.047619  0.089887                  0.398746          0.399729      0.019648                 0.987482  -80.344976        64.584575            0.511395\n",
      "     13                0.69998848         0.042663  0.090315         1.423615       0.021881  0.052789                  0.344905          0.350163      0.009032                 0.996514  -90.968498        42.361488            0.391336\n",
      "     14                0.80003071         0.031338  0.022174         1.248368       0.005372  0.036297                  0.302447          0.310915      0.002218                 0.998732  -97.782587        24.836754            0.262234\n",
      "     15                1.00000000         0.024997  0.006339         1.000000       0.001536  0.026434                  0.242274          0.254027      0.001268                 1.000000  -99.366089         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.092605844\n",
      " RMSE: 0.30431208\n",
      " AUC: 0.9197581\n",
      " pr_auc: 0.80804634\n",
      " logloss: 0.2984282\n",
      " mean_per_class_error: 0.17285404\n",
      " default threshold: 0.33687493205070496\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4344   638  0.1281  638 / 4,982\n",
      "     1   333  1197  0.2176  333 / 1,530\n",
      "Totals  4677  1835  0.1491  971 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 25.01 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.962019  4.256209         4.256209       1.000000  0.966706                  1.000000          0.966706      0.043137                 0.043137  325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.957048  4.256209         4.256209       1.000000  0.959516                  1.000000          0.963138      0.042484                 0.085621  325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.950052  4.256209         4.256209       1.000000  0.953859                  1.000000          0.960061      0.042484                 0.128105  325.620915       325.620915            0.128105\n",
      "      4                0.04038698         0.937036  4.192684         4.240026       0.985075  0.943193                  0.996198          0.955764      0.043137                 0.171242  319.268364       324.002585            0.171041\n",
      "      5                0.05006143         0.909502  4.188650         4.230097       0.984127  0.923418                  0.993865          0.949513      0.040523                 0.211765  318.865027       323.009744            0.211363\n",
      "      6                0.10012285         0.730285  3.590360         3.910229       0.843558  0.819842                  0.918712          0.884677      0.179739                 0.391503  259.036048       291.022896            0.380865\n",
      "      7                0.15003071         0.585607  2.723974         3.515620       0.640000  0.655492                  0.825998          0.808439      0.135948                 0.527451  172.397386       251.562005            0.493328\n",
      "      8                0.20009214         0.467016  2.493669         3.259936       0.585890  0.523085                  0.765925          0.737046      0.124837                 0.652288  149.366855       225.993610            0.591067\n",
      "      9                0.30006143         0.310537  1.484116         2.668299       0.348694  0.385087                  0.626919          0.619786      0.148366                 0.800654   48.411594       166.829898            0.654327\n",
      "     10                0.40003071         0.199587  0.928390         2.233489       0.218126  0.248970                  0.524760          0.527117      0.092810                 0.893464   -7.161029       123.348864            0.644969\n",
      "     11                0.50000000         0.120892  0.679947         1.922876       0.159754  0.159761                  0.451781          0.453669      0.067974                 0.961438  -32.005261        92.287582            0.603148\n",
      "     12                0.59996929         0.067553  0.261518         1.646054       0.061444  0.091542                  0.386742          0.393330      0.026144                 0.987582  -73.848177        64.605376            0.506650\n",
      "     13                0.69993857         0.041800  0.071918         1.421226       0.016897  0.052578                  0.333918          0.344662      0.007190                 0.994771  -92.808249        42.122649            0.385377\n",
      "     14                0.79990786         0.030983  0.039228         1.248510       0.009217  0.035798                  0.293338          0.306061      0.003922                 0.998693  -96.077227        24.850981            0.259833\n",
      "     15                1.00000000         0.024997  0.006533         1.000000       0.001535  0.026285                  0.234951          0.250080      0.001307                 1.000000  -99.346706         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4052.073242          1.000000   0.244472\n",
      "                      capital_gain         3177.628418          0.784198   0.191714\n",
      "                               age         1430.078491          0.352925   0.086280\n",
      "marital_status. Married-civ-spouse         1423.016113          0.351182   0.085854\n",
      "                      capital_loss          881.459839          0.217533   0.053181\n",
      "                    hours_per_week          814.361938          0.200974   0.049133\n",
      "                            fnlwgt          725.550720          0.179057   0.043774\n",
      "              education. Bachelors          593.866333          0.146559   0.035829\n",
      "       occupation. Exec-managerial          527.004639          0.130058   0.031796\n",
      "        occupation. Prof-specialty          520.205994          0.128380   0.031385\n",
      "---\n",
      "             education. Assoc-acdm           11.900757          0.002937   0.000718\n",
      "            native_country. Mexico           11.102909          0.002740   0.000670\n",
      "       occupation. Protective-serv           10.588404          0.002613   0.000639\n",
      "                education. 5th-6th            6.929251          0.001710   0.000418\n",
      "          race. Asian-Pac-Islander            5.600218          0.001382   0.000338\n",
      "           relationship. Own-child            5.032860          0.001242   0.000304\n",
      "          marital_status. Divorced            4.844057          0.001195   0.000292\n",
      "                       race. Black            2.686562          0.000663   0.000162\n",
      "                     occupation.NA            2.316963          0.000572   0.000140\n",
      "           relationship. Unmarried            0.749263          0.000185   0.000045\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        35947.617188          1.000000   0.135631\n",
      "                      capital_gain        30157.169922          0.838920   0.113784\n",
      "                    hours_per_week        22532.951172          0.626827   0.085017\n",
      "                            fnlwgt        22106.941406          0.614977   0.083410\n",
      "             relationship. Husband        17940.238281          0.499066   0.067689\n",
      "                      capital_loss        13992.796875          0.389255   0.052795\n",
      "marital_status. Married-civ-spouse        12700.259766          0.353299   0.047918\n",
      "              education. Bachelors        11287.980469          0.314012   0.042590\n",
      "        occupation. Prof-specialty        10530.421875          0.292938   0.039732\n",
      "       occupation. Exec-managerial         9819.490234          0.273161   0.037049\n",
      "---\n",
      "              education. Assoc-voc          461.860199          0.012848   0.001743\n",
      "          race. Asian-Pac-Islander          459.352692          0.012778   0.001733\n",
      "      occupation. Transport-moving          452.578430          0.012590   0.001708\n",
      "                       race. Black          298.772369          0.008311   0.001127\n",
      "           relationship. Own-child          231.825882          0.006449   0.000875\n",
      "             education. Assoc-acdm          215.412369          0.005992   0.000813\n",
      "              workclass. Local-gov          214.517014          0.005967   0.000809\n",
      "          marital_status. Divorced          207.524185          0.005773   0.000783\n",
      "                     occupation.NA           72.605545          0.002020   0.000274\n",
      "           relationship. Unmarried           32.815861          0.000913   0.000124\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          295.000000          1.000000   0.296482\n",
      "                        age          226.000000          0.766102   0.227136\n",
      "             hours_per_week           84.000000          0.284746   0.084422\n",
      "       education. Bachelors           36.000000          0.122034   0.036181\n",
      "         education. HS-grad           34.000000          0.115254   0.034171\n",
      "               capital_gain           29.000000          0.098305   0.029146\n",
      " occupation. Prof-specialty           27.000000          0.091525   0.027136\n",
      "               capital_loss           24.000000          0.081356   0.024121\n",
      "occupation. Exec-managerial           23.000000          0.077966   0.023116\n",
      "         workclass. Private           21.000000          0.071186   0.021106\n",
      "---\n",
      "    relationship. Own-child            2.000000          0.006780   0.002010\n",
      "    workclass. Self-emp-inc            2.000000          0.006780   0.002010\n",
      "occupation. Protective-serv            2.000000          0.006780   0.002010\n",
      "    relationship. Unmarried            1.000000          0.003390   0.001005\n",
      "              occupation.NA            1.000000          0.003390   0.001005\n",
      "   race. Asian-Pac-Islander            1.000000          0.003390   0.001005\n",
      "     native_country. Mexico            1.000000          0.003390   0.001005\n",
      "      education. Assoc-acdm            1.000000          0.003390   0.001005\n",
      "         education. 5th-6th            1.000000          0.003390   0.001005\n",
      "             education. 9th            1.000000          0.003390   0.001005\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      "\n",
      "█10-20 18:27:01.635 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:01.635) \n",
      "10-20 18:27:01.636 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.084 (Wall: 20-Oct 18:27:01.636) \n",
      "10-20 18:27:01.645 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:01.644) \n",
      "10-20 18:27:01.663 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.094 (Wall: 20-Oct 18:27:01.663) \n",
      "10-20 18:27:01.684 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:01.684) \n",
      "10-20 18:27:01.719 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:01.719) \n",
      "10-20 18:27:01.720 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:01.720) \n",
      "10-20 18:27:01.728 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:01.728) \n",
      "10-20 18:27:01.734 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:01.734) \n",
      "10-20 18:27:01.785 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:01.785) \n",
      "10-20 18:27:01.785 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:01.785) \n",
      "10-20 18:27:01.813 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:01.813) \n",
      "10-20 18:27:01.822 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.094 (Wall: 20-Oct 18:27:01.822) \n",
      "10-20 18:27:01.832 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:01.832) \n",
      "10-20 18:27:01.874 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:01.874) \n",
      "10-20 18:27:01.874 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.089 (Wall: 20-Oct 18:27:01.874) \n",
      "10-20 18:27:01.958 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.084 (Wall: 20-Oct 18:27:01.958) \n",
      "10-20 18:27:01.967 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.152 (Wall: 20-Oct 18:27:01.966) \n",
      "10-20 18:27:02.031 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_26\n",
      "10-20 18:27:02.034 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_27\n",
      "10-20 18:27:02.045 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_27\n",
      "10-20 18:27:02.053 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_28\n",
      "10-20 18:27:02.076 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_26\n",
      "10-20 18:27:02.076 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_28\n",
      "10-20 18:27:02.110 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_29\n",
      "10-20 18:27:02.122 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_29\n",
      "10-20 18:27:02.166 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_30\n",
      "10-20 18:27:02.174 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_30\n",
      "10-20 18:27:02.194 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.082653165\n",
      " RMSE: 0.28749463\n",
      " AUC: 0.9380212\n",
      " pr_auc: 0.85113794\n",
      " logloss: 0.26571754\n",
      " mean_per_class_error: 0.1581708\n",
      " default threshold: 0.36940667033195496\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17905  1863  0.0942  1,863 / 19,768\n",
      "     1   1395  4886  0.2221   1,395 / 6,281\n",
      "Totals  19300  6749  0.1251  3,258 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.47 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005797         0.985033  4.147270         4.147270       1.000000  0.987052                  1.000000          0.987052      0.041713                 0.041713   314.726954       314.726954            0.041713\n",
      "      2                0.02000077         0.980829  4.147270         4.147270       1.000000  0.983088                  1.000000          0.985082      0.041235                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03013551         0.973439  4.147270         4.147270       1.000000  0.977539                  1.000000          0.982545      0.042032                 0.124980   314.726954       314.726954            0.124980\n",
      "      4                0.04000154         0.962125  4.131132         4.143289       0.996109  0.968706                  0.999040          0.979132      0.040758                 0.165738   313.113231       314.328944            0.165687\n",
      "      5                0.05002111         0.943389  4.099600         4.134538       0.988506  0.954121                  0.996930          0.974122      0.041076                 0.206814   309.959978       313.453809            0.206612\n",
      "      6                0.10000384         0.778590  3.803256         3.968961       0.917051  0.858663                  0.957006          0.916414      0.190097                 0.396911   280.325640       296.896083            0.391246\n",
      "      7                0.15002495         0.622196  3.068279         3.668657       0.739831  0.700245                  0.884596          0.844340      0.153479                 0.550390   206.827923       266.865681            0.527575\n",
      "      8                0.20000768         0.493081  2.395351         3.350452       0.577573  0.558496                  0.807869          0.772906      0.119726                 0.670116   139.535077       235.045250            0.619479\n",
      "      9                0.30001152         0.303645  1.650948         2.783951       0.398081  0.387652                  0.671273          0.644488      0.165101                 0.835217    65.094761       178.395087            0.705260\n",
      "     10                0.40001536         0.179234  0.956817         2.327167       0.230710  0.236941                  0.561132          0.542601      0.095685                 0.930903    -4.318273       132.716747            0.699569\n",
      "     11                0.50001919         0.095396  0.401195         1.941973       0.096737  0.134455                  0.468253          0.460972      0.040121                 0.971024   -59.880540        94.197289            0.620659\n",
      "     12                0.59998464         0.047498  0.181562         1.648665       0.043779  0.068773                  0.397530          0.395626      0.018150                 0.989174   -81.843751        64.866502            0.512848\n",
      "     13                0.69998848         0.026275  0.079602         1.424501       0.019194  0.035179                  0.343479          0.344131      0.007961                 0.997134   -92.039790        42.450089            0.391560\n",
      "     14                0.79999232         0.015122  0.019105         1.248818       0.004607  0.020219                  0.301118          0.303640      0.001911                 0.999045   -98.089550        24.881791            0.262298\n",
      "     15                0.89999616         0.008572  0.009552         1.111116       0.002303  0.011455                  0.267915          0.271174      0.000955                 1.000000   -99.044775        11.111585            0.131779\n",
      "     16                1.00000000         0.005710  0.000000         1.000000       0.000000  0.006576                  0.241122          0.244713      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.092856064\n",
      " RMSE: 0.30472293\n",
      " AUC: 0.92179376\n",
      " pr_auc: 0.8100085\n",
      " logloss: 0.2924363\n",
      " mean_per_class_error: 0.16243216\n",
      " default threshold: 0.2797882556915283\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error           Rate\n",
      "     0  4194   758  0.1531    758 / 4,952\n",
      "     1   268  1292  0.1718    268 / 1,560\n",
      "Totals  4462  2050  0.1576  1,026 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.62 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.985465  4.174359         4.174359       1.000000  0.987392                  1.000000          0.987392      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.981285  4.174359         4.174359       1.000000  0.983306                  1.000000          0.985364      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03025184         0.972768  4.174359         4.174359       1.000000  0.977427                  1.000000          0.982705      0.042308                 0.126282  317.435897       317.435897            0.126282\n",
      "      4                0.04007985         0.964646  4.109135         4.158365       0.984375  0.969477                  0.996169          0.979461      0.040385                 0.166667  310.913462       315.836526            0.166465\n",
      "      5                0.05006143         0.948758  3.981696         4.123140       0.953846  0.957600                  0.987730          0.975103      0.039744                 0.206410  298.169625       312.313985            0.205603\n",
      "      6                0.10027641         0.774148  3.433953         3.778019       0.822630  0.862737                  0.905054          0.918834      0.172436                 0.378846  243.395280       277.801861            0.366326\n",
      "      7                0.15003071         0.644714  2.821557         3.460830       0.675926  0.707075                  0.829069          0.848609      0.140385                 0.519231  182.155745       246.082986            0.485507\n",
      "      8                0.20009214         0.502075  2.343275         3.181227       0.561350  0.576500                  0.762087          0.780529      0.117308                 0.636538  134.327513       218.122675            0.573937\n",
      "      9                0.30006143         0.300762  1.686415         2.683211       0.403994  0.394927                  0.642784          0.652061      0.168590                 0.805128   68.641538       168.321130            0.664175\n",
      "     10                0.40003071         0.175646  1.090078         2.285081       0.261137  0.234591                  0.547409          0.547733      0.108974                 0.914103    9.007838       128.508096            0.676017\n",
      "     11                0.50000000         0.092353  0.468092         1.921795       0.112135  0.131276                  0.460381          0.464467      0.046795                 0.960897  -53.190752        92.179487            0.606091\n",
      "     12                0.59996929         0.046431  0.250077         1.643247       0.059908  0.066565                  0.393652          0.398167      0.025000                 0.985897  -74.992320        64.324651            0.507505\n",
      "     13                0.69993857         0.025888  0.089771         1.421370       0.021505  0.034544                  0.340500          0.346232      0.008974                 0.994872  -91.022884        42.137015            0.387844\n",
      "     14                0.79990786         0.014902  0.025649         1.246938       0.006144  0.019978                  0.298714          0.305458      0.002564                 0.997436  -97.435110        24.693848            0.259754\n",
      "     15                0.89987715         0.008975  0.019237         1.110550       0.004608  0.011552                  0.266041          0.272808      0.001923                 0.999359  -98.076332        11.055045            0.130821\n",
      "     16                1.00000000         0.005710  0.006402         1.000000       0.001534  0.006704                  0.239558          0.246165      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3780.579102          1.000000   0.211412\n",
      "                      capital_gain         3382.059814          0.894588   0.189127\n",
      "                               age         1591.665039          0.421011   0.089007\n",
      "marital_status. Married-civ-spouse         1512.141968          0.399976   0.084560\n",
      "                      capital_loss         1109.824097          0.293559   0.062062\n",
      "                            fnlwgt          930.724365          0.246186   0.052047\n",
      "                    hours_per_week          863.978699          0.228531   0.048314\n",
      "              education. Bachelors          697.775818          0.184569   0.039020\n",
      "        occupation. Prof-specialty          543.490784          0.143759   0.030392\n",
      "       occupation. Exec-managerial          528.556152          0.139808   0.029557\n",
      "---\n",
      "                     occupation.NA           20.354479          0.005384   0.001138\n",
      "              workclass. Local-gov           19.036589          0.005035   0.001065\n",
      "                       race. Black           18.159512          0.004803   0.001015\n",
      "      occupation. Transport-moving           16.328186          0.004319   0.000913\n",
      "            native_country. Mexico           14.835849          0.003924   0.000830\n",
      "             education. Assoc-acdm           12.305281          0.003255   0.000688\n",
      "           marital_status. Widowed            6.453573          0.001707   0.000361\n",
      "          marital_status. Divorced            6.225519          0.001647   0.000348\n",
      "              workclass. State-gov            3.853467          0.001019   0.000215\n",
      "           relationship. Unmarried            1.949538          0.000516   0.000109\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        48403.320313          1.000000   0.130869\n",
      "                      capital_gain        44322.371094          0.915689   0.119835\n",
      "                      capital_loss        32553.917969          0.672555   0.088017\n",
      "                    hours_per_week        27497.886719          0.568099   0.074346\n",
      "                            fnlwgt        26572.437500          0.548980   0.071844\n",
      "             relationship. Husband        18009.621094          0.372074   0.048693\n",
      "marital_status. Married-civ-spouse        17632.072266          0.364274   0.047672\n",
      "              education. Bachelors        13775.103516          0.284590   0.037244\n",
      "        occupation. Prof-specialty        11087.894531          0.229073   0.029979\n",
      "                education. Masters        10003.890625          0.206678   0.027048\n",
      "---\n",
      "              education. Assoc-voc          922.439453          0.019057   0.002494\n",
      "       relationship. Not-in-family          819.764648          0.016936   0.002216\n",
      "                     occupation.NA          771.560913          0.015940   0.002086\n",
      "      occupation. Transport-moving          682.137085          0.014093   0.001844\n",
      "          occupation. Craft-repair          611.509583          0.012634   0.001653\n",
      "             education. Assoc-acdm          597.902588          0.012353   0.001617\n",
      "           marital_status. Widowed          318.847626          0.006587   0.000862\n",
      "              workclass. State-gov          243.183578          0.005024   0.000657\n",
      "          marital_status. Divorced          203.825729          0.004211   0.000551\n",
      "           relationship. Unmarried           38.517387          0.000796   0.000104\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          371.000000          1.000000   0.290297\n",
      "                         age          264.000000          0.711590   0.206573\n",
      "              hours_per_week          112.000000          0.301887   0.087637\n",
      "                capital_gain           46.000000          0.123989   0.035994\n",
      "                capital_loss           37.000000          0.099730   0.028951\n",
      "  occupation. Prof-specialty           35.000000          0.094340   0.027387\n",
      "        education. Bachelors           32.000000          0.086253   0.025039\n",
      "          education. HS-grad           31.000000          0.083558   0.024257\n",
      "          workclass. Private           30.000000          0.080863   0.023474\n",
      " occupation. Exec-managerial           29.000000          0.078167   0.022692\n",
      "---\n",
      "     workclass. Self-emp-inc            4.000000          0.010782   0.003130\n",
      "occupation. Transport-moving            4.000000          0.010782   0.003130\n",
      "             education. 11th            3.000000          0.008086   0.002347\n",
      "              education. 9th            3.000000          0.008086   0.002347\n",
      "     marital_status. Widowed            2.000000          0.005391   0.001565\n",
      "             education. 10th            2.000000          0.005391   0.001565\n",
      "      native_country. Mexico            2.000000          0.005391   0.001565\n",
      "       education. Assoc-acdm            2.000000          0.005391   0.001565\n",
      "     relationship. Unmarried            1.000000          0.002695   0.000782\n",
      "        workclass. State-gov            1.000000          0.002695   0.000782\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      "\n",
      "10-20 18:27:02.214 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:02.236 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_31\n",
      "10-20 18:27:02.246 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:02.246) \n",
      "10-20 18:27:02.249 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_31\n",
      "10-20 18:27:02.257 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_32\n",
      "10-20 18:27:02.262 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_32\n",
      "10-20 18:27:02.261 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.08324318\n",
      " RMSE: 0.28851894\n",
      " AUC: 0.93773675\n",
      " pr_auc: 0.8501577\n",
      " logloss: 0.26740897\n",
      " mean_per_class_error: 0.15578453\n",
      " default threshold: 0.3812304139137268\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17873  1865  0.0945  1,865 / 19,738\n",
      "     1   1370  4941  0.2171   1,370 / 6,311\n",
      "Totals  19243  6806  0.1242  3,235 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.47 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01021152         0.985193  4.127555         4.127555       1.000000  0.987842                  1.000000          0.987842      0.042149                 0.042149   312.755506       312.755506            0.042149\n",
      "      2                0.02053822         0.981425  4.127555         4.127555       1.000000  0.983145                  1.000000          0.985480      0.042624                 0.084773   312.755506       312.755506            0.084773\n",
      "      3                0.03002035         0.974764  4.127555         4.127555       1.000000  0.978431                  1.000000          0.983254      0.039138                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.962033  4.111680         4.123594       0.996154  0.968704                  0.999040          0.979623      0.041039                 0.164950   311.167985       312.359388            0.164899\n",
      "      5                0.05002111         0.941750  4.048483         4.108549       0.980843  0.952996                  0.995395          0.974289      0.040564                 0.205514   304.848313       310.854867            0.205210\n",
      "      6                0.10000384         0.757271  3.769326         3.939003       0.913210  0.846575                  0.954319          0.910457      0.188401                 0.393915   276.932640       293.900264            0.387886\n",
      "      7                0.15002495         0.621165  3.041023         3.639599       0.736761  0.686246                  0.881781          0.835701      0.152115                 0.546031   204.102292       263.959947            0.522624\n",
      "      8                0.20000768         0.497778  2.437857         3.339279       0.590630  0.558299                  0.809021          0.766377      0.121851                 0.667881   143.785702       233.927919            0.617471\n",
      "      9                0.30001152         0.313039  1.658944         2.779168       0.401919  0.401174                  0.673321          0.644643      0.165901                 0.833782    65.894440       177.916759            0.704438\n",
      "     10                0.40001536         0.176884  0.933255         2.317690       0.226104  0.242531                  0.561516          0.544115      0.093329                 0.927111    -6.674475       131.768951            0.695629\n",
      "     11                0.50001919         0.091463  0.438899         1.941931       0.106334  0.130662                  0.470480          0.461424      0.043892                 0.971003   -56.110067        94.193147            0.621576\n",
      "     12                0.59998464         0.046332  0.194965         1.650864       0.047235  0.066246                  0.399962          0.395582      0.019490                 0.990493   -80.503484        65.086357            0.515369\n",
      "     13                0.69998848         0.025713  0.061794         1.423841       0.014971  0.034235                  0.344960          0.343958      0.006180                 0.996672   -93.820551        42.384125            0.391545\n",
      "     14                0.79999232         0.015543  0.025352         1.249022       0.006142  0.020208                  0.302606          0.303488      0.002535                 0.999208   -97.464841        24.902165            0.262912\n",
      "     15                0.90084072         0.008644  0.007856         1.110074       0.001903  0.011979                  0.268942          0.270853      0.000792                 1.000000   -99.214398        11.007415            0.130864\n",
      "     16                1.00000000         0.005776  0.000000         1.000000       0.000000  0.006930                  0.242274          0.244683      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09037728\n",
      " RMSE: 0.30062816\n",
      " AUC: 0.9227747\n",
      " pr_auc: 0.81415915\n",
      " logloss: 0.2866432\n",
      " mean_per_class_error: 0.17922665\n",
      " default threshold: 0.3967225253582001\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4541   441  0.0885  441 / 4,982\n",
      "     1   413  1117  0.2699  413 / 1,530\n",
      "Totals  4954  1558  0.1311  854 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.95 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01028870         0.984537  4.256209         4.256209       1.000000  0.987277                  1.000000          0.987277      0.043791                 0.043791   325.620915       325.620915            0.043791\n",
      "      2                0.02011671         0.981431  4.256209         4.256209       1.000000  0.982924                  1.000000          0.985150      0.041830                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.975396  4.190729         4.234494       0.984615  0.979081                  0.994898          0.983138      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.961578  4.190729         4.223595       0.984615  0.968852                  0.992337          0.979580      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.940394  4.256209         4.230097       1.000000  0.951790                  0.993865          0.974039      0.042484                 0.211765   325.620915       323.009744            0.211363\n",
      "      6                0.10012285         0.746533  3.590360         3.910229       0.843558  0.841834                  0.918712          0.907937      0.179739                 0.391503   259.036048       291.022896            0.380865\n",
      "      7                0.15003071         0.604988  2.894222         3.572253       0.680000  0.672737                  0.839304          0.829697      0.144444                 0.535948   189.422222       257.225333            0.504434\n",
      "      8                0.20009214         0.475209  2.323942         3.259936       0.546012  0.537730                  0.765925          0.756650      0.116340                 0.652288   132.394242       225.993610            0.591067\n",
      "      9                0.30006143         0.298000  1.542958         2.687903       0.362519  0.382943                  0.631525          0.632145      0.154248                 0.806536    54.295754       168.790281            0.662016\n",
      "     10                0.40003071         0.171665  0.961079         2.256363       0.225806  0.228877                  0.530134          0.531366      0.096078                 0.902614    -3.892051       125.636270            0.656930\n",
      "     11                0.50000000         0.092825  0.601492         1.925490       0.141321  0.130109                  0.452396          0.451139      0.060131                 0.962745   -39.850808        92.549020            0.604857\n",
      "     12                0.59996929         0.045285  0.268056         1.649322       0.062980  0.067119                  0.387510          0.387152      0.026797                 0.989542   -73.194382        64.932190            0.509213\n",
      "     13                0.69993857         0.025149  0.065380         1.423094       0.015361  0.033561                  0.334357          0.336650      0.006536                 0.996078   -93.462044        42.309406            0.387086\n",
      "     14                0.79990786         0.015095  0.019614         1.247693       0.004608  0.019840                  0.293146          0.297057      0.001961                 0.998039   -98.038613        24.769272            0.258979\n",
      "     15                0.89987715         0.008500  0.019614         1.111263       0.004608  0.011565                  0.261092          0.265341      0.001961                 1.000000   -98.038613        11.126280            0.130871\n",
      "     16                1.00000000         0.005776  0.000000         1.000000       0.000000  0.006772                  0.234951          0.239452      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4065.315674          1.000000   0.227602\n",
      "                      capital_gain         3382.038330          0.831925   0.189348\n",
      "                               age         1656.612305          0.407499   0.092748\n",
      "marital_status. Married-civ-spouse         1463.180542          0.359918   0.081918\n",
      "                      capital_loss         1054.761108          0.259454   0.059052\n",
      "                            fnlwgt          898.204834          0.220943   0.050287\n",
      "                    hours_per_week          869.253357          0.213822   0.048666\n",
      "              education. Bachelors          604.075684          0.148593   0.033820\n",
      "       occupation. Exec-managerial          542.911011          0.133547   0.030396\n",
      "        occupation. Prof-specialty          532.906738          0.131086   0.029836\n",
      "---\n",
      "      occupation. Transport-moving           15.451007          0.003801   0.000865\n",
      "             education. Assoc-acdm           11.900757          0.002927   0.000666\n",
      "                     occupation.NA            9.257658          0.002277   0.000518\n",
      "                education. 5th-6th            6.929251          0.001704   0.000388\n",
      "                       race. Black            6.863628          0.001688   0.000384\n",
      "           marital_status. Widowed            5.938560          0.001461   0.000332\n",
      "          race. Asian-Pac-Islander            5.600218          0.001378   0.000314\n",
      "         marital_status. Separated            5.456517          0.001342   0.000305\n",
      "                 native_country.NA            5.196322          0.001278   0.000291\n",
      "           relationship. Unmarried            3.313882          0.000815   0.000186\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        45537.347656          1.000000   0.123347\n",
      "                               age        45494.296875          0.999055   0.123230\n",
      "                            fnlwgt        31518.500000          0.692146   0.085374\n",
      "                      capital_loss        31186.644531          0.684859   0.084475\n",
      "                    hours_per_week        26396.947266          0.579677   0.071501\n",
      "             relationship. Husband        18154.132813          0.398665   0.049174\n",
      "marital_status. Married-civ-spouse        15828.675781          0.347598   0.042875\n",
      "              education. Bachelors        12408.646484          0.272494   0.033611\n",
      "        occupation. Prof-specialty        10830.734375          0.237843   0.029337\n",
      "       occupation. Exec-managerial        10316.842773          0.226558   0.027945\n",
      "---\n",
      "          occupation. Adm-clerical         1048.485229          0.023025   0.002840\n",
      "          occupation. Craft-repair          997.288208          0.021900   0.002701\n",
      "       relationship. Not-in-family          949.958679          0.020861   0.002573\n",
      "                         sex. Male          939.587585          0.020633   0.002545\n",
      "                 native_country.NA          896.452454          0.019686   0.002428\n",
      "                       race. White          776.327576          0.017048   0.002103\n",
      "                education. 5th-6th          713.308777          0.015664   0.001932\n",
      "          race. Asian-Pac-Islander          459.352692          0.010087   0.001244\n",
      "             education. Assoc-acdm          215.412369          0.004730   0.000583\n",
      "           relationship. Unmarried           99.091766          0.002176   0.000268\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          356.000000          1.000000   0.289666\n",
      "                        age          272.000000          0.764045   0.221318\n",
      "             hours_per_week           95.000000          0.266854   0.077299\n",
      "               capital_gain           45.000000          0.126404   0.036615\n",
      "       education. Bachelors           40.000000          0.112360   0.032547\n",
      "               capital_loss           37.000000          0.103933   0.030106\n",
      "         education. HS-grad           35.000000          0.098315   0.028478\n",
      " occupation. Prof-specialty           29.000000          0.081461   0.023596\n",
      "occupation. Exec-managerial           26.000000          0.073034   0.021155\n",
      "         workclass. Private           25.000000          0.070225   0.020342\n",
      "---\n",
      "    relationship. Own-child            3.000000          0.008427   0.002441\n",
      "              occupation.NA            2.000000          0.005618   0.001627\n",
      "    workclass. Self-emp-inc            2.000000          0.005618   0.001627\n",
      "             education. 9th            2.000000          0.005618   0.001627\n",
      "    marital_status. Widowed            1.000000          0.002809   0.000814\n",
      "  marital_status. Separated            1.000000          0.002809   0.000814\n",
      "   race. Asian-Pac-Islander            1.000000          0.002809   0.000814\n",
      "      education. Assoc-acdm            1.000000          0.002809   0.000814\n",
      "          native_country.NA            1.000000          0.002809   0.000814\n",
      "         education. 5th-6th            1.000000          0.002809   0.000814\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      "\n",
      "10-20 18:27:02.279 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.08398483\n",
      " RMSE: 0.28980136\n",
      " AUC: 0.9356807\n",
      " pr_auc: 0.8435332\n",
      " logloss: 0.2694832\n",
      " mean_per_class_error: 0.15712696\n",
      " default threshold: 0.35853463411331177\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17784  2049  0.1033  2,049 / 19,833\n",
      "     1   1311  4904  0.2109   1,311 / 6,215\n",
      "Totals  19095  6953  0.1290  3,360 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 24.13 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.981904  4.191150         4.191150       1.000000  0.986337                  1.000000          0.986337      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.972952  4.191150         4.191150       1.000000  0.977148                  1.000000          0.981752      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.963644  4.191150         4.191150       1.000000  0.968579                  1.000000          0.977355      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.949896  4.175031         4.187128       0.996154  0.956977                  0.999040          0.972270      0.041673                 0.167498   317.503063       318.712823            0.167448\n",
      "      5                0.05002303         0.927338  4.126918         4.175068       0.984674  0.939984                  0.996163          0.965803      0.041352                 0.208850   312.691825       317.506775            0.208597\n",
      "      6                0.10000768         0.753344  3.769460         3.972342       0.899386  0.836854                  0.947793          0.901353      0.188415                 0.397265   276.946019       297.234182            0.390407\n",
      "      7                0.15003071         0.610846  3.020330         3.654923       0.720645  0.680153                  0.872057          0.827601      0.151086                 0.548351   202.033021       265.492342            0.523140\n",
      "      8                0.20001536         0.483720  2.423914         3.347289       0.578341  0.545912                  0.798656          0.757206      0.121158                 0.669509   142.391420       234.728925            0.616618\n",
      "      9                0.30002303         0.307218  1.602451         2.765677       0.382342  0.388161                  0.659885          0.634191      0.160257                 0.829767    60.245138       176.567663            0.695748\n",
      "     10                0.39999232         0.178195  0.988236         2.321444       0.235791  0.239691                  0.553892          0.535594      0.098793                 0.928560    -1.176407       132.144440            0.694203\n",
      "     11                0.50000000         0.091625  0.432791         1.943685       0.103263  0.130923                  0.463759          0.454654      0.043282                 0.971842   -56.720942        94.368463            0.619702\n",
      "     12                0.60000768         0.045693  0.185022         1.650555       0.044146  0.066692                  0.393819          0.389989      0.018504                 0.990346   -81.497800        65.055544            0.512657\n",
      "     13                0.69997697         0.025472  0.069209         1.424711       0.016513  0.033773                  0.339933          0.339115      0.006919                 0.997265   -93.079129        42.471071            0.390448\n",
      "     14                0.80013821         0.015757  0.020883         1.248980       0.004983  0.020239                  0.298004          0.299198      0.002092                 0.999356   -97.911654        24.897972            0.261647\n",
      "     15                0.90202703         0.008593  0.006317         1.108614       0.001507  0.011707                  0.264513          0.266725      0.000644                 1.000000   -99.368327        10.861423            0.128674\n",
      "     16                1.00000000         0.005110  0.000000         1.000000       0.000000  0.006999                  0.238598          0.241279      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09141306\n",
      " RMSE: 0.30234593\n",
      " AUC: 0.9260787\n",
      " pr_auc: 0.8313999\n",
      " logloss: 0.28962806\n",
      " mean_per_class_error: 0.17261872\n",
      " default threshold: 0.3510570526123047\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4381   506  0.1035  506 / 4,887\n",
      "     1   393  1233  0.2417  393 / 1,626\n",
      "Totals  4774  1739  0.1380  899 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.980427  4.005535         4.005535       1.000000  0.985207                  1.000000          0.985207      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.971984  4.005535         4.005535       1.000000  0.975860                  1.000000          0.980569      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.961164  4.005535         4.005535       1.000000  0.967122                  1.000000          0.976110      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.950640  4.005535         4.005535       1.000000  0.956234                  1.000000          0.971160      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.931801  4.005535         4.005535       1.000000  0.941826                  1.000000          0.965311      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.766454  3.538632         3.772084       0.883436  0.850504                  0.941718          0.907908      0.177122                 0.377614   253.863220       277.208363            0.369838\n",
      "      7                0.15000768         0.618007  2.957934         3.501256       0.738462  0.692560                  0.874104          0.836272      0.147601                 0.525215   195.793358       250.125582            0.500046\n",
      "      8                0.20006142         0.482099  2.260793         3.190902       0.564417  0.548091                  0.796623          0.764171      0.113161                 0.638376   126.079279       219.090206            0.584151\n",
      "      9                0.30001535         0.301314  1.655129         2.679240       0.413210  0.385484                  0.668884          0.638007      0.165437                 0.803813    65.512892       167.923967            0.671421\n",
      "     10                0.39996929         0.174640  0.984463         2.255708       0.245776  0.234104                  0.563148          0.537070      0.098401                 0.902214    -1.553670       125.570823            0.669351\n",
      "     11                0.50007677         0.095783  0.583629         1.920984       0.145706  0.132294                  0.479582          0.456040      0.058426                 0.960640   -41.637143        92.098427            0.613801\n",
      "     12                0.60003071         0.045917  0.246116         1.641982       0.061444  0.068560                  0.409928          0.391493      0.024600                 0.985240   -75.388417        64.198238            0.513376\n",
      "     13                0.69998465         0.025589  0.110752         1.423331       0.027650  0.034570                  0.355341          0.340527      0.011070                 0.996310   -88.924788        42.333117            0.394919\n",
      "     14                0.80024566         0.015638  0.030670         1.248848       0.007657  0.020128                  0.311781          0.300384      0.003075                 0.999385   -96.932975        24.884775            0.265397\n",
      "     15                0.90388454         0.008593  0.005934         1.106336       0.001481  0.011810                  0.276202          0.267297      0.000615                 1.000000   -99.406587        10.633599            0.128095\n",
      "     16                1.00000000         0.005801  0.000000         1.000000       0.000000  0.007014                  0.249655          0.242280      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4117.699219          1.000000   0.240644\n",
      "                      capital_gain         3109.007080          0.755035   0.181695\n",
      "             relationship. Husband         1822.661621          0.442641   0.106519\n",
      "                               age         1333.914307          0.323947   0.077956\n",
      "                      capital_loss         1041.644775          0.252968   0.060875\n",
      "                    hours_per_week          931.909668          0.226318   0.054462\n",
      "                            fnlwgt          647.590881          0.157270   0.037846\n",
      "        occupation. Prof-specialty          582.600647          0.141487   0.034048\n",
      "              education. Bachelors          518.730713          0.125976   0.030315\n",
      "       occupation. Exec-managerial          480.546692          0.116703   0.028084\n",
      "---\n",
      "           workclass. Self-emp-inc           11.788568          0.002863   0.000689\n",
      "      relationship. Other-relative            9.518335          0.002312   0.000556\n",
      "          occupation. Craft-repair            8.373713          0.002034   0.000489\n",
      "                      workclass.NA            8.340279          0.002025   0.000487\n",
      "          marital_status. Divorced            8.100668          0.001967   0.000473\n",
      "                education. 5th-6th            7.998797          0.001943   0.000467\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001927   0.000464\n",
      "                     occupation.NA            4.577152          0.001112   0.000267\n",
      "           marital_status. Widowed            0.747231          0.000181   0.000044\n",
      "           relationship. Unmarried            0.133739          0.000032   0.000008\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        46475.925781          1.000000   0.127181\n",
      "                               age        45996.667969          0.989688   0.125870\n",
      "                      capital_loss        32942.054688          0.708798   0.090146\n",
      "                    hours_per_week        28538.705078          0.614054   0.078096\n",
      "marital_status. Married-civ-spouse        26483.849609          0.569840   0.072473\n",
      "                            fnlwgt        23771.833984          0.511487   0.065052\n",
      "              education. Bachelors        13129.819336          0.282508   0.035930\n",
      "        occupation. Prof-specialty        11626.310547          0.250158   0.031815\n",
      "       occupation. Exec-managerial        10958.965820          0.235799   0.029989\n",
      "              education. Doctorate         8478.356445          0.182425   0.023201\n",
      "---\n",
      "                     occupation.NA         1109.066284          0.023863   0.003035\n",
      "          occupation. Adm-clerical         1061.543823          0.022841   0.002905\n",
      "                education. 5th-6th         1003.292114          0.021587   0.002746\n",
      "              workclass. Local-gov          938.169678          0.020186   0.002567\n",
      "          occupation. Craft-repair          817.171875          0.017583   0.002236\n",
      "                         sex. Male          672.399048          0.014468   0.001840\n",
      "          marital_status. Divorced          419.028625          0.009016   0.001147\n",
      "                      workclass.NA          335.362122          0.007216   0.000918\n",
      "           relationship. Unmarried           88.143829          0.001897   0.000241\n",
      "           marital_status. Widowed           86.806030          0.001868   0.000238\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          279.000000          1.000000   0.236641\n",
      "                         age          272.000000          0.974910   0.230704\n",
      "              hours_per_week          121.000000          0.433692   0.102629\n",
      "                capital_gain           39.000000          0.139785   0.033079\n",
      "                capital_loss           37.000000          0.132616   0.031383\n",
      "          workclass. Private           34.000000          0.121864   0.028838\n",
      "          education. HS-grad           32.000000          0.114695   0.027142\n",
      "  occupation. Prof-specialty           31.000000          0.111111   0.026293\n",
      "        education. Bachelors           31.000000          0.111111   0.026293\n",
      "     education. Some-college           22.000000          0.078853   0.018660\n",
      "---\n",
      "       education. Assoc-acdm            3.000000          0.010753   0.002545\n",
      "                workclass.NA            2.000000          0.007168   0.001696\n",
      "      native_country. Mexico            2.000000          0.007168   0.001696\n",
      "     workclass. Self-emp-inc            2.000000          0.007168   0.001696\n",
      "     relationship. Unmarried            1.000000          0.003584   0.000848\n",
      "     marital_status. Widowed            1.000000          0.003584   0.000848\n",
      "relationship. Other-relative            1.000000          0.003584   0.000848\n",
      "               occupation.NA            1.000000          0.003584   0.000848\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.003584   0.000848\n",
      "          education. 5th-6th            1.000000          0.003584   0.000848\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      "\n",
      "10-20 18:27:02.287 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:02.287) \n",
      "10-20 18:27:02.293 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_33\n",
      "10-20 18:27:02.319 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_33\n",
      "10-20 18:27:02.325 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.08261831\n",
      " RMSE: 0.287434\n",
      " AUC: 0.938647\n",
      " pr_auc: 0.8515357\n",
      " logloss: 0.26523185\n",
      " mean_per_class_error: 0.15745507\n",
      " default threshold: 0.39039015769958496\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17981  1764  0.0893  1,764 / 19,745\n",
      "     1   1422  4882  0.2256   1,422 / 6,304\n",
      "Totals  19403  6646  0.1223  3,186 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.52 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01009636         0.983408  4.132138         4.132138       1.000000  0.985981                  1.000000          0.985981      0.041720                 0.041720  313.213832       313.213832            0.041720\n",
      "      2                0.02003916         0.979058  4.132138         4.132138       1.000000  0.981243                  1.000000          0.983630      0.041085                 0.082805  313.213832       313.213832            0.082805\n",
      "      3                0.03002035         0.973042  4.132138         4.132138       1.000000  0.976089                  1.000000          0.981123      0.041244                 0.124048  313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.960738  4.100353         4.124207       0.992308  0.968078                  0.998081          0.977868      0.040926                 0.164975  310.035265       312.420716            0.164873\n",
      "      5                0.05002111         0.941970  4.116306         4.122625       0.996169  0.951181                  0.997698          0.972522      0.041244                 0.206218  311.630638       312.262458            0.206066\n",
      "      6                0.10008062         0.772657  3.774062         3.948276       0.913344  0.856136                  0.955504          0.914307      0.188928                 0.395146  277.406192       294.827640            0.389271\n",
      "      7                0.15002495         0.632584  3.042728         3.646813       0.736357  0.701124                  0.882549          0.843337      0.151967                 0.547113  204.272753       264.681297            0.523867\n",
      "      8                0.20000768         0.502008  2.446911         3.346953       0.592166  0.567211                  0.809981          0.774332      0.122303                 0.669416  144.691140       234.695273            0.619277\n",
      "      9                0.30035702         0.311497  1.685103         2.791728       0.407804  0.399161                  0.675613          0.648987      0.169099                 0.838515   68.510308       179.172842            0.709976\n",
      "     10                0.40001536         0.174283  0.935939         2.329384       0.226502  0.239563                  0.563724          0.546985      0.093274                 0.931789   -6.406112       132.938393            0.701554\n",
      "     11                0.50001919         0.090444  0.398145         1.943136       0.096353  0.129588                  0.470250          0.463505      0.039816                 0.971605  -60.185539        94.313606            0.622150\n",
      "     12                0.59998464         0.043538  0.187247         1.650582       0.045315  0.064397                  0.399450          0.397008      0.018718                 0.990324  -81.275256        65.058158            0.514963\n",
      "     13                0.69998848         0.023705  0.066622         1.424289       0.016123  0.031853                  0.344686          0.344840      0.006662                 0.996986  -93.337819        42.428921            0.391820\n",
      "     14                0.79999232         0.015030  0.025380         1.249417       0.006142  0.019044                  0.302366          0.304114      0.002538                 0.999524  -97.462026        24.941713            0.263236\n",
      "     15                0.90003455         0.009062  0.003171         1.110892       0.000767  0.011874                  0.268842          0.271630      0.000317                 0.999841  -99.682875        11.089221            0.131672\n",
      "     16                1.00000000         0.005369  0.001587         1.000000       0.000384  0.007025                  0.242005          0.245179      0.000159                 1.000000  -99.841316         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09449828\n",
      " RMSE: 0.3074057\n",
      " AUC: 0.91471004\n",
      " pr_auc: 0.80193126\n",
      " logloss: 0.29905537\n",
      " mean_per_class_error: 0.19331315\n",
      " default threshold: 0.4280287027359009\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4534   441  0.0886  441 / 4,975\n",
      "     1   458  1079  0.2980  458 / 1,537\n",
      "Totals  4992  1520  0.1381  899 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.51 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.982799  4.236825         4.236825       1.000000  0.985457                  1.000000          0.985457      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.977913  4.236825         4.236825       1.000000  0.980582                  1.000000          0.983038      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.971352  4.236825         4.236825       1.000000  0.975218                  1.000000          0.980445      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.953968  4.236825         4.236825       1.000000  0.964699                  1.000000          0.976523      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.932003  4.106461         4.210832       0.969231  0.942659                  0.993865          0.969771      0.040989                 0.210800  310.646114       321.083219            0.210398\n",
      "      6                0.10012285         0.764033  3.600002         3.905417       0.849693  0.841955                  0.921779          0.905863      0.180221                 0.391021  260.000160       290.541689            0.380770\n",
      "      7                0.15003071         0.622962  2.672459         3.495272       0.630769  0.687868                  0.824974          0.833347      0.133377                 0.524398  167.245884       249.527220            0.490026\n",
      "      8                0.20009214         0.498007  2.274369         3.189812       0.536810  0.557360                  0.752878          0.764297      0.113858                 0.638256  127.436924       218.981221            0.573533\n",
      "      9                0.30006143         0.325092  1.542439         2.640969       0.364055  0.404428                  0.623337          0.644402      0.154196                 0.792453   54.243859       164.096870            0.644513\n",
      "     10                0.40003071         0.180814  1.080358         2.250966       0.254992  0.250033                  0.531286          0.545848      0.108003                 0.900455    8.035783       125.096575            0.655028\n",
      "     11                0.50000000         0.092035  0.540179         1.908913       0.127496  0.133611                  0.450553          0.463426      0.054001                 0.954457  -45.982109        90.891347            0.594859\n",
      "     12                0.59996929         0.041906  0.234294         1.629882       0.055300  0.063272                  0.384694          0.396750      0.023422                 0.977879  -76.570553        62.988174            0.494663\n",
      "     13                0.69993857         0.024410  0.117147         1.413824       0.027650  0.031636                  0.333699          0.344603      0.011711                 0.989590  -88.285277        41.382422            0.379138\n",
      "     14                0.79990786         0.015520  0.084606         1.247704       0.019969  0.019665                  0.294490          0.303993      0.008458                 0.998048  -91.539366        24.770388            0.259355\n",
      "     15                0.90171990         0.009221  0.012781         1.108270       0.003017  0.012103                  0.261580          0.271036      0.001301                 0.999349  -98.721923        10.827030            0.127792\n",
      "     16                1.00000000         0.005369  0.006620         1.000000       0.001563  0.007027                  0.236026          0.245090      0.000651                 1.000000  -99.337996         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4133.209473          1.000000   0.231126\n",
      "                      capital_gain         3323.220947          0.804029   0.185832\n",
      "                               age         1595.187378          0.385944   0.089202\n",
      "marital_status. Married-civ-spouse         1434.945068          0.347175   0.080241\n",
      "                      capital_loss         1095.944580          0.265156   0.061285\n",
      "                    hours_per_week          912.309570          0.220727   0.051016\n",
      "                            fnlwgt          818.031494          0.197917   0.045744\n",
      "              education. Bachelors          675.435364          0.163417   0.037770\n",
      "       occupation. Exec-managerial          485.373260          0.117433   0.027142\n",
      "        occupation. Prof-specialty          482.120209          0.116645   0.026960\n",
      "---\n",
      "             education. Assoc-acdm           17.338703          0.004195   0.000970\n",
      "      occupation. Transport-moving           15.826141          0.003829   0.000885\n",
      "          occupation. Craft-repair           11.725878          0.002837   0.000656\n",
      "          marital_status. Divorced           11.558912          0.002797   0.000646\n",
      "                       race. Black           11.069815          0.002678   0.000619\n",
      "                     occupation.NA            7.819288          0.001892   0.000437\n",
      "           relationship. Unmarried            7.569074          0.001831   0.000423\n",
      "                education. 5th-6th            5.686970          0.001376   0.000318\n",
      "              workclass. State-gov            4.530758          0.001096   0.000253\n",
      "          race. Asian-Pac-Islander            0.537106          0.000130   0.000030\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        50163.343750          1.000000   0.136507\n",
      "                      capital_gain        45827.945313          0.913574   0.124709\n",
      "                      capital_loss        30031.642578          0.598677   0.081724\n",
      "                    hours_per_week        28112.431641          0.560418   0.076501\n",
      "                            fnlwgt        27097.244141          0.540180   0.073738\n",
      "             relationship. Husband        18003.257813          0.358893   0.048991\n",
      "marital_status. Married-civ-spouse        17309.062500          0.345054   0.047102\n",
      "              education. Bachelors        12277.312500          0.244747   0.033410\n",
      "        occupation. Prof-specialty        11435.987305          0.227975   0.031120\n",
      "                education. Masters         9543.010742          0.190239   0.025969\n",
      "---\n",
      "                       race. Black          999.186768          0.019919   0.002719\n",
      "                       race. White          677.717834          0.013510   0.001844\n",
      "       relationship. Not-in-family          594.587952          0.011853   0.001618\n",
      "              workclass. State-gov          433.376862          0.008639   0.001179\n",
      "          occupation. Craft-repair          403.496155          0.008044   0.001098\n",
      "              workclass. Local-gov          379.362183          0.007563   0.001032\n",
      "          marital_status. Divorced          283.327271          0.005648   0.000771\n",
      "           relationship. Unmarried          240.046570          0.004785   0.000653\n",
      "                     occupation.NA           98.981148          0.001973   0.000269\n",
      "          race. Asian-Pac-Islander           49.246716          0.000982   0.000134\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          374.000000          1.000000   0.298722\n",
      "                          age          263.000000          0.703209   0.210064\n",
      "               hours_per_week          117.000000          0.312834   0.093450\n",
      "                 capital_gain           46.000000          0.122995   0.036741\n",
      "                 capital_loss           39.000000          0.104278   0.031150\n",
      "         education. Bachelors           38.000000          0.101604   0.030351\n",
      "   occupation. Prof-specialty           32.000000          0.085561   0.025559\n",
      "           workclass. Private           30.000000          0.080214   0.023962\n",
      "  occupation. Exec-managerial           29.000000          0.077540   0.023163\n",
      "           education. HS-grad           22.000000          0.058824   0.017572\n",
      "---\n",
      "                  race. Black            3.000000          0.008021   0.002396\n",
      "occupation. Machine-op-inspct            3.000000          0.008021   0.002396\n",
      "      relationship. Own-child            3.000000          0.008021   0.002396\n",
      "        education. Assoc-acdm            3.000000          0.008021   0.002396\n",
      " occupation. Transport-moving            3.000000          0.008021   0.002396\n",
      "               education. 9th            2.000000          0.005348   0.001597\n",
      "                occupation.NA            1.000000          0.002674   0.000799\n",
      "     race. Asian-Pac-Islander            1.000000          0.002674   0.000799\n",
      "         workclass. State-gov            1.000000          0.002674   0.000799\n",
      "           education. 5th-6th            1.000000          0.002674   0.000799\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      "\n",
      "10-20 18:27:02.335 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:02.335) \n",
      "10-20 18:27:02.339 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:02.339) \n",
      "10-20 18:27:02.356 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:02.356) \n",
      "10-20 18:27:02.385 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:02.385) \n",
      "10-20 18:27:02.403 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:02.403) \n",
      "10-20 18:27:02.407 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.075 (Wall: 20-Oct 18:27:02.407) \n",
      "10-20 18:27:02.410 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:02.409) \n",
      "10-20 18:27:02.426 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:02.426) \n",
      "10-20 18:27:02.490 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:02.490) \n",
      "10-20 18:27:02.507 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.100 (Wall: 20-Oct 18:27:02.507) \n",
      "10-20 18:27:02.512 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:02.512) \n",
      "10-20 18:27:02.542 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_34\n",
      "10-20 18:27:02.550 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_34\n",
      "10-20 18:27:02.550 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:02.550) \n",
      "10-20 18:27:02.553 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:02.553) \n",
      "10-20 18:27:02.567 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.060 (Wall: 20-Oct 18:27:02.567) \n",
      "10-20 18:27:02.594 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:02.594) \n",
      "10-20 18:27:02.660 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:02.659) \n",
      "10-20 18:27:02.669 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.119 (Wall: 20-Oct 18:27:02.669) \n",
      "10-20 18:27:02.718 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:02.718) \n",
      "10-20 18:27:02.744 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:02.760 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_35\n",
      "10-20 18:27:02.766 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_36\n",
      "10-20 18:27:02.767 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_35\n",
      "10-20 18:27:02.779 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_36\n",
      "10-20 18:27:02.785 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_37\n",
      "10-20 18:27:02.799 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_37\n",
      "10-20 18:27:02.800 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.08057421\n",
      " RMSE: 0.28385597\n",
      " AUC: 0.9411138\n",
      " pr_auc: 0.8572933\n",
      " logloss: 0.25761333\n",
      " mean_per_class_error: 0.15165514\n",
      " default threshold: 0.36563101410865784\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17936  1832  0.0927  1,832 / 19,768\n",
      "     1   1323  4958  0.2106   1,323 / 6,281\n",
      "Totals  19259  6790  0.1211  3,155 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991197  4.147270         4.147270       1.000000  0.992525                  1.000000          0.992525      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.987816  4.147270         4.147270       1.000000  0.989705                  1.000000          0.991118      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.981932  4.147270         4.147270       1.000000  0.985324                  1.000000          0.989184      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.974105  4.131319         4.143289       0.996154  0.978392                  0.999040          0.986491      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05002111         0.958863  4.083710         4.131355       0.984674  0.967743                  0.996163          0.982736      0.040917                 0.206655   308.370986       313.135523            0.206402\n",
      "      6                0.10000384         0.784900  3.812812         3.972145       0.919355  0.869983                  0.957774          0.926381      0.190575                 0.397230   281.281232       297.214492            0.391665\n",
      "      7                0.15002495         0.637044  3.135119         3.693065       0.755948  0.711169                  0.890481          0.854626      0.156822                 0.554052   213.511934       269.306500            0.532401\n",
      "      8                0.20000768         0.505466  2.414463         3.373537       0.582181  0.570262                  0.813436          0.783562      0.120681                 0.674733   141.446261       237.353711            0.625563\n",
      "      9                0.30001152         0.302261  1.682788         2.809954       0.405758  0.392211                  0.677543          0.653112      0.168285                 0.843019    68.278845       180.995422            0.715540\n",
      "     10                0.40001536         0.166423  0.923384         2.338312       0.222649  0.229583                  0.563820          0.547229      0.092342                 0.935361    -7.661561       133.831176            0.705444\n",
      "     11                0.50001919         0.084520  0.401195         1.950888       0.096737  0.121779                  0.470403          0.462139      0.040121                 0.975482   -59.880540        95.088833            0.626534\n",
      "     12                0.59998464         0.038122  0.157673         1.652115       0.038018  0.058235                  0.398362          0.394844      0.015762                 0.991243   -84.232731        65.211467            0.515576\n",
      "     13                0.69998848         0.018328  0.066866         1.425638       0.016123  0.026849                  0.343753          0.342270      0.006687                 0.997930   -93.313423        42.563812            0.392609\n",
      "     14                0.79999232         0.009299  0.014328         1.249216       0.003455  0.013354                  0.301214          0.301153      0.001433                 0.999363   -98.567162        24.921594            0.262718\n",
      "     15                0.89999616         0.004351  0.006368         1.111116       0.001536  0.006607                  0.267915          0.268425      0.000637                 1.000000   -99.363183        11.111585            0.131779\n",
      "     16                1.00000000         0.001708  0.000000         1.000000       0.000000  0.002750                  0.241122          0.241856      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09226767\n",
      " RMSE: 0.30375594\n",
      " AUC: 0.92292315\n",
      " pr_auc: 0.81183547\n",
      " logloss: 0.28966266\n",
      " mean_per_class_error: 0.17668696\n",
      " default threshold: 0.36056604981422424\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4402   550  0.1111  550 / 4,952\n",
      "     1   378  1182  0.2423  378 / 1,560\n",
      "Totals  4780  1732  0.1425  928 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.34 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.991683  4.174359         4.174359       1.000000  0.992738                  1.000000          0.992738      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.988212  4.174359         4.174359       1.000000  0.989808                  1.000000          0.991284      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.981875  4.174359         4.174359       1.000000  0.985310                  1.000000          0.989303      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.974806  4.110138         4.158365       0.984615  0.978694                  0.996169          0.986661      0.041026                 0.166667  311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.963764  4.045917         4.135945       0.969231  0.970273                  0.990798          0.983393      0.040385                 0.207051  304.591716       313.594463            0.206445\n",
      "      6                0.10012285         0.788164  3.495706         3.815825       0.837423  0.876766                  0.914110          0.930080      0.175000                 0.382051  249.570552       281.582507            0.370743\n",
      "      7                0.15003071         0.652096  2.697278         3.443739       0.646154  0.719701                  0.824974          0.860097      0.134615                 0.516667  169.727811       244.373934            0.482135\n",
      "      8                0.20009214         0.516174  2.496933         3.206856       0.598160  0.585422                  0.768227          0.791376      0.125000                 0.641667  149.693252       220.685597            0.580681\n",
      "      9                0.30006143         0.300696  1.647942         2.687484       0.394777  0.398559                  0.643808          0.660504      0.164744                 0.806410   64.794202       168.748393            0.665861\n",
      "     10                0.40003071         0.166119  1.064429         2.281876       0.254992  0.227796                  0.546641          0.552368      0.106410                 0.912821    6.442948       128.187608            0.674331\n",
      "     11                0.50000000         0.079923  0.468092         1.919231       0.112135  0.119894                  0.459767          0.465900      0.046795                 0.959615  -53.190752        91.923077            0.604405\n",
      "     12                0.59996929         0.037618  0.256489         1.642178       0.061444  0.055353                  0.393396          0.397493      0.025641                 0.985256  -74.351097        64.217808            0.506662\n",
      "     13                0.69993857         0.018064  0.096183         1.421370       0.023041  0.026651                  0.340500          0.344527      0.009615                 0.994872  -90.381661        42.137015            0.387844\n",
      "     14                0.79990786         0.009315  0.032061         1.247740       0.007680  0.013198                  0.298906          0.303119      0.003205                 0.998077  -96.793887        24.773986            0.260597\n",
      "     15                0.90033784         0.004555  0.012766         1.109982       0.003058  0.006691                  0.265905          0.270053      0.001282                 0.999359  -98.723438        10.998220            0.130215\n",
      "     16                1.00000000         0.001734  0.006432         1.000000       0.001541  0.002855                  0.239558          0.243424      0.000641                 1.000000  -99.356801         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3781.856934          1.000000   0.201611\n",
      "                      capital_gain         3472.628906          0.918234   0.185126\n",
      "                               age         1778.034912          0.470149   0.094787\n",
      "marital_status. Married-civ-spouse         1518.410400          0.401499   0.080947\n",
      "                      capital_loss         1155.653442          0.305578   0.061608\n",
      "                            fnlwgt         1096.494507          0.289935   0.058454\n",
      "                    hours_per_week          964.516418          0.255038   0.051418\n",
      "              education. Bachelors          710.941162          0.187987   0.037900\n",
      "        occupation. Prof-specialty          545.598511          0.144267   0.029086\n",
      "       occupation. Exec-managerial          539.774231          0.142727   0.028775\n",
      "---\n",
      "          marital_status. Divorced           13.763988          0.003639   0.000734\n",
      "             education. Assoc-acdm           12.305281          0.003254   0.000656\n",
      "           marital_status. Widowed           11.497744          0.003040   0.000613\n",
      "          race. Asian-Pac-Islander            7.540277          0.001994   0.000402\n",
      "          race. Amer-Indian-Eskimo            6.894102          0.001823   0.000368\n",
      "      relationship. Other-relative            5.539434          0.001465   0.000295\n",
      "              workclass. State-gov            3.853467          0.001019   0.000205\n",
      "         marital_status. Separated            2.968688          0.000785   0.000158\n",
      "           relationship. Unmarried            1.949538          0.000515   0.000104\n",
      "                 native_country.NA            1.802669          0.000477   0.000096\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        62946.789063          1.000000   0.135334\n",
      "                      capital_gain        56696.863281          0.900711   0.121897\n",
      "                      capital_loss        43556.761719          0.691962   0.093646\n",
      "                            fnlwgt        34978.921875          0.555690   0.075204\n",
      "                    hours_per_week        33494.347656          0.532106   0.072012\n",
      "marital_status. Married-civ-spouse        18651.052734          0.296299   0.040099\n",
      "             relationship. Husband        18066.708984          0.287016   0.038843\n",
      "              education. Bachelors        16109.727539          0.255926   0.034635\n",
      "       occupation. Exec-managerial        11354.461914          0.180382   0.024412\n",
      "        occupation. Prof-specialty        11161.547852          0.177317   0.023997\n",
      "---\n",
      "         marital_status. Separated         1334.329346          0.021198   0.002869\n",
      "      relationship. Other-relative         1299.182373          0.020639   0.002793\n",
      "          occupation. Adm-clerical         1285.440063          0.020421   0.002764\n",
      "              education. Assoc-voc          922.439453          0.014654   0.001983\n",
      "                 native_country.NA          724.860779          0.011515   0.001558\n",
      "      occupation. Transport-moving          682.137085          0.010837   0.001467\n",
      "             education. Assoc-acdm          597.902588          0.009499   0.001285\n",
      "          marital_status. Divorced          514.636475          0.008176   0.001106\n",
      "              workclass. State-gov          243.183578          0.003863   0.000523\n",
      "           relationship. Unmarried           38.517387          0.000612   0.000083\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          421.000000          1.000000   0.274446\n",
      "                         age          340.000000          0.807601   0.221643\n",
      "              hours_per_week          146.000000          0.346793   0.095176\n",
      "                capital_gain           58.000000          0.137767   0.037810\n",
      "                capital_loss           45.000000          0.106888   0.029335\n",
      "          education. HS-grad           37.000000          0.087886   0.024120\n",
      "          workclass. Private           37.000000          0.087886   0.024120\n",
      "  occupation. Prof-specialty           36.000000          0.085511   0.023468\n",
      "        education. Bachelors           36.000000          0.085511   0.023468\n",
      " occupation. Exec-managerial           32.000000          0.076010   0.020860\n",
      "---\n",
      "     marital_status. Widowed            3.000000          0.007126   0.001956\n",
      "              education. 9th            3.000000          0.007126   0.001956\n",
      "       education. Assoc-acdm            2.000000          0.004751   0.001304\n",
      "     relationship. Unmarried            1.000000          0.002375   0.000652\n",
      "relationship. Other-relative            1.000000          0.002375   0.000652\n",
      "   marital_status. Separated            1.000000          0.002375   0.000652\n",
      "    race. Asian-Pac-Islander            1.000000          0.002375   0.000652\n",
      "        workclass. State-gov            1.000000          0.002375   0.000652\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002375   0.000652\n",
      "           native_country.NA            1.000000          0.002375   0.000652\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      " 2023-10-20 18:27:02  3.656 sec              20       0.28386          0.25761      0.94111         0.85729       4.14727                       0.12112         0.30376            0.28966        0.92292           0.81184         4.17436                         0.14251\n",
      "\n",
      "10-20 18:27:02.820 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_38\n",
      "10-20 18:27:02.828 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_38\n",
      "10-20 18:27:02.866 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:02.866) \n",
      "10-20 18:27:02.914 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_39\n",
      "10-20 18:27:02.924 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_39\n",
      "10-20 18:27:02.926 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:02.926) \n",
      "10-20 18:27:02.934 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.08152088\n",
      " RMSE: 0.28551862\n",
      " AUC: 0.93937105\n",
      " pr_auc: 0.85103816\n",
      " logloss: 0.26048145\n",
      " mean_per_class_error: 0.15818612\n",
      " default threshold: 0.38391631841659546\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18026  1807  0.0911  1,807 / 19,833\n",
      "     1   1400  4815  0.2253   1,400 / 6,215\n",
      "Totals  19426  6622  0.1231  3,207 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 24.02 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.990949  4.191150         4.191150       1.000000  0.993595                  1.000000          0.993595      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.984219  4.191150         4.191150       1.000000  0.987487                  1.000000          0.990547      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.976379  4.191150         4.191150       1.000000  0.980606                  1.000000          0.987229      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.965668  4.158911         4.183106       0.992308  0.971634                  0.998081          0.983338      0.041512                 0.167337   315.891082       318.310601            0.167236\n",
      "      5                0.05002303         0.944390  4.142976         4.175068       0.988506  0.956275                  0.996163          0.977917      0.041512                 0.208850   314.297630       317.506775            0.208597\n",
      "      6                0.10000768         0.770769  3.801650         3.988431       0.907066  0.857924                  0.951631          0.917944      0.190024                 0.398874   280.165029       298.843069            0.392521\n",
      "      7                0.15003071         0.623763  3.113610         3.696749       0.742901  0.695075                  0.882037          0.843635      0.155752                 0.554626   211.360985       269.674912            0.531382\n",
      "      8                0.20001536         0.495793  2.436790         3.381880       0.581413  0.556350                  0.806910          0.771842      0.121802                 0.676428   143.679023       238.188032            0.625704\n",
      "      9                0.30002303         0.303826  1.637847         2.800536       0.390787  0.393412                  0.668202          0.645698      0.163797                 0.840225    63.784689       180.053584            0.709484\n",
      "     10                0.39999232         0.169983  0.947998         2.337535       0.226190  0.233015                  0.557731          0.542557      0.094771                 0.934996    -5.200169       133.753481            0.702656\n",
      "     11                0.50000000         0.082530  0.389351         1.947868       0.092898  0.122447                  0.464757          0.458529      0.038938                 0.973934   -61.064936        94.786806            0.622449\n",
      "     12                0.60000768         0.038151  0.164106         1.650555       0.039155  0.057713                  0.393819          0.391722      0.016412                 0.990346   -83.589353        65.055544            0.512657\n",
      "     13                0.69997697         0.019199  0.075647         1.425630       0.018049  0.027281                  0.340152          0.339673      0.007562                 0.997908   -92.435328        42.563018            0.391293\n",
      "     14                0.79998464         0.010040  0.014480         1.249219       0.003455  0.014337                  0.298061          0.299002      0.001448                 0.999356   -98.552002        24.921947            0.261848\n",
      "     15                0.90014588         0.004485  0.006426         1.110931       0.001533  0.006981                  0.265066          0.266508      0.000644                 1.000000   -99.357432        11.093104            0.131145\n",
      "     16                1.00000000         0.001768  0.000000         1.000000       0.000000  0.003034                  0.238598          0.240199      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09116117\n",
      " RMSE: 0.3019291\n",
      " AUC: 0.9265924\n",
      " pr_auc: 0.8313383\n",
      " logloss: 0.286852\n",
      " mean_per_class_error: 0.16532792\n",
      " default threshold: 0.32625195384025574\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4311   576  0.1179  576 / 4,887\n",
      "     1   346  1280  0.2128  346 / 1,626\n",
      "Totals  4657  1856  0.1416  922 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.17 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.989984  4.005535         4.005535       1.000000  0.992944                  1.000000          0.992944      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.983121  4.005535         4.005535       1.000000  0.987014                  1.000000          0.990002      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.976953  4.005535         4.005535       1.000000  0.980258                  1.000000          0.986771      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.965785  4.005535         4.005535       1.000000  0.971859                  1.000000          0.983057      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.947323  4.005535         4.005535       1.000000  0.957097                  1.000000          0.977881      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.782037  3.501771         3.753653       0.874233  0.869085                  0.937117          0.923483      0.175277                 0.375769   250.177144       275.365325            0.367379\n",
      "      7                0.15000768         0.629039  2.896310         3.468457       0.723077  0.705934                  0.865916          0.851115      0.144526                 0.520295   189.630996       246.845717            0.493489\n",
      "      8                0.20006142         0.498890  2.260793         3.166309       0.564417  0.558813                  0.790483          0.777984      0.113161                 0.633456   126.079279       216.630937            0.577594\n",
      "      9                0.30001535         0.301412  1.735117         2.689489       0.433180  0.396214                  0.671443          0.650792      0.173432                 0.806888    73.511657       168.948925            0.675519\n",
      "     10                0.39996929         0.166631  0.990616         2.264934       0.247312  0.229743                  0.565451          0.545570      0.099016                 0.905904    -0.938380       126.493403            0.674269\n",
      "     11                0.50007677         0.085431  0.559055         1.923444       0.139571  0.123099                  0.480196          0.460998      0.055966                 0.961870   -44.094526        92.344391            0.615440\n",
      "     12                0.60003071         0.039375  0.221504         1.639932       0.055300  0.059461                  0.409417          0.394109      0.022140                 0.984010   -77.849576        63.993247            0.511736\n",
      "     13                0.69998465         0.019169  0.123058         1.423331       0.030722  0.027968                  0.355341          0.341826      0.012300                 0.996310   -87.694209        42.333117            0.394919\n",
      "     14                0.79993858         0.010123  0.030764         1.249327       0.007680  0.014036                  0.311900          0.300868      0.003075                 0.999385   -96.923552        24.932715            0.265806\n",
      "     15                0.89989252         0.004543  0.006153         1.111244       0.001536  0.007245                  0.277427          0.268255      0.000615                 1.000000   -99.384710        11.124382            0.133415\n",
      "     16                1.00000000         0.001769  0.000000         1.000000       0.000000  0.003052                  0.249655          0.241706      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4129.495605          1.000000   0.228646\n",
      "                      capital_gain         3168.713867          0.767337   0.175448\n",
      "             relationship. Husband         1827.405640          0.442525   0.101181\n",
      "                               age         1456.512573          0.352710   0.080646\n",
      "                      capital_loss         1102.664429          0.267022   0.061053\n",
      "                    hours_per_week         1022.004761          0.247489   0.056587\n",
      "                            fnlwgt          940.586853          0.227773   0.052079\n",
      "        occupation. Prof-specialty          588.458862          0.142501   0.032582\n",
      "              education. Bachelors          532.582275          0.128970   0.029488\n",
      "       occupation. Exec-managerial          497.043732          0.120364   0.027521\n",
      "---\n",
      "      relationship. Other-relative           13.204436          0.003198   0.000731\n",
      "                      workclass.NA           12.670101          0.003068   0.000702\n",
      "          occupation. Craft-repair           11.211122          0.002715   0.000621\n",
      "              workclass. State-gov            9.752470          0.002362   0.000540\n",
      "          race. Asian-Pac-Islander            8.307315          0.002012   0.000460\n",
      "                education. 5th-6th            7.998797          0.001937   0.000443\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001922   0.000439\n",
      "                     occupation.NA            7.890866          0.001911   0.000437\n",
      "           marital_status. Widowed            5.478282          0.001327   0.000303\n",
      "           relationship. Unmarried            0.133739          0.000032   0.000007\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        57568.558594          1.000000   0.125711\n",
      "                               age        55832.800781          0.969849   0.121921\n",
      "                      capital_loss        45122.238281          0.783800   0.098532\n",
      "                            fnlwgt        39766.160156          0.690762   0.086836\n",
      "                    hours_per_week        34985.570313          0.607720   0.076397\n",
      "marital_status. Married-civ-spouse        27970.064453          0.485857   0.061078\n",
      "              education. Bachelors        13561.415039          0.235570   0.029614\n",
      "       occupation. Exec-managerial        12708.334961          0.220751   0.027751\n",
      "        occupation. Prof-specialty        11825.689453          0.205419   0.025823\n",
      "              education. Doctorate         9512.612305          0.165240   0.020772\n",
      "---\n",
      "                      workclass.NA         1517.267090          0.026356   0.003313\n",
      "          occupation. Craft-repair         1380.507446          0.023980   0.003015\n",
      "          race. Amer-Indian-Eskimo         1349.694214          0.023445   0.002947\n",
      "           marital_status. Widowed         1163.378540          0.020209   0.002540\n",
      "                education. 5th-6th         1003.292114          0.017428   0.002191\n",
      "              workclass. Local-gov          938.169678          0.016297   0.002049\n",
      "                         sex. Male          672.399048          0.011680   0.001468\n",
      "          race. Asian-Pac-Islander          619.778381          0.010766   0.001353\n",
      "          marital_status. Divorced          551.664185          0.009583   0.001205\n",
      "           relationship. Unmarried           88.143829          0.001531   0.000192\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          384.000000          1.000000   0.262116\n",
      "                         age          318.000000          0.828125   0.217065\n",
      "              hours_per_week          148.000000          0.385417   0.101024\n",
      "          workclass. Private           49.000000          0.127604   0.033447\n",
      "                capital_gain           49.000000          0.127604   0.033447\n",
      "                capital_loss           48.000000          0.125000   0.032765\n",
      "          education. HS-grad           40.000000          0.104167   0.027304\n",
      "        education. Bachelors           36.000000          0.093750   0.024573\n",
      "  occupation. Prof-specialty           35.000000          0.091146   0.023891\n",
      "     education. Some-college           29.000000          0.075521   0.019795\n",
      "---\n",
      "     workclass. Self-emp-inc            3.000000          0.007813   0.002048\n",
      "       education. Assoc-acdm            3.000000          0.007813   0.002048\n",
      "     marital_status. Widowed            2.000000          0.005208   0.001365\n",
      "relationship. Other-relative            2.000000          0.005208   0.001365\n",
      "               occupation.NA            2.000000          0.005208   0.001365\n",
      "    race. Asian-Pac-Islander            2.000000          0.005208   0.001365\n",
      "      native_country. Mexico            2.000000          0.005208   0.001365\n",
      "     relationship. Unmarried            1.000000          0.002604   0.000683\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002604   0.000683\n",
      "          education. 5th-6th            1.000000          0.002604   0.000683\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      " 2023-10-20 18:27:02  3.900 sec              20       0.28552          0.26048      0.93937         0.85104       4.19115                       0.12312         0.30193            0.28685        0.92659           0.83134         4.00554                         0.14156\n",
      "\n",
      "10-20 18:27:02.972 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_40\n",
      "10-20 18:27:02.978 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_40\n",
      "10-20 18:27:02.983 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:02.983) \n",
      "10-20 18:27:02.986 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.08061745\n",
      " RMSE: 0.28393212\n",
      " AUC: 0.94145024\n",
      " pr_auc: 0.85819954\n",
      " logloss: 0.2583013\n",
      " mean_per_class_error: 0.14804733\n",
      " default threshold: 0.37070444226264954\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17800  1938  0.0982  1,938 / 19,738\n",
      "     1   1249  5062  0.1979   1,249 / 6,311\n",
      "Totals  19049  7000  0.1223  3,187 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.25 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.990122  4.127555         4.127555       1.000000  0.992352                  1.000000          0.992352      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.986911  4.127555         4.127555       1.000000  0.988593                  1.000000          0.990476      0.041198                 0.082554  312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.980936  4.127555         4.127555       1.000000  0.984452                  1.000000          0.988466      0.041356                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.971228  4.111680         4.123594       0.996154  0.976547                  0.999040          0.985492      0.041039                 0.164950  311.167985       312.359388            0.164899\n",
      "      5                0.05002111         0.954649  4.064298         4.111716       0.984674  0.963592                  0.996163          0.981105      0.040723                 0.205673  306.429751       311.171640            0.205419\n",
      "      6                0.10000384         0.774981  3.804198         3.958016       0.921659  0.863053                  0.958925          0.922102      0.190144                 0.395817  280.419821       295.801633            0.390396\n",
      "      7                0.15002495         0.636226  3.139223         3.685015       0.760553  0.703317                  0.892784          0.849155      0.157027                 0.552844  213.922261       268.501525            0.531616\n",
      "      8                0.20000768         0.507595  2.422006         3.369384       0.586790  0.572098                  0.816315          0.779917      0.121058                 0.673903  142.200620       236.938420            0.625418\n",
      "      9                0.30001152         0.307851  1.690634         2.809801       0.409597  0.404737                  0.680742          0.654857      0.169070                 0.842973   69.063388       180.980076            0.716567\n",
      "     10                0.40001536         0.163182  0.903150         2.333138       0.218810  0.230649                  0.565259          0.548805      0.090318                 0.933291   -9.684976       133.313813            0.703785\n",
      "     11                0.50001919         0.082087  0.404041         1.947319       0.097889  0.118196                  0.471785          0.462683      0.040406                 0.973697  -59.595910        94.731868            0.625131\n",
      "     12                0.59998464         0.038617  0.174359         1.651920       0.042243  0.057362                  0.400218          0.395151      0.017430                 0.991127  -82.564092        65.191995            0.516205\n",
      "     13                0.69998848         0.020289  0.060210         1.424520       0.014587  0.028477                  0.345124          0.342766      0.006021                 0.997148  -93.978998        42.452035            0.392173\n",
      "     14                0.79999232         0.010520  0.022183         1.249220       0.005374  0.015011                  0.302654          0.301795      0.002218                 0.999366  -97.781736        24.921972            0.263121\n",
      "     15                0.90011133         0.004955  0.004748         1.110798       0.001150  0.007471                  0.269118          0.269058      0.000475                 0.999842  -99.525205        11.079765            0.131618\n",
      "     16                1.00000000         0.001847  0.001586         1.000000       0.000384  0.003164                  0.242274          0.242498      0.000158                 1.000000  -99.841370         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.0902648\n",
      " RMSE: 0.300441\n",
      " AUC: 0.9230517\n",
      " pr_auc: 0.8149224\n",
      " logloss: 0.28486535\n",
      " mean_per_class_error: 0.17105502\n",
      " default threshold: 0.33843040466308594\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4401   581  0.1166  581 / 4,982\n",
      "     1   345  1185  0.2255  345 / 1,530\n",
      "Totals  4746  1766  0.1422  926 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.66 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.989954  4.256209         4.256209       1.000000  0.992001                  1.000000          0.992001      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.986510  4.256209         4.256209       1.000000  0.988391                  1.000000          0.990210      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.980860  4.190729         4.234494       0.984615  0.984294                  0.994898          0.988248      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.969596  4.190729         4.223595       0.984615  0.976147                  0.992337          0.985234      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.949926  4.256209         4.230097       1.000000  0.961139                  0.993865          0.980430      0.042484                 0.211765   325.620915       323.009744            0.211363\n",
      "      6                0.10012285         0.763277  3.629528         3.929813       0.852761  0.859388                  0.923313          0.919909      0.181699                 0.393464   262.952805       292.981274            0.383428\n",
      "      7                0.15003071         0.617466  2.802550         3.554828       0.658462  0.692743                  0.835210          0.844342      0.139869                 0.533333   180.255003       255.482770            0.501017\n",
      "      8                0.20009214         0.484954  2.493669         3.289334       0.585890  0.548048                  0.772832          0.770212      0.124837                 0.658170   149.366855       228.933432            0.598756\n",
      "      9                0.30006143         0.287109  1.477578         2.685725       0.347158  0.381668                  0.631013          0.640763      0.147712                 0.805882    47.757798       168.572461            0.661161\n",
      "     10                0.40003071         0.157390  0.967617         2.256363       0.227343  0.217116                  0.530134          0.534892      0.096732                 0.902614    -3.238256       125.636270            0.656930\n",
      "     11                0.50000000         0.081390  0.601492         1.925490       0.141321  0.115582                  0.452396          0.451056      0.060131                 0.962745   -39.850808        92.549020            0.604857\n",
      "     12                0.59996929         0.040042  0.268056         1.649322       0.062980  0.058160                  0.387510          0.385590      0.026797                 0.989542   -73.194382        64.932190            0.509213\n",
      "     13                0.69993857         0.019737  0.058842         1.422160       0.013825  0.028272                  0.334138          0.334556      0.005882                 0.995425   -94.115840        42.216028            0.386232\n",
      "     14                0.79990786         0.010343  0.045766         1.250144       0.010753  0.014591                  0.293722          0.294568      0.004575                 1.000000   -95.423431        25.014398            0.261542\n",
      "     15                0.89987715         0.004629  0.000000         1.111263       0.000000  0.007207                  0.261092          0.262644      0.000000                 1.000000  -100.000000        11.126280            0.130871\n",
      "     16                1.00000000         0.001772  0.000000         1.000000       0.000000  0.002968                  0.234951          0.236645      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4082.574951          1.000000   0.216468\n",
      "                      capital_gain         3469.753418          0.849893   0.183975\n",
      "                               age         1844.488892          0.451795   0.097799\n",
      "marital_status. Married-civ-spouse         1463.180542          0.358396   0.077581\n",
      "                            fnlwgt         1168.911865          0.286317   0.061979\n",
      "                      capital_loss         1104.536743          0.270549   0.058565\n",
      "                    hours_per_week          972.649475          0.238244   0.051572\n",
      "              education. Bachelors          624.225098          0.152900   0.033098\n",
      "       occupation. Exec-managerial          554.207886          0.135750   0.029385\n",
      "        occupation. Prof-specialty          536.280396          0.131358   0.028435\n",
      "---\n",
      "                       race. Black           12.654299          0.003100   0.000671\n",
      "          race. Asian-Pac-Islander           11.943666          0.002926   0.000633\n",
      "             education. Assoc-acdm           11.900757          0.002915   0.000631\n",
      "                     occupation.NA            9.257658          0.002268   0.000491\n",
      "         marital_status. Separated            9.013293          0.002208   0.000478\n",
      "           relationship. Unmarried            7.551877          0.001850   0.000400\n",
      "                education. 5th-6th            6.929251          0.001697   0.000367\n",
      "           marital_status. Widowed            5.938560          0.001455   0.000315\n",
      "                 native_country.NA            5.196322          0.001273   0.000276\n",
      "          race. Amer-Indian-Eskimo            4.215075          0.001032   0.000223\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        55978.863281          1.000000   0.122104\n",
      "                      capital_gain        54449.710938          0.972683   0.118768\n",
      "                            fnlwgt        47094.171875          0.841285   0.102724\n",
      "                      capital_loss        40250.820313          0.719036   0.087797\n",
      "                    hours_per_week        36617.593750          0.654132   0.079872\n",
      "             relationship. Husband        19112.855469          0.341430   0.041690\n",
      "marital_status. Married-civ-spouse        15828.675781          0.282762   0.034526\n",
      "              education. Bachelors        12769.154297          0.228107   0.027853\n",
      "       occupation. Exec-managerial        11773.800781          0.210326   0.025682\n",
      "        occupation. Prof-specialty        10899.500977          0.194707   0.023774\n",
      "---\n",
      "                     occupation.NA         1488.959595          0.026599   0.003248\n",
      "          race. Amer-Indian-Eskimo         1413.515991          0.025251   0.003083\n",
      "          occupation. Craft-repair         1224.972656          0.021883   0.002672\n",
      "           marital_status. Widowed         1190.760132          0.021272   0.002597\n",
      "       relationship. Not-in-family         1104.076050          0.019723   0.002408\n",
      "                         sex. Male          939.587585          0.016785   0.002049\n",
      "                 native_country.NA          896.452454          0.016014   0.001955\n",
      "           relationship. Unmarried          740.984497          0.013237   0.001616\n",
      "                education. 5th-6th          713.308777          0.012742   0.001556\n",
      "             education. Assoc-acdm          215.412369          0.003848   0.000470\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          443.000000          1.000000   0.289164\n",
      "                        age          345.000000          0.778781   0.225196\n",
      "             hours_per_week          132.000000          0.297968   0.086162\n",
      "               capital_gain           54.000000          0.121896   0.035248\n",
      "               capital_loss           47.000000          0.106095   0.030679\n",
      "       education. Bachelors           47.000000          0.106095   0.030679\n",
      "         education. HS-grad           45.000000          0.101580   0.029373\n",
      " occupation. Prof-specialty           30.000000          0.067720   0.019582\n",
      "         workclass. Private           30.000000          0.067720   0.019582\n",
      "occupation. Exec-managerial           29.000000          0.065463   0.018930\n",
      "---\n",
      "   race. Asian-Pac-Islander            3.000000          0.006772   0.001958\n",
      "    workclass. Self-emp-inc            3.000000          0.006772   0.001958\n",
      "             education. 9th            3.000000          0.006772   0.001958\n",
      "              occupation.NA            2.000000          0.004515   0.001305\n",
      "  marital_status. Separated            2.000000          0.004515   0.001305\n",
      "    marital_status. Widowed            1.000000          0.002257   0.000653\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.002257   0.000653\n",
      "      education. Assoc-acdm            1.000000          0.002257   0.000653\n",
      "          native_country.NA            1.000000          0.002257   0.000653\n",
      "         education. 5th-6th            1.000000          0.002257   0.000653\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      " 2023-10-20 18:27:02  3.824 sec              20       0.28393          0.25830      0.94145         0.85820       4.12756                       0.12235         0.30044            0.28487        0.92305           0.81492         4.25621                         0.14220\n",
      "\n",
      "10-20 18:27:02.999 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:02.999) \n",
      "10-20 18:27:03.003 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_41\n",
      "10-20 18:27:03.010 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_41\n",
      "10-20 18:27:03.018 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.080513105\n",
      " RMSE: 0.2837483\n",
      " AUC: 0.9415644\n",
      " pr_auc: 0.8577589\n",
      " logloss: 0.2571009\n",
      " mean_per_class_error: 0.15427199\n",
      " default threshold: 0.3920079469680786\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18019  1726  0.0874  1,726 / 19,745\n",
      "     1   1394  4910  0.2211   1,394 / 6,304\n",
      "Totals  19413  6636  0.1198  3,120 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.990850  4.132138         4.132138       1.000000  0.992617                  1.000000          0.992617      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.987036  4.132138         4.132138       1.000000  0.988986                  1.000000          0.990805      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.981732  4.132138         4.132138       1.000000  0.984723                  1.000000          0.988775      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.971823  4.116245         4.128173       0.996154  0.977545                  0.999040          0.985973      0.041085                 0.165133   311.624549       312.817274            0.165083\n",
      "      5                0.05002111         0.956401  4.037147         4.109940       0.977011  0.964901                  0.994628          0.981752      0.040451                 0.205584   303.714664       310.993958            0.205229\n",
      "      6                0.10000384         0.789164  3.811596         3.960825       0.922427  0.872168                  0.958541          0.926981      0.190514                 0.396098   281.159610       296.082510            0.390628\n",
      "      7                0.15002495         0.647190  3.101482         3.674304       0.750576  0.718055                  0.889202          0.857321      0.155140                 0.551237   210.148218       267.430417            0.529308\n",
      "      8                0.20000768         0.511070  2.484996         3.377091       0.601382  0.579223                  0.817274          0.787823      0.124207                 0.675444   148.499563       237.709117            0.627229\n",
      "      9                0.30001152         0.311620  1.681408         2.811863       0.406910  0.402560                  0.680486          0.659402      0.168147                 0.843591    68.140753       181.186329            0.717129\n",
      "     10                0.40001536         0.161883  0.913671         2.337315       0.221113  0.231064                  0.565643          0.552318      0.091371                 0.934962    -8.632949       133.731509            0.705739\n",
      "     11                0.50001919         0.078979  0.398145         1.949481       0.096353  0.116143                  0.471785          0.465083      0.039816                 0.974778   -60.185539        94.948100            0.626335\n",
      "     12                0.59998464         0.036051  0.172966         1.653490       0.041859  0.054487                  0.400154          0.396672      0.017291                 0.992069   -82.703415        65.348986            0.517265\n",
      "     13                0.69998848         0.017882  0.052346         1.424742       0.012668  0.025433                  0.344795          0.343635      0.005235                 0.997303   -94.765429        42.474244            0.392239\n",
      "     14                0.79999232         0.009542  0.022207         1.249417       0.005374  0.013349                  0.302366          0.302347      0.002221                 0.999524   -97.779273        24.941713            0.263236\n",
      "     15                0.89999616         0.004304  0.004759         1.111116       0.001152  0.006761                  0.268896          0.269503      0.000476                 1.000000   -99.524130        11.111585            0.131932\n",
      "     16                1.00000000         0.001741  0.000000         1.000000       0.000000  0.002973                  0.242005          0.242849      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09383087\n",
      " RMSE: 0.30631825\n",
      " AUC: 0.91635406\n",
      " pr_auc: 0.8045057\n",
      " logloss: 0.29578176\n",
      " mean_per_class_error: 0.19249062\n",
      " default threshold: 0.42773550748825073\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4526   449  0.0903  449 / 4,975\n",
      "     1   453  1084  0.2947  453 / 1,537\n",
      "Totals  4979  1533  0.1385  902 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.990317  4.236825         4.236825       1.000000  0.992304                  1.000000          0.992304      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.986601  4.236825         4.236825       1.000000  0.988361                  1.000000          0.990347      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.979501  4.236825         4.236825       1.000000  0.983428                  1.000000          0.988053      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.968408  4.171643         4.220592       0.984615  0.974905                  0.996169          0.984778      0.041640                 0.169161  317.164306       322.059194            0.168960\n",
      "      5                0.05006143         0.946444  4.171643         4.210832       0.984615  0.958723                  0.993865          0.979583      0.041640                 0.210800  317.164306       321.083219            0.210398\n",
      "      6                0.10012285         0.778463  3.548016         3.879424       0.837423  0.857644                  0.915644          0.918614      0.177619                 0.388419  254.801601       287.942410            0.377364\n",
      "      7                0.15003071         0.630325  2.750677         3.503945       0.649231  0.704531                  0.827021          0.847399      0.137280                 0.525699  175.067714       250.394533            0.491730\n",
      "      8                0.20009214         0.499796  2.274369         3.196315       0.536810  0.565205                  0.754413          0.776796      0.113858                 0.639558  127.436924       219.631539            0.575236\n",
      "      9                0.30006143         0.321334  1.509898         2.634464       0.356375  0.403435                  0.621801          0.652406      0.150943                 0.790501   50.989769       163.446385            0.641958\n",
      "     10                0.40003071         0.169592  1.106391         2.252592       0.261137  0.242142                  0.531670          0.549880      0.110605                 0.901106   10.639055       125.259217            0.655880\n",
      "     11                0.50000000         0.080492  0.553195         1.912817       0.130568  0.120410                  0.451474          0.464012      0.055303                 0.956409  -44.680473        91.281718            0.597414\n",
      "     12                0.59996929         0.034754  0.247311         1.635304       0.058372  0.053441                  0.385974          0.395601      0.024723                 0.981132  -75.268917        63.530383            0.498921\n",
      "     13                0.69993857         0.018340  0.097623         1.415683       0.023041  0.025164                  0.334138          0.342693      0.009759                 0.990891  -90.237730        41.568329            0.380841\n",
      "     14                0.79990786         0.009878  0.071590         1.247704       0.016897  0.013761                  0.294490          0.301585      0.007157                 0.998048  -92.841002        24.770388            0.259355\n",
      "     15                0.89987715         0.004487  0.013016         1.110540       0.003072  0.007070                  0.262116          0.268866      0.001301                 0.999349  -98.698364        11.053979            0.130204\n",
      "     16                1.00000000         0.001741  0.006498         1.000000       0.001534  0.003004                  0.236026          0.242247      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4137.533691          1.000000   0.220745\n",
      "                      capital_gain         3400.636963          0.821900   0.181430\n",
      "                               age         1789.039673          0.432393   0.095449\n",
      "marital_status. Married-civ-spouse         1439.568359          0.347929   0.076804\n",
      "                      capital_loss         1159.369019          0.280208   0.061854\n",
      "                            fnlwgt         1041.370483          0.251689   0.055559\n",
      "                    hours_per_week          979.241211          0.236673   0.052244\n",
      "              education. Bachelors          684.465637          0.165428   0.036517\n",
      "       occupation. Exec-managerial          494.884277          0.119609   0.026403\n",
      "        occupation. Prof-specialty          489.199860          0.118235   0.026100\n",
      "---\n",
      "          occupation. Craft-repair           13.443639          0.003249   0.000717\n",
      "                     occupation.NA           12.889235          0.003115   0.000688\n",
      "           relationship. Unmarried           12.597252          0.003045   0.000672\n",
      "                       race. Black           11.069815          0.002675   0.000591\n",
      "                      workclass.NA            7.304838          0.001766   0.000390\n",
      "          race. Asian-Pac-Islander            5.978405          0.001445   0.000319\n",
      "          race. Amer-Indian-Eskimo            5.838183          0.001411   0.000311\n",
      "                education. 5th-6th            5.686970          0.001374   0.000303\n",
      "              workclass. State-gov            4.530758          0.001095   0.000242\n",
      "      relationship. Other-relative            4.376630          0.001058   0.000234\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        63338.132813          1.000000   0.137235\n",
      "                      capital_gain        58541.230469          0.924265   0.126842\n",
      "                      capital_loss        42035.507813          0.663668   0.091079\n",
      "                            fnlwgt        38817.773438          0.612866   0.084107\n",
      "                    hours_per_week        31288.449219          0.493991   0.067793\n",
      "marital_status. Married-civ-spouse        18472.722656          0.291652   0.040025\n",
      "             relationship. Husband        18100.894531          0.285782   0.039219\n",
      "              education. Bachelors        13770.737305          0.217416   0.029837\n",
      "        occupation. Prof-specialty        11567.674805          0.182634   0.025064\n",
      "                education. Masters        10644.732422          0.168062   0.023064\n",
      "---\n",
      "          marital_status. Divorced         1181.321045          0.018651   0.002560\n",
      "              education. Assoc-voc         1162.115479          0.018348   0.002518\n",
      "                     occupation.NA         1116.120239          0.017622   0.002418\n",
      "                       race. Black          999.186768          0.015775   0.002165\n",
      "          race. Asian-Pac-Islander          842.630920          0.013304   0.001826\n",
      "              workclass. Local-gov          663.624329          0.010477   0.001438\n",
      "       relationship. Not-in-family          648.307922          0.010236   0.001405\n",
      "          occupation. Craft-repair          506.630646          0.007999   0.001098\n",
      "              workclass. State-gov          433.376862          0.006842   0.000939\n",
      "           relationship. Unmarried          308.500305          0.004871   0.000668\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          455.000000          1.000000   0.302125\n",
      "                         age          330.000000          0.725275   0.219124\n",
      "              hours_per_week          141.000000          0.309890   0.093625\n",
      "                capital_gain           57.000000          0.125275   0.037849\n",
      "                capital_loss           50.000000          0.109890   0.033201\n",
      "        education. Bachelors           40.000000          0.087912   0.026560\n",
      "  occupation. Prof-specialty           34.000000          0.074725   0.022576\n",
      " occupation. Exec-managerial           33.000000          0.072527   0.021912\n",
      "          workclass. Private           33.000000          0.072527   0.021912\n",
      "          education. HS-grad           27.000000          0.059341   0.017928\n",
      "---\n",
      "       education. Assoc-acdm            3.000000          0.006593   0.001992\n",
      "occupation. Transport-moving            3.000000          0.006593   0.001992\n",
      "               occupation.NA            2.000000          0.004396   0.001328\n",
      "                workclass.NA            2.000000          0.004396   0.001328\n",
      "    race. Asian-Pac-Islander            2.000000          0.004396   0.001328\n",
      "              education. 9th            2.000000          0.004396   0.001328\n",
      "relationship. Other-relative            1.000000          0.002198   0.000664\n",
      "        workclass. State-gov            1.000000          0.002198   0.000664\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002198   0.000664\n",
      "          education. 5th-6th            1.000000          0.002198   0.000664\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      " 2023-10-20 18:27:02  3.948 sec              20       0.28375          0.25710      0.94156         0.85776       4.13214                       0.11977         0.30632            0.29578        0.91635           0.80451         4.23682                         0.13851\n",
      "\n",
      "10-20 18:27:03.034 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:03.033) \n",
      "10-20 18:27:03.035 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:03.035) \n",
      "10-20 18:27:03.072 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:03.072) \n",
      "10-20 18:27:03.074 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:03.074) \n",
      "10-20 18:27:03.076 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:03.076) \n",
      "10-20 18:27:03.130 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.094 (Wall: 20-Oct 18:27:03.130) \n",
      "10-20 18:27:03.146 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:03.146) \n",
      "10-20 18:27:03.156 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:03.156) \n",
      "10-20 18:27:03.183 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:03.183) \n",
      "10-20 18:27:03.186 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_42\n",
      "10-20 18:27:03.192 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:03.192) \n",
      "10-20 18:27:03.201 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_42\n",
      "10-20 18:27:03.230 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:03.230) \n",
      "10-20 18:27:03.232 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:03.232) \n",
      "10-20 18:27:03.291 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.098 (Wall: 20-Oct 18:27:03.290) \n",
      "10-20 18:27:03.310 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:03.310) \n",
      "10-20 18:27:03.334 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:03.334) \n",
      "10-20 18:27:03.394 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.084 (Wall: 20-Oct 18:27:03.394) \n",
      "10-20 18:27:03.455 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_43\n",
      "10-20 18:27:03.467 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_43\n",
      "10-20 18:27:03.471 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_44\n",
      "10-20 18:27:03.482 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_44\n",
      "10-20 18:27:03.530 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_45\n",
      "10-20 18:27:03.532 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_46\n",
      "10-20 18:27:03.551 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_45\n",
      "10-20 18:27:03.554 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_46\n",
      "10-20 18:27:03.563 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.07865123\n",
      " RMSE: 0.28044826\n",
      " AUC: 0.9437626\n",
      " pr_auc: 0.8632953\n",
      " logloss: 0.25175306\n",
      " mean_per_class_error: 0.14590867\n",
      " default threshold: 0.3641279339790344\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17924  1844  0.0933  1,844 / 19,768\n",
      "     1   1247  5034  0.1985   1,247 / 6,281\n",
      "Totals  19171  6878  0.1187  3,091 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.993562  4.147270         4.147270       1.000000  0.994736                  1.000000          0.994736      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.990794  4.147270         4.147270       1.000000  0.992398                  1.000000          0.993569      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.986299  4.147270         4.147270       1.000000  0.988605                  1.000000          0.991912      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.979343  4.147270         4.147270       1.000000  0.983252                  1.000000          0.989751      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.965629  4.051930         4.128172       0.977011  0.973296                  0.995395          0.986455      0.040599                 0.206496   305.193001       312.817237            0.206192\n",
      "      6                0.10000384         0.799998  3.831924         3.980105       0.923963  0.881098                  0.959693          0.933797      0.191530                 0.398026   283.192416       298.010513            0.392714\n",
      "      7                0.15002495         0.649051  3.233788         3.731269       0.779739  0.723896                  0.899693          0.863812      0.161758                 0.559783   223.378807       273.126912            0.539953\n",
      "      8                0.20000768         0.511165  2.459057         3.413338       0.592934  0.577970                  0.823033          0.792379      0.122910                 0.682694   145.905690       241.333816            0.636053\n",
      "      9                0.30001152         0.298061  1.670052         2.832243       0.402687  0.395798                  0.682917          0.660185      0.167012                 0.849705    67.005211       183.224281            0.724351\n",
      "     10                0.40001536         0.160481  0.885175         2.345476       0.213436  0.225141                  0.565547          0.551424      0.088521                 0.938226   -11.482462       134.547595            0.709220\n",
      "     11                0.50001919         0.078917  0.372538         1.950888       0.089827  0.116612                  0.470403          0.464462      0.037255                 0.975482   -62.746216        95.088833            0.626534\n",
      "     12                0.59998464         0.035150  0.157673         1.652115       0.038018  0.054009                  0.398362          0.396075      0.015762                 0.991243   -84.232731        65.211467            0.515576\n",
      "     13                0.69998848         0.016229  0.066866         1.425638       0.016123  0.024358                  0.343753          0.342970      0.006687                 0.997930   -93.313423        42.563812            0.392609\n",
      "     14                0.79999232         0.007656  0.015920         1.249415       0.003839  0.011352                  0.301262          0.301515      0.001592                 0.999522   -98.407958        24.941495            0.262928\n",
      "     15                0.89999616         0.003171  0.004776         1.111116       0.001152  0.005191                  0.267915          0.268589      0.000478                 1.000000   -99.522387        11.111585            0.131779\n",
      "     16                1.00000000         0.000942  0.000000         1.000000       0.000000  0.001942                  0.241122          0.241923      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09243214\n",
      " RMSE: 0.30402654\n",
      " AUC: 0.9226507\n",
      " pr_auc: 0.8120562\n",
      " logloss: 0.29026288\n",
      " mean_per_class_error: 0.16294271\n",
      " default threshold: 0.3054356575012207\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4281   671  0.1355  671 / 4,952\n",
      "     1   297  1263  0.1904  297 / 1,560\n",
      "Totals  4578  1934  0.1486  968 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.38 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.993720  4.174359         4.174359       1.000000  0.994873                  1.000000          0.994873      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.991055  4.174359         4.174359       1.000000  0.992399                  1.000000          0.993646      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.984823  4.174359         4.174359       1.000000  0.988471                  1.000000          0.991930      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.979352  4.110138         4.158365       0.984615  0.982439                  0.996169          0.989566      0.041026                 0.166667  311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.969683  4.110138         4.148749       0.984615  0.975221                  0.993865          0.986706      0.041026                 0.207692  311.013807       314.874941            0.207288\n",
      "      6                0.10012285         0.800761  3.418877         3.783813       0.819018  0.889834                  0.906442          0.938270      0.171154                 0.378846  241.887683       278.381312            0.366528\n",
      "      7                0.15003071         0.662650  2.761499         3.443739       0.661538  0.732094                  0.824974          0.869685      0.137821                 0.516667  176.149901       244.373934            0.482135\n",
      "      8                0.20009214         0.528254  2.471323         3.200449       0.592025  0.593137                  0.766692          0.800495      0.123718                 0.640385  147.132295       220.044867            0.578995\n",
      "      9                0.30006143         0.300638  1.737713         2.713120       0.416283  0.401904                  0.649949          0.667699      0.173718                 0.814103   73.771318       171.311970            0.675977\n",
      "     10                0.40003071         0.163404  0.974658         2.278671       0.233487  0.224114                  0.545873          0.556846      0.097436                 0.911538   -2.534168       127.867119            0.672645\n",
      "     11                0.50000000         0.073888  0.468092         1.916667       0.112135  0.115639                  0.459152          0.468631      0.046795                 0.958333  -53.190752        91.666667            0.602719\n",
      "     12                0.59996929         0.034815  0.275726         1.643247       0.066052  0.051393                  0.393652          0.399109      0.027564                 0.985897  -72.427429        64.324651            0.507505\n",
      "     13                0.69993857         0.016296  0.096183         1.422286       0.023041  0.024448                  0.340720          0.345598      0.009615                 0.995513  -90.381661        42.228598            0.388687\n",
      "     14                0.79990786         0.007569  0.025649         1.247740       0.006144  0.011234                  0.298906          0.303811      0.002564                 0.998077  -97.435110        24.773986            0.260597\n",
      "     15                0.89987715         0.003338  0.012824         1.110550       0.003072  0.005285                  0.266041          0.270647      0.001282                 0.999359  -98.717555        11.055045            0.130821\n",
      "     16                1.00000000         0.000980  0.006402         1.000000       0.001534  0.002031                  0.239558          0.243752      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3786.539307          1.000000   0.194595\n",
      "                      capital_gain         3501.572998          0.924742   0.179950\n",
      "                               age         1931.428589          0.510078   0.099259\n",
      "marital_status. Married-civ-spouse         1526.093750          0.403031   0.078428\n",
      "                            fnlwgt         1256.561768          0.331850   0.064576\n",
      "                      capital_loss         1187.990723          0.313740   0.061052\n",
      "                    hours_per_week         1052.637451          0.277995   0.054096\n",
      "              education. Bachelors          722.202026          0.190729   0.037115\n",
      "        occupation. Prof-specialty          559.895142          0.147865   0.028774\n",
      "       occupation. Exec-managerial          548.447021          0.144841   0.028185\n",
      "---\n",
      "           marital_status. Widowed           11.497744          0.003036   0.000591\n",
      "          race. Asian-Pac-Islander           11.281467          0.002979   0.000580\n",
      "              workclass. State-gov            7.753006          0.002048   0.000398\n",
      "          race. Amer-Indian-Eskimo            6.894102          0.001821   0.000354\n",
      "      relationship. Other-relative            5.539434          0.001463   0.000285\n",
      "                 native_country.NA            4.971983          0.001313   0.000256\n",
      "                education. 5th-6th            4.151810          0.001096   0.000213\n",
      "           relationship. Unmarried            3.443455          0.000909   0.000177\n",
      "                   education. 12th            3.389948          0.000895   0.000174\n",
      "         marital_status. Separated            2.968688          0.000784   0.000153\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        77000.882813          1.000000   0.140139\n",
      "                      capital_gain        63770.105469          0.828174   0.116059\n",
      "                      capital_loss        53925.835938          0.700328   0.098143\n",
      "                            fnlwgt        43925.019531          0.570448   0.079942\n",
      "                    hours_per_week        41004.964844          0.532526   0.074627\n",
      "marital_status. Married-civ-spouse        18989.066406          0.246608   0.034559\n",
      "             relationship. Husband        18625.925781          0.241892   0.033898\n",
      "              education. Bachelors        16515.765625          0.214488   0.030058\n",
      "       occupation. Exec-managerial        12014.356445          0.156029   0.021866\n",
      "        occupation. Prof-specialty        11961.958008          0.155348   0.021770\n",
      "---\n",
      "          race. Amer-Indian-Eskimo         1368.539429          0.017773   0.002491\n",
      "         marital_status. Separated         1334.329346          0.017329   0.002428\n",
      "                   education. 12th         1323.394897          0.017187   0.002409\n",
      "      relationship. Other-relative         1299.182373          0.016872   0.002364\n",
      "          occupation. Adm-clerical         1285.440063          0.016694   0.002339\n",
      "              education. Assoc-voc         1172.189819          0.015223   0.002133\n",
      "           relationship. Unmarried         1144.842773          0.014868   0.002084\n",
      "          marital_status. Divorced         1027.833252          0.013348   0.001871\n",
      "      occupation. Transport-moving          682.137085          0.008859   0.001241\n",
      "             education. Assoc-acdm          597.902588          0.007765   0.001088\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          483.000000          1.000000   0.265969\n",
      "                         age          413.000000          0.855072   0.227423\n",
      "              hours_per_week          184.000000          0.380952   0.101322\n",
      "                capital_gain           65.000000          0.134576   0.035793\n",
      "                capital_loss           53.000000          0.109731   0.029185\n",
      "          education. HS-grad           45.000000          0.093168   0.024780\n",
      "          workclass. Private           45.000000          0.093168   0.024780\n",
      "  occupation. Prof-specialty           43.000000          0.089027   0.023678\n",
      "        education. Bachelors           43.000000          0.089027   0.023678\n",
      " occupation. Exec-managerial           37.000000          0.076605   0.020374\n",
      "---\n",
      "    race. Asian-Pac-Islander            3.000000          0.006211   0.001652\n",
      "     relationship. Unmarried            2.000000          0.004141   0.001101\n",
      "        workclass. State-gov            2.000000          0.004141   0.001101\n",
      "       education. Assoc-acdm            2.000000          0.004141   0.001101\n",
      "           native_country.NA            2.000000          0.004141   0.001101\n",
      "relationship. Other-relative            1.000000          0.002070   0.000551\n",
      "             education. 12th            1.000000          0.002070   0.000551\n",
      "   marital_status. Separated            1.000000          0.002070   0.000551\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002070   0.000551\n",
      "          education. 5th-6th            1.000000          0.002070   0.000551\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      " 2023-10-20 18:27:02  3.656 sec              20       0.28386          0.25761      0.94111         0.85729       4.14727                       0.12112         0.30376            0.28966        0.92292           0.81184         4.17436                         0.14251\n",
      " 2023-10-20 18:27:03  4.306 sec              25       0.28045          0.25175      0.94376         0.86330       4.14727                       0.11866         0.30403            0.29026        0.92265           0.81206         4.17436                         0.14865\n",
      "\n",
      "10-20 18:27:03.574 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:03.619 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:03.619) \n",
      "10-20 18:27:03.654 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_47\n",
      "10-20 18:27:03.662 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:03.661) \n",
      "10-20 18:27:03.669 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_47\n",
      "10-20 18:27:03.676 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.07965916\n",
      " RMSE: 0.28223953\n",
      " AUC: 0.94224095\n",
      " pr_auc: 0.8571154\n",
      " logloss: 0.25428173\n",
      " mean_per_class_error: 0.15555607\n",
      " default threshold: 0.3924768567085266\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18175  1658  0.0836  1,658 / 19,833\n",
      "     1   1414  4801  0.2275   1,414 / 6,215\n",
      "Totals  19589  6459  0.1179  3,072 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.82 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.994221  4.191150         4.191150       1.000000  0.996055                  1.000000          0.996055      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.989466  4.191150         4.191150       1.000000  0.991927                  1.000000          0.993995      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.983166  4.191150         4.191150       1.000000  0.986504                  1.000000          0.991495      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.974531  4.175031         4.187128       0.996154  0.979046                  0.999040          0.988388      0.041673                 0.167498   317.503063       318.712823            0.167448\n",
      "      5                0.05002303         0.955887  4.078744         4.165418       0.973180  0.965976                  0.993860          0.983899      0.040869                 0.208367   307.874411       316.541813            0.207963\n",
      "      6                0.10000768         0.783974  3.837059         4.001302       0.915515  0.868022                  0.954702          0.925983      0.191794                 0.400161   283.705939       300.130179            0.394211\n",
      "      7                0.15003071         0.625318  3.184374         3.728923       0.759785  0.702651                  0.889713          0.851520      0.159292                 0.559453   218.437371       272.892275            0.537721\n",
      "      8                0.20001536         0.498333  2.452885         3.410036       0.585253  0.560255                  0.813628          0.778731      0.122607                 0.682060   145.288528       241.003584            0.633101\n",
      "      9                0.30002303         0.298670  1.631411         2.817161       0.389251  0.389976                  0.672169          0.649146      0.163154                 0.845213    63.141134       181.716101            0.716035\n",
      "     10                0.39999232         0.159336  0.928684         2.345178       0.221582  0.224569                  0.559555          0.543033      0.092840                 0.938053    -7.131574       134.517776            0.706671\n",
      "     11                0.50000000         0.075688  0.379697         1.952051       0.090595  0.113842                  0.465756          0.457188      0.037973                 0.976026   -62.030269        95.205149            0.625196\n",
      "     12                0.60000768         0.034446  0.157671         1.652969       0.037620  0.052540                  0.394395          0.389742      0.015768                 0.991794   -84.232908        65.296892            0.514559\n",
      "     13                0.69997697         0.016351  0.065990         1.426320       0.015745  0.024146                  0.340317          0.337529      0.006597                 0.998391   -93.401030        42.631978            0.391927\n",
      "     14                0.79998464         0.007950  0.011262         1.249421       0.002687  0.011730                  0.298109          0.296800      0.001126                 0.999517   -98.873779        24.942060            0.262060\n",
      "     15                0.89999232         0.003507  0.004827         1.111121       0.001152  0.005481                  0.265111          0.264428      0.000483                 1.000000   -99.517334        11.112059            0.131347\n",
      "     16                1.00000000         0.000894  0.000000         1.000000       0.000000  0.002267                  0.238598          0.238210      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09163824\n",
      " RMSE: 0.30271807\n",
      " AUC: 0.9259282\n",
      " pr_auc: 0.8300195\n",
      " logloss: 0.2878203\n",
      " mean_per_class_error: 0.1720071\n",
      " default threshold: 0.3659703731536865\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4399   488  0.0999  488 / 4,887\n",
      "     1   397  1229  0.2442  397 / 1,626\n",
      "Totals  4796  1717  0.1359  885 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.97 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.993573  4.005535         4.005535       1.000000  0.995674                  1.000000          0.995674      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.989395  4.005535         4.005535       1.000000  0.991484                  1.000000          0.993595      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.983317  4.005535         4.005535       1.000000  0.986620                  1.000000          0.991282      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.974910  4.005535         4.005535       1.000000  0.979229                  1.000000          0.988280      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.956801  4.005535         4.005535       1.000000  0.966580                  1.000000          0.983953      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.788517  3.501771         3.753653       0.874233  0.878587                  0.937117          0.931270      0.175277                 0.375769   250.177144       275.365325            0.367379\n",
      "      7                0.15000768         0.638783  2.920959         3.476657       0.729231  0.712533                  0.867963          0.858507      0.145756                 0.521525   192.095941       247.665683            0.495129\n",
      "      8                0.20006142         0.498193  2.236219         3.166309       0.558282  0.564939                  0.790483          0.785059      0.111931                 0.633456   123.621896       216.630937            0.577594\n",
      "      9                0.30001535         0.301816  1.722811         2.685389       0.430108  0.393742                  0.670420          0.654687      0.172202                 0.805658    72.281078       168.538942            0.673880\n",
      "     10                0.39996929         0.155978  0.984463         2.260321       0.245776  0.221484                  0.564299          0.546428      0.098401                 0.904059    -1.553670       126.032113            0.671810\n",
      "     11                0.50007677         0.077255  0.577485         1.923444       0.144172  0.113665                  0.480196          0.459795      0.057811                 0.961870   -42.251488        92.344391            0.615440\n",
      "     12                0.60003071         0.035325  0.215351         1.638908       0.053763  0.053740                  0.409161          0.392154      0.021525                 0.983395   -78.464865        63.890751            0.510917\n",
      "     13                0.69998465         0.016901  0.129211         1.423331       0.032258  0.024604                  0.355341          0.339670      0.012915                 0.996310   -87.078919        42.333117            0.394919\n",
      "     14                0.79993858         0.008225  0.036917         1.250096       0.009217  0.011671                  0.312092          0.298686      0.003690                 1.000000   -96.308263        25.009597            0.266626\n",
      "     15                0.89989252         0.003607  0.000000         1.111244       0.000000  0.005627                  0.277427          0.266135      0.000000                 1.000000  -100.000000        11.124382            0.133415\n",
      "     16                1.00000000         0.000795  0.000000         1.000000       0.000000  0.002312                  0.249655          0.239724      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4133.813965          1.000000   0.220062\n",
      "                      capital_gain         3226.365723          0.780482   0.171754\n",
      "             relationship. Husband         1833.427979          0.443520   0.097602\n",
      "                               age         1523.183228          0.368469   0.081086\n",
      "                            fnlwgt         1140.557739          0.275909   0.060717\n",
      "                    hours_per_week         1132.733032          0.274016   0.060301\n",
      "                      capital_loss         1119.890869          0.270910   0.059617\n",
      "        occupation. Prof-specialty          615.637207          0.148927   0.032773\n",
      "              education. Bachelors          542.790771          0.131305   0.028895\n",
      "       occupation. Exec-managerial          505.773102          0.122350   0.026925\n",
      "---\n",
      "                      workclass.NA           12.670101          0.003065   0.000674\n",
      "           relationship. Unmarried           11.588886          0.002803   0.000617\n",
      "                     occupation.NA            9.435364          0.002282   0.000502\n",
      "          race. Asian-Pac-Islander            8.307315          0.002010   0.000442\n",
      "                education. 5th-6th            7.998797          0.001935   0.000426\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001920   0.000422\n",
      "                       race. Black            7.900686          0.001911   0.000421\n",
      "           marital_status. Widowed            5.478282          0.001325   0.000292\n",
      "                   education. 12th            3.699208          0.000895   0.000197\n",
      "                 native_country.NA            0.795650          0.000192   0.000042\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        69739.976563          1.000000   0.127719\n",
      "                               age        58528.625000          0.839241   0.107187\n",
      "                            fnlwgt        56150.882813          0.805146   0.102832\n",
      "                      capital_loss        48070.464844          0.689281   0.088034\n",
      "                    hours_per_week        46937.746094          0.673039   0.085960\n",
      "marital_status. Married-civ-spouse        28144.316406          0.403561   0.051542\n",
      "              education. Bachelors        15652.192383          0.224436   0.028665\n",
      "       occupation. Exec-managerial        13579.368164          0.194714   0.024869\n",
      "        occupation. Prof-specialty        13158.982422          0.188686   0.024099\n",
      "              education. Doctorate        10195.897461          0.146199   0.018672\n",
      "---\n",
      "          occupation. Adm-clerical         1727.835693          0.024775   0.003164\n",
      "                      workclass.NA         1517.267090          0.021756   0.002779\n",
      "                   education. 12th         1397.228027          0.020035   0.002559\n",
      "          race. Amer-Indian-Eskimo         1349.694214          0.019353   0.002472\n",
      "           marital_status. Widowed         1163.378540          0.016682   0.002131\n",
      "                education. 5th-6th         1003.292114          0.014386   0.001837\n",
      "                         sex. Male          729.991150          0.010467   0.001337\n",
      "          marital_status. Divorced          682.700195          0.009789   0.001250\n",
      "          race. Asian-Pac-Islander          619.778381          0.008887   0.001135\n",
      "                 native_country.NA           86.905121          0.001246   0.000159\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          448.000000          1.000000   0.257619\n",
      "                         age          342.000000          0.763393   0.196665\n",
      "              hours_per_week          199.000000          0.444196   0.114434\n",
      "                capital_gain           60.000000          0.133929   0.034503\n",
      "          workclass. Private           54.000000          0.120536   0.031052\n",
      "                capital_loss           52.000000          0.116071   0.029902\n",
      "          education. HS-grad           51.000000          0.113839   0.029327\n",
      "  occupation. Prof-specialty           45.000000          0.100446   0.025877\n",
      "        education. Bachelors           45.000000          0.100446   0.025877\n",
      "     education. Some-college           32.000000          0.071429   0.018401\n",
      "---\n",
      "                workclass.NA            3.000000          0.006696   0.001725\n",
      "                 race. Black            3.000000          0.006696   0.001725\n",
      "     marital_status. Widowed            2.000000          0.004464   0.001150\n",
      "relationship. Other-relative            2.000000          0.004464   0.001150\n",
      "    race. Asian-Pac-Islander            2.000000          0.004464   0.001150\n",
      "      native_country. Mexico            2.000000          0.004464   0.001150\n",
      "             education. 12th            1.000000          0.002232   0.000575\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002232   0.000575\n",
      "           native_country.NA            1.000000          0.002232   0.000575\n",
      "          education. 5th-6th            1.000000          0.002232   0.000575\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      " 2023-10-20 18:27:02  3.900 sec              20       0.28552          0.26048      0.93937         0.85104       4.19115                       0.12312         0.30193            0.28685        0.92659           0.83134         4.00554                         0.14156\n",
      " 2023-10-20 18:27:03  4.463 sec              25       0.28224          0.25428      0.94224         0.85712       4.19115                       0.11794         0.30272            0.28782        0.92593           0.83002         4.00554                         0.13588\n",
      "\n",
      "10-20 18:27:03.724 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:03.724) \n",
      "10-20 18:27:03.726 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_48\n",
      "10-20 18:27:03.732 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:03.732) \n",
      "10-20 18:27:03.735 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_48\n",
      "10-20 18:27:03.741 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07861148\n",
      " RMSE: 0.2803774\n",
      " AUC: 0.94407177\n",
      " pr_auc: 0.8642381\n",
      " logloss: 0.2520856\n",
      " mean_per_class_error: 0.14480266\n",
      " default threshold: 0.3795674741268158\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17975  1763  0.0893  1,763 / 19,738\n",
      "     1   1264  5047  0.2003   1,264 / 6,311\n",
      "Totals  19239  6810  0.1162  3,027 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.992310  4.127555         4.127555       1.000000  0.994255                  1.000000          0.994255      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.989025  4.127555         4.127555       1.000000  0.990676                  1.000000          0.992469      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.983485  4.127555         4.127555       1.000000  0.986650                  1.000000          0.990527      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.974125  4.095805         4.119633       0.992308  0.979330                  0.998081          0.987733      0.040881                 0.164792   309.580464       311.963269            0.164690\n",
      "      5                0.05002111         0.955901  4.080112         4.111716       0.988506  0.965825                  0.996163          0.983345      0.040881                 0.205673   308.011190       311.171640            0.205419\n",
      "      6                0.10000384         0.795245  3.829560         3.970692       0.927803  0.878419                  0.961996          0.930902      0.191412                 0.397084   282.955954       297.069213            0.392069\n",
      "      7                0.15002495         0.648093  3.183571         3.708251       0.771297  0.719111                  0.898414          0.860287      0.159246                 0.556330   218.357087       270.825123            0.536217\n",
      "      8                0.20000768         0.512917  2.510771         3.408996       0.608295  0.577990                  0.825912          0.789740      0.125495                 0.681825   151.077082       240.899605            0.635873\n",
      "      9                0.30001152         0.306956  1.666867         2.828286       0.403839  0.404767                  0.685221          0.661416      0.166693                 0.848518    66.686677       182.828629            0.723886\n",
      "     10                0.40001536         0.158119  0.884137         2.342249       0.214203  0.227174                  0.567466          0.552855      0.088417                 0.936936   -11.586345       134.224886            0.708594\n",
      "     11                0.50001919         0.075524  0.380274         1.949854       0.092131  0.112988                  0.472399          0.464882      0.038029                 0.974964   -61.972621        94.985384            0.626803\n",
      "     12                0.59998464         0.034228  0.161678         1.651920       0.039171  0.052212                  0.400218          0.396125      0.016162                 0.991127   -83.832158        65.191995            0.516205\n",
      "     13                0.69998848         0.016393  0.058626         1.424294       0.014203  0.024145                  0.345070          0.342982      0.005863                 0.996989   -94.137446        42.429398            0.391964\n",
      "     14                0.79999232         0.007800  0.028521         1.249814       0.006910  0.011739                  0.302798          0.301575      0.002852                 0.999842   -97.147947        24.981393            0.263749\n",
      "     15                0.89999616         0.002983  0.000000         1.110940       0.000000  0.005077                  0.269152          0.268629      0.000000                 0.999842  -100.000000        11.093979            0.131770\n",
      "     16                1.00000000         0.000801  0.001584         1.000000       0.000384  0.001742                  0.242274          0.241940      0.000158                 1.000000   -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09051948\n",
      " RMSE: 0.30086455\n",
      " AUC: 0.92254347\n",
      " pr_auc: 0.81423247\n",
      " logloss: 0.2854134\n",
      " mean_per_class_error: 0.17644304\n",
      " default threshold: 0.3680705726146698\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4445   537  0.1078  537 / 4,982\n",
      "     1   375  1155  0.2451  375 / 1,530\n",
      "Totals  4820  1692  0.1400  912 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.63 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.992222  4.256209         4.256209       1.000000  0.993951                  1.000000          0.993951      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.988985  4.256209         4.256209       1.000000  0.990540                  1.000000          0.992259      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.983018  4.190729         4.234494       0.984615  0.986439                  0.994898          0.990329      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.973237  4.190729         4.223595       0.984615  0.978517                  0.992337          0.987387      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.950542  4.190729         4.217042       0.984615  0.962179                  0.990798          0.982361      0.041830                 0.211111   319.072901       321.704158            0.210509\n",
      "      6                0.10012285         0.788441  3.655640         3.936341       0.858896  0.872700                  0.924847          0.927530      0.183007                 0.394118   265.563976       293.634067            0.384282\n",
      "      7                0.15003071         0.628354  2.828742         3.567897       0.664615  0.703433                  0.838280          0.852984      0.141176                 0.535294   182.874208       256.789692            0.503580\n",
      "      8                0.20009214         0.490088  2.480613         3.295867       0.582822  0.554785                  0.774367          0.778377      0.124183                 0.659477   148.061269       229.586725            0.600465\n",
      "      9                0.30006143         0.283752  1.503730         2.698794       0.353303  0.385235                  0.634084          0.647397      0.150327                 0.809804    50.372981       169.879383            0.666287\n",
      "     10                0.40003071         0.154405  0.921852         2.254729       0.216590  0.214328                  0.529750          0.539171      0.092157                 0.901961    -7.814825       125.472884            0.656076\n",
      "     11                0.50000000         0.076415  0.608030         1.925490       0.142857  0.111217                  0.452396          0.453607      0.060784                 0.962745   -39.197012        92.549020            0.604857\n",
      "     12                0.59996929         0.035097  0.274594         1.650411       0.064516  0.053362                  0.387766          0.386916      0.027451                 0.990196   -72.540586        65.041128            0.510068\n",
      "     13                0.69993857         0.016329  0.065380         1.424028       0.015361  0.023966                  0.334577          0.335077      0.006536                 0.996732   -93.462044        42.402785            0.387940\n",
      "     14                0.79990786         0.007573  0.013076         1.247693       0.003072  0.011515                  0.293146          0.294640      0.001307                 0.998039   -98.692409        24.769272            0.258979\n",
      "     15                0.89987715         0.002799  0.019614         1.111263       0.004608  0.004866                  0.261092          0.262448      0.001961                 1.000000   -98.038613        11.126280            0.130871\n",
      "     16                1.00000000         0.000813  0.000000         1.000000       0.000000  0.001629                  0.234951          0.236334      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4095.904053          1.000000   0.207975\n",
      "                      capital_gain         3479.706055          0.849558   0.176687\n",
      "                               age         2029.458252          0.495485   0.103048\n",
      "marital_status. Married-civ-spouse         1476.275024          0.360427   0.074960\n",
      "                            fnlwgt         1399.674683          0.341725   0.071070\n",
      "                      capital_loss         1117.473511          0.272827   0.056741\n",
      "                    hours_per_week         1063.226929          0.259583   0.053987\n",
      "              education. Bachelors          639.146912          0.156045   0.032454\n",
      "       occupation. Exec-managerial          565.379089          0.138035   0.028708\n",
      "        occupation. Prof-specialty          546.289612          0.133375   0.027739\n",
      "---\n",
      "           marital_status. Widowed           13.250572          0.003235   0.000673\n",
      "                       race. Black           12.654299          0.003090   0.000643\n",
      "                     occupation.NA            9.257658          0.002260   0.000470\n",
      "         marital_status. Separated            9.013293          0.002201   0.000458\n",
      "                 native_country.NA            8.301558          0.002027   0.000422\n",
      "           relationship. Unmarried            7.551877          0.001844   0.000383\n",
      "              workclass. State-gov            7.262564          0.001773   0.000369\n",
      "                education. 5th-6th            6.929251          0.001692   0.000352\n",
      "          race. Amer-Indian-Eskimo            4.215075          0.001029   0.000214\n",
      "                      workclass.NA            2.509929          0.000613   0.000127\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        68672.664063          1.000000   0.126470\n",
      "                            fnlwgt        63529.652344          0.925108   0.116998\n",
      "                      capital_gain        56941.839844          0.829178   0.104866\n",
      "                    hours_per_week        46607.429688          0.678690   0.085834\n",
      "                      capital_loss        43166.539063          0.628584   0.079497\n",
      "             relationship. Husband        19720.035156          0.287160   0.036317\n",
      "marital_status. Married-civ-spouse        16428.728516          0.239232   0.030256\n",
      "              education. Bachelors        14736.680664          0.214593   0.027140\n",
      "       occupation. Exec-managerial        13556.349609          0.197405   0.024966\n",
      "        occupation. Prof-specialty        11759.541016          0.171240   0.021657\n",
      "---\n",
      "      occupation. Transport-moving         1963.832520          0.028597   0.003617\n",
      "          marital_status. Divorced         1821.994141          0.026532   0.003355\n",
      "                     occupation.NA         1488.959595          0.021682   0.002742\n",
      "          race. Amer-Indian-Eskimo         1413.515991          0.020583   0.002603\n",
      "       relationship. Not-in-family         1381.600586          0.020119   0.002544\n",
      "              workclass. State-gov         1043.810913          0.015200   0.001922\n",
      "           relationship. Unmarried          740.984497          0.010790   0.001365\n",
      "                      workclass.NA          720.082886          0.010486   0.001326\n",
      "                education. 5th-6th          713.308777          0.010387   0.001314\n",
      "             education. Assoc-acdm          488.874268          0.007119   0.000900\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          533.000000          1.000000   0.283662\n",
      "                        age          423.000000          0.793621   0.225120\n",
      "             hours_per_week          175.000000          0.328330   0.093135\n",
      "               capital_gain           57.000000          0.106942   0.030335\n",
      "       education. Bachelors           54.000000          0.101313   0.028739\n",
      "               capital_loss           51.000000          0.095685   0.027142\n",
      "         education. HS-grad           51.000000          0.095685   0.027142\n",
      "         workclass. Private           48.000000          0.090056   0.025546\n",
      "occupation. Exec-managerial           36.000000          0.067542   0.019159\n",
      " occupation. Prof-specialty           34.000000          0.063790   0.018095\n",
      "---\n",
      "    workclass. Self-emp-inc            3.000000          0.005629   0.001597\n",
      "             education. 9th            3.000000          0.005629   0.001597\n",
      "              occupation.NA            2.000000          0.003752   0.001064\n",
      "  marital_status. Separated            2.000000          0.003752   0.001064\n",
      "       workclass. State-gov            2.000000          0.003752   0.001064\n",
      "      education. Assoc-acdm            2.000000          0.003752   0.001064\n",
      "          native_country.NA            2.000000          0.003752   0.001064\n",
      "               workclass.NA            1.000000          0.001876   0.000532\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.001876   0.000532\n",
      "         education. 5th-6th            1.000000          0.001876   0.000532\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      " 2023-10-20 18:27:02  3.824 sec              20       0.28393          0.25830      0.94145         0.85820       4.12756                       0.12235         0.30044            0.28487        0.92305           0.81492         4.25621                         0.14220\n",
      " 2023-10-20 18:27:03  4.564 sec              25       0.28038          0.25209      0.94407         0.86424       4.12756                       0.11620         0.30086            0.28541        0.92254           0.81423         4.25621                         0.14005\n",
      "\n",
      "█10-20 18:27:03.811 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:03.811) \n",
      "10-20 18:27:03.817 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:03.816) \n",
      "10-20 18:27:03.838 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.114 (Wall: 20-Oct 18:27:03.838) \n",
      "10-20 18:27:03.844 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_49\n",
      "10-20 18:27:03.849 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_49\n",
      "10-20 18:27:03.855 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07858243\n",
      " RMSE: 0.2803256\n",
      " AUC: 0.9444111\n",
      " pr_auc: 0.8636286\n",
      " logloss: 0.25097212\n",
      " mean_per_class_error: 0.15157773\n",
      " default threshold: 0.4015137255191803\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18116  1629  0.0825  1,629 / 19,745\n",
      "     1   1391  4913  0.2207   1,391 / 6,304\n",
      "Totals  19507  6542  0.1159  3,020 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.27 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991940  4.132138         4.132138       1.000000  0.993887                  1.000000          0.993887      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.988840  4.132138         4.132138       1.000000  0.990330                  1.000000          0.992112      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.984624  4.132138         4.132138       1.000000  0.986859                  1.000000          0.990358      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.976575  4.116245         4.128173       0.996154  0.981146                  0.999040          0.988060      0.041085                 0.165133   311.624549       312.817274            0.165083\n",
      "      5                0.05002111         0.961787  4.068811         4.116282       0.984674  0.970031                  0.996163          0.984448      0.040768                 0.205901   306.881053       311.628208            0.205648\n",
      "      6                0.10000384         0.802400  3.862375         3.989377       0.934716  0.883102                  0.965451          0.933795      0.193052                 0.398953   286.237507       298.937731            0.394395\n",
      "      7                0.15002495         0.659003  3.120510         3.699681       0.755180  0.731340                  0.895343          0.866292      0.156091                 0.555044   212.050968       269.968065            0.534330\n",
      "      8                0.20000768         0.521306  2.507211         3.401678       0.606759  0.588577                  0.823225          0.796890      0.125317                 0.680362   150.721143       240.167779            0.633717\n",
      "      9                0.30008830         0.306157  1.714988         2.839160       0.415036  0.406172                  0.687092          0.666584      0.171637                 0.851999    71.498798       183.916016            0.728119\n",
      "     10                0.40001536         0.155148  0.868336         2.346832       0.210142  0.225381                  0.567946          0.556368      0.086770                 0.938769   -13.166359       134.683250            0.710762\n",
      "     11                0.50001919         0.073503  0.383869         1.954240       0.092898  0.110756                  0.472937          0.467246      0.038388                 0.977157   -61.613149        95.423970            0.629474\n",
      "     12                0.59998464         0.032541  0.152337         1.654019       0.036866  0.050388                  0.400282          0.397792      0.015228                 0.992386   -84.766310        65.401864            0.517683\n",
      "     13                0.69998848         0.015395  0.052346         1.425196       0.012668  0.022561                  0.344905          0.344184      0.005235                 0.997621   -94.765429        42.519567            0.392657\n",
      "     14                0.79999232         0.007434  0.020621         1.249615       0.004990  0.010989                  0.302414          0.302533      0.002062                 0.999683   -97.937896        24.961542            0.263446\n",
      "     15                0.89999616         0.003049  0.003172         1.111116       0.000768  0.004985                  0.268896          0.269471      0.000317                 1.000000   -99.682753        11.111585            0.131932\n",
      "     16                1.00000000         0.000741  0.000000         1.000000       0.000000  0.001829                  0.242005          0.242705      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09409909\n",
      " RMSE: 0.30675575\n",
      " AUC: 0.9166056\n",
      " pr_auc: 0.8037734\n",
      " logloss: 0.2962931\n",
      " mean_per_class_error: 0.18691015\n",
      " default threshold: 0.40753743052482605\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4465   510  0.1025  510 / 4,975\n",
      "     1   417  1120  0.2713  417 / 1,537\n",
      "Totals  4882  1630  0.1424  927 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.26 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.991652  4.236825         4.236825       1.000000  0.993504                  1.000000          0.993504      0.042941                 0.042941   323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.988109  4.236825         4.236825       1.000000  0.989738                  1.000000          0.991636      0.042290                 0.085231   323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.983264  4.236825         4.236825       1.000000  0.985681                  1.000000          0.989661      0.042290                 0.127521   323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.972817  4.171643         4.220592       0.984615  0.977787                  0.996169          0.986704      0.041640                 0.169161   317.164306       322.059194            0.168960\n",
      "      5                0.05006143         0.951120  4.171643         4.210832       0.984615  0.963890                  0.993865          0.982155      0.041640                 0.210800   317.164306       321.083219            0.210398\n",
      "      6                0.10012285         0.789740  3.574009         3.892420       0.843558  0.871977                  0.918712          0.927066      0.178920                 0.389720   257.400881       289.242050            0.379067\n",
      "      7                0.15003071         0.653137  2.607277         3.464916       0.615385  0.719207                  0.817810          0.857921      0.130124                 0.519844   160.727691       246.491624            0.484065\n",
      "      8                0.20009214         0.506859  2.417330         3.202819       0.570552  0.576778                  0.755948          0.787582      0.121015                 0.640859   141.732959       220.281858            0.576939\n",
      "      9                0.30006143         0.322645  1.542439         2.649642       0.364055  0.408076                  0.625384          0.661144      0.154196                 0.795055    54.243859       164.964183            0.647920\n",
      "     10                0.40003071         0.162528  1.086866         2.259098       0.256528  0.238488                  0.533205          0.555521      0.108653                 0.903709     8.686601       125.909785            0.659286\n",
      "     11                0.50000000         0.074631  0.514146         1.910215       0.121352  0.113708                  0.450860          0.467186      0.051399                 0.955107   -48.585380        91.021470            0.595710\n",
      "     12                0.59996929         0.031121  0.253819         1.634219       0.059908  0.049849                  0.385718          0.397647      0.025374                 0.980481   -74.618099        63.421941            0.498069\n",
      "     13                0.69993857         0.015572  0.084606         1.412895       0.019969  0.022169                  0.333480          0.344019      0.008458                 0.988939   -91.539366        41.289469            0.378286\n",
      "     14                0.79990786         0.007687  0.097623         1.248517       0.023041  0.011322                  0.294682          0.302440      0.009759                 0.998699   -90.237730        24.851725            0.260206\n",
      "     15                0.89987715         0.003135  0.013016         1.111263       0.003072  0.005182                  0.262287          0.269417      0.001301                 1.000000   -98.698364        11.126280            0.131055\n",
      "     16                1.00000000         0.000848  0.000000         1.000000       0.000000  0.001844                  0.236026          0.242627      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4145.192383          1.000000   0.212395\n",
      "                      capital_gain         3440.399658          0.829973   0.176283\n",
      "                               age         1916.372192          0.462312   0.098193\n",
      "marital_status. Married-civ-spouse         1448.021362          0.349325   0.074195\n",
      "                            fnlwgt         1295.464600          0.312522   0.066378\n",
      "                      capital_loss         1176.660156          0.283861   0.060291\n",
      "                    hours_per_week         1074.242554          0.259154   0.055043\n",
      "              education. Bachelors          691.594177          0.166842   0.035437\n",
      "       occupation. Exec-managerial          506.222900          0.122123   0.025938\n",
      "        occupation. Prof-specialty          505.454559          0.121938   0.025899\n",
      "---\n",
      "           relationship. Unmarried           12.597252          0.003039   0.000645\n",
      "                       race. Black           11.069815          0.002671   0.000567\n",
      "          race. Asian-Pac-Islander            9.227043          0.002226   0.000473\n",
      "              workclass. State-gov            8.181561          0.001974   0.000419\n",
      "                      workclass.NA            7.304838          0.001762   0.000374\n",
      "          race. Amer-Indian-Eskimo            5.838183          0.001408   0.000299\n",
      "                education. 5th-6th            5.686970          0.001372   0.000291\n",
      "      relationship. Other-relative            4.376630          0.001056   0.000224\n",
      "                 native_country.NA            2.380165          0.000574   0.000122\n",
      "           marital_status. Widowed            1.797873          0.000434   0.000092\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        71252.210938          1.000000   0.130861\n",
      "                      capital_gain        65956.835938          0.925681   0.121135\n",
      "                            fnlwgt        54648.253906          0.766969   0.100366\n",
      "                      capital_loss        46954.355469          0.658988   0.086236\n",
      "                    hours_per_week        42324.687500          0.594012   0.077733\n",
      "marital_status. Married-civ-spouse        21007.472656          0.294833   0.038582\n",
      "             relationship. Husband        18243.750000          0.256045   0.033506\n",
      "              education. Bachelors        14630.399414          0.205333   0.026870\n",
      "        occupation. Prof-specialty        12481.396484          0.175172   0.022923\n",
      "                education. Masters        12318.084961          0.172880   0.022623\n",
      "---\n",
      "          race. Amer-Indian-Eskimo         1420.591553          0.019938   0.002609\n",
      "      relationship. Other-relative         1396.271484          0.019596   0.002564\n",
      "                education. 5th-6th         1351.620972          0.018970   0.002482\n",
      "          marital_status. Divorced         1181.321045          0.016579   0.002170\n",
      "                 native_country.NA         1153.071655          0.016183   0.002118\n",
      "                       race. Black          999.186768          0.014023   0.001835\n",
      "           marital_status. Widowed          832.821777          0.011688   0.001530\n",
      "          occupation. Craft-repair          703.631042          0.009875   0.001292\n",
      "              workclass. Local-gov          693.369751          0.009731   0.001273\n",
      "           relationship. Unmarried          308.500305          0.004330   0.000567\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          554.000000          1.000000   0.304396\n",
      "                         age          390.000000          0.703971   0.214286\n",
      "              hours_per_week          180.000000          0.324910   0.098901\n",
      "                capital_gain           66.000000          0.119134   0.036264\n",
      "                capital_loss           54.000000          0.097473   0.029670\n",
      "        education. Bachelors           44.000000          0.079422   0.024176\n",
      "  occupation. Prof-specialty           43.000000          0.077617   0.023626\n",
      "          workclass. Private           43.000000          0.077617   0.023626\n",
      " occupation. Exec-managerial           38.000000          0.068592   0.020879\n",
      "          education. HS-grad           34.000000          0.061372   0.018681\n",
      "---\n",
      "               occupation.NA            3.000000          0.005415   0.001648\n",
      "    race. Asian-Pac-Islander            3.000000          0.005415   0.001648\n",
      "                 race. Black            3.000000          0.005415   0.001648\n",
      "                workclass.NA            2.000000          0.003610   0.001099\n",
      "        workclass. State-gov            2.000000          0.003610   0.001099\n",
      "     marital_status. Widowed            1.000000          0.001805   0.000549\n",
      "relationship. Other-relative            1.000000          0.001805   0.000549\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001805   0.000549\n",
      "           native_country.NA            1.000000          0.001805   0.000549\n",
      "          education. 5th-6th            1.000000          0.001805   0.000549\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      " 2023-10-20 18:27:02  3.948 sec              20       0.28375          0.25710      0.94156         0.85776       4.13214                       0.11977         0.30632            0.29578        0.91635           0.80451         4.23682                         0.13851\n",
      " 2023-10-20 18:27:03  4.624 sec              25       0.28033          0.25097      0.94441         0.86363       4.13214                       0.11594         0.30676            0.29629        0.91661           0.80377         4.23682                         0.14235\n",
      "\n",
      "10-20 18:27:03.879 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:03.879) \n",
      "10-20 18:27:03.897 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:03.896) \n",
      "10-20 18:27:03.911 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.094 (Wall: 20-Oct 18:27:03.911) \n",
      "10-20 18:27:03.947 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:03.947) \n",
      "10-20 18:27:03.961 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.121 (Wall: 20-Oct 18:27:03.960) \n",
      "10-20 18:27:04.087 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.139 (Wall: 20-Oct 18:27:04.087) \n",
      "10-20 18:27:04.099 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.202 (Wall: 20-Oct 18:27:04.099) \n",
      "10-20 18:27:04.129 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.217 (Wall: 20-Oct 18:27:04.128) \n",
      "10-20 18:27:04.159 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:04.159) \n",
      "10-20 18:27:04.160 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_50\n",
      "10-20 18:27:04.177 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_50\n",
      "10-20 18:27:04.181 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:04.181) \n",
      "10-20 18:27:04.202 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:04.202) \n",
      "10-20 18:27:04.228 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:04.245 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:04.245) \n",
      "10-20 18:27:04.322 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.119 (Wall: 20-Oct 18:27:04.321) \n",
      "10-20 18:27:04.411 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_51\n",
      "10-20 18:27:04.413 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_52\n",
      "10-20 18:27:04.422 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_51\n",
      "10-20 18:27:04.439 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_52\n",
      "10-20 18:27:04.450 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_54\n",
      "10-20 18:27:04.451 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_53\n",
      "10-20 18:27:04.474 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_54\n",
      "10-20 18:27:04.495 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.0764277\n",
      " RMSE: 0.2764556\n",
      " AUC: 0.9468316\n",
      " pr_auc: 0.8704989\n",
      " logloss: 0.24550477\n",
      " mean_per_class_error: 0.15086648\n",
      " default threshold: 0.41639772057533264\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18348  1420  0.0718  1,420 / 19,768\n",
      "     1   1444  4837  0.2299   1,444 / 6,281\n",
      "Totals  19792  6257  0.1099  2,864 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.994358  4.147270         4.147270       1.000000  0.995701                  1.000000          0.995701      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.991320  4.147270         4.147270       1.000000  0.992889                  1.000000          0.994298      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.986430  4.147270         4.147270       1.000000  0.988942                  1.000000          0.992510      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.977355  4.131319         4.143289       0.996154  0.982323                  0.999040          0.989968      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05002111         0.963011  4.115490         4.137721       0.992337  0.970915                  0.997698          0.986152      0.041235                 0.206973   311.548970       313.772096            0.206822\n",
      "      6                0.10000384         0.811204  3.876518         4.007170       0.934716  0.887790                  0.966219          0.936990      0.193759                 0.400732   287.651846       300.716984            0.396281\n",
      "      7                0.15002495         0.656775  3.284714         3.766290       0.792018  0.732893                  0.908137          0.868940      0.164305                 0.565037   228.471387       276.628956            0.546877\n",
      "      8                0.20000768         0.511631  2.510022         3.452343       0.605223  0.583973                  0.832438          0.797726      0.125458                 0.690495   151.002181       245.234319            0.646333\n",
      "      9                0.30001152         0.294834  1.631843         2.845510       0.393474  0.395595                  0.686116          0.663682      0.163191                 0.853686    63.184310       184.550983            0.729596\n",
      "     10                0.40001536         0.157320  0.891544         2.357018       0.214971  0.221706                  0.568330          0.553188      0.089158                 0.942843   -10.845645       135.701826            0.715304\n",
      "     11                0.50001919         0.074578  0.351841         1.955983       0.084837  0.111922                  0.471631          0.464935      0.035185                 0.978029   -64.815871        95.598286            0.629891\n",
      "     12                0.59998464         0.033936  0.141746         1.653707       0.034178  0.051624                  0.398746          0.396072      0.014170                 0.992199   -85.825384        65.370681            0.516834\n",
      "     13                0.69998848         0.015275  0.060498         1.426093       0.014587  0.023269                  0.343863          0.342811      0.006050                 0.998249   -93.950240        42.609301            0.393028\n",
      "     14                0.79999232         0.006965  0.011144         1.249216       0.002687  0.010572                  0.301214          0.301280      0.001114                 0.999363   -98.885571        24.921594            0.262718\n",
      "     15                0.89999616         0.002729  0.006368         1.111116       0.001536  0.004614                  0.267915          0.268315      0.000637                 1.000000   -99.363183        11.111585            0.131779\n",
      "     16                1.00000000         0.000501  0.000000         1.000000       0.000000  0.001635                  0.241122          0.241646      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09301955\n",
      " RMSE: 0.30499107\n",
      " AUC: 0.9218378\n",
      " pr_auc: 0.8106367\n",
      " logloss: 0.291856\n",
      " mean_per_class_error: 0.18268144\n",
      " default threshold: 0.40646305680274963\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4495   457  0.0923  457 / 4,952\n",
      "     1   426  1134  0.2731  426 / 1,560\n",
      "Totals  4921  1591  0.1356  883 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.31 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994552  4.174359         4.174359       1.000000  0.995882                  1.000000          0.995882      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.991293  4.174359         4.174359       1.000000  0.992975                  1.000000          0.994439      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.985927  4.174359         4.174359       1.000000  0.988832                  1.000000          0.992580      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.978363  4.110138         4.158365       0.984615  0.982030                  0.996169          0.989952      0.041026                 0.166667  311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.966367  4.045917         4.135945       0.969231  0.973456                  0.990798          0.986663      0.040385                 0.207051  304.591716       313.594463            0.206445\n",
      "      6                0.10012285         0.817984  3.482901         3.809423       0.834356  0.893823                  0.912577          0.940243      0.174359                 0.381410  248.290074       280.942268            0.369900\n",
      "      7                0.15003071         0.667531  2.658746         3.426649       0.636923  0.740873                  0.820880          0.873923      0.132692                 0.514103  165.874556       242.664882            0.478763\n",
      "      8                0.20009214         0.519904  2.432909         3.178023       0.582822  0.593263                  0.761320          0.803704      0.121795                 0.635897  143.290860       217.802310            0.573095\n",
      "      9                0.30006143         0.294727  1.718477         2.691757       0.411674  0.399802                  0.644831          0.669139      0.171795                 0.807692   71.847651       169.175655            0.667547\n",
      "     10                0.40003071         0.160931  1.051605         2.281876       0.251920  0.220951                  0.546641          0.557135      0.105128                 0.912821    5.160503       128.187608            0.674331\n",
      "     11                0.50000000         0.072445  0.474505         1.920513       0.113671  0.111995                  0.460074          0.468134      0.047436                 0.960256  -52.549529        92.051282            0.605248\n",
      "     12                0.59996929         0.033919  0.237252         1.640041       0.056836  0.049778                  0.392885          0.398426      0.023718                 0.983974  -76.274765        64.004121            0.504976\n",
      "     13                0.69993857         0.015212  0.109008         1.421370       0.026114  0.023287                  0.340500          0.344847      0.010897                 0.994872  -89.099216        42.137015            0.387844\n",
      "     14                0.79990786         0.006820  0.032061         1.247740       0.007680  0.010532                  0.298906          0.303065      0.003205                 0.998077  -96.793887        24.773986            0.260597\n",
      "     15                0.89987715         0.002893  0.012824         1.110550       0.003072  0.004712                  0.266041          0.269921      0.001282                 0.999359  -98.717555        11.055045            0.130821\n",
      "     16                1.00000000         0.000585  0.006402         1.000000       0.001534  0.001706                  0.239558          0.243066      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3808.129395          1.000000   0.187149\n",
      "                      capital_gain         3506.267578          0.920732   0.172314\n",
      "                               age         2056.611084          0.540058   0.101071\n",
      "                            fnlwgt         1605.258789          0.421535   0.078890\n",
      "marital_status. Married-civ-spouse         1539.408325          0.404243   0.075654\n",
      "                      capital_loss         1217.251709          0.319646   0.059821\n",
      "                    hours_per_week         1167.486084          0.306577   0.057376\n",
      "              education. Bachelors          735.677551          0.193186   0.036155\n",
      "        occupation. Prof-specialty          569.286011          0.149492   0.027977\n",
      "       occupation. Exec-managerial          551.698669          0.144874   0.027113\n",
      "---\n",
      "           marital_status. Widowed           14.830153          0.003894   0.000729\n",
      "          race. Asian-Pac-Islander           11.499986          0.003020   0.000565\n",
      "                 native_country.NA            7.980460          0.002096   0.000392\n",
      "              workclass. State-gov            7.753006          0.002036   0.000381\n",
      "          race. Amer-Indian-Eskimo            6.894102          0.001810   0.000339\n",
      "           relationship. Unmarried            5.922441          0.001555   0.000291\n",
      "      relationship. Other-relative            5.539434          0.001455   0.000272\n",
      "                education. 5th-6th            4.151810          0.001090   0.000204\n",
      "                   education. 12th            3.389948          0.000890   0.000167\n",
      "         marital_status. Separated            2.968688          0.000780   0.000146\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        83330.171875          1.000000   0.132150\n",
      "                            fnlwgt        67859.828125          0.814349   0.107616\n",
      "                      capital_gain        64910.785156          0.778959   0.102940\n",
      "                      capital_loss        61022.351563          0.732296   0.096773\n",
      "                    hours_per_week        54840.433594          0.658110   0.086969\n",
      "             relationship. Husband        19318.207031          0.231827   0.030636\n",
      "marital_status. Married-civ-spouse        19312.023438          0.231753   0.030626\n",
      "              education. Bachelors        17511.623047          0.210147   0.027771\n",
      "        occupation. Prof-specialty        12318.416016          0.147827   0.019535\n",
      "       occupation. Exec-managerial        12085.889648          0.145036   0.019167\n",
      "---\n",
      "             education. Assoc-acdm         1894.797485          0.022738   0.003005\n",
      "              workclass. State-gov         1654.136597          0.019850   0.002623\n",
      "                       race. Black         1453.846558          0.017447   0.002306\n",
      "                education. 5th-6th         1389.220825          0.016671   0.002203\n",
      "          race. Amer-Indian-Eskimo         1368.539429          0.016423   0.002170\n",
      "         marital_status. Separated         1334.329346          0.016013   0.002116\n",
      "                   education. 12th         1323.394897          0.015881   0.002099\n",
      "      relationship. Other-relative         1299.182373          0.015591   0.002060\n",
      "          marital_status. Divorced         1082.461548          0.012990   0.001717\n",
      "      occupation. Transport-moving          963.571167          0.011563   0.001528\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          616.000000          1.000000   0.285185\n",
      "                         age          463.000000          0.751623   0.214352\n",
      "              hours_per_week          226.000000          0.366883   0.104630\n",
      "                capital_gain           67.000000          0.108766   0.031019\n",
      "                capital_loss           61.000000          0.099026   0.028241\n",
      "          workclass. Private           59.000000          0.095779   0.027315\n",
      "          education. HS-grad           55.000000          0.089286   0.025463\n",
      "        education. Bachelors           50.000000          0.081169   0.023148\n",
      "  occupation. Prof-specialty           46.000000          0.074675   0.021296\n",
      " occupation. Exec-managerial           38.000000          0.061688   0.017593\n",
      "---\n",
      "              education. 9th            4.000000          0.006494   0.001852\n",
      "     relationship. Unmarried            3.000000          0.004870   0.001389\n",
      "       education. Assoc-acdm            3.000000          0.004870   0.001389\n",
      "           native_country.NA            3.000000          0.004870   0.001389\n",
      "        workclass. State-gov            2.000000          0.003247   0.000926\n",
      "relationship. Other-relative            1.000000          0.001623   0.000463\n",
      "             education. 12th            1.000000          0.001623   0.000463\n",
      "   marital_status. Separated            1.000000          0.001623   0.000463\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001623   0.000463\n",
      "          education. 5th-6th            1.000000          0.001623   0.000463\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      " 2023-10-20 18:27:02  3.656 sec              20       0.28386          0.25761      0.94111         0.85729       4.14727                       0.12112         0.30376            0.28966        0.92292           0.81184         4.17436                         0.14251\n",
      " 2023-10-20 18:27:03  4.306 sec              25       0.28045          0.25175      0.94376         0.86330       4.14727                       0.11866         0.30403            0.29026        0.92265           0.81206         4.17436                         0.14865\n",
      " 2023-10-20 18:27:03  5.191 sec              30       0.27646          0.24550      0.94683         0.87050       4.14727                       0.10995         0.30499            0.29186        0.92184           0.81064         4.17436                         0.13560\n",
      "\n",
      "10-20 18:27:04.501 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_53\n",
      "10-20 18:27:04.520 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.31594263965377106, 0.2957002960187515, 0.29078727474994165, 0.29059384042346914]\n",
      "10-20 18:27:04.537 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.31594263965377106 --> 0.29059384042346914 (still improving).\n",
      "10-20 18:27:04.585 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:04.584) \n",
      "10-20 18:27:04.619 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:04.619) \n",
      "10-20 18:27:04.659 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:04.659) \n",
      "10-20 18:27:04.693 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:04.693) \n",
      "10-20 18:27:04.701 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_55\n",
      "10-20 18:27:04.709 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_55\n",
      "10-20 18:27:04.715 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07648953\n",
      " RMSE: 0.2765674\n",
      " AUC: 0.94737923\n",
      " pr_auc: 0.870188\n",
      " logloss: 0.24497987\n",
      " mean_per_class_error: 0.14606585\n",
      " default threshold: 0.402601033449173\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18152  1593  0.0807  1,593 / 19,745\n",
      "     1   1333  4971  0.2115   1,333 / 6,304\n",
      "Totals  19485  6564  0.1123  2,926 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.29 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.994181  4.132138         4.132138       1.000000  0.995736                  1.000000          0.995736      0.041402                 0.041402  313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.991402  4.132138         4.132138       1.000000  0.992871                  1.000000          0.994306      0.041244                 0.082646  313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.986831  4.132138         4.132138       1.000000  0.989349                  1.000000          0.992652      0.041402                 0.124048  313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.978607  4.100353         4.124207       0.992308  0.983113                  0.998081          0.990271      0.040926                 0.164975  310.035265       312.420716            0.164873\n",
      "      5                0.05002111         0.963989  4.052979         4.109940       0.980843  0.972132                  0.994628          0.986638      0.040609                 0.205584  305.297859       310.993958            0.205229\n",
      "      6                0.10000384         0.810254  3.881417         3.995722       0.939324  0.889301                  0.966987          0.937988      0.194004                 0.399588  288.141718       299.572224            0.395232\n",
      "      7                0.15002495         0.663552  3.206133         3.732459       0.775902  0.738073                  0.903275          0.871333      0.160374                 0.559962  220.613342       273.245862            0.540818\n",
      "      8                0.20000768         0.530047  2.551643         3.437368       0.617512  0.596123                  0.831862          0.802557      0.127538                 0.687500  155.164302       243.736804            0.643134\n",
      "      9                0.30001152         0.305453  1.719477         2.864738       0.416123  0.408583                  0.693282          0.671232      0.171954                 0.859454   71.947714       186.473774            0.738056\n",
      "     10                0.40001536         0.151283  0.861325         2.363885       0.208445  0.221481                  0.572073          0.558794      0.086136                 0.945590  -13.867520       136.388451            0.719761\n",
      "     11                0.50001919         0.072094  0.345799         1.960267       0.083685  0.107310                  0.474395          0.468498      0.034581                 0.980171  -65.420109        96.026739            0.633451\n",
      "     12                0.59998464         0.031155  0.138055         1.656663       0.033410  0.049025                  0.400921          0.398608      0.013801                 0.993972  -86.194469        65.666253            0.519776\n",
      "     13                0.69998848         0.014330  0.041242         1.425876       0.009981  0.021543                  0.345070          0.344738      0.004124                 0.998096  -95.875793        42.587553            0.393285\n",
      "     14                0.79999232         0.006488  0.015862         1.249615       0.003839  0.009988                  0.302414          0.302893      0.001586                 0.999683  -98.413766        24.961542            0.263446\n",
      "     15                0.89999616         0.002406  0.001586         1.110940       0.000384  0.004197                  0.268853          0.269703      0.000159                 0.999841  -99.841377        11.093959            0.131723\n",
      "     16                1.00000000         0.000427  0.001586         1.000000       0.000384  0.001391                  0.242005          0.242871      0.000159                 1.000000  -99.841377         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09432416\n",
      " RMSE: 0.30712238\n",
      " AUC: 0.91639537\n",
      " pr_auc: 0.803344\n",
      " logloss: 0.29717955\n",
      " mean_per_class_error: 0.19321264\n",
      " default threshold: 0.44214192032814026\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4535   440  0.0884  440 / 4,975\n",
      "     1   458  1079  0.2980  458 / 1,537\n",
      "Totals  4993  1519  0.1379  898 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.30 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.993964  4.236825         4.236825       1.000000  0.995509                  1.000000          0.995509      0.042941                 0.042941   323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.990753  4.236825         4.236825       1.000000  0.992438                  1.000000          0.993985      0.042290                 0.085231   323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.985494  4.236825         4.236825       1.000000  0.988530                  1.000000          0.992176      0.042290                 0.127521   323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.974457  4.171643         4.220592       0.984615  0.980360                  0.996169          0.989233      0.041640                 0.169161   317.164306       322.059194            0.168960\n",
      "      5                0.05006143         0.954388  4.236825         4.223829       1.000000  0.965337                  0.996933          0.984469      0.042290                 0.211451   323.682498       322.382859            0.211250\n",
      "      6                0.10012285         0.798995  3.444045         3.833937       0.812883  0.878326                  0.904908          0.931398      0.172414                 0.383865   244.404485       283.393672            0.371402\n",
      "      7                0.15003071         0.656345  2.724604         3.464916       0.643077  0.727802                  0.817810          0.863671      0.135979                 0.519844   172.460437       246.491624            0.484065\n",
      "      8                0.20009214         0.512667  2.417330         3.202819       0.570552  0.582380                  0.755948          0.793294      0.121015                 0.640859   141.732959       220.281858            0.576939\n",
      "      9                0.30006143         0.315872  1.542439         2.649642       0.364055  0.411053                  0.625384          0.665946      0.154196                 0.795055    54.243859       164.964183            0.647920\n",
      "     10                0.40003071         0.160213  1.067341         2.254219       0.251920  0.234656                  0.532054          0.558165      0.106701                 0.901757     6.734147       125.421859            0.656732\n",
      "     11                0.50000000         0.072588  0.540179         1.911516       0.127496  0.111191                  0.451167          0.468797      0.054001                 0.955758   -45.982109        91.151594            0.596562\n",
      "     12                0.59996929         0.030429  0.234294         1.632051       0.055300  0.048338                  0.385206          0.398739      0.023422                 0.979180   -76.570553        63.205058            0.496366\n",
      "     13                0.69993857         0.014745  0.097623         1.412895       0.023041  0.021353                  0.333480          0.344838      0.009759                 0.988939   -90.237730        41.289469            0.378286\n",
      "     14                0.79990786         0.006659  0.097623         1.248517       0.023041  0.010369                  0.294682          0.303038      0.009759                 0.998699   -90.237730        24.851725            0.260206\n",
      "     15                0.89987715         0.002438  0.013016         1.111263       0.003072  0.004375                  0.262287          0.269859      0.001301                 1.000000   -98.698364        11.126280            0.131055\n",
      "     16                1.00000000         0.000571  0.000000         1.000000       0.000000  0.001406                  0.236026          0.242980      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4152.551758          1.000000   0.203944\n",
      "                      capital_gain         3474.438232          0.836700   0.170640\n",
      "                               age         2077.196045          0.500222   0.102017\n",
      "                            fnlwgt         1623.933838          0.391069   0.079756\n",
      "marital_status. Married-civ-spouse         1458.202271          0.351158   0.071617\n",
      "                      capital_loss         1200.654297          0.289137   0.058968\n",
      "                    hours_per_week         1133.551880          0.272977   0.055672\n",
      "              education. Bachelors          702.881714          0.169265   0.034521\n",
      "        occupation. Prof-specialty          519.618652          0.125132   0.025520\n",
      "       occupation. Exec-managerial          506.222900          0.121906   0.024862\n",
      "---\n",
      "                     occupation.NA           14.503084          0.003493   0.000712\n",
      "              workclass. State-gov           10.103318          0.002433   0.000496\n",
      "          race. Asian-Pac-Islander            9.227043          0.002222   0.000453\n",
      "                      workclass.NA            7.304838          0.001759   0.000359\n",
      "          race. Amer-Indian-Eskimo            5.838183          0.001406   0.000287\n",
      "                education. 5th-6th            5.686970          0.001370   0.000279\n",
      "      relationship. Other-relative            4.376630          0.001054   0.000215\n",
      "                 native_country.NA            2.380165          0.000573   0.000117\n",
      "         marital_status. Separated            1.875626          0.000452   0.000092\n",
      "           marital_status. Widowed            1.797873          0.000433   0.000088\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        81750.632813          1.000000   0.131428\n",
      "                            fnlwgt        76806.242188          0.939519   0.123479\n",
      "                      capital_gain        71275.382813          0.871863   0.114587\n",
      "                      capital_loss        54372.402344          0.665101   0.087413\n",
      "                    hours_per_week        50264.179688          0.614848   0.080808\n",
      "marital_status. Married-civ-spouse        21279.023438          0.260292   0.034210\n",
      "             relationship. Husband        18518.595703          0.226525   0.029772\n",
      "              education. Bachelors        15148.884766          0.185306   0.024354\n",
      "        occupation. Prof-specialty        13323.698242          0.162980   0.021420\n",
      "                education. Masters        12621.817383          0.154394   0.020292\n",
      "---\n",
      "          race. Asian-Pac-Islander         1430.474731          0.017498   0.002300\n",
      "          race. Amer-Indian-Eskimo         1420.591553          0.017377   0.002284\n",
      "      relationship. Other-relative         1396.271484          0.017080   0.002245\n",
      "                education. 5th-6th         1351.620972          0.016533   0.002173\n",
      "          occupation. Craft-repair         1277.111816          0.015622   0.002053\n",
      "                 native_country.NA         1153.071655          0.014105   0.001854\n",
      "         marital_status. Separated          964.407288          0.011797   0.001550\n",
      "           relationship. Unmarried          955.970825          0.011694   0.001537\n",
      "              workclass. Local-gov          924.290039          0.011306   0.001486\n",
      "           marital_status. Widowed          832.821777          0.010187   0.001339\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          680.000000          1.000000   0.314378\n",
      "                         age          466.000000          0.685294   0.215442\n",
      "              hours_per_week          206.000000          0.302941   0.095238\n",
      "                capital_gain           74.000000          0.108824   0.034212\n",
      "                capital_loss           63.000000          0.092647   0.029126\n",
      "          workclass. Private           58.000000          0.085294   0.026815\n",
      "        education. Bachelors           50.000000          0.073529   0.023116\n",
      "  occupation. Prof-specialty           47.000000          0.069118   0.021729\n",
      "          education. HS-grad           46.000000          0.067647   0.021267\n",
      " occupation. Exec-managerial           38.000000          0.055882   0.017568\n",
      "---\n",
      "               occupation.NA            3.000000          0.004412   0.001387\n",
      "    race. Asian-Pac-Islander            3.000000          0.004412   0.001387\n",
      "        workclass. State-gov            3.000000          0.004412   0.001387\n",
      "                workclass.NA            2.000000          0.002941   0.000925\n",
      "     marital_status. Widowed            1.000000          0.001471   0.000462\n",
      "relationship. Other-relative            1.000000          0.001471   0.000462\n",
      "   marital_status. Separated            1.000000          0.001471   0.000462\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001471   0.000462\n",
      "           native_country.NA            1.000000          0.001471   0.000462\n",
      "          education. 5th-6th            1.000000          0.001471   0.000462\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      " 2023-10-20 18:27:02  3.948 sec              20       0.28375          0.25710      0.94156         0.85776       4.13214                       0.11977         0.30632            0.29578        0.91635           0.80451         4.23682                         0.13851\n",
      " 2023-10-20 18:27:03  4.624 sec              25       0.28033          0.25097      0.94441         0.86363       4.13214                       0.11594         0.30676            0.29629        0.91661           0.80377         4.23682                         0.14235\n",
      " 2023-10-20 18:27:04  5.552 sec              30       0.27657          0.24498      0.94738         0.87019       4.13214                       0.11233         0.30712            0.29718        0.91640           0.80334         4.23682                         0.13790\n",
      "\n",
      "10-20 18:27:04.726 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3217832013988385, 0.30200096254015674, 0.29704341270984735, 0.2964181317290027]\n",
      "10-20 18:27:04.726 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3217832013988385 --> 0.2964181317290027 (still improving).\n",
      "10-20 18:27:04.760 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:04.760) \n",
      "█10-20 18:27:04.841 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.115 (Wall: 20-Oct 18:27:04.841) \n",
      "10-20 18:27:04.850 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_56\n",
      "10-20 18:27:04.858 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_56\n",
      "10-20 18:27:04.865 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_57\n",
      "10-20 18:27:04.870 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_57\n",
      "10-20 18:27:04.887 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.07759276\n",
      " RMSE: 0.27855477\n",
      " AUC: 0.9451822\n",
      " pr_auc: 0.8638957\n",
      " logloss: 0.24808176\n",
      " mean_per_class_error: 0.14880526\n",
      " default threshold: 0.3845948874950409\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18146  1687  0.0851  1,687 / 19,833\n",
      "     1   1321  4894  0.2126   1,321 / 6,215\n",
      "Totals  19467  6581  0.1155  3,008 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.81 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.995658  4.191150         4.191150       1.000000  0.997093                  1.000000          0.997093      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.991541  4.191150         4.191150       1.000000  0.993760                  1.000000          0.995430      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.985884  4.191150         4.191150       1.000000  0.988994                  1.000000          0.993282      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.976504  4.175031         4.187128       0.996154  0.981399                  0.999040          0.990317      0.041673                 0.167498   317.503063       318.712823            0.167448\n",
      "      5                0.05002303         0.958596  4.110860         4.171851       0.980843  0.968367                  0.995395          0.985920      0.041191                 0.208689   311.086020       317.185121            0.208386\n",
      "      6                0.10004607         0.789444  3.869497         4.020674       0.923254  0.876114                  0.959325          0.931017      0.193564                 0.402253   286.949653       302.067387            0.396908\n",
      "      7                0.15003071         0.637751  3.241543         3.761096       0.773425  0.711022                  0.897390          0.857723      0.162027                 0.564280   224.154262       276.109637            0.544061\n",
      "      8                0.20001536         0.504773  2.501170         3.446236       0.596774  0.569687                  0.822265          0.785742      0.125020                 0.689300   150.117043       244.623580            0.642610\n",
      "      9                0.30002303         0.299225  1.623367         2.838613       0.387332  0.394083                  0.677287          0.655189      0.162349                 0.851649    62.336691       183.861283            0.724487\n",
      "     10                0.39999232         0.155215  0.906151         2.355637       0.216206  0.221545                  0.562050          0.546809      0.090587                 0.942237    -9.384881       135.563653            0.712165\n",
      "     11                0.50000000         0.071448  0.362000         1.956879       0.086372  0.108108                  0.466907          0.459062      0.036203                 0.978439   -63.800044        95.687852            0.628366\n",
      "     12                0.60000768         0.031162  0.144800         1.654846       0.034549  0.048593                  0.394843          0.390646      0.014481                 0.992920   -85.520018        65.484608            0.516038\n",
      "     13                0.69997697         0.014174  0.051504         1.425860       0.012289  0.021360                  0.340207          0.337905      0.005149                 0.998069   -94.849585        42.586004            0.391504\n",
      "     14                0.79998464         0.006570  0.017698         1.249823       0.004223  0.009966                  0.298205          0.296909      0.001770                 0.999839   -98.230224        24.982286            0.262482\n",
      "     15                0.89999232         0.002658  0.001609         1.111121       0.000384  0.004441                  0.265111          0.264410      0.000161                 1.000000   -99.839111        11.112059            0.131347\n",
      "     16                1.00000000         0.000455  0.000000         1.000000       0.000000  0.001599                  0.238598          0.238127      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09135064\n",
      " RMSE: 0.30224267\n",
      " AUC: 0.9265257\n",
      " pr_auc: 0.83069754\n",
      " logloss: 0.2867043\n",
      " mean_per_class_error: 0.16317427\n",
      " default threshold: 0.3234867453575134\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4305   582  0.1191  582 / 4,887\n",
      "     1   337  1289  0.2073  337 / 1,626\n",
      "Totals  4642  1871  0.1411  919 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.98 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.995259  4.005535         4.005535       1.000000  0.996732                  1.000000          0.996732      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.991649  4.005535         4.005535       1.000000  0.993478                  1.000000          0.995117      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.985663  4.005535         4.005535       1.000000  0.988926                  1.000000          0.993064      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.976357  4.005535         4.005535       1.000000  0.980911                  1.000000          0.990038      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.959339  4.005535         4.005535       1.000000  0.968071                  1.000000          0.985658      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.805034  3.477198         3.741366       0.868098  0.887038                  0.934049          0.936348      0.174047                 0.374539   247.719761       274.136633            0.365740\n",
      "      7                0.15000768         0.645248  2.945609         3.476657       0.735385  0.718064                  0.867963          0.863736      0.146986                 0.521525   194.560886       247.665683            0.495129\n",
      "      8                0.20006142         0.513084  2.199358         3.157087       0.549080  0.575543                  0.788181          0.791632      0.110086                 0.631611   119.935821       215.708711            0.575135\n",
      "      9                0.30001535         0.296602  1.784340         2.699739       0.445469  0.398623                  0.674002          0.660696      0.178352                 0.809963    78.433973       169.973883            0.679617\n",
      "     10                0.39996929         0.153613  0.941393         2.260321       0.235023  0.219646                  0.564299          0.550476      0.094096                 0.904059    -5.860697       126.032113            0.671810\n",
      "     11                0.50007677         0.074617  0.571342         1.922214       0.142638  0.108714                  0.479889          0.462042      0.057196                 0.961255   -42.865834        92.221409            0.614621\n",
      "     12                0.60003071         0.032191  0.221504         1.638908       0.055300  0.050241                  0.409161          0.393444      0.022140                 0.983395   -77.849576        63.890751            0.510917\n",
      "     13                0.69998465         0.014259  0.116905         1.421574       0.029186  0.021529                  0.354902          0.340336      0.011685                 0.995080   -88.309498        42.157397            0.393279\n",
      "     14                0.79993858         0.006654  0.049223         1.250096       0.012289  0.009944                  0.312092          0.299053      0.004920                 1.000000   -95.077683        25.009597            0.266626\n",
      "     15                0.89989252         0.002813  0.000000         1.111244       0.000000  0.004582                  0.277427          0.266345      0.000000                 1.000000  -100.000000        11.124382            0.133415\n",
      "     16                1.00000000         0.000454  0.000000         1.000000       0.000000  0.001653                  0.249655          0.239848      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4147.014648          1.000000   0.211518\n",
      "                      capital_gain         3253.106689          0.784445   0.165924\n",
      "             relationship. Husband         1837.382202          0.443061   0.093716\n",
      "                               age         1654.789307          0.399031   0.084402\n",
      "                            fnlwgt         1516.774536          0.365751   0.077363\n",
      "                    hours_per_week         1188.566406          0.286608   0.060623\n",
      "                      capital_loss         1138.631470          0.274567   0.058076\n",
      "        occupation. Prof-specialty          626.812866          0.151148   0.031971\n",
      "              education. Bachelors          547.008118          0.131904   0.027900\n",
      "       occupation. Exec-managerial          519.790527          0.125341   0.026512\n",
      "---\n",
      "           relationship. Unmarried           14.442497          0.003483   0.000737\n",
      "              workclass. State-gov           12.894225          0.003109   0.000658\n",
      "                       race. Black           10.866224          0.002620   0.000554\n",
      "                     occupation.NA            9.435364          0.002275   0.000481\n",
      "           marital_status. Widowed            9.016663          0.002174   0.000460\n",
      "          race. Asian-Pac-Islander            8.307315          0.002003   0.000424\n",
      "                education. 5th-6th            7.998797          0.001929   0.000408\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001914   0.000405\n",
      "                   education. 12th            3.699208          0.000892   0.000189\n",
      "                 native_country.NA            0.795650          0.000192   0.000041\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        85010.203125          1.000000   0.135041\n",
      "                      capital_gain        75348.617188          0.886348   0.119694\n",
      "                               age        68714.328125          0.808307   0.109155\n",
      "                      capital_loss        54485.695313          0.640931   0.086552\n",
      "                    hours_per_week        53698.761719          0.631674   0.085302\n",
      "marital_status. Married-civ-spouse        28633.410156          0.336823   0.045485\n",
      "              education. Bachelors        15902.378906          0.187064   0.025261\n",
      "        occupation. Prof-specialty        14624.916016          0.172037   0.023232\n",
      "       occupation. Exec-managerial        14098.483398          0.165845   0.022396\n",
      "                education. Masters        12602.762695          0.148250   0.020020\n",
      "---\n",
      "              workclass. Local-gov         2103.750000          0.024747   0.003342\n",
      "                     occupation.NA         1744.116699          0.020517   0.002771\n",
      "                      workclass.NA         1650.096802          0.019411   0.002621\n",
      "                   education. 12th         1397.228027          0.016436   0.002220\n",
      "          race. Amer-Indian-Eskimo         1349.694214          0.015877   0.002144\n",
      "          marital_status. Divorced         1008.812866          0.011867   0.001603\n",
      "                education. 5th-6th         1003.292114          0.011802   0.001594\n",
      "                         sex. Male          729.991150          0.008587   0.001160\n",
      "          race. Asian-Pac-Islander          619.778381          0.007291   0.000985\n",
      "                 native_country.NA           86.905121          0.001022   0.000138\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          586.000000          1.000000   0.288386\n",
      "                         age          389.000000          0.663823   0.191437\n",
      "              hours_per_week          223.000000          0.380546   0.109744\n",
      "                capital_gain           68.000000          0.116041   0.033465\n",
      "          workclass. Private           65.000000          0.110922   0.031988\n",
      "                capital_loss           58.000000          0.098976   0.028543\n",
      "          education. HS-grad           52.000000          0.088737   0.025591\n",
      "  occupation. Prof-specialty           49.000000          0.083618   0.024114\n",
      "        education. Bachelors           47.000000          0.080205   0.023130\n",
      "     education. Some-college           34.000000          0.058020   0.016732\n",
      "---\n",
      "     workclass. Self-emp-inc            4.000000          0.006826   0.001969\n",
      "     marital_status. Widowed            3.000000          0.005119   0.001476\n",
      "relationship. Other-relative            3.000000          0.005119   0.001476\n",
      "               occupation.NA            3.000000          0.005119   0.001476\n",
      "    race. Asian-Pac-Islander            2.000000          0.003413   0.000984\n",
      "      native_country. Mexico            2.000000          0.003413   0.000984\n",
      "             education. 12th            1.000000          0.001706   0.000492\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001706   0.000492\n",
      "           native_country.NA            1.000000          0.001706   0.000492\n",
      "          education. 5th-6th            1.000000          0.001706   0.000492\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      " 2023-10-20 18:27:02  3.900 sec              20       0.28552          0.26048      0.93937         0.85104       4.19115                       0.12312         0.30193            0.28685        0.92659           0.83134         4.00554                         0.14156\n",
      " 2023-10-20 18:27:03  4.463 sec              25       0.28224          0.25428      0.94224         0.85712       4.19115                       0.11794         0.30272            0.28782        0.92593           0.83002         4.00554                         0.13588\n",
      " 2023-10-20 18:27:04  5.318 sec              30       0.27855          0.24808      0.94518         0.86390       4.19115                       0.11548         0.30224            0.28670        0.92653           0.83070         4.00554                         0.14110\n",
      "\n",
      "10-20 18:27:04.897 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.31642547403597526, 0.294150910592242, 0.28810012827421844, 0.2871255414995885]\n",
      "10-20 18:27:04.897 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.31642547403597526 --> 0.2871255414995885 (still improving).\n",
      "10-20 18:27:04.892 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.076765195\n",
      " RMSE: 0.27706534\n",
      " AUC: 0.94663125\n",
      " pr_auc: 0.8699842\n",
      " logloss: 0.24658887\n",
      " mean_per_class_error: 0.14322071\n",
      " default threshold: 0.3947722613811493\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18100  1638  0.0830  1,638 / 19,738\n",
      "     1   1284  5027  0.2035   1,284 / 6,311\n",
      "Totals  19384  6665  0.1122  2,922 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.29 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.994046  4.127555         4.127555       1.000000  0.995677                  1.000000          0.995677      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.991558  4.127555         4.127555       1.000000  0.992827                  1.000000          0.994255      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.987021  4.127555         4.127555       1.000000  0.989452                  1.000000          0.992652      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.979358  4.095805         4.119633       0.992308  0.983527                  0.998081          0.990375      0.040881                 0.164792   309.580464       311.963269            0.164690\n",
      "      5                0.05002111         0.965451  4.095926         4.114884       0.992337  0.973197                  0.996930          0.986934      0.041039                 0.205831   309.592629       311.488413            0.205628\n",
      "      6                0.10000384         0.802468  3.858091         3.986537       0.934716  0.888017                  0.965835          0.937495      0.192838                 0.398669   285.809102       298.653687            0.394160\n",
      "      7                0.15002495         0.656868  3.208913         3.727262       0.777437  0.727636                  0.903019          0.867524      0.160513                 0.559182   220.891272       272.726249            0.539981\n",
      "      8                0.20000768         0.521892  2.593195         3.443854       0.628264  0.588265                  0.834357          0.797736      0.129615                 0.688797   159.319512       244.385448            0.645075\n",
      "      9                0.30001152         0.308674  1.674789         2.854166       0.405758  0.408406                  0.691491          0.667959      0.167485                 0.856283    67.478914       185.416603            0.734133\n",
      "     10                0.40001536         0.157126  0.841356         2.350963       0.203839  0.225443                  0.569578          0.557330      0.084139                 0.940421   -15.864425       135.096346            0.713195\n",
      "     11                0.50001919         0.073634  0.370767         1.954924       0.089827  0.110077                  0.473628          0.467880      0.037078                 0.977500   -62.923306        95.492416            0.630149\n",
      "     12                0.59998464         0.032554  0.139487         1.652448       0.033794  0.050280                  0.400346          0.398302      0.013944                 0.991444   -86.051273        65.244814            0.516623\n",
      "     13                0.69998848         0.015278  0.061794         1.425199       0.014971  0.022885                  0.345289          0.344668      0.006180                 0.997623   -93.820551        42.519944            0.392800\n",
      "     14                0.79999232         0.006729  0.022183         1.249814       0.005374  0.010537                  0.302798          0.302900      0.002218                 0.999842   -97.781736        24.981393            0.263749\n",
      "     15                0.89999616         0.002243  0.000000         1.110940       0.000000  0.004137                  0.269152          0.269702      0.000000                 0.999842  -100.000000        11.093979            0.131770\n",
      "     16                1.00000000         0.000373  0.001584         1.000000       0.000384  0.001225                  0.242274          0.242854      0.000158                 1.000000   -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09078484\n",
      " RMSE: 0.30130523\n",
      " AUC: 0.9226343\n",
      " pr_auc: 0.81393474\n",
      " logloss: 0.28561416\n",
      " mean_per_class_error: 0.18254356\n",
      " default threshold: 0.4140622913837433\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4534   448  0.0899  448 / 4,982\n",
      "     1   421  1109  0.2752  421 / 1,530\n",
      "Totals  4955  1557  0.1334  869 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.74 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.993880  4.256209         4.256209       1.000000  0.995403                  1.000000          0.995403      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.991165  4.256209         4.256209       1.000000  0.992472                  1.000000          0.993949      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.986717  4.190729         4.234494       0.984615  0.989356                  0.994898          0.992426      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.978748  4.190729         4.223595       0.984615  0.982867                  0.992337          0.990045      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.960123  4.190729         4.217042       0.984615  0.970650                  0.990798          0.986178      0.041830                 0.211111   319.072901       321.704158            0.210509\n",
      "      6                0.10012285         0.795806  3.681751         3.949397       0.865031  0.882504                  0.927914          0.934341      0.184314                 0.395425   268.175147       294.939653            0.385991\n",
      "      7                0.15003071         0.636097  2.789454         3.563541       0.655385  0.712589                  0.837257          0.860575      0.139216                 0.534641   178.945400       256.354052            0.502726\n",
      "      8                0.20009214         0.494835  2.415333         3.276268       0.567485  0.562305                  0.769762          0.785950      0.120915                 0.655556   141.533341       227.626844            0.595339\n",
      "      9                0.30006143         0.290987  1.510268         2.687903       0.354839  0.390966                  0.631525          0.654356      0.150980                 0.806536    51.026776       168.790281            0.662016\n",
      "     10                0.40003071         0.149469  0.954542         2.254729       0.224270  0.214946                  0.529750          0.544546      0.095425                 0.901961    -4.545847       125.472884            0.656076\n",
      "     11                0.50000000         0.074126  0.562264         1.916340       0.132104  0.106885                  0.450246          0.457041      0.056209                 0.958170   -43.773581        91.633987            0.598876\n",
      "     12                0.59996929         0.032948  0.339974         1.653679       0.079877  0.050729                  0.388533          0.389339      0.033987                 0.992157   -66.002630        65.367942            0.512631\n",
      "     13                0.69993857         0.015350  0.039228         1.423094       0.009217  0.022770                  0.334357          0.336984      0.003922                 0.996078   -96.077227        42.309406            0.387086\n",
      "     14                0.79990786         0.006558  0.026152         1.248510       0.006144  0.010450                  0.293338          0.296175      0.002614                 0.998693   -97.384818        24.850981            0.259833\n",
      "     15                0.89987715         0.002158  0.013076         1.111263       0.003072  0.004001                  0.261092          0.263717      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000398  0.000000         1.000000       0.000000  0.001133                  0.234951          0.237426      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4101.234375          1.000000   0.200167\n",
      "                      capital_gain         3504.889893          0.854594   0.171061\n",
      "                               age         2182.816406          0.532234   0.106536\n",
      "                            fnlwgt         1691.000000          0.412315   0.082532\n",
      "marital_status. Married-civ-spouse         1483.964355          0.361834   0.072427\n",
      "                      capital_loss         1139.461060          0.277834   0.055613\n",
      "                    hours_per_week         1120.879272          0.273303   0.054706\n",
      "              education. Bachelors          642.896240          0.156757   0.031377\n",
      "       occupation. Exec-managerial          571.052429          0.139239   0.027871\n",
      "        occupation. Prof-specialty          570.176514          0.139026   0.027828\n",
      "---\n",
      "           marital_status. Widowed           15.871960          0.003870   0.000775\n",
      "                       race. Black           15.021633          0.003663   0.000733\n",
      "                     occupation.NA            9.257658          0.002257   0.000452\n",
      "           relationship. Unmarried            9.212575          0.002246   0.000450\n",
      "         marital_status. Separated            9.013293          0.002198   0.000440\n",
      "                 native_country.NA            8.301558          0.002024   0.000405\n",
      "              workclass. State-gov            7.262564          0.001771   0.000354\n",
      "                education. 5th-6th            6.929251          0.001690   0.000338\n",
      "                      workclass.NA            4.656168          0.001135   0.000227\n",
      "          race. Amer-Indian-Eskimo            4.215075          0.001028   0.000206\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        87620.859375          1.000000   0.140098\n",
      "                               age        78401.140625          0.894777   0.125357\n",
      "                      capital_gain        63659.148438          0.726530   0.101785\n",
      "                    hours_per_week        50017.871094          0.570844   0.079974\n",
      "                      capital_loss        49980.300781          0.570416   0.079914\n",
      "             relationship. Husband        19859.433594          0.226652   0.031754\n",
      "marital_status. Married-civ-spouse        16600.218750          0.189455   0.026542\n",
      "              education. Bachelors        14851.249023          0.169494   0.023746\n",
      "       occupation. Exec-managerial        13741.993164          0.156835   0.021972\n",
      "        occupation. Prof-specialty        13217.804688          0.150852   0.021134\n",
      "---\n",
      "              education. Assoc-voc         2037.022705          0.023248   0.003257\n",
      "          marital_status. Divorced         1821.994141          0.020794   0.002913\n",
      "                     occupation.NA         1488.959595          0.016993   0.002381\n",
      "       relationship. Not-in-family         1472.834351          0.016809   0.002355\n",
      "          race. Amer-Indian-Eskimo         1413.515991          0.016132   0.002260\n",
      "           relationship. Unmarried         1412.981201          0.016126   0.002259\n",
      "              workclass. State-gov         1043.810913          0.011913   0.001669\n",
      "             education. Assoc-acdm          997.901489          0.011389   0.001596\n",
      "                      workclass.NA          899.357544          0.010264   0.001438\n",
      "                education. 5th-6th          713.308777          0.008141   0.001141\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          645.000000          1.000000   0.293315\n",
      "                        age          485.000000          0.751938   0.220555\n",
      "             hours_per_week          199.000000          0.308527   0.090496\n",
      "         workclass. Private           65.000000          0.100775   0.029559\n",
      "               capital_gain           64.000000          0.099225   0.029104\n",
      "               capital_loss           61.000000          0.094574   0.027740\n",
      "         education. HS-grad           61.000000          0.094574   0.027740\n",
      "       education. Bachelors           56.000000          0.086822   0.025466\n",
      " occupation. Prof-specialty           41.000000          0.063566   0.018645\n",
      "occupation. Exec-managerial           38.000000          0.058915   0.017281\n",
      "---\n",
      "       education. Assoc-voc            4.000000          0.006202   0.001819\n",
      "      education. Assoc-acdm            3.000000          0.004651   0.001364\n",
      "             education. 9th            3.000000          0.004651   0.001364\n",
      "              occupation.NA            2.000000          0.003101   0.000910\n",
      "  marital_status. Separated            2.000000          0.003101   0.000910\n",
      "               workclass.NA            2.000000          0.003101   0.000910\n",
      "       workclass. State-gov            2.000000          0.003101   0.000910\n",
      "          native_country.NA            2.000000          0.003101   0.000910\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.001550   0.000455\n",
      "         education. 5th-6th            1.000000          0.001550   0.000455\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      " 2023-10-20 18:27:02  3.824 sec              20       0.28393          0.25830      0.94145         0.85820       4.12756                       0.12235         0.30044            0.28487        0.92305           0.81492         4.25621                         0.14220\n",
      " 2023-10-20 18:27:03  4.564 sec              25       0.28038          0.25209      0.94407         0.86424       4.12756                       0.11620         0.30086            0.28541        0.92254           0.81423         4.25621                         0.14005\n",
      " 2023-10-20 18:27:04  5.475 sec              30       0.27707          0.24659      0.94663         0.86998       4.12756                       0.11217         0.30131            0.28561        0.92263           0.81393         4.25621                         0.13345\n",
      "\n",
      "10-20 18:27:04.923 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3105824288676712, 0.2899789302642067, 0.2856406659875552, 0.28529764870527846]\n",
      "10-20 18:27:04.923 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3105824288676712 --> 0.28529764870527846 (still improving).\n",
      "10-20 18:27:04.930 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.088 (Wall: 20-Oct 18:27:04.930) \n",
      "10-20 18:27:04.962 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:04.962) \n",
      "10-20 18:27:04.982 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_58\n",
      "10-20 18:27:04.994 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:04.994) \n",
      "10-20 18:27:05.005 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:05.005) \n",
      "10-20 18:27:05.016 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_58\n",
      "10-20 18:27:05.072 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:05.072) \n",
      "10-20 18:27:05.079 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:05.079) \n",
      "10-20 18:27:05.079 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.117 (Wall: 20-Oct 18:27:05.079) \n",
      "10-20 18:27:05.130 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:05.130) \n",
      "10-20 18:27:05.138 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:05.138) \n",
      "10-20 18:27:05.145 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:05.145) \n",
      "10-20 18:27:05.230 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:05.230) \n",
      "10-20 18:27:05.240 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.109 (Wall: 20-Oct 18:27:05.240) \n",
      "10-20 18:27:05.275 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:05.275) \n",
      "10-20 18:27:05.303 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:05.303) \n",
      "10-20 18:27:05.425 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_61\n",
      "10-20 18:27:05.440 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_59\n",
      "10-20 18:27:05.445 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_60\n",
      "10-20 18:27:05.450 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_59\n",
      "10-20 18:27:05.454 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_61\n",
      "10-20 18:27:05.455 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.07484265\n",
      " RMSE: 0.27357385\n",
      " AUC: 0.9491407\n",
      " pr_auc: 0.8754987\n",
      " logloss: 0.2407701\n",
      " mean_per_class_error: 0.14190583\n",
      " default threshold: 0.39210477471351624\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18205  1563  0.0791  1,563 / 19,768\n",
      "     1   1286  4995  0.2047   1,286 / 6,281\n",
      "Totals  19491  6558  0.1094  2,849 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995487  4.147270         4.147270       1.000000  0.996516                  1.000000          0.996516      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.992815  4.147270         4.147270       1.000000  0.994291                  1.000000          0.995406      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.988387  4.147270         4.147270       1.000000  0.990850                  1.000000          0.993885      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.981056  4.131319         4.143289       0.996154  0.985127                  0.999040          0.991700      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05002111         0.967507  4.099600         4.134538       0.988506  0.975233                  0.996930          0.988401      0.041076                 0.206814   309.959978       313.453809            0.206612\n",
      "      6                0.10000384         0.817223  3.921113         4.027866       0.945469  0.892404                  0.971209          0.940421      0.195988                 0.402802   292.111276       302.786639            0.399008\n",
      "      7                0.15002495         0.660875  3.259251         3.771596       0.785879  0.737200                  0.909417          0.872664      0.163031                 0.565833   225.925097       277.159569            0.547926\n",
      "      8                0.20000768         0.516706  2.564172         3.469856       0.618280  0.586925                  0.836660          0.801256      0.128164                 0.693998   156.417203       246.985565            0.650948\n",
      "      9                0.30001152         0.294764  1.650948         2.863553       0.398081  0.398355                  0.690467          0.666956      0.165101                 0.859099    65.094761       186.355297            0.736729\n",
      "     10                0.40001536         0.155502  0.867663         2.364580       0.209213  0.219359                  0.570154          0.555057      0.086770                 0.945868   -13.233708       136.458046            0.719290\n",
      "     11                0.50001919         0.072334  0.340697         1.959804       0.082150  0.109754                  0.472553          0.465996      0.034071                 0.979940   -65.930300        95.980376            0.632408\n",
      "     12                0.59998464         0.031841  0.124227         1.653972       0.029954  0.049171                  0.398810          0.396547      0.012418                 0.992358   -87.577303        65.397217            0.517044\n",
      "     13                0.69998848         0.013940  0.063682         1.426775       0.015355  0.021669                  0.344028          0.342990      0.006368                 0.998726   -93.631832        42.677536            0.393658\n",
      "     14                0.79999232         0.006095  0.007960         1.249415       0.001919  0.009485                  0.301262          0.301300      0.000796                 0.999522   -99.203979        24.941495            0.262928\n",
      "     15                0.89999616         0.002314  0.004776         1.111116       0.001152  0.003995                  0.267915          0.268265      0.000478                 1.000000   -99.522387        11.111585            0.131779\n",
      "     16                1.00000000         0.000310  0.000000         1.000000       0.000000  0.001339                  0.241122          0.241571      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09411839\n",
      " RMSE: 0.3067872\n",
      " AUC: 0.9204405\n",
      " pr_auc: 0.80745035\n",
      " logloss: 0.29476875\n",
      " mean_per_class_error: 0.18250072\n",
      " default threshold: 0.38865259289741516\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4446   506  0.1022  506 / 4,952\n",
      "     1   410  1150  0.2628  410 / 1,560\n",
      "Totals  4856  1656  0.1407  916 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.31 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995667  4.174359         4.174359       1.000000  0.996719                  1.000000          0.996719      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.993130  4.174359         4.174359       1.000000  0.994281                  1.000000          0.995510      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.988422  4.174359         4.174359       1.000000  0.990937                  1.000000          0.993993      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.982462  4.045917         4.142372       0.969231  0.985709                  0.992337          0.991930      0.040385                 0.166026  304.591716       314.237155            0.165622\n",
      "      5                0.05006143         0.970439  4.110138         4.135945       0.984615  0.977261                  0.990798          0.989005      0.041026                 0.207051  311.013807       313.594463            0.206445\n",
      "      6                0.10012285         0.813862  3.457291         3.796618       0.828221  0.898360                  0.909509          0.943682      0.173077                 0.380128  245.729118       279.661790            0.368214\n",
      "      7                0.15003071         0.661324  2.735811         3.443739       0.655385  0.742357                  0.824974          0.876711      0.136538                 0.516667  173.581065       244.373934            0.482135\n",
      "      8                0.20009214         0.529834  2.317666         3.162005       0.555215  0.595833                  0.757483          0.806438      0.116026                 0.632692  131.766557       216.200484            0.568880\n",
      "      9                0.30006143         0.294569  1.699240         2.674666       0.407066  0.403022                  0.640737          0.672035      0.169872                 0.802564   69.923983       167.466604            0.660803\n",
      "     10                0.40003071         0.156485  1.045193         2.267454       0.250384  0.219732                  0.543186          0.559002      0.104487                 0.907051    4.519280       126.745411            0.666744\n",
      "     11                0.50000000         0.071334  0.532215         1.920513       0.127496  0.110448                  0.460074          0.469319      0.053205                 0.960256  -46.778526        92.051282            0.605248\n",
      "     12                0.59996929         0.030959  0.243665         1.641110       0.058372  0.047910                  0.393141          0.399102      0.024359                 0.984615  -75.633542        64.110965            0.505819\n",
      "     13                0.69993857         0.013915  0.089771         1.419538       0.021505  0.021626                  0.340061          0.345189      0.008974                 0.993590  -91.022884        41.953848            0.386158\n",
      "     14                0.79990786         0.006255  0.044886         1.247740       0.010753  0.009534                  0.298906          0.303240      0.004487                 0.998077  -95.511442        24.773986            0.260597\n",
      "     15                0.89987715         0.002414  0.012824         1.110550       0.003072  0.004065                  0.266041          0.270004      0.001282                 0.999359  -98.717555        11.055045            0.130821\n",
      "     16                1.00000000         0.000291  0.006402         1.000000       0.001534  0.001406                  0.239558          0.243111      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3820.717285          1.000000   0.181344\n",
      "                      capital_gain         3541.795654          0.926998   0.168106\n",
      "                               age         2186.506592          0.572276   0.103779\n",
      "                            fnlwgt         1871.666504          0.489873   0.088836\n",
      "marital_status. Married-civ-spouse         1541.854126          0.403551   0.073182\n",
      "                      capital_loss         1235.700806          0.323421   0.058651\n",
      "                    hours_per_week         1210.818970          0.316909   0.057470\n",
      "              education. Bachelors          736.497192          0.192764   0.034957\n",
      "        occupation. Prof-specialty          581.694885          0.152248   0.027609\n",
      "       occupation. Exec-managerial          558.510315          0.146179   0.026509\n",
      "---\n",
      "             education. Assoc-acdm           15.646690          0.004095   0.000743\n",
      "                 native_country.NA           14.062036          0.003680   0.000667\n",
      "              workclass. State-gov            9.972363          0.002610   0.000473\n",
      "           relationship. Unmarried            9.174633          0.002401   0.000435\n",
      "         marital_status. Separated            8.163152          0.002137   0.000387\n",
      "                   education. 12th            7.714605          0.002019   0.000366\n",
      "          race. Amer-Indian-Eskimo            6.894102          0.001804   0.000327\n",
      "      relationship. Other-relative            5.539434          0.001450   0.000263\n",
      "                      workclass.NA            4.901551          0.001283   0.000233\n",
      "                education. 5th-6th            4.151810          0.001087   0.000197\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        91958.906250          1.000000   0.129111\n",
      "                            fnlwgt        89055.125000          0.968423   0.125034\n",
      "                      capital_gain        72591.515625          0.789391   0.101919\n",
      "                      capital_loss        67983.914063          0.739286   0.095450\n",
      "                    hours_per_week        63289.781250          0.688240   0.088860\n",
      "             relationship. Husband        20054.050781          0.218076   0.028156\n",
      "marital_status. Married-civ-spouse        19661.484375          0.213807   0.027605\n",
      "              education. Bachelors        17552.599609          0.190874   0.024644\n",
      "                education. Masters        13465.615234          0.146431   0.018906\n",
      "        occupation. Prof-specialty        12918.021484          0.140476   0.018137\n",
      "---\n",
      "          marital_status. Divorced         2235.865967          0.024314   0.003139\n",
      "           relationship. Unmarried         2118.826416          0.023041   0.002975\n",
      "              workclass. State-gov         1983.340088          0.021568   0.002785\n",
      "             education. Assoc-acdm         1894.797485          0.020605   0.002660\n",
      "                       race. Black         1453.846558          0.015810   0.002041\n",
      "                education. 5th-6th         1389.220825          0.015107   0.001950\n",
      "          race. Amer-Indian-Eskimo         1368.539429          0.014882   0.001921\n",
      "      relationship. Other-relative         1299.182373          0.014128   0.001824\n",
      "      occupation. Transport-moving         1245.741089          0.013547   0.001749\n",
      "                      workclass.NA          286.049194          0.003111   0.000402\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          726.000000          1.000000   0.295603\n",
      "                         age          525.000000          0.723140   0.213762\n",
      "              hours_per_week          243.000000          0.334711   0.098941\n",
      "                capital_gain           77.000000          0.106061   0.031352\n",
      "          education. HS-grad           68.000000          0.093664   0.027687\n",
      "          workclass. Private           68.000000          0.093664   0.027687\n",
      "                capital_loss           67.000000          0.092287   0.027280\n",
      "        education. Bachelors           51.000000          0.070248   0.020765\n",
      "  occupation. Prof-specialty           49.000000          0.067493   0.019951\n",
      " occupation. Exec-managerial           41.000000          0.056474   0.016694\n",
      "---\n",
      "           native_country.NA            4.000000          0.005510   0.001629\n",
      "              education. 9th            4.000000          0.005510   0.001629\n",
      "   marital_status. Separated            3.000000          0.004132   0.001221\n",
      "        workclass. State-gov            3.000000          0.004132   0.001221\n",
      "       education. Assoc-acdm            3.000000          0.004132   0.001221\n",
      "             education. 12th            2.000000          0.002755   0.000814\n",
      "relationship. Other-relative            1.000000          0.001377   0.000407\n",
      "                workclass.NA            1.000000          0.001377   0.000407\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001377   0.000407\n",
      "          education. 5th-6th            1.000000          0.001377   0.000407\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      " 2023-10-20 18:27:02  3.656 sec              20       0.28386          0.25761      0.94111         0.85729       4.14727                       0.12112         0.30376            0.28966        0.92292           0.81184         4.17436                         0.14251\n",
      " 2023-10-20 18:27:03  4.306 sec              25       0.28045          0.25175      0.94376         0.86330       4.14727                       0.11866         0.30403            0.29026        0.92265           0.81206         4.17436                         0.14865\n",
      " 2023-10-20 18:27:03  5.191 sec              30       0.27646          0.24550      0.94683         0.87050       4.14727                       0.10995         0.30499            0.29186        0.92184           0.81064         4.17436                         0.13560\n",
      " 2023-10-20 18:27:04  5.990 sec              35       0.27357          0.24077      0.94914         0.87550       4.14727                       0.10937         0.30679            0.29477        0.92044           0.80745         4.17436                         0.14066\n",
      "\n",
      "10-20 18:27:05.466 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_62\n",
      "10-20 18:27:05.467 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2957002960187515, 0.29078727474994165, 0.29059384042346914, 0.29229586926118234]\n",
      "10-20 18:27:05.467 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.2957002960187515 --> 0.29059384042346914 (still improving).\n",
      "10-20 18:27:05.475 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_60\n",
      "10-20 18:27:05.490 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:05.492 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_62\n",
      "10-20 18:27:05.513 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:05.513) \n",
      "10-20 18:27:05.559 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:05.559) \n",
      "10-20 18:27:05.602 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:05.602) \n",
      "10-20 18:27:05.652 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:05.652) \n",
      "10-20 18:27:05.706 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:05.706) \n",
      "█10-20 18:27:05.833 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_63\n",
      "10-20 18:27:05.839 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_64\n",
      "10-20 18:27:05.848 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_64\n",
      "10-20 18:27:05.854 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_65\n",
      "10-20 18:27:05.867 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07472883\n",
      " RMSE: 0.27336574\n",
      " AUC: 0.9499467\n",
      " pr_auc: 0.8759019\n",
      " logloss: 0.23982003\n",
      " mean_per_class_error: 0.13319282\n",
      " default threshold: 0.35625898838043213\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17846  1899  0.0962  1,899 / 19,745\n",
      "     1   1073  5231  0.1702   1,073 / 6,304\n",
      "Totals  18919  7130  0.1141  2,972 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.994941  4.132138         4.132138       1.000000  0.996311                  1.000000          0.996311      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.992369  4.132138         4.132138       1.000000  0.993750                  1.000000          0.995033      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.988568  4.132138         4.132138       1.000000  0.990606                  1.000000          0.993555      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.981410  4.116245         4.128173       0.996154  0.985151                  0.999040          0.991458      0.041085                 0.165133   311.624549       312.817274            0.165083\n",
      "      5                0.05002111         0.970039  4.068811         4.116282       0.984674  0.976026                  0.996163          0.988367      0.040768                 0.205901   306.881053       311.628208            0.205648\n",
      "      6                0.10000384         0.812188  3.887765         4.002067       0.940860  0.894436                  0.968522          0.941420      0.194321                 0.400222   288.776455       300.206718            0.396069\n",
      "      7                0.15002495         0.667102  3.244188         3.749376       0.785111  0.739504                  0.907369          0.874097      0.162278                 0.562500   224.418842       274.937628            0.544166\n",
      "      8                0.20000768         0.526583  2.570685         3.454817       0.622120  0.596770                  0.836084          0.804792      0.128490                 0.690990   157.068513       245.481661            0.647738\n",
      "      9                0.30001152         0.303629  1.744857         2.884830       0.422265  0.408485                  0.698145          0.672690      0.174492                 0.865482    74.485687       188.483003            0.746009\n",
      "     10                0.40001536         0.149784  0.821669         2.369040       0.198848  0.219982                  0.573321          0.559513      0.082170                 0.947652   -17.833104       136.903977            0.722481\n",
      "     11                0.50001919         0.070088  0.336282         1.962488       0.081382  0.105555                  0.474933          0.468721      0.033629                 0.981282   -66.371849        96.248811            0.634916\n",
      "     12                0.59998464         0.030424  0.126947         1.656663       0.030722  0.048158                  0.400921          0.398650      0.012690                 0.993972   -87.305259        65.666253            0.519776\n",
      "     13                0.69998848         0.013863  0.042828         1.426102       0.010365  0.020797                  0.345124          0.344668      0.004283                 0.998255   -95.717169        42.610214            0.393494\n",
      "     14                0.79999232         0.006265  0.014276         1.249615       0.003455  0.009695                  0.302414          0.302794      0.001428                 0.999683   -98.572390        24.961542            0.263446\n",
      "     15                0.89999616         0.002382  0.003172         1.111116       0.000768  0.004080                  0.268896          0.269602      0.000317                 1.000000   -99.682753        11.111585            0.131932\n",
      "     16                1.00000000         0.000261  0.000000         1.000000       0.000000  0.001291                  0.242005          0.242770      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09483878\n",
      " RMSE: 0.30795908\n",
      " AUC: 0.91594106\n",
      " pr_auc: 0.80103934\n",
      " logloss: 0.29865468\n",
      " mean_per_class_error: 0.18588133\n",
      " default threshold: 0.4127545952796936\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4472   503  0.1011  503 / 4,975\n",
      "     1   416  1121  0.2707  416 / 1,537\n",
      "Totals  4888  1624  0.1411  919 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.25 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994499  4.236825         4.236825       1.000000  0.996069                  1.000000          0.996069      0.042941                 0.042941   323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.991673  4.236825         4.236825       1.000000  0.993093                  1.000000          0.994592      0.042290                 0.085231   323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.986737  4.171643         4.215209       0.984615  0.989704                  0.994898          0.992971      0.041640                 0.126871   317.164306       321.520853            0.126670\n",
      "      4                0.04007985         0.977813  4.236825         4.220592       1.000000  0.982275                  0.996169          0.990307      0.042290                 0.169161   323.682498       322.059194            0.168960\n",
      "      5                0.05006143         0.959135  4.236825         4.223829       1.000000  0.970071                  0.996933          0.986272      0.042290                 0.211451   323.682498       322.382859            0.211250\n",
      "      6                0.10012285         0.798667  3.431048         3.827439       0.809816  0.883309                  0.903374          0.934791      0.171763                 0.383214   243.104845       282.743852            0.370551\n",
      "      7                0.15003071         0.652489  2.763714         3.473589       0.652308  0.730549                  0.819857          0.866850      0.137931                 0.521145   176.371353       247.358937            0.485768\n",
      "      8                0.20009214         0.513841  2.365344         3.196315       0.558282  0.580567                  0.754413          0.795224      0.118412                 0.639558   136.534401       219.631539            0.575236\n",
      "      9                0.30006143         0.314911  1.561963         2.651810       0.368664  0.410808                  0.625896          0.667151      0.156148                 0.795706    56.196313       165.181011            0.648771\n",
      "     10                0.40003071         0.158063  1.008768         2.241207       0.238095  0.230640                  0.528983          0.558065      0.100846                 0.896552     0.876785       124.120723            0.649919\n",
      "     11                0.50000000         0.069985  0.637802         1.920625       0.150538  0.109045                  0.453317          0.468289      0.063761                 0.960312   -36.219839        92.062459            0.602523\n",
      "     12                0.59996929         0.029688  0.188737         1.632051       0.044547  0.047525                  0.385206          0.398179      0.018868                 0.979180   -81.126279        63.205058            0.496366\n",
      "     13                0.69993857         0.014059  0.091115         1.411965       0.021505  0.020485                  0.333260          0.344235      0.009109                 0.988289   -90.888548        41.196515            0.377435\n",
      "     14                0.79990786         0.006330  0.097623         1.247704       0.023041  0.010006                  0.294490          0.302464      0.009759                 0.998048   -90.237730        24.770388            0.259355\n",
      "     15                0.89987715         0.002446  0.019525         1.111263       0.004608  0.004175                  0.262287          0.269327      0.001952                 1.000000   -98.047546        11.126280            0.131055\n",
      "     16                1.00000000         0.000318  0.000000         1.000000       0.000000  0.001296                  0.236026          0.242491      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4161.180176          1.000000   0.196780\n",
      "                      capital_gain         3481.997559          0.836781   0.164661\n",
      "                               age         2254.846924          0.541877   0.106630\n",
      "                            fnlwgt         1941.722168          0.466628   0.091823\n",
      "marital_status. Married-civ-spouse         1469.264893          0.353089   0.069481\n",
      "                      capital_loss         1233.536621          0.296439   0.058333\n",
      "                    hours_per_week         1179.368164          0.283422   0.055772\n",
      "              education. Bachelors          718.700500          0.172716   0.033987\n",
      "        occupation. Prof-specialty          526.745728          0.126586   0.024909\n",
      "       occupation. Exec-managerial          508.870728          0.122290   0.024064\n",
      "---\n",
      "                     occupation.NA           14.503084          0.003485   0.000686\n",
      "              workclass. State-gov           13.679756          0.003287   0.000647\n",
      "                 native_country.NA            9.256384          0.002224   0.000438\n",
      "          race. Asian-Pac-Islander            9.227043          0.002217   0.000436\n",
      "                      workclass.NA            7.304838          0.001755   0.000345\n",
      "          race. Amer-Indian-Eskimo            5.838183          0.001403   0.000276\n",
      "                education. 5th-6th            5.686970          0.001367   0.000269\n",
      "      relationship. Other-relative            4.376630          0.001052   0.000207\n",
      "         marital_status. Separated            1.875626          0.000451   0.000089\n",
      "           marital_status. Widowed            1.797873          0.000432   0.000085\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        98596.882813          1.000000   0.140817\n",
      "                            fnlwgt        97223.445313          0.986070   0.138856\n",
      "                      capital_gain        72600.398438          0.736336   0.103689\n",
      "                      capital_loss        64136.128906          0.650488   0.091600\n",
      "                    hours_per_week        54320.667969          0.550937   0.077581\n",
      "marital_status. Married-civ-spouse        21687.701172          0.219963   0.030975\n",
      "             relationship. Husband        18880.230469          0.191489   0.026965\n",
      "              education. Bachelors        15773.261719          0.159977   0.022528\n",
      "        occupation. Prof-specialty        14235.151367          0.144377   0.020331\n",
      "                education. Masters        12988.823242          0.131737   0.018551\n",
      "---\n",
      "          occupation. Adm-clerical         1800.479980          0.018261   0.002571\n",
      "          marital_status. Divorced         1687.844849          0.017119   0.002411\n",
      "           relationship. Unmarried         1540.066040          0.015620   0.002200\n",
      "          race. Asian-Pac-Islander         1430.474731          0.014508   0.002043\n",
      "          race. Amer-Indian-Eskimo         1420.591553          0.014408   0.002029\n",
      "      relationship. Other-relative         1396.271484          0.014161   0.001994\n",
      "                education. 5th-6th         1351.620972          0.013709   0.001930\n",
      "              workclass. Local-gov         1277.941284          0.012961   0.001825\n",
      "         marital_status. Separated          964.407288          0.009781   0.001377\n",
      "           marital_status. Widowed          832.821777          0.008447   0.001189\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          797.000000          1.000000   0.317530\n",
      "                         age          563.000000          0.706399   0.224303\n",
      "              hours_per_week          228.000000          0.286073   0.090837\n",
      "                capital_gain           77.000000          0.096612   0.030677\n",
      "                capital_loss           72.000000          0.090339   0.028685\n",
      "          workclass. Private           64.000000          0.080301   0.025498\n",
      "          education. HS-grad           61.000000          0.076537   0.024303\n",
      "        education. Bachelors           57.000000          0.071518   0.022709\n",
      "  occupation. Prof-specialty           52.000000          0.065245   0.020717\n",
      " occupation. Exec-managerial           40.000000          0.050188   0.015936\n",
      "---\n",
      "              education. 9th            4.000000          0.005019   0.001594\n",
      "               occupation.NA            3.000000          0.003764   0.001195\n",
      "    race. Asian-Pac-Islander            3.000000          0.003764   0.001195\n",
      "           native_country.NA            3.000000          0.003764   0.001195\n",
      "                workclass.NA            2.000000          0.002509   0.000797\n",
      "     marital_status. Widowed            1.000000          0.001255   0.000398\n",
      "relationship. Other-relative            1.000000          0.001255   0.000398\n",
      "   marital_status. Separated            1.000000          0.001255   0.000398\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001255   0.000398\n",
      "          education. 5th-6th            1.000000          0.001255   0.000398\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      " 2023-10-20 18:27:02  3.948 sec              20       0.28375          0.25710      0.94156         0.85776       4.13214                       0.11977         0.30632            0.29578        0.91635           0.80451         4.23682                         0.13851\n",
      " 2023-10-20 18:27:03  4.624 sec              25       0.28033          0.25097      0.94441         0.86363       4.13214                       0.11594         0.30676            0.29629        0.91661           0.80377         4.23682                         0.14235\n",
      " 2023-10-20 18:27:04  5.552 sec              30       0.27657          0.24498      0.94738         0.87019       4.13214                       0.11233         0.30712            0.29718        0.91640           0.80334         4.23682                         0.13790\n",
      " 2023-10-20 18:27:05  6.375 sec              35       0.27337          0.23982      0.94995         0.87590       4.13214                       0.11409         0.30796            0.29865        0.91594           0.80104         4.23682                         0.14112\n",
      "\n",
      "10-20 18:27:05.870 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.30200096254015674, 0.29704341270984735, 0.2964181317290027, 0.29737577411809873]\n",
      "10-20 18:27:05.870 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.30200096254015674 --> 0.2964181317290027 (still improving).\n",
      "10-20 18:27:05.878 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_63\n",
      "10-20 18:27:05.884 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.07581918\n",
      " RMSE: 0.27535284\n",
      " AUC: 0.9479108\n",
      " pr_auc: 0.8695351\n",
      " logloss: 0.24281898\n",
      " mean_per_class_error: 0.13547167\n",
      " default threshold: 0.34436723589897156\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17842  1991  0.1004  1,991 / 19,833\n",
      "     1   1060  5155  0.1706   1,060 / 6,215\n",
      "Totals  18902  7146  0.1171  3,051 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.81 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.996190  4.191150         4.191150       1.000000  0.997535                  1.000000          0.997535      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.992621  4.191150         4.191150       1.000000  0.994577                  1.000000          0.996059      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.986823  4.191150         4.191150       1.000000  0.990092                  1.000000          0.994067      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.977097  4.191150         4.191150       1.000000  0.982508                  1.000000          0.991183      0.041834                 0.167659   319.115044       319.115044            0.167659\n",
      "      5                0.05002303         0.958541  4.094802         4.171851       0.977011  0.969199                  0.995395          0.986779      0.041030                 0.208689   309.480216       317.185121            0.208386\n",
      "      6                0.10000768         0.795058  3.882126         4.027044       0.926267  0.880261                  0.960845          0.933541      0.194047                 0.402735   288.212553       302.704398            0.397592\n",
      "      7                0.15003071         0.642002  3.287303         3.780401       0.784344  0.717259                  0.901996          0.861428      0.164441                 0.567176   228.730296       278.040054            0.547865\n",
      "      8                0.20001536         0.508763  2.559113         3.475196       0.610599  0.575243                  0.829175          0.789910      0.127916                 0.695093   155.911260       247.519576            0.650218\n",
      "      9                0.30002303         0.298040  1.660371         2.870254       0.396161  0.395194                  0.684837          0.658338      0.166050                 0.861142    66.037131       187.025428            0.736955\n",
      "     10                0.39999232         0.152281  0.835333         2.361670       0.199309  0.219655                  0.563490          0.548699      0.083508                 0.944650   -16.466702       136.167043            0.715335\n",
      "     11                0.50000000         0.069395  0.357173         1.960740       0.085221  0.105740                  0.467829          0.460100      0.035720                 0.980370   -64.282710        96.074014            0.630902\n",
      "     12                0.60000768         0.029789  0.131929         1.655919       0.031478  0.046684                  0.395099          0.391193      0.013194                 0.993564   -86.807127        65.591874            0.516884\n",
      "     13                0.69997697         0.013112  0.045066         1.425860       0.010753  0.020234                  0.340207          0.338213      0.004505                 0.998069   -95.493387        42.586004            0.391504\n",
      "     14                0.79998464         0.005771  0.016089         1.249622       0.003839  0.009012                  0.298157          0.297059      0.001609                 0.999678   -98.391113        24.962173            0.262271\n",
      "     15                0.89999232         0.002069  0.003218         1.111121       0.000768  0.003694                  0.265111          0.264460      0.000322                 1.000000   -99.678223        11.112059            0.131347\n",
      "     16                1.00000000         0.000278  0.000000         1.000000       0.000000  0.001174                  0.238598          0.238130      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09202859\n",
      " RMSE: 0.30336213\n",
      " AUC: 0.92597467\n",
      " pr_auc: 0.82828385\n",
      " logloss: 0.28825706\n",
      " mean_per_class_error: 0.17159332\n",
      " default threshold: 0.3638858199119568\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4379   508  0.1039  508 / 4,887\n",
      "     1   389  1237  0.2392  389 / 1,626\n",
      "Totals  4768  1745  0.1377  897 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.02 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.995569  4.005535         4.005535       1.000000  0.997252                  1.000000          0.997252      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.992916  4.005535         4.005535       1.000000  0.994358                  1.000000          0.995816      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.988257  4.005535         4.005535       1.000000  0.990766                  1.000000          0.994141      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.977818  4.005535         4.005535       1.000000  0.982873                  1.000000          0.991335      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.962481  3.943911         3.993248       0.984615  0.970126                  0.996933          0.987106      0.039360                 0.199877   294.391144       299.324814            0.199672\n",
      "      6                0.10010748         0.804078  3.501771         3.747510       0.874233  0.890837                  0.935583          0.938971      0.175277                 0.375154   250.177144       274.750979            0.366560\n",
      "      7                0.15000768         0.645519  2.871661         3.456158       0.716923  0.723692                  0.862845          0.867359      0.143296                 0.518450   187.166052       245.615768            0.491030\n",
      "      8                0.20006142         0.516885  2.334514         3.175532       0.582822  0.582263                  0.792786          0.796030      0.116851                 0.635301   133.451430       217.553163            0.580053\n",
      "      9                0.30001535         0.296632  1.692046         2.681290       0.422427  0.401816                  0.669396          0.664693      0.169127                 0.804428    69.204630       168.128959            0.672241\n",
      "     10                0.39996929         0.150329  1.033686         2.269547       0.258065  0.219978                  0.566603          0.553557      0.103321                 0.907749     3.368647       126.954693            0.676728\n",
      "     11                0.50007677         0.070455  0.565198         1.928363       0.141104  0.106394                  0.481425          0.464042      0.056581                 0.964330   -43.480180        92.836321            0.618719\n",
      "     12                0.60003071         0.030090  0.190740         1.638908       0.047619  0.047880                  0.409161          0.394717      0.019065                 0.983395   -80.926024        63.890751            0.510917\n",
      "     13                0.69998465         0.012876  0.141517         1.425088       0.035330  0.019897                  0.355780          0.341195      0.014145                 0.997540   -85.848340        42.508837            0.396558\n",
      "     14                0.79993858         0.005927  0.024612         1.250096       0.006144  0.008960                  0.312092          0.299681      0.002460                 1.000000   -97.538842        25.009597            0.266626\n",
      "     15                0.89989252         0.002188  0.000000         1.111244       0.000000  0.003863                  0.277427          0.266824      0.000000                 1.000000  -100.000000        11.124382            0.133415\n",
      "     16                1.00000000         0.000318  0.000000         1.000000       0.000000  0.001231                  0.249655          0.240236      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4153.499023          1.000000   0.203943\n",
      "                      capital_gain         3285.845947          0.791103   0.161340\n",
      "             relationship. Husband         1866.736450          0.449437   0.091659\n",
      "                               age         1854.680420          0.446534   0.091067\n",
      "                            fnlwgt         1713.930542          0.412647   0.084156\n",
      "                    hours_per_week         1259.200195          0.303166   0.061829\n",
      "                      capital_loss         1142.169434          0.274990   0.056082\n",
      "        occupation. Prof-specialty          634.604248          0.152788   0.031160\n",
      "              education. Bachelors          557.900452          0.134321   0.027394\n",
      "       occupation. Exec-managerial          524.938293          0.126385   0.025775\n",
      "---\n",
      "           relationship. Unmarried           14.442497          0.003477   0.000709\n",
      "          race. Asian-Pac-Islander           13.720805          0.003303   0.000674\n",
      "              workclass. State-gov           12.894225          0.003104   0.000633\n",
      "                       race. Black           12.484092          0.003006   0.000613\n",
      "                     occupation.NA           10.518503          0.002532   0.000516\n",
      "           marital_status. Widowed            9.016663          0.002171   0.000443\n",
      "                education. 5th-6th            7.998797          0.001926   0.000393\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001911   0.000390\n",
      "                   education. 12th            3.699208          0.000891   0.000182\n",
      "                 native_country.NA            0.795650          0.000192   0.000039\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        96187.437500          1.000000   0.136176\n",
      "                      capital_gain        83733.898438          0.870528   0.118545\n",
      "                               age        81142.835938          0.843591   0.114876\n",
      "                    hours_per_week        60200.468750          0.625866   0.085228\n",
      "                      capital_loss        56056.175781          0.582781   0.079360\n",
      "marital_status. Married-civ-spouse        28718.912109          0.298572   0.040658\n",
      "              education. Bachelors        17306.615234          0.179926   0.024502\n",
      "        occupation. Prof-specialty        14935.278320          0.155273   0.021144\n",
      "              education. Doctorate        14506.331055          0.150813   0.020537\n",
      "       occupation. Exec-managerial        14189.700195          0.147521   0.020089\n",
      "---\n",
      "       relationship. Not-in-family         2460.240723          0.025578   0.003483\n",
      "           relationship. Unmarried         2243.961426          0.023329   0.003177\n",
      "                     occupation.NA         1834.313965          0.019070   0.002597\n",
      "                   education. 12th         1397.228027          0.014526   0.001978\n",
      "          race. Amer-Indian-Eskimo         1349.694214          0.014032   0.001911\n",
      "          marital_status. Divorced         1100.038208          0.011436   0.001557\n",
      "          race. Asian-Pac-Islander         1095.846313          0.011393   0.001551\n",
      "                education. 5th-6th         1003.292114          0.010431   0.001420\n",
      "                         sex. Male          729.991150          0.007589   0.001033\n",
      "                 native_country.NA           86.905121          0.000903   0.000123\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          664.000000          1.000000   0.283156\n",
      "                         age          476.000000          0.716867   0.202985\n",
      "              hours_per_week          252.000000          0.379518   0.107463\n",
      "                capital_gain           79.000000          0.118976   0.033689\n",
      "          workclass. Private           70.000000          0.105422   0.029851\n",
      "                capital_loss           60.000000          0.090361   0.025586\n",
      "          education. HS-grad           59.000000          0.088855   0.025160\n",
      "  occupation. Prof-specialty           54.000000          0.081325   0.023028\n",
      "        education. Bachelors           49.000000          0.073795   0.020896\n",
      "     education. Some-college           41.000000          0.061747   0.017484\n",
      "---\n",
      "               occupation.NA            4.000000          0.006024   0.001706\n",
      "    race. Asian-Pac-Islander            4.000000          0.006024   0.001706\n",
      "        workclass. State-gov            4.000000          0.006024   0.001706\n",
      "     marital_status. Widowed            3.000000          0.004518   0.001279\n",
      "relationship. Other-relative            3.000000          0.004518   0.001279\n",
      "      native_country. Mexico            3.000000          0.004518   0.001279\n",
      "             education. 12th            1.000000          0.001506   0.000426\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001506   0.000426\n",
      "           native_country.NA            1.000000          0.001506   0.000426\n",
      "          education. 5th-6th            1.000000          0.001506   0.000426\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      " 2023-10-20 18:27:02  3.900 sec              20       0.28552          0.26048      0.93937         0.85104       4.19115                       0.12312         0.30193            0.28685        0.92659           0.83134         4.00554                         0.14156\n",
      " 2023-10-20 18:27:03  4.463 sec              25       0.28224          0.25428      0.94224         0.85712       4.19115                       0.11794         0.30272            0.28782        0.92593           0.83002         4.00554                         0.13588\n",
      " 2023-10-20 18:27:04  5.318 sec              30       0.27855          0.24808      0.94518         0.86390       4.19115                       0.11548         0.30224            0.28670        0.92653           0.83070         4.00554                         0.14110\n",
      " 2023-10-20 18:27:05  6.505 sec              35       0.27535          0.24282      0.94791         0.86954       4.19115                       0.11713         0.30336            0.28826        0.92597           0.82828         4.00554                         0.13772\n",
      "\n",
      "10-20 18:27:05.888 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.294150910592242, 0.28810012827421844, 0.2871255414995885, 0.2875938874638124]\n",
      "10-20 18:27:05.888 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.294150910592242 --> 0.2871255414995885 (still improving).\n",
      "10-20 18:27:05.896 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_65\n",
      "10-20 18:27:05.908 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07512851\n",
      " RMSE: 0.2740958\n",
      " AUC: 0.9489551\n",
      " pr_auc: 0.87477875\n",
      " logloss: 0.24179603\n",
      " mean_per_class_error: 0.14565064\n",
      " default threshold: 0.42709478735923767\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18370  1368  0.0693  1,368 / 19,738\n",
      "     1   1401  4910  0.2220   1,401 / 6,311\n",
      "Totals  19771  6278  0.1063  2,769 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.33 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995336  4.127555         4.127555       1.000000  0.996646                  1.000000          0.996646      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.992882  4.127555         4.127555       1.000000  0.994118                  1.000000          0.995384      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.988644  4.127555         4.127555       1.000000  0.990937                  1.000000          0.993900      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.981455  4.095805         4.119633       0.992308  0.985590                  0.998081          0.991827      0.040881                 0.164792   309.580464       311.963269            0.164690\n",
      "      5                0.05002111         0.967938  4.064298         4.108549       0.984674  0.975287                  0.995395          0.988513      0.040723                 0.205514   306.429751       310.854867            0.205210\n",
      "      6                0.10000384         0.811101  3.877112         3.992875       0.939324  0.894386                  0.967370          0.941468      0.193789                 0.399303   287.711201       299.287476            0.394996\n",
      "      7                0.15002495         0.666149  3.269100         3.751555       0.792018  0.736836                  0.908905          0.873240      0.163524                 0.562827   226.909964       275.155465            0.544791\n",
      "      8                0.20000768         0.528058  2.596365         3.462868       0.629032  0.596120                  0.838964          0.803986      0.129773                 0.692600   159.636528       246.286817            0.650093\n",
      "      9                0.30001152         0.310570  1.695387         2.873708       0.410749  0.411748                  0.696225          0.673240      0.169545                 0.862145    69.538730       187.370788            0.741870\n",
      "     10                0.40001536         0.153374  0.825511         2.361659       0.200000  0.224242                  0.572169          0.560991      0.082554                 0.944700   -17.448899       136.165866            0.718841\n",
      "     11                0.50001919         0.070169  0.356507         1.960628       0.086372  0.107210                  0.475010          0.470235      0.035652                 0.980352   -64.349332        96.062827            0.633913\n",
      "     12                0.59998464         0.030434  0.115711         1.653240       0.028034  0.047350                  0.400537          0.399776      0.011567                 0.991919   -88.428897        65.324043            0.517251\n",
      "     13                0.69998848         0.013535  0.063379         1.426105       0.015355  0.020821                  0.345508          0.345637      0.006338                 0.998257   -93.662104        42.610491            0.393636\n",
      "     14                0.79999232         0.005851  0.015845         1.249814       0.003839  0.009264                  0.302798          0.303588      0.001585                 0.999842   -98.415526        24.981393            0.263749\n",
      "     15                0.89999616         0.002047  0.000000         1.110940       0.000000  0.003696                  0.269152          0.270266      0.000000                 0.999842  -100.000000        11.093979            0.131770\n",
      "     16                1.00000000         0.000246  0.001584         1.000000       0.000384  0.001076                  0.242274          0.243346      0.000158                 1.000000   -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09082276\n",
      " RMSE: 0.30136815\n",
      " AUC: 0.92321265\n",
      " pr_auc: 0.8140365\n",
      " logloss: 0.28518265\n",
      " mean_per_class_error: 0.17513336\n",
      " default threshold: 0.3674834966659546\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4432   550  0.1104  550 / 4,982\n",
      "     1   367  1163  0.2399  367 / 1,530\n",
      "Totals  4799  1713  0.1408  917 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.81 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994911  4.256209         4.256209       1.000000  0.996282                  1.000000          0.996282      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.992507  4.256209         4.256209       1.000000  0.993905                  1.000000          0.995102      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.988447  4.190729         4.234494       0.984615  0.990665                  0.994898          0.993631      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.980939  4.256209         4.239902       1.000000  0.984854                  0.996169          0.991445      0.042484                 0.169935   325.620915       323.990184            0.169734\n",
      "      5                0.05006143         0.963313  4.125249         4.217042       0.969231  0.973450                  0.990798          0.987857      0.041176                 0.211111   312.524887       321.704158            0.210509\n",
      "      6                0.10012285         0.801103  3.668696         3.942869       0.861963  0.887874                  0.926380          0.937866      0.183660                 0.394771   266.869562       294.286860            0.385137\n",
      "      7                0.15003071         0.646166  2.854934         3.580966       0.670769  0.721685                  0.841351          0.865953      0.142484                 0.537255   185.493414       258.096614            0.506143\n",
      "      8                0.20009214         0.508616  2.284775         3.256670       0.536810  0.568460                  0.765157          0.791523      0.114379                 0.651634   128.477485       225.666963            0.590213\n",
      "      9                0.30006143         0.294414  1.575647         2.696616       0.370200  0.396118                  0.633572          0.659788      0.157516                 0.809150    57.564732       169.661562            0.665433\n",
      "     10                0.40003071         0.149077  0.980693         2.267800       0.230415  0.214000                  0.532821          0.548384      0.098039                 0.907190    -1.930665       126.779973            0.662910\n",
      "     11                0.50000000         0.069592  0.549188         1.924183       0.129032  0.104780                  0.452088          0.459690      0.054902                 0.962092   -45.081172        92.418301            0.604002\n",
      "     12                0.59996929         0.030562  0.287670         1.651501       0.067588  0.048131                  0.388021          0.391115      0.028758                 0.990850   -71.232995        65.150066            0.510922\n",
      "     13                0.69993857         0.013643  0.058842         1.424028       0.013825  0.020950                  0.334577          0.338246      0.005882                 0.996732   -94.115840        42.402785            0.387940\n",
      "     14                0.79990786         0.005723  0.019614         1.248510       0.004608  0.009159                  0.293338          0.297118      0.001961                 0.998693   -98.038613        24.850981            0.259833\n",
      "     15                0.89987715         0.001910  0.013076         1.111263       0.003072  0.003590                  0.261092          0.264509      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000249  0.000000         1.000000       0.000000  0.000983                  0.234951          0.238124      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4110.832031          1.000000   0.194029\n",
      "                      capital_gain         3535.970947          0.860159   0.166896\n",
      "                               age         2342.309326          0.569790   0.110556\n",
      "                            fnlwgt         1898.585449          0.461849   0.089612\n",
      "marital_status. Married-civ-spouse         1495.084595          0.363694   0.070567\n",
      "                      capital_loss         1179.010986          0.286806   0.055649\n",
      "                    hours_per_week         1149.676880          0.279670   0.054264\n",
      "              education. Bachelors          661.622864          0.160946   0.031228\n",
      "       occupation. Exec-managerial          581.386292          0.141428   0.027441\n",
      "        occupation. Prof-specialty          576.046326          0.140129   0.027189\n",
      "---\n",
      "           marital_status. Widowed           17.837631          0.004339   0.000842\n",
      "                       race. Black           15.021633          0.003654   0.000709\n",
      "                     occupation.NA           11.762693          0.002861   0.000555\n",
      "                      workclass.NA            9.695875          0.002359   0.000458\n",
      "           relationship. Unmarried            9.212575          0.002241   0.000435\n",
      "         marital_status. Separated            9.013293          0.002193   0.000425\n",
      "                 native_country.NA            8.301558          0.002019   0.000392\n",
      "              workclass. State-gov            7.262564          0.001767   0.000343\n",
      "                education. 5th-6th            6.929251          0.001686   0.000327\n",
      "          race. Amer-Indian-Eskimo            4.215075          0.001025   0.000199\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       102346.476563          1.000000   0.144982\n",
      "                               age        89935.398438          0.878735   0.127400\n",
      "                      capital_gain        72825.000000          0.711554   0.103162\n",
      "                      capital_loss        58237.500000          0.569023   0.082498\n",
      "                    hours_per_week        54014.281250          0.527759   0.076515\n",
      "             relationship. Husband        20323.101563          0.198572   0.028789\n",
      "marital_status. Married-civ-spouse        17905.720703          0.174952   0.025365\n",
      "              education. Bachelors        15665.782227          0.153066   0.022192\n",
      "       occupation. Exec-managerial        15219.902344          0.148710   0.021560\n",
      "        occupation. Prof-specialty        13989.630859          0.136689   0.019817\n",
      "---\n",
      "             education. Assoc-acdm         2353.236816          0.022993   0.003334\n",
      "                 native_country.NA         2136.068604          0.020871   0.003026\n",
      "              education. Assoc-voc         2037.022705          0.019903   0.002886\n",
      "                     occupation.NA         1970.962646          0.019258   0.002792\n",
      "          marital_status. Divorced         1843.108032          0.018009   0.002611\n",
      "                      workclass.NA         1758.579102          0.017183   0.002491\n",
      "          race. Amer-Indian-Eskimo         1413.515991          0.013811   0.002002\n",
      "           relationship. Unmarried         1412.981201          0.013806   0.002002\n",
      "              workclass. State-gov         1043.810913          0.010199   0.001479\n",
      "                education. 5th-6th          713.308777          0.006970   0.001010\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          738.000000          1.000000   0.293907\n",
      "                        age          563.000000          0.762873   0.224213\n",
      "             hours_per_week          217.000000          0.294038   0.086420\n",
      "         workclass. Private           77.000000          0.104336   0.030665\n",
      "               capital_gain           72.000000          0.097561   0.028674\n",
      "               capital_loss           70.000000          0.094851   0.027877\n",
      "         education. HS-grad           69.000000          0.093496   0.027479\n",
      "       education. Bachelors           62.000000          0.084011   0.024691\n",
      "occupation. Exec-managerial           44.000000          0.059621   0.017523\n",
      " occupation. Prof-specialty           44.000000          0.059621   0.017523\n",
      "---\n",
      "       education. Assoc-voc            4.000000          0.005420   0.001593\n",
      "      education. Assoc-acdm            4.000000          0.005420   0.001593\n",
      "             education. 9th            4.000000          0.005420   0.001593\n",
      "              occupation.NA            3.000000          0.004065   0.001195\n",
      "               workclass.NA            3.000000          0.004065   0.001195\n",
      "  marital_status. Separated            2.000000          0.002710   0.000796\n",
      "       workclass. State-gov            2.000000          0.002710   0.000796\n",
      "          native_country.NA            2.000000          0.002710   0.000796\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.001355   0.000398\n",
      "         education. 5th-6th            1.000000          0.001355   0.000398\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      " 2023-10-20 18:27:02  3.824 sec              20       0.28393          0.25830      0.94145         0.85820       4.12756                       0.12235         0.30044            0.28487        0.92305           0.81492         4.25621                         0.14220\n",
      " 2023-10-20 18:27:03  4.564 sec              25       0.28038          0.25209      0.94407         0.86424       4.12756                       0.11620         0.30086            0.28541        0.92254           0.81423         4.25621                         0.14005\n",
      " 2023-10-20 18:27:04  5.475 sec              30       0.27707          0.24659      0.94663         0.86998       4.12756                       0.11217         0.30131            0.28561        0.92263           0.81393         4.25621                         0.13345\n",
      " 2023-10-20 18:27:05  6.533 sec              35       0.27410          0.24180      0.94896         0.87478       4.12756                       0.10630         0.30137            0.28518        0.92321           0.81404         4.25621                         0.14082\n",
      "\n",
      "10-20 18:27:05.914 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2899789302642067, 0.2856406659875552, 0.28529764870527846, 0.285403418861261]\n",
      "10-20 18:27:05.914 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.2899789302642067 --> 0.28529764870527846 (still improving).\n",
      "10-20 18:27:05.925 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:05.925) \n",
      "10-20 18:27:05.953 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:05.953) \n",
      "10-20 18:27:05.973 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:05.973) \n",
      "10-20 18:27:05.996 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:05.996) \n",
      "10-20 18:27:06.008 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:06.008) \n",
      "10-20 18:27:06.012 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_66\n",
      "10-20 18:27:06.028 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:06.028) \n",
      "10-20 18:27:06.037 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_66\n",
      "10-20 18:27:06.060 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:06.060) \n",
      "10-20 18:27:06.083 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.075 (Wall: 20-Oct 18:27:06.083) \n",
      "10-20 18:27:06.099 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:06.099) \n",
      "10-20 18:27:06.110 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:06.110) \n",
      "10-20 18:27:06.131 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:06.131) \n",
      "10-20 18:27:06.161 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:06.161) \n",
      "10-20 18:27:06.292 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.160 (Wall: 20-Oct 18:27:06.291) \n",
      "10-20 18:27:06.292 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.192 (Wall: 20-Oct 18:27:06.291) \n",
      "10-20 18:27:06.536 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.244 (Wall: 20-Oct 18:27:06.536) \n",
      "10-20 18:27:06.631 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_67\n",
      "10-20 18:27:06.651 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_67\n",
      "10-20 18:27:06.677 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_68\n",
      "10-20 18:27:06.688 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_68\n",
      "10-20 18:27:06.725 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.073237315\n",
      " RMSE: 0.27062392\n",
      " AUC: 0.9513348\n",
      " pr_auc: 0.8799897\n",
      " logloss: 0.23615739\n",
      " mean_per_class_error: 0.13795242\n",
      " default threshold: 0.3944703936576843\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18248  1520  0.0769  1,520 / 19,768\n",
      "     1   1250  5031  0.1990   1,250 / 6,281\n",
      "Totals  19498  6551  0.1063  2,770 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996212  4.147270         4.147270       1.000000  0.997249                  1.000000          0.997249      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.993847  4.147270         4.147270       1.000000  0.995184                  1.000000          0.996218      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.990010  4.147270         4.147270       1.000000  0.992102                  1.000000          0.994844      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.982898  4.131319         4.143289       0.996154  0.986875                  0.999040          0.992856      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05002111         0.970012  4.099600         4.134538       0.988506  0.977668                  0.996930          0.989813      0.041076                 0.206814   309.959978       313.453809            0.206612\n",
      "      6                0.10000384         0.825064  3.924298         4.029458       0.946237  0.897938                  0.971593          0.943894      0.196147                 0.402961   292.429806       302.945843            0.399218\n",
      "      7                0.15002495         0.670386  3.332457         3.797065       0.803530  0.747757                  0.915558          0.878498      0.166693                 0.569655   233.245680       279.706510            0.552961\n",
      "      8                0.20000768         0.520807  2.576913         3.492144       0.621352  0.594095                  0.842035          0.807425      0.128801                 0.698456   157.691326       249.214424            0.656823\n",
      "      9                0.30001152         0.294749  1.679604         2.887964       0.404990  0.401533                  0.696353          0.672127      0.167967                 0.866423    67.960436       188.796428            0.746380\n",
      "     10                0.40001536         0.151624  0.810349         2.368561       0.195393  0.217019                  0.571113          0.558350      0.081038                 0.947461   -18.965060       136.856056            0.721388\n",
      "     11                0.50001919         0.070008  0.342289         1.963306       0.082534  0.106871                  0.473397          0.468054      0.034230                 0.981691   -65.771096        96.330626            0.634716\n",
      "     12                0.59998464         0.030285  0.122634         1.656626       0.029570  0.047152                  0.399450          0.397926      0.012259                 0.993950   -87.736569        65.662574            0.519142\n",
      "     13                0.69998848         0.013128  0.049353         1.427003       0.011900  0.020503                  0.344082          0.344006      0.004936                 0.998886   -95.064670        42.700280            0.393867\n",
      "     14                0.79999232         0.005591  0.006368         1.249415       0.001536  0.008836                  0.301262          0.302107      0.000637                 0.999522   -99.363183        24.941495            0.262928\n",
      "     15                0.89999616         0.001975  0.004776         1.111116       0.001152  0.003580                  0.267915          0.268936      0.000478                 1.000000   -99.522387        11.111585            0.131779\n",
      "     16                1.00000000         0.000223  0.000000         1.000000       0.000000  0.001112                  0.241122          0.242153      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09517617\n",
      " RMSE: 0.30850634\n",
      " AUC: 0.9193489\n",
      " pr_auc: 0.80503285\n",
      " logloss: 0.29748315\n",
      " mean_per_class_error: 0.18119174\n",
      " default threshold: 0.36670634150505066\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4405   547  0.1105  547 / 4,952\n",
      "     1   393  1167  0.2519  393 / 1,560\n",
      "Totals  4798  1714  0.1443  940 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.33 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996340  4.174359         4.174359       1.000000  0.997467                  1.000000          0.997467      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.993832  4.174359         4.174359       1.000000  0.995195                  1.000000          0.996340      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.990112  4.174359         4.174359       1.000000  0.992060                  1.000000          0.994920      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.984488  4.110138         4.158365       0.984615  0.987304                  0.996169          0.993024      0.041026                 0.166667  311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.971830  4.045917         4.135945       0.969231  0.979173                  0.990798          0.990262      0.040385                 0.207051  304.591716       313.594463            0.206445\n",
      "      6                0.10012285         0.825382  3.534120         3.835032       0.846626  0.902750                  0.918712          0.946506      0.176923                 0.383974  253.411987       283.503225            0.373272\n",
      "      7                0.15003071         0.676126  2.633057         3.435194       0.630769  0.752162                  0.822927          0.881857      0.131410                 0.515385  163.305720       243.519408            0.480449\n",
      "      8                0.20009214         0.534177  2.304861         3.152394       0.552147  0.599896                  0.755180          0.811313      0.115385                 0.630769  130.486078       215.239388            0.566351\n",
      "      9                0.30006143         0.292393  1.680003         2.661848       0.402458  0.404337                  0.637666          0.675724      0.167949                 0.798718   68.000315       166.184815            0.655745\n",
      "     10                0.40003071         0.153761  1.102903         2.272261       0.264209  0.216049                  0.544338          0.560849      0.110256                 0.908974   10.290283       127.226143            0.669273\n",
      "     11                0.50000000         0.069751  0.525803         1.923077       0.125960  0.108672                  0.460688          0.470442      0.052564                 0.961538  -47.419749        92.307692            0.606934\n",
      "     12                0.59996929         0.029386  0.250077         1.644315       0.059908  0.046653                  0.393908          0.399828      0.025000                 0.986538  -74.992320        64.431494            0.508348\n",
      "     13                0.69993857         0.012970  0.070534         1.419538       0.016897  0.020164                  0.340061          0.345602      0.007051                 0.993590  -92.946552        41.953848            0.386158\n",
      "     14                0.79990786         0.005681  0.051298         1.248541       0.012289  0.008840                  0.299098          0.303515      0.005128                 0.998718  -94.870219        24.854123            0.261440\n",
      "     15                0.89987715         0.002103  0.006412         1.110550       0.001536  0.003672                  0.266041          0.270205      0.000641                 0.999359  -99.358777        11.055045            0.130821\n",
      "     16                1.00000000         0.000274  0.006402         1.000000       0.001534  0.001184                  0.239558          0.243270      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3821.199219          1.000000   0.175787\n",
      "                      capital_gain         3567.216553          0.933533   0.164103\n",
      "                               age         2291.251221          0.599616   0.105404\n",
      "                            fnlwgt         2219.637207          0.580875   0.102110\n",
      "marital_status. Married-civ-spouse         1548.758911          0.405307   0.071248\n",
      "                    hours_per_week         1262.276611          0.330335   0.058069\n",
      "                      capital_loss         1245.979614          0.326070   0.057319\n",
      "              education. Bachelors          742.360168          0.194274   0.034151\n",
      "        occupation. Prof-specialty          593.354065          0.155280   0.027296\n",
      "       occupation. Exec-managerial          564.880249          0.147828   0.025986\n",
      "---\n",
      "           marital_status. Widowed           16.921299          0.004428   0.000778\n",
      "                 native_country.NA           16.834946          0.004406   0.000774\n",
      "              workclass. State-gov           11.931560          0.003122   0.000549\n",
      "           relationship. Unmarried            9.174633          0.002401   0.000422\n",
      "         marital_status. Separated            8.163152          0.002136   0.000376\n",
      "                   education. 12th            7.714605          0.002019   0.000355\n",
      "          race. Amer-Indian-Eskimo            6.894102          0.001804   0.000317\n",
      "                      workclass.NA            6.740609          0.001764   0.000310\n",
      "      relationship. Other-relative            5.539434          0.001450   0.000255\n",
      "                education. 5th-6th            4.151810          0.001087   0.000191\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       124570.445313          1.000000   0.157037\n",
      "                               age        97207.765625          0.780344   0.122543\n",
      "                      capital_gain        82293.765625          0.660620   0.103742\n",
      "                      capital_loss        71106.273438          0.570812   0.089638\n",
      "                    hours_per_week        68349.265625          0.548680   0.086163\n",
      "             relationship. Husband        20090.976563          0.161282   0.025327\n",
      "marital_status. Married-civ-spouse        19934.738281          0.160028   0.025130\n",
      "              education. Bachelors        17684.382813          0.141963   0.022293\n",
      "                education. Masters        13465.615234          0.108096   0.016975\n",
      "        occupation. Prof-specialty        13254.338867          0.106400   0.016709\n",
      "---\n",
      "             education. Assoc-acdm         2563.472656          0.020578   0.003232\n",
      "          marital_status. Divorced         2333.347168          0.018731   0.002941\n",
      "              workclass. State-gov         2143.855957          0.017210   0.002703\n",
      "           relationship. Unmarried         2118.826416          0.017009   0.002671\n",
      "                       race. Black         1505.673950          0.012087   0.001898\n",
      "                education. 5th-6th         1389.220825          0.011152   0.001751\n",
      "          race. Amer-Indian-Eskimo         1368.539429          0.010986   0.001725\n",
      "      relationship. Other-relative         1299.182373          0.010429   0.001638\n",
      "                      workclass.NA         1247.093750          0.010011   0.001572\n",
      "      occupation. Transport-moving         1245.741089          0.010000   0.001570\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          872.000000          1.000000   0.318016\n",
      "                         age          568.000000          0.651376   0.207148\n",
      "              hours_per_week          268.000000          0.307339   0.097739\n",
      "                capital_gain           85.000000          0.097477   0.030999\n",
      "          workclass. Private           73.000000          0.083716   0.026623\n",
      "          education. HS-grad           72.000000          0.082569   0.026258\n",
      "                capital_loss           71.000000          0.081422   0.025894\n",
      "        education. Bachelors           54.000000          0.061927   0.019694\n",
      "  occupation. Prof-specialty           53.000000          0.060780   0.019329\n",
      " occupation. Exec-managerial           44.000000          0.050459   0.016047\n",
      "---\n",
      "      native_country. Mexico            4.000000          0.004587   0.001459\n",
      "        workclass. State-gov            4.000000          0.004587   0.001459\n",
      "       education. Assoc-acdm            4.000000          0.004587   0.001459\n",
      "              education. 9th            4.000000          0.004587   0.001459\n",
      "   marital_status. Separated            3.000000          0.003440   0.001094\n",
      "             education. 12th            2.000000          0.002294   0.000729\n",
      "                workclass.NA            2.000000          0.002294   0.000729\n",
      "relationship. Other-relative            1.000000          0.001147   0.000365\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001147   0.000365\n",
      "          education. 5th-6th            1.000000          0.001147   0.000365\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      " 2023-10-20 18:27:02  3.656 sec              20       0.28386          0.25761      0.94111         0.85729       4.14727                       0.12112         0.30376            0.28966        0.92292           0.81184         4.17436                         0.14251\n",
      " 2023-10-20 18:27:03  4.306 sec              25       0.28045          0.25175      0.94376         0.86330       4.14727                       0.11866         0.30403            0.29026        0.92265           0.81206         4.17436                         0.14865\n",
      " 2023-10-20 18:27:03  5.191 sec              30       0.27646          0.24550      0.94683         0.87050       4.14727                       0.10995         0.30499            0.29186        0.92184           0.81064         4.17436                         0.13560\n",
      " 2023-10-20 18:27:04  5.990 sec              35       0.27357          0.24077      0.94914         0.87550       4.14727                       0.10937         0.30679            0.29477        0.92044           0.80745         4.17436                         0.14066\n",
      " 2023-10-20 18:27:05  6.936 sec              40       0.27062          0.23616      0.95133         0.87999       4.14727                       0.10634         0.30851            0.29748        0.91935           0.80503         4.17436                         0.14435\n",
      "\n",
      "10-20 18:27:06.732 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29078727474994165, 0.29059384042346914, 0.29229586926118234, 0.29470262365862054]\n",
      "10-20 18:27:06.732 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.29078727474994165 --> 0.29059384042346914 (converged).\n",
      "10-20 18:27:06.732 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:06.732 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:06.726 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_69\n",
      "10-20 18:27:06.741 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:06.775 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_69\n",
      "█10-20 18:27:06.803 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_70\n",
      "10-20 18:27:06.815 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_70\n",
      "10-20 18:27:06.963 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_71\n",
      "10-20 18:27:06.993 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_71\n",
      "10-20 18:27:07.207 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_72\n",
      "10-20 18:27:07.214 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_72\n",
      "10-20 18:27:07.223 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.074248455\n",
      " RMSE: 0.2724857\n",
      " AUC: 0.950203\n",
      " pr_auc: 0.8746757\n",
      " logloss: 0.23829576\n",
      " mean_per_class_error: 0.14534362\n",
      " default threshold: 0.4090777337551117\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18395  1438  0.0725  1,438 / 19,833\n",
      "     1   1356  4859  0.2182   1,356 / 6,215\n",
      "Totals  19751  6297  0.1073  2,794 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.77 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.996369  4.191150         4.191150       1.000000  0.997649                  1.000000          0.997649      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.992932  4.191150         4.191150       1.000000  0.994834                  1.000000          0.996244      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.988022  4.191150         4.191150       1.000000  0.990720                  1.000000          0.994400      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.979355  4.191150         4.191150       1.000000  0.984090                  1.000000          0.991828      0.041834                 0.167659   319.115044       319.115044            0.167659\n",
      "      5                0.05002303         0.961738  4.126918         4.178284       0.984674  0.972198                  0.996930          0.987896      0.041352                 0.209010   312.691825       317.828429            0.208809\n",
      "      6                0.10000768         0.795213  3.904659         4.041524       0.931644  0.882105                  0.964299          0.935021      0.195173                 0.404183   290.465859       304.152396            0.399494\n",
      "      7                0.15003071         0.647846  3.329118         3.803995       0.794321  0.720354                  0.907625          0.863447      0.166533                 0.570716   232.911796       280.399453            0.552514\n",
      "      8                0.20001536         0.506303  2.610617         3.505765       0.622888  0.576462                  0.836468          0.791728      0.130491                 0.701207   161.061675       250.576461            0.658248\n",
      "      9                0.30002303         0.295259  1.652327         2.887952       0.394242  0.393490                  0.689060          0.658982      0.165245                 0.866452    65.232687       188.795203            0.743929\n",
      "     10                0.39999232         0.151500  0.835333         2.374945       0.199309  0.217227                  0.566657          0.548575      0.083508                 0.949960   -16.466702       137.494502            0.722309\n",
      "     11                0.50000000         0.067589  0.326604         1.965245       0.077927  0.104585                  0.468904          0.459770      0.032663                 0.982623   -67.339595        96.524537            0.633861\n",
      "     12                0.60000768         0.028889  0.115840         1.656991       0.027639  0.045405                  0.395355          0.390705      0.011585                 0.994208   -88.416014        65.699140            0.517729\n",
      "     13                0.69997697         0.012568  0.043457         1.426550       0.010369  0.019403                  0.340372          0.337676      0.004344                 0.998552   -95.654337        42.654964            0.392138\n",
      "     14                0.79998464         0.005397  0.011262         1.249622       0.002687  0.008475                  0.298157          0.296522      0.001126                 0.999678   -98.873779        24.962173            0.262271\n",
      "     15                0.89999232         0.001825  0.003218         1.111121       0.000768  0.003373                  0.265111          0.263947      0.000322                 1.000000   -99.678223        11.112059            0.131347\n",
      "     16                1.00000000         0.000161  0.000000         1.000000       0.000000  0.000998                  0.238598          0.237650      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09207797\n",
      " RMSE: 0.30344352\n",
      " AUC: 0.9263019\n",
      " pr_auc: 0.8278981\n",
      " logloss: 0.2879206\n",
      " mean_per_class_error: 0.17066967\n",
      " default threshold: 0.35756829380989075\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4373   514  0.1052  514 / 4,887\n",
      "     1   384  1242  0.2362  384 / 1,626\n",
      "Totals  4757  1756  0.1379  898 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.95 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.996081  4.005535         4.005535       1.000000  0.997452                  1.000000          0.997452      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.993262  4.005535         4.005535       1.000000  0.994751                  1.000000          0.996112      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.988120  4.005535         4.005535       1.000000  0.990826                  1.000000          0.994359      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.979918  4.005535         4.005535       1.000000  0.984202                  1.000000          0.991829      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.965063  4.005535         4.005535       1.000000  0.973329                  1.000000          0.988141      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.808520  3.477198         3.741366       0.868098  0.892263                  0.934049          0.940202      0.174047                 0.374539   247.719761       274.136633            0.365740\n",
      "      7                0.15000768         0.648886  2.810037         3.431559       0.701538  0.726726                  0.856704          0.869189      0.140221                 0.514760   181.003690       243.155869            0.486113\n",
      "      8                0.20006142         0.518675  2.371375         3.166309       0.592025  0.583504                  0.790483          0.797713      0.118696                 0.633456   137.137505       216.630937            0.577594\n",
      "      9                0.30001535         0.294131  1.735117         2.689489       0.433180  0.400341                  0.671443          0.665324      0.173432                 0.806888    73.511657       168.948925            0.675519\n",
      "     10                0.39996929         0.147933  1.045992         2.278773       0.261137  0.215994                  0.568906          0.553034      0.104551                 0.911439     4.599226       127.877273            0.681646\n",
      "     11                0.50007677         0.069918  0.509907         1.924674       0.127301  0.104003                  0.480504          0.463145      0.051046                 0.962485   -49.009293        92.467374            0.616260\n",
      "     12                0.60003071         0.029196  0.233810         1.643007       0.058372  0.046375                  0.410184          0.393719      0.023370                 0.985855   -76.618997        64.300734            0.514195\n",
      "     13                0.69998465         0.012110  0.110752         1.424210       0.027650  0.019163                  0.355560          0.340234      0.011070                 0.996925   -88.924788        42.420977            0.395738\n",
      "     14                0.79993858         0.005483  0.030764         1.250096       0.007680  0.008547                  0.312092          0.298789      0.003075                 1.000000   -96.923552        25.009597            0.266626\n",
      "     15                0.89989252         0.001901  0.000000         1.111244       0.000000  0.003510                  0.277427          0.265992      0.000000                 1.000000  -100.000000        11.124382            0.133415\n",
      "     16                1.00000000         0.000198  0.000000         1.000000       0.000000  0.001041                  0.249655          0.239468      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4155.880371          1.000000   0.197282\n",
      "                      capital_gain         3304.359131          0.795104   0.156860\n",
      "                               age         2015.546509          0.484987   0.095679\n",
      "                            fnlwgt         1984.911133          0.477615   0.094225\n",
      "             relationship. Husband         1875.324463          0.451246   0.089023\n",
      "                    hours_per_week         1302.846802          0.313495   0.061847\n",
      "                      capital_loss         1166.192505          0.280613   0.055360\n",
      "        occupation. Prof-specialty          650.136108          0.156438   0.030862\n",
      "              education. Bachelors          562.604614          0.135376   0.026707\n",
      "       occupation. Exec-managerial          532.013855          0.128015   0.025255\n",
      "---\n",
      "           workclass. Self-emp-inc           19.087101          0.004593   0.000906\n",
      "              workclass. State-gov           12.894225          0.003103   0.000612\n",
      "                       race. Black           12.484092          0.003004   0.000593\n",
      "                     occupation.NA           10.518503          0.002531   0.000499\n",
      "           marital_status. Widowed            9.016663          0.002170   0.000428\n",
      "                education. 5th-6th            7.998797          0.001925   0.000380\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001910   0.000377\n",
      "                   education. 12th            3.699208          0.000890   0.000176\n",
      "       native_country. Philippines            3.323099          0.000800   0.000158\n",
      "                 native_country.NA            2.587692          0.000623   0.000123\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       119217.687500          1.000000   0.151705\n",
      "                      capital_gain        90329.640625          0.757687   0.114945\n",
      "                               age        89733.218750          0.752684   0.114186\n",
      "                    hours_per_week        66358.687500          0.556618   0.084442\n",
      "                      capital_loss        62365.160156          0.523120   0.079360\n",
      "marital_status. Married-civ-spouse        28794.529297          0.241529   0.036641\n",
      "              education. Bachelors        17415.529297          0.146082   0.022161\n",
      "              education. Doctorate        16386.648438          0.137451   0.020852\n",
      "        occupation. Prof-specialty        15735.185547          0.131987   0.020023\n",
      "       occupation. Exec-managerial        14651.946289          0.122901   0.018645\n",
      "---\n",
      "       relationship. Not-in-family         2460.240723          0.020637   0.003131\n",
      "          race. Asian-Pac-Islander         1869.164063          0.015679   0.002379\n",
      "                     occupation.NA         1834.313965          0.015386   0.002334\n",
      "                 native_country.NA         1425.331177          0.011956   0.001814\n",
      "                   education. 12th         1397.228027          0.011720   0.001778\n",
      "          race. Amer-Indian-Eskimo         1349.694214          0.011321   0.001717\n",
      "       native_country. Philippines         1276.138184          0.010704   0.001624\n",
      "          marital_status. Divorced         1100.038208          0.009227   0.001400\n",
      "                education. 5th-6th         1003.292114          0.008416   0.001277\n",
      "                         sex. Male          729.991150          0.006123   0.000929\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          780.000000          1.000000   0.293343\n",
      "                         age          555.000000          0.711538   0.208725\n",
      "              hours_per_week          273.000000          0.350000   0.102670\n",
      "                capital_gain           87.000000          0.111538   0.032719\n",
      "          workclass. Private           80.000000          0.102564   0.030086\n",
      "          education. HS-grad           68.000000          0.087179   0.025574\n",
      "                capital_loss           67.000000          0.085897   0.025197\n",
      "  occupation. Prof-specialty           59.000000          0.075641   0.022189\n",
      "        education. Bachelors           51.000000          0.065385   0.019180\n",
      "     education. Some-college           44.000000          0.056410   0.016548\n",
      "---\n",
      "               occupation.NA            4.000000          0.005128   0.001504\n",
      "        workclass. State-gov            4.000000          0.005128   0.001504\n",
      "     marital_status. Widowed            3.000000          0.003846   0.001128\n",
      "relationship. Other-relative            3.000000          0.003846   0.001128\n",
      "      native_country. Mexico            3.000000          0.003846   0.001128\n",
      "           native_country.NA            2.000000          0.002564   0.000752\n",
      "             education. 12th            1.000000          0.001282   0.000376\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001282   0.000376\n",
      " native_country. Philippines            1.000000          0.001282   0.000376\n",
      "          education. 5th-6th            1.000000          0.001282   0.000376\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      " 2023-10-20 18:27:02  3.900 sec              20       0.28552          0.26048      0.93937         0.85104       4.19115                       0.12312         0.30193            0.28685        0.92659           0.83134         4.00554                         0.14156\n",
      " 2023-10-20 18:27:03  4.463 sec              25       0.28224          0.25428      0.94224         0.85712       4.19115                       0.11794         0.30272            0.28782        0.92593           0.83002         4.00554                         0.13588\n",
      " 2023-10-20 18:27:04  5.318 sec              30       0.27855          0.24808      0.94518         0.86390       4.19115                       0.11548         0.30224            0.28670        0.92653           0.83070         4.00554                         0.14110\n",
      " 2023-10-20 18:27:05  6.505 sec              35       0.27535          0.24282      0.94791         0.86954       4.19115                       0.11713         0.30336            0.28826        0.92597           0.82828         4.00554                         0.13772\n",
      " 2023-10-20 18:27:06  7.522 sec              40       0.27249          0.23830      0.95020         0.87468       4.19115                       0.10726         0.30344            0.28792        0.92630           0.82790         4.00554                         0.13788\n",
      "\n",
      "10-20 18:27:07.232 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28810012827421844, 0.2871255414995885, 0.2875938874638124, 0.2876273144371815]\n",
      "10-20 18:27:07.233 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.28810012827421844 --> 0.2871255414995885 (converged).\n",
      "10-20 18:27:07.233 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:07.233 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:07.368 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_73\n",
      "10-20 18:27:07.452 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_73\n",
      "10-20 18:27:07.538 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07316164\n",
      " RMSE: 0.2704841\n",
      " AUC: 0.952134\n",
      " pr_auc: 0.88076967\n",
      " logloss: 0.235396\n",
      " mean_per_class_error: 0.13242607\n",
      " default threshold: 0.3811228573322296\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18083  1662  0.0842  1,662 / 19,745\n",
      "     1   1139  5165  0.1807   1,139 / 6,304\n",
      "Totals  19222  6827  0.1075  2,801 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.26 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995246  4.132138         4.132138       1.000000  0.996620                  1.000000          0.996620      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.992633  4.132138         4.132138       1.000000  0.993953                  1.000000          0.995289      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.988162  4.132138         4.132138       1.000000  0.990526                  1.000000          0.993699      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.980887  4.116245         4.128173       0.996154  0.984992                  0.999040          0.991527      0.041085                 0.165133   311.624549       312.817274            0.165083\n",
      "      5                0.05002111         0.968174  4.084642         4.119453       0.988506  0.975406                  0.996930          0.988298      0.040926                 0.206060   308.464248       311.945333            0.205857\n",
      "      6                0.10000384         0.818710  3.916328         4.017930       0.947773  0.896103                  0.972361          0.942218      0.195749                 0.401808   291.632772       301.792951            0.398162\n",
      "      7                0.15002495         0.672563  3.301271         3.778982       0.798926  0.743122                  0.914534          0.875836      0.165133                 0.566942   230.127091       277.898218            0.550026\n",
      "      8                0.20000768         0.530814  2.573859         3.477817       0.622888  0.599820                  0.841651          0.806858      0.128648                 0.695590   157.385882       247.781700            0.653807\n",
      "      9                0.30001152         0.305118  1.755961         2.903865       0.424952  0.410144                  0.702751          0.674620      0.175603                 0.871193    75.596051       190.386483            0.753543\n",
      "     10                0.40001536         0.149124  0.786772         2.374592       0.190403  0.219436                  0.574664          0.560824      0.078680                 0.949873   -21.322817       137.459158            0.725411\n",
      "     11                0.50001919         0.068084  0.342626         1.968199       0.082917  0.103120                  0.476315          0.469283      0.034264                 0.984137   -65.737356        96.819855            0.638683\n",
      "     12                0.59998464         0.028987  0.103145         1.657456       0.024962  0.045969                  0.401113          0.398753      0.010311                 0.994448   -89.685523        65.745570            0.520404\n",
      "     13                0.69998848         0.012694  0.042828         1.426782       0.010365  0.019575                  0.345289          0.344582      0.004283                 0.998731   -95.717169        42.678199            0.394122\n",
      "     14                0.79999232         0.005594  0.011104         1.249814       0.002687  0.008782                  0.302462          0.302605      0.001110                 0.999841   -98.889637        24.981371            0.263655\n",
      "     15                0.89999616         0.002058  0.001586         1.111116       0.000384  0.003626                  0.268896          0.269384      0.000159                 1.000000   -99.841377        11.111585            0.131932\n",
      "     16                1.00000000         0.000201  0.000000         1.000000       0.000000  0.001092                  0.242005          0.242554      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09504632\n",
      " RMSE: 0.30829585\n",
      " AUC: 0.9153765\n",
      " pr_auc: 0.800664\n",
      " logloss: 0.29972842\n",
      " mean_per_class_error: 0.18473087\n",
      " default threshold: 0.3804539442062378\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4409   566  0.1138  566 / 4,975\n",
      "     1   393  1144  0.2557  393 / 1,537\n",
      "Totals  4802  1710  0.1473  959 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994576  4.236825         4.236825       1.000000  0.996420                  1.000000          0.996420      0.042941                 0.042941   323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.991554  4.236825         4.236825       1.000000  0.993063                  1.000000          0.994754      0.042290                 0.085231   323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.986943  4.236825         4.236825       1.000000  0.989628                  1.000000          0.993054      0.042290                 0.127521   323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.976612  4.171643         4.220592       0.984615  0.982104                  0.996169          0.990327      0.041640                 0.169161   317.164306       322.059194            0.168960\n",
      "      5                0.05006143         0.959500  4.236825         4.223829       1.000000  0.969198                  0.996933          0.986114      0.042290                 0.211451   323.682498       322.382859            0.211250\n",
      "      6                0.10012285         0.807380  3.392059         3.807944       0.800613  0.885413                  0.898773          0.935764      0.169811                 0.381262   239.205927       280.794393            0.367996\n",
      "      7                0.15003071         0.655982  2.868005         3.495272       0.676923  0.735268                  0.824974          0.869069      0.143136                 0.524398   186.800460       249.527220            0.490026\n",
      "      8                0.20009214         0.510434  2.274369         3.189812       0.536810  0.584920                  0.752878          0.797977      0.113858                 0.638256   127.436924       218.981221            0.573533\n",
      "      9                0.30006143         0.311696  1.568471         2.649642       0.370200  0.407384                  0.625384          0.667846      0.156799                 0.795055    56.847131       164.964183            0.647920\n",
      "     10                0.40003071         0.156078  1.080358         2.257471       0.254992  0.229314                  0.532821          0.558255      0.108003                 0.903058     8.035783       125.747143            0.658435\n",
      "     11                0.50000000         0.068313  0.540179         1.914118       0.127496  0.106289                  0.451781          0.467890      0.054001                 0.957059   -45.982109        91.411841            0.598265\n",
      "     12                0.59996929         0.028663  0.221278         1.632051       0.052227  0.046040                  0.385206          0.397599      0.022121                 0.979180   -77.872189        63.205058            0.496366\n",
      "     13                0.69993857         0.012865  0.091115         1.411965       0.021505  0.019319                  0.333260          0.343571      0.009109                 0.988289   -90.888548        41.196515            0.377435\n",
      "     14                0.79990786         0.005657  0.084606         1.246077       0.019969  0.008999                  0.294106          0.301758      0.008458                 0.996747   -91.539366        24.607715            0.257651\n",
      "     15                0.89987715         0.002090  0.032541         1.111263       0.007680  0.003674                  0.262287          0.268643      0.003253                 1.000000   -96.745910        11.126280            0.131055\n",
      "     16                1.00000000         0.000217  0.000000         1.000000       0.000000  0.001097                  0.236026          0.241855      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4170.911133          1.000000   0.191350\n",
      "                      capital_gain         3503.247559          0.839924   0.160720\n",
      "                               age         2342.478027          0.561623   0.107467\n",
      "                            fnlwgt         2265.592041          0.543189   0.103939\n",
      "marital_status. Married-civ-spouse         1477.721436          0.354292   0.067794\n",
      "                      capital_loss         1241.546265          0.297668   0.056959\n",
      "                    hours_per_week         1223.862915          0.293428   0.056148\n",
      "              education. Bachelors          724.218262          0.173636   0.033225\n",
      "        occupation. Prof-specialty          532.505920          0.127671   0.024430\n",
      "       occupation. Exec-managerial          521.607666          0.125058   0.023930\n",
      "---\n",
      "                     occupation.NA           14.503084          0.003477   0.000665\n",
      "                      workclass.NA           11.150998          0.002674   0.000512\n",
      "                 native_country.NA            9.256384          0.002219   0.000425\n",
      "          race. Asian-Pac-Islander            9.227043          0.002212   0.000423\n",
      "          race. Amer-Indian-Eskimo            5.838183          0.001400   0.000268\n",
      "                education. 5th-6th            5.686970          0.001363   0.000261\n",
      "       native_country. Philippines            5.432164          0.001302   0.000249\n",
      "           marital_status. Widowed            5.054038          0.001212   0.000232\n",
      "      relationship. Other-relative            4.376630          0.001049   0.000201\n",
      "         marital_status. Separated            1.875626          0.000450   0.000086\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       130528.203125          1.000000   0.167892\n",
      "                               age       105780.156250          0.810401   0.136060\n",
      "                      capital_gain        78731.195313          0.603174   0.101268\n",
      "                      capital_loss        67099.117188          0.514058   0.086306\n",
      "                    hours_per_week        57185.156250          0.438106   0.073555\n",
      "marital_status. Married-civ-spouse        22437.347656          0.171897   0.028860\n",
      "             relationship. Husband        19355.892578          0.148289   0.024897\n",
      "              education. Bachelors        17278.517578          0.132374   0.022225\n",
      "                education. Masters        14962.429688          0.114630   0.019245\n",
      "        occupation. Prof-specialty        14813.842773          0.113492   0.019054\n",
      "---\n",
      "              workclass. Local-gov         2026.174561          0.015523   0.002606\n",
      "                     occupation.NA         1890.959473          0.014487   0.002432\n",
      "          marital_status. Divorced         1869.199585          0.014320   0.002404\n",
      "           relationship. Unmarried         1540.066040          0.011799   0.001981\n",
      "          race. Asian-Pac-Islander         1430.474731          0.010959   0.001840\n",
      "          race. Amer-Indian-Eskimo         1420.591553          0.010883   0.001827\n",
      "      relationship. Other-relative         1396.271484          0.010697   0.001796\n",
      "                education. 5th-6th         1351.620972          0.010355   0.001739\n",
      "       native_country. Philippines         1315.266724          0.010076   0.001692\n",
      "         marital_status. Separated          964.407288          0.007388   0.001240\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          933.000000          1.000000   0.332620\n",
      "                         age          611.000000          0.654877   0.217825\n",
      "              hours_per_week          246.000000          0.263666   0.087701\n",
      "                capital_gain           84.000000          0.090032   0.029947\n",
      "          workclass. Private           77.000000          0.082529   0.027451\n",
      "                capital_loss           76.000000          0.081458   0.027094\n",
      "          education. HS-grad           71.000000          0.076099   0.025312\n",
      "        education. Bachelors           60.000000          0.064309   0.021390\n",
      "  occupation. Prof-specialty           55.000000          0.058950   0.019608\n",
      " occupation. Exec-managerial           45.000000          0.048232   0.016043\n",
      "---\n",
      "              education. 9th            4.000000          0.004287   0.001426\n",
      "     marital_status. Widowed            3.000000          0.003215   0.001070\n",
      "               occupation.NA            3.000000          0.003215   0.001070\n",
      "    race. Asian-Pac-Islander            3.000000          0.003215   0.001070\n",
      "           native_country.NA            3.000000          0.003215   0.001070\n",
      "relationship. Other-relative            1.000000          0.001072   0.000357\n",
      "   marital_status. Separated            1.000000          0.001072   0.000357\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001072   0.000357\n",
      " native_country. Philippines            1.000000          0.001072   0.000357\n",
      "          education. 5th-6th            1.000000          0.001072   0.000357\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      " 2023-10-20 18:27:02  3.948 sec              20       0.28375          0.25710      0.94156         0.85776       4.13214                       0.11977         0.30632            0.29578        0.91635           0.80451         4.23682                         0.13851\n",
      " 2023-10-20 18:27:03  4.624 sec              25       0.28033          0.25097      0.94441         0.86363       4.13214                       0.11594         0.30676            0.29629        0.91661           0.80377         4.23682                         0.14235\n",
      " 2023-10-20 18:27:04  5.552 sec              30       0.27657          0.24498      0.94738         0.87019       4.13214                       0.11233         0.30712            0.29718        0.91640           0.80334         4.23682                         0.13790\n",
      " 2023-10-20 18:27:05  6.375 sec              35       0.27337          0.23982      0.94995         0.87590       4.13214                       0.11409         0.30796            0.29865        0.91594           0.80104         4.23682                         0.14112\n",
      " 2023-10-20 18:27:06  7.392 sec              40       0.27048          0.23540      0.95213         0.88077       4.13214                       0.10753         0.30830            0.29973        0.91538           0.80066         4.23682                         0.14727\n",
      "\n",
      "10-20 18:27:07.557 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29704341270984735, 0.2964181317290027, 0.29737577411809873, 0.2985208808223378]\n",
      "10-20 18:27:07.558 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29704341270984735 --> 0.2964181317290027 (converged).\n",
      "10-20 18:27:07.558 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:07.561 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:07.676 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_75\n",
      "10-20 18:27:07.684 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_74\n",
      "10-20 18:27:07.694 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_75\n",
      "10-20 18:27:07.695 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_76\n",
      "10-20 18:27:07.697 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_74\n",
      "10-20 18:27:07.730 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_76\n",
      "10-20 18:27:07.717 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.073273316\n",
      " RMSE: 0.27069044\n",
      " AUC: 0.95153475\n",
      " pr_auc: 0.8807637\n",
      " logloss: 0.23681758\n",
      " mean_per_class_error: 0.13625406\n",
      " default threshold: 0.3991260230541229\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18203  1535  0.0778  1,535 / 19,738\n",
      "     1   1229  5082  0.1947   1,229 / 6,311\n",
      "Totals  19432  6617  0.1061  2,764 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.31 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995395  4.127555         4.127555       1.000000  0.996734                  1.000000          0.996734      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.992630  4.127555         4.127555       1.000000  0.994130                  1.000000          0.995435      0.041198                 0.082554  312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.988486  4.127555         4.127555       1.000000  0.990749                  1.000000          0.993871      0.041356                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.981450  4.111680         4.123594       0.996154  0.985297                  0.999040          0.991732      0.041039                 0.164950  311.167985       312.359388            0.164899\n",
      "      5                0.05002111         0.968156  4.064298         4.111716       0.984674  0.975531                  0.996163          0.988487      0.040723                 0.205673  306.429751       311.171640            0.205419\n",
      "      6                0.10000384         0.814054  3.889793         4.000797       0.942396  0.895274                  0.969290          0.941898      0.194422                 0.400095  288.979267       300.079713            0.396042\n",
      "      7                0.15002495         0.667253  3.341957         3.781128       0.809670  0.738252                  0.916070          0.873999      0.167168                 0.567264  234.195748       278.112772            0.550646\n",
      "      8                0.20000768         0.529709  2.656598         3.500103       0.643625  0.599787                  0.847985          0.805472      0.132784                 0.700048  165.659842       250.010331            0.659922\n",
      "      9                0.30001152         0.305058  1.682712         2.894306       0.407678  0.410664                  0.701216          0.673869      0.168278                 0.868325   68.271151       189.430605            0.750025\n",
      "     10                0.40001536         0.152146  0.782730         2.366412       0.189635  0.223024                  0.573321          0.561158      0.078276                 0.946601  -21.726979       136.641209            0.721350\n",
      "     11                0.50001919         0.068096  0.339077         1.960945       0.082150  0.105801                  0.475086          0.470086      0.033909                 0.980510  -66.092254        96.094516            0.634123\n",
      "     12                0.59998464         0.030158  0.123636         1.654825       0.029954  0.046400                  0.400921          0.399495      0.012359                 0.992870  -87.636356        65.482501            0.518505\n",
      "     13                0.69998848         0.013284  0.053872         1.426105       0.013052  0.020446                  0.345508          0.345342      0.005387                 0.998257  -94.612788        42.610491            0.393636\n",
      "     14                0.79999232         0.005615  0.014260         1.249616       0.003455  0.008984                  0.302750          0.303295      0.001426                 0.999683  -98.573973        24.961586            0.263540\n",
      "     15                0.89999616         0.001972  0.001584         1.110940       0.000384  0.003552                  0.269152          0.269989      0.000158                 0.999842  -99.841553        11.093979            0.131770\n",
      "     16                1.00000000         0.000139  0.001584         1.000000       0.000384  0.001049                  0.242274          0.243094      0.000158                 1.000000  -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09128824\n",
      " RMSE: 0.30213943\n",
      " AUC: 0.92242235\n",
      " pr_auc: 0.81301343\n",
      " logloss: 0.28645223\n",
      " mean_per_class_error: 0.17523621\n",
      " default threshold: 0.3742513060569763\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4444   538  0.1080  538 / 4,982\n",
      "     1   371  1159  0.2425  371 / 1,530\n",
      "Totals  4815  1697  0.1396  909 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.80 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995085  4.256209         4.256209       1.000000  0.996383                  1.000000          0.996383      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.992425  4.256209         4.256209       1.000000  0.993825                  1.000000          0.995114      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.988181  4.256209         4.256209       1.000000  0.990674                  1.000000          0.993641      0.042484                 0.128105   325.620915       325.620915            0.128105\n",
      "      4                0.04007985         0.980329  4.190729         4.239902       0.984615  0.984883                  0.996169          0.991460      0.041830                 0.169935   319.072901       323.990184            0.169734\n",
      "      5                0.05006143         0.964839  4.125249         4.217042       0.969231  0.974039                  0.990798          0.987987      0.041176                 0.211111   312.524887       321.704158            0.210509\n",
      "      6                0.10012285         0.809195  3.694807         3.955924       0.868098  0.887649                  0.929448          0.937818      0.184967                 0.396078   269.480733       295.592446            0.386845\n",
      "      7                0.15003071         0.650474  2.841838         3.585323       0.667692  0.724124                  0.842375          0.866732      0.141830                 0.537908   184.183811       258.532255            0.506997\n",
      "      8                0.20009214         0.508490  2.180328         3.233804       0.512270  0.573839                  0.759785          0.793453      0.109150                 0.647059   118.032800       223.380434            0.584233\n",
      "      9                0.30006143         0.291641  1.601799         2.690081       0.376344  0.394842                  0.632037          0.660651      0.160131                 0.807190    60.179914       169.008101            0.662870\n",
      "     10                0.40003071         0.146386  0.987231         2.264532       0.231951  0.213176                  0.532054          0.548825      0.098693                 0.905882    -1.276869       126.453201            0.661202\n",
      "     11                0.50000000         0.068060  0.581878         1.928105       0.136713  0.103604                  0.453010          0.459808      0.058170                 0.964052   -41.812194        92.810458            0.606565\n",
      "     12                0.59996929         0.030260  0.254980         1.649322       0.059908  0.047214                  0.387510          0.391060      0.025490                 0.989542   -74.501973        64.932190            0.509213\n",
      "     13                0.69993857         0.013572  0.065380         1.423094       0.015361  0.020712                  0.334357          0.338165      0.006536                 0.996078   -93.462044        42.309406            0.387086\n",
      "     14                0.79990786         0.005609  0.026152         1.248510       0.006144  0.008967                  0.293338          0.297023      0.002614                 0.998693   -97.384818        24.850981            0.259833\n",
      "     15                0.89987715         0.001875  0.013076         1.111263       0.003072  0.003460                  0.261092          0.264410      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000185  0.000000         1.000000       0.000000  0.000953                  0.234951          0.238032      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4114.416016          1.000000   0.187427\n",
      "                      capital_gain         3546.480225          0.861964   0.161555\n",
      "                               age         2424.776611          0.589337   0.110458\n",
      "                            fnlwgt         2332.043213          0.566798   0.106233\n",
      "marital_status. Married-civ-spouse         1500.098511          0.364596   0.068335\n",
      "                    hours_per_week         1200.268188          0.291723   0.054677\n",
      "                      capital_loss         1189.409302          0.289083   0.054182\n",
      "              education. Bachelors          669.774536          0.162787   0.030511\n",
      "        occupation. Prof-specialty          584.839233          0.142144   0.026642\n",
      "       occupation. Exec-managerial          582.938721          0.141682   0.026555\n",
      "---\n",
      "           marital_status. Widowed           17.837631          0.004335   0.000813\n",
      "                       race. Black           15.021633          0.003651   0.000684\n",
      "                     occupation.NA           11.762693          0.002859   0.000536\n",
      "           relationship. Unmarried           11.002371          0.002674   0.000501\n",
      "              workclass. State-gov           10.131887          0.002463   0.000462\n",
      "                      workclass.NA            9.695875          0.002357   0.000442\n",
      "         marital_status. Separated            9.013293          0.002191   0.000411\n",
      "                 native_country.NA            8.593095          0.002089   0.000391\n",
      "                education. 5th-6th            6.929251          0.001684   0.000316\n",
      "          race. Amer-Indian-Eskimo            4.215075          0.001024   0.000192\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       137839.234375          1.000000   0.176327\n",
      "                               age        95360.812500          0.691826   0.121987\n",
      "                      capital_gain        76565.117188          0.555467   0.097944\n",
      "                      capital_loss        62134.785156          0.450777   0.079484\n",
      "                    hours_per_week        59594.886719          0.432351   0.076235\n",
      "             relationship. Husband        20522.976563          0.148891   0.026253\n",
      "marital_status. Married-civ-spouse        18039.359375          0.130872   0.023076\n",
      "              education. Bachelors        15803.999023          0.114655   0.020217\n",
      "       occupation. Exec-managerial        15298.596680          0.110989   0.019570\n",
      "        occupation. Prof-specialty        14197.132813          0.102998   0.018161\n",
      "---\n",
      "                       race. Black         2560.242188          0.018574   0.003275\n",
      "         marital_status. Separated         2429.499023          0.017626   0.003108\n",
      "           relationship. Unmarried         2286.664551          0.016589   0.002925\n",
      "                 native_country.NA         2190.556885          0.015892   0.002802\n",
      "                     occupation.NA         1970.962646          0.014299   0.002521\n",
      "              workclass. State-gov         1939.761353          0.014073   0.002481\n",
      "          marital_status. Divorced         1843.108032          0.013371   0.002358\n",
      "                      workclass.NA         1758.579102          0.012758   0.002250\n",
      "          race. Amer-Indian-Eskimo         1413.515991          0.010255   0.001808\n",
      "                education. 5th-6th          713.308777          0.005175   0.000912\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          927.000000          1.000000   0.325606\n",
      "                          age          604.000000          0.651564   0.212153\n",
      "               hours_per_week          241.000000          0.259978   0.084651\n",
      "           workclass. Private           86.000000          0.092772   0.030207\n",
      "           education. HS-grad           77.000000          0.083064   0.027046\n",
      "                 capital_gain           77.000000          0.083064   0.027046\n",
      "                 capital_loss           74.000000          0.079827   0.025992\n",
      "         education. Bachelors           64.000000          0.069040   0.022480\n",
      "   occupation. Prof-specialty           47.000000          0.050701   0.016509\n",
      "  occupation. Exec-managerial           45.000000          0.048544   0.015806\n",
      "---\n",
      "        education. Assoc-acdm            5.000000          0.005394   0.001756\n",
      "occupation. Handlers-cleaners            4.000000          0.004315   0.001405\n",
      "               education. 9th            4.000000          0.004315   0.001405\n",
      "                occupation.NA            3.000000          0.003236   0.001054\n",
      "                 workclass.NA            3.000000          0.003236   0.001054\n",
      "         workclass. State-gov            3.000000          0.003236   0.001054\n",
      "            native_country.NA            3.000000          0.003236   0.001054\n",
      "    marital_status. Separated            2.000000          0.002157   0.000702\n",
      "     race. Amer-Indian-Eskimo            1.000000          0.001079   0.000351\n",
      "           education. 5th-6th            1.000000          0.001079   0.000351\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      " 2023-10-20 18:27:02  3.824 sec              20       0.28393          0.25830      0.94145         0.85820       4.12756                       0.12235         0.30044            0.28487        0.92305           0.81492         4.25621                         0.14220\n",
      " 2023-10-20 18:27:03  4.564 sec              25       0.28038          0.25209      0.94407         0.86424       4.12756                       0.11620         0.30086            0.28541        0.92254           0.81423         4.25621                         0.14005\n",
      " 2023-10-20 18:27:04  5.475 sec              30       0.27707          0.24659      0.94663         0.86998       4.12756                       0.11217         0.30131            0.28561        0.92263           0.81393         4.25621                         0.13345\n",
      " 2023-10-20 18:27:05  6.533 sec              35       0.27410          0.24180      0.94896         0.87478       4.12756                       0.10630         0.30137            0.28518        0.92321           0.81404         4.25621                         0.14082\n",
      " 2023-10-20 18:27:06  7.766 sec              40       0.27069          0.23682      0.95153         0.88076       4.12756                       0.10611         0.30214            0.28645        0.92242           0.81301         4.25621                         0.13959\n",
      "\n",
      "█10-20 18:27:07.725 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.073237315\n",
      " RMSE: 0.27062392\n",
      " AUC: 0.9513348\n",
      " pr_auc: 0.8799897\n",
      " logloss: 0.23615739\n",
      " mean_per_class_error: 0.13795242\n",
      " default threshold: 0.3944703936576843\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18248  1520  0.0769  1,520 / 19,768\n",
      "     1   1250  5031  0.1990   1,250 / 6,281\n",
      "Totals  19498  6551  0.1063  2,770 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996212  4.147270         4.147270       1.000000  0.997249                  1.000000          0.997249      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.993847  4.147270         4.147270       1.000000  0.995184                  1.000000          0.996218      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.990010  4.147270         4.147270       1.000000  0.992102                  1.000000          0.994844      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.982898  4.131319         4.143289       0.996154  0.986875                  0.999040          0.992856      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05002111         0.970012  4.099600         4.134538       0.988506  0.977668                  0.996930          0.989813      0.041076                 0.206814   309.959978       313.453809            0.206612\n",
      "      6                0.10000384         0.825064  3.924298         4.029458       0.946237  0.897938                  0.971593          0.943894      0.196147                 0.402961   292.429806       302.945843            0.399218\n",
      "      7                0.15002495         0.670386  3.332457         3.797065       0.803530  0.747757                  0.915558          0.878498      0.166693                 0.569655   233.245680       279.706510            0.552961\n",
      "      8                0.20000768         0.520807  2.576913         3.492144       0.621352  0.594095                  0.842035          0.807425      0.128801                 0.698456   157.691326       249.214424            0.656823\n",
      "      9                0.30001152         0.294749  1.679604         2.887964       0.404990  0.401533                  0.696353          0.672127      0.167967                 0.866423    67.960436       188.796428            0.746380\n",
      "     10                0.40001536         0.151624  0.810349         2.368561       0.195393  0.217019                  0.571113          0.558350      0.081038                 0.947461   -18.965060       136.856056            0.721388\n",
      "     11                0.50001919         0.070008  0.342289         1.963306       0.082534  0.106871                  0.473397          0.468054      0.034230                 0.981691   -65.771096        96.330626            0.634716\n",
      "     12                0.59998464         0.030285  0.122634         1.656626       0.029570  0.047152                  0.399450          0.397926      0.012259                 0.993950   -87.736569        65.662574            0.519142\n",
      "     13                0.69998848         0.013128  0.049353         1.427003       0.011900  0.020503                  0.344082          0.344006      0.004936                 0.998886   -95.064670        42.700280            0.393867\n",
      "     14                0.79999232         0.005591  0.006368         1.249415       0.001536  0.008836                  0.301262          0.302107      0.000637                 0.999522   -99.363183        24.941495            0.262928\n",
      "     15                0.89999616         0.001975  0.004776         1.111116       0.001152  0.003580                  0.267915          0.268936      0.000478                 1.000000   -99.522387        11.111585            0.131779\n",
      "     16                1.00000000         0.000223  0.000000         1.000000       0.000000  0.001112                  0.241122          0.242153      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09517617\n",
      " RMSE: 0.30850634\n",
      " AUC: 0.9193489\n",
      " pr_auc: 0.80503285\n",
      " logloss: 0.29748315\n",
      " mean_per_class_error: 0.18119174\n",
      " default threshold: 0.36670634150505066\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4405   547  0.1105  547 / 4,952\n",
      "     1   393  1167  0.2519  393 / 1,560\n",
      "Totals  4798  1714  0.1443  940 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.33 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996340  4.174359         4.174359       1.000000  0.997467                  1.000000          0.997467      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.993832  4.174359         4.174359       1.000000  0.995195                  1.000000          0.996340      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.990112  4.174359         4.174359       1.000000  0.992060                  1.000000          0.994920      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.984488  4.110138         4.158365       0.984615  0.987304                  0.996169          0.993024      0.041026                 0.166667  311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.971830  4.045917         4.135945       0.969231  0.979173                  0.990798          0.990262      0.040385                 0.207051  304.591716       313.594463            0.206445\n",
      "      6                0.10012285         0.825382  3.534120         3.835032       0.846626  0.902750                  0.918712          0.946506      0.176923                 0.383974  253.411987       283.503225            0.373272\n",
      "      7                0.15003071         0.676126  2.633057         3.435194       0.630769  0.752162                  0.822927          0.881857      0.131410                 0.515385  163.305720       243.519408            0.480449\n",
      "      8                0.20009214         0.534177  2.304861         3.152394       0.552147  0.599896                  0.755180          0.811313      0.115385                 0.630769  130.486078       215.239388            0.566351\n",
      "      9                0.30006143         0.292393  1.680003         2.661848       0.402458  0.404337                  0.637666          0.675724      0.167949                 0.798718   68.000315       166.184815            0.655745\n",
      "     10                0.40003071         0.153761  1.102903         2.272261       0.264209  0.216049                  0.544338          0.560849      0.110256                 0.908974   10.290283       127.226143            0.669273\n",
      "     11                0.50000000         0.069751  0.525803         1.923077       0.125960  0.108672                  0.460688          0.470442      0.052564                 0.961538  -47.419749        92.307692            0.606934\n",
      "     12                0.59996929         0.029386  0.250077         1.644315       0.059908  0.046653                  0.393908          0.399828      0.025000                 0.986538  -74.992320        64.431494            0.508348\n",
      "     13                0.69993857         0.012970  0.070534         1.419538       0.016897  0.020164                  0.340061          0.345602      0.007051                 0.993590  -92.946552        41.953848            0.386158\n",
      "     14                0.79990786         0.005681  0.051298         1.248541       0.012289  0.008840                  0.299098          0.303515      0.005128                 0.998718  -94.870219        24.854123            0.261440\n",
      "     15                0.89987715         0.002103  0.006412         1.110550       0.001536  0.003672                  0.266041          0.270205      0.000641                 0.999359  -99.358777        11.055045            0.130821\n",
      "     16                1.00000000         0.000274  0.006402         1.000000       0.001534  0.001184                  0.239558          0.243270      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3821.199219          1.000000   0.175787\n",
      "                      capital_gain         3567.216553          0.933533   0.164103\n",
      "                               age         2291.251221          0.599616   0.105404\n",
      "                            fnlwgt         2219.637207          0.580875   0.102110\n",
      "marital_status. Married-civ-spouse         1548.758911          0.405307   0.071248\n",
      "                    hours_per_week         1262.276611          0.330335   0.058069\n",
      "                      capital_loss         1245.979614          0.326070   0.057319\n",
      "              education. Bachelors          742.360168          0.194274   0.034151\n",
      "        occupation. Prof-specialty          593.354065          0.155280   0.027296\n",
      "       occupation. Exec-managerial          564.880249          0.147828   0.025986\n",
      "---\n",
      "           marital_status. Widowed           16.921299          0.004428   0.000778\n",
      "                 native_country.NA           16.834946          0.004406   0.000774\n",
      "              workclass. State-gov           11.931560          0.003122   0.000549\n",
      "           relationship. Unmarried            9.174633          0.002401   0.000422\n",
      "         marital_status. Separated            8.163152          0.002136   0.000376\n",
      "                   education. 12th            7.714605          0.002019   0.000355\n",
      "          race. Amer-Indian-Eskimo            6.894102          0.001804   0.000317\n",
      "                      workclass.NA            6.740609          0.001764   0.000310\n",
      "      relationship. Other-relative            5.539434          0.001450   0.000255\n",
      "                education. 5th-6th            4.151810          0.001087   0.000191\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       124570.445313          1.000000   0.157037\n",
      "                               age        97207.765625          0.780344   0.122543\n",
      "                      capital_gain        82293.765625          0.660620   0.103742\n",
      "                      capital_loss        71106.273438          0.570812   0.089638\n",
      "                    hours_per_week        68349.265625          0.548680   0.086163\n",
      "             relationship. Husband        20090.976563          0.161282   0.025327\n",
      "marital_status. Married-civ-spouse        19934.738281          0.160028   0.025130\n",
      "              education. Bachelors        17684.382813          0.141963   0.022293\n",
      "                education. Masters        13465.615234          0.108096   0.016975\n",
      "        occupation. Prof-specialty        13254.338867          0.106400   0.016709\n",
      "---\n",
      "             education. Assoc-acdm         2563.472656          0.020578   0.003232\n",
      "          marital_status. Divorced         2333.347168          0.018731   0.002941\n",
      "              workclass. State-gov         2143.855957          0.017210   0.002703\n",
      "           relationship. Unmarried         2118.826416          0.017009   0.002671\n",
      "                       race. Black         1505.673950          0.012087   0.001898\n",
      "                education. 5th-6th         1389.220825          0.011152   0.001751\n",
      "          race. Amer-Indian-Eskimo         1368.539429          0.010986   0.001725\n",
      "      relationship. Other-relative         1299.182373          0.010429   0.001638\n",
      "                      workclass.NA         1247.093750          0.010011   0.001572\n",
      "      occupation. Transport-moving         1245.741089          0.010000   0.001570\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          872.000000          1.000000   0.318016\n",
      "                         age          568.000000          0.651376   0.207148\n",
      "              hours_per_week          268.000000          0.307339   0.097739\n",
      "                capital_gain           85.000000          0.097477   0.030999\n",
      "          workclass. Private           73.000000          0.083716   0.026623\n",
      "          education. HS-grad           72.000000          0.082569   0.026258\n",
      "                capital_loss           71.000000          0.081422   0.025894\n",
      "        education. Bachelors           54.000000          0.061927   0.019694\n",
      "  occupation. Prof-specialty           53.000000          0.060780   0.019329\n",
      " occupation. Exec-managerial           44.000000          0.050459   0.016047\n",
      "---\n",
      "      native_country. Mexico            4.000000          0.004587   0.001459\n",
      "        workclass. State-gov            4.000000          0.004587   0.001459\n",
      "       education. Assoc-acdm            4.000000          0.004587   0.001459\n",
      "              education. 9th            4.000000          0.004587   0.001459\n",
      "   marital_status. Separated            3.000000          0.003440   0.001094\n",
      "             education. 12th            2.000000          0.002294   0.000729\n",
      "                workclass.NA            2.000000          0.002294   0.000729\n",
      "relationship. Other-relative            1.000000          0.001147   0.000365\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001147   0.000365\n",
      "          education. 5th-6th            1.000000          0.001147   0.000365\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.485 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:00  1.568 sec               5       0.31428          0.33885      0.92486         0.82410       4.14727                       0.14526         0.32256            0.35039        0.91311           0.79172         4.17436                         0.15587\n",
      " 2023-10-20 18:27:01  2.380 sec              10       0.29421          0.28372      0.93305         0.84160       4.14727                       0.13321         0.30870            0.30500        0.91774           0.80260         4.17436                         0.15126\n",
      " 2023-10-20 18:27:01  3.197 sec              15       0.28749          0.26572      0.93802         0.85114       4.14727                       0.12507         0.30472            0.29244        0.92179           0.81001         4.17436                         0.15756\n",
      " 2023-10-20 18:27:02  3.656 sec              20       0.28386          0.25761      0.94111         0.85729       4.14727                       0.12112         0.30376            0.28966        0.92292           0.81184         4.17436                         0.14251\n",
      " 2023-10-20 18:27:03  4.306 sec              25       0.28045          0.25175      0.94376         0.86330       4.14727                       0.11866         0.30403            0.29026        0.92265           0.81206         4.17436                         0.14865\n",
      " 2023-10-20 18:27:03  5.191 sec              30       0.27646          0.24550      0.94683         0.87050       4.14727                       0.10995         0.30499            0.29186        0.92184           0.81064         4.17436                         0.13560\n",
      " 2023-10-20 18:27:04  5.990 sec              35       0.27357          0.24077      0.94914         0.87550       4.14727                       0.10937         0.30679            0.29477        0.92044           0.80745         4.17436                         0.14066\n",
      " 2023-10-20 18:27:05  6.936 sec              40       0.27062          0.23616      0.95133         0.87999       4.14727                       0.10634         0.30851            0.29748        0.91935           0.80503         4.17436                         0.14435\n",
      "\n",
      "10-20 18:27:07.761 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2856406659875552, 0.28529764870527846, 0.285403418861261, 0.28574969069000417]\n",
      "10-20 18:27:07.769 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: In-training scoring took 5721ms.\n",
      "10-20 18:27:07.772 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.2856406659875552 --> 0.28529764870527846 (converged).\n",
      "10-20 18:27:07.772 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:07.772 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:07.937 172.17.0.2:54321      22766  4648757-71  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:07.948 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model XGBoost_1_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:07.963 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_77\n",
      "10-20 18:27:07.977 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_77\n",
      "10-20 18:27:08.060 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_78\n",
      "10-20 18:27:08.087 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_78\n",
      "10-20 18:27:08.192 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_79\n",
      "10-20 18:27:08.200 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_79\n",
      "10-20 18:27:08.219 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.074248455\n",
      " RMSE: 0.2724857\n",
      " AUC: 0.950203\n",
      " pr_auc: 0.8746757\n",
      " logloss: 0.23829576\n",
      " mean_per_class_error: 0.14534362\n",
      " default threshold: 0.4090777337551117\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18395  1438  0.0725  1,438 / 19,833\n",
      "     1   1356  4859  0.2182   1,356 / 6,215\n",
      "Totals  19751  6297  0.1073  2,794 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.77 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.996369  4.191150         4.191150       1.000000  0.997649                  1.000000          0.997649      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.992932  4.191150         4.191150       1.000000  0.994834                  1.000000          0.996244      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.988022  4.191150         4.191150       1.000000  0.990720                  1.000000          0.994400      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.979355  4.191150         4.191150       1.000000  0.984090                  1.000000          0.991828      0.041834                 0.167659   319.115044       319.115044            0.167659\n",
      "      5                0.05002303         0.961738  4.126918         4.178284       0.984674  0.972198                  0.996930          0.987896      0.041352                 0.209010   312.691825       317.828429            0.208809\n",
      "      6                0.10000768         0.795213  3.904659         4.041524       0.931644  0.882105                  0.964299          0.935021      0.195173                 0.404183   290.465859       304.152396            0.399494\n",
      "      7                0.15003071         0.647846  3.329118         3.803995       0.794321  0.720354                  0.907625          0.863447      0.166533                 0.570716   232.911796       280.399453            0.552514\n",
      "      8                0.20001536         0.506303  2.610617         3.505765       0.622888  0.576462                  0.836468          0.791728      0.130491                 0.701207   161.061675       250.576461            0.658248\n",
      "      9                0.30002303         0.295259  1.652327         2.887952       0.394242  0.393490                  0.689060          0.658982      0.165245                 0.866452    65.232687       188.795203            0.743929\n",
      "     10                0.39999232         0.151500  0.835333         2.374945       0.199309  0.217227                  0.566657          0.548575      0.083508                 0.949960   -16.466702       137.494502            0.722309\n",
      "     11                0.50000000         0.067589  0.326604         1.965245       0.077927  0.104585                  0.468904          0.459770      0.032663                 0.982623   -67.339595        96.524537            0.633861\n",
      "     12                0.60000768         0.028889  0.115840         1.656991       0.027639  0.045405                  0.395355          0.390705      0.011585                 0.994208   -88.416014        65.699140            0.517729\n",
      "     13                0.69997697         0.012568  0.043457         1.426550       0.010369  0.019403                  0.340372          0.337676      0.004344                 0.998552   -95.654337        42.654964            0.392138\n",
      "     14                0.79998464         0.005397  0.011262         1.249622       0.002687  0.008475                  0.298157          0.296522      0.001126                 0.999678   -98.873779        24.962173            0.262271\n",
      "     15                0.89999232         0.001825  0.003218         1.111121       0.000768  0.003373                  0.265111          0.263947      0.000322                 1.000000   -99.678223        11.112059            0.131347\n",
      "     16                1.00000000         0.000161  0.000000         1.000000       0.000000  0.000998                  0.238598          0.237650      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09207797\n",
      " RMSE: 0.30344352\n",
      " AUC: 0.9263019\n",
      " pr_auc: 0.8278981\n",
      " logloss: 0.2879206\n",
      " mean_per_class_error: 0.17066967\n",
      " default threshold: 0.35756829380989075\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4373   514  0.1052  514 / 4,887\n",
      "     1   384  1242  0.2362  384 / 1,626\n",
      "Totals  4757  1756  0.1379  898 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.95 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.996081  4.005535         4.005535       1.000000  0.997452                  1.000000          0.997452      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.993262  4.005535         4.005535       1.000000  0.994751                  1.000000          0.996112      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.988120  4.005535         4.005535       1.000000  0.990826                  1.000000          0.994359      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.979918  4.005535         4.005535       1.000000  0.984202                  1.000000          0.991829      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.965063  4.005535         4.005535       1.000000  0.973329                  1.000000          0.988141      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.808520  3.477198         3.741366       0.868098  0.892263                  0.934049          0.940202      0.174047                 0.374539   247.719761       274.136633            0.365740\n",
      "      7                0.15000768         0.648886  2.810037         3.431559       0.701538  0.726726                  0.856704          0.869189      0.140221                 0.514760   181.003690       243.155869            0.486113\n",
      "      8                0.20006142         0.518675  2.371375         3.166309       0.592025  0.583504                  0.790483          0.797713      0.118696                 0.633456   137.137505       216.630937            0.577594\n",
      "      9                0.30001535         0.294131  1.735117         2.689489       0.433180  0.400341                  0.671443          0.665324      0.173432                 0.806888    73.511657       168.948925            0.675519\n",
      "     10                0.39996929         0.147933  1.045992         2.278773       0.261137  0.215994                  0.568906          0.553034      0.104551                 0.911439     4.599226       127.877273            0.681646\n",
      "     11                0.50007677         0.069918  0.509907         1.924674       0.127301  0.104003                  0.480504          0.463145      0.051046                 0.962485   -49.009293        92.467374            0.616260\n",
      "     12                0.60003071         0.029196  0.233810         1.643007       0.058372  0.046375                  0.410184          0.393719      0.023370                 0.985855   -76.618997        64.300734            0.514195\n",
      "     13                0.69998465         0.012110  0.110752         1.424210       0.027650  0.019163                  0.355560          0.340234      0.011070                 0.996925   -88.924788        42.420977            0.395738\n",
      "     14                0.79993858         0.005483  0.030764         1.250096       0.007680  0.008547                  0.312092          0.298789      0.003075                 1.000000   -96.923552        25.009597            0.266626\n",
      "     15                0.89989252         0.001901  0.000000         1.111244       0.000000  0.003510                  0.277427          0.265992      0.000000                 1.000000  -100.000000        11.124382            0.133415\n",
      "     16                1.00000000         0.000198  0.000000         1.000000       0.000000  0.001041                  0.249655          0.239468      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4155.880371          1.000000   0.197282\n",
      "                      capital_gain         3304.359131          0.795104   0.156860\n",
      "                               age         2015.546509          0.484987   0.095679\n",
      "                            fnlwgt         1984.911133          0.477615   0.094225\n",
      "             relationship. Husband         1875.324463          0.451246   0.089023\n",
      "                    hours_per_week         1302.846802          0.313495   0.061847\n",
      "                      capital_loss         1166.192505          0.280613   0.055360\n",
      "        occupation. Prof-specialty          650.136108          0.156438   0.030862\n",
      "              education. Bachelors          562.604614          0.135376   0.026707\n",
      "       occupation. Exec-managerial          532.013855          0.128015   0.025255\n",
      "---\n",
      "           workclass. Self-emp-inc           19.087101          0.004593   0.000906\n",
      "              workclass. State-gov           12.894225          0.003103   0.000612\n",
      "                       race. Black           12.484092          0.003004   0.000593\n",
      "                     occupation.NA           10.518503          0.002531   0.000499\n",
      "           marital_status. Widowed            9.016663          0.002170   0.000428\n",
      "                education. 5th-6th            7.998797          0.001925   0.000380\n",
      "          race. Amer-Indian-Eskimo            7.935828          0.001910   0.000377\n",
      "                   education. 12th            3.699208          0.000890   0.000176\n",
      "       native_country. Philippines            3.323099          0.000800   0.000158\n",
      "                 native_country.NA            2.587692          0.000623   0.000123\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       119217.687500          1.000000   0.151705\n",
      "                      capital_gain        90329.640625          0.757687   0.114945\n",
      "                               age        89733.218750          0.752684   0.114186\n",
      "                    hours_per_week        66358.687500          0.556618   0.084442\n",
      "                      capital_loss        62365.160156          0.523120   0.079360\n",
      "marital_status. Married-civ-spouse        28794.529297          0.241529   0.036641\n",
      "              education. Bachelors        17415.529297          0.146082   0.022161\n",
      "              education. Doctorate        16386.648438          0.137451   0.020852\n",
      "        occupation. Prof-specialty        15735.185547          0.131987   0.020023\n",
      "       occupation. Exec-managerial        14651.946289          0.122901   0.018645\n",
      "---\n",
      "       relationship. Not-in-family         2460.240723          0.020637   0.003131\n",
      "          race. Asian-Pac-Islander         1869.164063          0.015679   0.002379\n",
      "                     occupation.NA         1834.313965          0.015386   0.002334\n",
      "                 native_country.NA         1425.331177          0.011956   0.001814\n",
      "                   education. 12th         1397.228027          0.011720   0.001778\n",
      "          race. Amer-Indian-Eskimo         1349.694214          0.011321   0.001717\n",
      "       native_country. Philippines         1276.138184          0.010704   0.001624\n",
      "          marital_status. Divorced         1100.038208          0.009227   0.001400\n",
      "                education. 5th-6th         1003.292114          0.008416   0.001277\n",
      "                         sex. Male          729.991150          0.006123   0.000929\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          780.000000          1.000000   0.293343\n",
      "                         age          555.000000          0.711538   0.208725\n",
      "              hours_per_week          273.000000          0.350000   0.102670\n",
      "                capital_gain           87.000000          0.111538   0.032719\n",
      "          workclass. Private           80.000000          0.102564   0.030086\n",
      "          education. HS-grad           68.000000          0.087179   0.025574\n",
      "                capital_loss           67.000000          0.085897   0.025197\n",
      "  occupation. Prof-specialty           59.000000          0.075641   0.022189\n",
      "        education. Bachelors           51.000000          0.065385   0.019180\n",
      "     education. Some-college           44.000000          0.056410   0.016548\n",
      "---\n",
      "               occupation.NA            4.000000          0.005128   0.001504\n",
      "        workclass. State-gov            4.000000          0.005128   0.001504\n",
      "     marital_status. Widowed            3.000000          0.003846   0.001128\n",
      "relationship. Other-relative            3.000000          0.003846   0.001128\n",
      "      native_country. Mexico            3.000000          0.003846   0.001128\n",
      "           native_country.NA            2.000000          0.002564   0.000752\n",
      "             education. 12th            1.000000          0.001282   0.000376\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001282   0.000376\n",
      " native_country. Philippines            1.000000          0.001282   0.000376\n",
      "          education. 5th-6th            1.000000          0.001282   0.000376\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.472 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:00  1.384 sec               5       0.31666          0.34352      0.92331         0.81741       4.19115                       0.13464         0.32306            0.35368        0.91567           0.81291         4.00554                         0.14433\n",
      " 2023-10-20 18:27:01  2.405 sec              10       0.29696          0.28908      0.93047         0.83266       4.19115                       0.13283         0.30743            0.30597        0.92154           0.82273         4.00554                         0.13726\n",
      " 2023-10-20 18:27:01  3.062 sec              15       0.28980          0.26948      0.93568         0.84353       4.19115                       0.12899         0.30235            0.28963        0.92608           0.83140         4.00554                         0.13803\n",
      " 2023-10-20 18:27:02  3.900 sec              20       0.28552          0.26048      0.93937         0.85104       4.19115                       0.12312         0.30193            0.28685        0.92659           0.83134         4.00554                         0.14156\n",
      " 2023-10-20 18:27:03  4.463 sec              25       0.28224          0.25428      0.94224         0.85712       4.19115                       0.11794         0.30272            0.28782        0.92593           0.83002         4.00554                         0.13588\n",
      " 2023-10-20 18:27:04  5.318 sec              30       0.27855          0.24808      0.94518         0.86390       4.19115                       0.11548         0.30224            0.28670        0.92653           0.83070         4.00554                         0.14110\n",
      " 2023-10-20 18:27:05  6.505 sec              35       0.27535          0.24282      0.94791         0.86954       4.19115                       0.11713         0.30336            0.28826        0.92597           0.82828         4.00554                         0.13772\n",
      " 2023-10-20 18:27:06  7.522 sec              40       0.27249          0.23830      0.95020         0.87468       4.19115                       0.10726         0.30344            0.28792        0.92630           0.82790         4.00554                         0.13788\n",
      "\n",
      "10-20 18:27:08.224 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: In-training scoring took 6013ms.\n",
      "10-20 18:27:08.249 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model XGBoost_1_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:08.250 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:08.309 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_80\n",
      "10-20 18:27:08.316 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_80\n",
      "10-20 18:27:08.329 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07316164\n",
      " RMSE: 0.2704841\n",
      " AUC: 0.952134\n",
      " pr_auc: 0.88076967\n",
      " logloss: 0.235396\n",
      " mean_per_class_error: 0.13242607\n",
      " default threshold: 0.3811228573322296\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18083  1662  0.0842  1,662 / 19,745\n",
      "     1   1139  5165  0.1807   1,139 / 6,304\n",
      "Totals  19222  6827  0.1075  2,801 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.26 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995246  4.132138         4.132138       1.000000  0.996620                  1.000000          0.996620      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.992633  4.132138         4.132138       1.000000  0.993953                  1.000000          0.995289      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.988162  4.132138         4.132138       1.000000  0.990526                  1.000000          0.993699      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.980887  4.116245         4.128173       0.996154  0.984992                  0.999040          0.991527      0.041085                 0.165133   311.624549       312.817274            0.165083\n",
      "      5                0.05002111         0.968174  4.084642         4.119453       0.988506  0.975406                  0.996930          0.988298      0.040926                 0.206060   308.464248       311.945333            0.205857\n",
      "      6                0.10000384         0.818710  3.916328         4.017930       0.947773  0.896103                  0.972361          0.942218      0.195749                 0.401808   291.632772       301.792951            0.398162\n",
      "      7                0.15002495         0.672563  3.301271         3.778982       0.798926  0.743122                  0.914534          0.875836      0.165133                 0.566942   230.127091       277.898218            0.550026\n",
      "      8                0.20000768         0.530814  2.573859         3.477817       0.622888  0.599820                  0.841651          0.806858      0.128648                 0.695590   157.385882       247.781700            0.653807\n",
      "      9                0.30001152         0.305118  1.755961         2.903865       0.424952  0.410144                  0.702751          0.674620      0.175603                 0.871193    75.596051       190.386483            0.753543\n",
      "     10                0.40001536         0.149124  0.786772         2.374592       0.190403  0.219436                  0.574664          0.560824      0.078680                 0.949873   -21.322817       137.459158            0.725411\n",
      "     11                0.50001919         0.068084  0.342626         1.968199       0.082917  0.103120                  0.476315          0.469283      0.034264                 0.984137   -65.737356        96.819855            0.638683\n",
      "     12                0.59998464         0.028987  0.103145         1.657456       0.024962  0.045969                  0.401113          0.398753      0.010311                 0.994448   -89.685523        65.745570            0.520404\n",
      "     13                0.69998848         0.012694  0.042828         1.426782       0.010365  0.019575                  0.345289          0.344582      0.004283                 0.998731   -95.717169        42.678199            0.394122\n",
      "     14                0.79999232         0.005594  0.011104         1.249814       0.002687  0.008782                  0.302462          0.302605      0.001110                 0.999841   -98.889637        24.981371            0.263655\n",
      "     15                0.89999616         0.002058  0.001586         1.111116       0.000384  0.003626                  0.268896          0.269384      0.000159                 1.000000   -99.841377        11.111585            0.131932\n",
      "     16                1.00000000         0.000201  0.000000         1.000000       0.000000  0.001092                  0.242005          0.242554      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09504632\n",
      " RMSE: 0.30829585\n",
      " AUC: 0.9153765\n",
      " pr_auc: 0.800664\n",
      " logloss: 0.29972842\n",
      " mean_per_class_error: 0.18473087\n",
      " default threshold: 0.3804539442062378\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4409   566  0.1138  566 / 4,975\n",
      "     1   393  1144  0.2557  393 / 1,537\n",
      "Totals  4802  1710  0.1473  959 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994576  4.236825         4.236825       1.000000  0.996420                  1.000000          0.996420      0.042941                 0.042941   323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.991554  4.236825         4.236825       1.000000  0.993063                  1.000000          0.994754      0.042290                 0.085231   323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.986943  4.236825         4.236825       1.000000  0.989628                  1.000000          0.993054      0.042290                 0.127521   323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.976612  4.171643         4.220592       0.984615  0.982104                  0.996169          0.990327      0.041640                 0.169161   317.164306       322.059194            0.168960\n",
      "      5                0.05006143         0.959500  4.236825         4.223829       1.000000  0.969198                  0.996933          0.986114      0.042290                 0.211451   323.682498       322.382859            0.211250\n",
      "      6                0.10012285         0.807380  3.392059         3.807944       0.800613  0.885413                  0.898773          0.935764      0.169811                 0.381262   239.205927       280.794393            0.367996\n",
      "      7                0.15003071         0.655982  2.868005         3.495272       0.676923  0.735268                  0.824974          0.869069      0.143136                 0.524398   186.800460       249.527220            0.490026\n",
      "      8                0.20009214         0.510434  2.274369         3.189812       0.536810  0.584920                  0.752878          0.797977      0.113858                 0.638256   127.436924       218.981221            0.573533\n",
      "      9                0.30006143         0.311696  1.568471         2.649642       0.370200  0.407384                  0.625384          0.667846      0.156799                 0.795055    56.847131       164.964183            0.647920\n",
      "     10                0.40003071         0.156078  1.080358         2.257471       0.254992  0.229314                  0.532821          0.558255      0.108003                 0.903058     8.035783       125.747143            0.658435\n",
      "     11                0.50000000         0.068313  0.540179         1.914118       0.127496  0.106289                  0.451781          0.467890      0.054001                 0.957059   -45.982109        91.411841            0.598265\n",
      "     12                0.59996929         0.028663  0.221278         1.632051       0.052227  0.046040                  0.385206          0.397599      0.022121                 0.979180   -77.872189        63.205058            0.496366\n",
      "     13                0.69993857         0.012865  0.091115         1.411965       0.021505  0.019319                  0.333260          0.343571      0.009109                 0.988289   -90.888548        41.196515            0.377435\n",
      "     14                0.79990786         0.005657  0.084606         1.246077       0.019969  0.008999                  0.294106          0.301758      0.008458                 0.996747   -91.539366        24.607715            0.257651\n",
      "     15                0.89987715         0.002090  0.032541         1.111263       0.007680  0.003674                  0.262287          0.268643      0.003253                 1.000000   -96.745910        11.126280            0.131055\n",
      "     16                1.00000000         0.000217  0.000000         1.000000       0.000000  0.001097                  0.236026          0.241855      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4170.911133          1.000000   0.191350\n",
      "                      capital_gain         3503.247559          0.839924   0.160720\n",
      "                               age         2342.478027          0.561623   0.107467\n",
      "                            fnlwgt         2265.592041          0.543189   0.103939\n",
      "marital_status. Married-civ-spouse         1477.721436          0.354292   0.067794\n",
      "                      capital_loss         1241.546265          0.297668   0.056959\n",
      "                    hours_per_week         1223.862915          0.293428   0.056148\n",
      "              education. Bachelors          724.218262          0.173636   0.033225\n",
      "        occupation. Prof-specialty          532.505920          0.127671   0.024430\n",
      "       occupation. Exec-managerial          521.607666          0.125058   0.023930\n",
      "---\n",
      "                     occupation.NA           14.503084          0.003477   0.000665\n",
      "                      workclass.NA           11.150998          0.002674   0.000512\n",
      "                 native_country.NA            9.256384          0.002219   0.000425\n",
      "          race. Asian-Pac-Islander            9.227043          0.002212   0.000423\n",
      "          race. Amer-Indian-Eskimo            5.838183          0.001400   0.000268\n",
      "                education. 5th-6th            5.686970          0.001363   0.000261\n",
      "       native_country. Philippines            5.432164          0.001302   0.000249\n",
      "           marital_status. Widowed            5.054038          0.001212   0.000232\n",
      "      relationship. Other-relative            4.376630          0.001049   0.000201\n",
      "         marital_status. Separated            1.875626          0.000450   0.000086\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       130528.203125          1.000000   0.167892\n",
      "                               age       105780.156250          0.810401   0.136060\n",
      "                      capital_gain        78731.195313          0.603174   0.101268\n",
      "                      capital_loss        67099.117188          0.514058   0.086306\n",
      "                    hours_per_week        57185.156250          0.438106   0.073555\n",
      "marital_status. Married-civ-spouse        22437.347656          0.171897   0.028860\n",
      "             relationship. Husband        19355.892578          0.148289   0.024897\n",
      "              education. Bachelors        17278.517578          0.132374   0.022225\n",
      "                education. Masters        14962.429688          0.114630   0.019245\n",
      "        occupation. Prof-specialty        14813.842773          0.113492   0.019054\n",
      "---\n",
      "              workclass. Local-gov         2026.174561          0.015523   0.002606\n",
      "                     occupation.NA         1890.959473          0.014487   0.002432\n",
      "          marital_status. Divorced         1869.199585          0.014320   0.002404\n",
      "           relationship. Unmarried         1540.066040          0.011799   0.001981\n",
      "          race. Asian-Pac-Islander         1430.474731          0.010959   0.001840\n",
      "          race. Amer-Indian-Eskimo         1420.591553          0.010883   0.001827\n",
      "      relationship. Other-relative         1396.271484          0.010697   0.001796\n",
      "                education. 5th-6th         1351.620972          0.010355   0.001739\n",
      "       native_country. Philippines         1315.266724          0.010076   0.001692\n",
      "         marital_status. Separated          964.407288          0.007388   0.001240\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          933.000000          1.000000   0.332620\n",
      "                         age          611.000000          0.654877   0.217825\n",
      "              hours_per_week          246.000000          0.263666   0.087701\n",
      "                capital_gain           84.000000          0.090032   0.029947\n",
      "          workclass. Private           77.000000          0.082529   0.027451\n",
      "                capital_loss           76.000000          0.081458   0.027094\n",
      "          education. HS-grad           71.000000          0.076099   0.025312\n",
      "        education. Bachelors           60.000000          0.064309   0.021390\n",
      "  occupation. Prof-specialty           55.000000          0.058950   0.019608\n",
      " occupation. Exec-managerial           45.000000          0.048232   0.016043\n",
      "---\n",
      "              education. 9th            4.000000          0.004287   0.001426\n",
      "     marital_status. Widowed            3.000000          0.003215   0.001070\n",
      "               occupation.NA            3.000000          0.003215   0.001070\n",
      "    race. Asian-Pac-Islander            3.000000          0.003215   0.001070\n",
      "           native_country.NA            3.000000          0.003215   0.001070\n",
      "relationship. Other-relative            1.000000          0.001072   0.000357\n",
      "   marital_status. Separated            1.000000          0.001072   0.000357\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.001072   0.000357\n",
      " native_country. Philippines            1.000000          0.001072   0.000357\n",
      "          education. 5th-6th            1.000000          0.001072   0.000357\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.476 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:00  1.653 sec               5       0.31422          0.33853      0.92577         0.82437       4.13214                       0.14430         0.32520            0.35513        0.90480           0.78218         4.23682                         0.15387\n",
      " 2023-10-20 18:27:01  2.520 sec              10       0.29373          0.28252      0.93393         0.84248       4.13214                       0.12649         0.31165            0.31117        0.90996           0.79259         4.23682                         0.15080\n",
      " 2023-10-20 18:27:01  3.188 sec              15       0.28743          0.26523      0.93865         0.85154       4.13214                       0.12231         0.30741            0.29906        0.91471           0.80193         4.23682                         0.13805\n",
      " 2023-10-20 18:27:02  3.948 sec              20       0.28375          0.25710      0.94156         0.85776       4.13214                       0.11977         0.30632            0.29578        0.91635           0.80451         4.23682                         0.13851\n",
      " 2023-10-20 18:27:03  4.624 sec              25       0.28033          0.25097      0.94441         0.86363       4.13214                       0.11594         0.30676            0.29629        0.91661           0.80377         4.23682                         0.14235\n",
      " 2023-10-20 18:27:04  5.552 sec              30       0.27657          0.24498      0.94738         0.87019       4.13214                       0.11233         0.30712            0.29718        0.91640           0.80334         4.23682                         0.13790\n",
      " 2023-10-20 18:27:05  6.375 sec              35       0.27337          0.23982      0.94995         0.87590       4.13214                       0.11409         0.30796            0.29865        0.91594           0.80104         4.23682                         0.14112\n",
      " 2023-10-20 18:27:06  7.392 sec              40       0.27048          0.23540      0.95213         0.88077       4.13214                       0.10753         0.30830            0.29973        0.91538           0.80066         4.23682                         0.14727\n",
      "\n",
      "10-20 18:27:08.334 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: In-training scoring took 5596ms.\n",
      "10-20 18:27:08.345 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model XGBoost_1_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:08.406 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_81\n",
      "10-20 18:27:08.418 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_81\n",
      "10-20 18:27:08.423 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.073273316\n",
      " RMSE: 0.27069044\n",
      " AUC: 0.95153475\n",
      " pr_auc: 0.8807637\n",
      " logloss: 0.23681758\n",
      " mean_per_class_error: 0.13625406\n",
      " default threshold: 0.3991260230541229\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18203  1535  0.0778  1,535 / 19,738\n",
      "     1   1229  5082  0.1947   1,229 / 6,311\n",
      "Totals  19432  6617  0.1061  2,764 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.31 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995395  4.127555         4.127555       1.000000  0.996734                  1.000000          0.996734      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.992630  4.127555         4.127555       1.000000  0.994130                  1.000000          0.995435      0.041198                 0.082554  312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.988486  4.127555         4.127555       1.000000  0.990749                  1.000000          0.993871      0.041356                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.981450  4.111680         4.123594       0.996154  0.985297                  0.999040          0.991732      0.041039                 0.164950  311.167985       312.359388            0.164899\n",
      "      5                0.05002111         0.968156  4.064298         4.111716       0.984674  0.975531                  0.996163          0.988487      0.040723                 0.205673  306.429751       311.171640            0.205419\n",
      "      6                0.10000384         0.814054  3.889793         4.000797       0.942396  0.895274                  0.969290          0.941898      0.194422                 0.400095  288.979267       300.079713            0.396042\n",
      "      7                0.15002495         0.667253  3.341957         3.781128       0.809670  0.738252                  0.916070          0.873999      0.167168                 0.567264  234.195748       278.112772            0.550646\n",
      "      8                0.20000768         0.529709  2.656598         3.500103       0.643625  0.599787                  0.847985          0.805472      0.132784                 0.700048  165.659842       250.010331            0.659922\n",
      "      9                0.30001152         0.305058  1.682712         2.894306       0.407678  0.410664                  0.701216          0.673869      0.168278                 0.868325   68.271151       189.430605            0.750025\n",
      "     10                0.40001536         0.152146  0.782730         2.366412       0.189635  0.223024                  0.573321          0.561158      0.078276                 0.946601  -21.726979       136.641209            0.721350\n",
      "     11                0.50001919         0.068096  0.339077         1.960945       0.082150  0.105801                  0.475086          0.470086      0.033909                 0.980510  -66.092254        96.094516            0.634123\n",
      "     12                0.59998464         0.030158  0.123636         1.654825       0.029954  0.046400                  0.400921          0.399495      0.012359                 0.992870  -87.636356        65.482501            0.518505\n",
      "     13                0.69998848         0.013284  0.053872         1.426105       0.013052  0.020446                  0.345508          0.345342      0.005387                 0.998257  -94.612788        42.610491            0.393636\n",
      "     14                0.79999232         0.005615  0.014260         1.249616       0.003455  0.008984                  0.302750          0.303295      0.001426                 0.999683  -98.573973        24.961586            0.263540\n",
      "     15                0.89999616         0.001972  0.001584         1.110940       0.000384  0.003552                  0.269152          0.269989      0.000158                 0.999842  -99.841553        11.093979            0.131770\n",
      "     16                1.00000000         0.000139  0.001584         1.000000       0.000384  0.001049                  0.242274          0.243094      0.000158                 1.000000  -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09128824\n",
      " RMSE: 0.30213943\n",
      " AUC: 0.92242235\n",
      " pr_auc: 0.81301343\n",
      " logloss: 0.28645223\n",
      " mean_per_class_error: 0.17523621\n",
      " default threshold: 0.3742513060569763\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4444   538  0.1080  538 / 4,982\n",
      "     1   371  1159  0.2425  371 / 1,530\n",
      "Totals  4815  1697  0.1396  909 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.80 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995085  4.256209         4.256209       1.000000  0.996383                  1.000000          0.996383      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.992425  4.256209         4.256209       1.000000  0.993825                  1.000000          0.995114      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.988181  4.256209         4.256209       1.000000  0.990674                  1.000000          0.993641      0.042484                 0.128105   325.620915       325.620915            0.128105\n",
      "      4                0.04007985         0.980329  4.190729         4.239902       0.984615  0.984883                  0.996169          0.991460      0.041830                 0.169935   319.072901       323.990184            0.169734\n",
      "      5                0.05006143         0.964839  4.125249         4.217042       0.969231  0.974039                  0.990798          0.987987      0.041176                 0.211111   312.524887       321.704158            0.210509\n",
      "      6                0.10012285         0.809195  3.694807         3.955924       0.868098  0.887649                  0.929448          0.937818      0.184967                 0.396078   269.480733       295.592446            0.386845\n",
      "      7                0.15003071         0.650474  2.841838         3.585323       0.667692  0.724124                  0.842375          0.866732      0.141830                 0.537908   184.183811       258.532255            0.506997\n",
      "      8                0.20009214         0.508490  2.180328         3.233804       0.512270  0.573839                  0.759785          0.793453      0.109150                 0.647059   118.032800       223.380434            0.584233\n",
      "      9                0.30006143         0.291641  1.601799         2.690081       0.376344  0.394842                  0.632037          0.660651      0.160131                 0.807190    60.179914       169.008101            0.662870\n",
      "     10                0.40003071         0.146386  0.987231         2.264532       0.231951  0.213176                  0.532054          0.548825      0.098693                 0.905882    -1.276869       126.453201            0.661202\n",
      "     11                0.50000000         0.068060  0.581878         1.928105       0.136713  0.103604                  0.453010          0.459808      0.058170                 0.964052   -41.812194        92.810458            0.606565\n",
      "     12                0.59996929         0.030260  0.254980         1.649322       0.059908  0.047214                  0.387510          0.391060      0.025490                 0.989542   -74.501973        64.932190            0.509213\n",
      "     13                0.69993857         0.013572  0.065380         1.423094       0.015361  0.020712                  0.334357          0.338165      0.006536                 0.996078   -93.462044        42.309406            0.387086\n",
      "     14                0.79990786         0.005609  0.026152         1.248510       0.006144  0.008967                  0.293338          0.297023      0.002614                 0.998693   -97.384818        24.850981            0.259833\n",
      "     15                0.89987715         0.001875  0.013076         1.111263       0.003072  0.003460                  0.261092          0.264410      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000185  0.000000         1.000000       0.000000  0.000953                  0.234951          0.238032      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         4114.416016          1.000000   0.187427\n",
      "                      capital_gain         3546.480225          0.861964   0.161555\n",
      "                               age         2424.776611          0.589337   0.110458\n",
      "                            fnlwgt         2332.043213          0.566798   0.106233\n",
      "marital_status. Married-civ-spouse         1500.098511          0.364596   0.068335\n",
      "                    hours_per_week         1200.268188          0.291723   0.054677\n",
      "                      capital_loss         1189.409302          0.289083   0.054182\n",
      "              education. Bachelors          669.774536          0.162787   0.030511\n",
      "        occupation. Prof-specialty          584.839233          0.142144   0.026642\n",
      "       occupation. Exec-managerial          582.938721          0.141682   0.026555\n",
      "---\n",
      "           marital_status. Widowed           17.837631          0.004335   0.000813\n",
      "                       race. Black           15.021633          0.003651   0.000684\n",
      "                     occupation.NA           11.762693          0.002859   0.000536\n",
      "           relationship. Unmarried           11.002371          0.002674   0.000501\n",
      "              workclass. State-gov           10.131887          0.002463   0.000462\n",
      "                      workclass.NA            9.695875          0.002357   0.000442\n",
      "         marital_status. Separated            9.013293          0.002191   0.000411\n",
      "                 native_country.NA            8.593095          0.002089   0.000391\n",
      "                education. 5th-6th            6.929251          0.001684   0.000316\n",
      "          race. Amer-Indian-Eskimo            4.215075          0.001024   0.000192\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       137839.234375          1.000000   0.176327\n",
      "                               age        95360.812500          0.691826   0.121987\n",
      "                      capital_gain        76565.117188          0.555467   0.097944\n",
      "                      capital_loss        62134.785156          0.450777   0.079484\n",
      "                    hours_per_week        59594.886719          0.432351   0.076235\n",
      "             relationship. Husband        20522.976563          0.148891   0.026253\n",
      "marital_status. Married-civ-spouse        18039.359375          0.130872   0.023076\n",
      "              education. Bachelors        15803.999023          0.114655   0.020217\n",
      "       occupation. Exec-managerial        15298.596680          0.110989   0.019570\n",
      "        occupation. Prof-specialty        14197.132813          0.102998   0.018161\n",
      "---\n",
      "                       race. Black         2560.242188          0.018574   0.003275\n",
      "         marital_status. Separated         2429.499023          0.017626   0.003108\n",
      "           relationship. Unmarried         2286.664551          0.016589   0.002925\n",
      "                 native_country.NA         2190.556885          0.015892   0.002802\n",
      "                     occupation.NA         1970.962646          0.014299   0.002521\n",
      "              workclass. State-gov         1939.761353          0.014073   0.002481\n",
      "          marital_status. Divorced         1843.108032          0.013371   0.002358\n",
      "                      workclass.NA         1758.579102          0.012758   0.002250\n",
      "          race. Amer-Indian-Eskimo         1413.515991          0.010255   0.001808\n",
      "                education. 5th-6th          713.308777          0.005175   0.000912\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          927.000000          1.000000   0.325606\n",
      "                          age          604.000000          0.651564   0.212153\n",
      "               hours_per_week          241.000000          0.259978   0.084651\n",
      "           workclass. Private           86.000000          0.092772   0.030207\n",
      "           education. HS-grad           77.000000          0.083064   0.027046\n",
      "                 capital_gain           77.000000          0.083064   0.027046\n",
      "                 capital_loss           74.000000          0.079827   0.025992\n",
      "         education. Bachelors           64.000000          0.069040   0.022480\n",
      "   occupation. Prof-specialty           47.000000          0.050701   0.016509\n",
      "  occupation. Exec-managerial           45.000000          0.048544   0.015806\n",
      "---\n",
      "        education. Assoc-acdm            5.000000          0.005394   0.001756\n",
      "occupation. Handlers-cleaners            4.000000          0.004315   0.001405\n",
      "               education. 9th            4.000000          0.004315   0.001405\n",
      "                occupation.NA            3.000000          0.003236   0.001054\n",
      "                 workclass.NA            3.000000          0.003236   0.001054\n",
      "         workclass. State-gov            3.000000          0.003236   0.001054\n",
      "            native_country.NA            3.000000          0.003236   0.001054\n",
      "    marital_status. Separated            2.000000          0.002157   0.000702\n",
      "     race. Amer-Indian-Eskimo            1.000000          0.001079   0.000351\n",
      "           education. 5th-6th            1.000000          0.001079   0.000351\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:26:59  0.452 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:00  1.650 sec               5       0.31473          0.33933      0.92473         0.82356       4.12756                       0.13425         0.31985            0.34668        0.91378           0.79545         4.25621                         0.14512\n",
      " 2023-10-20 18:27:01  2.517 sec              10       0.29488          0.28424      0.93286         0.84071       4.12756                       0.13006         0.30431            0.29843        0.91976           0.80805         4.25621                         0.14911\n",
      " 2023-10-20 18:27:01  3.105 sec              15       0.28852          0.26741      0.93774         0.85016       4.12756                       0.12419         0.30063            0.28664        0.92277           0.81416         4.25621                         0.13114\n",
      " 2023-10-20 18:27:02  3.824 sec              20       0.28393          0.25830      0.94145         0.85820       4.12756                       0.12235         0.30044            0.28487        0.92305           0.81492         4.25621                         0.14220\n",
      " 2023-10-20 18:27:03  4.564 sec              25       0.28038          0.25209      0.94407         0.86424       4.12756                       0.11620         0.30086            0.28541        0.92254           0.81423         4.25621                         0.14005\n",
      " 2023-10-20 18:27:04  5.475 sec              30       0.27707          0.24659      0.94663         0.86998       4.12756                       0.11217         0.30131            0.28561        0.92263           0.81393         4.25621                         0.13345\n",
      " 2023-10-20 18:27:05  6.533 sec              35       0.27410          0.24180      0.94896         0.87478       4.12756                       0.10630         0.30137            0.28518        0.92321           0.81404         4.25621                         0.14082\n",
      " 2023-10-20 18:27:06  7.766 sec              40       0.27069          0.23682      0.95153         0.88076       4.12756                       0.10611         0.30214            0.28645        0.92242           0.81301         4.25621                         0.13959\n",
      "\n",
      "10-20 18:27:08.430 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: In-training scoring took 5644ms.\n",
      "10-20 18:27:08.449 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Completing model XGBoost_1_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 5 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:08.450 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:08.455 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:08.455 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: {\"_train\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_5_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":42,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":4,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":15,\"_min_rows\":10.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:08.456 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:08.478 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:08.511 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:08.511 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Starting model XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      "10-20 18:27:08.512 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:08.513 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:08.514 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:08.514 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:08.514 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:08.514 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:08.514 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:08.515 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:08.515 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  seed = 42\n",
      "10-20 18:27:08.515 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 15\n",
      "10-20 18:27:08.515 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:08.515 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:08.516 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:08.517 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:08.517 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:08.517 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 10.0\n",
      "10-20 18:27:08.517 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:08.517 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:08.554 172.17.0.2:54321      22766  82658_cv_5  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:08.606 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_82\n",
      "10-20 18:27:08.611 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_82\n",
      "10-20 18:27:08.636 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_83\n",
      "10-20 18:27:08.641 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_83\n",
      "10-20 18:27:08.644 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2400476\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19796  1.0000  19,796 / 19,796\n",
      "     1  0   6253  0.0000        0 / 6,253\n",
      "Totals  0  26049  0.7600  19,796 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.240048  0.500000                  0.240048          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24385749\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4924  1.0000  4,924 / 4,924\n",
      "     1  0  1588  0.0000      0 / 1,588\n",
      "Totals  0  6512  0.7561  4,924 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.243857  0.500000                  0.243857          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      "\n",
      "10-20 18:27:08.700 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:08.700) \n",
      "█10-20 18:27:08.740 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:08.740) \n",
      "10-20 18:27:08.788 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:08.788) \n",
      "10-20 18:27:08.832 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:08.832) \n",
      "10-20 18:27:08.871 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:08.870) \n",
      "10-20 18:27:08.896 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_84\n",
      "10-20 18:27:08.907 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_84\n",
      "10-20 18:27:08.939 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_85\n",
      "10-20 18:27:08.946 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_85\n",
      "10-20 18:27:08.953 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.09899639\n",
      " RMSE: 0.31463692\n",
      " AUC: 0.9235283\n",
      " pr_auc: 0.8208707\n",
      " logloss: 0.33915213\n",
      " mean_per_class_error: 0.17236201\n",
      " default threshold: 0.36163628101348877\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17480  2316  0.1170  2,316 / 19,796\n",
      "     1   1424  4829  0.2277   1,424 / 6,253\n",
      "Totals  18904  7145  0.1436  3,740 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 29.17 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01992399         0.894486  4.165840         4.165840       1.000000  0.894575                  1.000000          0.894575      0.083000                 0.083000  316.584040       316.584040            0.083000\n",
      "      2                0.02840800         0.893738  4.165840         4.165840       1.000000  0.893738                  1.000000          0.894325      0.035343                 0.118343  316.584040       316.584040            0.118343\n",
      "      3                0.03205497         0.886823  4.165840         4.165840       1.000000  0.886982                  1.000000          0.893489      0.015193                 0.133536  316.584040       316.584040            0.133536\n",
      "      4                0.04019348         0.879823  4.165840         4.165840       1.000000  0.881681                  1.000000          0.891098      0.033904                 0.167440  316.584040       316.584040            0.167440\n",
      "      5                0.05052017         0.860490  3.980004         4.127854       0.955390  0.867071                  0.990881          0.886187      0.041100                 0.208540  298.000365       312.785401            0.207934\n",
      "      6                0.10000384         0.675023  3.681065         3.906775       0.883631  0.751391                  0.937812          0.819488      0.182153                 0.390692  268.106456       290.677470            0.382509\n",
      "      7                0.15002495         0.552930  2.864615         3.559299       0.687644  0.613950                  0.854401          0.750958      0.143291                 0.533984  186.461473       255.929915            0.505241\n",
      "      8                0.20000768         0.456383  2.220502         3.224728       0.533026  0.501639                  0.774088          0.688652      0.110987                 0.644970  122.050172       222.472828            0.585514\n",
      "      9                0.30008830         0.342662  1.589954         2.679525       0.381665  0.392774                  0.643214          0.589976      0.159124                 0.804094   58.995443       167.952482            0.663207\n",
      "     10                0.40001536         0.264344  1.035459         2.268824       0.248559  0.303724                  0.544626          0.518468      0.103470                 0.907564    3.545860       126.882382            0.667869\n",
      "     11                0.50001919         0.194391  0.505338         1.916127       0.121305  0.228238                  0.459962          0.460422      0.050536                 0.958100  -49.466197        91.612667            0.602776\n",
      "     12                0.60009981         0.140808  0.271651         1.641872       0.065209  0.165199                  0.394127          0.411186      0.027187                 0.985287  -72.834949        64.187197            0.506857\n",
      "     13                0.73208185         0.115975  0.075126         1.359414       0.018034  0.122576                  0.326324          0.359155      0.009915                 0.995202  -92.487432        35.941399            0.346233\n",
      "     14                0.80759338         0.108249  0.042357         1.236267       0.010168  0.111833                  0.296763          0.336030      0.003198                 0.998401  -95.764270        23.626665            0.251078\n",
      "     15                1.00000000         0.105028  0.008312         1.000000       0.001995  0.105475                  0.240048          0.291670      0.001599                 1.000000  -99.168827         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.10504019\n",
      " RMSE: 0.32409903\n",
      " AUC: 0.9115499\n",
      " pr_auc: 0.7973728\n",
      " logloss: 0.35345364\n",
      " mean_per_class_error: 0.18029796\n",
      " default threshold: 0.35436388850212097\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error           Rate\n",
      "     0  4274   650  0.1320    650 / 4,924\n",
      "     1   363  1225  0.2286    363 / 1,588\n",
      "Totals  4637  1875  0.1556  1,013 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 29.26 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02027027         0.894486  4.100756         4.100756       1.000000  0.894595                  1.000000          0.894595      0.083123                 0.083123  310.075567       310.075567            0.083123\n",
      "      2                0.03209459         0.886823  4.100756         4.100756       1.000000  0.891785                  1.000000          0.893560      0.048489                 0.131612  310.075567       310.075567            0.131612\n",
      "      3                0.04069410         0.879823  4.100756         4.100756       1.000000  0.881764                  1.000000          0.891067      0.035264                 0.166877  310.075567       310.075567            0.166877\n",
      "      4                0.05098280         0.860490  3.855934         4.051349       0.940299  0.865975                  0.987952          0.886003      0.039673                 0.206549  285.593443       305.134897            0.205737\n",
      "      5                0.10012285         0.671569  3.408753         3.735965       0.831250  0.744690                  0.911043          0.816647      0.167506                 0.374055  240.875315       273.596452            0.362276\n",
      "      6                0.15003071         0.551049  2.674954         3.383018       0.652308  0.613439                  0.824974          0.749050      0.133501                 0.507557  167.495447       238.301849            0.472829\n",
      "      7                0.20009214         0.460449  2.264221         3.103104       0.552147  0.505927                  0.756715          0.688222      0.113350                 0.620907  126.422092       210.310444            0.556528\n",
      "      8                0.30006143         0.344173  1.650381         2.619111       0.402458  0.394821                  0.638690          0.590472      0.164987                 0.785894   65.038093       161.911109            0.642515\n",
      "      9                0.40003071         0.262131  0.957473         2.203861       0.233487  0.303285                  0.537428          0.518703      0.095718                 0.881612   -4.252709       120.386101            0.636892\n",
      "     10                0.50030713         0.197417  0.590308         1.880457       0.143951  0.229962                  0.458564          0.460831      0.059194                 0.940806  -40.969214        88.045702            0.582561\n",
      "     11                0.60089066         0.144119  0.406945         1.633805       0.099237  0.167947                  0.398416          0.411805      0.040932                 0.981738  -59.305478        63.380478            0.503671\n",
      "     12                0.70039926         0.115979  0.126567         1.419665       0.030864  0.127250                  0.346196          0.371377      0.012594                 0.994332  -87.343347        41.966525            0.388727\n",
      "     13                0.80927518         0.108249  0.034703         1.233339       0.008463  0.113227                  0.300759          0.336647      0.003778                 0.998111  -96.529685        23.333923            0.249736\n",
      "     14                1.00000000         0.105028  0.009905         1.000000       0.002415  0.105468                  0.243857          0.292555      0.001889                 1.000000  -99.009479         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3782.169189          1.000000   0.288396\n",
      "                      capital_gain         2804.579834          0.741527   0.213853\n",
      "marital_status. Married-civ-spouse         1190.248901          0.314700   0.090758\n",
      "                               age          728.890137          0.192717   0.055579\n",
      "                      capital_loss          684.617004          0.181012   0.052203\n",
      "                    hours_per_week          549.518005          0.145292   0.041902\n",
      "              education. Bachelors          545.257080          0.144165   0.041577\n",
      "       occupation. Exec-managerial          492.449158          0.130203   0.037550\n",
      "        occupation. Prof-specialty          488.814087          0.129242   0.037273\n",
      "                            fnlwgt          367.268188          0.097105   0.028005\n",
      "---\n",
      "       relationship. Not-in-family            8.555092          0.002262   0.000652\n",
      "            workclass. Federal-gov            7.877038          0.002083   0.000601\n",
      "                    education. 9th            7.637779          0.002019   0.000582\n",
      "                   education. 10th            6.377386          0.001686   0.000486\n",
      "                     occupation.NA            6.096756          0.001612   0.000465\n",
      "      occupation. Transport-moving            5.662746          0.001497   0.000432\n",
      "           relationship. Own-child            2.753830          0.000728   0.000210\n",
      "     occupation. Handlers-cleaners            2.454334          0.000649   0.000187\n",
      "          marital_status. Divorced            2.224319          0.000588   0.000170\n",
      "                       race. Black            1.216843          0.000322   0.000093\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        17940.707031          1.000000   0.119509\n",
      "                      capital_gain        17430.068359          0.971537   0.116108\n",
      "             relationship. Husband        13705.279297          0.763921   0.091296\n",
      "                    hours_per_week        13482.842773          0.751522   0.089814\n",
      "       occupation. Exec-managerial         9737.155273          0.542741   0.064863\n",
      "        occupation. Prof-specialty         9444.685547          0.526439   0.062914\n",
      "                            fnlwgt         9114.835938          0.508053   0.060717\n",
      "                      capital_loss         7261.246582          0.404736   0.048370\n",
      "marital_status. Married-civ-spouse         7159.186035          0.399047   0.047690\n",
      "              education. Bachelors         6824.134766          0.380372   0.045458\n",
      "---\n",
      "                   education. 10th          383.846649          0.021395   0.002557\n",
      "       relationship. Not-in-family          278.342133          0.015515   0.001854\n",
      "                         sex. Male          245.611237          0.013690   0.001636\n",
      "     occupation. Handlers-cleaners          235.237000          0.013112   0.001567\n",
      "                       race. Black          226.792725          0.012641   0.001511\n",
      "      occupation. Transport-moving          170.315964          0.009493   0.001135\n",
      "           relationship. Own-child          161.637070          0.009010   0.001077\n",
      "             education. Assoc-acdm          126.351097          0.007043   0.000842\n",
      "                       race. White           97.817673          0.005452   0.000652\n",
      "          marital_status. Divorced           51.500000          0.002871   0.000343\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          159.000000          1.000000   0.290146\n",
      "                          age          117.000000          0.735849   0.213504\n",
      "               hours_per_week           48.000000          0.301887   0.087591\n",
      "         education. Bachelors           20.000000          0.125786   0.036496\n",
      "  occupation. Exec-managerial           17.000000          0.106918   0.031022\n",
      "                 capital_gain           17.000000          0.106918   0.031022\n",
      "                 capital_loss           15.000000          0.094340   0.027372\n",
      "   occupation. Prof-specialty           15.000000          0.094340   0.027372\n",
      "                  sex. Female           15.000000          0.094340   0.027372\n",
      "           education. HS-grad           14.000000          0.088050   0.025547\n",
      "---\n",
      "occupation. Handlers-cleaners            1.000000          0.006289   0.001825\n",
      "     marital_status. Divorced            1.000000          0.006289   0.001825\n",
      "      relationship. Own-child            1.000000          0.006289   0.001825\n",
      "              education. 10th            1.000000          0.006289   0.001825\n",
      "       workclass. Federal-gov            1.000000          0.006289   0.001825\n",
      "        education. Assoc-acdm            1.000000          0.006289   0.001825\n",
      "                occupation.NA            1.000000          0.006289   0.001825\n",
      "       native_country. Mexico            1.000000          0.006289   0.001825\n",
      "               education. 9th            1.000000          0.006289   0.001825\n",
      "                  race. Black            1.000000          0.006289   0.001825\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      "\n",
      "10-20 18:27:09.011 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:09.011) \n",
      "10-20 18:27:09.060 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:09.060) \n",
      "10-20 18:27:09.106 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:09.106) \n",
      "10-20 18:27:09.154 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:09.154) \n",
      "10-20 18:27:09.192 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:09.192) \n",
      "10-20 18:27:09.217 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_86\n",
      "10-20 18:27:09.228 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_86\n",
      "10-20 18:27:09.277 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_87\n",
      "10-20 18:27:09.290 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_87\n",
      "10-20 18:27:09.294 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.086759076\n",
      " RMSE: 0.29454893\n",
      " AUC: 0.93263936\n",
      " pr_auc: 0.8386119\n",
      " logloss: 0.28383973\n",
      " mean_per_class_error: 0.16559221\n",
      " default threshold: 0.3654665946960449\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17862  1934  0.0977  1,934 / 19,796\n",
      "     1   1460  4793  0.2335   1,460 / 6,253\n",
      "Totals  19322  6727  0.1303  3,394 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 25.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013475         0.963456  4.165840         4.165840       1.000000  0.966257                  1.000000          0.966257      0.042220                 0.042220  316.584040       316.584040            0.042220\n",
      "      2                0.02019271         0.957662  4.165840         4.165840       1.000000  0.960120                  1.000000          0.963200      0.041900                 0.084120  316.584040       316.584040            0.084120\n",
      "      3                0.03002035         0.947776  4.165840         4.165840       1.000000  0.953198                  1.000000          0.959926      0.040940                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.936277  4.165840         4.165840       1.000000  0.942602                  1.000000          0.955603      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.915980  4.117957         4.156249       0.988506  0.926212                  0.997698          0.949716      0.041260                 0.207900  311.795717       315.624905            0.207749\n",
      "      6                0.10000384         0.741528  3.714701         3.935560       0.891705  0.823463                  0.944722          0.886613      0.185671                 0.393571  271.470100       293.555978            0.386297\n",
      "      7                0.15002495         0.593511  3.046850         3.639247       0.731389  0.665821                  0.873593          0.812997      0.152407                 0.545978  204.685027       263.924747            0.521023\n",
      "      8                0.20000768         0.471287  2.294092         3.303088       0.550691  0.530659                  0.792898          0.742440      0.114665                 0.660643  129.409183       230.308765            0.606137\n",
      "      9                0.30001152         0.313952  1.640749         2.748975       0.393858  0.383654                  0.659885          0.622844      0.164081                 0.824724   64.074942       174.897491            0.690455\n",
      "     10                0.40001536         0.206888  0.989887         2.309203       0.237620  0.258850                  0.554319          0.531846      0.098992                 0.923717   -1.011316       130.920289            0.689124\n",
      "     11                0.50001919         0.119703  0.436574         1.934677       0.104798  0.161309                  0.464415          0.457738      0.043659                 0.967376  -56.342632        93.467705            0.614981\n",
      "     12                0.59998464         0.066853  0.193574         1.644586       0.046467  0.090789                  0.394779          0.396600      0.019351                 0.986726  -80.642600        64.458604            0.508903\n",
      "     13                0.70033399         0.041439  0.092433         1.422181       0.022188  0.052234                  0.341391          0.347256      0.009276                 0.996002  -90.756743        42.218133            0.389061\n",
      "     14                0.79999232         0.032413  0.024071         1.248013       0.005778  0.036493                  0.299583          0.308543      0.002399                 0.998401  -97.592927        24.801294            0.261080\n",
      "     15                0.91792391         0.025073  0.012205         1.089241       0.002930  0.028243                  0.261470          0.272531      0.001439                 0.999840  -98.779539         8.924069            0.107791\n",
      "     16                1.00000000         0.024516  0.001948         1.000000       0.000468  0.024519                  0.240048          0.252175      0.000160                 1.000000  -99.805152         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09501673\n",
      " RMSE: 0.30824783\n",
      " AUC: 0.9181973\n",
      " pr_auc: 0.8108562\n",
      " logloss: 0.30601683\n",
      " mean_per_class_error: 0.17137083\n",
      " default threshold: 0.33169326186180115\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4303   621  0.1261  621 / 4,924\n",
      "     1   344  1244  0.2166  344 / 1,588\n",
      "Totals  4647  1865  0.1482  965 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 25.37 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01028870         0.963810  4.100756         4.100756       1.000000  0.966432                  1.000000          0.966432      0.042191                 0.042191  310.075567       310.075567            0.042191\n",
      "      2                0.02149877         0.957981  4.100756         4.100756       1.000000  0.960485                  1.000000          0.963331      0.045970                 0.088161  310.075567       310.075567            0.088161\n",
      "      3                0.03009828         0.947069  4.100756         4.100756       1.000000  0.953420                  1.000000          0.960499      0.035264                 0.123426  310.075567       310.075567            0.123426\n",
      "      4                0.04023342         0.934911  4.038623         4.085104       0.984848  0.941351                  0.996183          0.955676      0.040932                 0.164358  303.862301       308.510393            0.164155\n",
      "      5                0.05006143         0.916492  4.036681         4.075598       0.984375  0.926031                  0.993865          0.949856      0.039673                 0.204030  303.668136       307.559766            0.203624\n",
      "      6                0.10012285         0.735835  3.459226         3.767412       0.843558  0.814375                  0.918712          0.882115      0.173174                 0.377204  245.922641       276.741203            0.366440\n",
      "      7                0.15003071         0.599041  2.750661         3.429189       0.670769  0.669253                  0.836233          0.811307      0.137280                 0.514484  175.066072       242.918872            0.481990\n",
      "      8                0.20009214         0.472456  2.402590         3.172342       0.585890  0.533457                  0.773599          0.741791      0.120277                 0.634761  140.258998       217.234207            0.574850\n",
      "      9                0.30006143         0.317898  1.618885         2.654788       0.394777  0.386129                  0.647390          0.623298      0.161839                 0.796599   61.888511       165.478809            0.656673\n",
      "     10                0.40003071         0.207663  0.988969         2.238493       0.241167  0.261551                  0.545873          0.532896      0.098866                 0.895466   -1.103128       123.849311            0.655214\n",
      "     11                0.50015356         0.124559  0.528318         1.896143       0.128834  0.164439                  0.462389          0.459136      0.052897                 0.948363  -47.168179        89.614309            0.592758\n",
      "     12                0.59996929         0.070814  0.321752         1.634215       0.078462  0.094318                  0.398515          0.398442      0.032116                 0.980479  -67.824840        63.421463            0.503224\n",
      "     13                0.69993857         0.042826  0.132282         1.419700       0.032258  0.055237                  0.346204          0.349424      0.013224                 0.993703  -86.771756        41.969997            0.388504\n",
      "     14                0.79990786         0.032536  0.044094         1.247782       0.010753  0.037182                  0.304281          0.310401      0.004408                 0.998111  -95.590585        24.778225            0.262124\n",
      "     15                0.91953317         0.025073  0.010528         1.086824       0.002567  0.028317                  0.265030          0.273704      0.001259                 0.999370  -98.947174         8.682352            0.105585\n",
      "     16                1.00000000         0.024516  0.007826         1.000000       0.001908  0.024519                  0.243857          0.253653      0.000630                 1.000000  -99.217413         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3900.518066          1.000000   0.238554\n",
      "                      capital_gain         3194.131592          0.818899   0.195352\n",
      "                               age         1518.413330          0.389285   0.092866\n",
      "marital_status. Married-civ-spouse         1465.320679          0.375673   0.089618\n",
      "                      capital_loss          901.875183          0.231219   0.055158\n",
      "                    hours_per_week          727.884399          0.186612   0.044517\n",
      "                            fnlwgt          715.646179          0.183475   0.043769\n",
      "              education. Bachelors          613.131470          0.157192   0.037499\n",
      "        occupation. Prof-specialty          568.933411          0.145861   0.034796\n",
      "       occupation. Exec-managerial          543.400146          0.139315   0.033234\n",
      "---\n",
      "              education. Assoc-voc           14.028854          0.003597   0.000858\n",
      "     occupation. Handlers-cleaners           13.064272          0.003349   0.000799\n",
      "      occupation. Transport-moving           12.573780          0.003224   0.000769\n",
      "                education. 5th-6th           10.591439          0.002715   0.000648\n",
      "           relationship. Own-child            8.003714          0.002052   0.000490\n",
      "                     occupation.NA            7.747216          0.001986   0.000474\n",
      "          marital_status. Divorced            6.812427          0.001747   0.000417\n",
      "     occupation. Machine-op-inspct            2.606582          0.000668   0.000159\n",
      "           relationship. Unmarried            1.572975          0.000403   0.000096\n",
      "                       race. Black            1.216843          0.000312   0.000074\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        36964.304688          1.000000   0.141243\n",
      "                      capital_gain        31764.865234          0.859339   0.121375\n",
      "                            fnlwgt        20546.683594          0.555852   0.078510\n",
      "                    hours_per_week        20308.525391          0.549409   0.077600\n",
      "             relationship. Husband        17440.437500          0.471818   0.066641\n",
      "                      capital_loss        13276.663086          0.359175   0.050731\n",
      "marital_status. Married-civ-spouse        13136.034180          0.355371   0.050194\n",
      "        occupation. Prof-specialty        12151.918945          0.328747   0.046433\n",
      "       occupation. Exec-managerial        11887.534180          0.321595   0.045423\n",
      "              education. Bachelors        10072.094727          0.272482   0.038486\n",
      "---\n",
      "              workclass. Local-gov          652.569031          0.017654   0.002494\n",
      "                       race. White          555.515503          0.015028   0.002123\n",
      "           relationship. Own-child          497.669800          0.013464   0.001902\n",
      "                     occupation.NA          409.300720          0.011073   0.001564\n",
      "                         sex. Male          388.441345          0.010509   0.001484\n",
      "     occupation. Machine-op-inspct          298.729431          0.008082   0.001141\n",
      "           relationship. Unmarried          244.646667          0.006618   0.000935\n",
      "                       race. Black          226.792725          0.006135   0.000867\n",
      "          marital_status. Divorced          159.068817          0.004303   0.000608\n",
      "             education. Assoc-acdm          126.351097          0.003418   0.000483\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          288.000000          1.000000   0.292981\n",
      "                          age          216.000000          0.750000   0.219736\n",
      "               hours_per_week           86.000000          0.298611   0.087487\n",
      "         education. Bachelors           36.000000          0.125000   0.036623\n",
      "                 capital_gain           32.000000          0.111111   0.032553\n",
      "                 capital_loss           27.000000          0.093750   0.027467\n",
      "                  sex. Female           24.000000          0.083333   0.024415\n",
      "  occupation. Exec-managerial           23.000000          0.079861   0.023398\n",
      "           education. HS-grad           23.000000          0.079861   0.023398\n",
      "   occupation. Prof-specialty           22.000000          0.076389   0.022380\n",
      "---\n",
      "occupation. Handlers-cleaners            2.000000          0.006944   0.002035\n",
      "         education. Assoc-voc            2.000000          0.006944   0.002035\n",
      "              education. 10th            2.000000          0.006944   0.002035\n",
      "                occupation.NA            2.000000          0.006944   0.002035\n",
      "              education. 11th            2.000000          0.006944   0.002035\n",
      "               education. 9th            2.000000          0.006944   0.002035\n",
      "                  race. Black            1.000000          0.003472   0.001017\n",
      "occupation. Machine-op-inspct            1.000000          0.003472   0.001017\n",
      "        education. Assoc-acdm            1.000000          0.003472   0.001017\n",
      "           education. 5th-6th            1.000000          0.003472   0.001017\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      "\n",
      "10-20 18:27:09.337 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:09.337) \n",
      "10-20 18:27:09.380 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:09.380) \n",
      "10-20 18:27:09.424 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:09.424) \n",
      "10-20 18:27:09.463 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:09.463) \n",
      "10-20 18:27:09.508 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:09.508) \n",
      "10-20 18:27:09.547 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_88\n",
      "10-20 18:27:09.559 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_88\n",
      "10-20 18:27:09.640 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_89\n",
      "10-20 18:27:09.652 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:09.663 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_89\n",
      "10-20 18:27:09.669 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.08279637\n",
      " RMSE: 0.2877436\n",
      " AUC: 0.93777394\n",
      " pr_auc: 0.8489658\n",
      " logloss: 0.26614422\n",
      " mean_per_class_error: 0.15883636\n",
      " default threshold: 0.37632834911346436\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18044  1752  0.0885  1,752 / 19,796\n",
      "     1   1433  4820  0.2292   1,433 / 6,253\n",
      "Totals  19477  6572  0.1223  3,185 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.25 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005797         0.985344  4.165840         4.165840       1.000000  0.987062                  1.000000          0.987062      0.041900                 0.041900  316.584040       316.584040            0.041900\n",
      "      2                0.02007755         0.981728  4.165840         4.165840       1.000000  0.983702                  1.000000          0.985385      0.041740                 0.083640  316.584040       316.584040            0.083640\n",
      "      3                0.03002035         0.975534  4.165840         4.165840       1.000000  0.979002                  1.000000          0.983271      0.041420                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.964312  4.165840         4.165840       1.000000  0.970220                  1.000000          0.980015      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05005950         0.949132  4.070439         4.146672       0.977099  0.957578                  0.995399          0.975507      0.040940                 0.207580  307.043947       314.667242            0.207277\n",
      "      6                0.10000384         0.763871  3.736768         3.941956       0.897002  0.852811                  0.946257          0.914230      0.186630                 0.394211  273.676844       294.195646            0.387139\n",
      "      7                0.15002495         0.609045  3.145961         3.676557       0.755180  0.684133                  0.882549          0.837511      0.157364                 0.551575  214.596082       267.655669            0.528389\n",
      "      8                0.20000768         0.485453  2.425274         3.363856       0.582181  0.547044                  0.807486          0.764922      0.121222                 0.672797  142.527421       236.385615            0.622130\n",
      "      9                0.30001152         0.306555  1.624758         2.784157       0.390019  0.385877                  0.668330          0.638574      0.162482                 0.835279   62.475771       178.415667            0.704344\n",
      "     10                0.40001536         0.177944  0.964300         2.329193       0.231478  0.240164                  0.559117          0.538971      0.096434                 0.931713   -3.569990       132.919253            0.699646\n",
      "     11                0.50001919         0.092155  0.394995         1.942353       0.094818  0.131806                  0.466257          0.457538      0.039501                 0.971214  -60.500477        94.235307            0.620032\n",
      "     12                0.59998464         0.045303  0.179176         1.648584       0.043011  0.065958                  0.395739          0.392296      0.017911                 0.989125  -82.082407        64.858423            0.512059\n",
      "     13                0.69998848         0.025154  0.079959         1.424483       0.019194  0.033529                  0.341944          0.341040      0.007996                 0.997121  -92.004145        42.448255            0.390989\n",
      "     14                0.79999232         0.015406  0.015992         1.248413       0.003839  0.019958                  0.299678          0.300903      0.001599                 0.998721  -98.400829        24.841275            0.261501\n",
      "     15                0.90260663         0.007540  0.010909         1.107725       0.002619  0.011243                  0.265907          0.267973      0.001119                 0.999840  -98.909058        10.772517            0.127947\n",
      "     16                1.00000000         0.005841  0.001642         1.000000       0.000394  0.006808                  0.240048          0.242537      0.000160                 1.000000  -99.835797         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09221756\n",
      " RMSE: 0.30367345\n",
      " AUC: 0.922278\n",
      " pr_auc: 0.81850404\n",
      " logloss: 0.29286632\n",
      " mean_per_class_error: 0.16522554\n",
      " default threshold: 0.3217979073524475\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4286   638  0.1296  638 / 4,924\n",
      "     1   319  1269  0.2009  319 / 1,588\n",
      "Totals  4605  1907  0.1470  957 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.40 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01028870         0.985439  4.100756         4.100756       1.000000  0.987060                  1.000000          0.987060      0.042191                 0.042191   310.075567       310.075567            0.042191\n",
      "      2                0.02011671         0.982464  4.100756         4.100756       1.000000  0.984138                  1.000000          0.985632      0.040302                 0.082494   310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.975175  4.100756         4.100756       1.000000  0.979035                  1.000000          0.983445      0.040932                 0.123426   310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.963159  4.037667         4.085044       0.984615  0.969209                  0.996169          0.979899      0.040302                 0.163728   303.766712       308.504396            0.163525\n",
      "      5                0.05006143         0.949893  3.974579         4.063019       0.969231  0.956899                  0.990798          0.975313      0.039673                 0.203401   297.457857       306.301865            0.202791\n",
      "      6                0.10012285         0.756487  3.559858         3.811439       0.868098  0.842232                  0.929448          0.908773      0.178212                 0.381612   255.985845       281.143855            0.372270\n",
      "      7                0.15003071         0.613334  2.738043         3.454372       0.667692  0.686077                  0.842375          0.834693      0.136650                 0.518262   173.804301       245.437248            0.486987\n",
      "      8                0.20009214         0.491113  2.490643         3.213255       0.607362  0.548543                  0.783576          0.763100      0.124685                 0.642947   149.064301       221.325521            0.585677\n",
      "      9                0.30006143         0.312731  1.644082         2.690465       0.400922  0.390094                  0.656090          0.638828      0.164358                 0.807305    64.408177       169.046508            0.670830\n",
      "     10                0.40003071         0.181468  0.988969         2.265254       0.241167  0.243034                  0.552399          0.539918      0.098866                 0.906171    -1.103128       126.525428            0.669372\n",
      "     11                0.50000000         0.097063  0.453540         1.903023       0.110599  0.135317                  0.464066          0.459022      0.045340                 0.951511   -54.646020        90.302267            0.597125\n",
      "     12                0.59996929         0.049183  0.302360         1.636314       0.073733  0.071032                  0.399027          0.394374      0.030227                 0.981738   -69.764014        63.631382            0.504890\n",
      "     13                0.69993857         0.025928  0.144881         1.423299       0.035330  0.035360                  0.347082          0.343097      0.014484                 0.996222   -85.511923        42.329870            0.391835\n",
      "     14                0.79990786         0.015792  0.031496         1.249357       0.007680  0.020544                  0.304665          0.302786      0.003149                 0.999370   -96.850418        24.935674            0.263789\n",
      "     15                0.90156634         0.007540  0.000000         1.108482       0.000000  0.011303                  0.270312          0.269919      0.000000                 0.999370  -100.000000        10.848224            0.129346\n",
      "     16                1.00000000         0.005841  0.006397         1.000000       0.001560  0.006822                  0.243857          0.244021      0.000630                 1.000000   -99.360257         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3907.983398          1.000000   0.221504\n",
      "                      capital_gain         3447.320801          0.882123   0.195393\n",
      "                               age         1732.225342          0.443253   0.098182\n",
      "marital_status. Married-civ-spouse         1503.350830          0.384687   0.085210\n",
      "                      capital_loss         1070.734253          0.273986   0.060689\n",
      "                            fnlwgt          890.800964          0.227944   0.050490\n",
      "                    hours_per_week          775.349426          0.198401   0.043947\n",
      "              education. Bachelors          624.790466          0.159875   0.035413\n",
      "        occupation. Prof-specialty          577.762390          0.147842   0.032747\n",
      "       occupation. Exec-managerial          550.451843          0.140853   0.031199\n",
      "---\n",
      "                education. 5th-6th           20.498913          0.005245   0.001162\n",
      "              workclass. Local-gov           19.509922          0.004992   0.001106\n",
      "             education. Assoc-acdm           15.590469          0.003989   0.000884\n",
      "              education. Assoc-voc           14.028854          0.003590   0.000795\n",
      "          marital_status. Divorced           13.909436          0.003559   0.000788\n",
      "     occupation. Machine-op-inspct           12.799887          0.003275   0.000725\n",
      "      occupation. Transport-moving           12.573780          0.003217   0.000713\n",
      "                     occupation.NA            7.747216          0.001982   0.000439\n",
      "                       race. Black            2.280982          0.000584   0.000129\n",
      "           relationship. Unmarried            1.745163          0.000447   0.000099\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        51476.898438          1.000000   0.140456\n",
      "                               age        50618.398438          0.983323   0.138114\n",
      "                      capital_loss        31972.347656          0.621101   0.087237\n",
      "                            fnlwgt        30229.572266          0.587245   0.082482\n",
      "                    hours_per_week        23652.724609          0.459482   0.064537\n",
      "             relationship. Husband        17579.404297          0.341501   0.047966\n",
      "marital_status. Married-civ-spouse        16400.681641          0.318603   0.044750\n",
      "        occupation. Prof-specialty        12246.563477          0.237904   0.033415\n",
      "       occupation. Exec-managerial        12173.278320          0.236480   0.033215\n",
      "              education. Bachelors        10505.562500          0.204083   0.028665\n",
      "---\n",
      "          occupation. Adm-clerical         1095.387207          0.021279   0.002989\n",
      "          occupation. Craft-repair          956.580811          0.018583   0.002610\n",
      "              education. Assoc-voc          685.564514          0.013318   0.001871\n",
      "      occupation. Transport-moving          677.795166          0.013167   0.001849\n",
      "              workclass. Local-gov          652.569031          0.012677   0.001781\n",
      "                         sex. Male          428.737640          0.008329   0.001170\n",
      "                     occupation.NA          409.300720          0.007951   0.001117\n",
      "           relationship. Unmarried          304.313660          0.005912   0.000830\n",
      "                       race. Black          253.260071          0.004920   0.000691\n",
      "             education. Assoc-acdm          126.351097          0.002455   0.000345\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          351.000000          1.000000   0.286765\n",
      "                          age          266.000000          0.757835   0.217320\n",
      "               hours_per_week           99.000000          0.282051   0.080882\n",
      "                 capital_gain           50.000000          0.142450   0.040850\n",
      "                 capital_loss           41.000000          0.116809   0.033497\n",
      "         education. Bachelors           39.000000          0.111111   0.031863\n",
      "           education. HS-grad           31.000000          0.088319   0.025327\n",
      "                  sex. Female           26.000000          0.074074   0.021242\n",
      "  occupation. Exec-managerial           25.000000          0.071225   0.020425\n",
      "   occupation. Prof-specialty           25.000000          0.071225   0.020425\n",
      "---\n",
      "               education. 9th            4.000000          0.011396   0.003268\n",
      "      relationship. Unmarried            3.000000          0.008547   0.002451\n",
      "      workclass. Self-emp-inc            3.000000          0.008547   0.002451\n",
      " occupation. Transport-moving            3.000000          0.008547   0.002451\n",
      "         education. Assoc-voc            2.000000          0.005698   0.001634\n",
      "                occupation.NA            2.000000          0.005698   0.001634\n",
      "                  race. Black            2.000000          0.005698   0.001634\n",
      "occupation. Machine-op-inspct            2.000000          0.005698   0.001634\n",
      "           education. 5th-6th            2.000000          0.005698   0.001634\n",
      "        education. Assoc-acdm            1.000000          0.002849   0.000817\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      "\n",
      "10-20 18:27:09.717 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:09.717) \n",
      "10-20 18:27:09.755 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:09.755) \n",
      "10-20 18:27:09.791 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:09.791) \n",
      "10-20 18:27:09.834 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:09.834) \n",
      "10-20 18:27:09.877 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:09.877) \n",
      "10-20 18:27:09.934 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_90\n",
      "10-20 18:27:09.950 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_90\n",
      "10-20 18:27:10.113 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_91\n",
      "10-20 18:27:10.126 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_91\n",
      "10-20 18:27:10.135 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.08065227\n",
      " RMSE: 0.28399342\n",
      " AUC: 0.9407984\n",
      " pr_auc: 0.85529065\n",
      " logloss: 0.2582712\n",
      " mean_per_class_error: 0.15297404\n",
      " default threshold: 0.37424802780151367\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18026  1770  0.0894  1,770 / 19,796\n",
      "     1   1354  4899  0.2165   1,354 / 6,253\n",
      "Totals  19380  6669  0.1199  3,124 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991066  4.165840         4.165840       1.000000  0.992558                  1.000000          0.992558      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.988095  4.165840         4.165840       1.000000  0.989789                  1.000000          0.991176      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.982144  4.165840         4.165840       1.000000  0.985332                  1.000000          0.989226      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.973325  4.133795         4.157845       0.992308  0.978066                  0.998081          0.986441      0.041260                 0.166320  313.379547       315.784454            0.166219\n",
      "      5                0.05002111         0.956578  4.086035         4.143461       0.980843  0.965291                  0.994628          0.982205      0.040940                 0.207261  308.603503       314.346059            0.206907\n",
      "      6                0.10004223         0.778074  3.807764         3.975612       0.914045  0.867076                  0.954336          0.924640      0.190469                 0.397729  280.776356       297.561207            0.391718\n",
      "      7                0.15002495         0.627799  3.138778         3.696810       0.753456  0.701040                  0.887410          0.850145      0.156885                 0.554614  213.877836       269.681026            0.532387\n",
      "      8                0.20000768         0.496623  2.438072         3.382247       0.585253  0.560889                  0.811900          0.777859      0.121862                 0.676475  143.807249       238.224662            0.626970\n",
      "      9                0.30020346         0.302782  1.669528         2.810610       0.400766  0.389192                  0.674680          0.648138      0.167280                 0.843755   66.952837       181.061048            0.715244\n",
      "     10                0.40001536         0.168167  0.934110         2.342386       0.224231  0.232424                  0.562284          0.544409      0.093235                 0.936990   -6.589040       134.238569            0.706590\n",
      "     11                0.50001919         0.082412  0.366210         1.947151       0.087908  0.121054                  0.467409          0.459738      0.036622                 0.973613  -63.378985        94.715058            0.623188\n",
      "     12                0.59998464         0.037352  0.174377         1.651783       0.041859  0.056689                  0.396506          0.392585      0.017432                 0.991044  -82.562342        65.178277            0.514584\n",
      "     13                0.69998848         0.018474  0.059169         1.424254       0.014203  0.026713                  0.341889          0.340314      0.005917                 0.996961  -94.083067        42.425409            0.390778\n",
      "     14                0.79999232         0.009848  0.022388         1.249012       0.005374  0.013749                  0.299822          0.299492      0.002239                 0.999200  -97.761161        24.901247            0.262132\n",
      "     15                0.89999616         0.003761  0.006397         1.110938       0.001536  0.006583                  0.266678          0.266945      0.000640                 0.999840  -99.360332        11.093816            0.131382\n",
      "     16                1.00000000         0.001910  0.001599         1.000000       0.000384  0.002845                  0.240048          0.240534      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09197374\n",
      " RMSE: 0.30327174\n",
      " AUC: 0.9229561\n",
      " pr_auc: 0.8183425\n",
      " logloss: 0.29091486\n",
      " mean_per_class_error: 0.17733735\n",
      " default threshold: 0.39492014050483704\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4483   441  0.0896  441 / 4,924\n",
      "     1   421  1167  0.2651  421 / 1,588\n",
      "Totals  4904  1608  0.1324  862 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.17 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.991579  4.100756         4.100756       1.000000  0.992856                  1.000000          0.992856      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.988289  4.100756         4.100756       1.000000  0.990036                  1.000000          0.991456      0.040932                 0.082494  310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.982168  4.100756         4.100756       1.000000  0.985358                  1.000000          0.989434      0.040932                 0.123426  310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.972692  3.974579         4.069332       0.969231  0.978151                  0.992337          0.986624      0.039673                 0.163098  297.457857       306.933225            0.162692\n",
      "      5                0.05006143         0.952742  3.974579         4.050440       0.969231  0.963620                  0.987730          0.982037      0.039673                 0.202771  297.457857       305.043965            0.201958\n",
      "      6                0.10012285         0.768654  3.534700         3.792570       0.861963  0.855192                  0.924847          0.918614      0.176952                 0.379723  253.470044       279.257004            0.369772\n",
      "      7                0.15003071         0.624818  2.813749         3.466964       0.686154  0.699569                  0.845445          0.845749      0.140428                 0.520151  181.374927       246.696436            0.489485\n",
      "      8                0.20009214         0.501317  2.390011         3.197519       0.582822  0.564032                  0.779739          0.775266      0.119647                 0.639798  139.001097       219.751938            0.581513\n",
      "      9                0.30006143         0.305087  1.669278         2.688366       0.407066  0.393417                  0.655578          0.648048      0.166877                 0.806675   66.927842       168.836643            0.669998\n",
      "     10                0.40003071         0.170124  0.970071         2.258958       0.236559  0.233831                  0.550864          0.544533      0.096977                 0.903652   -2.992877       125.895754            0.666041\n",
      "     11                0.50000000         0.087076  0.560626         1.919395       0.136713  0.125523                  0.468059          0.460757      0.056045                 0.959698  -43.937442        91.939547            0.607951\n",
      "     12                0.59996929         0.041032  0.239368         1.639463       0.058372  0.061609                  0.399795          0.394250      0.023929                 0.983627  -76.063177        63.946259            0.507388\n",
      "     13                0.69993857         0.019307  0.119684         1.422399       0.029186  0.028304                  0.346863          0.341983      0.011965                 0.995592  -88.031589        42.239901            0.391002\n",
      "     14                0.79990786         0.009913  0.031496         1.248569       0.007680  0.014280                  0.304473          0.301028      0.003149                 0.998741  -96.850418        24.856949            0.262957\n",
      "     15                0.89987715         0.003829  0.006299         1.110563       0.001536  0.006634                  0.270819          0.268323      0.000630                 0.999370  -99.370084        11.056301            0.131580\n",
      "     16                1.00000000         0.002104  0.006290         1.000000       0.001534  0.002874                  0.243857          0.241746      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3919.374756          1.000000   0.211928\n",
      "                      capital_gain         3497.929199          0.892471   0.189140\n",
      "                               age         1931.695923          0.492858   0.104451\n",
      "marital_status. Married-civ-spouse         1506.333496          0.384330   0.081450\n",
      "                      capital_loss         1126.030273          0.287298   0.060887\n",
      "                            fnlwgt         1075.149048          0.274316   0.058135\n",
      "                    hours_per_week          856.805664          0.218608   0.046329\n",
      "              education. Bachelors          639.841736          0.163251   0.034597\n",
      "        occupation. Prof-specialty          581.131714          0.148272   0.031423\n",
      "       occupation. Exec-managerial          569.372864          0.145271   0.030787\n",
      "---\n",
      "              education. Assoc-voc           14.028854          0.003579   0.000759\n",
      "          race. Amer-Indian-Eskimo           11.035846          0.002816   0.000597\n",
      "          race. Asian-Pac-Islander            8.892183          0.002269   0.000481\n",
      "      relationship. Other-relative            5.857741          0.001495   0.000317\n",
      "           marital_status. Widowed            4.977230          0.001270   0.000269\n",
      "         marital_status. Separated            4.794008          0.001223   0.000259\n",
      "              workclass. State-gov            4.356952          0.001112   0.000236\n",
      "                      workclass.NA            2.306062          0.000588   0.000125\n",
      "                       race. Black            2.280982          0.000582   0.000123\n",
      "           relationship. Unmarried            1.745163          0.000445   0.000094\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        62806.070313          1.000000   0.136708\n",
      "                      capital_gain        61178.207031          0.974081   0.133165\n",
      "                      capital_loss        41755.066406          0.664825   0.090887\n",
      "                            fnlwgt        41419.769531          0.659487   0.090157\n",
      "                    hours_per_week        31245.167969          0.497486   0.068011\n",
      "             relationship. Husband        17780.267578          0.283098   0.038702\n",
      "marital_status. Married-civ-spouse        17497.777344          0.278600   0.038087\n",
      "       occupation. Exec-managerial        14671.190430          0.233595   0.031934\n",
      "              education. Bachelors        12913.153320          0.205604   0.028108\n",
      "        occupation. Prof-specialty        12405.454102          0.197520   0.027003\n",
      "---\n",
      "              workclass. State-gov         1193.456421          0.019002   0.002598\n",
      "          occupation. Craft-repair          956.580811          0.015231   0.002082\n",
      "         marital_status. Separated          954.012207          0.015190   0.002077\n",
      "              workclass. Local-gov          880.999756          0.014027   0.001918\n",
      "      occupation. Transport-moving          802.050842          0.012770   0.001746\n",
      "              education. Assoc-voc          685.564514          0.010916   0.001492\n",
      "           relationship. Unmarried          304.313660          0.004845   0.000662\n",
      "                       race. Black          253.260071          0.004032   0.000551\n",
      "           marital_status. Widowed          201.867920          0.003214   0.000439\n",
      "             education. Assoc-acdm          126.351097          0.002012   0.000275\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          413.000000          1.000000   0.276995\n",
      "                         age          348.000000          0.842615   0.233400\n",
      "              hours_per_week          127.000000          0.307506   0.085178\n",
      "                capital_gain           61.000000          0.147700   0.040912\n",
      "                capital_loss           51.000000          0.123487   0.034205\n",
      "        education. Bachelors           43.000000          0.104116   0.028840\n",
      "          education. HS-grad           37.000000          0.089588   0.024816\n",
      " occupation. Exec-managerial           29.000000          0.070218   0.019450\n",
      "                 sex. Female           29.000000          0.070218   0.019450\n",
      "          workclass. Private           28.000000          0.067797   0.018779\n",
      "---\n",
      "                 race. Black            2.000000          0.004843   0.001341\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.004843   0.001341\n",
      "          education. 5th-6th            2.000000          0.004843   0.001341\n",
      "     marital_status. Widowed            1.000000          0.002421   0.000671\n",
      "relationship. Other-relative            1.000000          0.002421   0.000671\n",
      "   marital_status. Separated            1.000000          0.002421   0.000671\n",
      "                workclass.NA            1.000000          0.002421   0.000671\n",
      "    race. Asian-Pac-Islander            1.000000          0.002421   0.000671\n",
      "        workclass. State-gov            1.000000          0.002421   0.000671\n",
      "       education. Assoc-acdm            1.000000          0.002421   0.000671\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      " 2023-10-20 18:27:09 11.108 sec              20       0.28399          0.25827      0.94080         0.85529       4.16584                       0.11993         0.30327            0.29091        0.92296           0.81834         4.10076                         0.13237\n",
      "\n",
      "10-20 18:27:10.196 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:10.196) \n",
      "10-20 18:27:10.242 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:10.242) \n",
      "10-20 18:27:10.279 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:10.279) \n",
      "10-20 18:27:10.317 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:10.317) \n",
      "10-20 18:27:10.365 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:10.365) \n",
      "10-20 18:27:10.430 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_92\n",
      "10-20 18:27:10.444 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_92\n",
      "10-20 18:27:10.557 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_93\n",
      "10-20 18:27:10.565 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_93\n",
      "10-20 18:27:10.571 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07888996\n",
      " RMSE: 0.28087357\n",
      " AUC: 0.9433154\n",
      " pr_auc: 0.86073303\n",
      " logloss: 0.2527134\n",
      " mean_per_class_error: 0.14701523\n",
      " default threshold: 0.36680933833122253\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17958  1838  0.0928  1,838 / 19,796\n",
      "     1   1258  4995  0.2012   1,258 / 6,253\n",
      "Totals  19216  6833  0.1189  3,096 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.06 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.992964  4.165840         4.165840       1.000000  0.994306                  1.000000          0.994306      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.990156  4.165840         4.165840       1.000000  0.991674                  1.000000          0.992992      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.985846  4.165840         4.165840       1.000000  0.988262                  1.000000          0.991413      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.978411  4.133795         4.157845       0.992308  0.982521                  0.998081          0.989195      0.041260                 0.166320  313.379547       315.784454            0.166219\n",
      "      5                0.05002111         0.963765  4.117957         4.149855       0.988506  0.971803                  0.996163          0.985711      0.041260                 0.207580  311.795717       314.985482            0.207328\n",
      "      6                0.10000384         0.792910  3.829886         3.989932       0.919355  0.878709                  0.957774          0.932231      0.191428                 0.399008  282.988553       298.993159            0.393452\n",
      "      7                0.15002495         0.635400  3.200312         3.726658       0.768227  0.711932                  0.894575          0.858779      0.160083                 0.559092  220.031177       272.665763            0.538279\n",
      "      8                0.20000768         0.502454  2.425274         3.401437       0.582181  0.567894                  0.816507          0.786086      0.121222                 0.680313  142.527421       240.143667            0.632021\n",
      "      9                0.30001152         0.301989  1.707915         2.836929       0.409981  0.393115                  0.680998          0.655096      0.170798                 0.851111   70.791460       183.692931            0.725177\n",
      "     10                0.40001536         0.165111  0.885941         2.349182       0.212668  0.230093                  0.563916          0.548845      0.088597                 0.939709  -11.405928       134.918217            0.710168\n",
      "     11                0.50001919         0.076796  0.353417         1.950029       0.084837  0.116506                  0.468100          0.462377      0.035343                 0.975052  -64.658321        95.002909            0.625082\n",
      "     12                0.59998464         0.034248  0.161578         1.652049       0.038786  0.052530                  0.396570          0.394091      0.016152                 0.991204  -83.842171        65.204932            0.514795\n",
      "     13                0.69998848         0.016033  0.063967         1.425168       0.015355  0.023802                  0.342108          0.341190      0.006397                 0.997601  -93.603316        42.516795            0.391620\n",
      "     14                0.79999232         0.007592  0.017591         1.249212       0.004223  0.011470                  0.299870          0.299973      0.001759                 0.999360  -98.240912        24.921237            0.262343\n",
      "     15                0.89999616         0.002251  0.003198         1.110760       0.000768  0.004549                  0.266635          0.267147      0.000320                 0.999680  -99.680166        11.076046            0.131171\n",
      "     16                1.00000000         0.000881  0.003198         1.000000       0.000768  0.001521                  0.240048          0.240583      0.000320                 1.000000  -99.680166         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.092386924\n",
      " RMSE: 0.3039522\n",
      " AUC: 0.9222539\n",
      " pr_auc: 0.81701696\n",
      " logloss: 0.2916794\n",
      " mean_per_class_error: 0.17285612\n",
      " default threshold: 0.3668982684612274\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4400   524  0.1064  524 / 4,924\n",
      "     1   380  1208  0.2393  380 / 1,588\n",
      "Totals  4780  1732  0.1388  904 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.993162  4.100756         4.100756       1.000000  0.994619                  1.000000          0.994619      0.041562                 0.041562   310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.989819  4.100756         4.100756       1.000000  0.991722                  1.000000          0.993181      0.040932                 0.082494   310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.986015  4.100756         4.100756       1.000000  0.988244                  1.000000          0.991544      0.040932                 0.123426   310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.978831  3.974579         4.069332       0.969231  0.982620                  0.992337          0.989322      0.039673                 0.163098   297.457857       306.933225            0.162692\n",
      "      5                0.05006143         0.959933  3.974579         4.050440       0.969231  0.970329                  0.987730          0.985535      0.039673                 0.202771   297.457857       305.043965            0.201958\n",
      "      6                0.10012285         0.780848  3.496963         3.773702       0.852761  0.867393                  0.920245          0.926464      0.175063                 0.377834   249.696342       277.370153            0.367273\n",
      "      7                0.15003071         0.636428  2.889456         3.479556       0.704615  0.709081                  0.848516          0.854151      0.144207                 0.522040   188.945553       247.955624            0.491983\n",
      "      8                0.20009214         0.502018  2.415169         3.213255       0.588957  0.568221                  0.783576          0.782614      0.120907                 0.642947   141.516898       221.325521            0.585677\n",
      "      9                0.30006143         0.302582  1.644082         2.690465       0.400922  0.395534                  0.656090          0.653653      0.164358                 0.807305    64.408177       169.046508            0.670830\n",
      "     10                0.40003071         0.169825  0.938575         2.252661       0.228879  0.231196                  0.549328          0.548079      0.093829                 0.901134    -6.142459       125.266079            0.662709\n",
      "     11                0.50000000         0.082957  0.598421         1.921914       0.145929  0.121971                  0.468673          0.462884      0.059824                 0.960957   -40.157943        92.191436            0.609617\n",
      "     12                0.59996929         0.037156  0.214172         1.637363       0.052227  0.057547                  0.399283          0.395345      0.021411                 0.982368   -78.582843        63.736341            0.505723\n",
      "     13                0.69993857         0.017058  0.119684         1.420600       0.029186  0.025464                  0.346424          0.342517      0.011965                 0.994332   -88.031589        42.059965            0.389337\n",
      "     14                0.79990786         0.007687  0.050393         1.249357       0.012289  0.012021                  0.304665          0.301213      0.005038                 0.999370   -94.960669        24.935674            0.263789\n",
      "     15                0.89987715         0.002315  0.000000         1.110563       0.000000  0.004596                  0.270819          0.268261      0.000000                 0.999370  -100.000000        11.056301            0.131580\n",
      "     16                1.00000000         0.000931  0.006290         1.000000       0.001534  0.001551                  0.243857          0.241557      0.000630                 1.000000   -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3924.454102          1.000000   0.204230\n",
      "                      capital_gain         3513.239258          0.895217   0.182831\n",
      "                               age         2060.580566          0.525062   0.107234\n",
      "marital_status. Married-civ-spouse         1512.057251          0.385291   0.078688\n",
      "                            fnlwgt         1327.271484          0.338205   0.069072\n",
      "                      capital_loss         1170.340210          0.298217   0.060905\n",
      "                    hours_per_week          910.726379          0.232064   0.047395\n",
      "              education. Bachelors          658.126099          0.167699   0.034249\n",
      "       occupation. Exec-managerial          585.875854          0.149288   0.030489\n",
      "        occupation. Prof-specialty          585.224731          0.149123   0.030455\n",
      "---\n",
      "             education. Assoc-acdm           15.590469          0.003973   0.000811\n",
      "          race. Amer-Indian-Eskimo           11.035846          0.002812   0.000574\n",
      "          race. Asian-Pac-Islander            8.892183          0.002266   0.000463\n",
      "      relationship. Other-relative            5.857741          0.001493   0.000305\n",
      "           marital_status. Widowed            4.977230          0.001268   0.000259\n",
      "         marital_status. Separated            4.794008          0.001222   0.000249\n",
      "              workclass. State-gov            4.356952          0.001110   0.000227\n",
      "                       race. Black            3.446261          0.000878   0.000179\n",
      "                      workclass.NA            2.306062          0.000588   0.000120\n",
      "           relationship. Unmarried            1.745163          0.000445   0.000091\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        72190.617188          1.000000   0.132412\n",
      "                      capital_gain        64506.312500          0.893555   0.118318\n",
      "                            fnlwgt        63861.468750          0.884623   0.117135\n",
      "                      capital_loss        52639.726563          0.729177   0.096552\n",
      "                    hours_per_week        38850.582031          0.538167   0.071260\n",
      "             relationship. Husband        17958.968750          0.248772   0.032940\n",
      "marital_status. Married-civ-spouse        17873.033203          0.247581   0.032783\n",
      "       occupation. Exec-managerial        15616.268555          0.216320   0.028643\n",
      "              education. Bachelors        13765.914063          0.190688   0.025249\n",
      "        occupation. Prof-specialty        12731.829102          0.176364   0.023353\n",
      "---\n",
      "      relationship. Other-relative         1385.789795          0.019196   0.002542\n",
      "                      workclass.NA         1346.937988          0.018658   0.002471\n",
      "              workclass. State-gov         1193.456421          0.016532   0.002189\n",
      "              education. Assoc-voc         1182.730591          0.016383   0.002169\n",
      "         marital_status. Separated          954.012207          0.013215   0.001750\n",
      "      occupation. Transport-moving          802.050842          0.011110   0.001471\n",
      "                       race. Black          364.713043          0.005052   0.000669\n",
      "           relationship. Unmarried          304.313660          0.004215   0.000558\n",
      "           marital_status. Widowed          201.867920          0.002796   0.000370\n",
      "             education. Assoc-acdm          126.351097          0.001750   0.000232\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          500.000000          1.000000   0.280899\n",
      "                         age          409.000000          0.818000   0.229775\n",
      "              hours_per_week          157.000000          0.314000   0.088202\n",
      "                capital_gain           65.000000          0.130000   0.036517\n",
      "                capital_loss           60.000000          0.120000   0.033708\n",
      "        education. Bachelors           48.000000          0.096000   0.026966\n",
      "          education. HS-grad           47.000000          0.094000   0.026404\n",
      " occupation. Exec-managerial           36.000000          0.072000   0.020225\n",
      "          workclass. Private           36.000000          0.072000   0.020225\n",
      "                 sex. Female           31.000000          0.062000   0.017416\n",
      "---\n",
      "                 race. Black            3.000000          0.006000   0.001685\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.004000   0.001124\n",
      "          education. 5th-6th            2.000000          0.004000   0.001124\n",
      "     marital_status. Widowed            1.000000          0.002000   0.000562\n",
      "relationship. Other-relative            1.000000          0.002000   0.000562\n",
      "   marital_status. Separated            1.000000          0.002000   0.000562\n",
      "                workclass.NA            1.000000          0.002000   0.000562\n",
      "    race. Asian-Pac-Islander            1.000000          0.002000   0.000562\n",
      "        workclass. State-gov            1.000000          0.002000   0.000562\n",
      "       education. Assoc-acdm            1.000000          0.002000   0.000562\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      " 2023-10-20 18:27:09 11.108 sec              20       0.28399          0.25827      0.94080         0.85529       4.16584                       0.11993         0.30327            0.29091        0.92296           0.81834         4.10076                         0.13237\n",
      " 2023-10-20 18:27:10 11.595 sec              25       0.28087          0.25271      0.94332         0.86073       4.16584                       0.11885         0.30395            0.29168        0.92225           0.81702         4.10076                         0.13882\n",
      "\n",
      "█10-20 18:27:10.616 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:10.616) \n",
      "10-20 18:27:10.657 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:10.657) \n",
      "10-20 18:27:10.703 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:10.703) \n",
      "10-20 18:27:10.747 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:10.747) \n",
      "10-20 18:27:10.792 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:10.792) \n",
      "10-20 18:27:10.877 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_94\n",
      "10-20 18:27:10.890 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_94\n",
      "10-20 18:27:10.920 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:11.052 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_95\n",
      "10-20 18:27:11.061 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_95\n",
      "10-20 18:27:11.066 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07630979\n",
      " RMSE: 0.2762423\n",
      " AUC: 0.94703853\n",
      " pr_auc: 0.8697007\n",
      " logloss: 0.24531174\n",
      " mean_per_class_error: 0.14092533\n",
      " default threshold: 0.36305180191993713\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17987  1809  0.0914  1,809 / 19,796\n",
      "     1   1191  5062  0.1905   1,191 / 6,253\n",
      "Totals  19178  6871  0.1152  3,000 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.03 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.993156  4.165840         4.165840       1.000000  0.994632                  1.000000          0.994632      0.041740                 0.041740   316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.990155  4.165840         4.165840       1.000000  0.991734                  1.000000          0.993186      0.041580                 0.083320   316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.986047  4.165840         4.165840       1.000000  0.988366                  1.000000          0.991577      0.041740                 0.125060   316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.979158  4.165840         4.165840       1.000000  0.983056                  1.000000          0.989451      0.041580                 0.166640   316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.963759  4.101996         4.153052       0.984674  0.972380                  0.996930          0.986032      0.041100                 0.207740   310.199610       315.305194            0.207538\n",
      "      6                0.10000384         0.800899  3.877879         4.015518       0.930876  0.884857                  0.963916          0.935464      0.193827                 0.401567   287.787908       301.551832            0.396819\n",
      "      7                0.15002495         0.640396  3.315408         3.782088       0.795856  0.720986                  0.907881          0.863953      0.165840                 0.567408   231.540790       278.208847            0.549222\n",
      "      8                0.20000768         0.508741  2.460469         3.451811       0.590630  0.570660                  0.828599          0.790658      0.122981                 0.690389   146.046948       245.181056            0.645278\n",
      "      9                0.30001152         0.297219  1.688725         2.864115       0.405374  0.393675                  0.687524          0.658330      0.168879                 0.859268    68.872455       186.411522            0.735909\n",
      "     10                0.40001536         0.161803  0.860354         2.363175       0.206526  0.226041                  0.567274          0.550258      0.086039                 0.945306   -13.964601       136.317491            0.717533\n",
      "     11                0.50001919         0.073675  0.315037         1.953547       0.075624  0.113197                  0.468944          0.462846      0.031505                 0.976811   -68.496332        95.354727            0.627397\n",
      "     12                0.59998464         0.032532  0.153579         1.653649       0.036866  0.050451                  0.396954          0.394135      0.015353                 0.992164   -84.642063        65.364859            0.516057\n",
      "     13                0.69998848         0.015072  0.055971         1.425396       0.013436  0.022541                  0.342163          0.341048      0.005597                 0.997761   -94.402902        42.539642            0.391831\n",
      "     14                0.79999232         0.006649  0.015992         1.249212       0.003839  0.010531                  0.299870          0.299731      0.001599                 0.999360   -98.400829        24.921237            0.262343\n",
      "     15                0.89999616         0.002017  0.006397         1.111116       0.001536  0.003993                  0.266721          0.266870      0.000640                 1.000000   -99.360332        11.111585            0.131592\n",
      "     16                1.00000000         0.000539  0.000000         1.000000       0.000000  0.001297                  0.240048          0.240312      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09370165\n",
      " RMSE: 0.30610725\n",
      " AUC: 0.9203717\n",
      " pr_auc: 0.81283975\n",
      " logloss: 0.2950873\n",
      " mean_per_class_error: 0.17699972\n",
      " default threshold: 0.36042290925979614\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4384   540  0.1097  540 / 4,924\n",
      "     1   388  1200  0.2443  388 / 1,588\n",
      "Totals  4772  1740  0.1425  928 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.993118  4.100756         4.100756       1.000000  0.994645                  1.000000          0.994645      0.041562                 0.041562   310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.990108  4.100756         4.100756       1.000000  0.991516                  1.000000          0.993093      0.040932                 0.082494   310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.986467  4.100756         4.100756       1.000000  0.988524                  1.000000          0.991577      0.040932                 0.123426   310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.977283  3.974579         4.069332       0.969231  0.982098                  0.992337          0.989217      0.039673                 0.163098   297.457857       306.933225            0.162692\n",
      "      5                0.05006143         0.963246  4.100756         4.075598       1.000000  0.970809                  0.993865          0.985546      0.040932                 0.204030   310.075567       307.559766            0.203624\n",
      "      6                0.10012285         0.787073  3.434068         3.754833       0.837423  0.872955                  0.915644          0.929251      0.171914                 0.375945   243.406840       275.483303            0.364775\n",
      "      7                0.15003071         0.643504  2.864220         3.458570       0.698462  0.713866                  0.843398          0.857603      0.142947                 0.518892   186.422011       245.856977            0.487819\n",
      "      8                0.20009214         0.504222  2.377432         3.188078       0.579755  0.569909                  0.777437          0.785624      0.119018                 0.637909   137.743197       218.807789            0.579014\n",
      "      9                0.30006143         0.299973  1.650381         2.675775       0.402458  0.395346                  0.652508          0.655598      0.164987                 0.802897    65.038093       167.577455            0.665001\n",
      "     10                0.40003071         0.164440  0.951174         2.244790       0.231951  0.225224                  0.547409          0.548046      0.095088                 0.897985    -4.882626       124.478986            0.658545\n",
      "     11                0.50000000         0.080623  0.541728         1.904282       0.132104  0.117500                  0.464373          0.461963      0.054156                 0.952141   -45.827191        90.428212            0.597957\n",
      "     12                0.59996929         0.036217  0.321257         1.640512       0.078341  0.054894                  0.400051          0.394136      0.032116                 0.984257   -67.874264        64.051219            0.508221\n",
      "     13                0.69993857         0.015676  0.100787         1.420600       0.024578  0.024553                  0.346424          0.341350      0.010076                 0.994332   -89.921338        42.059965            0.389337\n",
      "     14                0.79990786         0.006769  0.044094         1.248569       0.010753  0.010823                  0.304473          0.300042      0.004408                 0.998741   -95.590585        24.856949            0.262957\n",
      "     15                0.89987715         0.002065  0.012598         1.111263       0.003072  0.004043                  0.270990          0.267159      0.001259                 1.000000   -98.740167        11.126280            0.132413\n",
      "     16                1.00000000         0.000638  0.000000         1.000000       0.000000  0.001324                  0.243857          0.240542      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3942.898193          1.000000   0.195134\n",
      "                      capital_gain         3520.298340          0.892820   0.174219\n",
      "                               age         2252.830566          0.571364   0.111492\n",
      "                            fnlwgt         1733.697021          0.439701   0.085800\n",
      "marital_status. Married-civ-spouse         1516.921631          0.384722   0.075072\n",
      "                      capital_loss         1191.386475          0.302160   0.058962\n",
      "                    hours_per_week         1002.462158          0.254245   0.049612\n",
      "              education. Bachelors          669.298035          0.169748   0.033123\n",
      "        occupation. Prof-specialty          598.256042          0.151730   0.029608\n",
      "       occupation. Exec-managerial          597.172974          0.151455   0.029554\n",
      "---\n",
      "          race. Amer-Indian-Eskimo           11.035846          0.002799   0.000546\n",
      "          race. Asian-Pac-Islander            8.892183          0.002255   0.000440\n",
      "           marital_status. Widowed            7.120713          0.001806   0.000352\n",
      "                       race. Black            5.984648          0.001518   0.000296\n",
      "      relationship. Other-relative            5.857741          0.001486   0.000290\n",
      "         marital_status. Separated            4.794008          0.001216   0.000237\n",
      "              workclass. State-gov            4.356952          0.001105   0.000216\n",
      "                   education. 12th            3.347121          0.000849   0.000166\n",
      "                      workclass.NA            2.306062          0.000585   0.000114\n",
      "           relationship. Unmarried            1.745163          0.000443   0.000086\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        84865.968750          1.000000   0.136020\n",
      "                               age        83927.789063          0.988945   0.134517\n",
      "                      capital_gain        67515.156250          0.795550   0.108211\n",
      "                      capital_loss        58818.847656          0.693079   0.094273\n",
      "                    hours_per_week        48878.242188          0.575946   0.078340\n",
      "             relationship. Husband        19442.314453          0.229094   0.031161\n",
      "marital_status. Married-civ-spouse        18142.169922          0.213774   0.029078\n",
      "       occupation. Exec-managerial        15853.597656          0.186807   0.025410\n",
      "              education. Bachelors        14194.417969          0.167257   0.022750\n",
      "        occupation. Prof-specialty        13039.876953          0.153653   0.020900\n",
      "---\n",
      "       relationship. Not-in-family         1457.158691          0.017170   0.002335\n",
      "          race. Asian-Pac-Islander         1432.215698          0.016876   0.002296\n",
      "                   education. 12th         1390.342163          0.016383   0.002228\n",
      "      relationship. Other-relative         1385.789795          0.016329   0.002221\n",
      "                      workclass.NA         1346.937988          0.015871   0.002159\n",
      "      occupation. Transport-moving         1280.052368          0.015083   0.002052\n",
      "              workclass. State-gov         1193.456421          0.014063   0.001913\n",
      "         marital_status. Separated          954.012207          0.011241   0.001529\n",
      "                       race. Black          856.429321          0.010092   0.001373\n",
      "           relationship. Unmarried          304.313660          0.003586   0.000488\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          654.000000          1.000000   0.302079\n",
      "                         age          484.000000          0.740061   0.223557\n",
      "              hours_per_week          194.000000          0.296636   0.089607\n",
      "                capital_gain           68.000000          0.103976   0.031409\n",
      "          education. HS-grad           67.000000          0.102446   0.030947\n",
      "                capital_loss           66.000000          0.100917   0.030485\n",
      "        education. Bachelors           54.000000          0.082569   0.024942\n",
      "          workclass. Private           50.000000          0.076453   0.023095\n",
      " occupation. Exec-managerial           39.000000          0.059633   0.018014\n",
      "  occupation. Prof-specialty           34.000000          0.051988   0.015704\n",
      "---\n",
      "       education. Assoc-acdm            3.000000          0.004587   0.001386\n",
      "     marital_status. Widowed            2.000000          0.003058   0.000924\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.003058   0.000924\n",
      "          education. 5th-6th            2.000000          0.003058   0.000924\n",
      "relationship. Other-relative            1.000000          0.001529   0.000462\n",
      "             education. 12th            1.000000          0.001529   0.000462\n",
      "   marital_status. Separated            1.000000          0.001529   0.000462\n",
      "                workclass.NA            1.000000          0.001529   0.000462\n",
      "    race. Asian-Pac-Islander            1.000000          0.001529   0.000462\n",
      "        workclass. State-gov            1.000000          0.001529   0.000462\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      " 2023-10-20 18:27:09 11.108 sec              20       0.28399          0.25827      0.94080         0.85529       4.16584                       0.11993         0.30327            0.29091        0.92296           0.81834         4.10076                         0.13237\n",
      " 2023-10-20 18:27:10 11.595 sec              25       0.28087          0.25271      0.94332         0.86073       4.16584                       0.11885         0.30395            0.29168        0.92225           0.81702         4.10076                         0.13882\n",
      " 2023-10-20 18:27:10 12.022 sec              30       0.27624          0.24531      0.94704         0.86970       4.16584                       0.11517         0.30611            0.29509        0.92037           0.81284         4.10076                         0.14251\n",
      "\n",
      "10-20 18:27:11.069 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.31744559185866866, 0.2965993368819598, 0.29182020046893536, 0.29256053457486425]\n",
      "10-20 18:27:11.069 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.31744559185866866 --> 0.29182020046893536 (still improving).\n",
      "10-20 18:27:11.112 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:11.112) \n",
      "10-20 18:27:11.153 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:11.153) \n",
      "10-20 18:27:11.190 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:11.189) \n",
      "10-20 18:27:11.231 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:11.231) \n",
      "10-20 18:27:11.280 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:11.279) \n",
      "10-20 18:27:11.364 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_96\n",
      "10-20 18:27:11.391 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_96\n",
      "█10-20 18:27:11.608 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_97\n",
      "10-20 18:27:11.620 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_97\n",
      "10-20 18:27:11.634 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.074674636\n",
      " RMSE: 0.2732666\n",
      " AUC: 0.94933295\n",
      " pr_auc: 0.8749062\n",
      " logloss: 0.24049978\n",
      " mean_per_class_error: 0.15056774\n",
      " default threshold: 0.4350622594356537\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18517  1279  0.0646  1,279 / 19,796\n",
      "     1   1479  4774  0.2365   1,479 / 6,253\n",
      "Totals  19996  6053  0.1059  2,758 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.03 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.994229  4.165840         4.165840       1.000000  0.995614                  1.000000          0.995614      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.991346  4.165840         4.165840       1.000000  0.992846                  1.000000          0.994233      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.987543  4.165840         4.165840       1.000000  0.989486                  1.000000          0.992648      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.981073  4.165840         4.165840       1.000000  0.984739                  1.000000          0.990675      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.965661  4.117957         4.156249       0.988506  0.974310                  0.997698          0.987397      0.041260                 0.207900  311.795717       315.624905            0.207749\n",
      "      6                0.10000384         0.806659  3.890677         4.023514       0.933948  0.889458                  0.965835          0.938446      0.194467                 0.402367  289.067736       302.351418            0.397871\n",
      "      7                0.15002495         0.648915  3.334591         3.793814       0.800460  0.727377                  0.910696          0.868072      0.166800                 0.569167  233.459059       279.381422            0.551537\n",
      "      8                0.20000768         0.510603  2.527660         3.477397       0.606759  0.577831                  0.834741          0.795539      0.126339                 0.695506  152.766046       247.739729            0.652013\n",
      "      9                0.30001152         0.295392  1.712712         2.889169       0.411132  0.396332                  0.693538          0.662470      0.171278                 0.866784   71.271212       188.916890            0.745800\n",
      "     10                0.40001536         0.158344  0.805982         2.368372       0.193474  0.222017                  0.568522          0.552357      0.080601                 0.947385  -19.401783       136.837222            0.720269\n",
      "     11                0.50001919         0.071353  0.313438         1.957385       0.075240  0.109210                  0.469866          0.463728      0.031345                 0.978730  -68.656249        95.738528            0.629922\n",
      "     12                0.59998464         0.031431  0.147180         1.655781       0.035330  0.048587                  0.397466          0.394560      0.014713                 0.993443  -85.281977        65.578095            0.517741\n",
      "     13                0.69998848         0.014196  0.043178         1.425396       0.010365  0.021504                  0.342163          0.341263      0.004318                 0.997761  -95.682238        42.539642            0.391831\n",
      "     14                0.79999232         0.006098  0.015992         1.249212       0.003839  0.009816                  0.299870          0.299830      0.001599                 0.999360  -98.400829        24.921237            0.262343\n",
      "     15                0.89999616         0.001795  0.004798         1.110938       0.001152  0.003610                  0.266678          0.266915      0.000480                 0.999840  -99.520249        11.093816            0.131382\n",
      "     16                1.00000000         0.000392  0.001599         1.000000       0.000384  0.001077                  0.240048          0.240331      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09355097\n",
      " RMSE: 0.30586103\n",
      " AUC: 0.9206064\n",
      " pr_auc: 0.8131838\n",
      " logloss: 0.29513878\n",
      " mean_per_class_error: 0.17443043\n",
      " default threshold: 0.36508914828300476\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4400   524  0.1064  524 / 4,924\n",
      "     1   385  1203  0.2424  385 / 1,588\n",
      "Totals  4785  1727  0.1396  909 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.03 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994302  4.100756         4.100756       1.000000  0.995664                  1.000000          0.995664      0.041562                 0.041562   310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.991371  4.100756         4.100756       1.000000  0.992783                  1.000000          0.994234      0.040932                 0.082494   310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.987342  4.037667         4.079833       0.984615  0.989452                  0.994898          0.992648      0.040302                 0.122796   303.766712       307.983344            0.122593\n",
      "      4                0.04007985         0.979711  4.037667         4.069332       0.984615  0.984198                  0.992337          0.990544      0.040302                 0.163098   303.766712       306.933225            0.162692\n",
      "      5                0.05006143         0.963637  3.974579         4.050440       0.969231  0.972903                  0.987730          0.987026      0.039673                 0.202771   297.457857       305.043965            0.201958\n",
      "      6                0.10012285         0.793067  3.459226         3.754833       0.843558  0.878965                  0.915644          0.932996      0.173174                 0.375945   245.922641       275.483303            0.364775\n",
      "      7                0.15003071         0.653009  2.826367         3.445978       0.689231  0.720556                  0.840328          0.862327      0.141058                 0.517003   182.636698       244.597789            0.485321\n",
      "      8                0.20009214         0.503809  2.364853         3.175489       0.576687  0.576602                  0.774367          0.790841      0.118388                 0.635390   136.485296       217.548923            0.575683\n",
      "      9                0.30006143         0.296634  1.669278         2.673676       0.407066  0.395787                  0.651996          0.659224      0.166877                 0.802267    66.927842       167.367591            0.664168\n",
      "     10                0.40003071         0.155746  0.938575         2.240067       0.228879  0.220137                  0.546257          0.549494      0.093829                 0.896096    -6.142459       124.006730            0.656047\n",
      "     11                0.50000000         0.076874  0.579523         1.908060       0.141321  0.112944                  0.465295          0.462211      0.057935                 0.954030   -42.047693        90.806045            0.600456\n",
      "     12                0.59996929         0.035771  0.308659         1.641562       0.075269  0.053158                  0.400307          0.394053      0.030856                 0.984887   -69.134097        64.156178            0.509054\n",
      "     13                0.69993857         0.015237  0.107086         1.422399       0.026114  0.023705                  0.346863          0.341158      0.010705                 0.995592   -89.291421        42.239901            0.391002\n",
      "     14                0.79990786         0.006225  0.031496         1.248569       0.007680  0.010166                  0.304473          0.299792      0.003149                 0.998741   -96.850418        24.856949            0.262957\n",
      "     15                0.89987715         0.001795  0.012598         1.111263       0.003072  0.003645                  0.270990          0.266892      0.001259                 1.000000   -98.740167        11.126280            0.132413\n",
      "     16                1.00000000         0.000411  0.000000         1.000000       0.000000  0.001107                  0.243857          0.240281      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3967.304443          1.000000   0.189706\n",
      "                      capital_gain         3547.562744          0.894200   0.169635\n",
      "                               age         2401.382080          0.605293   0.114828\n",
      "                            fnlwgt         1987.094604          0.500868   0.095018\n",
      "marital_status. Married-civ-spouse         1524.232666          0.384199   0.072885\n",
      "                      capital_loss         1223.368774          0.308363   0.058498\n",
      "                    hours_per_week         1038.699707          0.261815   0.049668\n",
      "              education. Bachelors          672.475098          0.169504   0.032156\n",
      "       occupation. Exec-managerial          609.296692          0.153580   0.029135\n",
      "        occupation. Prof-specialty          602.984436          0.151988   0.028833\n",
      "---\n",
      "          race. Amer-Indian-Eskimo           11.035846          0.002782   0.000528\n",
      "           marital_status. Widowed           10.109044          0.002548   0.000483\n",
      "              workclass. State-gov            8.148808          0.002054   0.000390\n",
      "                       race. Black            8.115697          0.002046   0.000388\n",
      "      relationship. Other-relative            5.857741          0.001477   0.000280\n",
      "           relationship. Unmarried            5.188114          0.001308   0.000248\n",
      "         marital_status. Separated            4.794008          0.001208   0.000229\n",
      "                      workclass.NA            3.992634          0.001006   0.000191\n",
      "                   education. 12th            3.347121          0.000844   0.000160\n",
      "                 native_country.NA            3.153743          0.000795   0.000151\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       103047.812500          1.000000   0.145993\n",
      "                               age        94364.664063          0.915737   0.133691\n",
      "                      capital_gain        76190.140625          0.739367   0.107942\n",
      "                      capital_loss        66452.140625          0.644867   0.094146\n",
      "                    hours_per_week        52198.707031          0.506548   0.073952\n",
      "             relationship. Husband        20039.820313          0.194471   0.028391\n",
      "marital_status. Married-civ-spouse        18553.652344          0.180049   0.026286\n",
      "       occupation. Exec-managerial        16580.677734          0.160903   0.023491\n",
      "              education. Bachelors        14403.804688          0.139778   0.020407\n",
      "        occupation. Prof-specialty        13730.542969          0.133244   0.019453\n",
      "---\n",
      "          occupation. Adm-clerical         1828.750732          0.017747   0.002591\n",
      "           marital_status. Widowed         1683.758057          0.016340   0.002385\n",
      "                     occupation.NA         1592.119507          0.015450   0.002256\n",
      "                      workclass.NA         1474.325928          0.014307   0.002089\n",
      "                   education. 12th         1390.342163          0.013492   0.001970\n",
      "      relationship. Other-relative         1385.789795          0.013448   0.001963\n",
      "                 native_country.NA         1327.416382          0.012882   0.001881\n",
      "                       race. Black         1137.288330          0.011037   0.001611\n",
      "         marital_status. Separated          954.012207          0.009258   0.001352\n",
      "           relationship. Unmarried          572.588013          0.005557   0.000811\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          747.000000          1.000000   0.302797\n",
      "                         age          557.000000          0.745649   0.225780\n",
      "              hours_per_week          214.000000          0.286479   0.086745\n",
      "                capital_loss           77.000000          0.103079   0.031212\n",
      "                capital_gain           76.000000          0.101740   0.030807\n",
      "          education. HS-grad           75.000000          0.100402   0.030401\n",
      "          workclass. Private           59.000000          0.078983   0.023916\n",
      "        education. Bachelors           57.000000          0.076305   0.023105\n",
      " occupation. Exec-managerial           42.000000          0.056225   0.017025\n",
      "  occupation. Prof-specialty           36.000000          0.048193   0.014593\n",
      "---\n",
      "     marital_status. Widowed            3.000000          0.004016   0.001216\n",
      "    race. Asian-Pac-Islander            3.000000          0.004016   0.001216\n",
      "        workclass. State-gov            3.000000          0.004016   0.001216\n",
      "                workclass.NA            2.000000          0.002677   0.000811\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.002677   0.000811\n",
      "          education. 5th-6th            2.000000          0.002677   0.000811\n",
      "relationship. Other-relative            1.000000          0.001339   0.000405\n",
      "             education. 12th            1.000000          0.001339   0.000405\n",
      "   marital_status. Separated            1.000000          0.001339   0.000405\n",
      "           native_country.NA            1.000000          0.001339   0.000405\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      " 2023-10-20 18:27:09 11.108 sec              20       0.28399          0.25827      0.94080         0.85529       4.16584                       0.11993         0.30327            0.29091        0.92296           0.81834         4.10076                         0.13237\n",
      " 2023-10-20 18:27:10 11.595 sec              25       0.28087          0.25271      0.94332         0.86073       4.16584                       0.11885         0.30395            0.29168        0.92225           0.81702         4.10076                         0.13882\n",
      " 2023-10-20 18:27:10 12.022 sec              30       0.27624          0.24531      0.94704         0.86970       4.16584                       0.11517         0.30611            0.29509        0.92037           0.81284         4.10076                         0.14251\n",
      " 2023-10-20 18:27:11 12.510 sec              35       0.27327          0.24050      0.94933         0.87491       4.16584                       0.10588         0.30586            0.29514        0.92061           0.81318         4.10076                         0.13959\n",
      "\n",
      "10-20 18:27:11.641 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2965993368819598, 0.29182020046893536, 0.29256053457486425, 0.29396850700335325]\n",
      "10-20 18:27:11.642 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.2965993368819598 --> 0.29182020046893536 (still improving).\n",
      "10-20 18:27:11.691 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:11.691) \n",
      "10-20 18:27:11.738 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:11.738) \n",
      "10-20 18:27:11.774 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:11.774) \n",
      "10-20 18:27:11.818 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:11.818) \n",
      "10-20 18:27:11.907 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.089 (Wall: 20-Oct 18:27:11.907) \n",
      "10-20 18:27:12.007 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_98\n",
      "10-20 18:27:12.027 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_98\n",
      "10-20 18:27:12.227 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_99\n",
      "10-20 18:27:12.237 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_99\n",
      "10-20 18:27:12.251 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07311449\n",
      " RMSE: 0.27039692\n",
      " AUC: 0.9514945\n",
      " pr_auc: 0.87936807\n",
      " logloss: 0.23588778\n",
      " mean_per_class_error: 0.13951309\n",
      " default threshold: 0.41098061203956604\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18350  1446  0.0730  1,446 / 19,796\n",
      "     1   1288  4965  0.2060   1,288 / 6,253\n",
      "Totals  19638  6411  0.1050  2,734 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.14 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995624  4.165840         4.165840       1.000000  0.996683                  1.000000          0.996683      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.993139  4.165840         4.165840       1.000000  0.994391                  1.000000          0.995539      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.990338  4.165840         4.165840       1.000000  0.991910                  1.000000          0.994328      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.984750  4.149818         4.161842       0.996154  0.987880                  0.999040          0.992719      0.041420                 0.166480  314.981793       316.184247            0.166430\n",
      "      5                0.05002111         0.972369  4.101996         4.149855       0.984674  0.979618                  0.996163          0.990095      0.041100                 0.207580  310.199610       314.985482            0.207328\n",
      "      6                0.10000384         0.816053  3.909875         4.029911       0.938556  0.897121                  0.967370          0.943626      0.195426                 0.403007  290.987478       302.991086            0.398713\n",
      "      7                0.15002495         0.656806  3.376153         3.811936       0.810437  0.736345                  0.915046          0.874515      0.168879                 0.571885  237.615308       281.193584            0.555114\n",
      "      8                0.20000768         0.518544  2.559656         3.498986       0.614439  0.586095                  0.839923          0.802437      0.127939                 0.699824  155.965616       249.898610            0.657694\n",
      "      9                0.30001152         0.296746  1.715910         2.904628       0.411900  0.401517                  0.697249          0.668797      0.171598                 0.871422   71.591046       190.462755            0.751903\n",
      "     10                0.40001536         0.154724  0.788391         2.375568       0.189251  0.221831                  0.570250          0.557056      0.078842                 0.950264  -21.160871       137.556849            0.724057\n",
      "     11                0.50001919         0.068143  0.295847         1.959624       0.071017  0.105693                  0.470403          0.466783      0.029586                 0.979850  -70.415337        95.962412            0.631395\n",
      "     12                0.59998464         0.029270  0.147180         1.657647       0.035330  0.045992                  0.397914          0.396674      0.014713                 0.994563  -85.281977        65.764677            0.519214\n",
      "     13                0.69998848         0.013269  0.035182         1.425853       0.008445  0.020189                  0.342273          0.342887      0.003518                 0.998081  -96.481824        42.585335            0.392251\n",
      "     14                0.79999232         0.005659  0.012793         1.249212       0.003071  0.009048                  0.299870          0.301155      0.001279                 0.999360  -98.720663        24.921237            0.262343\n",
      "     15                0.89999616         0.001731  0.004798         1.110938       0.001152  0.003435                  0.266678          0.268074      0.000480                 0.999840  -99.520249        11.093816            0.131382\n",
      "     16                1.00000000         0.000274  0.001599         1.000000       0.000384  0.001055                  0.240048          0.241371      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.094228946\n",
      " RMSE: 0.30696735\n",
      " AUC: 0.9196226\n",
      " pr_auc: 0.8112081\n",
      " logloss: 0.29714444\n",
      " mean_per_class_error: 0.1772138\n",
      " default threshold: 0.37906017899513245\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4416   508  0.1032  508 / 4,924\n",
      "     1   399  1189  0.2513  399 / 1,588\n",
      "Totals  4815  1697  0.1393  907 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.15 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995802  4.100756         4.100756       1.000000  0.996727                  1.000000          0.996727      0.041562                 0.041562   310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.993604  4.100756         4.100756       1.000000  0.994647                  1.000000          0.995695      0.040932                 0.082494   310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.990011  4.037667         4.079833       0.984615  0.991829                  0.994898          0.994413      0.040302                 0.122796   303.766712       307.983344            0.122593\n",
      "      4                0.04007985         0.984849  3.974579         4.053621       0.969231  0.987707                  0.988506          0.992743      0.039673                 0.162469   297.457857       305.362054            0.161859\n",
      "      5                0.05006143         0.971296  4.037667         4.050440       0.984615  0.979052                  0.987730          0.990013      0.040302                 0.202771   303.766712       305.043965            0.201958\n",
      "      6                0.10012285         0.802879  3.396331         3.723386       0.828221  0.886153                  0.907975          0.938083      0.170025                 0.372796   239.633138       272.338551            0.360611\n",
      "      7                0.15003071         0.653392  2.889456         3.445978       0.704615  0.729488                  0.840328          0.868694      0.144207                 0.517003   188.945553       244.597789            0.485321\n",
      "      8                0.20009214         0.513278  2.377432         3.178636       0.579755  0.582814                  0.775134          0.797169      0.119018                 0.636020   137.743197       217.863640            0.576516\n",
      "      9                0.30006143         0.298151  1.675578         2.677873       0.408602  0.402400                  0.653019          0.665647      0.167506                 0.803526    67.557758       167.787320            0.665834\n",
      "     10                0.40003071         0.153505  0.907080         2.235345       0.221198  0.221621                  0.545106          0.554683      0.090680                 0.894207    -9.292041       123.534474            0.653549\n",
      "     11                0.50000000         0.074533  0.573224         1.903023       0.139785  0.109168                  0.464066          0.465607      0.057305                 0.951511   -42.677609        90.302267            0.597125\n",
      "     12                0.59996929         0.033058  0.327557         1.640512       0.079877  0.050899                  0.400051          0.396507      0.032746                 0.984257   -67.244348        64.051219            0.508221\n",
      "     13                0.69993857         0.013854  0.119684         1.423299       0.029186  0.022017                  0.347082          0.343020      0.011965                 0.996222   -88.031589        42.329870            0.391835\n",
      "     14                0.79990786         0.005860  0.018897         1.247782       0.004608  0.009428                  0.304281          0.301329      0.001889                 0.998111   -98.110251        24.778225            0.262124\n",
      "     15                0.89987715         0.001790  0.018897         1.111263       0.004608  0.003502                  0.270990          0.268243      0.001889                 1.000000   -98.110251        11.126280            0.132413\n",
      "     16                1.00000000         0.000288  0.000000         1.000000       0.000000  0.001091                  0.243857          0.241495      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3984.772461          1.000000   0.184049\n",
      "                      capital_gain         3561.777344          0.893847   0.164511\n",
      "                               age         2524.946777          0.633649   0.116622\n",
      "                            fnlwgt         2337.074951          0.586501   0.107945\n",
      "marital_status. Married-civ-spouse         1534.767944          0.385158   0.070888\n",
      "                      capital_loss         1240.860229          0.311401   0.057313\n",
      "                    hours_per_week         1095.405273          0.274898   0.050595\n",
      "              education. Bachelors          677.566650          0.170039   0.031295\n",
      "       occupation. Exec-managerial          620.189392          0.155640   0.028645\n",
      "        occupation. Prof-specialty          610.450195          0.153196   0.028195\n",
      "---\n",
      "          race. Amer-Indian-Eskimo           11.035846          0.002770   0.000510\n",
      "              workclass. State-gov           10.431362          0.002618   0.000482\n",
      "           marital_status. Widowed           10.109044          0.002537   0.000467\n",
      "                       race. Black            8.115697          0.002037   0.000375\n",
      "           relationship. Unmarried            8.009746          0.002010   0.000370\n",
      "      relationship. Other-relative            5.857741          0.001470   0.000271\n",
      "                      workclass.NA            5.343087          0.001341   0.000247\n",
      "         marital_status. Separated            4.794008          0.001203   0.000221\n",
      "                   education. 12th            3.347121          0.000840   0.000155\n",
      "                 native_country.NA            3.153743          0.000791   0.000146\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       127602.640625          1.000000   0.162573\n",
      "                               age       103676.656250          0.812496   0.132090\n",
      "                      capital_gain        80644.101563          0.631994   0.102745\n",
      "                      capital_loss        75391.343750          0.590829   0.096053\n",
      "                    hours_per_week        58214.468750          0.456217   0.074169\n",
      "             relationship. Husband        20391.296875          0.159803   0.025980\n",
      "marital_status. Married-civ-spouse        19667.310547          0.154129   0.025057\n",
      "       occupation. Exec-managerial        17716.718750          0.138843   0.022572\n",
      "              education. Bachelors        15759.737305          0.123506   0.020079\n",
      "        occupation. Prof-specialty        14319.268555          0.112218   0.018244\n",
      "---\n",
      "          occupation. Adm-clerical         1828.750732          0.014332   0.002330\n",
      "           marital_status. Widowed         1683.758057          0.013195   0.002145\n",
      "                     occupation.NA         1592.119507          0.012477   0.002028\n",
      "                      workclass.NA         1531.793213          0.012004   0.001952\n",
      "                   education. 12th         1390.342163          0.010896   0.001771\n",
      "      relationship. Other-relative         1385.789795          0.010860   0.001766\n",
      "                 native_country.NA         1327.416382          0.010403   0.001691\n",
      "                       race. Black         1137.288330          0.008913   0.001449\n",
      "         marital_status. Separated          954.012207          0.007476   0.001215\n",
      "           relationship. Unmarried          788.801697          0.006182   0.001005\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          904.000000          1.000000   0.324713\n",
      "                         age          609.000000          0.673673   0.218750\n",
      "              hours_per_week          238.000000          0.263274   0.085489\n",
      "                capital_loss           85.000000          0.094027   0.030532\n",
      "          education. HS-grad           82.000000          0.090708   0.029454\n",
      "                capital_gain           81.000000          0.089602   0.029095\n",
      "          workclass. Private           63.000000          0.069690   0.022629\n",
      "        education. Bachelors           60.000000          0.066372   0.021552\n",
      " occupation. Exec-managerial           46.000000          0.050885   0.016523\n",
      "       relationship. Husband           43.000000          0.047566   0.015445\n",
      "---\n",
      "        workclass. State-gov            4.000000          0.004425   0.001437\n",
      "     marital_status. Widowed            3.000000          0.003319   0.001078\n",
      "                workclass.NA            3.000000          0.003319   0.001078\n",
      "    race. Asian-Pac-Islander            3.000000          0.003319   0.001078\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.002212   0.000718\n",
      "          education. 5th-6th            2.000000          0.002212   0.000718\n",
      "relationship. Other-relative            1.000000          0.001106   0.000359\n",
      "             education. 12th            1.000000          0.001106   0.000359\n",
      "   marital_status. Separated            1.000000          0.001106   0.000359\n",
      "           native_country.NA            1.000000          0.001106   0.000359\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      " 2023-10-20 18:27:09 11.108 sec              20       0.28399          0.25827      0.94080         0.85529       4.16584                       0.11993         0.30327            0.29091        0.92296           0.81834         4.10076                         0.13237\n",
      " 2023-10-20 18:27:10 11.595 sec              25       0.28087          0.25271      0.94332         0.86073       4.16584                       0.11885         0.30395            0.29168        0.92225           0.81702         4.10076                         0.13882\n",
      " 2023-10-20 18:27:10 12.022 sec              30       0.27624          0.24531      0.94704         0.86970       4.16584                       0.11517         0.30611            0.29509        0.92037           0.81284         4.10076                         0.14251\n",
      " 2023-10-20 18:27:11 12.510 sec              35       0.27327          0.24050      0.94933         0.87491       4.16584                       0.10588         0.30586            0.29514        0.92061           0.81318         4.10076                         0.13959\n",
      " 2023-10-20 18:27:11 13.138 sec              40       0.27040          0.23589      0.95149         0.87937       4.16584                       0.10496         0.30697            0.29714        0.91962           0.81121         4.10076                         0.13928\n",
      "\n",
      "10-20 18:27:12.256 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29182020046893536, 0.29256053457486425, 0.29396850700335325, 0.2957901862944999]\n",
      "10-20 18:27:12.257 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.29182020046893536 --> 0.29256053457486425 (converged).\n",
      "10-20 18:27:12.258 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:12.258 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:12.361 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_100\n",
      "10-20 18:27:12.377 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_100\n",
      "█10-20 18:27:12.462 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:12.611 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_101\n",
      "10-20 18:27:12.622 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_101\n",
      "10-20 18:27:12.627 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07311449\n",
      " RMSE: 0.27039692\n",
      " AUC: 0.9514945\n",
      " pr_auc: 0.87936807\n",
      " logloss: 0.23588778\n",
      " mean_per_class_error: 0.13951309\n",
      " default threshold: 0.41098061203956604\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18350  1446  0.0730  1,446 / 19,796\n",
      "     1   1288  4965  0.2060   1,288 / 6,253\n",
      "Totals  19638  6411  0.1050  2,734 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.14 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995624  4.165840         4.165840       1.000000  0.996683                  1.000000          0.996683      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.993139  4.165840         4.165840       1.000000  0.994391                  1.000000          0.995539      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.990338  4.165840         4.165840       1.000000  0.991910                  1.000000          0.994328      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.984750  4.149818         4.161842       0.996154  0.987880                  0.999040          0.992719      0.041420                 0.166480  314.981793       316.184247            0.166430\n",
      "      5                0.05002111         0.972369  4.101996         4.149855       0.984674  0.979618                  0.996163          0.990095      0.041100                 0.207580  310.199610       314.985482            0.207328\n",
      "      6                0.10000384         0.816053  3.909875         4.029911       0.938556  0.897121                  0.967370          0.943626      0.195426                 0.403007  290.987478       302.991086            0.398713\n",
      "      7                0.15002495         0.656806  3.376153         3.811936       0.810437  0.736345                  0.915046          0.874515      0.168879                 0.571885  237.615308       281.193584            0.555114\n",
      "      8                0.20000768         0.518544  2.559656         3.498986       0.614439  0.586095                  0.839923          0.802437      0.127939                 0.699824  155.965616       249.898610            0.657694\n",
      "      9                0.30001152         0.296746  1.715910         2.904628       0.411900  0.401517                  0.697249          0.668797      0.171598                 0.871422   71.591046       190.462755            0.751903\n",
      "     10                0.40001536         0.154724  0.788391         2.375568       0.189251  0.221831                  0.570250          0.557056      0.078842                 0.950264  -21.160871       137.556849            0.724057\n",
      "     11                0.50001919         0.068143  0.295847         1.959624       0.071017  0.105693                  0.470403          0.466783      0.029586                 0.979850  -70.415337        95.962412            0.631395\n",
      "     12                0.59998464         0.029270  0.147180         1.657647       0.035330  0.045992                  0.397914          0.396674      0.014713                 0.994563  -85.281977        65.764677            0.519214\n",
      "     13                0.69998848         0.013269  0.035182         1.425853       0.008445  0.020189                  0.342273          0.342887      0.003518                 0.998081  -96.481824        42.585335            0.392251\n",
      "     14                0.79999232         0.005659  0.012793         1.249212       0.003071  0.009048                  0.299870          0.301155      0.001279                 0.999360  -98.720663        24.921237            0.262343\n",
      "     15                0.89999616         0.001731  0.004798         1.110938       0.001152  0.003435                  0.266678          0.268074      0.000480                 0.999840  -99.520249        11.093816            0.131382\n",
      "     16                1.00000000         0.000274  0.001599         1.000000       0.000384  0.001055                  0.240048          0.241371      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.094228946\n",
      " RMSE: 0.30696735\n",
      " AUC: 0.9196226\n",
      " pr_auc: 0.8112081\n",
      " logloss: 0.29714444\n",
      " mean_per_class_error: 0.1772138\n",
      " default threshold: 0.37906017899513245\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4416   508  0.1032  508 / 4,924\n",
      "     1   399  1189  0.2513  399 / 1,588\n",
      "Totals  4815  1697  0.1393  907 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.15 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995802  4.100756         4.100756       1.000000  0.996727                  1.000000          0.996727      0.041562                 0.041562   310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.993604  4.100756         4.100756       1.000000  0.994647                  1.000000          0.995695      0.040932                 0.082494   310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.990011  4.037667         4.079833       0.984615  0.991829                  0.994898          0.994413      0.040302                 0.122796   303.766712       307.983344            0.122593\n",
      "      4                0.04007985         0.984849  3.974579         4.053621       0.969231  0.987707                  0.988506          0.992743      0.039673                 0.162469   297.457857       305.362054            0.161859\n",
      "      5                0.05006143         0.971296  4.037667         4.050440       0.984615  0.979052                  0.987730          0.990013      0.040302                 0.202771   303.766712       305.043965            0.201958\n",
      "      6                0.10012285         0.802879  3.396331         3.723386       0.828221  0.886153                  0.907975          0.938083      0.170025                 0.372796   239.633138       272.338551            0.360611\n",
      "      7                0.15003071         0.653392  2.889456         3.445978       0.704615  0.729488                  0.840328          0.868694      0.144207                 0.517003   188.945553       244.597789            0.485321\n",
      "      8                0.20009214         0.513278  2.377432         3.178636       0.579755  0.582814                  0.775134          0.797169      0.119018                 0.636020   137.743197       217.863640            0.576516\n",
      "      9                0.30006143         0.298151  1.675578         2.677873       0.408602  0.402400                  0.653019          0.665647      0.167506                 0.803526    67.557758       167.787320            0.665834\n",
      "     10                0.40003071         0.153505  0.907080         2.235345       0.221198  0.221621                  0.545106          0.554683      0.090680                 0.894207    -9.292041       123.534474            0.653549\n",
      "     11                0.50000000         0.074533  0.573224         1.903023       0.139785  0.109168                  0.464066          0.465607      0.057305                 0.951511   -42.677609        90.302267            0.597125\n",
      "     12                0.59996929         0.033058  0.327557         1.640512       0.079877  0.050899                  0.400051          0.396507      0.032746                 0.984257   -67.244348        64.051219            0.508221\n",
      "     13                0.69993857         0.013854  0.119684         1.423299       0.029186  0.022017                  0.347082          0.343020      0.011965                 0.996222   -88.031589        42.329870            0.391835\n",
      "     14                0.79990786         0.005860  0.018897         1.247782       0.004608  0.009428                  0.304281          0.301329      0.001889                 0.998111   -98.110251        24.778225            0.262124\n",
      "     15                0.89987715         0.001790  0.018897         1.111263       0.004608  0.003502                  0.270990          0.268243      0.001889                 1.000000   -98.110251        11.126280            0.132413\n",
      "     16                1.00000000         0.000288  0.000000         1.000000       0.000000  0.001091                  0.243857          0.241495      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3984.772461          1.000000   0.184049\n",
      "                      capital_gain         3561.777344          0.893847   0.164511\n",
      "                               age         2524.946777          0.633649   0.116622\n",
      "                            fnlwgt         2337.074951          0.586501   0.107945\n",
      "marital_status. Married-civ-spouse         1534.767944          0.385158   0.070888\n",
      "                      capital_loss         1240.860229          0.311401   0.057313\n",
      "                    hours_per_week         1095.405273          0.274898   0.050595\n",
      "              education. Bachelors          677.566650          0.170039   0.031295\n",
      "       occupation. Exec-managerial          620.189392          0.155640   0.028645\n",
      "        occupation. Prof-specialty          610.450195          0.153196   0.028195\n",
      "---\n",
      "          race. Amer-Indian-Eskimo           11.035846          0.002770   0.000510\n",
      "              workclass. State-gov           10.431362          0.002618   0.000482\n",
      "           marital_status. Widowed           10.109044          0.002537   0.000467\n",
      "                       race. Black            8.115697          0.002037   0.000375\n",
      "           relationship. Unmarried            8.009746          0.002010   0.000370\n",
      "      relationship. Other-relative            5.857741          0.001470   0.000271\n",
      "                      workclass.NA            5.343087          0.001341   0.000247\n",
      "         marital_status. Separated            4.794008          0.001203   0.000221\n",
      "                   education. 12th            3.347121          0.000840   0.000155\n",
      "                 native_country.NA            3.153743          0.000791   0.000146\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       127602.640625          1.000000   0.162573\n",
      "                               age       103676.656250          0.812496   0.132090\n",
      "                      capital_gain        80644.101563          0.631994   0.102745\n",
      "                      capital_loss        75391.343750          0.590829   0.096053\n",
      "                    hours_per_week        58214.468750          0.456217   0.074169\n",
      "             relationship. Husband        20391.296875          0.159803   0.025980\n",
      "marital_status. Married-civ-spouse        19667.310547          0.154129   0.025057\n",
      "       occupation. Exec-managerial        17716.718750          0.138843   0.022572\n",
      "              education. Bachelors        15759.737305          0.123506   0.020079\n",
      "        occupation. Prof-specialty        14319.268555          0.112218   0.018244\n",
      "---\n",
      "          occupation. Adm-clerical         1828.750732          0.014332   0.002330\n",
      "           marital_status. Widowed         1683.758057          0.013195   0.002145\n",
      "                     occupation.NA         1592.119507          0.012477   0.002028\n",
      "                      workclass.NA         1531.793213          0.012004   0.001952\n",
      "                   education. 12th         1390.342163          0.010896   0.001771\n",
      "      relationship. Other-relative         1385.789795          0.010860   0.001766\n",
      "                 native_country.NA         1327.416382          0.010403   0.001691\n",
      "                       race. Black         1137.288330          0.008913   0.001449\n",
      "         marital_status. Separated          954.012207          0.007476   0.001215\n",
      "           relationship. Unmarried          788.801697          0.006182   0.001005\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          904.000000          1.000000   0.324713\n",
      "                         age          609.000000          0.673673   0.218750\n",
      "              hours_per_week          238.000000          0.263274   0.085489\n",
      "                capital_loss           85.000000          0.094027   0.030532\n",
      "          education. HS-grad           82.000000          0.090708   0.029454\n",
      "                capital_gain           81.000000          0.089602   0.029095\n",
      "          workclass. Private           63.000000          0.069690   0.022629\n",
      "        education. Bachelors           60.000000          0.066372   0.021552\n",
      " occupation. Exec-managerial           46.000000          0.050885   0.016523\n",
      "       relationship. Husband           43.000000          0.047566   0.015445\n",
      "---\n",
      "        workclass. State-gov            4.000000          0.004425   0.001437\n",
      "     marital_status. Widowed            3.000000          0.003319   0.001078\n",
      "                workclass.NA            3.000000          0.003319   0.001078\n",
      "    race. Asian-Pac-Islander            3.000000          0.003319   0.001078\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.002212   0.000718\n",
      "          education. 5th-6th            2.000000          0.002212   0.000718\n",
      "relationship. Other-relative            1.000000          0.001106   0.000359\n",
      "             education. 12th            1.000000          0.001106   0.000359\n",
      "   marital_status. Separated            1.000000          0.001106   0.000359\n",
      "           native_country.NA            1.000000          0.001106   0.000359\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:08  9.740 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:08 10.101 sec               5       0.31464          0.33915      0.92353         0.82087       4.16584                       0.14358         0.32410            0.35345        0.91155           0.79737         4.10076                         0.15556\n",
      " 2023-10-20 18:27:09 10.422 sec              10       0.29455          0.28384      0.93264         0.83861       4.16584                       0.13029         0.30825            0.30602        0.91820           0.81086         4.10076                         0.14819\n",
      " 2023-10-20 18:27:09 10.738 sec              15       0.28774          0.26614      0.93777         0.84897       4.16584                       0.12227         0.30367            0.29287        0.92228           0.81850         4.10076                         0.14696\n",
      " 2023-10-20 18:27:09 11.108 sec              20       0.28399          0.25827      0.94080         0.85529       4.16584                       0.11993         0.30327            0.29091        0.92296           0.81834         4.10076                         0.13237\n",
      " 2023-10-20 18:27:10 11.595 sec              25       0.28087          0.25271      0.94332         0.86073       4.16584                       0.11885         0.30395            0.29168        0.92225           0.81702         4.10076                         0.13882\n",
      " 2023-10-20 18:27:10 12.022 sec              30       0.27624          0.24531      0.94704         0.86970       4.16584                       0.11517         0.30611            0.29509        0.92037           0.81284         4.10076                         0.14251\n",
      " 2023-10-20 18:27:11 12.510 sec              35       0.27327          0.24050      0.94933         0.87491       4.16584                       0.10588         0.30586            0.29514        0.92061           0.81318         4.10076                         0.13959\n",
      " 2023-10-20 18:27:11 13.138 sec              40       0.27040          0.23589      0.95149         0.87937       4.16584                       0.10496         0.30697            0.29714        0.91962           0.81121         4.10076                         0.13928\n",
      "\n",
      "10-20 18:27:12.630 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: In-training scoring took 2282ms.\n",
      "10-20 18:27:12.636 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Completing model XGBoost_1_AutoML_1_20231020_182658_cv_5\n",
      "10-20 18:27:12.637 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 4 / 5.\n",
      "10-20 18:27:12.637 172.17.0.2:54321      22766      FJ-2-7  WARN water.default: _ntrees: Setting optimal _ntrees to 40 for cross-validation main model based on early stopping of cross-validation models.\n",
      "10-20 18:27:12.639 172.17.0.2:54321      22766      FJ-2-7  WARN water.default: _stopping_rounds: Disabling convergence-based early stopping for cross-validation main model.\n",
      "10-20 18:27:12.639 172.17.0.2:54321      22766      FJ-2-7  WARN water.default: _max_runtime_secs: Disabling maximum allowed runtime for cross-validation main model.\n",
      "10-20 18:27:12.639 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Scoring the 5 CV models\n",
      "10-20 18:27:12.720 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_102\n",
      "10-20 18:27:12.732 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_102\n",
      "10-20 18:27:12.801 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model Quantiles_model_1697826262527_103\n",
      "10-20 18:27:12.807 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model Quantiles_model_1697826262527_103\n",
      "10-20 18:27:12.874 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Starting model Quantiles_model_1697826262527_104\n",
      "10-20 18:27:12.882 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Completing model Quantiles_model_1697826262527_104\n",
      "10-20 18:27:12.947 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model Quantiles_model_1697826262527_105\n",
      "10-20 18:27:12.969 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model Quantiles_model_1697826262527_105\n",
      "10-20 18:27:13.035 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model Quantiles_model_1697826262527_106\n",
      "10-20 18:27:13.043 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model Quantiles_model_1697826262527_106\n",
      "10-20 18:27:13.048 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Building main model.\n",
      "10-20 18:27:13.048 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Remaining time for main model (ms): 0\n",
      "10-20 18:27:13.048 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:13.048 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: {\"_train\":{\"name\":\"AutoML_1_20231020_182658_training_py_9_sid_88b4\",\"type\":\"Key\"},\"_valid\":null,\"_nfolds\":5,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":42,\"_fold_assignment\":\"Modulo\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":null,\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":false,\"_cv_fold\":-1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":0,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":40,\"_n_estimators\":0,\"_max_depth\":15,\"_min_rows\":10.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:13.049 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:13.142 172.17.0.2:54321      22766      FJ-3-1  WARN water.default: _stopping_metric: Stopping metric is ignored for _stopping_rounds=0.\n",
      "10-20 18:27:13.142 172.17.0.2:54321      22766      FJ-3-1  WARN water.default: _stopping_tolerance: Stopping tolerance is ignored for _stopping_rounds=0.\n",
      "10-20 18:27:13.155 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:13.155 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model XGBoost_1_AutoML_1_20231020_182658\n",
      "10-20 18:27:13.156 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  seed = 42\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 15\n",
      "10-20 18:27:13.158 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:13.159 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  nround = 40\n",
      "10-20 18:27:13.159 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:13.159 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:13.160 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:13.160 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:13.160 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:13.160 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:13.160 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:13.161 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:13.162 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:13.162 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 10.0\n",
      "10-20 18:27:13.162 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:13.162 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:13.231 172.17.0.2:54321      22766  020_182658  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:13.246 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_107\n",
      "10-20 18:27:13.247 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_107\n",
      "10-20 18:27:13.273 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24080956\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  24720  1.0000  24,720 / 24,720\n",
      "     1  0   7841  0.0000        0 / 7,841\n",
      "Totals  0  32561  0.7592  24,720 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.240810  0.500000                  0.240810          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      "\n",
      "10-20 18:27:13.342 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:13.342) \n",
      "█10-20 18:27:13.413 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:13.413) \n",
      "10-20 18:27:13.457 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:13.457) \n",
      "10-20 18:27:13.513 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:13.513) \n",
      "10-20 18:27:13.555 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:13.555) \n",
      "10-20 18:27:13.578 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_108\n",
      "10-20 18:27:13.589 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_108\n",
      "10-20 18:27:13.594 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.10002155\n",
      " RMSE: 0.31626183\n",
      " AUC: 0.9252508\n",
      " pr_auc: 0.8202904\n",
      " logloss: 0.34333932\n",
      " mean_per_class_error: 0.16984874\n",
      " default threshold: 0.37557461857795715\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  21802  2918  0.1180  2,918 / 24,720\n",
      "     1   1738  6103  0.2217   1,738 / 7,841\n",
      "Totals  23540  9021  0.1430  4,656 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 29.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01025767         0.863289  4.152659         4.152659       1.000000  0.883225                  1.000000          0.883225      0.042597                 0.042597  315.265910       315.265910            0.042597\n",
      "      2                0.02002396         0.840658  4.139600         4.146290       0.996855  0.853073                  0.998466          0.868519      0.040429                 0.083025  313.960042       314.628999            0.082985\n",
      "      3                0.03000522         0.823292  4.063217         4.118656       0.978462  0.831487                  0.991812          0.856200      0.040556                 0.123581  306.321721       311.865575            0.123258\n",
      "      4                0.04007862         0.798797  4.038714         4.098563       0.972561  0.810242                  0.986973          0.844649      0.040684                 0.164265  303.871419       309.856316            0.163577\n",
      "      5                0.05005989         0.776469  3.986553         4.076230       0.960000  0.788207                  0.981595          0.833395      0.039791                 0.204056  298.655274       307.622979            0.202842\n",
      "      6                0.10002764         0.677271  3.611563         3.844110       0.869699  0.726537                  0.925698          0.780015      0.180462                 0.384517  261.156277       284.411028            0.374728\n",
      "      7                0.15005682         0.571607  2.921392         3.536475       0.703499  0.624962                  0.851617          0.728320      0.146155                 0.530672  192.139185       253.647452            0.501344\n",
      "      8                0.20002457         0.480354  2.294555         3.226233       0.552551  0.523856                  0.776908          0.677243      0.114654                 0.645326  129.455472       222.623293            0.586548\n",
      "      9                0.30002150         0.358335  1.640147         2.697592       0.394963  0.411233                  0.649606          0.588582      0.164010                 0.809336   64.014730       169.759184            0.670865\n",
      "     10                0.40004914         0.266047  1.053146         2.286417       0.253608  0.311890                  0.550591          0.519399      0.105344                 0.914679    5.314597       128.641725            0.677867\n",
      "     11                0.50001536         0.192033  0.492451         1.927756       0.118587  0.227611                  0.464222          0.461063      0.049228                 0.963908  -50.754949        92.775613            0.611035\n",
      "     12                0.60001228         0.142934  0.219367         1.643039       0.052826  0.165591                  0.395660          0.411820      0.021936                 0.985844  -78.063349        64.303910            0.508214\n",
      "     13                0.70007064         0.118290  0.086673         1.420594       0.020872  0.129427                  0.342093          0.371458      0.008672                 0.994516  -91.332694        42.059380            0.387841\n",
      "     14                0.80080464         0.111869  0.034183         1.246196       0.008232  0.114479                  0.300096          0.339133      0.003443                 0.997959  -96.581653        24.619588            0.259691\n",
      "     15                1.00000000         0.104699  0.010244         1.000000       0.002467  0.106537                  0.240810          0.292801      0.002041                 1.000000  -98.975601         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3629.620850          1.000000   0.225897\n",
      "                      capital_gain         2725.740967          0.750971   0.169642\n",
      "marital_status. Married-civ-spouse         2143.335938          0.590512   0.133395\n",
      "        occupation. Prof-specialty         1060.915039          0.292294   0.066028\n",
      "                               age          984.435425          0.271223   0.061268\n",
      "                      capital_loss          771.524536          0.212563   0.048017\n",
      "                    hours_per_week          761.325256          0.209753   0.047383\n",
      "       occupation. Exec-managerial          647.293213          0.178336   0.040286\n",
      "     marital_status. Never-married          461.313843          0.127097   0.028711\n",
      "                            fnlwgt          445.529755          0.122748   0.027728\n",
      "---\n",
      "                       race. White           14.710442          0.004053   0.000916\n",
      "                   education. 11th           14.086014          0.003881   0.000877\n",
      "              workclass. Local-gov           12.548145          0.003457   0.000781\n",
      "                     occupation.NA            7.386438          0.002035   0.000460\n",
      "           workclass. Self-emp-inc            7.379813          0.002033   0.000459\n",
      "          race. Asian-Pac-Islander            5.420071          0.001493   0.000337\n",
      "                       race. Black            5.001227          0.001378   0.000311\n",
      "                   education. 10th            4.457323          0.001228   0.000277\n",
      "          occupation. Craft-repair            3.657973          0.001008   0.000228\n",
      "           relationship. Unmarried            2.676048          0.000737   0.000167\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        24953.951172          1.000000   0.129593\n",
      "                    hours_per_week        18044.957031          0.723130   0.093713\n",
      "        occupation. Prof-specialty        15734.083984          0.630525   0.081712\n",
      "                      capital_gain        14601.147461          0.585124   0.075828\n",
      "       occupation. Exec-managerial        12907.351563          0.517247   0.067032\n",
      "marital_status. Married-civ-spouse        12490.954102          0.500560   0.064869\n",
      "                            fnlwgt        11407.476563          0.457141   0.059242\n",
      "             relationship. Husband         9886.225586          0.396179   0.051342\n",
      "                      capital_loss         9804.059570          0.392886   0.050915\n",
      "              education. Bachelors         8291.922852          0.332289   0.043062\n",
      "---\n",
      "          marital_status. Divorced          436.886047          0.017508   0.002269\n",
      "             education. Assoc-acdm          315.471497          0.012642   0.001638\n",
      "      occupation. Transport-moving          312.500000          0.012523   0.001623\n",
      "          occupation. Craft-repair          309.469696          0.012402   0.001607\n",
      "           workclass. Self-emp-inc          251.191971          0.010066   0.001305\n",
      "                   education. 10th          168.052460          0.006735   0.000873\n",
      "                       race. Black          103.230080          0.004137   0.000536\n",
      "                     occupation.NA           93.723495          0.003756   0.000487\n",
      "           relationship. Unmarried           52.033039          0.002085   0.000270\n",
      "          race. Asian-Pac-Islander           50.180462          0.002011   0.000261\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          190.000000          1.000000   0.296875\n",
      "                         age          132.000000          0.694737   0.206250\n",
      "              hours_per_week           63.000000          0.331579   0.098438\n",
      "          workclass. Private           26.000000          0.136842   0.040625\n",
      "          education. HS-grad           19.000000          0.100000   0.029688\n",
      "  occupation. Prof-specialty           17.000000          0.089474   0.026563\n",
      "        education. Bachelors           17.000000          0.089474   0.026563\n",
      "     education. Some-college           15.000000          0.078947   0.023438\n",
      " occupation. Exec-managerial           13.000000          0.068421   0.020313\n",
      "                 sex. Female           12.000000          0.063158   0.018750\n",
      "---\n",
      "               occupation.NA            2.000000          0.010526   0.003125\n",
      "occupation. Transport-moving            2.000000          0.010526   0.003125\n",
      "    occupation. Craft-repair            2.000000          0.010526   0.003125\n",
      " occupation. Protective-serv            2.000000          0.010526   0.003125\n",
      "     relationship. Unmarried            1.000000          0.005263   0.001563\n",
      "             education. 10th            1.000000          0.005263   0.001563\n",
      "             education. 11th            1.000000          0.005263   0.001563\n",
      "    race. Asian-Pac-Islander            1.000000          0.005263   0.001563\n",
      "              education. 9th            1.000000          0.005263   0.001563\n",
      "                 race. Black            1.000000          0.005263   0.001563\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      "\n",
      "10-20 18:27:13.648 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:13.648) \n",
      "10-20 18:27:13.692 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:13.691) \n",
      "10-20 18:27:13.736 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:13.736) \n",
      "10-20 18:27:13.777 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:13.777) \n",
      "10-20 18:27:13.817 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:13.817) \n",
      "10-20 18:27:13.848 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_109\n",
      "10-20 18:27:13.855 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:13.870 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_109\n",
      "10-20 18:27:13.873 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08701591\n",
      " RMSE: 0.2949846\n",
      " AUC: 0.93307954\n",
      " pr_auc: 0.838972\n",
      " logloss: 0.28518835\n",
      " mean_per_class_error: 0.16272698\n",
      " default threshold: 0.3705460727214813\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22214  2506  0.1014  2,506 / 24,720\n",
      "     1   1757  6084  0.2241   1,757 / 7,841\n",
      "Totals  23971  8590  0.1309  4,263 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 25.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.957542  4.152659         4.152659       1.000000  0.964844                  1.000000          0.964844      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.943898  4.139921         4.146290       0.996933  0.950781                  0.998466          0.957812      0.041449                 0.083025  313.992088       314.628999            0.082985\n",
      "      3                0.03000522         0.928798  4.127104         4.139908       0.993846  0.937349                  0.996929          0.951005      0.041194                 0.124219  312.710427       313.990784            0.124097\n",
      "      4                0.04004791         0.910884  4.127261         4.136736       0.993884  0.920150                  0.996166          0.943268      0.041449                 0.165668  312.726057       313.673633            0.165465\n",
      "      5                0.05002918         0.883628  4.114327         4.132265       0.990769  0.898360                  0.995089          0.934308      0.041066                 0.206734  311.432686       313.226544            0.206410\n",
      "      6                0.10002764         0.733996  3.693520         3.912960       0.889435  0.808232                  0.942278          0.871289      0.184670                 0.391404  269.351989       291.296002            0.383799\n",
      "      7                0.15002610         0.595299  3.007362         3.611156       0.724201  0.662821                  0.869601          0.801814      0.150363                 0.541768  200.736184       261.115575            0.515999\n",
      "      8                0.20002457         0.482162  2.433438         3.316771       0.585995  0.537421                  0.798710          0.735726      0.121668                 0.663436  143.343783       231.677148            0.610402\n",
      "      9                0.30002150         0.322642  1.623567         2.752428       0.390971  0.393598                  0.662811          0.621695      0.162352                 0.825788   62.356727       175.242785            0.692535\n",
      "     10                0.40001843         0.202218  0.961642         2.304766       0.231572  0.261920                  0.555010          0.531758      0.096161                 0.921949   -3.835843       130.476565            0.687483\n",
      "     11                0.50001536         0.121004  0.464241         1.936683       0.111794  0.158912                  0.466372          0.457193      0.046423                 0.968371  -53.575924        93.668328            0.616915\n",
      "     12                0.60001228         0.067027  0.191308         1.645802       0.046069  0.091909                  0.396325          0.396316      0.019130                 0.987502  -80.869199        64.580229            0.510398\n",
      "     13                0.70000921         0.042635  0.089277         1.423451       0.021499  0.052758                  0.342781          0.347238      0.008927                 0.996429  -91.072293        42.345130            0.390442\n",
      "     14                0.80003685         0.032773  0.026775         1.248827       0.006448  0.037112                  0.300729          0.308464      0.002678                 0.999107  -97.322510        24.882654            0.262214\n",
      "     15                0.90270569         0.025249  0.007453         1.107639       0.001795  0.028956                  0.266730          0.276674      0.000765                 0.999872  -99.254683        10.763948            0.127987\n",
      "     16                1.00000000         0.024499  0.001311         1.000000       0.000316  0.024810                  0.240810          0.252169      0.000128                 1.000000  -99.868919         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "             relationship. Husband         3630.878174          1.000000   0.180636\n",
      "                      capital_gain         3537.660156          0.974326   0.175998\n",
      "marital_status. Married-civ-spouse         2718.545898          0.748730   0.135247\n",
      "                               age         1430.795898          0.394063   0.071182\n",
      "                      capital_loss         1200.085938          0.330522   0.059704\n",
      "        occupation. Prof-specialty         1121.998535          0.309016   0.055819\n",
      "                    hours_per_week         1034.862915          0.285017   0.051484\n",
      "       occupation. Exec-managerial          704.487549          0.194027   0.035048\n",
      "     marital_status. Never-married          703.669556          0.193801   0.035007\n",
      "                            fnlwgt          678.404114          0.186843   0.033750\n",
      "---\n",
      "           relationship. Own-child           13.297894          0.003662   0.000662\n",
      "           workclass. Self-emp-inc           12.568443          0.003462   0.000625\n",
      "                       race. Black           11.154298          0.003072   0.000555\n",
      "          occupation. Craft-repair           10.734896          0.002957   0.000534\n",
      "     occupation. Handlers-cleaners            9.651173          0.002658   0.000480\n",
      "                     occupation.NA            8.436129          0.002323   0.000420\n",
      "          race. Asian-Pac-Islander            8.410213          0.002316   0.000418\n",
      "                education. 5th-6th            8.258062          0.002274   0.000411\n",
      "           marital_status. Widowed            8.028831          0.002211   0.000399\n",
      "           relationship. Unmarried            5.502995          0.001516   0.000274\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        43364.589844          1.000000   0.126061\n",
      "                      capital_gain        35620.839844          0.821427   0.103550\n",
      "                    hours_per_week        29526.039063          0.680879   0.085832\n",
      "                      capital_loss        24665.144531          0.568785   0.071701\n",
      "                            fnlwgt        22607.158203          0.521328   0.065719\n",
      "marital_status. Married-civ-spouse        22598.042969          0.521117   0.065692\n",
      "        occupation. Prof-specialty        17967.582031          0.414338   0.052232\n",
      "       occupation. Exec-managerial        15821.666992          0.364852   0.045993\n",
      "              education. Bachelors        13926.910156          0.321159   0.040485\n",
      "             relationship. Husband         9960.637695          0.229695   0.028956\n",
      "---\n",
      "                education. 5th-6th          998.753723          0.023032   0.002903\n",
      "          occupation. Craft-repair          838.162659          0.019328   0.002437\n",
      "             education. Assoc-acdm          651.456665          0.015023   0.001894\n",
      "           relationship. Own-child          628.848450          0.014501   0.001828\n",
      "                       race. Black          527.871704          0.012173   0.001535\n",
      "           workclass. Self-emp-inc          402.419189          0.009280   0.001170\n",
      "      occupation. Transport-moving          312.500000          0.007206   0.000908\n",
      "                     occupation.NA          194.691956          0.004490   0.000566\n",
      "          race. Asian-Pac-Islander          141.774307          0.003269   0.000412\n",
      "           relationship. Unmarried           99.272415          0.002289   0.000289\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          304.000000          1.000000   0.279412\n",
      "                          age          219.000000          0.720395   0.201287\n",
      "               hours_per_week          113.000000          0.371711   0.103860\n",
      "         education. Bachelors           39.000000          0.128289   0.035846\n",
      "           workclass. Private           35.000000          0.115132   0.032169\n",
      "                 capital_loss           30.000000          0.098684   0.027574\n",
      "           education. HS-grad           29.000000          0.095395   0.026654\n",
      "  occupation. Exec-managerial           26.000000          0.085526   0.023897\n",
      "   occupation. Prof-specialty           24.000000          0.078947   0.022059\n",
      "                 capital_gain           24.000000          0.078947   0.022059\n",
      "---\n",
      "  occupation. Protective-serv            3.000000          0.009868   0.002757\n",
      "      relationship. Unmarried            2.000000          0.006579   0.001838\n",
      "      marital_status. Widowed            2.000000          0.006579   0.001838\n",
      "occupation. Handlers-cleaners            2.000000          0.006579   0.001838\n",
      "              education. 10th            2.000000          0.006579   0.001838\n",
      "     race. Asian-Pac-Islander            2.000000          0.006579   0.001838\n",
      " occupation. Transport-moving            2.000000          0.006579   0.001838\n",
      "    marital_status. Separated            1.000000          0.003289   0.000919\n",
      "       native_country. Mexico            1.000000          0.003289   0.000919\n",
      "           education. 5th-6th            1.000000          0.003289   0.000919\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      "\n",
      "10-20 18:27:13.924 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:13.924) \n",
      "10-20 18:27:13.972 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:13.972) \n",
      "10-20 18:27:14.033 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:14.033) \n",
      "10-20 18:27:14.082 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:14.082) \n",
      "10-20 18:27:14.123 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:14.123) \n",
      "10-20 18:27:14.168 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_110\n",
      "10-20 18:27:14.180 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_110\n",
      "10-20 18:27:14.183 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08337315\n",
      " RMSE: 0.2887441\n",
      " AUC: 0.93750274\n",
      " pr_auc: 0.8478958\n",
      " logloss: 0.26743734\n",
      " mean_per_class_error: 0.15673083\n",
      " default threshold: 0.3662959039211273\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22274  2446  0.0989  2,446 / 24,720\n",
      "     1   1682  6159  0.2145   1,682 / 7,841\n",
      "Totals  23956  8605  0.1268  4,128 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.29 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.984432  4.152659         4.152659       1.000000  0.988158                  1.000000          0.988158      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.974379  4.152659         4.152659       1.000000  0.979785                  1.000000          0.983972      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.963424  4.152659         4.152659       1.000000  0.969146                  1.000000          0.979040      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.946584  4.088968         4.136724       0.984663  0.956024                  0.996163          0.973282      0.040939                 0.165540  308.896801       313.672411            0.165338\n",
      "      5                0.05002918         0.921806  4.114444         4.132265       0.990798  0.934602                  0.995089          0.965541      0.041194                 0.206734  311.444445       313.226544            0.206410\n",
      "      6                0.10002764         0.761436  3.741985         3.937185       0.901106  0.840995                  0.948112          0.903287      0.187093                 0.393827  274.198458       293.718492            0.386991\n",
      "      7                0.15002610         0.620145  3.081334         3.651960       0.742015  0.688367                  0.879427          0.831662      0.154062                 0.547889  208.133427       265.195977            0.524062\n",
      "      8                0.20002457         0.497188  2.441090         3.349289       0.587838  0.557735                  0.806541          0.763191      0.122051                 0.669940  144.109015       234.928885            0.618969\n",
      "      9                0.30008292         0.311408  1.628944         2.775664       0.392265  0.393984                  0.668407          0.640084      0.162989                 0.832929   62.894362       177.566437            0.701862\n",
      "     10                0.40001843         0.178972  0.971166         2.324851       0.233866  0.242083                  0.559846          0.540653      0.097054                 0.929983   -2.883418       132.485145            0.698066\n",
      "     11                0.50001536         0.092626  0.431081         1.946121       0.103808  0.131483                  0.468644          0.458824      0.043107                 0.973090  -56.891929        94.612057            0.623131\n",
      "     12                0.60001228         0.045495  0.172177         1.650478       0.041462  0.066314                  0.397451          0.393409      0.017217                 0.990307  -82.782280        65.047847            0.514094\n",
      "     13                0.70000921         0.023727  0.075248         1.425455       0.018120  0.032774                  0.343263          0.341892      0.007525                 0.997832  -92.475218        42.545539            0.392290\n",
      "     14                0.80000614         0.014158  0.010203         1.248556       0.002457  0.018483                  0.300664          0.301467      0.001020                 0.998852  -98.979691        24.855565            0.261919\n",
      "     15                0.90000307         0.008004  0.010203         1.110966       0.002457  0.010693                  0.267531          0.269160      0.001020                 0.999872  -98.979691        11.096561            0.131547\n",
      "     16                1.00000000         0.005466  0.001275         1.000000       0.000307  0.006610                  0.240810          0.242906      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain         3902.679932          1.000000   0.178887\n",
      "             relationship. Husband         3638.499756          0.932308   0.166778\n",
      "marital_status. Married-civ-spouse         2758.206543          0.706747   0.126428\n",
      "                               age         1724.248779          0.441811   0.079034\n",
      "                      capital_loss         1224.251099          0.313695   0.056116\n",
      "                    hours_per_week         1155.280029          0.296022   0.052954\n",
      "        occupation. Prof-specialty         1141.562988          0.292507   0.052326\n",
      "                            fnlwgt          939.442261          0.240717   0.043061\n",
      "     marital_status. Never-married          768.675659          0.196961   0.035234\n",
      "       occupation. Exec-managerial          712.607605          0.182594   0.032664\n",
      "---\n",
      "           workclass. Self-emp-inc           21.417080          0.005488   0.000982\n",
      "     occupation. Machine-op-inspct           19.662182          0.005038   0.000901\n",
      "           relationship. Own-child           19.308220          0.004947   0.000885\n",
      "          occupation. Craft-repair           18.003363          0.004613   0.000825\n",
      "                education. 5th-6th           14.217984          0.003643   0.000652\n",
      "                     occupation.NA           13.112532          0.003360   0.000601\n",
      "                       race. Black           11.154298          0.002858   0.000511\n",
      "          race. Asian-Pac-Islander            8.410213          0.002155   0.000385\n",
      "           marital_status. Widowed            8.028831          0.002057   0.000368\n",
      "           relationship. Unmarried            6.171168          0.001581   0.000283\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        60814.007813          1.000000   0.128822\n",
      "                      capital_gain        55618.187500          0.914562   0.117816\n",
      "                    hours_per_week        36867.523438          0.606234   0.078096\n",
      "                            fnlwgt        34865.210938          0.573309   0.073855\n",
      "                      capital_loss        26953.546875          0.443213   0.057096\n",
      "marital_status. Married-civ-spouse        26409.210938          0.434262   0.055943\n",
      "        occupation. Prof-specialty        18622.388672          0.306219   0.039448\n",
      "       occupation. Exec-managerial        16032.039063          0.263624   0.033961\n",
      "              education. Bachelors        15655.597656          0.257434   0.033163\n",
      "                education. Masters        11447.486328          0.188238   0.024249\n",
      "---\n",
      "                     occupation.NA         1658.941895          0.027279   0.003514\n",
      "      occupation. Transport-moving         1589.141357          0.026131   0.003366\n",
      "              education. Assoc-voc         1570.998535          0.025833   0.003328\n",
      "             education. Assoc-acdm         1500.501221          0.024674   0.003179\n",
      "           marital_status. Widowed         1226.176025          0.020163   0.002597\n",
      "          occupation. Craft-repair         1083.543945          0.017817   0.002295\n",
      "           relationship. Own-child          949.539612          0.015614   0.002011\n",
      "                       race. Black          527.871704          0.008680   0.001118\n",
      "           relationship. Unmarried          240.138031          0.003949   0.000509\n",
      "          race. Asian-Pac-Islander          141.774307          0.002331   0.000300\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          401.000000          1.000000   0.280616\n",
      "                          age          286.000000          0.713217   0.200140\n",
      "               hours_per_week          153.000000          0.381546   0.107068\n",
      "         education. Bachelors           50.000000          0.124688   0.034990\n",
      "           workclass. Private           41.000000          0.102244   0.028691\n",
      "                 capital_gain           41.000000          0.102244   0.028691\n",
      "                 capital_loss           32.000000          0.079800   0.022393\n",
      "   occupation. Prof-specialty           32.000000          0.079800   0.022393\n",
      "           education. HS-grad           30.000000          0.074813   0.020994\n",
      "  occupation. Exec-managerial           28.000000          0.069825   0.019594\n",
      "---\n",
      "  occupation. Protective-serv            4.000000          0.009975   0.002799\n",
      "       native_country. Mexico            3.000000          0.007481   0.002099\n",
      "                  race. Black            3.000000          0.007481   0.002099\n",
      "occupation. Machine-op-inspct            3.000000          0.007481   0.002099\n",
      " occupation. Transport-moving            3.000000          0.007481   0.002099\n",
      "               education. 9th            3.000000          0.007481   0.002099\n",
      "      marital_status. Widowed            2.000000          0.004988   0.001400\n",
      "    marital_status. Separated            2.000000          0.004988   0.001400\n",
      "     race. Asian-Pac-Islander            2.000000          0.004988   0.001400\n",
      "           education. 5th-6th            2.000000          0.004988   0.001400\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      " 2023-10-20 18:27:14 15.353 sec              15       0.28874          0.26744      0.93750         0.84790       4.15266                       0.12678\n",
      "\n",
      "10-20 18:27:14.224 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:14.224) \n",
      "10-20 18:27:14.263 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:14.263) \n",
      "10-20 18:27:14.301 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:14.301) \n",
      "█10-20 18:27:14.340 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:14.340) \n",
      "10-20 18:27:14.382 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:14.382) \n",
      "10-20 18:27:14.427 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_111\n",
      "10-20 18:27:14.442 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_111\n",
      "10-20 18:27:14.446 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08126182\n",
      " RMSE: 0.28506458\n",
      " AUC: 0.94028646\n",
      " pr_auc: 0.8541096\n",
      " logloss: 0.259612\n",
      " mean_per_class_error: 0.15544806\n",
      " default threshold: 0.3760824501514435\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22432  2288  0.0926  2,288 / 24,720\n",
      "     1   1712  6129  0.2183   1,712 / 7,841\n",
      "Totals  24144  8417  0.1228  4,000 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.12 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.991996  4.152659         4.152659       1.000000  0.994399                  1.000000          0.994399      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.986413  4.152659         4.152659       1.000000  0.989444                  1.000000          0.991922      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.978171  4.152659         4.152659       1.000000  0.982452                  1.000000          0.988772      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.965428  4.101706         4.139911       0.987730  0.972318                  0.996930          0.984655      0.041066                 0.165668  310.170623       313.991111            0.165506\n",
      "      5                0.05002918         0.945015  4.088968         4.129716       0.984663  0.955714                  0.994475          0.978863      0.040939                 0.206606  308.896801       312.971623            0.206242\n",
      "      6                0.10002764         0.776900  3.767492         3.948660       0.907248  0.862150                  0.950875          0.920525      0.188369                 0.394975  276.749232       294.865988            0.388503\n",
      "      7                0.15002610         0.632059  3.170611         3.689363       0.763514  0.704481                  0.888434          0.848525      0.158526                 0.553501  217.061134       268.936346            0.531454\n",
      "      8                0.20002457         0.501715  2.433438         3.375430       0.585995  0.566517                  0.812836          0.778034      0.121668                 0.675169  143.343783       237.543026            0.625857\n",
      "      9                0.30002150         0.304250  1.651626         2.800888       0.397727  0.394435                  0.674480          0.650180      0.165158                 0.840326   65.162578       180.088758            0.711686\n",
      "     10                0.40001843         0.167234  0.950163         2.338242       0.228808  0.232958                  0.563071          0.545883      0.095013                 0.935340   -4.983691       133.824198            0.705121\n",
      "     11                0.50001536         0.082131  0.406848         1.951987       0.097973  0.120423                  0.470057          0.460796      0.040684                 0.976023  -59.315164        95.198698            0.626994\n",
      "     12                0.60001228         0.038302  0.145394         1.650904       0.035012  0.057515                  0.397553          0.393586      0.014539                 0.990562  -85.460592        65.090358            0.514430\n",
      "     13                0.70000921         0.018869  0.068871         1.424909       0.016585  0.027139                  0.343132          0.341239      0.006887                 0.997449  -93.112912        42.490882            0.391786\n",
      "     14                0.80000614         0.009607  0.017855         1.249034       0.004300  0.013846                  0.300779          0.300316      0.001785                 0.999235  -98.214459        24.903390            0.262422\n",
      "     15                0.90037161         0.003933  0.006354         1.110511       0.001530  0.006336                  0.267422          0.267546      0.000638                 0.999872  -99.364648        11.051088            0.131062\n",
      "     16                1.00000000         0.001809  0.001280         1.000000       0.000308  0.002747                  0.240810          0.241164      0.000128                 1.000000  -99.871990         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain         3968.308350          1.000000   0.174540\n",
      "             relationship. Husband         3660.406738          0.922410   0.160997\n",
      "marital_status. Married-civ-spouse         2770.174805          0.698074   0.121842\n",
      "                               age         1900.418701          0.478899   0.083587\n",
      "                      capital_loss         1338.609497          0.337325   0.058877\n",
      "                    hours_per_week         1213.616821          0.305827   0.053379\n",
      "        occupation. Prof-specialty         1154.536255          0.290939   0.050781\n",
      "                            fnlwgt         1097.489258          0.276564   0.048271\n",
      "     marital_status. Never-married          783.510559          0.197442   0.034462\n",
      "       occupation. Exec-managerial          722.038147          0.181951   0.031758\n",
      "---\n",
      "          occupation. Craft-repair           18.003363          0.004537   0.000792\n",
      "                       race. Black           16.556890          0.004172   0.000728\n",
      "          race. Asian-Pac-Islander           16.189165          0.004080   0.000712\n",
      "                     occupation.NA           13.112532          0.003304   0.000577\n",
      "           marital_status. Widowed            8.028831          0.002023   0.000353\n",
      "          race. Amer-Indian-Eskimo            6.878814          0.001733   0.000303\n",
      "       native_country. Philippines            6.498859          0.001638   0.000286\n",
      "           relationship. Unmarried            6.171168          0.001555   0.000271\n",
      "              workclass. State-gov            5.623904          0.001417   0.000247\n",
      "                      workclass.NA            4.935256          0.001244   0.000217\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        74873.109375          1.000000   0.126226\n",
      "                      capital_gain        67129.867188          0.896582   0.113172\n",
      "                            fnlwgt        48486.316406          0.647580   0.081742\n",
      "                    hours_per_week        45104.105469          0.602407   0.076040\n",
      "                      capital_loss        42816.554688          0.571855   0.072183\n",
      "marital_status. Married-civ-spouse        26793.185547          0.357848   0.045170\n",
      "        occupation. Prof-specialty        18876.082031          0.252108   0.031823\n",
      "              education. Bachelors        17216.861328          0.229947   0.029025\n",
      "       occupation. Exec-managerial        16483.468750          0.220152   0.027789\n",
      "     marital_status. Never-married        14858.123047          0.198444   0.025049\n",
      "---\n",
      "                     occupation.NA         1658.941895          0.022157   0.002797\n",
      "      occupation. Transport-moving         1589.141357          0.021224   0.002679\n",
      "       native_country. Philippines         1480.071167          0.019768   0.002495\n",
      "           marital_status. Widowed         1226.176025          0.016377   0.002067\n",
      "                      workclass.NA         1192.646973          0.015929   0.002011\n",
      "              workclass. State-gov         1092.328857          0.014589   0.001842\n",
      "          occupation. Craft-repair         1083.543945          0.014472   0.001827\n",
      "                       race. Black          971.720947          0.012978   0.001638\n",
      "          race. Asian-Pac-Islander          468.109009          0.006252   0.000789\n",
      "           relationship. Unmarried          240.138031          0.003207   0.000405\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          456.000000          1.000000   0.267920\n",
      "                         age          368.000000          0.807018   0.216216\n",
      "              hours_per_week          172.000000          0.377193   0.101058\n",
      "        education. Bachelors           53.000000          0.116228   0.031140\n",
      "                capital_gain           49.000000          0.107456   0.028790\n",
      "                capital_loss           43.000000          0.094298   0.025264\n",
      "          workclass. Private           43.000000          0.094298   0.025264\n",
      "  occupation. Prof-specialty           36.000000          0.078947   0.021152\n",
      " occupation. Exec-managerial           33.000000          0.072368   0.019389\n",
      "          education. HS-grad           33.000000          0.072368   0.019389\n",
      "---\n",
      "              education. 9th            4.000000          0.008772   0.002350\n",
      "    race. Asian-Pac-Islander            3.000000          0.006579   0.001763\n",
      "      native_country. Mexico            3.000000          0.006579   0.001763\n",
      "occupation. Transport-moving            3.000000          0.006579   0.001763\n",
      "          education. 5th-6th            3.000000          0.006579   0.001763\n",
      "     marital_status. Widowed            2.000000          0.004386   0.001175\n",
      "        workclass. State-gov            2.000000          0.004386   0.001175\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.004386   0.001175\n",
      "                workclass.NA            1.000000          0.002193   0.000588\n",
      " native_country. Philippines            1.000000          0.002193   0.000588\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      " 2023-10-20 18:27:14 15.353 sec              15       0.28874          0.26744      0.93750         0.84790       4.15266                       0.12678\n",
      " 2023-10-20 18:27:14 15.612 sec              20       0.28506          0.25961      0.94029         0.85411       4.15266                       0.12285\n",
      "\n",
      "10-20 18:27:14.494 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:14.494) \n",
      "10-20 18:27:14.531 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:14.531) \n",
      "10-20 18:27:14.573 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:14.573) \n",
      "10-20 18:27:14.622 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:14.622) \n",
      "10-20 18:27:14.666 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:14.666) \n",
      "10-20 18:27:14.705 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_112\n",
      "10-20 18:27:14.724 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_112\n",
      "10-20 18:27:14.728 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.07925992\n",
      " RMSE: 0.2815314\n",
      " AUC: 0.9431684\n",
      " pr_auc: 0.8603901\n",
      " logloss: 0.25296563\n",
      " mean_per_class_error: 0.14822167\n",
      " default threshold: 0.3590085506439209\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22288  2432  0.0984  2,432 / 24,720\n",
      "     1   1553  6288  0.1981   1,553 / 7,841\n",
      "Totals  23841  8720  0.1224  3,985 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.994648  4.152659         4.152659       1.000000  0.996380                  1.000000          0.996380      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.990778  4.152659         4.152659       1.000000  0.992761                  1.000000          0.994571      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.984876  4.152659         4.152659       1.000000  0.988114                  1.000000          0.992423      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.974659  4.139921         4.149472       0.996933  0.980750                  0.999233          0.989502      0.041449                 0.166050  313.992088       314.947210            0.166010\n",
      "      5                0.05002918         0.956353  4.088968         4.137364       0.984663  0.966254                  0.996317          0.984850      0.040939                 0.206989  308.896801       313.736385            0.206746\n",
      "      6                0.10002764         0.791414  3.803203         3.970335       0.915848  0.875180                  0.956095          0.930032      0.190154                 0.397143  280.320314       297.033480            0.391358\n",
      "      7                0.15002610         0.643641  3.201221         3.714016       0.770885  0.718310                  0.894371          0.859472      0.160056                 0.557199  220.122062       271.401589            0.536326\n",
      "      8                0.20002457         0.509665  2.494656         3.409223       0.600737  0.574213                  0.820973          0.788168      0.124729                 0.681928  149.465639       240.922282            0.634760\n",
      "      9                0.30002150         0.301621  1.647800         2.822142       0.396806  0.396443                  0.679599          0.657607      0.164775                 0.846703   64.779962       182.214185            0.720085\n",
      "     10                0.40001843         0.160395  0.914452         2.345256       0.220209  0.226852                  0.564760          0.549926      0.091442                 0.938146   -8.554774       134.525607            0.708817\n",
      "     11                0.50001536         0.075004  0.406848         1.957598       0.097973  0.113191                  0.471408          0.462585      0.040684                 0.978829  -59.315164        95.759834            0.630690\n",
      "     12                0.60001228         0.033041  0.136466         1.654092       0.032862  0.051555                  0.398321          0.394083      0.013646                 0.992475  -86.353362        65.409188            0.516950\n",
      "     13                0.70000921         0.015212  0.053566         1.425455       0.012899  0.022804                  0.343263          0.341046      0.005356                 0.997832  -94.643376        42.545539            0.392290\n",
      "     14                0.80000614         0.007371  0.014029         1.249034       0.003378  0.010950                  0.300779          0.299785      0.001403                 0.999235  -98.597075        24.903390            0.262422\n",
      "     15                0.90000307         0.002964  0.006377         1.110966       0.001536  0.004861                  0.267531          0.267017      0.000638                 0.999872  -99.362307        11.096561            0.131547\n",
      "     16                1.00000000         0.000755  0.001275         1.000000       0.000307  0.001969                  0.240810          0.240513      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain         4044.156738          1.000000   0.170147\n",
      "             relationship. Husband         3660.406738          0.905110   0.154002\n",
      "marital_status. Married-civ-spouse         2781.881836          0.687877   0.117040\n",
      "                               age         1993.904907          0.493034   0.083888\n",
      "                            fnlwgt         1540.567871          0.380937   0.064815\n",
      "                      capital_loss         1358.015015          0.335797   0.057135\n",
      "                    hours_per_week         1276.944092          0.315750   0.053724\n",
      "        occupation. Prof-specialty         1176.356934          0.290878   0.049492\n",
      "     marital_status. Never-married          783.510559          0.193739   0.032964\n",
      "       occupation. Exec-managerial          750.764465          0.185642   0.031586\n",
      "---\n",
      "                       race. Black           21.950539          0.005428   0.000924\n",
      "                education. 5th-6th           20.128967          0.004977   0.000847\n",
      "                     occupation.NA           13.112532          0.003242   0.000552\n",
      "           relationship. Unmarried           10.557873          0.002611   0.000444\n",
      "              workclass. State-gov            9.078959          0.002245   0.000382\n",
      "                      workclass.NA            8.930552          0.002208   0.000376\n",
      "           marital_status. Widowed            8.028831          0.001985   0.000338\n",
      "          race. Amer-Indian-Eskimo            6.878814          0.001701   0.000289\n",
      "       native_country. Philippines            6.498859          0.001607   0.000273\n",
      "      relationship. Other-relative            3.591786          0.000888   0.000151\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        83945.523438          1.000000   0.119630\n",
      "                               age        81335.289063          0.968906   0.115910\n",
      "                            fnlwgt        81157.023438          0.966782   0.115656\n",
      "                    hours_per_week        49680.929688          0.591823   0.070800\n",
      "                      capital_loss        49577.921875          0.590596   0.070653\n",
      "marital_status. Married-civ-spouse        28783.548828          0.342884   0.041019\n",
      "        occupation. Prof-specialty        20615.863281          0.245586   0.029379\n",
      "       occupation. Exec-managerial        17840.685547          0.212527   0.025425\n",
      "              education. Bachelors        17294.865234          0.206025   0.024647\n",
      "                education. Masters        14965.475586          0.178276   0.021327\n",
      "---\n",
      "      occupation. Transport-moving         1857.797607          0.022131   0.002648\n",
      "             education. Assoc-acdm         1795.252075          0.021386   0.002558\n",
      "                       race. Black         1775.565796          0.021151   0.002530\n",
      "              workclass. State-gov         1751.250854          0.020862   0.002496\n",
      "      relationship. Other-relative         1660.067139          0.019776   0.002366\n",
      "                     occupation.NA         1658.941895          0.019762   0.002364\n",
      "       native_country. Philippines         1480.071167          0.017631   0.002109\n",
      "          race. Asian-Pac-Islander         1470.155029          0.017513   0.002095\n",
      "           marital_status. Widowed         1226.176025          0.014607   0.001747\n",
      "           relationship. Unmarried          391.495697          0.004664   0.000558\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          621.000000          1.000000   0.302043\n",
      "                         age          400.000000          0.644122   0.194553\n",
      "              hours_per_week          200.000000          0.322061   0.097276\n",
      "                capital_gain           63.000000          0.101449   0.030642\n",
      "        education. Bachelors           55.000000          0.088567   0.026751\n",
      "          workclass. Private           49.000000          0.078905   0.023833\n",
      "                capital_loss           47.000000          0.075684   0.022860\n",
      "  occupation. Prof-specialty           44.000000          0.070853   0.021401\n",
      "          education. HS-grad           44.000000          0.070853   0.021401\n",
      " occupation. Exec-managerial           42.000000          0.067633   0.020428\n",
      "---\n",
      "   marital_status. Separated            4.000000          0.006441   0.001946\n",
      "              education. 9th            4.000000          0.006441   0.001946\n",
      "      native_country. Mexico            3.000000          0.004831   0.001459\n",
      "        workclass. State-gov            3.000000          0.004831   0.001459\n",
      "          education. 5th-6th            3.000000          0.004831   0.001459\n",
      "     marital_status. Widowed            2.000000          0.003221   0.000973\n",
      "                workclass.NA            2.000000          0.003221   0.000973\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.003221   0.000973\n",
      "relationship. Other-relative            1.000000          0.001610   0.000486\n",
      " native_country. Philippines            1.000000          0.001610   0.000486\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      " 2023-10-20 18:27:14 15.353 sec              15       0.28874          0.26744      0.93750         0.84790       4.15266                       0.12678\n",
      " 2023-10-20 18:27:14 15.612 sec              20       0.28506          0.25961      0.94029         0.85411       4.15266                       0.12285\n",
      " 2023-10-20 18:27:14 15.896 sec              25       0.28153          0.25297      0.94317         0.86039       4.15266                       0.12239\n",
      "\n",
      "10-20 18:27:14.769 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:14.769) \n",
      "10-20 18:27:14.807 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:14.807) \n",
      "10-20 18:27:14.854 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:14.854) \n",
      "10-20 18:27:14.909 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:14.909) \n",
      "10-20 18:27:14.955 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:14.955) \n",
      "10-20 18:27:15.008 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_113\n",
      "10-20 18:27:15.020 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:15.040 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_113\n",
      "10-20 18:27:15.045 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.07741376\n",
      " RMSE: 0.2782333\n",
      " AUC: 0.94583786\n",
      " pr_auc: 0.86638004\n",
      " logloss: 0.24769533\n",
      " mean_per_class_error: 0.14235029\n",
      " default threshold: 0.35695400834083557\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22304  2416  0.0977  2,416 / 24,720\n",
      "     1   1466  6375  0.1870   1,466 / 7,841\n",
      "Totals  23770  8791  0.1192  3,882 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.995300  4.152659         4.152659       1.000000  0.996938                  1.000000          0.996938      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.992258  4.152659         4.152659       1.000000  0.993897                  1.000000          0.995417      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.987418  4.152659         4.152659       1.000000  0.990084                  1.000000          0.993643      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.976724  4.127183         4.146285       0.993865  0.982472                  0.998465          0.990848      0.041321                 0.165923  312.718266       314.628510            0.165842\n",
      "      5                0.05002918         0.959646  4.088968         4.134815       0.984663  0.968929                  0.995703          0.986462      0.040939                 0.206861  308.896801       313.481465            0.206578\n",
      "      6                0.10002764         0.800946  3.836363         3.985635       0.923833  0.882469                  0.959779          0.934481      0.191812                 0.398674  283.636320       298.563474            0.393374\n",
      "      7                0.15002610         0.649518  3.259888         3.743769       0.785012  0.724497                  0.901535          0.864501      0.162989                 0.561663  225.988841       274.376882            0.542205\n",
      "      8                0.20002457         0.514238  2.479352         3.427713       0.597052  0.580507                  0.825426          0.793513      0.123964                 0.685627  147.935175       242.771308            0.639632\n",
      "      9                0.30002150         0.302043  1.675858         2.843821       0.403563  0.399537                  0.684819          0.662201      0.167581                 0.853207   67.585813       184.382121            0.728652\n",
      "     10                0.40001843         0.159448  0.880017         2.352908       0.211916  0.225581                  0.566603          0.553054      0.087999                 0.941206  -11.998318       135.290780            0.712849\n",
      "     11                0.50001536         0.073296  0.386442         1.959639       0.093059  0.111363                  0.471900          0.464722      0.038643                 0.979850  -61.355783        95.963883            0.632034\n",
      "     12                0.60001228         0.031572  0.124988         1.653879       0.030098  0.049618                  0.398270          0.395541      0.012498                 0.992348  -87.501210        65.387933            0.516782\n",
      "     13                0.70000921         0.014428  0.058668         1.426002       0.014128  0.021776                  0.343395          0.342149      0.005867                 0.998215  -94.133221        42.600196            0.392794\n",
      "     14                0.80000614         0.006500  0.011478         1.249193       0.002764  0.010145                  0.300818          0.300650      0.001148                 0.999362  -98.852152        24.919332            0.262590\n",
      "     15                0.90000307         0.002264  0.003826         1.110824       0.000921  0.004088                  0.267497          0.267699      0.000383                 0.999745  -99.617384        11.082391            0.131379\n",
      "     16                1.00000000         0.000449  0.002551         1.000000       0.000614  0.001387                  0.240810          0.241069      0.000255                 1.000000  -99.744923         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain         4072.185303          1.000000   0.164930\n",
      "             relationship. Husband         3670.103760          0.901261   0.148645\n",
      "marital_status. Married-civ-spouse         2788.777100          0.684836   0.112950\n",
      "                               age         2136.678711          0.524701   0.086539\n",
      "                            fnlwgt         1951.911011          0.479328   0.079056\n",
      "                      capital_loss         1383.567871          0.339761   0.056037\n",
      "                    hours_per_week         1346.691284          0.330705   0.054543\n",
      "        occupation. Prof-specialty         1189.416260          0.292083   0.048173\n",
      "     marital_status. Never-married          785.378296          0.192864   0.031809\n",
      "       occupation. Exec-managerial          760.514954          0.186758   0.030802\n",
      "---\n",
      "                       race. Black           21.950539          0.005390   0.000889\n",
      "                education. 5th-6th           20.128967          0.004943   0.000815\n",
      "       native_country. Philippines           14.346540          0.003523   0.000581\n",
      "                     occupation.NA           13.112532          0.003220   0.000531\n",
      "           relationship. Unmarried           11.928981          0.002929   0.000483\n",
      "              workclass. State-gov           11.846092          0.002909   0.000480\n",
      "           marital_status. Widowed           10.363701          0.002545   0.000420\n",
      "      relationship. Other-relative            8.939981          0.002195   0.000362\n",
      "                      workclass.NA            8.930552          0.002193   0.000362\n",
      "          race. Amer-Indian-Eskimo            6.878814          0.001689   0.000279\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       112531.312500          1.000000   0.139653\n",
      "                               age        96085.062500          0.853852   0.119243\n",
      "                      capital_gain        90544.289063          0.804614   0.112367\n",
      "                      capital_loss        57475.023438          0.510747   0.071327\n",
      "                    hours_per_week        55750.253906          0.495420   0.069187\n",
      "marital_status. Married-civ-spouse        29368.285156          0.260979   0.036446\n",
      "        occupation. Prof-specialty        22489.666016          0.199853   0.027910\n",
      "       occupation. Exec-managerial        19236.416016          0.170943   0.023873\n",
      "              education. Bachelors        19188.464844          0.170517   0.023813\n",
      "                education. Masters        15399.152344          0.136843   0.019111\n",
      "---\n",
      "              workclass. State-gov         2951.250977          0.026226   0.003663\n",
      "          race. Amer-Indian-Eskimo         2628.642578          0.023359   0.003262\n",
      "           marital_status. Widowed         2415.389160          0.021464   0.002998\n",
      "      occupation. Transport-moving         2104.547607          0.018702   0.002612\n",
      "                      workclass.NA         2038.236328          0.018113   0.002529\n",
      "             education. Assoc-acdm         1795.252075          0.015953   0.002228\n",
      "                       race. Black         1775.565796          0.015778   0.002204\n",
      "                     occupation.NA         1658.941895          0.014742   0.002059\n",
      "          race. Asian-Pac-Islander         1470.155029          0.013064   0.001824\n",
      "           relationship. Unmarried          616.790283          0.005481   0.000765\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          767.000000          1.000000   0.317467\n",
      "                         age          462.000000          0.602347   0.191225\n",
      "              hours_per_week          234.000000          0.305085   0.096854\n",
      "                capital_gain           71.000000          0.092568   0.029387\n",
      "          workclass. Private           63.000000          0.082138   0.026076\n",
      "        education. Bachelors           58.000000          0.075619   0.024007\n",
      "                capital_loss           54.000000          0.070404   0.022351\n",
      "          education. HS-grad           53.000000          0.069100   0.021937\n",
      "  occupation. Prof-specialty           50.000000          0.065189   0.020695\n",
      " occupation. Exec-managerial           47.000000          0.061278   0.019454\n",
      "---\n",
      "              education. 9th            5.000000          0.006519   0.002070\n",
      "               occupation.NA            4.000000          0.005215   0.001656\n",
      "        workclass. State-gov            4.000000          0.005215   0.001656\n",
      "     marital_status. Widowed            3.000000          0.003911   0.001242\n",
      "      native_country. Mexico            3.000000          0.003911   0.001242\n",
      " native_country. Philippines            3.000000          0.003911   0.001242\n",
      "          education. 5th-6th            3.000000          0.003911   0.001242\n",
      "relationship. Other-relative            2.000000          0.002608   0.000828\n",
      "                workclass.NA            2.000000          0.002608   0.000828\n",
      "    race. Amer-Indian-Eskimo            2.000000          0.002608   0.000828\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      " 2023-10-20 18:27:14 15.353 sec              15       0.28874          0.26744      0.93750         0.84790       4.15266                       0.12678\n",
      " 2023-10-20 18:27:14 15.612 sec              20       0.28506          0.25961      0.94029         0.85411       4.15266                       0.12285\n",
      " 2023-10-20 18:27:14 15.896 sec              25       0.28153          0.25297      0.94317         0.86039       4.15266                       0.12239\n",
      " 2023-10-20 18:27:14 16.185 sec              30       0.27823          0.24770      0.94584         0.86638       4.15266                       0.11922\n",
      "\n",
      "10-20 18:27:15.096 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:15.096) \n",
      "10-20 18:27:15.141 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:15.141) \n",
      "10-20 18:27:15.183 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:15.183) \n",
      "10-20 18:27:15.218 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:15.218) \n",
      "█10-20 18:27:15.266 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:15.266) \n",
      "10-20 18:27:15.320 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_114\n",
      "10-20 18:27:15.334 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_114\n",
      "10-20 18:27:15.343 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.075604275\n",
      " RMSE: 0.2749623\n",
      " AUC: 0.9483339\n",
      " pr_auc: 0.8723611\n",
      " logloss: 0.242527\n",
      " mean_per_class_error: 0.1452462\n",
      " default threshold: 0.3980419635772705\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22722  1998  0.0808  1,998 / 24,720\n",
      "     1   1644  6197  0.2097   1,644 / 7,841\n",
      "Totals  24366  8195  0.1119  3,642 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.20 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.995656  4.152659         4.152659       1.000000  0.997154                  1.000000          0.997154      0.041576                 0.041576   315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.991819  4.152659         4.152659       1.000000  0.993835                  1.000000          0.995495      0.041576                 0.083153   315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.987060  4.139882         4.148409       0.996923  0.989580                  0.998976          0.993527      0.041321                 0.124474   313.988169       314.840868            0.124433\n",
      "      4                0.04001720         0.977099  4.152659         4.149472       1.000000  0.982893                  0.999233          0.990867      0.041576                 0.166050   315.265910       314.947210            0.166010\n",
      "      5                0.05002918         0.961357  4.101706         4.139913       0.987730  0.970216                  0.996931          0.986734      0.041066                 0.207116   310.170623       313.991306            0.206914\n",
      "      6                0.10002764         0.808434  3.866972         4.003485       0.931204  0.888827                  0.964077          0.937795      0.193343                 0.400459   286.697248       300.348467            0.395726\n",
      "      7                0.15002610         0.657765  3.305802         3.770971       0.796069  0.732440                  0.908086          0.869358      0.165285                 0.565744   230.580233       277.097150            0.547581\n",
      "      8                0.20002457         0.518146  2.520164         3.458318       0.606880  0.587768                  0.832796          0.798971      0.126004                 0.691749   152.016412       245.831767            0.647695\n",
      "      9                0.30002150         0.303340  1.665655         2.860825       0.401106  0.404565                  0.688914          0.667516      0.166560                 0.858309    66.565503       186.082462            0.735372\n",
      "     10                0.40001843         0.157195  0.867263         2.362472       0.208845  0.225052                  0.568906          0.556908      0.086724                 0.945033   -13.273704       136.247247            0.717889\n",
      "     11                0.50001536         0.071091  0.357108         1.961424       0.085995  0.109605                  0.472330          0.467453      0.035710                 0.980742   -64.289172        96.142427            0.633210\n",
      "     12                0.60001228         0.030646  0.126263         1.655580       0.030405  0.048310                  0.398679          0.397599      0.012626                 0.993368   -87.373672        65.557976            0.518125\n",
      "     13                0.70000921         0.013431  0.045914         1.425638       0.011057  0.020729                  0.343307          0.343763      0.004591                 0.997959   -95.408608        42.563758            0.392458\n",
      "     14                0.80000614         0.005713  0.016580         1.249512       0.003993  0.009231                  0.300894          0.301948      0.001658                 0.999617   -98.341997        24.951215            0.262926\n",
      "     15                0.90000307         0.001810  0.003826         1.111107       0.000921  0.003444                  0.267565          0.268782      0.000383                 1.000000   -99.617384        11.110732            0.131715\n",
      "     16                1.00000000         0.000266  0.000000         1.000000       0.000000  0.001006                  0.240810          0.242005      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain         4107.787109          1.000000   0.160538\n",
      "                relationship. Husband         3678.326904          0.895452   0.143754\n",
      "   marital_status. Married-civ-spouse         2801.409180          0.681975   0.109483\n",
      "                                  age         2341.562744          0.570030   0.091511\n",
      "                               fnlwgt         2176.230469          0.529782   0.085050\n",
      "                       hours_per_week         1480.516968          0.360417   0.057861\n",
      "                         capital_loss         1430.125732          0.348150   0.055891\n",
      "           occupation. Prof-specialty         1204.971680          0.293338   0.047092\n",
      "        marital_status. Never-married          786.212036          0.191396   0.030726\n",
      "          occupation. Exec-managerial          777.258545          0.189216   0.030376\n",
      "---\n",
      "                   education. 5th-6th           20.128967          0.004900   0.000787\n",
      "              marital_status. Widowed           15.202587          0.003701   0.000594\n",
      "              relationship. Unmarried           14.818839          0.003607   0.000579\n",
      "          native_country. Philippines           14.346540          0.003493   0.000561\n",
      "                        occupation.NA           13.112532          0.003192   0.000512\n",
      "                 workclass. State-gov           11.846092          0.002884   0.000463\n",
      "         relationship. Other-relative            8.939981          0.002176   0.000349\n",
      "                         workclass.NA            8.930552          0.002174   0.000349\n",
      "             race. Amer-Indian-Eskimo            6.878814          0.001675   0.000269\n",
      "marital_status. Married-spouse-absent            2.449133          0.000596   0.000096\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt       127131.453125          1.000000   0.139396\n",
      "                                  age       118918.554688          0.935398   0.130390\n",
      "                         capital_gain        98960.265625          0.778409   0.108507\n",
      "                         capital_loss        73476.507813          0.577957   0.080565\n",
      "                       hours_per_week        69918.304688          0.549969   0.076663\n",
      "   marital_status. Married-civ-spouse        30778.125000          0.242097   0.033747\n",
      "           occupation. Prof-specialty        23717.376953          0.186558   0.026005\n",
      "          occupation. Exec-managerial        20742.453125          0.163158   0.022743\n",
      "                 education. Bachelors        19489.378906          0.153301   0.021369\n",
      "                   education. Masters        16122.838867          0.126820   0.017678\n",
      "---\n",
      "              marital_status. Widowed         3329.415527          0.026189   0.003651\n",
      "                 workclass. State-gov         2951.250977          0.023214   0.003236\n",
      "             race. Amer-Indian-Eskimo         2628.642578          0.020677   0.002882\n",
      "                education. Assoc-acdm         2428.842773          0.019105   0.002663\n",
      "                          race. Black         2360.789063          0.018570   0.002589\n",
      "                         workclass.NA         2038.236328          0.016033   0.002235\n",
      "                        occupation.NA         1658.941895          0.013049   0.001819\n",
      "             race. Asian-Pac-Islander         1470.155029          0.011564   0.001612\n",
      "marital_status. Married-spouse-absent         1438.591797          0.011316   0.001577\n",
      "              relationship. Unmarried          886.929871          0.006976   0.000972\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          842.000000          1.000000   0.302443\n",
      "                                  age          569.000000          0.675772   0.204382\n",
      "                       hours_per_week          292.000000          0.346793   0.104885\n",
      "                         capital_gain           81.000000          0.096200   0.029095\n",
      "                   workclass. Private           73.000000          0.086698   0.026221\n",
      "                         capital_loss           65.000000          0.077197   0.023348\n",
      "                 education. Bachelors           64.000000          0.076010   0.022989\n",
      "                   education. HS-grad           60.000000          0.071259   0.021552\n",
      "           occupation. Prof-specialty           55.000000          0.065321   0.019756\n",
      "          occupation. Exec-managerial           52.000000          0.061758   0.018678\n",
      "---\n",
      "              marital_status. Widowed            4.000000          0.004751   0.001437\n",
      "                        occupation.NA            4.000000          0.004751   0.001437\n",
      "                 workclass. State-gov            4.000000          0.004751   0.001437\n",
      "               native_country. Mexico            3.000000          0.003563   0.001078\n",
      "          native_country. Philippines            3.000000          0.003563   0.001078\n",
      "                   education. 5th-6th            3.000000          0.003563   0.001078\n",
      "         relationship. Other-relative            2.000000          0.002375   0.000718\n",
      "                         workclass.NA            2.000000          0.002375   0.000718\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.002375   0.000718\n",
      "marital_status. Married-spouse-absent            1.000000          0.001188   0.000359\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      " 2023-10-20 18:27:14 15.353 sec              15       0.28874          0.26744      0.93750         0.84790       4.15266                       0.12678\n",
      " 2023-10-20 18:27:14 15.612 sec              20       0.28506          0.25961      0.94029         0.85411       4.15266                       0.12285\n",
      " 2023-10-20 18:27:14 15.896 sec              25       0.28153          0.25297      0.94317         0.86039       4.15266                       0.12239\n",
      " 2023-10-20 18:27:14 16.185 sec              30       0.27823          0.24770      0.94584         0.86638       4.15266                       0.11922\n",
      " 2023-10-20 18:27:15 16.496 sec              35       0.27496          0.24253      0.94833         0.87236       4.15266                       0.11185\n",
      "\n",
      "10-20 18:27:15.396 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:15.396) \n",
      "10-20 18:27:15.473 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:15.473) \n",
      "10-20 18:27:15.558 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:15.558) \n",
      "10-20 18:27:15.602 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:15.601) \n",
      "10-20 18:27:15.642 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:15.642) \n",
      "10-20 18:27:15.726 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_115\n",
      "10-20 18:27:15.739 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_115\n",
      "10-20 18:27:15.747 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.074277915\n",
      " RMSE: 0.27253973\n",
      " AUC: 0.9503035\n",
      " pr_auc: 0.87678504\n",
      " logloss: 0.23847969\n",
      " mean_per_class_error: 0.14519383\n",
      " default threshold: 0.4063836932182312\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22857  1863  0.0754  1,863 / 24,720\n",
      "     1   1686  6155  0.2150   1,686 / 7,841\n",
      "Totals  24543  8018  0.1090  3,549 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.09 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.995965  4.152659         4.152659       1.000000  0.997395                  1.000000          0.997395      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.992377  4.152659         4.152659       1.000000  0.994259                  1.000000          0.995827      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.987991  4.152659         4.152659       1.000000  0.990411                  1.000000          0.994025      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.979793  4.139921         4.149472       0.996933  0.984565                  0.999233          0.991658      0.041449                 0.166050  313.992088       314.947210            0.166010\n",
      "      5                0.05002918         0.965167  4.139921         4.147561       0.996933  0.973321                  0.998772          0.987989      0.041449                 0.207499  313.992088       314.756068            0.207418\n",
      "      6                0.10002764         0.812135  3.902683         4.025160       0.939803  0.893271                  0.969297          0.940644      0.195128                 0.402627  290.268331       302.515959            0.398582\n",
      "      7                0.15002610         0.657468  3.305802         3.785423       0.796069  0.732372                  0.911566          0.871234      0.165285                 0.567912  230.580233       278.542292            0.550437\n",
      "      8                0.20002457         0.515392  2.558426         3.478721       0.616093  0.587132                  0.837709          0.800220      0.127917                 0.695830  155.842572       247.872072            0.653071\n",
      "      9                0.30002150         0.299579  1.687337         2.881654       0.406327  0.400682                  0.693930          0.667054      0.168728                 0.864558   68.733661       188.165381            0.743603\n",
      "     10                0.40001843         0.154511  0.835378         2.370124       0.201167  0.221053                  0.570749          0.555563      0.083535                 0.948093  -16.462171       137.012420            0.721920\n",
      "     11                0.50001536         0.069963  0.344354         1.964995       0.082924  0.107191                  0.473190          0.465894      0.034434                 0.982528  -65.564559        96.499513            0.635562\n",
      "     12                0.60001228         0.029439  0.108408         1.655580       0.026106  0.047042                  0.398679          0.396089      0.010840                 0.993368  -89.159213        65.557976            0.518125\n",
      "     13                0.70000921         0.012826  0.051015         1.426366       0.012285  0.019841                  0.343483          0.342341      0.005101                 0.998470  -94.898453        42.636634            0.393130\n",
      "     14                0.80000614         0.005287  0.012754         1.249672       0.003071  0.008618                  0.300933          0.300628      0.001275                 0.999745  -98.724613        24.967157            0.263094\n",
      "     15                0.90000307         0.001675  0.001275         1.110966       0.000307  0.003183                  0.267531          0.267579      0.000128                 0.999872  -99.872461        11.096561            0.131547\n",
      "     16                1.00000000         0.000190  0.001275         1.000000       0.000307  0.000944                  0.240810          0.240917      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain         4127.314941          1.000000   0.156588\n",
      "                relationship. Husband         3680.835938          0.891823   0.139649\n",
      "   marital_status. Married-civ-spouse         2803.432617          0.679239   0.106361\n",
      "                               fnlwgt         2534.039063          0.613968   0.096140\n",
      "                                  age         2517.913574          0.610061   0.095528\n",
      "                       hours_per_week         1521.849976          0.368726   0.057738\n",
      "                         capital_loss         1443.492188          0.349741   0.054765\n",
      "           occupation. Prof-specialty         1210.267334          0.293234   0.045917\n",
      "          occupation. Exec-managerial          788.203308          0.190972   0.029904\n",
      "        marital_status. Never-married          786.857971          0.190646   0.029853\n",
      "---\n",
      "          native_country. Philippines           17.828444          0.004320   0.000676\n",
      "              marital_status. Widowed           15.202587          0.003683   0.000577\n",
      "              relationship. Unmarried           14.818839          0.003590   0.000562\n",
      "                        occupation.NA           13.112532          0.003177   0.000497\n",
      "                 workclass. State-gov           11.846092          0.002870   0.000449\n",
      "                         workclass.NA           11.664589          0.002826   0.000443\n",
      "         relationship. Other-relative           11.263262          0.002729   0.000427\n",
      "             race. Amer-Indian-Eskimo            6.878814          0.001667   0.000261\n",
      "                    native_country.NA            4.161695          0.001008   0.000158\n",
      "marital_status. Married-spouse-absent            2.449133          0.000593   0.000093\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt       164543.734375          1.000000   0.161812\n",
      "                                  age       133855.171875          0.813493   0.131633\n",
      "                         capital_gain       106254.796875          0.645754   0.104491\n",
      "                         capital_loss        78956.859375          0.479853   0.077646\n",
      "                       hours_per_week        73430.625000          0.446268   0.072211\n",
      "   marital_status. Married-civ-spouse        32191.931641          0.195644   0.031657\n",
      "           occupation. Prof-specialty        24040.958984          0.146107   0.023642\n",
      "          occupation. Exec-managerial        22262.171875          0.135296   0.021893\n",
      "                 education. Bachelors        20192.800781          0.122720   0.019858\n",
      "                   education. Masters        17698.607422          0.107562   0.017405\n",
      "---\n",
      "              marital_status. Widowed         3329.415527          0.020234   0.003274\n",
      "             race. Asian-Pac-Islander         3302.673340          0.020072   0.003248\n",
      "                 workclass. State-gov         2951.250977          0.017936   0.002902\n",
      "                          race. Black         2728.580078          0.016583   0.002683\n",
      "                    native_country.NA         2687.838623          0.016335   0.002643\n",
      "             race. Amer-Indian-Eskimo         2628.642578          0.015975   0.002585\n",
      "                         workclass.NA         2132.007813          0.012957   0.002097\n",
      "                        occupation.NA         1658.941895          0.010082   0.001631\n",
      "marital_status. Married-spouse-absent         1438.591797          0.008743   0.001415\n",
      "              relationship. Unmarried          886.929871          0.005390   0.000872\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          985.000000          1.000000   0.314998\n",
      "                                  age          663.000000          0.673096   0.212024\n",
      "                       hours_per_week          310.000000          0.314721   0.099137\n",
      "                         capital_gain           88.000000          0.089340   0.028142\n",
      "                   workclass. Private           77.000000          0.078173   0.024624\n",
      "                 education. Bachelors           71.000000          0.072081   0.022705\n",
      "                         capital_loss           70.000000          0.071066   0.022386\n",
      "                   education. HS-grad           66.000000          0.067005   0.021106\n",
      "          occupation. Exec-managerial           59.000000          0.059898   0.018868\n",
      "           occupation. Prof-specialty           59.000000          0.059898   0.018868\n",
      "---\n",
      "                        occupation.NA            4.000000          0.004061   0.001279\n",
      "                 workclass. State-gov            4.000000          0.004061   0.001279\n",
      "          native_country. Philippines            4.000000          0.004061   0.001279\n",
      "         relationship. Other-relative            3.000000          0.003046   0.000959\n",
      "                         workclass.NA            3.000000          0.003046   0.000959\n",
      "               native_country. Mexico            3.000000          0.003046   0.000959\n",
      "                   education. 5th-6th            3.000000          0.003046   0.000959\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.002030   0.000640\n",
      "                    native_country.NA            2.000000          0.002030   0.000640\n",
      "marital_status. Married-spouse-absent            1.000000          0.001015   0.000320\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight            10.0\n",
      "           nthread               4\n",
      "              seed              42\n",
      "         max_depth              15\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              40\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:13 14.385 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:13 14.785 sec               5       0.31626          0.34334      0.92525         0.82029       4.15266                       0.14299\n",
      " 2023-10-20 18:27:13 15.047 sec              10       0.29498          0.28519      0.93308         0.83897       4.15266                       0.13092\n",
      " 2023-10-20 18:27:14 15.353 sec              15       0.28874          0.26744      0.93750         0.84790       4.15266                       0.12678\n",
      " 2023-10-20 18:27:14 15.612 sec              20       0.28506          0.25961      0.94029         0.85411       4.15266                       0.12285\n",
      " 2023-10-20 18:27:14 15.896 sec              25       0.28153          0.25297      0.94317         0.86039       4.15266                       0.12239\n",
      " 2023-10-20 18:27:14 16.185 sec              30       0.27823          0.24770      0.94584         0.86638       4.15266                       0.11922\n",
      " 2023-10-20 18:27:15 16.496 sec              35       0.27496          0.24253      0.94833         0.87236       4.15266                       0.11185\n",
      " 2023-10-20 18:27:15 16.872 sec              40       0.27254          0.23848      0.95030         0.87679       4.15266                       0.10900\n",
      "\n",
      "10-20 18:27:15.749 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: In-training scoring took 610ms.\n",
      "10-20 18:27:15.757 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model XGBoost_1_AutoML_1_20231020_182658\n",
      "10-20 18:27:15.758 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Computing 5-fold cross-validation metrics.\n",
      "10-20 18:27:15.931 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_116\n",
      "10-20 18:27:15.967 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_116\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Model Metrics Type: Binomial\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  Description: 5-fold cross-validation on training data (Metrics computed for combined holdout predictions)\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  model id: XGBoost_1_AutoML_1_20231020_182658\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  MSE: 0.09356348\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  RMSE: 0.30588147\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  AUC: 0.9205609\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  pr_auc: 0.81126606\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  logloss: 0.2937456\n",
      "10-20 18:27:15.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  mean_per_class_error: 0.1770299\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  default threshold: 0.36473730206489563\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:             0     1   Error            Rate\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      0  21964  2756  0.1115  2,756 / 24,720\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      1   1902  5939  0.2426   1,902 / 7,841\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Totals  23866  8695  0.1431  4,658 / 32,561\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.08 %):\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:   Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       1                0.01001198         0.995684  4.152659         4.152659       1.000000  0.996986                  1.000000          0.996986      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       2                0.02002396         0.992932  4.152659         4.152659       1.000000  0.994359                  1.000000          0.995672      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       3                0.03000522         0.988877  4.139882         4.148409       0.996923  0.991050                  0.998976          0.994135      0.041321                 0.124474  313.988169       314.840868            0.124433\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       4                0.04001720         0.981711  4.076230         4.130350       0.981595  0.985646                  0.994628          0.992011      0.040811                 0.165285  307.622979       313.035011            0.165002\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       5                0.05002918         0.967067  4.127183         4.129716       0.993865  0.975096                  0.994475          0.988626      0.041321                 0.206606  312.718266       312.971623            0.206242\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       6                0.10002764         0.810716  3.492009         3.810960       0.840909  0.891131                  0.917716          0.939893      0.174595                 0.381201  249.200879       281.096041            0.370360\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       7                0.15002610         0.655846  2.790546         3.470892       0.671990  0.733799                  0.835824          0.871209      0.139523                 0.520724  179.054610       247.089194            0.488281\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       8                0.20002457         0.517814  2.323755         3.184152       0.559582  0.585117                  0.766774          0.799697      0.116184                 0.636909  132.375457       218.415163            0.575460\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       9                0.30002150         0.297870  1.654177         2.674212       0.398342  0.401954                  0.643976          0.667130      0.165413                 0.802321   65.417655       167.421214            0.661625\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      10                0.40001843         0.151258  1.019034         2.260449       0.245393  0.219149                  0.544338          0.555143      0.101900                 0.904221    1.903397       126.044937            0.664132\n",
      "10-20 18:27:15.972 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      11                0.50001536         0.069953  0.553518         1.919084       0.133292  0.106341                  0.462134          0.465388      0.055350                 0.959571  -44.648217        91.908403            0.605324\n",
      "10-20 18:27:15.973 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      12                0.60001228         0.029931  0.257628         1.642189       0.062039  0.047423                  0.395455          0.395731      0.025762                 0.985334  -74.237189        64.218888            0.507542\n",
      "10-20 18:27:15.973 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      13                0.70000921         0.013031  0.089277         1.420354       0.021499  0.020242                  0.342035          0.342092      0.008927                 0.994261  -91.072293        42.035407            0.387586\n",
      "10-20 18:27:15.973 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      14                0.80000614         0.005671  0.042088         1.248077       0.010135  0.008934                  0.300549          0.300449      0.004209                 0.998470  -95.791224        24.807740            0.261415\n",
      "10-20 18:27:15.973 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      15                0.90000307         0.001936  0.012754         1.110824       0.003071  0.003562                  0.267497          0.267463      0.001275                 0.999745  -98.724613        11.082391            0.131379\n",
      "10-20 18:27:15.973 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      16                1.00000000         0.000185  0.002551         1.000000       0.000614  0.001068                  0.240810          0.240824      0.000255                 1.000000  -99.744923         0.000000            0.000000\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Cross-Validation Metrics Summary:\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                                mean         sd  cv_1_valid  cv_2_valid  cv_3_valid  cv_4_valid  cv_5_valid\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                accuracy    0.858327   0.003966    0.862122    0.860412    0.852733    0.855651    0.860719\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     auc    0.920614   0.004051    0.926302    0.922422    0.915376    0.919349    0.919623\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     err    0.141673   0.003966    0.137878    0.139588    0.147267    0.144349    0.139281\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:               err_count  922.599976  25.793409  898.000000  909.000000  959.000000  940.000000  907.000000\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                f0point5    0.700102   0.013848    0.717919    0.696682    0.682822    0.693322    0.709766\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                      f1    0.718845   0.011259    0.734477    0.718314    0.704650    0.712889    0.723897\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                      f2    0.738653   0.008962    0.751816    0.741333    0.727921    0.733593    0.738601\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:          lift_top_group    4.154737   0.103193    4.005535    4.256209    4.236825    4.174359    4.100756\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                 logloss    0.293746   0.006092    0.287921    0.286452    0.299728    0.297483    0.297144\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:     max_per_class_error    0.247504   0.007977    0.236162    0.242484    0.255693    0.251923    0.251259\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     mcc    0.625546   0.012966    0.642413    0.627344    0.608465    0.617983    0.631524\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: mean_per_class_accuracy    0.822192   0.005415    0.829330    0.824764    0.815269    0.818808    0.822786\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:    mean_per_class_error    0.177808   0.005415    0.170670    0.175236    0.184731    0.181192    0.177214\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     mse    0.093564   0.001777    0.092078    0.091288    0.095046    0.095176    0.094229\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                  pr_auc    0.811563   0.010374    0.827898    0.813013    0.800664    0.805033    0.811208\n",
      "10-20 18:27:15.991 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:               precision    0.688155   0.015564    0.707289    0.682970    0.669006    0.680863    0.700648\n",
      "10-20 18:27:15.992 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                      r2    0.488002   0.013914    0.508464    0.492135    0.472895    0.477542    0.488972\n",
      "10-20 18:27:15.992 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                  recall    0.752496   0.007977    0.763838    0.757516    0.744307    0.748077    0.748741\n",
      "10-20 18:27:15.992 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                    rmse    0.305871   0.002909    0.303444    0.302139    0.308296    0.308506    0.306967\n",
      "10-20 18:27:15.992 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:             specificity    0.891887   0.004201    0.894823    0.892011    0.886231    0.889540    0.896832\n",
      "10-20 18:27:15.995 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: 5 CV models were removed\n",
      "10-20 18:27:16.048 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: New leader: XGBoost_1_AutoML_1_20231020_182658, auc: 0.9205608851530974\n",
      "10-20 18:27:16.049 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML step returned with state: StepResultState{_id='XGBoost:def_2', _status=success}\n",
      "10-20 18:27:16.050 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML step returned with state: StepResultState{_id='GLM:def_1', _status=skipped}\n",
      "10-20 18:27:16.056 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: AutoML: starting GBM_1_AutoML_1_20231020_182658 model training\n",
      "10-20 18:27:16.058 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Creating 5 cross-validation splits with random number seed: 43\n",
      "10-20 18:27:16.095 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 1 / 5.\n",
      "10-20 18:27:16.099 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 2 / 5.\n",
      "10-20 18:27:16.099 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 3 / 5.\n",
      "10-20 18:27:16.100 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 4 / 5.\n",
      "10-20 18:27:16.100 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:16.100 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:16.100 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:16.101 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:16.115 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: {\"_train\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_4_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_4_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":43,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":3,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":15,\"_min_rows\":100.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:16.115 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_1_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_1_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":43,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":0,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":15,\"_min_rows\":100.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:16.116 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: {\"_train\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_3_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_3_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":43,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":2,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":15,\"_min_rows\":100.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:16.117 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:16.119 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: {\"_train\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_2_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_2_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":43,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":15,\"_min_rows\":100.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:16.119 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:16.119 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:16.134 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:16.134 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:16.139 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:16.144 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:16.158 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "█10-20 18:27:16.193 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Starting model GBM_1_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:16.201 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model GBM_1_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:16.204 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model GBM_1_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:16.210 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Prior class distribution: [0.7579945487350762, 0.2420054512649238]\n",
      "10-20 18:27:16.219 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Prior class distribution: [0.761402027027027, 0.23859797297297297]\n",
      "10-20 18:27:16.219 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Model class distribution: [0.7579945487350762, 0.2420054512649238]\n",
      "10-20 18:27:16.214 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model GBM_1_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:16.223 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Prior class distribution: [0.7577258244078467, 0.24227417559215325]\n",
      "10-20 18:27:16.223 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Model class distribution: [0.7577258244078467, 0.24227417559215325]\n",
      "10-20 18:27:16.219 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model class distribution: [0.761402027027027, 0.23859797297297297]\n",
      "10-20 18:27:16.210 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Prior class distribution: [0.758877500095973, 0.24112249990402704]\n",
      "10-20 18:27:16.224 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Model class distribution: [0.758877500095973, 0.24112249990402704]\n",
      "10-20 18:27:16.309 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:16.314 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:16.319 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:16.319 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:16.431 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_118\n",
      "10-20 18:27:16.431 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_119\n",
      "10-20 18:27:16.439 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_120\n",
      "10-20 18:27:16.445 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_121\n",
      "10-20 18:27:16.456 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_120\n",
      "10-20 18:27:16.460 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_121\n",
      "10-20 18:27:16.465 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_119\n",
      "10-20 18:27:16.478 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_118\n",
      "10-20 18:27:16.495 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_122\n",
      "10-20 18:27:16.496 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_124\n",
      "10-20 18:27:16.511 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_122\n",
      "10-20 18:27:16.517 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.1835774\n",
      " RMSE: 0.42845935\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24227418\n",
      " logloss: 0.55368716\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.2422741800546646\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19738  1.0000  19,738 / 19,738\n",
      "     1  0   6311  0.0000        0 / 6,311\n",
      "Totals  0  26049  0.7577  19,738 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242274  1.000000         1.000000       0.242274  0.242274                  0.242274          0.242274      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.17980258\n",
      " RMSE: 0.42403135\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23495086\n",
      " logloss: 0.5453368\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.2422741800546646\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4982  1.0000  4,982 / 4,982\n",
      "     1  0  1530  0.0000      0 / 1,530\n",
      "Totals  0  6512  0.7650  4,982 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242274  1.000000         1.000000       0.234951  0.242274                  0.234951          0.242274      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.157 sec               0       0.42846          0.55369      0.50000         0.24227       1.00000                       0.75773         0.42403            0.54534        0.50000           0.23495         1.00000                         0.76505\n",
      "\n",
      "10-20 18:27:16.518 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_125\n",
      "10-20 18:27:16.521 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_125\n",
      "10-20 18:27:16.528 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_124\n",
      "10-20 18:27:16.529 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.18343881\n",
      " RMSE: 0.42829758\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24200545\n",
      " logloss: 0.55338055\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24200545251369476\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19745  1.0000  19,745 / 19,745\n",
      "     1  0   6304  0.0000        0 / 6,304\n",
      "Totals  0  26049  0.7580  19,745 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.20 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242005  1.000000         1.000000       0.242005  0.242005                  0.242005          0.242005      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.18035337\n",
      " RMSE: 0.42468032\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2360258\n",
      " logloss: 0.5465535\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24200545251369476\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4975  1.0000  4,975 / 4,975\n",
      "     1  0  1537  0.0000      0 / 1,537\n",
      "Totals  0  6512  0.7640  4,975 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.20 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242005  1.000000         1.000000       0.236026  0.242005                  0.236026          0.242005      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.144 sec               0       0.42830          0.55338      0.50000         0.24201       1.00000                       0.75799         0.42468            0.54655        0.50000           0.23603         1.00000                         0.76397\n",
      "\n",
      "10-20 18:27:16.547 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_123\n",
      "10-20 18:27:16.549 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.18166898\n",
      " RMSE: 0.42622644\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23859797\n",
      " logloss: 0.54945844\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.23859797418117523\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19833  1.0000  19,833 / 19,833\n",
      "     1  0   6215  0.0000        0 / 6,215\n",
      "Totals  0  26048  0.7614  19,833 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.86 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.238598  1.000000         1.000000       0.238598  0.238598                  0.238598          0.238598      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.1874494\n",
      " RMSE: 0.43295425\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24965453\n",
      " logloss: 0.5622883\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.23859797418117523\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4887  1.0000  4,887 / 4,887\n",
      "     1  0  1626  0.0000      0 / 1,626\n",
      "Totals  0  6513  0.7503  4,887 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.86 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.238598  1.000000         1.000000       0.249655  0.238598                  0.249655          0.238598      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.147 sec               0       0.42623          0.54946      0.50000         0.23860       1.00000                       0.76140         0.43295            0.56229        0.50000           0.24965         1.00000                         0.75035\n",
      "\n",
      "10-20 18:27:16.556 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_123\n",
      "10-20 18:27:16.562 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.18298244\n",
      " RMSE: 0.42776448\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2411225\n",
      " logloss: 0.55237037\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24112249910831451\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19768  1.0000  19,768 / 19,768\n",
      "     1  0   6281  0.0000        0 / 6,281\n",
      "Totals  0  26049  0.7589  19,768 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.241122  1.000000         1.000000       0.241122  0.241122                  0.241122          0.241122      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.18217228\n",
      " RMSE: 0.42681643\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23955774\n",
      " logloss: 0.5505763\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24112249910831451\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4952  1.0000  4,952 / 4,952\n",
      "     1  0  1560  0.0000      0 / 1,560\n",
      "Totals  0  6512  0.7604  4,952 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.241122  1.000000         1.000000       0.239558  0.241122                  0.239558          0.241122      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.135 sec               0       0.42776          0.55237      0.50000         0.24112       1.00000                       0.75888         0.42682            0.55058        0.50000           0.23956         1.00000                         0.76044\n",
      "\n",
      "10-20 18:27:16.770 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "\n",
      "18:27:15.997: XGBoost_1_AutoML_1_20231020_182658 [XGBoost def_2] complete\n",
      "18:27:15.998: Adding model XGBoost_1_AutoML_1_20231020_182658 to leaderboard Leaderboard_AutoML_1_20231020_182658@@label. Training time: model=3s, total=17s\n",
      "18:27:16.48: New leader: XGBoost_1_AutoML_1_20231020_182658, auc: 0.9205608851530974\n",
      "18:27:16.55: No time limitation for GBM_1_AutoML_1_20231020_182658\n",
      "18:27:16.56: AutoML: starting GBM_1_AutoML_1_20231020_182658 model training\n",
      "18:27:16.68: GBM_1_AutoML_1_20231020_182658 [GBM def_5] started\n",
      "\n",
      "█10-20 18:27:17.134 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.585 (Wall: 20-Oct 18:27:17.134) \n",
      "10-20 18:27:17.134 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.605 (Wall: 20-Oct 18:27:17.134) \n",
      "10-20 18:27:17.135 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.617 (Wall: 20-Oct 18:27:17.135) \n",
      "10-20 18:27:17.152 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.590 (Wall: 20-Oct 18:27:17.152) \n",
      "10-20 18:27:17.477 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.325 (Wall: 20-Oct 18:27:17.477) \n",
      "10-20 18:27:17.477 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.341 (Wall: 20-Oct 18:27:17.477) \n",
      "10-20 18:27:17.503 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.368 (Wall: 20-Oct 18:27:17.502) \n",
      "10-20 18:27:17.519 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.385 (Wall: 20-Oct 18:27:17.519) \n",
      "10-20 18:27:17.803 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.326 (Wall: 20-Oct 18:27:17.803) \n",
      "10-20 18:27:17.816 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.339 (Wall: 20-Oct 18:27:17.816) \n",
      "10-20 18:27:17.849 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.328 (Wall: 20-Oct 18:27:17.848) \n",
      "10-20 18:27:17.889 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.386 (Wall: 20-Oct 18:27:17.889) \n",
      "10-20 18:27:17.943 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:18.073 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.257 (Wall: 20-Oct 18:27:18.073) \n",
      "10-20 18:27:18.077 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.274 (Wall: 20-Oct 18:27:18.077) \n",
      "10-20 18:27:18.091 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.242 (Wall: 20-Oct 18:27:18.091) \n",
      "10-20 18:27:18.154 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.265 (Wall: 20-Oct 18:27:18.154) \n",
      "10-20 18:27:18.376 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.284 (Wall: 20-Oct 18:27:18.376) \n",
      "10-20 18:27:18.383 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.304 (Wall: 20-Oct 18:27:18.382) \n",
      "10-20 18:27:18.383 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:18.385 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:18.398 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.325 (Wall: 20-Oct 18:27:18.398) \n",
      "10-20 18:27:18.405 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:18.444 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_126\n",
      "10-20 18:27:18.453 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_127\n",
      "10-20 18:27:18.454 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_128\n",
      "10-20 18:27:18.473 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.319 (Wall: 20-Oct 18:27:18.473) \n",
      "10-20 18:27:18.473 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:18.494 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_127\n",
      "10-20 18:27:18.498 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_126\n",
      "10-20 18:27:18.507 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_128\n",
      "10-20 18:27:18.532 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_129\n",
      "10-20 18:27:18.544 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_129\n",
      "10-20 18:27:18.703 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_130\n",
      "10-20 18:27:18.713 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_132\n",
      "10-20 18:27:18.714 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_131\n",
      "10-20 18:27:18.718 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_130\n",
      "10-20 18:27:18.724 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_133\n",
      "10-20 18:27:18.752 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_132\n",
      "10-20 18:27:18.756 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_133\n",
      "10-20 18:27:18.761 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_131\n",
      "10-20 18:27:18.925 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.165 (Wall: 20-Oct 18:27:18.925) \n",
      "10-20 18:27:18.945 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.223 (Wall: 20-Oct 18:27:18.945) \n",
      "10-20 18:27:18.957 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.199 (Wall: 20-Oct 18:27:18.957) \n",
      "10-20 18:27:18.957 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:18.979 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.193 (Wall: 20-Oct 18:27:18.979) \n",
      "10-20 18:27:19.121 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.164 (Wall: 20-Oct 18:27:19.121) \n",
      "10-20 18:27:19.133 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.188 (Wall: 20-Oct 18:27:19.133) \n",
      "10-20 18:27:19.145 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.220 (Wall: 20-Oct 18:27:19.145) \n",
      "10-20 18:27:19.176 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.196 (Wall: 20-Oct 18:27:19.176) \n",
      "10-20 18:27:19.366 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.244 (Wall: 20-Oct 18:27:19.366) \n",
      "10-20 18:27:19.368 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.192 (Wall: 20-Oct 18:27:19.368) \n",
      "10-20 18:27:19.371 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.238 (Wall: 20-Oct 18:27:19.371) \n",
      "10-20 18:27:19.397 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.251 (Wall: 20-Oct 18:27:19.396) \n",
      "10-20 18:27:19.568 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.202 (Wall: 20-Oct 18:27:19.568) \n",
      "10-20 18:27:19.571 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.203 (Wall: 20-Oct 18:27:19.571) \n",
      "10-20 18:27:19.571 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.174 (Wall: 20-Oct 18:27:19.571) \n",
      "10-20 18:27:19.594 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.223 (Wall: 20-Oct 18:27:19.594) \n",
      "10-20 18:27:19.712 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.141 (Wall: 20-Oct 18:27:19.712) \n",
      "10-20 18:27:19.714 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:19.714 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.142 (Wall: 20-Oct 18:27:19.714) \n",
      "10-20 18:27:19.715 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:19.775 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.207 (Wall: 20-Oct 18:27:19.775) \n",
      "10-20 18:27:19.776 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:19.781 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_134\n",
      "10-20 18:27:19.784 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.190 (Wall: 20-Oct 18:27:19.784) \n",
      "10-20 18:27:19.788 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:19.788 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_135\n",
      "10-20 18:27:19.828 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_135\n",
      "10-20 18:27:19.821 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_136\n",
      "10-20 18:27:19.829 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_134\n",
      "10-20 18:27:19.826 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_137\n",
      "10-20 18:27:19.858 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_136\n",
      "█10-20 18:27:19.883 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_137\n",
      "10-20 18:27:19.898 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_138\n",
      "10-20 18:27:19.904 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_139\n",
      "10-20 18:27:19.913 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_138\n",
      "10-20 18:27:19.926 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_139\n",
      "10-20 18:27:19.954 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_141\n",
      "10-20 18:27:19.954 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_140\n",
      "10-20 18:27:19.972 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_140\n",
      "10-20 18:27:19.992 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_141\n",
      "10-20 18:27:20.095 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.164 (Wall: 20-Oct 18:27:20.095) \n",
      "10-20 18:27:20.122 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.142 (Wall: 20-Oct 18:27:20.122) \n",
      "10-20 18:27:20.135 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.218 (Wall: 20-Oct 18:27:20.135) \n",
      "10-20 18:27:20.189 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.185 (Wall: 20-Oct 18:27:20.189) \n",
      "10-20 18:27:20.246 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.151 (Wall: 20-Oct 18:27:20.246) \n",
      "10-20 18:27:20.291 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.169 (Wall: 20-Oct 18:27:20.291) \n",
      "10-20 18:27:20.295 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.160 (Wall: 20-Oct 18:27:20.295) \n",
      "10-20 18:27:20.352 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.162 (Wall: 20-Oct 18:27:20.352) \n",
      "10-20 18:27:20.382 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.091 (Wall: 20-Oct 18:27:20.382) \n",
      "10-20 18:27:20.412 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:20.412) \n",
      "10-20 18:27:20.426 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.180 (Wall: 20-Oct 18:27:20.426) \n",
      "10-20 18:27:20.503 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.120 (Wall: 20-Oct 18:27:20.503) \n",
      "10-20 18:27:20.504 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.151 (Wall: 20-Oct 18:27:20.504) \n",
      "10-20 18:27:20.587 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.161 (Wall: 20-Oct 18:27:20.587) \n",
      "10-20 18:27:20.599 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.187 (Wall: 20-Oct 18:27:20.599) \n",
      "10-20 18:27:20.679 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.175 (Wall: 20-Oct 18:27:20.679) \n",
      "10-20 18:27:20.711 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.124 (Wall: 20-Oct 18:27:20.711) \n",
      "10-20 18:27:20.712 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.209 (Wall: 20-Oct 18:27:20.712) \n",
      "10-20 18:27:20.713 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:20.714 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:20.739 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_142\n",
      "10-20 18:27:20.742 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.142 (Wall: 20-Oct 18:27:20.742) \n",
      "10-20 18:27:20.742 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:20.750 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_143\n",
      "10-20 18:27:20.765 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_144\n",
      "10-20 18:27:20.780 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_142\n",
      "10-20 18:27:20.793 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_143\n",
      "10-20 18:27:20.807 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:20.813 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_144\n",
      "10-20 18:27:20.815 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.136 (Wall: 20-Oct 18:27:20.815) \n",
      "10-20 18:27:20.815 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:20.836 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_145\n",
      "10-20 18:27:20.863 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_145\n",
      "10-20 18:27:20.943 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_146\n",
      "10-20 18:27:20.946 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_147\n",
      "10-20 18:27:20.947 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_148\n",
      "10-20 18:27:20.958 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_147\n",
      "10-20 18:27:20.959 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_148\n",
      "10-20 18:27:20.960 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_146\n",
      "10-20 18:27:20.996 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_149\n",
      "10-20 18:27:21.047 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_149\n",
      "10-20 18:27:21.070 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.106 (Wall: 20-Oct 18:27:21.070) \n",
      "10-20 18:27:21.075 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.108 (Wall: 20-Oct 18:27:21.075) \n",
      "10-20 18:27:21.075 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.111 (Wall: 20-Oct 18:27:21.075) \n",
      "10-20 18:27:21.198 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.127 (Wall: 20-Oct 18:27:21.198) \n",
      "10-20 18:27:21.201 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.125 (Wall: 20-Oct 18:27:21.201) \n",
      "10-20 18:27:21.201 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.144 (Wall: 20-Oct 18:27:21.201) \n",
      "10-20 18:27:21.217 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.142 (Wall: 20-Oct 18:27:21.217) \n",
      "10-20 18:27:21.300 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:21.300) \n",
      "10-20 18:27:21.304 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:21.304) \n",
      "10-20 18:27:21.317 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:21.317) \n",
      "10-20 18:27:21.320 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:21.320) \n",
      "10-20 18:27:21.373 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:21.373) \n",
      "10-20 18:27:21.395 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.091 (Wall: 20-Oct 18:27:21.395) \n",
      "10-20 18:27:21.401 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:21.400) \n",
      "10-20 18:27:21.403 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:21.403) \n",
      "10-20 18:27:21.463 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:21.463) \n",
      "10-20 18:27:21.465 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:21.466 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:21.466) \n",
      "10-20 18:27:21.466 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:21.484 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:21.483) \n",
      "10-20 18:27:21.484 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_150\n",
      "10-20 18:27:21.485 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:21.499 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.096 (Wall: 20-Oct 18:27:21.499) \n",
      "10-20 18:27:21.503 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_150\n",
      "10-20 18:27:21.510 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_151\n",
      "10-20 18:27:21.511 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_152\n",
      "10-20 18:27:21.535 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_152\n",
      "10-20 18:27:21.544 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_151\n",
      "10-20 18:27:21.549 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_153\n",
      "10-20 18:27:21.562 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_154\n",
      "10-20 18:27:21.566 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_153\n",
      "10-20 18:27:21.579 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:21.579) \n",
      "10-20 18:27:21.580 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:21.580 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_155\n",
      "10-20 18:27:21.586 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_154\n",
      "10-20 18:27:21.596 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_155\n",
      "10-20 18:27:21.608 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_156\n",
      "10-20 18:27:21.636 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_156\n",
      "10-20 18:27:21.658 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.089 (Wall: 20-Oct 18:27:21.657) \n",
      "10-20 18:27:21.681 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_157\n",
      "10-20 18:27:21.685 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.094 (Wall: 20-Oct 18:27:21.685) \n",
      "10-20 18:27:21.688 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:21.687) \n",
      "10-20 18:27:21.692 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_157\n",
      "10-20 18:27:21.731 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:21.765 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.107 (Wall: 20-Oct 18:27:21.765) \n",
      "10-20 18:27:21.797 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.109 (Wall: 20-Oct 18:27:21.797) \n",
      "10-20 18:27:21.806 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.121 (Wall: 20-Oct 18:27:21.806) \n",
      "10-20 18:27:21.855 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.159 (Wall: 20-Oct 18:27:21.855) \n",
      "10-20 18:27:21.876 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:21.876) \n",
      "10-20 18:27:21.909 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.144 (Wall: 20-Oct 18:27:21.909) \n",
      "10-20 18:27:21.959 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.153 (Wall: 20-Oct 18:27:21.959) \n",
      "10-20 18:27:21.997 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.142 (Wall: 20-Oct 18:27:21.997) \n",
      "10-20 18:27:22.009 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.132 (Wall: 20-Oct 18:27:22.009) \n",
      "10-20 18:27:22.029 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.120 (Wall: 20-Oct 18:27:22.029) \n",
      "10-20 18:27:22.068 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.108 (Wall: 20-Oct 18:27:22.067) \n",
      "10-20 18:27:22.082 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:22.082) \n",
      "10-20 18:27:22.084 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.092 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.095 (Wall: 20-Oct 18:27:22.092) \n",
      "10-20 18:27:22.103 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_158\n",
      "10-20 18:27:22.128 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_158\n",
      "10-20 18:27:22.134 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:22.134) \n",
      "10-20 18:27:22.136 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.155 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.087 (Wall: 20-Oct 18:27:22.155) \n",
      "10-20 18:27:22.156 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.168 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_159\n",
      "10-20 18:27:22.171 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_160\n",
      "10-20 18:27:22.189 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_159\n",
      "10-20 18:27:22.189 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_160\n",
      "10-20 18:27:22.190 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.098 (Wall: 20-Oct 18:27:22.190) \n",
      "10-20 18:27:22.207 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_161\n",
      "10-20 18:27:22.238 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_162\n",
      "10-20 18:27:22.239 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_161\n",
      "10-20 18:27:22.266 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.076 (Wall: 20-Oct 18:27:22.266) \n",
      "10-20 18:27:22.267 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.287 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_163\n",
      "10-20 18:27:22.288 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_162\n",
      "10-20 18:27:22.293 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_164\n",
      "10-20 18:27:22.302 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_163\n",
      "10-20 18:27:22.311 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_164\n",
      "10-20 18:27:22.359 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.115 (Wall: 20-Oct 18:27:22.359) \n",
      "10-20 18:27:22.382 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_165\n",
      "10-20 18:27:22.394 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_165\n",
      "10-20 18:27:22.396 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.104 (Wall: 20-Oct 18:27:22.396) \n",
      "10-20 18:27:22.422 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:22.422) \n",
      "10-20 18:27:22.460 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.101 (Wall: 20-Oct 18:27:22.460) \n",
      "10-20 18:27:22.518 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:22.518) \n",
      "10-20 18:27:22.536 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.140 (Wall: 20-Oct 18:27:22.536) \n",
      "10-20 18:27:22.574 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.151 (Wall: 20-Oct 18:27:22.574) \n",
      "10-20 18:27:22.580 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.119 (Wall: 20-Oct 18:27:22.580) \n",
      "10-20 18:27:22.621 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:22.620) \n",
      "10-20 18:27:22.641 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:22.641) \n",
      "█10-20 18:27:22.690 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.115 (Wall: 20-Oct 18:27:22.690) \n",
      "10-20 18:27:22.730 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.150 (Wall: 20-Oct 18:27:22.730) \n",
      "10-20 18:27:22.731 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.110 (Wall: 20-Oct 18:27:22.731) \n",
      "10-20 18:27:22.751 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.109 (Wall: 20-Oct 18:27:22.750) \n",
      "10-20 18:27:22.816 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.126 (Wall: 20-Oct 18:27:22.816) \n",
      "10-20 18:27:22.857 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.126 (Wall: 20-Oct 18:27:22.857) \n",
      "10-20 18:27:22.865 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.114 (Wall: 20-Oct 18:27:22.865) \n",
      "10-20 18:27:22.866 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.882 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.152 (Wall: 20-Oct 18:27:22.882) \n",
      "10-20 18:27:22.883 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_166\n",
      "10-20 18:27:22.884 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.906 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.089 (Wall: 20-Oct 18:27:22.906) \n",
      "10-20 18:27:22.907 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.908 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_167\n",
      "10-20 18:27:22.913 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_166\n",
      "10-20 18:27:22.925 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_168\n",
      "10-20 18:27:22.948 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.091 (Wall: 20-Oct 18:27:22.948) \n",
      "10-20 18:27:22.949 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:22.956 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_169\n",
      "10-20 18:27:22.957 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_167\n",
      "10-20 18:27:22.960 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_168\n",
      "10-20 18:27:22.968 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_170\n",
      "10-20 18:27:22.982 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_171\n",
      "10-20 18:27:22.982 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_169\n",
      "10-20 18:27:22.985 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_172\n",
      "10-20 18:27:22.987 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.37303365609880174, 0.34014767777094096, 0.3230016376292295, 0.31298040100693875]\n",
      "10-20 18:27:22.988 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.37303365609880174 --> 0.31298040100693875 (still improving).\n",
      "10-20 18:27:23.001 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_170\n",
      "10-20 18:27:23.003 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_171\n",
      "10-20 18:27:23.006 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3663345776784044, 0.3310908671067215, 0.3118184456204713, 0.29995209713279064]\n",
      "10-20 18:27:23.006 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.3663345776784044 --> 0.29995209713279064 (still improving).\n",
      "10-20 18:27:23.008 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_172\n",
      "10-20 18:27:23.019 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3754310987001512, 0.33977643805861396, 0.3206771363316061, 0.3091060093819779]\n",
      "10-20 18:27:23.019 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3754310987001512 --> 0.3091060093819779 (still improving).\n",
      "10-20 18:27:23.066 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_173\n",
      "10-20 18:27:23.069 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.081 (Wall: 20-Oct 18:27:23.069) \n",
      "10-20 18:27:23.096 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_173\n",
      "10-20 18:27:23.102 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:23.102) \n",
      "10-20 18:27:23.103 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.36957488380195264, 0.33555568746981274, 0.3180214894512897, 0.3076826290876051]\n",
      "10-20 18:27:23.103 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.36957488380195264 --> 0.3076826290876051 (still improving).\n",
      "10-20 18:27:23.112 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.106 (Wall: 20-Oct 18:27:23.112) \n",
      "10-20 18:27:23.159 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:23.159) \n",
      "10-20 18:27:23.174 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:23.174) \n",
      "10-20 18:27:23.184 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:23.219 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.117 (Wall: 20-Oct 18:27:23.219) \n",
      "10-20 18:27:23.221 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.107 (Wall: 20-Oct 18:27:23.220) \n",
      "10-20 18:27:23.261 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:23.261) \n",
      "10-20 18:27:23.304 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.129 (Wall: 20-Oct 18:27:23.304) \n",
      "10-20 18:27:23.319 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.098 (Wall: 20-Oct 18:27:23.319) \n",
      "10-20 18:27:23.325 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:23.325) \n",
      "10-20 18:27:23.366 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.104 (Wall: 20-Oct 18:27:23.366) \n",
      "10-20 18:27:23.412 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.108 (Wall: 20-Oct 18:27:23.412) \n",
      "10-20 18:27:23.418 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.099 (Wall: 20-Oct 18:27:23.418) \n",
      "10-20 18:27:23.424 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.098 (Wall: 20-Oct 18:27:23.424) \n",
      "10-20 18:27:23.458 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:23.458) \n",
      "10-20 18:27:23.460 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:23.490 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_174\n",
      "10-20 18:27:23.505 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:23.505) \n",
      "10-20 18:27:23.517 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:23.517) \n",
      "10-20 18:27:23.518 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:23.520 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:23.520) \n",
      "10-20 18:27:23.521 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:23.526 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_174\n",
      "10-20 18:27:23.541 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_175\n",
      "10-20 18:27:23.546 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_176\n",
      "10-20 18:27:23.564 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_177\n",
      "10-20 18:27:23.570 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:23.570) \n",
      "10-20 18:27:23.571 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "█10-20 18:27:23.582 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_177\n",
      "10-20 18:27:23.582 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_175\n",
      "10-20 18:27:23.583 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_176\n",
      "10-20 18:27:23.587 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.34014767777094096, 0.3230016376292295, 0.31298040100693875, 0.30729613384134186]\n",
      "10-20 18:27:23.587 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.34014767777094096 --> 0.30729613384134186 (still improving).\n",
      "10-20 18:27:23.590 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_178\n",
      "10-20 18:27:23.633 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_179\n",
      "10-20 18:27:23.634 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_178\n",
      "10-20 18:27:23.641 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_180\n",
      "10-20 18:27:23.650 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_179\n",
      "10-20 18:27:23.654 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_180\n",
      "10-20 18:27:23.657 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.33977643805861396, 0.3206771363316061, 0.3091060093819779, 0.3019163710877936]\n",
      "10-20 18:27:23.657 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.33977643805861396 --> 0.3019163710877936 (still improving).\n",
      "10-20 18:27:23.666 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3310908671067215, 0.3118184456204713, 0.29995209713279064, 0.2929992094045594]\n",
      "10-20 18:27:23.666 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.3310908671067215 --> 0.2929992094045594 (still improving).\n",
      "10-20 18:27:23.692 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_181\n",
      "10-20 18:27:23.692 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:23.692) \n",
      "10-20 18:27:23.709 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_181\n",
      "10-20 18:27:23.720 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.33555568746981274, 0.3180214894512897, 0.3076826290876051, 0.3018950817262525]\n",
      "10-20 18:27:23.720 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.33555568746981274 --> 0.3018950817262525 (still improving).\n",
      "10-20 18:27:23.801 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.135 (Wall: 20-Oct 18:27:23.801) \n",
      "10-20 18:27:23.831 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.174 (Wall: 20-Oct 18:27:23.831) \n",
      "10-20 18:27:23.862 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.170 (Wall: 20-Oct 18:27:23.862) \n",
      "10-20 18:27:23.874 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.154 (Wall: 20-Oct 18:27:23.874) \n",
      "10-20 18:27:23.918 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.117 (Wall: 20-Oct 18:27:23.918) \n",
      "10-20 18:27:23.920 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.088 (Wall: 20-Oct 18:27:23.919) \n",
      "10-20 18:27:23.949 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:23.949) \n",
      "10-20 18:27:24.003 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.141 (Wall: 20-Oct 18:27:24.003) \n",
      "10-20 18:27:24.039 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.121 (Wall: 20-Oct 18:27:24.039) \n",
      "10-20 18:27:24.044 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.095 (Wall: 20-Oct 18:27:24.044) \n",
      "10-20 18:27:24.048 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.127 (Wall: 20-Oct 18:27:24.048) \n",
      "10-20 18:27:24.111 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.108 (Wall: 20-Oct 18:27:24.111) \n",
      "10-20 18:27:24.155 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.115 (Wall: 20-Oct 18:27:24.155) \n",
      "10-20 18:27:24.186 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.142 (Wall: 20-Oct 18:27:24.186) \n",
      "10-20 18:27:24.203 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.155 (Wall: 20-Oct 18:27:24.203) \n",
      "10-20 18:27:24.222 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.110 (Wall: 20-Oct 18:27:24.222) \n",
      "10-20 18:27:24.223 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:24.267 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.111 (Wall: 20-Oct 18:27:24.266) \n",
      "10-20 18:27:24.268 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:24.286 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_182\n",
      "10-20 18:27:24.289 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_183\n",
      "10-20 18:27:24.296 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:24.296) \n",
      "10-20 18:27:24.298 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:24.309 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_182\n",
      "10-20 18:27:24.313 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.127 (Wall: 20-Oct 18:27:24.313) \n",
      "10-20 18:27:24.314 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:24.324 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_183\n",
      "10-20 18:27:24.325 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_184\n",
      "10-20 18:27:24.341 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_184\n",
      "10-20 18:27:24.345 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_185\n",
      "10-20 18:27:24.348 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:24.349 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_186\n",
      "10-20 18:27:24.367 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_185\n",
      "10-20 18:27:24.369 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3230016376292295, 0.31298040100693875, 0.30729613384134186, 0.3031905843027752]\n",
      "10-20 18:27:24.369 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.3230016376292295 --> 0.3031905843027752 (still improving).\n",
      "10-20 18:27:24.373 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_186\n",
      "10-20 18:27:24.381 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_187\n",
      "10-20 18:27:24.397 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_188\n",
      "10-20 18:27:24.409 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_187\n",
      "10-20 18:27:24.416 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_188\n",
      "10-20 18:27:24.419 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3206771363316061, 0.3091060093819779, 0.3019163710877936, 0.29685490028395844]\n",
      "10-20 18:27:24.419 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3118184456204713, 0.29995209713279064, 0.2929992094045594, 0.28828751772322114]\n",
      "10-20 18:27:24.419 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3206771363316061 --> 0.29685490028395844 (still improving).\n",
      "10-20 18:27:24.419 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.3118184456204713 --> 0.28828751772322114 (still improving).\n",
      "10-20 18:27:24.441 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_189\n",
      "10-20 18:27:24.461 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_189\n",
      "10-20 18:27:24.468 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3180214894512897, 0.3076826290876051, 0.3018950817262525, 0.29741024824115403]\n",
      "10-20 18:27:24.468 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3180214894512897 --> 0.29741024824115403 (still improving).\n",
      "10-20 18:27:24.475 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.106 (Wall: 20-Oct 18:27:24.475) \n",
      "█10-20 18:27:24.541 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.122 (Wall: 20-Oct 18:27:24.541) \n",
      "10-20 18:27:24.542 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.122 (Wall: 20-Oct 18:27:24.542) \n",
      "10-20 18:27:24.590 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.122 (Wall: 20-Oct 18:27:24.590) \n",
      "10-20 18:27:24.612 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.137 (Wall: 20-Oct 18:27:24.612) \n",
      "10-20 18:27:24.691 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.149 (Wall: 20-Oct 18:27:24.691) \n",
      "10-20 18:27:24.721 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.108 (Wall: 20-Oct 18:27:24.721) \n",
      "10-20 18:27:24.737 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.195 (Wall: 20-Oct 18:27:24.737) \n",
      "10-20 18:27:24.778 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.188 (Wall: 20-Oct 18:27:24.778) \n",
      "10-20 18:27:24.823 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.131 (Wall: 20-Oct 18:27:24.823) \n",
      "10-20 18:27:24.865 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.144 (Wall: 20-Oct 18:27:24.865) \n",
      "10-20 18:27:24.877 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.139 (Wall: 20-Oct 18:27:24.877) \n",
      "10-20 18:27:24.920 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.141 (Wall: 20-Oct 18:27:24.919) \n",
      "10-20 18:27:24.933 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.110 (Wall: 20-Oct 18:27:24.933) \n",
      "10-20 18:27:25.020 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.155 (Wall: 20-Oct 18:27:25.020) \n",
      "10-20 18:27:25.027 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:25.036 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.159 (Wall: 20-Oct 18:27:25.036) \n",
      "10-20 18:27:25.074 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.141 (Wall: 20-Oct 18:27:25.074) \n",
      "10-20 18:27:25.083 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:25.089 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_190\n",
      "10-20 18:27:25.099 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.179 (Wall: 20-Oct 18:27:25.099) \n",
      "10-20 18:27:25.112 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_191\n",
      "10-20 18:27:25.121 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_190\n",
      "10-20 18:27:25.159 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_191\n",
      "10-20 18:27:25.163 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.127 (Wall: 20-Oct 18:27:25.163) \n",
      "10-20 18:27:25.164 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:25.183 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.084 (Wall: 20-Oct 18:27:25.183) \n",
      "10-20 18:27:25.185 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:25.192 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_192\n",
      "10-20 18:27:25.198 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_194\n",
      "10-20 18:27:25.199 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_193\n",
      "10-20 18:27:25.211 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_195\n",
      "10-20 18:27:25.216 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_194\n",
      "10-20 18:27:25.229 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_192\n",
      "10-20 18:27:25.232 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_193\n",
      "10-20 18:27:25.234 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_195\n",
      "10-20 18:27:25.237 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.31298040100693875, 0.30729613384134186, 0.3031905843027752, 0.3002200276754002]\n",
      "10-20 18:27:25.237 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.31298040100693875 --> 0.3002200276754002 (still improving).\n",
      "10-20 18:27:25.240 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29995209713279064, 0.2929992094045594, 0.28828751772322114, 0.2851319193196016]\n",
      "10-20 18:27:25.241 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.29995209713279064 --> 0.2851319193196016 (still improving).\n",
      "10-20 18:27:25.270 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_196\n",
      "10-20 18:27:25.280 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_196\n",
      "10-20 18:27:25.283 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_197\n",
      "10-20 18:27:25.284 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3091060093819779, 0.3019163710877936, 0.29685490028395844, 0.2930372345701842]\n",
      "10-20 18:27:25.284 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3091060093819779 --> 0.2930372345701842 (still improving).\n",
      "10-20 18:27:25.315 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_197\n",
      "10-20 18:27:25.318 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3076826290876051, 0.3018950817262525, 0.29741024824115403, 0.2941607726797984]\n",
      "10-20 18:27:25.318 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3076826290876051 --> 0.2941607726797984 (still improving).\n",
      "10-20 18:27:25.320 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:25.320) \n",
      "10-20 18:27:25.370 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.129 (Wall: 20-Oct 18:27:25.370) \n",
      "10-20 18:27:25.410 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:25.410) \n",
      "10-20 18:27:25.419 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.135 (Wall: 20-Oct 18:27:25.419) \n",
      "10-20 18:27:25.430 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:25.485 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.165 (Wall: 20-Oct 18:27:25.485) \n",
      "10-20 18:27:25.566 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.147 (Wall: 20-Oct 18:27:25.566) \n",
      "10-20 18:27:25.586 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.216 (Wall: 20-Oct 18:27:25.586) \n",
      "10-20 18:27:25.609 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.198 (Wall: 20-Oct 18:27:25.609) \n",
      "10-20 18:27:25.612 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.127 (Wall: 20-Oct 18:27:25.612) \n",
      "10-20 18:27:25.685 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.119 (Wall: 20-Oct 18:27:25.685) \n",
      "10-20 18:27:25.689 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:25.689) \n",
      "10-20 18:27:25.726 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:25.726) \n",
      "10-20 18:27:25.730 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.118 (Wall: 20-Oct 18:27:25.730) \n",
      "10-20 18:27:25.820 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.135 (Wall: 20-Oct 18:27:25.820) \n",
      "10-20 18:27:25.842 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:25.842) \n",
      "10-20 18:27:25.855 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.166 (Wall: 20-Oct 18:27:25.855) \n",
      "10-20 18:27:25.887 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 50. tree was built in 00:00:00.156 (Wall: 20-Oct 18:27:25.887) \n",
      "10-20 18:27:25.890 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:25.929 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_198\n",
      "10-20 18:27:25.951 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 50. tree was built in 00:00:00.131 (Wall: 20-Oct 18:27:25.951) \n",
      "10-20 18:27:25.952 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_198\n",
      "10-20 18:27:25.953 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:25.991 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 50. tree was built in 00:00:00.149 (Wall: 20-Oct 18:27:25.991) \n",
      "10-20 18:27:25.993 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_199\n",
      "10-20 18:27:26.001 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:26.047 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 50. tree was built in 00:00:00.187 (Wall: 20-Oct 18:27:26.042) \n",
      "10-20 18:27:26.064 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:26.084 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_200\n",
      "10-20 18:27:26.107 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_201\n",
      "10-20 18:27:26.122 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_199\n",
      "10-20 18:27:26.144 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_202\n",
      "10-20 18:27:26.171 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_200\n",
      "10-20 18:27:26.181 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_201\n",
      "10-20 18:27:26.191 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_202\n",
      "10-20 18:27:26.192 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_203\n",
      "10-20 18:27:26.200 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.30729613384134186, 0.3031905843027752, 0.3002200276754002, 0.2979503663513104]\n",
      "10-20 18:27:26.200 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.30729613384134186 --> 0.2979503663513104 (still improving).\n",
      "10-20 18:27:26.204 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_204\n",
      "10-20 18:27:26.218 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_203\n",
      "10-20 18:27:26.222 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3019163710877936, 0.29685490028395844, 0.2930372345701842, 0.29014670613461496]\n",
      "10-20 18:27:26.223 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3019163710877936 --> 0.29014670613461496 (still improving).\n",
      "10-20 18:27:26.225 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_204\n",
      "10-20 18:27:26.229 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3018950817262525, 0.29741024824115403, 0.2941607726797984, 0.2916079586388885]\n",
      "10-20 18:27:26.229 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3018950817262525 --> 0.2916079586388885 (still improving).\n",
      "10-20 18:27:26.262 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_205\n",
      "10-20 18:27:26.265 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 51. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:26.265) \n",
      "10-20 18:27:26.287 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 51. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:26.287) \n",
      "10-20 18:27:26.293 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 51. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:26.293) \n",
      "10-20 18:27:26.295 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_205\n",
      "10-20 18:27:26.299 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2929992094045594, 0.28828751772322114, 0.2851319193196016, 0.2828446348774905]\n",
      "10-20 18:27:26.300 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.2929992094045594 --> 0.2828446348774905 (still improving).\n",
      "10-20 18:27:26.330 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 52. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:26.330) \n",
      "█10-20 18:27:26.370 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 52. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:26.370) \n",
      "10-20 18:27:26.380 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 52. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:26.380) \n",
      "10-20 18:27:26.380 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 51. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:26.380) \n",
      "10-20 18:27:26.408 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 53. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:26.408) \n",
      "10-20 18:27:26.444 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 53. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:26.444) \n",
      "10-20 18:27:26.463 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 53. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:26.463) \n",
      "10-20 18:27:26.463 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 52. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:26.463) \n",
      "10-20 18:27:26.479 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 54. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:26.479) \n",
      "10-20 18:27:26.536 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 54. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:26.536) \n",
      "10-20 18:27:26.541 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 54. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:26.541) \n",
      "10-20 18:27:26.542 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 53. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:26.542) \n",
      "10-20 18:27:26.549 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 55. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:26.549) \n",
      "10-20 18:27:26.550 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:26.572 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_206\n",
      "10-20 18:27:26.598 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_206\n",
      "10-20 18:27:26.613 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 55. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:26.613) \n",
      "10-20 18:27:26.614 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:26.615 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 55. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:26.615) \n",
      "10-20 18:27:26.619 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:26.629 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_207\n",
      "10-20 18:27:26.631 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 54. tree was built in 00:00:00.089 (Wall: 20-Oct 18:27:26.631) \n",
      "10-20 18:27:26.637 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_209\n",
      "10-20 18:27:26.638 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_208\n",
      "10-20 18:27:26.643 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_207\n",
      "10-20 18:27:26.647 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3031905843027752, 0.3002200276754002, 0.2979503663513104, 0.29668079231189926]\n",
      "10-20 18:27:26.647 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.3031905843027752 --> 0.29668079231189926 (still improving).\n",
      "10-20 18:27:26.681 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_209\n",
      "10-20 18:27:26.685 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_208\n",
      "10-20 18:27:26.703 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 55. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:26.703) \n",
      "10-20 18:27:26.705 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:26.722 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_210\n",
      "10-20 18:27:26.724 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_211\n",
      "10-20 18:27:26.730 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 56. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:26.730) \n",
      "10-20 18:27:26.736 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_212\n",
      "10-20 18:27:26.741 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_210\n",
      "10-20 18:27:26.744 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29741024824115403, 0.2941607726797984, 0.2916079586388885, 0.2902576207691993]\n",
      "10-20 18:27:26.744 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.29741024824115403 --> 0.2902576207691993 (still improving).\n",
      "10-20 18:27:26.767 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_212\n",
      "10-20 18:27:26.769 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_211\n",
      "10-20 18:27:26.774 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29685490028395844, 0.2930372345701842, 0.29014670613461496, 0.28796405204266]\n",
      "10-20 18:27:26.774 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29685490028395844 --> 0.28796405204266 (still improving).\n",
      "10-20 18:27:26.818 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_213\n",
      "10-20 18:27:26.830 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_213\n",
      "10-20 18:27:26.834 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28828751772322114, 0.2851319193196016, 0.2828446348774905, 0.2812471048137481]\n",
      "10-20 18:27:26.834 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.28828751772322114 --> 0.2812471048137481 (still improving).\n",
      "10-20 18:27:26.836 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 57. tree was built in 00:00:00.106 (Wall: 20-Oct 18:27:26.836) \n",
      "10-20 18:27:26.836 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 56. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:26.836) \n",
      "10-20 18:27:26.867 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 56. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:26.867) \n",
      "10-20 18:27:26.925 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 56. tree was built in 00:00:00.091 (Wall: 20-Oct 18:27:26.925) \n",
      "10-20 18:27:26.937 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 57. tree was built in 00:00:00.101 (Wall: 20-Oct 18:27:26.937) \n",
      "10-20 18:27:26.939 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 58. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:26.939) \n",
      "10-20 18:27:26.969 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 57. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:26.969) \n",
      "10-20 18:27:27.005 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 57. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:27.005) \n",
      "10-20 18:27:27.016 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 58. tree was built in 00:00:00.079 (Wall: 20-Oct 18:27:27.016) \n",
      "10-20 18:27:27.019 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 59. tree was built in 00:00:00.079 (Wall: 20-Oct 18:27:27.019) \n",
      "10-20 18:27:27.056 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 58. tree was built in 00:00:00.087 (Wall: 20-Oct 18:27:27.056) \n",
      "10-20 18:27:27.072 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 58. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:27.072) \n",
      "10-20 18:27:27.090 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 59. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:27.090) \n",
      "10-20 18:27:27.105 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 60. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:27.105) \n",
      "10-20 18:27:27.106 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:27.125 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_214\n",
      "10-20 18:27:27.143 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 59. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:27.143) \n",
      "10-20 18:27:27.146 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_214\n",
      "10-20 18:27:27.162 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 59. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:27.162) \n",
      "10-20 18:27:27.175 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 60. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:27.175) \n",
      "10-20 18:27:27.179 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:27.195 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_215\n",
      "10-20 18:27:27.221 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 60. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:27.221) \n",
      "10-20 18:27:27.223 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:27.223 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_215\n",
      "10-20 18:27:27.234 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3002200276754002, 0.2979503663513104, 0.29668079231189926, 0.29603905127089286]\n",
      "10-20 18:27:27.234 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.3002200276754002 --> 0.29603905127089286 (still improving).\n",
      "10-20 18:27:27.237 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 60. tree was built in 00:00:00.075 (Wall: 20-Oct 18:27:27.237) \n",
      "10-20 18:27:27.237 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:27.237 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_216\n",
      "10-20 18:27:27.256 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_217\n",
      "10-20 18:27:27.266 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:27.270 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_218\n",
      "█10-20 18:27:27.282 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_216\n",
      "10-20 18:27:27.310 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_217\n",
      "10-20 18:27:27.316 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_218\n",
      "10-20 18:27:27.341 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 61. tree was built in 00:00:00.107 (Wall: 20-Oct 18:27:27.341) \n",
      "10-20 18:27:27.344 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_219\n",
      "10-20 18:27:27.359 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_219\n",
      "10-20 18:27:27.367 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2941607726797984, 0.2916079586388885, 0.2902576207691993, 0.28953786936954123]\n",
      "10-20 18:27:27.368 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.2941607726797984 --> 0.28953786936954123 (still improving).\n",
      "10-20 18:27:27.381 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_220\n",
      "10-20 18:27:27.388 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_221\n",
      "10-20 18:27:27.405 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_221\n",
      "10-20 18:27:27.407 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_220\n",
      "10-20 18:27:27.411 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2930372345701842, 0.29014670613461496, 0.28796405204266, 0.28644951508606686]\n",
      "10-20 18:27:27.411 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2930372345701842 --> 0.28644951508606686 (still improving).\n",
      "10-20 18:27:27.411 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2851319193196016, 0.2828446348774905, 0.2812471048137481, 0.28026258685949584]\n",
      "10-20 18:27:27.412 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.2851319193196016 --> 0.28026258685949584 (still improving).\n",
      "10-20 18:27:27.443 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 62. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:27.443) \n",
      "10-20 18:27:27.503 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 61. tree was built in 00:00:00.134 (Wall: 20-Oct 18:27:27.502) \n",
      "10-20 18:27:27.548 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 61. tree was built in 00:00:00.137 (Wall: 20-Oct 18:27:27.548) \n",
      "10-20 18:27:27.585 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 61. tree was built in 00:00:00.173 (Wall: 20-Oct 18:27:27.585) \n",
      "10-20 18:27:27.590 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 63. tree was built in 00:00:00.146 (Wall: 20-Oct 18:27:27.590) \n",
      "10-20 18:27:27.607 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 62. tree was built in 00:00:00.104 (Wall: 20-Oct 18:27:27.607) \n",
      "10-20 18:27:27.728 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 62. tree was built in 00:00:00.143 (Wall: 20-Oct 18:27:27.728) \n",
      "10-20 18:27:27.735 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 62. tree was built in 00:00:00.187 (Wall: 20-Oct 18:27:27.735) \n",
      "10-20 18:27:27.756 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 63. tree was built in 00:00:00.149 (Wall: 20-Oct 18:27:27.756) \n",
      "10-20 18:27:27.757 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 64. tree was built in 00:00:00.167 (Wall: 20-Oct 18:27:27.757) \n",
      "10-20 18:27:27.877 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 63. tree was built in 00:00:00.139 (Wall: 20-Oct 18:27:27.874) \n",
      "10-20 18:27:27.892 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 64. tree was built in 00:00:00.135 (Wall: 20-Oct 18:27:27.891) \n",
      "10-20 18:27:27.895 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 63. tree was built in 00:00:00.166 (Wall: 20-Oct 18:27:27.895) \n",
      "10-20 18:27:27.918 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 65. tree was built in 00:00:00.161 (Wall: 20-Oct 18:27:27.918) \n",
      "10-20 18:27:27.919 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:27.956 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_222\n",
      "10-20 18:27:27.975 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 64. tree was built in 00:00:00.097 (Wall: 20-Oct 18:27:27.975) \n",
      "10-20 18:27:27.983 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_222\n",
      "10-20 18:27:28.003 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 64. tree was built in 00:00:00.108 (Wall: 20-Oct 18:27:28.003) \n",
      "10-20 18:27:28.006 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 65. tree was built in 00:00:00.114 (Wall: 20-Oct 18:27:28.006) \n",
      "10-20 18:27:28.012 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.037 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_223\n",
      "10-20 18:27:28.039 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_224\n",
      "10-20 18:27:28.063 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_223\n",
      "10-20 18:27:28.074 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 65. tree was built in 00:00:00.099 (Wall: 20-Oct 18:27:28.074) \n",
      "10-20 18:27:28.076 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.082 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_224\n",
      "10-20 18:27:28.089 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2979503663513104, 0.29668079231189926, 0.29603905127089286, 0.2956814208459369]\n",
      "10-20 18:27:28.089 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.2979503663513104 --> 0.2956814208459369 (still improving).\n",
      "10-20 18:27:28.100 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_225\n",
      "10-20 18:27:28.107 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 65. tree was built in 00:00:00.104 (Wall: 20-Oct 18:27:28.107) \n",
      "10-20 18:27:28.110 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.128 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_225\n",
      "10-20 18:27:28.145 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_226\n",
      "10-20 18:27:28.154 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_227\n",
      "10-20 18:27:28.159 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_226\n",
      "10-20 18:27:28.163 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2916079586388885, 0.2902576207691993, 0.28953786936954123, 0.28914114157456633]\n",
      "10-20 18:27:28.163 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.2916079586388885 --> 0.28914114157456633 (still improving).\n",
      "10-20 18:27:28.181 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_228\n",
      "10-20 18:27:28.206 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_227\n",
      "10-20 18:27:28.211 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:28.213 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 66. tree was built in 00:00:00.124 (Wall: 20-Oct 18:27:28.213) \n",
      "█10-20 18:27:28.220 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_228\n",
      "10-20 18:27:28.236 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29014670613461496, 0.28796405204266, 0.28644951508606686, 0.2851807097949544]\n",
      "10-20 18:27:28.236 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29014670613461496 --> 0.2851807097949544 (still improving).\n",
      "10-20 18:27:28.273 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 66. tree was built in 00:00:00.109 (Wall: 20-Oct 18:27:28.272) \n",
      "10-20 18:27:28.288 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_229\n",
      "10-20 18:27:28.309 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_229\n",
      "10-20 18:27:28.313 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2828446348774905, 0.2812471048137481, 0.28026258685949584, 0.27974500956482423]\n",
      "10-20 18:27:28.313 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.2828446348774905 --> 0.27974500956482423 (still improving).\n",
      "10-20 18:27:28.325 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 67. tree was built in 00:00:00.111 (Wall: 20-Oct 18:27:28.324) \n",
      "10-20 18:27:28.330 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 66. tree was built in 00:00:00.094 (Wall: 20-Oct 18:27:28.330) \n",
      "10-20 18:27:28.409 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 67. tree was built in 00:00:00.079 (Wall: 20-Oct 18:27:28.409) \n",
      "10-20 18:27:28.415 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 68. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:28.415) \n",
      "10-20 18:27:28.416 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 67. tree was built in 00:00:00.143 (Wall: 20-Oct 18:27:28.416) \n",
      "10-20 18:27:28.442 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 66. tree was built in 00:00:00.128 (Wall: 20-Oct 18:27:28.442) \n",
      "10-20 18:27:28.499 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 68. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:28.499) \n",
      "10-20 18:27:28.508 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 69. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:28.508) \n",
      "10-20 18:27:28.538 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 68. tree was built in 00:00:00.122 (Wall: 20-Oct 18:27:28.538) \n",
      "10-20 18:27:28.547 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 67. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:28.547) \n",
      "10-20 18:27:28.594 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 69. tree was built in 00:00:00.095 (Wall: 20-Oct 18:27:28.594) \n",
      "10-20 18:27:28.601 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 70. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:28.601) \n",
      "10-20 18:27:28.602 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.634 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 68. tree was built in 00:00:00.087 (Wall: 20-Oct 18:27:28.634) \n",
      "10-20 18:27:28.641 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 69. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:28.641) \n",
      "10-20 18:27:28.661 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_230\n",
      "10-20 18:27:28.680 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_230\n",
      "10-20 18:27:28.711 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 70. tree was built in 00:00:00.117 (Wall: 20-Oct 18:27:28.711) \n",
      "10-20 18:27:28.712 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.745 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_232\n",
      "10-20 18:27:28.746 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 70. tree was built in 00:00:00.104 (Wall: 20-Oct 18:27:28.746) \n",
      "10-20 18:27:28.747 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.747 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_231\n",
      "10-20 18:27:28.758 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 69. tree was built in 00:00:00.123 (Wall: 20-Oct 18:27:28.758) \n",
      "10-20 18:27:28.769 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_231\n",
      "10-20 18:27:28.780 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_232\n",
      "10-20 18:27:28.782 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_233\n",
      "10-20 18:27:28.785 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29668079231189926, 0.29603905127089286, 0.2956814208459369, 0.2955931941533234]\n",
      "10-20 18:27:28.785 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.29668079231189926 --> 0.2955931941533234 (converged).\n",
      "10-20 18:27:28.785 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Cross-Validation model 3 / 5 built total of 70 trees, however the best score was obtained using only ntrees=65. Trimming model to 65 trees.\n",
      "10-20 18:27:28.788 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07481509\n",
      " RMSE: 0.27352345\n",
      " AUC: 0.9523203\n",
      " pr_auc: 0.876211\n",
      " logloss: 0.23809959\n",
      " mean_per_class_error: 0.13667986\n",
      " default threshold: 0.36856377124786377\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17962  1783  0.0903  1,783 / 19,745\n",
      "     1   1154  5150  0.1831   1,154 / 6,304\n",
      "Totals  19116  6933  0.1127  2,937 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991514  4.132138         4.132138       1.000000  0.993448                  1.000000          0.993448      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.986377  4.132138         4.132138       1.000000  0.989175                  1.000000          0.991316      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.980319  4.132138         4.132138       1.000000  0.983430                  1.000000          0.988684      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.971880  4.132138         4.132138       1.000000  0.976470                  1.000000          0.985636      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.954205  4.100474         4.125796       0.992337  0.964417                  0.998465          0.981386      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.792651  3.840159         3.983032       0.929339  0.868683                  0.963916          0.925056      0.191942                 0.398319   284.015927       298.303237            0.393558\n",
      "      7                0.15002495         0.657103  3.272730         3.746204       0.792018  0.726223                  0.906602          0.858762      0.163706                 0.562024   227.272966       274.620422            0.543538\n",
      "      8                0.20000768         0.523313  2.551643         3.447679       0.617512  0.590343                  0.834357          0.791683      0.127538                 0.689562   155.164302       244.767856            0.645855\n",
      "      9                0.30001152         0.306350  1.730581         2.875313       0.418810  0.406140                  0.695841          0.663168      0.173065                 0.862627    73.058077       187.531263            0.742242\n",
      "     10                0.40001536         0.159029  0.920015         2.386488       0.222649  0.228742                  0.577543          0.554562      0.092005                 0.954632    -7.998456       138.648833            0.731689\n",
      "     11                0.50001919         0.074199  0.352144         1.979619       0.085221  0.112767                  0.479079          0.466203      0.035216                 0.989848   -64.785616        97.961944            0.646216\n",
      "     12                0.59998464         0.031432  0.080929         1.663272       0.019585  0.049548                  0.402521          0.396783      0.008090                 0.997938   -91.907102        66.327226            0.525008\n",
      "     13                0.69998848         0.014313  0.017449         1.428142       0.004223  0.021433                  0.345618          0.343158      0.001745                 0.999683   -98.255143        42.814170            0.395378\n",
      "     14                0.79999232         0.006853  0.003172         1.250012       0.000768  0.010115                  0.302510          0.301526      0.000317                 1.000000   -99.682753        25.001200            0.263864\n",
      "     15                0.89999616         0.003119  0.000000         1.111116       0.000000  0.004738                  0.268896          0.268548      0.000000                 1.000000  -100.000000        11.111585            0.131932\n",
      "     16                1.00000000         0.000531  0.000000         1.000000       0.000000  0.002150                  0.242005          0.241907      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_3\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09349205\n",
      " RMSE: 0.3057647\n",
      " AUC: 0.9169862\n",
      " pr_auc: 0.8051474\n",
      " logloss: 0.29565004\n",
      " mean_per_class_error: 0.18166819\n",
      " default threshold: 0.3883780837059021\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4433   542  0.1089  542 / 4,975\n",
      "     1   391  1146  0.2544  391 / 1,537\n",
      "Totals  4824  1688  0.1433  933 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 23.97 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.991970  4.236825         4.236825       1.000000  0.993703                  1.000000          0.993703      0.042941                 0.042941   323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.986357  4.236825         4.236825       1.000000  0.989305                  1.000000          0.991521      0.042290                 0.085231   323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.978310  4.171643         4.215209       0.984615  0.982625                  0.994898          0.988570      0.041640                 0.126871   317.164306       321.520853            0.126670\n",
      "      4                0.04007985         0.969591  4.236825         4.220592       1.000000  0.974033                  0.996169          0.984950      0.042290                 0.169161   323.682498       322.059194            0.168960\n",
      "      5                0.05006143         0.944508  4.171643         4.210832       0.984615  0.957473                  0.993865          0.979471      0.041640                 0.210800   317.164306       321.083219            0.210398\n",
      "      6                0.10012285         0.779925  3.587005         3.898919       0.846626  0.853612                  0.920245          0.916542      0.179571                 0.390371   258.700520       289.891870            0.379919\n",
      "      7                0.15003071         0.635128  2.750677         3.516955       0.649231  0.709372                  0.830092          0.847627      0.137280                 0.527651   175.067714       251.695503            0.494284\n",
      "      8                0.20009214         0.508785  2.261373         3.202819       0.533742  0.569122                  0.755948          0.777947      0.113208                 0.640859   126.137284       220.281858            0.576939\n",
      "      9                0.30006143         0.313131  1.542439         2.649642       0.364055  0.403761                  0.625384          0.653282      0.154196                 0.795055    54.243859       164.964183            0.647920\n",
      "     10                0.40003071         0.163291  1.080358         2.257471       0.254992  0.235113                  0.532821          0.548780      0.108003                 0.903058     8.035783       125.747143            0.658435\n",
      "     11                0.50000000         0.074403  0.514146         1.908913       0.121352  0.114199                  0.450553          0.461891      0.051399                 0.954457   -48.585380        90.891347            0.594859\n",
      "     12                0.59996929         0.031278  0.221278         1.627713       0.052227  0.049239                  0.384182          0.393133      0.022121                 0.976578   -77.872189        62.771290            0.492960\n",
      "     13                0.69993857         0.014157  0.156196         1.417542       0.036866  0.021350                  0.334577          0.340033      0.015615                 0.992193   -84.380369        41.754237            0.382544\n",
      "     14                0.79990786         0.006953  0.065082         1.248517       0.015361  0.010069                  0.294682          0.298795      0.006506                 0.998699   -93.491820        24.851725            0.260206\n",
      "     15                0.89987715         0.003130  0.013016         1.111263       0.003072  0.004889                  0.262287          0.266145      0.001301                 1.000000   -98.698364        11.126280            0.131055\n",
      "     16                1.00000000         0.000718  0.000000         1.000000       0.000000  0.002168                  0.236026          0.239714      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "      Variable Relative Importance Scaled Importance Percentage\n",
      "  relationship         3585.865234          1.000000   0.276710\n",
      "  capital_gain         2492.924805          0.695209   0.192371\n",
      "     education         1990.292725          0.555038   0.153585\n",
      "    occupation         1100.128296          0.306796   0.084893\n",
      "marital_status          991.234192          0.276428   0.076490\n",
      "           age          940.054993          0.262156   0.072541\n",
      "  capital_loss          535.431824          0.149317   0.041318\n",
      "hours_per_week          484.501404          0.135114   0.037387\n",
      "     workclass          298.120911          0.083138   0.023005\n",
      "        fnlwgt          237.471664          0.066224   0.018325\n",
      "native_country          221.233170          0.061696   0.017072\n",
      "           sex           49.425705          0.013783   0.003814\n",
      "          race           32.238464          0.008990   0.002488\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "              65                       70               96906         15         15   15.00000          38         154   102.27143\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.144 sec               0       0.42830          0.55338      0.50000         0.24201       1.00000                       0.75799         0.42468            0.54655        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:18  2.416 sec               5       0.35863          0.41490      0.92428         0.81308       4.13214                       0.14642         0.36050            0.41885        0.90482           0.77478         4.23682                         0.15464\n",
      " 2023-10-20 18:27:19  3.718 sec              10       0.32538          0.35245      0.92796         0.82333       4.13214                       0.13935         0.33168            0.36348        0.90754           0.78408         4.23682                         0.14742\n",
      " 2023-10-20 18:27:20  4.655 sec              15       0.31023          0.32002      0.93008         0.82886       4.13214                       0.13620         0.32005            0.33677        0.90878           0.78690         4.23682                         0.14957\n",
      " 2023-10-20 18:27:21  5.426 sec              20       0.30118          0.29809      0.93297         0.83424       4.13214                       0.13463         0.31382            0.32020        0.91049           0.79091         4.23682                         0.15295\n",
      " 2023-10-20 18:27:22  6.098 sec              25       0.29621          0.28519      0.93534         0.83909       4.13214                       0.12983         0.31129            0.31204        0.91160           0.79340         4.23682                         0.14896\n",
      " 2023-10-20 18:27:22  6.808 sec              30       0.29226          0.27544      0.93798         0.84457       4.13214                       0.12599         0.30963            0.30670        0.91282           0.79584         4.23682                         0.14558\n",
      " 2023-10-20 18:27:23  7.401 sec              35       0.28869          0.26754      0.94061         0.85012       4.13214                       0.12603         0.30854            0.30314        0.91396           0.79779         4.23682                         0.14343\n",
      " 2023-10-20 18:27:24  8.165 sec              40       0.28577          0.26134      0.94277         0.85498       4.13214                       0.12300         0.30704            0.29972        0.91527           0.80127         4.23682                         0.14481\n",
      " 2023-10-20 18:27:25  8.963 sec              45       0.28347          0.25639      0.94454         0.85877       4.13214                       0.12108         0.30634            0.29779        0.91606           0.80275         4.23682                         0.14619\n",
      " 2023-10-20 18:27:25  9.830 sec              50       0.28141          0.25231      0.94611         0.86222       4.13214                       0.11743         0.30565            0.29633        0.91679           0.80448         4.23682                         0.14588\n",
      " 2023-10-20 18:27:26 10.492 sec              55       0.27902          0.24793      0.94802         0.86636       4.13214                       0.11628         0.30573            0.29591        0.91688           0.80490         4.23682                         0.14619\n",
      " 2023-10-20 18:27:27 11.048 sec              60       0.27709          0.24447      0.94953         0.86976       4.13214                       0.11459         0.30573            0.29587        0.91689           0.80501         4.23682                         0.14036\n",
      " 2023-10-20 18:27:27 11.861 sec              65       0.27531          0.24128      0.95095         0.87298       4.13214                       0.11240         0.30544            0.29526        0.91721           0.80593         4.23682                         0.13913\n",
      " 2023-10-20 18:27:28 12.544 sec              70       0.27352          0.23810      0.95232         0.87621       4.13214                       0.11275         0.30576            0.29565        0.91699           0.80515         4.23682                         0.14327\n",
      "\n",
      "10-20 18:27:28.806 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model GBM_1_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:28.831 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_233\n",
      "10-20 18:27:28.836 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_234\n",
      "10-20 18:27:28.836 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 70. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:28.836) \n",
      "10-20 18:27:28.843 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:28.854 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_234\n",
      "10-20 18:27:28.857 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28796405204266, 0.28644951508606686, 0.2851807097949544, 0.28436925511191036]\n",
      "10-20 18:27:28.857 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.28796405204266 --> 0.28436925511191036 (still improving).\n",
      "10-20 18:27:28.859 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_235\n",
      "10-20 18:27:28.871 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_236\n",
      "10-20 18:27:28.887 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_235\n",
      "10-20 18:27:28.902 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_236\n",
      "10-20 18:27:28.906 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2902576207691993, 0.28953786936954123, 0.28914114157456633, 0.28867362285863013]\n",
      "10-20 18:27:28.906 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.2902576207691993 --> 0.28867362285863013 (converged).\n",
      "10-20 18:27:28.910 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 71. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:28.909) \n",
      "10-20 18:27:28.911 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.0749188\n",
      " RMSE: 0.273713\n",
      " AUC: 0.9514514\n",
      " pr_auc: 0.8757353\n",
      " logloss: 0.23938577\n",
      " mean_per_class_error: 0.14314364\n",
      " default threshold: 0.3878770172595978\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18112  1656  0.0838  1,656 / 19,768\n",
      "     1   1272  5009  0.2025   1,272 / 6,281\n",
      "Totals  19384  6665  0.1124  2,928 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.990842  4.147270         4.147270       1.000000  0.992654                  1.000000          0.992654      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.986887  4.147270         4.147270       1.000000  0.988987                  1.000000          0.990824      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.981637  4.147270         4.147270       1.000000  0.984553                  1.000000          0.988731      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.973285  4.147270         4.147270       1.000000  0.977966                  1.000000          0.986045      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.952594  4.131380         4.144087       0.996169  0.964444                  0.999233          0.981718      0.041395                 0.207292   313.137962       314.408668            0.207241\n",
      "      6                0.10000384         0.794860  3.854221         3.999210       0.929339  0.870977                  0.964299          0.926369      0.192644                 0.399936   285.422131       299.920963            0.395232\n",
      "      7                0.15002495         0.650192  3.275165         3.757800       0.789716  0.720379                  0.906090          0.857688      0.163827                 0.563764   227.516528       275.779976            0.545198\n",
      "      8                0.20000768         0.516952  2.589654         3.465876       0.624424  0.582156                  0.835701          0.788832      0.129438                 0.693202   158.965448       246.587555            0.649899\n",
      "      9                0.30001152         0.300697  1.687565         2.873105       0.406910  0.401358                  0.692770          0.659674      0.168763                 0.861965    68.756457       187.310522            0.740506\n",
      "     10                0.40001536         0.160959  0.915424         2.383685       0.220729  0.225670                  0.574760          0.551173      0.091546                 0.953511    -8.457582       138.368496            0.729360\n",
      "     11                0.50001919         0.075484  0.329553         1.972859       0.079463  0.114570                  0.475701          0.463852      0.032957                 0.986467   -67.044730        97.285851            0.641010\n",
      "     12                0.59998464         0.032981  0.105115         1.661668       0.025346  0.051175                  0.400665          0.395095      0.010508                 0.996975   -89.488487        66.166753            0.523128\n",
      "     13                0.69998848         0.015024  0.025473         1.427913       0.006142  0.022748                  0.344302          0.341899      0.002547                 0.999522   -97.452733        42.791259            0.394707\n",
      "     14                0.79999232         0.007259  0.004776         1.250012       0.001152  0.010650                  0.301406          0.300491      0.000478                 1.000000   -99.522387        25.001200            0.263557\n",
      "     15                0.89999616         0.003280  0.000000         1.111116       0.000000  0.005042                  0.267915          0.267662      0.000000                 1.000000  -100.000000        11.111585            0.131779\n",
      "     16                1.00000000         0.000601  0.000000         1.000000       0.000000  0.002400                  0.241122          0.241135      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_4\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.091671124\n",
      " RMSE: 0.3027724\n",
      " AUC: 0.92379546\n",
      " pr_auc: 0.8133871\n",
      " logloss: 0.2881814\n",
      " mean_per_class_error: 0.17065935\n",
      " default threshold: 0.3928610682487488\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4449   503  0.1016  503 / 4,952\n",
      "     1   374  1186  0.2397  374 / 1,560\n",
      "Totals  4823  1689  0.1347  877 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.33 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.990788  4.174359         4.174359       1.000000  0.992651                  1.000000          0.992651      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.986303  4.174359         4.174359       1.000000  0.988460                  1.000000          0.990572      0.041667                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.981499  4.174359         4.174359       1.000000  0.983735                  1.000000          0.988304      0.041667                 0.125641  317.435897       317.435897            0.125641\n",
      "      4                0.04007985         0.971808  4.110138         4.158365       0.984615  0.977535                  0.996169          0.985622      0.041026                 0.166667  311.013807       315.836526            0.166465\n",
      "      5                0.05006143         0.956452  4.174359         4.161554       1.000000  0.964605                  0.996933          0.981432      0.041667                 0.208333  317.435897       316.155419            0.208131\n",
      "      6                0.10012285         0.799844  3.431682         3.796618       0.822086  0.872706                  0.909509          0.927069      0.171795                 0.380128  243.168161       279.661790            0.368214\n",
      "      7                0.15003071         0.659517  2.812876         3.469375       0.673846  0.729568                  0.831116          0.861370      0.140385                 0.520513  181.287574       246.937511            0.487193\n",
      "      8                0.20009214         0.521016  2.407299         3.203652       0.576687  0.592254                  0.767460          0.794039      0.120513                 0.641026  140.729904       220.365232            0.579838\n",
      "      9                0.30006143         0.304333  1.724889         2.710983       0.413210  0.409663                  0.649437          0.665979      0.172436                 0.813462   72.488873       171.098339            0.675134\n",
      "     10                0.40003071         0.162062  0.993895         2.281876       0.238095  0.232434                  0.546641          0.557635      0.099359                 0.912821   -0.610501       128.187608            0.674331\n",
      "     11                0.50000000         0.072601  0.512978         1.928205       0.122888  0.112267                  0.461916          0.468588      0.051282                 0.964103  -48.702194        92.820513            0.610306\n",
      "     12                0.59996929         0.031393  0.237252         1.646452       0.056836  0.049436                  0.394420          0.398747      0.023718                 0.987821  -76.274765        64.645180            0.510034\n",
      "     13                0.69993857         0.015306  0.064122         1.420454       0.015361  0.022385                  0.340281          0.344993      0.006410                 0.994231  -93.587774        42.045432            0.387001\n",
      "     14                0.79990786         0.007355  0.044886         1.248541       0.010753  0.010901                  0.299098          0.303240      0.004487                 0.998718  -95.511442        24.854123            0.261440\n",
      "     15                0.89987715         0.003319  0.006412         1.110550       0.001536  0.005061                  0.266041          0.270114      0.000641                 0.999359  -99.358777        11.055045            0.130821\n",
      "     16                1.00000000         0.000563  0.006402         1.000000       0.001534  0.002454                  0.239558          0.243315      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "      Variable Relative Importance Scaled Importance Percentage\n",
      "  relationship         3841.452148          1.000000   0.298076\n",
      "  capital_gain         2483.854980          0.646593   0.192734\n",
      "     education         2110.858887          0.549495   0.163791\n",
      "    occupation          963.816040          0.250899   0.074787\n",
      "           age          929.434998          0.241949   0.072119\n",
      "marital_status          632.837830          0.164739   0.049105\n",
      "  capital_loss          542.199585          0.141144   0.042072\n",
      "hours_per_week          458.445343          0.119342   0.035573\n",
      "     workclass          299.870728          0.078062   0.023268\n",
      "        fnlwgt          285.120667          0.074222   0.022124\n",
      "native_country          247.284729          0.064373   0.019188\n",
      "           sex           60.761372          0.015817   0.004715\n",
      "          race           31.545815          0.008212   0.002448\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "              70                       70               96744         15         15   15.00000          35         150   102.20000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.135 sec               0       0.42776          0.55237      0.50000         0.24112       1.00000                       0.75888         0.42682            0.55058        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:18  2.325 sec               5       0.35860          0.41495      0.92236         0.81215       4.14727                       0.14715         0.35971            0.41690        0.91361           0.78691         4.11111                         0.14926\n",
      " 2023-10-20 18:27:19  3.727 sec              10       0.32553          0.35282      0.92723         0.82308       4.14727                       0.14404         0.32999            0.35969        0.91607           0.79172         4.11111                         0.14911\n",
      " 2023-10-20 18:27:20  4.758 sec              15       0.31076          0.32117      0.92899         0.82770       4.14727                       0.13379         0.31793            0.33213        0.91636           0.79400         4.11111                         0.14911\n",
      " 2023-10-20 18:27:21  5.522 sec              20       0.30160          0.29941      0.93197         0.83348       4.14727                       0.12910         0.31148            0.31485        0.91790           0.79767         4.11111                         0.13606\n",
      " 2023-10-20 18:27:22  6.209 sec              25       0.29676          0.28677      0.93418         0.83782       4.14727                       0.12834         0.30938            0.30709        0.91806           0.79857         4.11111                         0.14128\n",
      " 2023-10-20 18:27:22  6.891 sec              30       0.29258          0.27668      0.93696         0.84379       4.14727                       0.13724         0.30749            0.30111        0.91920           0.80120         4.11111                         0.13943\n",
      " 2023-10-20 18:27:23  7.513 sec              35       0.28917          0.26912      0.93940         0.84903       4.14727                       0.12956         0.30626            0.29748        0.92002           0.80389         4.11111                         0.13682\n",
      " 2023-10-20 18:27:24  8.256 sec              40       0.28628          0.26290      0.94158         0.85381       4.14727                       0.12077         0.30459            0.29363        0.92153           0.80805         4.17436                         0.13483\n",
      " 2023-10-20 18:27:25  9.126 sec              45       0.28386          0.25795      0.94339         0.85794       4.14727                       0.11954         0.30367            0.29136        0.92243           0.81043         4.17436                         0.13636\n",
      " 2023-10-20 18:27:25  9.934 sec              50       0.28150          0.25323      0.94527         0.86212       4.14727                       0.11970         0.30310            0.28983        0.92305           0.81188         4.17436                         0.13467\n",
      " 2023-10-20 18:27:26 10.558 sec              55       0.27916          0.24891      0.94721         0.86623       4.14727                       0.11828         0.30316            0.28958        0.92303           0.81170         4.17436                         0.13682\n",
      " 2023-10-20 18:27:27 11.118 sec              60       0.27723          0.24545      0.94876         0.86953       4.14727                       0.11620         0.30313            0.28920        0.92325           0.81225         4.17436                         0.13713\n",
      " 2023-10-20 18:27:28 11.949 sec              65       0.27551          0.24242      0.95004         0.87247       4.14727                       0.11302         0.30297            0.28864        0.92359           0.81266         4.17436                         0.13652\n",
      " 2023-10-20 18:27:28 12.689 sec              70       0.27371          0.23939      0.95145         0.87574       4.14727                       0.11240         0.30277            0.28818        0.92380           0.81339         4.17436                         0.13467\n",
      "\n",
      "10-20 18:27:28.920 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Completing model GBM_1_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:28.927 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_237\n",
      "10-20 18:27:28.943 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_237\n",
      "10-20 18:27:28.946 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2812471048137481, 0.28026258685949584, 0.27974500956482423, 0.27949747834003236]\n",
      "10-20 18:27:28.946 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.2812471048137481 --> 0.27949747834003236 (still improving).\n",
      "10-20 18:27:28.967 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 72. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:28.967) \n",
      "10-20 18:27:29.029 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 71. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:29.029) \n",
      "10-20 18:27:29.039 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 73. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:29.039) \n",
      "10-20 18:27:29.093 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 72. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:29.093) \n",
      "10-20 18:27:29.098 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 74. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:29.098) \n",
      "█10-20 18:27:29.144 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 73. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:29.144) \n",
      "10-20 18:27:29.146 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 75. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:29.146) \n",
      "10-20 18:27:29.147 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:29.166 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_238\n",
      "10-20 18:27:29.190 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_238\n",
      "10-20 18:27:29.211 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 74. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:29.211) \n",
      "10-20 18:27:29.228 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_239\n",
      "10-20 18:27:29.242 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_239\n",
      "10-20 18:27:29.246 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28644951508606686, 0.2851807097949544, 0.28436925511191036, 0.283724181478707]\n",
      "10-20 18:27:29.247 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.28644951508606686 --> 0.283724181478707 (still improving).\n",
      "10-20 18:27:29.262 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 75. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:29.262) \n",
      "10-20 18:27:29.263 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:29.279 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_240\n",
      "10-20 18:27:29.297 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_240\n",
      "10-20 18:27:29.319 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 76. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:29.319) \n",
      "10-20 18:27:29.336 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_241\n",
      "10-20 18:27:29.351 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_241\n",
      "10-20 18:27:29.359 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28026258685949584, 0.27974500956482423, 0.27949747834003236, 0.27926756886406934]\n",
      "10-20 18:27:29.359 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.28026258685949584 --> 0.27926756886406934 (converged).\n",
      "10-20 18:27:29.362 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.074146375\n",
      " RMSE: 0.2722983\n",
      " AUC: 0.9530781\n",
      " pr_auc: 0.87878\n",
      " logloss: 0.23710607\n",
      " mean_per_class_error: 0.13795128\n",
      " default threshold: 0.3917079269886017\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18136  1602  0.0812  1,602 / 19,738\n",
      "     1   1229  5082  0.1947   1,229 / 6,311\n",
      "Totals  19365  6684  0.1087  2,831 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.21 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991817  4.127555         4.127555       1.000000  0.993469                  1.000000          0.993469      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.988365  4.127555         4.127555       1.000000  0.990087                  1.000000          0.991781      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.982646  4.127555         4.127555       1.000000  0.985721                  1.000000          0.989759      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.973973  4.127555         4.127555       1.000000  0.978790                  1.000000          0.987022      0.041198                 0.165109   312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.955541  4.111741         4.124387       0.996169  0.966162                  0.999233          0.982843      0.041198                 0.206306   311.174068       312.438733            0.206256\n",
      "      6                0.10000384         0.787543  3.870772         3.997628       0.937788  0.868372                  0.968522          0.925630      0.193472                 0.399778   287.077168       299.762819            0.395624\n",
      "      7                0.15002495         0.656125  3.253261         3.749442       0.788181  0.720523                  0.908393          0.857243      0.162732                 0.562510   225.326097       274.944229            0.544372\n",
      "      8                0.20000768         0.526435  2.567834         3.454154       0.622120  0.591934                  0.836852          0.790941      0.128347                 0.690857   156.783379       245.415356            0.647793\n",
      "      9                0.30001152         0.307745  1.765104         2.891137       0.427639  0.408414                  0.700448          0.663432      0.176517                 0.867374    76.510416       189.113710            0.748771\n",
      "     10                0.40001536         0.157498  0.892059         2.391368       0.216123  0.227646                  0.579367          0.554486      0.089209                 0.956584   -10.794107       139.136755            0.734525\n",
      "     11                0.50001919         0.072711  0.308972         1.974889       0.074856  0.110973                  0.478464          0.465783      0.030898                 0.987482   -69.102755        97.488853            0.643324\n",
      "     12                0.59998464         0.032600  0.109371         1.664068       0.026498  0.049987                  0.403161          0.396506      0.010933                 0.998415   -89.062930        66.406836            0.525825\n",
      "     13                0.69998848         0.015473  0.014260         1.428369       0.003455  0.022875                  0.346057          0.343127      0.001426                 0.999842   -98.573973        42.836857            0.395728\n",
      "     14                0.79999232         0.007608  0.001584         1.250012       0.000384  0.011017                  0.302846          0.301611      0.000158                 1.000000   -99.841553        25.001200            0.263958\n",
      "     15                0.89999616         0.003700  0.000000         1.111116       0.000000  0.005469                  0.269195          0.268705      0.000000                 1.000000  -100.000000        11.111585            0.131979\n",
      "     16                1.00000000         0.000279  0.000000         1.000000       0.000000  0.002555                  0.242274          0.242089      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_2\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.088985816\n",
      " RMSE: 0.2983049\n",
      " AUC: 0.92669505\n",
      " pr_auc: 0.81941515\n",
      " logloss: 0.27909827\n",
      " mean_per_class_error: 0.17145646\n",
      " default threshold: 0.34263283014297485\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4397   585  0.1174  585 / 4,982\n",
      "     1   345  1185  0.2255  345 / 1,530\n",
      "Totals  4742  1770  0.1428  930 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.64 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.991508  4.256209         4.256209       1.000000  0.993357                  1.000000          0.993357      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.987910  4.256209         4.256209       1.000000  0.989908                  1.000000          0.991646      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.983243  4.256209         4.256209       1.000000  0.985825                  1.000000          0.989715      0.042484                 0.128105   325.620915       325.620915            0.128105\n",
      "      4                0.04007985         0.972782  4.125249         4.223595       0.969231  0.978232                  0.992337          0.986856      0.041176                 0.169281   312.524887       322.359452            0.168880\n",
      "      5                0.05006143         0.946697  4.256209         4.230097       1.000000  0.962474                  0.993865          0.981994      0.042484                 0.211765   325.620915       323.009744            0.211363\n",
      "      6                0.10012285         0.780943  3.694807         3.962452       0.868098  0.861126                  0.930982          0.921560      0.184967                 0.396732   269.480733       296.245238            0.387700\n",
      "      7                0.15003071         0.629568  2.868030         3.598392       0.673846  0.701702                  0.845445          0.848424      0.143137                 0.539869   186.803017       259.839177            0.509560\n",
      "      8                0.20009214         0.500709  2.193384         3.246870       0.515337  0.565568                  0.762855          0.777656      0.109804                 0.649673   119.338386       224.687022            0.587650\n",
      "      9                0.30006143         0.288981  1.621413         2.705328       0.380952  0.390636                  0.635619          0.648715      0.162092                 0.811765    62.141301       170.532844            0.668850\n",
      "     10                0.40003071         0.155966  1.046073         2.290674       0.245776  0.218063                  0.538196          0.541094      0.104575                 0.916340     4.607291       129.067379            0.674871\n",
      "     11                0.50000000         0.073009  0.549188         1.942484       0.129032  0.110272                  0.456388          0.454956      0.054902                 0.971242   -45.081172        94.248366            0.615963\n",
      "     12                0.59996929         0.030930  0.196139         1.651501       0.046083  0.048985                  0.388021          0.387311      0.019608                 0.990850   -80.386133        65.150066            0.510922\n",
      "     13                0.69993857         0.014898  0.052304         1.423094       0.012289  0.021948                  0.334357          0.335128      0.005229                 0.996078   -94.769635        42.309406            0.387086\n",
      "     14                0.79990786         0.007188  0.032690         1.249327       0.007680  0.010539                  0.293530          0.294562      0.003268                 0.999346   -96.731022        24.932689            0.260687\n",
      "     15                0.89987715         0.003436  0.006538         1.111263       0.001536  0.005033                  0.261092          0.262398      0.000654                 1.000000   -99.346204        11.126280            0.130871\n",
      "     16                1.00000000         0.000379  0.000000         1.000000       0.000000  0.002431                  0.234951          0.236369      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "      Variable Relative Importance Scaled Importance Percentage\n",
      "  relationship         3708.336426          1.000000   0.285082\n",
      "  capital_gain         2478.645996          0.668398   0.190548\n",
      "     education         2079.913330          0.560875   0.159895\n",
      "           age          956.353821          0.257893   0.073521\n",
      "    occupation          935.069763          0.252153   0.071884\n",
      "marital_status          847.467834          0.228530   0.065150\n",
      "hours_per_week          559.622070          0.150909   0.043022\n",
      "  capital_loss          549.110596          0.148075   0.042213\n",
      "     workclass          298.536743          0.080504   0.022950\n",
      "        fnlwgt          295.244507          0.079616   0.022697\n",
      "native_country          215.201736          0.058032   0.016544\n",
      "           sex           48.765499          0.013150   0.003749\n",
      "          race           35.691299          0.009625   0.002744\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "              75                       75              103028         15         15   15.00000          38         154   101.58667\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.157 sec               0       0.42846          0.55369      0.50000         0.24227       1.00000                       0.75773         0.42403            0.54534        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:18  2.341 sec               5       0.35954          0.41648      0.92270         0.81043       4.12756                       0.14630         0.35805            0.41441        0.91580           0.79467         4.25621                         0.13974\n",
      " 2023-10-20 18:27:19  3.655 sec              10       0.32693          0.35500      0.92623         0.81979       4.12756                       0.14377         0.32778            0.35678        0.91778           0.80150         4.25621                         0.13360\n",
      " 2023-10-20 18:27:20  4.685 sec              15       0.31202          0.32299      0.92817         0.82485       4.11174                       0.13870         0.31487            0.32781        0.91863           0.80399         4.25621                         0.13529\n",
      " 2023-10-20 18:27:21  5.409 sec              20       0.30270          0.30097      0.93152         0.83163       4.12756                       0.13348         0.30742            0.30868        0.92120           0.80852         4.25621                         0.13406\n",
      " 2023-10-20 18:27:22  6.025 sec              25       0.29756          0.28781      0.93411         0.83678       4.12756                       0.13079         0.30441            0.29897        0.92209           0.81013         4.25621                         0.13176\n",
      " 2023-10-20 18:27:22  6.825 sec              30       0.29315          0.27785      0.93694         0.84357       4.12756                       0.12953         0.30211            0.29221        0.92361           0.81355         4.25621                         0.14435\n",
      " 2023-10-20 18:27:23  7.463 sec              35       0.28941          0.26966      0.93974         0.84956       4.12756                       0.12642         0.30080            0.28782        0.92463           0.81498         4.25621                         0.14788\n",
      " 2023-10-20 18:27:24  8.209 sec              40       0.28617          0.26287      0.94218         0.85497       4.12756                       0.12319         0.29989            0.28483        0.92516           0.81632         4.25621                         0.14312\n",
      " 2023-10-20 18:27:25  9.017 sec              45       0.28384          0.25791      0.94400         0.85873       4.12756                       0.12143         0.29911            0.28274        0.92573           0.81751         4.25621                         0.14880\n",
      " 2023-10-20 18:27:26  9.985 sec              50       0.28180          0.25394      0.94549         0.86210       4.12756                       0.11643         0.29841            0.28096        0.92641           0.81912         4.25621                         0.14312\n",
      " 2023-10-20 18:27:26 10.646 sec              55       0.27966          0.24982      0.94718         0.86581       4.12756                       0.11198         0.29819            0.28004        0.92656           0.81957         4.25621                         0.14036\n",
      " 2023-10-20 18:27:27 11.180 sec              60       0.27785          0.24661      0.94861         0.86903       4.12756                       0.11137         0.29816            0.27979        0.92660           0.81961         4.25621                         0.14220\n",
      " 2023-10-20 18:27:28 12.050 sec              65       0.27605          0.24350      0.95006         0.87224       4.12756                       0.11187         0.29819            0.27941        0.92665           0.81971         4.25621                         0.14235\n",
      " 2023-10-20 18:27:28 12.779 sec              70       0.27435          0.24050      0.95147         0.87528       4.12756                       0.11014         0.29828            0.27930        0.92666           0.81947         4.25621                         0.14128\n",
      " 2023-10-20 18:27:29 13.205 sec              75       0.27230          0.23711      0.95308         0.87878       4.12756                       0.10868         0.29830            0.27910        0.92670           0.81942         4.25621                         0.14281\n",
      "\n",
      "10-20 18:27:29.485 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model GBM_1_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:29.502 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 77. tree was built in 00:00:00.183 (Wall: 20-Oct 18:27:29.502) \n",
      "10-20 18:27:29.602 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:29.691 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 78. tree was built in 00:00:00.185 (Wall: 20-Oct 18:27:29.690) \n",
      "10-20 18:27:29.760 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 79. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:29.760) \n",
      "10-20 18:27:29.840 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 80. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:29.840) \n",
      "10-20 18:27:29.841 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:29.879 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_242\n",
      "10-20 18:27:29.925 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_242\n",
      "10-20 18:27:29.958 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_243\n",
      "10-20 18:27:29.983 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_243\n",
      "10-20 18:27:29.987 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2851807097949544, 0.28436925511191036, 0.283724181478707, 0.2835048640878355]\n",
      "10-20 18:27:29.987 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2851807097949544 --> 0.2835048640878355 (still improving).\n",
      "10-20 18:27:30.037 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 81. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:30.037) \n",
      "█10-20 18:27:30.114 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 82. tree was built in 00:00:00.076 (Wall: 20-Oct 18:27:30.114) \n",
      "10-20 18:27:30.162 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 83. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:30.162) \n",
      "10-20 18:27:30.242 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 84. tree was built in 00:00:00.079 (Wall: 20-Oct 18:27:30.242) \n",
      "10-20 18:27:30.298 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 85. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:30.298) \n",
      "10-20 18:27:30.299 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:30.318 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_244\n",
      "10-20 18:27:30.340 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_244\n",
      "10-20 18:27:30.366 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_245\n",
      "10-20 18:27:30.384 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_245\n",
      "10-20 18:27:30.388 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28436925511191036, 0.283724181478707, 0.2835048640878355, 0.28346193706738326]\n",
      "10-20 18:27:30.389 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.28436925511191036 --> 0.28346193706738326 (converged).\n",
      "10-20 18:27:30.389 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Cross-Validation model 1 / 5 built total of 85 trees, however the best score was obtained using only ntrees=80. Trimming model to 80 trees.\n",
      "10-20 18:27:30.392 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.0724765\n",
      " RMSE: 0.2692146\n",
      " AUC: 0.9550251\n",
      " pr_auc: 0.88085663\n",
      " logloss: 0.23155262\n",
      " mean_per_class_error: 0.1346897\n",
      " default threshold: 0.38595500588417053\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18240  1593  0.0803  1,593 / 19,833\n",
      "     1   1175  5040  0.1891   1,175 / 6,215\n",
      "Totals  19415  6633  0.1063  2,768 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.85 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.992991  4.191150         4.191150       1.000000  0.994747                  1.000000          0.994747      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.989346  4.191150         4.191150       1.000000  0.991404                  1.000000          0.993079      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.983294  4.191150         4.191150       1.000000  0.986596                  1.000000          0.990915      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.972748  4.191150         4.191150       1.000000  0.978431                  1.000000          0.987800      0.041834                 0.167659   319.115044       319.115044            0.167659\n",
      "      5                0.05002303         0.950944  4.175092         4.187934       0.996169  0.962696                  0.999233          0.982772      0.041834                 0.209493   317.509239       318.793390            0.209443\n",
      "      6                0.10000768         0.785608  3.895002         4.041524       0.929339  0.865952                  0.964299          0.924384      0.194690                 0.404183   289.500156       304.152396            0.399494\n",
      "      7                0.15003071         0.645891  3.322685         3.801850       0.792786  0.714483                  0.907114          0.854399      0.166211                 0.570394   232.268489       280.184962            0.552091\n",
      "      8                0.20001536         0.512472  2.626712         3.508178       0.626728  0.580530                  0.837044          0.785958      0.131295                 0.701689   162.671180       250.817794            0.658882\n",
      "      9                0.30002303         0.301868  1.690940         2.902432       0.403455  0.397999                  0.692514          0.656638      0.169107                 0.870796    69.094016       190.243201            0.749635\n",
      "     10                0.40003071         0.157560  0.900977         2.402068       0.214971  0.225014                  0.573129          0.548732      0.090105                 0.960901    -9.902332       140.206818            0.736628\n",
      "     11                0.50000000         0.068535  0.300977         1.981979       0.071813  0.108156                  0.472896          0.460644      0.030088                 0.990990   -69.902261        98.197908            0.644849\n",
      "     12                0.60000768         0.029301  0.067573         1.662891       0.016123  0.045983                  0.396762          0.391529      0.006758                 0.997747   -93.242675        66.289103            0.522378\n",
      "     13                0.69997697         0.013217  0.019314         1.428159       0.004608  0.020144                  0.340756          0.338489      0.001931                 0.999678   -98.068594        42.815871            0.393618\n",
      "     14                0.79998464         0.006127  0.003218         1.250024       0.000768  0.009232                  0.298253          0.297328      0.000322                 1.000000   -99.678223        25.002399            0.262693\n",
      "     15                0.89999232         0.002855  0.000000         1.111121       0.000000  0.004313                  0.265111          0.264768      0.000000                 1.000000  -100.000000        11.112059            0.131347\n",
      "     16                1.00000000         0.000298  0.000000         1.000000       0.000000  0.001818                  0.238598          0.238471      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_1\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09012657\n",
      " RMSE: 0.30021086\n",
      " AUC: 0.92819107\n",
      " pr_auc: 0.83472997\n",
      " logloss: 0.2837649\n",
      " mean_per_class_error: 0.16019475\n",
      " default threshold: 0.30709370970726013\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4268   619  0.1267  619 / 4,887\n",
      "     1   315  1311  0.1937  315 / 1,626\n",
      "Totals  4583  1930  0.1434  934 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.99 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.992412  4.005535         4.005535       1.000000  0.994489                  1.000000          0.994489      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.988872  4.005535         4.005535       1.000000  0.990553                  1.000000          0.992536      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.983294  4.005535         4.005535       1.000000  0.986542                  1.000000          0.990548      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.974068  4.005535         4.005535       1.000000  0.979091                  1.000000          0.987695      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.953773  4.005535         4.005535       1.000000  0.964585                  1.000000          0.983087      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.792244  3.526345         3.765940       0.880368  0.874717                  0.940184          0.928902      0.176507                 0.376999   252.634528       276.594017            0.369018\n",
      "      7                0.15000768         0.647226  2.933284         3.488956       0.732308  0.720766                  0.871034          0.859665      0.146371                 0.523370   193.328413       248.895633            0.497588\n",
      "      8                0.20006142         0.522806  2.371375         3.209347       0.592025  0.584892                  0.801228          0.790919      0.118696                 0.642066   137.137505       220.934658            0.589069\n",
      "      9                0.30001535         0.299819  1.685893         2.701789       0.420891  0.402677                  0.674514          0.661571      0.168512                 0.810578    68.589340       170.178874            0.680437\n",
      "     10                0.39996929         0.153748  1.021381         2.281848       0.254992  0.219813                  0.569674          0.551174      0.102091                 0.912669     2.138067       128.184799            0.683285\n",
      "     11                0.50007677         0.070018  0.497620         1.924674       0.124233  0.109415                  0.480504          0.462741      0.049815                 0.962485   -50.237985        92.467374            0.616260\n",
      "     12                0.60003071         0.030055  0.227657         1.641982       0.056836  0.047688                  0.409928          0.393601      0.022755                 0.985240   -77.234286        64.198238            0.513376\n",
      "     13                0.69998465         0.013912  0.116905         1.424210       0.029186  0.021051                  0.355560          0.340403      0.011685                 0.996925   -88.309498        42.420977            0.395738\n",
      "     14                0.79993858         0.006464  0.024612         1.249327       0.006144  0.009785                  0.311900          0.299091      0.002460                 0.999385   -97.538842        24.932715            0.265806\n",
      "     15                0.89989252         0.002764  0.006153         1.111244       0.001536  0.004412                  0.277427          0.266360      0.000615                 1.000000   -99.384710        11.124382            0.133415\n",
      "     16                1.00000000         0.000241  0.000000         1.000000       0.000000  0.001783                  0.249655          0.239874      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "      Variable Relative Importance Scaled Importance Percentage\n",
      "  relationship         3553.017334          1.000000   0.274532\n",
      "  capital_gain         2466.657959          0.694243   0.190592\n",
      "     education         2090.691650          0.588427   0.161542\n",
      "marital_status          986.072327          0.277531   0.076191\n",
      "    occupation          929.303467          0.261553   0.071805\n",
      "           age          888.905945          0.250183   0.068683\n",
      "  capital_loss          562.924011          0.158435   0.043496\n",
      "hours_per_week          542.708557          0.152746   0.041934\n",
      "        fnlwgt          311.702362          0.087729   0.024084\n",
      "     workclass          296.880280          0.083557   0.022939\n",
      "native_country          225.795883          0.063550   0.017447\n",
      "           sex           47.594234          0.013395   0.003677\n",
      "          race           39.828312          0.011210   0.003077\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "              80                       85              115167         15         15   15.00000          35         156   100.05882\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:16  0.147 sec               0       0.42623          0.54946      0.50000         0.23860       1.00000                       0.76140         0.43295            0.56229        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:18  2.319 sec               5       0.35796          0.41338      0.92191         0.80681       4.19115                       0.13824         0.36486            0.42494        0.91586           0.80615         4.00554                         0.14878\n",
      " 2023-10-20 18:27:19  3.657 sec              10       0.32567          0.35239      0.92573         0.81608       4.19115                       0.14362         0.33348            0.36536        0.91799           0.81378         4.00554                         0.14863\n",
      " 2023-10-20 18:27:20  4.654 sec              15       0.31092          0.32069      0.92784         0.82166       4.19115                       0.13882         0.32005            0.33600        0.91848           0.81616         4.00554                         0.15016\n",
      " 2023-10-20 18:27:21  5.406 sec              20       0.30226          0.29975      0.93058         0.82717       4.19115                       0.13978         0.31302            0.31798        0.91976           0.81821         4.00554                         0.14770\n",
      " 2023-10-20 18:27:22  6.077 sec              25       0.29765          0.28755      0.93273         0.83136       4.19115                       0.13268         0.30957            0.30806        0.92097           0.82048         4.00554                         0.14525\n",
      " 2023-10-20 18:27:22  6.849 sec              30       0.29366          0.27783      0.93544         0.83735       4.19115                       0.13084         0.30723            0.30128        0.92231           0.82321         4.00554                         0.15308\n",
      " 2023-10-20 18:27:23  7.460 sec              35       0.29004          0.27009      0.93826         0.84354       4.19115                       0.12684         0.30541            0.29641        0.92388           0.82576         4.00554                         0.15262\n",
      " 2023-10-20 18:27:24  8.239 sec              40       0.28673          0.26334      0.94088         0.84946       4.19115                       0.12062         0.30406            0.29288        0.92493           0.82789         4.00554                         0.14770\n",
      " 2023-10-20 18:27:25  9.106 sec              45       0.28455          0.25882      0.94261         0.85307       4.19115                       0.12193         0.30274            0.28983        0.92609           0.83036         4.00554                         0.13987\n",
      " 2023-10-20 18:27:25  9.894 sec              50       0.28216          0.25422      0.94448         0.85739       4.19115                       0.11652         0.30182            0.28773        0.92677           0.83196         4.00554                         0.14770\n",
      " 2023-10-20 18:27:26 10.556 sec              55       0.28001          0.25001      0.94640         0.86131       4.19115                       0.11341         0.30115            0.28633        0.92732           0.83306         4.00554                         0.14648\n",
      " 2023-10-20 18:27:27 11.164 sec              60       0.27808          0.24654      0.94792         0.86487       4.19115                       0.11145         0.30074            0.28529        0.92771           0.83391         4.00554                         0.14632\n",
      " 2023-10-20 18:27:28 12.017 sec              65       0.27645          0.24361      0.94928         0.86792       4.19115                       0.10984         0.30009            0.28393        0.92829           0.83518         4.00554                         0.14479\n",
      " 2023-10-20 18:27:28 12.653 sec              70       0.27483          0.24083      0.95056         0.87082       4.19115                       0.10903         0.30026            0.28389        0.92828           0.83460         4.00554                         0.14402\n",
      " 2023-10-20 18:27:29 13.089 sec              75       0.27298          0.23777      0.95204         0.87418       4.19115                       0.11137         0.30012            0.28335        0.92850           0.83492         4.00554                         0.14387\n",
      " 2023-10-20 18:27:29 13.783 sec              80       0.27123          0.23479      0.95342         0.87723       4.19115                       0.10822         0.30002            0.28327        0.92854           0.83494         4.00554                         0.14402\n",
      " 2023-10-20 18:27:30 14.241 sec              85       0.26921          0.23155      0.95503         0.88086       4.19115                       0.10627         0.30021            0.28376        0.92819           0.83473         4.00554                         0.14341\n",
      "\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model GBM_1_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Building cross-validation model 5 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:30.407 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:30.408 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:30.408 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_5_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_1_AutoML_1_20231020_182658_cv_5_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":43,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":4,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":15,\"_min_rows\":100.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:30.409 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:30.420 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:30.441 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model GBM_1_AutoML_1_20231020_182658_cv_5\n",
      "10-20 18:27:30.442 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Prior class distribution: [0.7599523974048907, 0.2400476025951092]\n",
      "10-20 18:27:30.445 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model class distribution: [0.7599523974048907, 0.2400476025951092]\n",
      "10-20 18:27:30.460 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:30.476 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_246\n",
      "10-20 18:27:30.482 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_246\n",
      "10-20 18:27:30.495 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_247\n",
      "10-20 18:27:30.499 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_247\n",
      "10-20 18:27:30.502 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.18242475\n",
      " RMSE: 0.4271121\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2400476\n",
      " logloss: 0.55113477\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.2400476038455963\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19796  1.0000  19,796 / 19,796\n",
      "     1  0   6253  0.0000        0 / 6,253\n",
      "Totals  0  26049  0.7600  19,796 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.240048  1.000000         1.000000       0.240048  0.240048                  0.240048          0.240048      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.18440554\n",
      " RMSE: 0.42942464\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24385749\n",
      " logloss: 0.55552536\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.2400476038455963\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4924  1.0000  4,924 / 4,924\n",
      "     1  0  1588  0.0000      0 / 1,588\n",
      "Totals  0  6512  0.7561  4,924 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.240048  1.000000         1.000000       0.243857  0.240048                  0.243857          0.240048      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:30 14.384 sec               0       0.42711          0.55113      0.50000         0.24005       1.00000                       0.75995         0.42942            0.55553        0.50000           0.24386         1.00000                         0.75614\n",
      "\n",
      "10-20 18:27:30.577 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:30.576) \n",
      "10-20 18:27:30.613 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:30.612) \n",
      "10-20 18:27:30.651 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:30.651) \n",
      "10-20 18:27:30.696 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:30.696) \n",
      "10-20 18:27:30.750 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:30.750) \n",
      "10-20 18:27:30.751 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:30.761 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:30.773 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_248\n",
      "10-20 18:27:30.793 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_248\n",
      "10-20 18:27:30.815 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_249\n",
      "10-20 18:27:30.826 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_249\n",
      "10-20 18:27:30.876 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:30.876) \n",
      "10-20 18:27:30.924 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:30.924) \n",
      "█10-20 18:27:30.990 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:30.990) \n",
      "10-20 18:27:31.061 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:31.061) \n",
      "10-20 18:27:31.128 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:31.128) \n",
      "10-20 18:27:31.129 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:31.145 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_250\n",
      "10-20 18:27:31.168 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_250\n",
      "10-20 18:27:31.192 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_251\n",
      "10-20 18:27:31.204 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_251\n",
      "10-20 18:27:31.236 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:31.235) \n",
      "10-20 18:27:31.271 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:31.271) \n",
      "10-20 18:27:31.305 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:31.305) \n",
      "10-20 18:27:31.333 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:31.333) \n",
      "10-20 18:27:31.362 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:31.362) \n",
      "10-20 18:27:31.363 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:31.374 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_252\n",
      "10-20 18:27:31.387 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_252\n",
      "10-20 18:27:31.408 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_253\n",
      "10-20 18:27:31.421 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_253\n",
      "10-20 18:27:31.460 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:31.460) \n",
      "10-20 18:27:31.492 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:31.492) \n",
      "10-20 18:27:31.534 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:31.534) \n",
      "10-20 18:27:31.583 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:31.583) \n",
      "10-20 18:27:31.627 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:31.627) \n",
      "10-20 18:27:31.628 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:31.643 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_254\n",
      "10-20 18:27:31.663 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_254\n",
      "10-20 18:27:31.688 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_255\n",
      "10-20 18:27:31.704 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_255\n",
      "10-20 18:27:31.749 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:31.749) \n",
      "10-20 18:27:31.789 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:31.789) \n",
      "10-20 18:27:31.821 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:31.821) \n",
      "10-20 18:27:31.858 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:31.858) \n",
      "10-20 18:27:31.892 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:31.892) \n",
      "10-20 18:27:31.893 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:31.910 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_256\n",
      "10-20 18:27:31.916 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:31.951 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_256\n",
      "10-20 18:27:31.974 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_257\n",
      "10-20 18:27:31.988 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_257\n",
      "10-20 18:27:32.043 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:32.043) \n",
      "10-20 18:27:32.112 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:32.112) \n",
      "10-20 18:27:32.154 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:32.154) \n",
      "10-20 18:27:32.200 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:32.200) \n",
      "10-20 18:27:32.274 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:32.274) \n",
      "10-20 18:27:32.275 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:32.307 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_258\n",
      "10-20 18:27:32.326 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_258\n",
      "10-20 18:27:32.369 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_259\n",
      "10-20 18:27:32.390 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_259\n",
      "10-20 18:27:32.396 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.37251978332934305, 0.33675493093316317, 0.3172171471675841, 0.3057440326950919]\n",
      "10-20 18:27:32.396 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.37251978332934305 --> 0.3057440326950919 (still improving).\n",
      "10-20 18:27:32.463 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:32.463) \n",
      "10-20 18:27:32.550 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.087 (Wall: 20-Oct 18:27:32.550) \n",
      "10-20 18:27:32.641 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:32.641) \n",
      "10-20 18:27:32.696 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:32.696) \n",
      "10-20 18:27:32.752 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:32.752) \n",
      "10-20 18:27:32.753 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:32.770 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_260\n",
      "10-20 18:27:32.789 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_260\n",
      "10-20 18:27:32.829 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:32.831 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_261\n",
      "█10-20 18:27:32.845 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_261\n",
      "10-20 18:27:32.848 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.33675493093316317, 0.3172171471675841, 0.3057440326950919, 0.2990658040715838]\n",
      "10-20 18:27:32.848 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.33675493093316317 --> 0.2990658040715838 (still improving).\n",
      "10-20 18:27:32.893 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:32.893) \n",
      "10-20 18:27:32.934 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:32.934) \n",
      "10-20 18:27:32.997 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:32.997) \n",
      "10-20 18:27:33.052 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:33.052) \n",
      "10-20 18:27:33.090 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:33.090) \n",
      "10-20 18:27:33.091 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:33.105 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_262\n",
      "10-20 18:27:33.124 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_262\n",
      "10-20 18:27:33.145 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_263\n",
      "10-20 18:27:33.156 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_263\n",
      "10-20 18:27:33.160 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3172171471675841, 0.3057440326950919, 0.2990658040715838, 0.29465820925662906]\n",
      "10-20 18:27:33.160 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3172171471675841 --> 0.29465820925662906 (still improving).\n",
      "10-20 18:27:33.196 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:33.196) \n",
      "10-20 18:27:33.244 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:33.244) \n",
      "10-20 18:27:33.280 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:33.280) \n",
      "10-20 18:27:33.327 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:33.327) \n",
      "10-20 18:27:33.379 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:33.379) \n",
      "10-20 18:27:33.380 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:33.392 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_264\n",
      "10-20 18:27:33.410 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_264\n",
      "10-20 18:27:33.434 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_265\n",
      "10-20 18:27:33.456 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_265\n",
      "10-20 18:27:33.462 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3057440326950919, 0.2990658040715838, 0.29465820925662906, 0.2912496236547903]\n",
      "10-20 18:27:33.463 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3057440326950919 --> 0.2912496236547903 (still improving).\n",
      "10-20 18:27:33.530 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:33.530) \n",
      "10-20 18:27:33.569 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:33.569) \n",
      "10-20 18:27:33.612 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:33.612) \n",
      "10-20 18:27:33.645 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:33.645) \n",
      "10-20 18:27:33.677 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 50. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:33.677) \n",
      "10-20 18:27:33.678 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:33.689 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_266\n",
      "10-20 18:27:33.706 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_266\n",
      "10-20 18:27:33.727 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_267\n",
      "10-20 18:27:33.742 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_267\n",
      "10-20 18:27:33.745 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2990658040715838, 0.29465820925662906, 0.2912496236547903, 0.28862247643435013]\n",
      "10-20 18:27:33.745 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2990658040715838 --> 0.28862247643435013 (still improving).\n",
      "█10-20 18:27:33.795 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 51. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:33.795) \n",
      "10-20 18:27:33.837 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 52. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:33.837) \n",
      "10-20 18:27:33.875 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 53. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:33.875) \n",
      "10-20 18:27:33.914 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 54. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:33.914) \n",
      "10-20 18:27:33.949 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 55. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:33.949) \n",
      "10-20 18:27:33.950 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:33.964 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_268\n",
      "10-20 18:27:33.984 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_268\n",
      "10-20 18:27:34.006 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_269\n",
      "10-20 18:27:34.025 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_269\n",
      "10-20 18:27:34.027 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29465820925662906, 0.2912496236547903, 0.28862247643435013, 0.2868617120233558]\n",
      "10-20 18:27:34.028 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29465820925662906 --> 0.2868617120233558 (still improving).\n",
      "10-20 18:27:34.076 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 56. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:34.075) \n",
      "10-20 18:27:34.125 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 57. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:34.125) \n",
      "10-20 18:27:34.165 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 58. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:34.165) \n",
      "10-20 18:27:34.206 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 59. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:34.206) \n",
      "10-20 18:27:34.258 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 60. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:34.258) \n",
      "10-20 18:27:34.261 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:34.262 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:34.287 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_270\n",
      "10-20 18:27:34.329 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_270\n",
      "10-20 18:27:34.489 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_271\n",
      "10-20 18:27:34.510 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_271\n",
      "10-20 18:27:34.515 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2912496236547903, 0.28862247643435013, 0.2868617120233558, 0.2858909535303732]\n",
      "10-20 18:27:34.515 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2912496236547903 --> 0.2858909535303732 (still improving).\n",
      "10-20 18:27:34.587 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 61. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:34.587) \n",
      "10-20 18:27:34.641 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 62. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:34.641) \n",
      "█10-20 18:27:34.697 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 63. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:34.697) \n",
      "10-20 18:27:34.744 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 64. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:34.744) \n",
      "10-20 18:27:34.776 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 65. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:34.776) \n",
      "10-20 18:27:34.777 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:34.787 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_272\n",
      "10-20 18:27:34.801 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_272\n",
      "10-20 18:27:34.822 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_273\n",
      "10-20 18:27:34.837 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_273\n",
      "10-20 18:27:34.840 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28862247643435013, 0.2868617120233558, 0.2858909535303732, 0.2852902584909989]\n",
      "10-20 18:27:34.840 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.28862247643435013 --> 0.2852902584909989 (still improving).\n",
      "10-20 18:27:34.907 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 66. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:34.906) \n",
      "10-20 18:27:34.959 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 67. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:34.959) \n",
      "10-20 18:27:35.008 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 68. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:35.008) \n",
      "10-20 18:27:35.054 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 69. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:35.053) \n",
      "10-20 18:27:35.091 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 70. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:35.091) \n",
      "10-20 18:27:35.091 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:35.104 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_274\n",
      "10-20 18:27:35.119 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_274\n",
      "10-20 18:27:35.143 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_275\n",
      "10-20 18:27:35.156 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_275\n",
      "10-20 18:27:35.159 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2868617120233558, 0.2858909535303732, 0.2852902584909989, 0.2847043183481743]\n",
      "10-20 18:27:35.159 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2868617120233558 --> 0.2847043183481743 (still improving).\n",
      "10-20 18:27:35.190 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 71. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:35.190) \n",
      "10-20 18:27:35.223 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 72. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:35.223) \n",
      "10-20 18:27:35.253 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 73. tree was built in 00:00:00.030 (Wall: 20-Oct 18:27:35.253) \n",
      "10-20 18:27:35.282 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 74. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:35.282) \n",
      "10-20 18:27:35.314 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 75. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:35.314) \n",
      "10-20 18:27:35.315 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:35.326 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_276\n",
      "10-20 18:27:35.342 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_276\n",
      "10-20 18:27:35.364 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_277\n",
      "10-20 18:27:35.378 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_277\n",
      "10-20 18:27:35.381 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2858909535303732, 0.2852902584909989, 0.2847043183481743, 0.2844371843446289]\n",
      "10-20 18:27:35.381 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2858909535303732 --> 0.2844371843446289 (converged).\n",
      "10-20 18:27:35.381 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Cross-Validation model 5 / 5 built total of 75 trees, however the best score was obtained using only ntrees=70. Trimming model to 70 trees.\n",
      "10-20 18:27:35.385 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.074871376\n",
      " RMSE: 0.27362636\n",
      " AUC: 0.9518313\n",
      " pr_auc: 0.8745372\n",
      " logloss: 0.2382569\n",
      " mean_per_class_error: 0.13494216\n",
      " default threshold: 0.344525009393692\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17787  2009  0.1015  2,009 / 19,796\n",
      "     1   1053  5200  0.1684   1,053 / 6,253\n",
      "Totals  18840  7209  0.1175  3,062 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.992103  4.165840         4.165840       1.000000  0.993595                  1.000000          0.993595      0.041740                 0.041740   316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.989091  4.165840         4.165840       1.000000  0.990669                  1.000000          0.992135      0.041580                 0.083320   316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.983934  4.165840         4.165840       1.000000  0.986704                  1.000000          0.990322      0.041740                 0.125060   316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.975177  4.165840         4.165840       1.000000  0.979493                  1.000000          0.987620      0.041580                 0.166640   316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.958538  4.149879         4.162643       0.996169  0.967774                  0.999233          0.983645      0.041580                 0.208220   314.987932       316.264328            0.208170\n",
      "      6                0.10000384         0.792222  3.887478         4.025113       0.933180  0.869867                  0.966219          0.926778      0.194307                 0.402527   288.747779       302.511335            0.398081\n",
      "      7                0.15002495         0.644335  3.200312         3.750109       0.768227  0.717605                  0.900205          0.857036      0.160083                 0.562610   220.031177       275.010914            0.542909\n",
      "      8                0.20000768         0.510743  2.588452         3.459806       0.621352  0.575431                  0.830518          0.786662      0.129378                 0.691988   158.845229       245.980641            0.647383\n",
      "      9                0.30001152         0.302977  1.735101         2.884904       0.416507  0.397937                  0.692514          0.657087      0.173517                 0.865505    73.510051       188.490444            0.744116\n",
      "     10                0.40001536         0.159859  0.901932         2.389161       0.216507  0.227200                  0.573512          0.549615      0.090197                 0.955701    -9.806757       138.916144            0.731211\n",
      "     11                0.50001919         0.071487  0.315037         1.974336       0.075624  0.111597                  0.473935          0.462011      0.031505                 0.987206   -68.496332        97.433649            0.641076\n",
      "     12                0.59998464         0.031472  0.105586         1.662978       0.025346  0.048505                  0.399194          0.393116      0.010555                 0.997761   -89.441418        66.297768            0.523423\n",
      "     13                0.69998848         0.014756  0.019190         1.428138       0.004607  0.021886                  0.342821          0.340080      0.001919                 0.999680   -98.080995        42.813800            0.394356\n",
      "     14                0.79999232         0.007805  0.003198         1.250012       0.000768  0.010857                  0.300062          0.298925      0.000320                 1.000000   -99.680166        25.001200            0.263184\n",
      "     15                0.89999616         0.003958  0.000000         1.111116       0.000000  0.005703                  0.266721          0.266344      0.000000                 1.000000  -100.000000        11.111585            0.131592\n",
      "     16                1.00000000         0.000508  0.000000         1.000000       0.000000  0.002749                  0.240048          0.239983      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658_cv_5\n",
      " frame id: GBM_1_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09003406\n",
      " RMSE: 0.30005676\n",
      " AUC: 0.92717665\n",
      " pr_auc: 0.8225615\n",
      " logloss: 0.2844188\n",
      " mean_per_class_error: 0.15878814\n",
      " default threshold: 0.3410409986972809\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4368   556  0.1129  556 / 4,924\n",
      "     1   325  1263  0.2047  325 / 1,588\n",
      "Totals  4693  1819  0.1353  881 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.992697  4.100756         4.100756       1.000000  0.994094                  1.000000          0.994094      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.989141  3.974579         4.038149       0.969231  0.990835                  0.984733          0.992477      0.039673                 0.081234  297.457857       303.814871            0.080828\n",
      "      3                0.03009828         0.983816  4.037667         4.037989       0.984615  0.986759                  0.984694          0.990581      0.040302                 0.121537  303.766712       303.798900            0.120927\n",
      "      4                0.04007985         0.974049  4.100756         4.053621       1.000000  0.979468                  0.988506          0.987813      0.040932                 0.162469  310.075567       305.362054            0.161859\n",
      "      5                0.05006143         0.952985  4.100756         4.063019       1.000000  0.964803                  0.990798          0.983225      0.040932                 0.203401  310.075567       306.301865            0.202791\n",
      "      6                0.10012285         0.778410  3.471805         3.767412       0.846626  0.858217                  0.918712          0.920721      0.173804                 0.377204  247.180541       276.741203            0.366440\n",
      "      7                0.15003071         0.641579  2.939926         3.492148       0.716923  0.709121                  0.851586          0.850332      0.146725                 0.523929  193.992637       249.214812            0.494482\n",
      "      8                0.20009214         0.509273  2.452906         3.232138       0.598160  0.574986                  0.788181          0.781443      0.122796                 0.646725  145.290600       223.213820            0.590673\n",
      "      9                0.30006143         0.303460  1.732270         2.732438       0.422427  0.400214                  0.666325          0.654432      0.173174                 0.819899   73.227006       173.243801            0.687487\n",
      "     10                0.40003071         0.164502  0.844088         2.260532       0.205837  0.226014                  0.551248          0.547368      0.084383                 0.904282  -15.591204       126.053172            0.666874\n",
      "     11                0.50000000         0.079478  0.617318         1.931990       0.150538  0.116924                  0.471130          0.461306      0.061713                 0.965995  -38.268194        93.198992            0.616279\n",
      "     12                0.59996929         0.035373  0.233069         1.648909       0.056836  0.054618                  0.402099          0.393542      0.023300                 0.989295  -76.693094        64.890892            0.514884\n",
      "     13                0.69993857         0.015644  0.050393         1.420600       0.012289  0.023813                  0.346424          0.340735      0.005038                 0.994332  -94.960669        42.059965            0.389337\n",
      "     14                0.79990786         0.007954  0.037795         1.247782       0.009217  0.011354                  0.304281          0.299570      0.003778                 0.998111  -96.220502        24.778225            0.262124\n",
      "     15                0.89987715         0.003984  0.012598         1.110563       0.003072  0.005734                  0.270819          0.266927      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000862  0.006290         1.000000       0.001534  0.002797                  0.243857          0.240482      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "      Variable Relative Importance Scaled Importance Percentage\n",
      "  relationship         3651.110352          1.000000   0.284461\n",
      "  capital_gain         2491.409912          0.682370   0.194108\n",
      "     education         2095.927734          0.574052   0.163295\n",
      "    occupation          959.188110          0.262711   0.074731\n",
      "           age          903.055481          0.247337   0.070358\n",
      "marital_status          833.928406          0.228404   0.064972\n",
      "  capital_loss          578.315186          0.158394   0.045057\n",
      "hours_per_week          461.967926          0.126528   0.035992\n",
      "        fnlwgt          291.975739          0.079969   0.022748\n",
      "     workclass          263.558685          0.072186   0.020534\n",
      "native_country          217.259186          0.059505   0.016927\n",
      "           sex           59.278927          0.016236   0.004618\n",
      "          race           28.209692          0.007726   0.002198\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "              70                       75              102332         15         15   15.00000          42         152   100.89333\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:30 14.384 sec               0       0.42711          0.55113      0.50000         0.24005       1.00000                       0.75995         0.42942            0.55553        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:30 14.693 sec               5       0.35826          0.41421      0.92179         0.80893       4.16584                       0.14546         0.36284            0.42177        0.91582           0.79515         4.10076                         0.15341\n",
      " 2023-10-20 18:27:31 15.071 sec              10       0.32600          0.35332      0.92562         0.81836       4.16584                       0.13858         0.33210            0.36301        0.91883           0.80336         4.10076                         0.15756\n",
      " 2023-10-20 18:27:31 15.305 sec              15       0.31170          0.32230      0.92732         0.82294       4.16584                       0.14212         0.31825            0.33278        0.92085           0.80900         4.10076                         0.14665\n",
      " 2023-10-20 18:27:31 15.570 sec              20       0.30229          0.29995      0.93083         0.82982       4.16584                       0.13709         0.31105            0.31448        0.92139           0.81122         4.10076                         0.14343\n",
      " 2023-10-20 18:27:31 15.835 sec              25       0.29716          0.28693      0.93348         0.83535       4.16584                       0.13632         0.30742            0.30440        0.92265           0.81344         4.10076                         0.14266\n",
      " 2023-10-20 18:27:32 16.217 sec              30       0.29344          0.27772      0.93595         0.84051       4.16584                       0.13674         0.30525            0.29836        0.92337           0.81606         4.10076                         0.13851\n",
      " 2023-10-20 18:27:32 16.695 sec              35       0.29015          0.27006      0.93848         0.84561       4.16584                       0.13313         0.30387            0.29444        0.92380           0.81733         4.10076                         0.14051\n",
      " 2023-10-20 18:27:33 17.033 sec              40       0.28734          0.26385      0.94067         0.85033       4.16584                       0.12810         0.30268            0.29117        0.92475           0.81872         4.10076                         0.13790\n",
      " 2023-10-20 18:27:33 17.322 sec              45       0.28487          0.25870      0.94267         0.85472       4.16584                       0.12661         0.30128            0.28813        0.92601           0.82100         4.10076                         0.13590\n",
      " 2023-10-20 18:27:33 17.620 sec              50       0.28249          0.25386      0.94465         0.85903       4.16584                       0.12473         0.30070            0.28656        0.92638           0.82223         4.10076                         0.13206\n",
      " 2023-10-20 18:27:33 17.892 sec              55       0.28039          0.24999      0.94639         0.86265       4.16584                       0.12457         0.30049            0.28589        0.92664           0.82238         4.10076                         0.13529\n",
      " 2023-10-20 18:27:34 18.201 sec              60       0.27810          0.24597      0.94829         0.86671       4.16584                       0.11985         0.30032            0.28522        0.92687           0.82230         4.10076                         0.13652\n",
      " 2023-10-20 18:27:34 18.719 sec              65       0.27674          0.24342      0.94941         0.86901       4.16584                       0.12043         0.30012            0.28476        0.92704           0.82273         4.10076                         0.12869\n",
      " 2023-10-20 18:27:35 19.034 sec              70       0.27553          0.24133      0.95031         0.87110       4.16584                       0.11993         0.29977            0.28413        0.92736           0.82347         4.10076                         0.13299\n",
      " 2023-10-20 18:27:35 19.257 sec              75       0.27363          0.23826      0.95183         0.87454       4.16584                       0.11755         0.30006            0.28442        0.92718           0.82256         4.10076                         0.13529\n",
      "\n",
      "10-20 18:27:35.390 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model GBM_1_AutoML_1_20231020_182658_cv_5\n",
      "10-20 18:27:35.390 172.17.0.2:54321      22766      FJ-2-7  INFO hex.CVModelBuilder: Completed cross-validation model 4 / 5.\n",
      "10-20 18:27:35.390 172.17.0.2:54321      22766      FJ-2-7  WARN water.default: _ntrees: Setting optimal _ntrees to 72 for cross-validation main model based on early stopping of cross-validation models.\n",
      "10-20 18:27:35.390 172.17.0.2:54321      22766      FJ-2-7  WARN water.default: _stopping_rounds: Disabling convergence-based early stopping for cross-validation main model.\n",
      "10-20 18:27:35.390 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Scoring the 5 CV models\n",
      "10-20 18:27:35.418 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:35.643 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_278\n",
      "10-20 18:27:35.657 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_278\n",
      "10-20 18:27:35.875 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_279\n",
      "10-20 18:27:35.888 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_279\n",
      "10-20 18:27:36.120 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_280\n",
      "10-20 18:27:36.135 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_280\n",
      "10-20 18:27:36.336 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_281\n",
      "10-20 18:27:36.346 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_281\n",
      "10-20 18:27:36.532 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:36.537 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_282\n",
      "10-20 18:27:36.548 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_282\n",
      "█10-20 18:27:36.551 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Building main model.\n",
      "10-20 18:27:36.552 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Remaining time for main model (ms): 0\n",
      "10-20 18:27:36.552 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:36.552 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"AutoML_1_20231020_182658_training_py_9_sid_88b4\",\"type\":\"Key\"},\"_valid\":null,\"_nfolds\":5,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":43,\"_fold_assignment\":\"Modulo\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":null,\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":false,\"_cv_fold\":-1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":0,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":72,\"_max_depth\":15,\"_min_rows\":100.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:36.552 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:36.564 172.17.0.2:54321      22766      FJ-3-5  WARN water.default: _stopping_metric: Stopping metric is ignored for _stopping_rounds=0.\n",
      "10-20 18:27:36.564 172.17.0.2:54321      22766      FJ-3-5  WARN water.default: _stopping_tolerance: Stopping tolerance is ignored for _stopping_rounds=0.\n",
      "10-20 18:27:36.571 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model GBM_1_AutoML_1_20231020_182658\n",
      "10-20 18:27:36.571 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Prior class distribution: [0.7591904425539756, 0.2408095574460244]\n",
      "10-20 18:27:36.571 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model class distribution: [0.7591904425539756, 0.2408095574460244]\n",
      "10-20 18:27:36.577 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:36.596 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_283\n",
      "10-20 18:27:36.598 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_283\n",
      "10-20 18:27:36.600 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.18282032\n",
      " RMSE: 0.42757493\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24080956\n",
      " logloss: 0.5520113\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24080955982208252\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  24720  1.0000  24,720 / 24,720\n",
      "     1  0   7841  0.0000        0 / 7,841\n",
      "Totals  0  32561  0.7592  24,720 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.08 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.240810  1.000000         1.000000       0.240810  0.240810                  0.240810          0.240810      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:36 20.514 sec               0       0.42757          0.55201      0.50000         0.24081       1.00000                       0.75919\n",
      "\n",
      "10-20 18:27:36.720 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.120 (Wall: 20-Oct 18:27:36.720) \n",
      "10-20 18:27:36.773 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:36.773) \n",
      "10-20 18:27:36.825 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:36.825) \n",
      "10-20 18:27:36.895 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:36.895) \n",
      "10-20 18:27:36.941 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:36.941) \n",
      "10-20 18:27:36.942 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:36.968 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_284\n",
      "10-20 18:27:36.986 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_284\n",
      "10-20 18:27:37.034 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:37.034) \n",
      "10-20 18:27:37.071 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:37.071) \n",
      "10-20 18:27:37.103 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:37.103) \n",
      "10-20 18:27:37.136 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:37.136) \n",
      "10-20 18:27:37.168 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:37.168) \n",
      "10-20 18:27:37.168 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:37.182 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_285\n",
      "10-20 18:27:37.199 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_285\n",
      "10-20 18:27:37.239 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:37.239) \n",
      "10-20 18:27:37.273 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:37.273) \n",
      "10-20 18:27:37.309 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:37.309) \n",
      "10-20 18:27:37.352 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:37.352) \n",
      "10-20 18:27:37.395 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:37.395) \n",
      "10-20 18:27:37.396 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:37.412 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_286\n",
      "10-20 18:27:37.430 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_286\n",
      "10-20 18:27:37.458 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:37.494 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:37.494) \n",
      "10-20 18:27:37.547 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:37.547) \n",
      "10-20 18:27:37.602 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:37.602) \n",
      "10-20 18:27:37.638 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:37.638) \n",
      "10-20 18:27:37.674 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:37.674) \n",
      "10-20 18:27:37.674 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:37.685 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_287\n",
      "10-20 18:27:37.709 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_287\n",
      "10-20 18:27:37.752 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:37.752) \n",
      "10-20 18:27:37.796 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:37.796) \n",
      "10-20 18:27:37.836 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:37.836) \n",
      "10-20 18:27:37.868 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:37.868) \n",
      "10-20 18:27:37.901 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:37.900) \n",
      "10-20 18:27:37.901 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:37.914 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_288\n",
      "10-20 18:27:37.935 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_288\n",
      "10-20 18:27:37.980 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:37.980) \n",
      "10-20 18:27:38.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:38.015) \n",
      "10-20 18:27:38.050 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:38.050) \n",
      "10-20 18:27:38.089 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:38.089) \n",
      "10-20 18:27:38.127 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:38.127) \n",
      "10-20 18:27:38.128 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:38.143 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_289\n",
      "10-20 18:27:38.160 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_289\n",
      "10-20 18:27:38.215 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:38.215) \n",
      "10-20 18:27:38.256 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:38.256) \n",
      "10-20 18:27:38.300 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:38.300) \n",
      "10-20 18:27:38.344 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:38.344) \n",
      "█10-20 18:27:38.387 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:38.387) \n",
      "10-20 18:27:38.388 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:38.413 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_290\n",
      "10-20 18:27:38.443 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_290\n",
      "10-20 18:27:38.592 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:38.592) \n",
      "10-20 18:27:38.666 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:38.666) \n",
      "10-20 18:27:38.828 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.161 (Wall: 20-Oct 18:27:38.828) \n",
      "10-20 18:27:38.886 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:38.886) \n",
      "10-20 18:27:38.913 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:38.945 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:38.945) \n",
      "10-20 18:27:38.945 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:38.961 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_291\n",
      "10-20 18:27:38.987 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_291\n",
      "10-20 18:27:39.041 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:39.041) \n",
      "10-20 18:27:39.084 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:39.084) \n",
      "10-20 18:27:39.125 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:39.125) \n",
      "10-20 18:27:39.169 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:39.169) \n",
      "10-20 18:27:39.211 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:39.211) \n",
      "10-20 18:27:39.212 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:39.226 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_292\n",
      "10-20 18:27:39.244 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_292\n",
      "10-20 18:27:39.293 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:39.293) \n",
      "█10-20 18:27:39.333 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:39.333) \n",
      "10-20 18:27:39.371 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:39.371) \n",
      "10-20 18:27:39.415 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:39.415) \n",
      "10-20 18:27:39.451 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 50. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:39.451) \n",
      "10-20 18:27:39.452 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:39.468 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_293\n",
      "10-20 18:27:39.482 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_293\n",
      "10-20 18:27:39.521 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 51. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:39.521) \n",
      "10-20 18:27:39.566 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 52. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:39.566) \n",
      "10-20 18:27:39.610 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 53. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:39.610) \n",
      "10-20 18:27:39.662 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 54. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:39.662) \n",
      "10-20 18:27:39.707 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 55. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:39.707) \n",
      "10-20 18:27:39.708 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:39.722 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_294\n",
      "10-20 18:27:39.739 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_294\n",
      "10-20 18:27:39.784 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 56. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:39.784) \n",
      "10-20 18:27:39.821 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 57. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:39.821) \n",
      "10-20 18:27:39.876 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 58. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:39.876) \n",
      "10-20 18:27:39.929 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 59. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:39.929) \n",
      "10-20 18:27:39.986 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 60. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:39.986) \n",
      "10-20 18:27:39.992 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:40.012 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_295\n",
      "10-20 18:27:40.048 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_295\n",
      "10-20 18:27:40.084 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:40.160 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 61. tree was built in 00:00:00.106 (Wall: 20-Oct 18:27:40.160) \n",
      "10-20 18:27:40.212 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 62. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:40.212) \n",
      "█10-20 18:27:40.263 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 63. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:40.263) \n",
      "10-20 18:27:40.302 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 64. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:40.302) \n",
      "10-20 18:27:40.332 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 65. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:40.332) \n",
      "10-20 18:27:40.333 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:40.345 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_296\n",
      "10-20 18:27:40.358 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_296\n",
      "10-20 18:27:40.390 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 66. tree was built in 00:00:00.030 (Wall: 20-Oct 18:27:40.390) \n",
      "10-20 18:27:40.432 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 67. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:40.432) \n",
      "10-20 18:27:40.469 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 68. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:40.469) \n",
      "10-20 18:27:40.503 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 69. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:40.503) \n",
      "10-20 18:27:40.542 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 70. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:40.542) \n",
      "10-20 18:27:40.543 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:40.554 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_297\n",
      "10-20 18:27:40.575 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_297\n",
      "10-20 18:27:40.618 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 71. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:40.618) \n",
      "10-20 18:27:40.662 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:40.666 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 72. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:40.666) \n",
      "10-20 18:27:40.667 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:40.690 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_298\n",
      "10-20 18:27:40.714 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_298\n",
      "10-20 18:27:40.720 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_1_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.074990086\n",
      " RMSE: 0.27384317\n",
      " AUC: 0.95143366\n",
      " pr_auc: 0.8749514\n",
      " logloss: 0.23889571\n",
      " mean_per_class_error: 0.14244552\n",
      " default threshold: 0.3881431221961975\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22665  2055  0.0831  2,055 / 24,720\n",
      "     1   1582  6259  0.2018   1,582 / 7,841\n",
      "Totals  24247  8314  0.1117  3,637 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.08 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.990948  4.152659         4.152659       1.000000  0.992823                  1.000000          0.992823      0.041576                 0.041576   315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.987361  4.152659         4.152659       1.000000  0.989244                  1.000000          0.991034      0.041576                 0.083153   315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.982672  4.152659         4.152659       1.000000  0.985200                  1.000000          0.989093      0.041449                 0.124601   315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.975001  4.152659         4.152659       1.000000  0.979344                  1.000000          0.986654      0.041576                 0.166178   315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.957482  4.139921         4.150110       0.996933  0.968104                  0.999386          0.982942      0.041449                 0.207627   313.992088       315.010989            0.207586\n",
      "      6                0.10002764         0.789457  3.892480         4.021335       0.937346  0.870190                  0.968376          0.926583      0.194618                 0.402245   289.248021       302.133460            0.398078\n",
      "      7                0.15002610         0.651195  3.226728         3.756520       0.777027  0.720218                  0.904606          0.857809      0.161331                 0.563576   222.672835       275.652007            0.544725\n",
      "      8                0.20002457         0.519115  2.509961         3.444928       0.604423  0.583481                  0.829572          0.789237      0.125494                 0.689070   150.996103       244.492816            0.644167\n",
      "      9                0.30002150         0.304303  1.738352         2.876128       0.418612  0.402779                  0.692599          0.660431      0.173830                 0.862900    73.835207       187.612770            0.741420\n",
      "     10                0.40001843         0.158467  0.913177         2.385428       0.219902  0.226924                  0.574434          0.552062      0.091315                 0.954215    -8.682312       138.542767            0.729984\n",
      "     11                0.50001536         0.072239  0.326499         1.973667       0.078624  0.111159                  0.475278          0.463887      0.032649                 0.986864   -67.350100        97.366723            0.641273\n",
      "     12                0.60001228         0.031248  0.104582         1.662169       0.025184  0.048648                  0.400266          0.394684      0.010458                 0.997322   -89.541829        66.216892            0.523333\n",
      "     13                0.70000921         0.014329  0.021682         1.427824       0.005221  0.021448                  0.343834          0.341367      0.002168                 0.999490   -97.831843        42.782387            0.394474\n",
      "     14                0.80000614         0.007254  0.005102         1.249990       0.001229  0.010392                  0.301010          0.299997      0.000510                 1.000000   -99.489845        24.999040            0.263430\n",
      "     15                0.90000307         0.003474  0.000000         1.111107       0.000000  0.005179                  0.267565          0.267240      0.000000                 1.000000  -100.000000        11.110732            0.131715\n",
      "     16                1.00000000         0.000363  0.000000         1.000000       0.000000  0.002404                  0.240810          0.240758      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "      Variable Relative Importance Scaled Importance Percentage\n",
      "  relationship         4602.744629          1.000000   0.286272\n",
      "  capital_gain         3140.770996          0.682369   0.195343\n",
      "     education         2609.794678          0.567008   0.162319\n",
      "    occupation         1140.884888          0.247871   0.070958\n",
      "           age         1114.520630          0.242143   0.069319\n",
      "marital_status         1045.372681          0.227119   0.065018\n",
      "  capital_loss          740.770874          0.160941   0.046073\n",
      "hours_per_week          622.132202          0.135165   0.038694\n",
      "     workclass          353.183838          0.076733   0.021967\n",
      "        fnlwgt          329.372070          0.071560   0.020486\n",
      "native_country          275.414551          0.059837   0.017130\n",
      "           sex           65.169701          0.014159   0.004053\n",
      "          race           38.088749          0.008275   0.002369\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "              72                       72              116356         15         15   15.00000          39         191   120.19444\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:36 20.514 sec               0       0.42757          0.55201      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:36 20.884 sec               5       0.35807          0.41390      0.92315         0.81191       4.15266                       0.14198\n",
      " 2023-10-20 18:27:37 21.111 sec              10       0.32504          0.35182      0.92745         0.82241       4.15266                       0.14216\n",
      " 2023-10-20 18:27:37 21.338 sec              15       0.31013          0.31983      0.92935         0.82747       4.15266                       0.13817\n",
      " 2023-10-20 18:27:37 21.617 sec              20       0.30081          0.29773      0.93262         0.83410       4.15266                       0.13415\n",
      " 2023-10-20 18:27:37 21.843 sec              25       0.29600          0.28503      0.93485         0.83835       4.15266                       0.13409\n",
      " 2023-10-20 18:27:38 22.070 sec              30       0.29190          0.27537      0.93754         0.84422       4.15266                       0.13009\n",
      " 2023-10-20 18:27:38 22.330 sec              35       0.28872          0.26821      0.93981         0.84905       4.15266                       0.12576\n",
      " 2023-10-20 18:27:38 22.888 sec              40       0.28596          0.26221      0.94184         0.85372       4.15266                       0.12441\n",
      " 2023-10-20 18:27:39 23.154 sec              45       0.28390          0.25761      0.94339         0.85711       4.15266                       0.12143\n",
      " 2023-10-20 18:27:39 23.394 sec              50       0.28197          0.25356      0.94487         0.86041       4.15266                       0.11922\n",
      " 2023-10-20 18:27:39 23.650 sec              55       0.28024          0.25000      0.94630         0.86331       4.15266                       0.11812\n",
      " 2023-10-20 18:27:39 23.929 sec              60       0.27816          0.24647      0.94796         0.86716       4.15266                       0.11578\n",
      " 2023-10-20 18:27:40 24.275 sec              65       0.27630          0.24315      0.94943         0.87053       4.15266                       0.11428\n",
      " 2023-10-20 18:27:40 24.485 sec              70       0.27460          0.24014      0.95078         0.87356       4.15266                       0.11419\n",
      " 2023-10-20 18:27:40 24.609 sec              72       0.27384          0.23890      0.95143         0.87495       4.15266                       0.11170\n",
      "\n",
      "10-20 18:27:40.725 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model GBM_1_AutoML_1_20231020_182658\n",
      "10-20 18:27:40.726 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Computing 5-fold cross-validation metrics.\n",
      "10-20 18:27:40.789 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_299\n",
      "10-20 18:27:40.808 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_299\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Model Metrics Type: Binomial\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  Description: 5-fold cross-validation on training data (Metrics computed for combined holdout predictions)\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  model id: GBM_1_AutoML_1_20231020_182658\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  MSE: 0.09076467\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  RMSE: 0.30127177\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  AUC: 0.92469066\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  pr_auc: 0.8193197\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  logloss: 0.2859891\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  mean_per_class_error: 0.16988826\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  default threshold: 0.35521602630615234\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:  CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:             0     1   Error            Rate\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      0  21923  2797  0.1131  2,797 / 24,720\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      1   1777  6064  0.2266   1,777 / 7,841\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Totals  23700  8861  0.1405  4,574 / 32,561\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.00 %):\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:   Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       1                0.01001198         0.991402  4.152659         4.152659       1.000000  0.993189                  1.000000          0.993189      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       2                0.02002396         0.987297  4.127183         4.139921       0.993865  0.989459                  0.996933          0.991324      0.041321                 0.082898  312.718266       313.992088            0.082817\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       3                0.03000522         0.981213  4.114327         4.131407       0.990769  0.984514                  0.994882          0.989059      0.041066                 0.123964  311.432686       313.140701            0.123762\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       4                0.04001720         0.970792  4.127183         4.130350       0.993865  0.976707                  0.994628          0.985968      0.041321                 0.165285  312.718266       313.035011            0.165002\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       5                0.05002918         0.950426  4.139921         4.132265       0.996933  0.962231                  0.995089          0.981218      0.041449                 0.206734  313.992088       313.226544            0.206410\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       6                0.10002764         0.784915  3.535372         3.833910       0.851351  0.862702                  0.923242          0.921978      0.176763                 0.383497  253.537194       283.391032            0.373384\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       7                0.15002610         0.640314  2.874722         3.514246       0.692260  0.713406                  0.846264          0.852469      0.143732                 0.527229  187.472162       251.424621            0.496848\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       8                0.20002457         0.510624  2.367118         3.227508       0.570025  0.576267                  0.777215          0.783429      0.118352                 0.645581  136.711772       222.750812            0.586884\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:       9                0.30002150         0.301489  1.650350         2.701843       0.397420  0.401118                  0.650630          0.656005      0.165030                 0.810611   65.035039       170.184269            0.672545\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      10                0.40001843         0.160228  0.983323         2.272246       0.236794  0.226576                  0.547179          0.548656      0.098329                 0.908940   -1.667685       127.224579            0.670348\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      11                0.50001536         0.075007  0.545866         1.926991       0.131450  0.113443                  0.464038          0.461619      0.054585                 0.963525  -45.413449        92.699094            0.610532\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      12                0.60001228         0.032473  0.218091         1.642189       0.052518  0.050827                  0.395455          0.393157      0.021808                 0.985334  -78.190887        64.218888            0.507542\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      13                0.70000921         0.015288  0.098205         1.421629       0.023649  0.022570                  0.342342          0.340218      0.009820                 0.995154  -90.179522        42.162940            0.388762\n",
      "10-20 18:27:40.812 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      14                0.80000614         0.007550  0.035711         1.248396       0.008600  0.010930                  0.300626          0.299059      0.003571                 0.998725  -96.428917        24.839623            0.261751\n",
      "10-20 18:27:40.813 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      15                0.90000307         0.003595  0.010203         1.110824       0.002457  0.005352                  0.267497          0.266426      0.001020                 0.999745  -98.979691        11.082391            0.131379\n",
      "10-20 18:27:40.813 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:      16                1.00000000         0.000325  0.002551         1.000000       0.000614  0.002518                  0.240810          0.240036      0.000255                 1.000000  -99.744923         0.000000            0.000000\n",
      "10-20 18:27:40.834 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Cross-Validation Metrics Summary:\n",
      "10-20 18:27:40.834 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                                mean         sd  cv_1_valid  cv_2_valid  cv_3_valid  cv_4_valid  cv_5_valid\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                accuracy    0.860109   0.004492    0.856595    0.857187    0.856726    0.865326    0.864711\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     auc    0.924569   0.004542    0.928191    0.926695    0.916986    0.923795    0.927177\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     err    0.139891   0.004492    0.143405    0.142813    0.143274    0.134674    0.135289\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:               err_count  911.000000  29.283100  934.000000  930.000000  933.000000  877.000000  881.000000\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                f0point5    0.701263   0.011576    0.701370    0.688153    0.691278    0.713083    0.712432\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                      f1    0.727542   0.012906    0.737345    0.718182    0.710698    0.730071    0.741415\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                      f2    0.756029   0.018963    0.777211    0.750951    0.731240    0.747887    0.772855\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:          lift_top_group    4.154737   0.103193    4.005535    4.256209    4.236825    4.174359    4.100756\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                 logloss    0.286223   0.006180    0.283765    0.279098    0.295650    0.288181    0.284419\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:     max_per_class_error    0.223602   0.024817    0.193727    0.225490    0.254392    0.239744    0.204660\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     mcc    0.636371   0.014557    0.644151    0.626186    0.616955    0.641438    0.653126\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: mean_per_class_accuracy    0.831447   0.009355    0.839805    0.828544    0.818332    0.829341    0.841212\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:    mean_per_class_error    0.168553   0.009355    0.160195    0.171456    0.181668    0.170659    0.158788\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                     mse    0.090862   0.001755    0.090127    0.088986    0.093492    0.091671    0.090034\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                  pr_auc    0.819048   0.010996    0.834730    0.819415    0.805147    0.813387    0.822562\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:               precision    0.684841   0.013162    0.679275    0.669492    0.678910    0.702191    0.694338\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                      r2    0.502769   0.014423    0.518881    0.504944    0.481515    0.496782    0.511722\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                  recall    0.776398   0.024817    0.806273    0.774510    0.745608    0.760256    0.795340\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:                    rmse    0.301422   0.002904    0.300211    0.298305    0.305765    0.302772    0.300057\n",
      "10-20 18:27:40.835 172.17.0.2:54321      22766      FJ-2-7  INFO water.default:             specificity    0.886496   0.009380    0.873337    0.882577    0.891055    0.898425    0.887084\n",
      "10-20 18:27:40.839 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: 5 CV models were removed\n",
      "10-20 18:27:40.843 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: New leader: GBM_1_AutoML_1_20231020_182658, auc: 0.9246906817908851\n",
      "10-20 18:27:40.843 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML step returned with state: StepResultState{_id='GBM:def_5', _status=success}\n",
      "10-20 18:27:40.845 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: AutoML: starting XGBoost_2_AutoML_1_20231020_182658 model training\n",
      "10-20 18:27:40.848 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Creating 5 cross-validation splits with random number seed: 44\n",
      "10-20 18:27:40.888 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 1 / 5.\n",
      "10-20 18:27:40.889 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 2 / 5.\n",
      "10-20 18:27:40.889 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 3 / 5.\n",
      "10-20 18:27:40.889 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:40.889 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:40.890 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_1_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":44,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":0,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":10,\"_min_rows\":5.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:40.890 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: {\"_train\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_2_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":44,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":10,\"_min_rows\":5.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:40.890 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:40.892 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:40.892 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: {\"_train\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_3_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":44,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":2,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":10,\"_min_rows\":5.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:40.892 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:40.895 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:40.890 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 4 / 5.\n",
      "10-20 18:27:40.908 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:40.908 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: {\"_train\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_4_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":44,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":3,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":10,\"_min_rows\":5.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:40.931 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:41.062 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:41.080 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:41.094 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "█10-20 18:27:41.159 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:41.199 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:41.199 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:41.200 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  seed = 44\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 10\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:41.201 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 5.0\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:41.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:41.211 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:41.211 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:41.212 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  seed = 44\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 10\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 5.0\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:41.213 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:41.233 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:41.234 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:41.234 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  seed = 44\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 10\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:41.235 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 5.0\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:41.236 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:41.246 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:41.246 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Starting model XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:41.247 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  seed = 44\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 10\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 5.0\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:41.248 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:41.249 172.17.0.2:54321      22766  82658_cv_4  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:41.269 172.17.0.2:54321      22766  82658_cv_1  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:41.286 172.17.0.2:54321      22766  82658_cv_2  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:41.291 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_301\n",
      "10-20 18:27:41.294 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_302\n",
      "10-20 18:27:41.295 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_301\n",
      "10-20 18:27:41.294 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_303\n",
      "10-20 18:27:41.301 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_303\n",
      "10-20 18:27:41.302 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_302\n",
      "10-20 18:27:41.311 172.17.0.2:54321      22766  82658_cv_3  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:41.324 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_304\n",
      "10-20 18:27:41.325 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_305\n",
      "10-20 18:27:41.328 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_304\n",
      "10-20 18:27:41.329 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_306\n",
      "10-20 18:27:41.329 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_305\n",
      "10-20 18:27:41.330 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_307\n",
      "10-20 18:27:41.330 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23859797\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19833  1.0000  19,833 / 19,833\n",
      "     1  0   6215  0.0000        0 / 6,215\n",
      "Totals  0  26048  0.7614  19,833 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.238598  0.500000                  0.238598          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24965453\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4887  1.0000  4,887 / 4,887\n",
      "     1  0  1626  0.0000      0 / 1,626\n",
      "Totals  0  6513  0.7503  4,887 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.249655  0.500000                  0.249655          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      "\n",
      "10-20 18:27:41.335 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_306\n",
      "10-20 18:27:41.337 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_307\n",
      "10-20 18:27:41.337 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2411225\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19768  1.0000  19,768 / 19,768\n",
      "     1  0   6281  0.0000        0 / 6,281\n",
      "Totals  0  26049  0.7589  19,768 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.241122  0.500000                  0.241122          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23955774\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4952  1.0000  4,952 / 4,952\n",
      "     1  0  1560  0.0000      0 / 1,560\n",
      "Totals  0  6512  0.7604  4,952 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.239558  0.500000                  0.239558          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      "\n",
      "10-20 18:27:41.340 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24227418\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19738  1.0000  19,738 / 19,738\n",
      "     1  0   6311  0.0000        0 / 6,311\n",
      "Totals  0  26049  0.7577  19,738 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.242274  0.500000                  0.242274          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23495086\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4982  1.0000  4,982 / 4,982\n",
      "     1  0  1530  0.0000      0 / 1,530\n",
      "Totals  0  6512  0.7650  4,982 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.234951  0.500000                  0.234951          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      "\n",
      "10-20 18:27:41.342 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_308\n",
      "10-20 18:27:41.344 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_308\n",
      "10-20 18:27:41.348 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24200545\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19745  1.0000  19,745 / 19,745\n",
      "     1  0   6304  0.0000        0 / 6,304\n",
      "Totals  0  26049  0.7580  19,745 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.242005  0.500000                  0.242005          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2360258\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4975  1.0000  4,975 / 4,975\n",
      "     1  0  1537  0.0000      0 / 1,537\n",
      "Totals  0  6512  0.7640  4,975 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.236026  0.500000                  0.236026          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      "\n",
      "10-20 18:27:41.408 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:41.408) \n",
      "10-20 18:27:41.419 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:41.418) \n",
      "10-20 18:27:41.444 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:41.444) \n",
      "10-20 18:27:41.447 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.116 (Wall: 20-Oct 18:27:41.447) \n",
      "10-20 18:27:41.457 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:41.457) \n",
      "10-20 18:27:41.493 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:41.493) \n",
      "10-20 18:27:41.498 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:41.498) \n",
      "10-20 18:27:41.505 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:41.505) \n",
      "10-20 18:27:41.518 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:41.518) \n",
      "10-20 18:27:41.543 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:41.543) \n",
      "10-20 18:27:41.548 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:41.548) \n",
      "10-20 18:27:41.551 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:41.551) \n",
      "10-20 18:27:41.574 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:41.574) \n",
      "10-20 18:27:41.610 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:41.610) \n",
      "10-20 18:27:41.614 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:41.614) \n",
      "10-20 18:27:41.618 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:41.617) \n",
      "10-20 18:27:41.648 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:41.648) \n",
      "10-20 18:27:41.675 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:41.675) \n",
      "10-20 18:27:41.716 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:41.716) \n",
      "10-20 18:27:41.738 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.128 (Wall: 20-Oct 18:27:41.738) \n",
      "10-20 18:27:41.767 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_310\n",
      "10-20 18:27:41.767 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_309\n",
      "10-20 18:27:41.774 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_311\n",
      "10-20 18:27:41.776 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_312\n",
      "10-20 18:27:41.790 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_310\n",
      "10-20 18:27:41.794 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_311\n",
      "10-20 18:27:41.796 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_309\n",
      "10-20 18:27:41.805 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_312\n",
      "10-20 18:27:41.827 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "\n",
      "18:27:40.840: GBM_1_AutoML_1_20231020_182658 [GBM def_5] complete\n",
      "18:27:40.840: Adding model GBM_1_AutoML_1_20231020_182658 to leaderboard Leaderboard_AutoML_1_20231020_182658@@label. Training time: model=4s, total=25s\n",
      "18:27:40.843: New leader: GBM_1_AutoML_1_20231020_182658, auc: 0.9246906817908851\n",
      "18:27:40.845: No time limitation for XGBoost_2_AutoML_1_20231020_182658\n",
      "18:27:40.845: AutoML: starting XGBoost_2_AutoML_1_20231020_182658 model training\n",
      "18:27:40.847: XGBoost_2_AutoML_1_20231020_182658 [XGBoost def_1] started\n",
      "\n",
      "10-20 18:27:41.856 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_314\n",
      "10-20 18:27:41.867 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_314\n",
      "10-20 18:27:41.856 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_313\n",
      "10-20 18:27:41.874 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.0994681\n",
      " RMSE: 0.31538564\n",
      " AUC: 0.9230687\n",
      " pr_auc: 0.8193283\n",
      " logloss: 0.34015533\n",
      " mean_per_class_error: 0.17038135\n",
      " default threshold: 0.3727823495864868\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17421  2412  0.1216  2,412 / 19,833\n",
      "     1   1362  4853  0.2191   1,362 / 6,215\n",
      "Totals  18783  7265  0.1449  3,774 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 29.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01627764         0.893822  4.191150         4.191150       1.000000  0.893822                  1.000000          0.893822      0.068222                 0.068222  319.115044       319.115044            0.068222\n",
      "      2                0.02956081         0.893489  4.179037         4.185707       0.997110  0.893489                  0.998701          0.893672      0.055511                 0.123733  317.903729       318.570739            0.123682\n",
      "      3                0.03036701         0.888920  4.191150         4.185852       1.000000  0.888920                  0.998736          0.893546      0.003379                 0.127112  319.115044       318.585190            0.127061\n",
      "      4                0.04057893         0.881820  4.191150         4.187185       1.000000  0.884509                  0.999054          0.891272      0.042800                 0.169912  319.115044       318.718530            0.169861\n",
      "      5                0.05025338         0.856248  4.074730         4.165536       0.972222  0.865507                  0.993888          0.886312      0.039421                 0.209332  307.472960       316.553608            0.208929\n",
      "      6                0.10000768         0.649592  3.641385         3.904769       0.868827  0.726763                  0.931670          0.806935      0.181175                 0.390507  264.138534       290.476857            0.381532\n",
      "      7                0.15003071         0.553615  2.836987         3.548750       0.676899  0.598277                  0.846725          0.737365      0.141915                 0.532422  183.698748       254.875046            0.502219\n",
      "      8                0.20001536         0.463611  2.262964         3.227427       0.539939  0.505468                  0.770058          0.679413      0.113113                 0.645535  126.296372       222.742717            0.585131\n",
      "      9                0.30002303         0.358429  1.620149         2.691668       0.386564  0.397568                  0.642226          0.585465      0.162027                 0.807562   62.014913       169.166783            0.666585\n",
      "     10                0.40037623         0.271788  1.014919         2.271395       0.242158  0.314125                  0.541950          0.517454      0.101850                 0.909413    1.491899       127.139537            0.668552\n",
      "     11                0.50015356         0.195983  0.520870         1.922177       0.124279  0.232049                  0.458628          0.460518      0.051971                 0.961384  -47.912982        92.217715            0.605764\n",
      "     12                0.60012285         0.135674  0.220502         1.638710       0.052611  0.165342                  0.390993          0.411347      0.022043                 0.983427  -77.949785        63.870979            0.503419\n",
      "     13                0.70001536         0.117132  0.101477         1.419346       0.024212  0.123388                  0.338653          0.370255      0.010137                 0.993564  -89.852326        41.934595            0.385537\n",
      "     14                0.81203931         0.108855  0.035908         1.228495       0.008568  0.112540                  0.293116          0.334702      0.004023                 0.997586  -96.409227        22.849531            0.243691\n",
      "     15                1.00000000         0.104546  0.012841         1.000000       0.003064  0.105155                  0.238598          0.291556      0.002414                 1.000000  -98.715947         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.10313296\n",
      " RMSE: 0.3211432\n",
      " AUC: 0.91612715\n",
      " pr_auc: 0.8188213\n",
      " logloss: 0.34917068\n",
      " mean_per_class_error: 0.17783268\n",
      " default threshold: 0.3727691173553467\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4309   578  0.1183  578 / 4,887\n",
      "     1   386  1240  0.2374  386 / 1,626\n",
      "Totals  4695  1818  0.1480  964 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 29.42 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01535391         0.893822  4.005535         4.005535       1.000000  0.893822                  1.000000          0.893822      0.061501                 0.061501  300.553506       300.553506            0.061501\n",
      "      2                0.03040074         0.893489  4.005535         4.005535       1.000000  0.893489                  1.000000          0.893657      0.060271                 0.121771  300.553506       300.553506            0.121771\n",
      "      3                0.04022724         0.882625  4.005535         4.005535       1.000000  0.885554                  1.000000          0.891678      0.039360                 0.161132  300.553506       300.553506            0.161132\n",
      "      4                0.05097497         0.858636  4.005535         4.005535       1.000000  0.868243                  1.000000          0.886736      0.043050                 0.204182  300.553506       300.553506            0.204182\n",
      "      5                0.10026102         0.658973  3.493925         3.754039       0.872274  0.739210                  0.937213          0.814216      0.172202                 0.376384  249.392466       275.403898            0.367994\n",
      "      6                0.15077537         0.561423  2.946321         3.483429       0.735562  0.607549                  0.869654          0.744976      0.148831                 0.525215  194.632062       248.342865            0.499023\n",
      "      7                0.20006142         0.464180  2.121311         3.147865       0.529595  0.508785                  0.785879          0.686789      0.104551                 0.629766  112.131140       214.786485            0.572676\n",
      "      8                0.30001535         0.357533  1.568988         2.621842       0.391705  0.399109                  0.654555          0.590945      0.156827                 0.786593   56.898839       162.184203            0.648471\n",
      "      9                0.40012283         0.273768  1.013671         2.219491       0.253067  0.316061                  0.554106          0.522171      0.101476                 0.888069    1.367068       121.949064            0.650295\n",
      "     10                0.50007677         0.201240  0.566066         1.889009       0.141321  0.236923                  0.471600          0.465157      0.056581                 0.944649  -43.393360        88.900886            0.592491\n",
      "     11                0.60018425         0.136569  0.331747         1.629266       0.082822  0.167621                  0.406754          0.415529      0.033210                 0.977860  -66.825323        62.926599            0.503336\n",
      "     12                0.70121296         0.117132  0.127836         1.412944       0.031915  0.123889                  0.352748          0.373511      0.012915                 0.990775  -87.216377        41.294438            0.385905\n",
      "     13                0.82051282         0.108855  0.061862         1.216501       0.015444  0.112421                  0.303705          0.335549      0.007380                 0.998155  -93.813845        21.650138            0.236747\n",
      "     14                1.00000000         0.104546  0.010279         1.000000       0.002566  0.105134                  0.249655          0.294193      0.001845                 1.000000  -98.972061         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4593.890137          1.000000   0.357823\n",
      "                      capital_gain         2946.304688          0.641353   0.229491\n",
      "                      capital_loss          979.060425          0.213122   0.076260\n",
      "                               age          646.615967          0.140756   0.050366\n",
      "                    hours_per_week          574.714905          0.125104   0.044765\n",
      "     marital_status. Never-married          536.284058          0.116739   0.041772\n",
      "        occupation. Prof-specialty          417.184265          0.090813   0.032495\n",
      "       occupation. Exec-managerial          413.598694          0.090032   0.032216\n",
      "              education. Bachelors          237.624420          0.051726   0.018509\n",
      "                education. Masters          193.607849          0.042145   0.015080\n",
      "---\n",
      "             relationship. Husband           12.924511          0.002813   0.001007\n",
      "     native_country. United-States           12.805607          0.002788   0.000997\n",
      "       occupation. Protective-serv            6.123596          0.001333   0.000477\n",
      "                       race. White            5.116704          0.001114   0.000399\n",
      "              workclass. Local-gov            4.731589          0.001030   0.000369\n",
      "          occupation. Craft-repair            4.393706          0.000956   0.000342\n",
      "              education. Assoc-voc            4.031647          0.000878   0.000314\n",
      "           relationship. Unmarried            3.297344          0.000718   0.000257\n",
      "              workclass. State-gov            3.142525          0.000684   0.000245\n",
      "          race. Asian-Pac-Islander            2.200842          0.000479   0.000171\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        20481.974609          1.000000   0.153935\n",
      "marital_status. Married-civ-spouse        15331.560547          0.748539   0.115227\n",
      "                               age        15267.258789          0.745400   0.114743\n",
      "                    hours_per_week        14300.933594          0.698220   0.107481\n",
      "                      capital_loss        13995.615234          0.683314   0.105186\n",
      "        occupation. Prof-specialty         6928.562012          0.338276   0.052073\n",
      "       occupation. Exec-managerial         5760.700195          0.281257   0.043295\n",
      "     marital_status. Never-married         3602.539551          0.175888   0.027075\n",
      "              education. Bachelors         3471.422852          0.169487   0.026090\n",
      "                education. Masters         3323.156006          0.162248   0.024976\n",
      "---\n",
      "              education. Assoc-voc          235.298584          0.011488   0.001768\n",
      "                workclass. Private          223.475128          0.010911   0.001680\n",
      "                       race. White          211.213837          0.010312   0.001587\n",
      "             relationship. Husband          145.713608          0.007114   0.001095\n",
      "     native_country. United-States          144.000000          0.007031   0.001082\n",
      "                       sex. Female          119.441902          0.005832   0.000898\n",
      "           relationship. Unmarried           78.336502          0.003825   0.000589\n",
      "              workclass. State-gov           51.000000          0.002490   0.000383\n",
      "          occupation. Craft-repair           33.027813          0.001613   0.000248\n",
      "          race. Asian-Pac-Islander           15.438437          0.000754   0.000116\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                        age           99.000000          1.000000   0.246269\n",
      "             hours_per_week           45.000000          0.454545   0.111940\n",
      "                     fnlwgt           27.000000          0.272727   0.067164\n",
      "               capital_loss           27.000000          0.272727   0.067164\n",
      "               capital_gain           18.000000          0.181818   0.044776\n",
      "occupation. Exec-managerial           16.000000          0.161616   0.039801\n",
      " occupation. Prof-specialty           15.000000          0.151515   0.037313\n",
      "         education. HS-grad           14.000000          0.141414   0.034826\n",
      "         education. Masters           12.000000          0.121212   0.029851\n",
      "    education. Some-college           11.000000          0.111111   0.027363\n",
      "---\n",
      "            education. 10th            2.000000          0.020202   0.004975\n",
      "     workclass. Federal-gov            2.000000          0.020202   0.004975\n",
      "     native_country. Mexico            2.000000          0.020202   0.004975\n",
      "occupation. Protective-serv            2.000000          0.020202   0.004975\n",
      "       workclass. State-gov            1.000000          0.010101   0.002488\n",
      "       education. Assoc-voc            1.000000          0.010101   0.002488\n",
      "         education. 7th-8th            1.000000          0.010101   0.002488\n",
      "   race. Asian-Pac-Islander            1.000000          0.010101   0.002488\n",
      "   occupation. Craft-repair            1.000000          0.010101   0.002488\n",
      "             education. 9th            1.000000          0.010101   0.002488\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      "\n",
      "10-20 18:27:41.880 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_313\n",
      "10-20 18:27:41.894 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.098531164\n",
      " RMSE: 0.31389675\n",
      " AUC: 0.925027\n",
      " pr_auc: 0.82534707\n",
      " logloss: 0.33750683\n",
      " mean_per_class_error: 0.17688474\n",
      " default threshold: 0.40904974937438965\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17884  1861  0.0943  1,861 / 19,745\n",
      "     1   1636  4668  0.2595   1,636 / 6,304\n",
      "Totals  19520  6529  0.1342  3,497 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 29.37 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03309148         0.895320  4.127345         4.127345       0.998840  0.895320                  0.998840          0.895320      0.136580                 0.136580  312.734466       312.734466            0.136529\n",
      "      2                0.04019348         0.879544  4.109802         4.124245       0.994595  0.885271                  0.998090          0.893544      0.029188                 0.165768  310.980244       312.424503            0.165666\n",
      "      3                0.05002111         0.857046  4.115997         4.122625       0.996094  0.867470                  0.997698          0.888421      0.040451                 0.206218  311.599716       312.262458            0.206066\n",
      "      4                0.10000384         0.678772  3.652912         3.887858       0.884025  0.757845                  0.940883          0.823158      0.182582                 0.388801  265.291184       288.785836            0.381001\n",
      "      5                0.15017851         0.560186  2.861198         3.544851       0.692425  0.624324                  0.857873          0.756728      0.143560                 0.532360  186.119754       254.485077            0.504201\n",
      "      6                0.20108258         0.455551  2.281090         3.224930       0.552036  0.506782                  0.780451          0.693454      0.116117                 0.648477  128.108993       222.492964            0.590235\n",
      "      7                0.32012745         0.347183  1.563044         2.606929       0.378265  0.389352                  0.630891          0.580369      0.186072                 0.834549   56.304362       160.692886            0.678662\n",
      "      8                0.40020730         0.266354  0.901305         2.265641       0.218121  0.303796                  0.548297          0.525028      0.072176                 0.906726   -9.869466       126.564054            0.668235\n",
      "      9                0.50005758         0.190144  0.554447         1.923954       0.134179  0.229518                  0.465607          0.466021      0.055362                 0.962088  -44.555314        92.395355            0.609543\n",
      "     10                0.60048370         0.140438  0.241673         1.642606       0.058486  0.162196                  0.397519          0.415209      0.024270                 0.986358  -75.832677        64.260556            0.509072\n",
      "     11                0.70175439         0.114322  0.078320         1.416862       0.018954  0.123261                  0.342888          0.373077      0.007931                 0.994289  -92.168047        41.686231            0.385933\n",
      "     12                0.81488733         0.105807  0.035054         1.225022       0.008483  0.110780                  0.296462          0.336662      0.003966                 0.998255  -96.494623        22.502221            0.241912\n",
      "     13                1.00000000         0.104547  0.009426         1.000000       0.002281  0.104718                  0.242005          0.293726      0.001745                 1.000000  -99.057372         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.10564621\n",
      " RMSE: 0.32503262\n",
      " AUC: 0.90420365\n",
      " pr_auc: 0.7830973\n",
      " logloss: 0.35439223\n",
      " mean_per_class_error: 0.20453504\n",
      " default threshold: 0.41580644249916077\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4445   530  0.1065  530 / 4,975\n",
      "     1   465  1072  0.3025  465 / 1,537\n",
      "Totals  4910  1602  0.1528  995 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 29.29 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03086609         0.895320  4.236825         4.236825       1.000000  0.895320                  1.000000          0.895320      0.130774                 0.130774  323.682498       323.682498            0.130774\n",
      "      2                0.04084767         0.870212  4.171643         4.220897       0.984615  0.881027                  0.996241          0.891827      0.041640                 0.172414  317.164306       322.089707            0.172213\n",
      "      3                0.05006143         0.833121  4.236825         4.223829       1.000000  0.852579                  0.996933          0.884604      0.039037                 0.211451  323.682498       322.382859            0.211250\n",
      "      4                0.10012285         0.671948  3.431048         3.827439       0.809816  0.742824                  0.903374          0.813714      0.171763                 0.383214  243.104845       282.743852            0.370551\n",
      "      5                0.15003071         0.556177  2.607277         3.421551       0.615385  0.614168                  0.807574          0.747335      0.130124                 0.513338  160.727691       242.155058            0.475549\n",
      "      6                0.20009214         0.451886  2.157402         3.105271       0.509202  0.500209                  0.732924          0.685506      0.108003                 0.621340  115.740168       210.527081            0.551391\n",
      "      7                0.32708845         0.347183  1.383244         2.436672       0.326481  0.386903                  0.575117          0.569569      0.175667                 0.797007   38.324395       143.667165            0.615098\n",
      "      8                0.40018428         0.274333  1.166017         2.204580       0.275210  0.307401                  0.520338          0.521683      0.085231                 0.882238   16.601696       120.457969            0.630982\n",
      "      9                0.50030713         0.191612  0.656318         1.894737       0.154908  0.234801                  0.447207          0.464271      0.065712                 0.947951  -34.368202        89.473726            0.585941\n",
      "     10                0.60058354         0.140438  0.272506         1.623882       0.064319  0.162427                  0.383278          0.413874      0.027326                 0.975277  -72.749365        62.388153            0.490452\n",
      "     11                0.76167076         0.112802  0.109051         1.303507       0.025739  0.118961                  0.307661          0.351502      0.017567                 0.992843  -89.094921        30.350704            0.302592\n",
      "     12                0.81372850         0.105807  0.062490         1.224114       0.014749  0.108614                  0.288922          0.335964      0.003253                 0.996096  -93.750996        22.411380            0.238709\n",
      "     13                1.00000000         0.104547  0.020957         1.000000       0.004946  0.104738                  0.236026          0.292893      0.003904                 1.000000  -97.904291         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5405.071289          1.000000   0.406153\n",
      "                      capital_gain         2764.262939          0.511420   0.207715\n",
      "                      capital_loss          948.342346          0.175454   0.071261\n",
      "                               age          852.863953          0.157790   0.064087\n",
      "        occupation. Prof-specialty          615.900330          0.113949   0.046281\n",
      "       occupation. Exec-managerial          520.907898          0.096374   0.039143\n",
      "                    hours_per_week          494.797729          0.091543   0.037181\n",
      "              education. Bachelors          379.332092          0.070181   0.028504\n",
      "                education. Masters          179.954559          0.033294   0.013522\n",
      "                            fnlwgt          126.534973          0.023410   0.009508\n",
      "---\n",
      "         occupation. Other-service           14.728625          0.002725   0.001107\n",
      "                relationship. Wife           13.625109          0.002521   0.001024\n",
      "             relationship. Husband           13.061584          0.002417   0.000981\n",
      "                         sex. Male           12.687830          0.002347   0.000953\n",
      "          occupation. Craft-repair            8.471675          0.001567   0.000637\n",
      "       relationship. Not-in-family            7.820740          0.001447   0.000588\n",
      "     marital_status. Never-married            3.721555          0.000689   0.000280\n",
      "                       race. White            1.592937          0.000295   0.000120\n",
      "           relationship. Unmarried            0.907308          0.000168   0.000068\n",
      "         marital_status. Separated            0.267845          0.000050   0.000020\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        21247.210938          1.000000   0.156158\n",
      "                      capital_gain        17252.166016          0.811973   0.126796\n",
      "marital_status. Married-civ-spouse        16607.136719          0.781615   0.122055\n",
      "                    hours_per_week        12292.211914          0.578533   0.090342\n",
      "                      capital_loss        12009.411133          0.565223   0.088264\n",
      "        occupation. Prof-specialty         8809.474609          0.414618   0.064746\n",
      "              education. Bachelors         8609.737305          0.405217   0.063278\n",
      "       occupation. Exec-managerial         6210.583984          0.292301   0.045645\n",
      "                education. Masters         4978.531250          0.234315   0.036590\n",
      "              education. Doctorate         3911.059082          0.184074   0.028745\n",
      "---\n",
      "          marital_status. Divorced          274.445099          0.012917   0.002017\n",
      "                workclass. Private          253.674545          0.011939   0.001864\n",
      "                         sex. Male          227.234344          0.010695   0.001670\n",
      "       relationship. Not-in-family          209.004333          0.009837   0.001536\n",
      "             relationship. Husband          185.749237          0.008742   0.001365\n",
      "                       race. White          178.209839          0.008387   0.001310\n",
      "                relationship. Wife          159.054581          0.007486   0.001169\n",
      "         marital_status. Separated           97.625999          0.004595   0.000718\n",
      "     marital_status. Never-married           91.504028          0.004307   0.000673\n",
      "           relationship. Unmarried           14.000000          0.000659   0.000103\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                        age          137.000000          1.000000   0.305804\n",
      "             hours_per_week           46.000000          0.335766   0.102679\n",
      "                     fnlwgt           42.000000          0.306569   0.093750\n",
      "occupation. Exec-managerial           21.000000          0.153285   0.046875\n",
      " occupation. Prof-specialty           18.000000          0.131387   0.040179\n",
      "               capital_loss           17.000000          0.124088   0.037946\n",
      "               capital_gain           17.000000          0.124088   0.037946\n",
      "       education. Bachelors           15.000000          0.109489   0.033482\n",
      "                sex. Female           13.000000          0.094891   0.029018\n",
      "    education. Some-college           11.000000          0.080292   0.024554\n",
      "---\n",
      "    workclass. Self-emp-inc            2.000000          0.014599   0.004464\n",
      "      relationship. Husband            2.000000          0.014599   0.004464\n",
      "                  sex. Male            2.000000          0.014599   0.004464\n",
      "     native_country. Mexico            2.000000          0.014599   0.004464\n",
      "  occupation. Other-service            1.000000          0.007299   0.002232\n",
      "    relationship. Unmarried            1.000000          0.007299   0.002232\n",
      "            education. 10th            1.000000          0.007299   0.002232\n",
      "            education. 11th            1.000000          0.007299   0.002232\n",
      "         education. 7th-8th            1.000000          0.007299   0.002232\n",
      "  marital_status. Separated            1.000000          0.007299   0.002232\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      "\n",
      "10-20 18:27:41.912 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_316\n",
      "10-20 18:27:41.929 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_316\n",
      "10-20 18:27:41.931 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_315\n",
      "10-20 18:27:41.933 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.09977771\n",
      " RMSE: 0.3158761\n",
      " AUC: 0.9222045\n",
      " pr_auc: 0.82109296\n",
      " logloss: 0.34084675\n",
      " mean_per_class_error: 0.17749718\n",
      " default threshold: 0.391756534576416\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17632  2106  0.1067  2,106 / 19,738\n",
      "     1   1567  4744  0.2483   1,567 / 6,311\n",
      "Totals  19199  6850  0.1410  3,673 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 29.43 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03255403         0.894505  4.122688         4.122688       0.998821  0.894505                  0.998821          0.894505      0.134210                 0.134210   312.268766       312.268766            0.134159\n",
      "      2                0.04007831         0.881952  4.127555         4.123601       1.000000  0.887528                  0.999042          0.893195      0.031057                 0.165267   312.755506       312.360147            0.165216\n",
      "      3                0.05005950         0.853061  4.064054         4.111729       0.984615  0.871178                  0.996166          0.888805      0.040564                 0.205831   306.405422       311.172855            0.205578\n",
      "      4                0.10004223         0.664298  3.617158         3.864633       0.876344  0.745716                  0.936301          0.817315      0.180795                 0.386627   261.715847       286.463329            0.378216\n",
      "      5                0.15002495         0.565281  2.878510         3.536094       0.697389  0.615610                  0.856704          0.750115      0.143876                 0.530502   187.850998       253.609374            0.502131\n",
      "      6                0.20054513         0.469005  2.220600         3.204702       0.537994  0.514428                  0.776417          0.690742      0.112185                 0.642687   122.059953       220.470202            0.583512\n",
      "      7                0.30008830         0.339982  1.585440         2.667572       0.384111  0.407592                  0.646284          0.596817      0.157820                 0.800507    58.543958       166.757173            0.660422\n",
      "      8                0.40005374         0.269196  1.030304         2.258451       0.249616  0.307495                  0.547164          0.524522      0.102995                 0.903502     3.030368       125.845111            0.664420\n",
      "      9                0.50009597         0.200429  0.544850         1.915652       0.132003  0.231077                  0.464113          0.465819      0.054508                 0.958010   -45.515006        91.565195            0.604327\n",
      "     10                0.60009981         0.136348  0.258269         1.639457       0.062572  0.166391                  0.397198          0.415921      0.025828                 0.983838   -74.173072        63.945684            0.506434\n",
      "     11                0.71104457         0.116441  0.089978         1.397691       0.021799  0.122392                  0.338624          0.370121      0.009983                 0.993820   -91.002216        39.769060            0.373190\n",
      "     12                0.80102883         0.110651  0.038740         1.245032       0.009386  0.112768                  0.301639          0.341211      0.003486                 0.997306   -96.126015        24.503171            0.259035\n",
      "     13                0.99969289         0.105483  0.013559         1.000307       0.003285  0.105658                  0.242349          0.294401      0.002694                 1.000000   -98.644088         0.030721            0.000405\n",
      "     14                1.00000000         0.104527  0.000000         1.000000       0.000000  0.104527                  0.242274          0.294343      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.10175566\n",
      " RMSE: 0.31899163\n",
      " AUC: 0.91452116\n",
      " pr_auc: 0.79888064\n",
      " logloss: 0.34521452\n",
      " mean_per_class_error: 0.18324439\n",
      " default threshold: 0.368554025888443\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4387   595  0.1194  595 / 4,982\n",
      "     1   378  1152  0.2471  378 / 1,530\n",
      "Totals  4765  1747  0.1494  973 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 29.07 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03301597         0.894505  4.256209         4.256209       1.000000  0.894505                  1.000000          0.894505      0.140523                 0.140523   325.620915       325.620915            0.140523\n",
      "      2                0.04023342         0.879781  4.165652         4.239964       0.978723  0.886980                  0.996183          0.893155      0.030065                 0.170588   316.565151       323.996408            0.170388\n",
      "      3                0.05006143         0.850929  4.123203         4.217042       0.968750  0.867874                  0.990798          0.888192      0.040523                 0.211111   312.320261       321.704158            0.210509\n",
      "      4                0.10027641         0.657636  3.540333         3.878169       0.831804  0.744799                  0.911179          0.816386      0.177778                 0.388889   254.033299       287.816913            0.377247\n",
      "      5                0.15340909         0.550375  2.644754         3.450980       0.621387  0.601521                  0.810811          0.741968      0.140523                 0.529412   164.475424       245.098039            0.491475\n",
      "      6                0.21314496         0.455214  2.111692         3.075632       0.496144  0.487926                  0.722622          0.670770      0.126144                 0.655556   111.169246       207.563240            0.578277\n",
      "      7                0.31019656         0.336804  1.548937         2.597973       0.363924  0.379736                  0.610396          0.579714      0.150327                 0.805882    54.893687       159.797321            0.647914\n",
      "      8                0.40003071         0.264267  0.894895         2.215516       0.210256  0.297483                  0.520537          0.516334      0.080392                 0.886275   -10.510474       121.551616            0.635572\n",
      "      9                0.50000000         0.201884  0.693023         1.911111       0.162826  0.229452                  0.449017          0.458975      0.069281                 0.955556   -30.697670        91.111111            0.595459\n",
      "     10                0.59996929         0.135718  0.268056         1.637339       0.062980  0.165615                  0.384694          0.410094      0.026797                 0.982353   -73.194382        63.733871            0.499816\n",
      "     11                0.70669533         0.116441  0.122481         1.408563       0.028777  0.122027                  0.330943          0.366590      0.013072                 0.995425   -87.751916        40.856292            0.377400\n",
      "     12                0.80006143         0.107861  0.021001         1.246636       0.004934  0.112657                  0.292898          0.336956      0.001961                 0.997386   -97.899897        24.663631            0.257924\n",
      "     13                0.99984644         0.105483  0.013086         1.000154       0.003075  0.105572                  0.234987          0.290722      0.002614                 1.000000   -98.691404         0.015359            0.000201\n",
      "     14                1.00000000         0.104527  0.000000         1.000000       0.000000  0.104527                  0.234951          0.290694      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5351.461914          1.000000   0.407892\n",
      "                      capital_gain         2807.001465          0.524530   0.213952\n",
      "                      capital_loss          945.502258          0.176681   0.072067\n",
      "                               age          906.508606          0.169395   0.069095\n",
      "                    hours_per_week          561.757507          0.104973   0.042818\n",
      "        occupation. Prof-specialty          544.379272          0.101725   0.041493\n",
      "       occupation. Exec-managerial          524.216003          0.097958   0.039956\n",
      "              education. Bachelors          352.947693          0.065954   0.026902\n",
      "                education. Masters          156.355255          0.029217   0.011918\n",
      "       workclass. Self-emp-not-inc          109.586197          0.020478   0.008353\n",
      "---\n",
      "             education. Assoc-acdm            7.497360          0.001401   0.000571\n",
      "             relationship. Husband            6.320465          0.001181   0.000482\n",
      "          occupation. Craft-repair            5.206692          0.000973   0.000397\n",
      "     occupation. Machine-op-inspct            4.895532          0.000915   0.000373\n",
      "              workclass. Local-gov            3.798979          0.000710   0.000290\n",
      "            native_country. Mexico            2.634361          0.000492   0.000201\n",
      "           workclass. Self-emp-inc            1.841930          0.000344   0.000140\n",
      "                     occupation.NA            0.341675          0.000064   0.000026\n",
      "      occupation. Transport-moving            0.055309          0.000010   0.000004\n",
      "           relationship. Unmarried            0.017906          0.000003   0.000001\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        21104.587891          1.000000   0.158677\n",
      "                      capital_gain        18373.296875          0.870583   0.138142\n",
      "marital_status. Married-civ-spouse        16631.554688          0.788054   0.125046\n",
      "                    hours_per_week        13628.160156          0.645744   0.102465\n",
      "                      capital_loss        11900.585938          0.563886   0.089476\n",
      "              education. Bachelors         8351.166992          0.395704   0.062789\n",
      "        occupation. Prof-specialty         7945.867188          0.376500   0.059742\n",
      "       occupation. Exec-managerial         5836.896973          0.276570   0.043885\n",
      "                education. Masters         5006.604980          0.237228   0.037643\n",
      "       occupation. Protective-serv         1872.378662          0.088719   0.014078\n",
      "---\n",
      "          marital_status. Divorced          170.964371          0.008101   0.001285\n",
      "     occupation. Machine-op-inspct          128.894394          0.006107   0.000969\n",
      "             relationship. Husband          118.805954          0.005629   0.000893\n",
      "     marital_status. Never-married          115.547852          0.005475   0.000869\n",
      "           workclass. Self-emp-inc           90.845917          0.004305   0.000683\n",
      "          occupation. Craft-repair           81.662704          0.003869   0.000614\n",
      "                     occupation.NA           74.569618          0.003533   0.000561\n",
      "           relationship. Unmarried           57.750000          0.002736   0.000434\n",
      "            native_country. Mexico           54.252598          0.002571   0.000408\n",
      "      occupation. Transport-moving           52.196423          0.002473   0.000392\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          136.000000          1.000000   0.296943\n",
      "               hours_per_week           43.000000          0.316176   0.093886\n",
      "                       fnlwgt           28.000000          0.205882   0.061135\n",
      "   occupation. Prof-specialty           20.000000          0.147059   0.043668\n",
      "                 capital_loss           19.000000          0.139706   0.041485\n",
      "                 capital_gain           19.000000          0.139706   0.041485\n",
      "         education. Bachelors           17.000000          0.125000   0.037118\n",
      "  occupation. Exec-managerial           17.000000          0.125000   0.037118\n",
      "           workclass. Private           15.000000          0.110294   0.032751\n",
      "           education. HS-grad           12.000000          0.088235   0.026201\n",
      "---\n",
      "     occupation. Craft-repair            2.000000          0.014706   0.004367\n",
      "      relationship. Unmarried            1.000000          0.007353   0.002183\n",
      "occupation. Machine-op-inspct            1.000000          0.007353   0.002183\n",
      "      workclass. Self-emp-inc            1.000000          0.007353   0.002183\n",
      "        relationship. Husband            1.000000          0.007353   0.002183\n",
      "              education. 11th            1.000000          0.007353   0.002183\n",
      "        education. Assoc-acdm            1.000000          0.007353   0.002183\n",
      "                occupation.NA            1.000000          0.007353   0.002183\n",
      " occupation. Transport-moving            1.000000          0.007353   0.002183\n",
      "       native_country. Mexico            1.000000          0.007353   0.002183\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      "\n",
      "10-20 18:27:41.944 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:41.943) \n",
      "10-20 18:27:41.958 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_315\n",
      "10-20 18:27:41.962 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.09949453\n",
      " RMSE: 0.31542754\n",
      " AUC: 0.92252123\n",
      " pr_auc: 0.82119817\n",
      " logloss: 0.33999872\n",
      " mean_per_class_error: 0.17681079\n",
      " default threshold: 0.3785673677921295\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17744  2024  0.1024  2,024 / 19,768\n",
      "     1   1578  4703  0.2512   1,578 / 6,281\n",
      "Totals  19322  6727  0.1383  3,602 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 29.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03293792         0.896210  4.147270         4.147270       1.000000  0.896210                  1.000000          0.896210      0.136602                 0.136602  314.726954       314.726954            0.136602\n",
      "      2                0.04142194         0.879761  4.128504         4.143426       0.995475  0.883884                  0.999073          0.893685      0.035026                 0.171629  312.850362       314.342592            0.171578\n",
      "      3                0.05005950         0.855958  4.128837         4.140909       0.995556  0.869807                  0.998466          0.889565      0.035663                 0.207292  312.883723       314.090870            0.207191\n",
      "      4                0.10004223         0.681788  3.647176         3.894232       0.879416  0.751313                  0.938987          0.820492      0.182296                 0.389588  264.717636       289.423199            0.381544\n",
      "      5                0.15002495         0.548344  2.834923         3.541310       0.683564  0.613721                  0.853889          0.751603      0.141697                 0.531285  183.492311       254.130974            0.502400\n",
      "      6                0.20042996         0.452569  2.144704         3.190085       0.517136  0.499440                  0.769201          0.688188      0.108104                 0.639389  114.470375       219.008513            0.578432\n",
      "      7                0.30066413         0.337498  1.655096         2.678357       0.399081  0.390381                  0.645812          0.588906      0.165897                 0.805286   65.509570       167.835666            0.664958\n",
      "      8                0.40001536         0.274458  0.977525         2.255924       0.235703  0.306776                  0.543954          0.518834      0.097118                 0.902404   -2.247511       125.592359            0.662016\n",
      "      9                0.50021114         0.198833  0.589516         1.922131       0.142146  0.236463                  0.463469          0.462273      0.059067                 0.961471  -41.048391        92.213053            0.607819\n",
      "     10                0.60501363         0.136802  0.224834         1.628119       0.054212  0.165078                  0.392576          0.410792      0.023563                 0.985034  -77.516634        62.811908            0.500767\n",
      "     11                0.75212100         0.113524  0.073595         1.324070       0.017745  0.119195                  0.319263          0.353759      0.010826                 0.995861  -92.640545        32.406957            0.321184\n",
      "     12                0.80076011         0.109266  0.032733         1.245632       0.007893  0.111529                  0.300350          0.339045      0.001592                 0.997453  -96.726701        24.563228            0.259189\n",
      "     13                1.00000000         0.104469  0.012785         1.000000       0.003083  0.104634                  0.241122          0.292341      0.002547                 1.000000  -98.721458         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.10302206\n",
      " RMSE: 0.3209705\n",
      " AUC: 0.91245556\n",
      " pr_auc: 0.796237\n",
      " logloss: 0.34788212\n",
      " mean_per_class_error: 0.19088584\n",
      " default threshold: 0.3834967613220215\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4382   570  0.1151  570 / 4,952\n",
      "     1   416  1144  0.2667  416 / 1,560\n",
      "Totals  4798  1714  0.1514  986 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 29.43 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03378378         0.896210  4.136410         4.136410       0.990909  0.896210                  0.990909          0.896210      0.139744                 0.139744  313.641026       313.641026            0.139340\n",
      "      2                0.04315111         0.879761  4.105927         4.129793       0.983607  0.883608                  0.989324          0.893474      0.038462                 0.178205  310.592686       312.979286            0.177599\n",
      "      3                0.05144349         0.866873  4.174359         4.136977       1.000000  0.871495                  0.991045          0.889931      0.034615                 0.212821  317.435897       313.697666            0.212215\n",
      "      4                0.10012285         0.683731  3.450101         3.803020       0.826498  0.756899                  0.911043          0.825251      0.167949                 0.380769  245.010111       280.302029            0.369057\n",
      "      5                0.15033784         0.565959  2.719078         3.440968       0.651376  0.625031                  0.824311          0.758375      0.136538                 0.517308  171.907786       244.096802            0.482574\n",
      "      6                0.20009214         0.467456  2.177366         3.126765       0.521605  0.516895                  0.749041          0.698329      0.108333                 0.625641  117.736626       212.676467            0.559607\n",
      "      7                0.30006143         0.343654  1.564583         2.606304       0.374808  0.400924                  0.624360          0.599245      0.156410                 0.782051   56.458309       160.630397            0.633828\n",
      "      8                0.40064496         0.269004  1.147152         2.239978       0.274809  0.307555                  0.536604          0.526015      0.115385                 0.897436   14.715208       123.997799            0.653292\n",
      "      9                0.50000000         0.192608  0.548409         1.903846       0.131376  0.232531                  0.456081          0.467697      0.054487                 0.951923  -45.159117        90.384615            0.594290\n",
      "     10                0.59996929         0.134527  0.301375         1.636836       0.072197  0.161786                  0.392117          0.416725      0.030128                 0.982051  -69.862539        63.683592            0.502447\n",
      "     11                0.74585381         0.113524  0.052729         1.326994       0.012632  0.119043                  0.317892          0.358500      0.007692                 0.989744  -94.727126        32.699408            0.320721\n",
      "     12                0.80021499         0.109105  0.094336         1.243256       0.022599  0.111515                  0.297832          0.341721      0.005128                 0.994872  -90.566420        24.325564            0.255978\n",
      "     13                1.00000000         0.104469  0.025669         1.000000       0.006149  0.104569                  0.239558          0.294342      0.005128                 1.000000  -97.433138         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5235.750000          1.000000   0.402841\n",
      "                      capital_gain         2788.036865          0.532500   0.214513\n",
      "                      capital_loss          924.550354          0.176584   0.071135\n",
      "                               age          903.669067          0.172596   0.069529\n",
      "        occupation. Prof-specialty          573.851257          0.109602   0.044152\n",
      "       occupation. Exec-managerial          503.900513          0.096242   0.038770\n",
      "                    hours_per_week          463.828369          0.088589   0.035687\n",
      "              education. Bachelors          345.134888          0.065919   0.026555\n",
      "                education. HS-grad          136.412659          0.026054   0.010496\n",
      "       workclass. Self-emp-not-inc          129.781982          0.024788   0.009985\n",
      "---\n",
      "             relationship. Husband           10.585968          0.002022   0.000814\n",
      "                education. 7th-8th            9.995115          0.001909   0.000769\n",
      "                   education. 10th            8.972065          0.001714   0.000690\n",
      "                       race. White            8.600249          0.001643   0.000662\n",
      "     occupation. Handlers-cleaners            8.024657          0.001533   0.000617\n",
      "              workclass. State-gov            3.869537          0.000739   0.000298\n",
      "              workclass. Local-gov            3.484098          0.000665   0.000268\n",
      "           relationship. Unmarried            1.688430          0.000322   0.000130\n",
      "     marital_status. Never-married            1.085388          0.000207   0.000084\n",
      "       occupation. Farming-fishing            1.062531          0.000203   0.000082\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        21108.578125          1.000000   0.160538\n",
      "                      capital_gain        17989.511719          0.852237   0.136817\n",
      "marital_status. Married-civ-spouse        16623.546875          0.787526   0.126428\n",
      "                      capital_loss        12529.255859          0.593562   0.095289\n",
      "                    hours_per_week        12150.706055          0.575629   0.092410\n",
      "        occupation. Prof-specialty         9040.639648          0.428292   0.068757\n",
      "              education. Bachelors         6705.301270          0.317658   0.050996\n",
      "       occupation. Exec-managerial         6627.106934          0.313953   0.050402\n",
      "                education. Masters         2801.402832          0.132714   0.021306\n",
      "                       sex. Female         2057.724365          0.097483   0.015650\n",
      "---\n",
      "                education. 7th-8th          241.005249          0.011417   0.001833\n",
      "       occupation. Farming-fishing          235.802246          0.011171   0.001793\n",
      "     occupation. Handlers-cleaners          233.668701          0.011070   0.001777\n",
      "                   education. 10th          228.659500          0.010833   0.001739\n",
      "             relationship. Husband          227.710846          0.010788   0.001732\n",
      "          marital_status. Divorced          209.839630          0.009941   0.001596\n",
      "                       race. White          192.457504          0.009118   0.001464\n",
      "              workclass. State-gov          142.389999          0.006746   0.001083\n",
      "              workclass. Local-gov          131.107681          0.006211   0.000997\n",
      "           relationship. Unmarried           17.921309          0.000849   0.000136\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          138.000000          1.000000   0.310112\n",
      "               hours_per_week           37.000000          0.268116   0.083146\n",
      "                       fnlwgt           31.000000          0.224638   0.069663\n",
      "   occupation. Prof-specialty           21.000000          0.152174   0.047191\n",
      "                 capital_gain           21.000000          0.152174   0.047191\n",
      "  occupation. Exec-managerial           20.000000          0.144928   0.044944\n",
      "                 capital_loss           18.000000          0.130435   0.040449\n",
      "           education. HS-grad           14.000000          0.101449   0.031461\n",
      "         education. Bachelors           13.000000          0.094203   0.029213\n",
      "  workclass. Self-emp-not-inc           12.000000          0.086957   0.026966\n",
      "---\n",
      "         workclass. Local-gov            2.000000          0.014493   0.004494\n",
      "         workclass. State-gov            1.000000          0.007246   0.002247\n",
      "      relationship. Unmarried            1.000000          0.007246   0.002247\n",
      "  occupation. Farming-fishing            1.000000          0.007246   0.002247\n",
      "occupation. Handlers-cleaners            1.000000          0.007246   0.002247\n",
      "         education. Assoc-voc            1.000000          0.007246   0.002247\n",
      "marital_status. Never-married            1.000000          0.007246   0.002247\n",
      "              education. 10th            1.000000          0.007246   0.002247\n",
      "              education. 11th            1.000000          0.007246   0.002247\n",
      "           education. 7th-8th            1.000000          0.007246   0.002247\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      "\n",
      "10-20 18:27:41.972 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:41.972) \n",
      "10-20 18:27:41.994 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:41.994) \n",
      "10-20 18:27:41.997 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:41.997) \n",
      "10-20 18:27:42.014 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:42.014) \n",
      "10-20 18:27:42.034 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:42.033) \n",
      "10-20 18:27:42.049 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:42.049) \n",
      "10-20 18:27:42.068 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:42.068) \n",
      "█10-20 18:27:42.087 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:42.087) \n",
      "10-20 18:27:42.097 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:42.097) \n",
      "10-20 18:27:42.108 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:42.108) \n",
      "10-20 18:27:42.159 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.091 (Wall: 20-Oct 18:27:42.159) \n",
      "10-20 18:27:42.192 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:42.192) \n",
      "10-20 18:27:42.197 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.100 (Wall: 20-Oct 18:27:42.197) \n",
      "10-20 18:27:42.202 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:42.202) \n",
      "10-20 18:27:42.205 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.097 (Wall: 20-Oct 18:27:42.205) \n",
      "10-20 18:27:42.263 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:42.263) \n",
      "10-20 18:27:42.266 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:42.266) \n",
      "10-20 18:27:42.328 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_317\n",
      "10-20 18:27:42.331 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.139 (Wall: 20-Oct 18:27:42.331) \n",
      "10-20 18:27:42.347 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_318\n",
      "10-20 18:27:42.375 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_319\n",
      "10-20 18:27:42.382 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_318\n",
      "10-20 18:27:42.382 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_317\n",
      "10-20 18:27:42.403 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:42.403) \n",
      "10-20 18:27:42.429 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_319\n",
      "10-20 18:27:42.466 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_320\n",
      "10-20 18:27:42.480 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_321\n",
      "10-20 18:27:42.492 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_322\n",
      "10-20 18:27:42.493 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_320\n",
      "10-20 18:27:42.498 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.0880309\n",
      " RMSE: 0.2967\n",
      " AUC: 0.93138397\n",
      " pr_auc: 0.8346791\n",
      " logloss: 0.28602618\n",
      " mean_per_class_error: 0.16756849\n",
      " default threshold: 0.36632123589515686\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17740  2093  0.1055  2,093 / 19,833\n",
      "     1   1427  4788  0.2296   1,427 / 6,215\n",
      "Totals  19167  6881  0.1351  3,520 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 25.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01063421         0.974416  4.191150         4.191150       1.000000  0.974416                  1.000000          0.974416      0.044570                 0.044570   319.115044       319.115044            0.044570\n",
      "      2                0.02000154         0.970017  4.191150         4.191150       1.000000  0.974249                  1.000000          0.974338      0.039260                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.963813  4.191150         4.191150       1.000000  0.968101                  1.000000          0.972256      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04007985         0.948917  4.175154         4.187136       0.996183  0.957021                  0.999042          0.968433      0.041995                 0.167820   317.515369       318.713593            0.167769\n",
      "      5                0.05002303         0.925826  4.158786         4.181501       0.992278  0.938217                  0.997698          0.962427      0.041352                 0.209171   315.878635       318.150083            0.209020\n",
      "      6                0.10012285         0.686027  3.709409         3.945274       0.885057  0.788237                  0.941334          0.875265      0.185841                 0.395012   270.940901       294.527390            0.387298\n",
      "      7                0.15006910         0.569263  2.973430         3.621823       0.709454  0.624573                  0.864160          0.791829      0.148512                 0.543524   197.342956       262.182302            0.516750\n",
      "      8                0.20112869         0.461010  2.278347         3.280761       0.543609  0.514653                  0.782783          0.721464      0.116331                 0.659855   127.834720       228.076121            0.602476\n",
      "      9                0.31073403         0.326625  1.598656         2.687432       0.381436  0.376330                  0.641216          0.599725      0.175221                 0.835076    59.865598       168.743153            0.688654\n",
      "     10                0.39999232         0.217652  0.984244         2.307365       0.234839  0.268795                  0.550533          0.525878      0.087852                 0.922928    -1.575564       130.736529            0.686807\n",
      "     11                0.50000000         0.122001  0.466577         1.939179       0.111324  0.168311                  0.462684          0.454359      0.046661                 0.969590   -53.342279        93.917940            0.616743\n",
      "     12                0.60000768         0.064880  0.176978         1.645460       0.042226  0.090162                  0.392603          0.393655      0.017699                 0.987289   -82.302244        64.546031            0.508642\n",
      "     13                0.70009214         0.042524  0.091636         1.423327       0.021864  0.052062                  0.339603          0.344822      0.009171                 0.996460   -90.836380        42.332719            0.389240\n",
      "     14                0.79998464         0.032505  0.025772         1.248817       0.006149  0.037281                  0.297965          0.306420      0.002574                 0.999035   -97.422813        24.881721            0.261426\n",
      "     15                0.90152795         0.025241  0.009507         1.109228       0.002268  0.028871                  0.264660          0.275158      0.000965                 1.000000   -99.049266        10.922795            0.129330\n",
      "     16                1.00000000         0.024089  0.000000         1.000000       0.000000  0.024282                  0.238598          0.250454      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09378952\n",
      " RMSE: 0.30625075\n",
      " AUC: 0.92161256\n",
      " pr_auc: 0.8280079\n",
      " logloss: 0.3021777\n",
      " mean_per_class_error: 0.17590234\n",
      " default threshold: 0.3661271035671234\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4400   487  0.0997  487 / 4,887\n",
      "     1   410  1216  0.2522  410 / 1,626\n",
      "Totals  4810  1703  0.1377  897 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 25.24 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01919238         0.974328  4.005535         4.005535       1.000000  0.974378                  1.000000          0.974378      0.076876                 0.076876   300.553506       300.553506            0.076876\n",
      "      2                0.02226317         0.970005  4.005535         4.005535       1.000000  0.970101                  1.000000          0.973788      0.012300                 0.089176   300.553506       300.553506            0.089176\n",
      "      3                0.03009366         0.963671  4.005535         4.005535       1.000000  0.967762                  1.000000          0.972220      0.031365                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04022724         0.950280  4.005535         4.005535       1.000000  0.956850                  1.000000          0.968348      0.040590                 0.161132   300.553506       300.553506            0.161132\n",
      "      5                0.05005374         0.930675  4.005535         4.005535       1.000000  0.939617                  1.000000          0.962708      0.039360                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10026102         0.701105  3.625805         3.815379       0.905199  0.807250                  0.952527          0.884860      0.182042                 0.382534   262.580543       281.537949            0.376190\n",
      "      7                0.15185015         0.569883  2.789569         3.466874       0.696429  0.631582                  0.865521          0.798812      0.143911                 0.526445   178.956906       246.687362            0.499230\n",
      "      8                0.20113619         0.461010  2.320964         3.186082       0.579439  0.513342                  0.795420          0.728861      0.114391                 0.640836   132.096424       218.608208            0.585997\n",
      "      9                0.30784585         0.326625  1.556107         2.621078       0.388489  0.376493                  0.654364          0.606718      0.166052                 0.806888    55.610714       162.107830            0.665083\n",
      "     10                0.39996929         0.221320  0.907921         2.226493       0.226667  0.269194                  0.555854          0.528978      0.083641                 0.890529    -9.207872       122.649319            0.653778\n",
      "     11                0.50023031         0.126856  0.637941         1.908100       0.159265  0.172025                  0.476366          0.457434      0.063961                 0.954490   -36.205874        90.810019            0.605400\n",
      "     12                0.60003071         0.065530  0.289631         1.638908       0.072308  0.092395                  0.409161          0.396719      0.028905                 0.983395   -71.036900        63.890751            0.510917\n",
      "     13                0.70013819         0.042498  0.073722         1.415113       0.018405  0.052150                  0.353289          0.347451      0.007380                 0.990775   -92.627850        41.511337            0.387337\n",
      "     14                0.80132044         0.033207  0.060782         1.244103       0.015175  0.037721                  0.310596          0.308342      0.006150                 0.996925   -93.921798        24.410276            0.260686\n",
      "     15                0.90265623         0.025450  0.030345         1.107841       0.007576  0.029367                  0.276578          0.277023      0.003075                 1.000000   -96.965504        10.784147            0.129732\n",
      "     16                1.00000000         0.024089  0.000000         1.000000       0.000000  0.024315                  0.249655          0.252423      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5081.705078          1.000000   0.319831\n",
      "                      capital_gain         3450.015625          0.678909   0.217136\n",
      "                               age         1177.406982          0.231695   0.074103\n",
      "                      capital_loss         1117.485352          0.219904   0.070332\n",
      "                    hours_per_week          819.360046          0.161237   0.051569\n",
      "     marital_status. Never-married          662.601196          0.130390   0.041703\n",
      "        occupation. Prof-specialty          498.088562          0.098016   0.031349\n",
      "       occupation. Exec-managerial          461.819275          0.090879   0.029066\n",
      "                            fnlwgt          340.933044          0.067090   0.021458\n",
      "              education. Bachelors          326.543396          0.064259   0.020552\n",
      "---\n",
      "          race. Asian-Pac-Islander            8.024557          0.001579   0.000505\n",
      "              workclass. Local-gov            4.731589          0.000931   0.000298\n",
      "              education. Assoc-voc            4.031647          0.000793   0.000254\n",
      "              workclass. State-gov            3.142525          0.000618   0.000198\n",
      "           marital_status. Widowed            2.031811          0.000400   0.000128\n",
      "                     occupation.NA            1.850180          0.000364   0.000116\n",
      "      occupation. Transport-moving            1.547573          0.000305   0.000097\n",
      "                       race. Black            0.585720          0.000115   0.000037\n",
      "     occupation. Machine-op-inspct            0.397594          0.000078   0.000025\n",
      "           relationship. Own-child            0.392542          0.000077   0.000025\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        41350.058594          1.000000   0.183708\n",
      "                               age        27745.980469          0.671002   0.123269\n",
      "marital_status. Married-civ-spouse        23017.949219          0.556661   0.102263\n",
      "                    hours_per_week        21297.654297          0.515057   0.094620\n",
      "                      capital_loss        21267.501953          0.514328   0.094486\n",
      "        occupation. Prof-specialty         9038.314453          0.218580   0.040155\n",
      "       occupation. Exec-managerial         7473.775391          0.180744   0.033204\n",
      "              education. Bachelors         6986.158203          0.168952   0.031038\n",
      "     marital_status. Never-married         6250.455566          0.151160   0.027769\n",
      "                            fnlwgt         5455.119141          0.131925   0.024236\n",
      "---\n",
      "     native_country. United-States          202.676392          0.004901   0.000900\n",
      "          race. Asian-Pac-Islander          202.484787          0.004897   0.000900\n",
      "             relationship. Husband          193.688095          0.004684   0.000861\n",
      "           marital_status. Widowed          110.467537          0.002672   0.000491\n",
      "      occupation. Transport-moving          105.390991          0.002549   0.000468\n",
      "     occupation. Machine-op-inspct           95.182678          0.002302   0.000423\n",
      "              workclass. State-gov           51.000000          0.001233   0.000227\n",
      "                       race. Black           49.947670          0.001208   0.000222\n",
      "           relationship. Own-child           20.981199          0.000507   0.000093\n",
      "                     occupation.NA           16.088591          0.000389   0.000071\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          158.000000          1.000000   0.199495\n",
      "                       fnlwgt          146.000000          0.924051   0.184343\n",
      "               hours_per_week           85.000000          0.537975   0.107323\n",
      "                 capital_loss           43.000000          0.272152   0.054293\n",
      "                 capital_gain           42.000000          0.265823   0.053030\n",
      "   occupation. Prof-specialty           31.000000          0.196203   0.039141\n",
      "  occupation. Exec-managerial           23.000000          0.145570   0.029040\n",
      "         education. Bachelors           23.000000          0.145570   0.029040\n",
      "           education. HS-grad           19.000000          0.120253   0.023990\n",
      "      education. Some-college           16.000000          0.101266   0.020202\n",
      "---\n",
      "      marital_status. Widowed            1.000000          0.006329   0.001263\n",
      "occupation. Handlers-cleaners            1.000000          0.006329   0.001263\n",
      "         education. Assoc-voc            1.000000          0.006329   0.001263\n",
      "                occupation.NA            1.000000          0.006329   0.001263\n",
      "                  race. Black            1.000000          0.006329   0.001263\n",
      "         workclass. State-gov            1.000000          0.006329   0.001263\n",
      "occupation. Machine-op-inspct            1.000000          0.006329   0.001263\n",
      "      relationship. Own-child            1.000000          0.006329   0.001263\n",
      " occupation. Transport-moving            1.000000          0.006329   0.001263\n",
      "           education. 5th-6th            1.000000          0.006329   0.001263\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      "\n",
      "10-20 18:27:42.525 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_322\n",
      "10-20 18:27:42.530 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_321\n",
      "10-20 18:27:42.530 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.08747311\n",
      " RMSE: 0.29575855\n",
      " AUC: 0.93335\n",
      " pr_auc: 0.8407858\n",
      " logloss: 0.28450713\n",
      " mean_per_class_error: 0.16672006\n",
      " default threshold: 0.3862575590610504\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17944  1801  0.0912  1,801 / 19,745\n",
      "     1   1527  4777  0.2422   1,527 / 6,304\n",
      "Totals  19471  6578  0.1278  3,328 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 25.29 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02337902         0.974580  4.132138         4.132138       1.000000  0.974582                  1.000000          0.974582      0.096605                 0.096605   313.213832       313.213832            0.096605\n",
      "      2                0.03017390         0.968626  4.108793         4.126881       0.994350  0.970761                  0.998728          0.973721      0.027919                 0.124524   310.879291       312.688115            0.124473\n",
      "      3                0.04003992         0.945571  4.116060         4.124215       0.996109  0.957857                  0.998082          0.969812      0.040609                 0.165133   311.605997       312.421476            0.165032\n",
      "      4                0.05017467         0.922787  4.085182         4.116331       0.988636  0.932838                  0.996174          0.962344      0.041402                 0.206536   308.518221       311.633060            0.206282\n",
      "      5                0.10000384         0.709923  3.746939         3.932273       0.906780  0.802336                  0.951631          0.882617      0.186707                 0.393242   274.693899       293.227290            0.386861\n",
      "      6                0.15002495         0.582301  2.914378         3.592888       0.705295  0.648240                  0.869498          0.804471      0.145780                 0.539023   191.437845       259.288793            0.513194\n",
      "      7                0.20004607         0.451364  2.397465         3.293975       0.580200  0.517708                  0.797160          0.732767      0.119924                 0.658947   139.746475       229.397478            0.605414\n",
      "      8                0.30308265         0.333691  1.658090         2.737836       0.401267  0.384845                  0.662571          0.614487      0.170844                 0.829791    65.808978       173.783605            0.694870\n",
      "      9                0.40016891         0.220744  0.964002         2.307481       0.233294  0.274349                  0.558423          0.531965      0.093591                 0.923382    -3.599778       130.748054            0.690260\n",
      "     10                0.50001919         0.126275  0.452772         1.937108       0.109573  0.172761                  0.468791          0.460234      0.045209                 0.968591   -54.722821        93.710838            0.618174\n",
      "     11                0.60013820         0.065492  0.199636         1.647252       0.048313  0.090294                  0.398644          0.398518      0.019987                 0.988579   -80.036448        64.725171            0.512458\n",
      "     12                0.70014204         0.040402  0.076139         1.422844       0.018426  0.050025                  0.344336          0.348742      0.007614                 0.996193   -92.386079        42.284399            0.390571\n",
      "     13                0.80014588         0.031280  0.022207         1.247790       0.005374  0.035284                  0.301972          0.309565      0.002221                 0.998414   -97.779273        24.778960            0.261569\n",
      "     14                0.90110945         0.025675  0.015712         1.109743       0.003802  0.028203                  0.268564          0.278040      0.001586                 1.000000   -98.428845        10.974311            0.130463\n",
      "     15                1.00000000         0.023785  0.000000         1.000000       0.000000  0.024076                  0.242005          0.252926      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09613669\n",
      " RMSE: 0.31005916\n",
      " AUC: 0.9115398\n",
      " pr_auc: 0.7971806\n",
      " logloss: 0.30820593\n",
      " mean_per_class_error: 0.19314392\n",
      " default threshold: 0.3907991647720337\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4458   517  0.1039  517 / 4,975\n",
      "     1   434  1103  0.2824  434 / 1,537\n",
      "Totals  4892  1620  0.1460  951 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 25.12 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02410934         0.974580  4.236825         4.236825       1.000000  0.974580                  1.000000          0.974580      0.102147                 0.102147   323.682498       323.682498            0.102147\n",
      "      2                0.03055897         0.965148  4.236825         4.236825       1.000000  0.969448                  1.000000          0.973497      0.027326                 0.129473   323.682498       323.682498            0.129473\n",
      "      3                0.04023342         0.939151  4.236825         4.236825       1.000000  0.952053                  1.000000          0.968341      0.040989                 0.170462   323.682498       323.682498            0.170462\n",
      "      4                0.05021499         0.909987  4.171643         4.223868       0.984615  0.925037                  0.996942          0.959733      0.041640                 0.212101   317.164306       322.386833            0.211900\n",
      "      5                0.10012285         0.694149  3.493751         3.859930       0.824615  0.783362                  0.911043          0.871818      0.174366                 0.386467   249.375106       285.992951            0.374809\n",
      "      6                0.15018428         0.569162  2.781229         3.500363       0.656442  0.632137                  0.826176          0.791924      0.139232                 0.525699   178.122867       250.036256            0.491529\n",
      "      7                0.20009214         0.442692  2.151003         3.163799       0.507692  0.503475                  0.746738          0.719978      0.107352                 0.633051   115.100345       216.379947            0.566720\n",
      "      8                0.30835381         0.333691  1.448333         2.561507       0.341844  0.380556                  0.604582          0.600808      0.156799                 0.789850    44.833308       156.150674            0.630252\n",
      "      9                0.40003071         0.227295  1.107110         2.228196       0.261307  0.278549                  0.525912          0.526955      0.101496                 0.891347    10.711005       122.819586            0.643106\n",
      "     10                0.50000000         0.126576  0.605261         1.903709       0.142857  0.176725                  0.449324          0.456930      0.060507                 0.951854   -39.473929        90.370852            0.591452\n",
      "     11                0.59996929         0.063857  0.260327         1.629882       0.061444  0.090062                  0.384694          0.395801      0.026025                 0.977879   -73.967281        62.988174            0.494663\n",
      "     12                0.70024570         0.040053  0.110300         1.412275       0.026034  0.049411                  0.333333          0.346197      0.011061                 0.988939   -88.969981        41.227499            0.377884\n",
      "     13                0.80098280         0.031866  0.071044         1.243593       0.016768  0.035199                  0.293520          0.307084      0.007157                 0.996096   -92.895568        24.359261            0.255393\n",
      "     14                0.90248771         0.026452  0.038458         1.108048       0.009077  0.028385                  0.261528          0.275738      0.003904                 1.000000   -96.154168        10.804832            0.127638\n",
      "     15                1.00000000         0.023785  0.000000         1.000000       0.000000  0.024159                  0.236026          0.251206      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6109.325195          1.000000   0.378500\n",
      "                      capital_gain         3422.335449          0.560182   0.212029\n",
      "                               age         1241.993774          0.203295   0.076947\n",
      "                      capital_loss         1099.731689          0.180009   0.068133\n",
      "                    hours_per_week          681.004150          0.111470   0.042191\n",
      "        occupation. Prof-specialty          639.950012          0.104750   0.039648\n",
      "       occupation. Exec-managerial          541.326172          0.088607   0.033538\n",
      "              education. Bachelors          409.700836          0.067062   0.025383\n",
      "                            fnlwgt          266.258636          0.043582   0.016496\n",
      "                education. Masters          222.336334          0.036393   0.013775\n",
      "---\n",
      "     marital_status. Never-married            9.319324          0.001525   0.000577\n",
      "                       race. White            7.567312          0.001239   0.000469\n",
      "           marital_status. Widowed            6.161215          0.001008   0.000382\n",
      "              workclass. Local-gov            4.434198          0.000726   0.000275\n",
      "              education. Assoc-voc            3.880440          0.000635   0.000240\n",
      "      occupation. Transport-moving            2.426607          0.000397   0.000150\n",
      "                     occupation.NA            2.357271          0.000386   0.000146\n",
      "                       race. Black            1.005824          0.000165   0.000062\n",
      "           relationship. Unmarried            0.907308          0.000149   0.000056\n",
      "         marital_status. Separated            0.267845          0.000044   0.000017\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        43552.804688          1.000000   0.190946\n",
      "                               age        31429.039063          0.721631   0.137792\n",
      "marital_status. Married-civ-spouse        26788.148438          0.615073   0.117445\n",
      "                      capital_loss        18128.435547          0.416240   0.079479\n",
      "                    hours_per_week        17480.925781          0.401373   0.076640\n",
      "              education. Bachelors        10331.240234          0.237212   0.045295\n",
      "        occupation. Prof-specialty         9303.124023          0.213606   0.040787\n",
      "                education. Masters         7311.094238          0.167867   0.032054\n",
      "       occupation. Exec-managerial         7023.638184          0.161267   0.030793\n",
      "                            fnlwgt         6643.413086          0.152537   0.029126\n",
      "---\n",
      "     marital_status. Never-married          192.115692          0.004411   0.000842\n",
      "             relationship. Husband          185.749237          0.004265   0.000814\n",
      "           marital_status. Widowed          159.965958          0.003673   0.000701\n",
      "              education. Assoc-voc          118.935387          0.002731   0.000521\n",
      "              workclass. Local-gov           97.833755          0.002246   0.000429\n",
      "         marital_status. Separated           97.625999          0.002242   0.000428\n",
      "      occupation. Transport-moving           83.694038          0.001922   0.000367\n",
      "                       race. Black           66.348007          0.001523   0.000291\n",
      "                     occupation.NA           63.607670          0.001460   0.000279\n",
      "           relationship. Unmarried           14.000000          0.000321   0.000061\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          200.000000          1.000000   0.268456\n",
      "                       fnlwgt           99.000000          0.495000   0.132886\n",
      "               hours_per_week           71.000000          0.355000   0.095302\n",
      "                 capital_gain           50.000000          0.250000   0.067114\n",
      "                 capital_loss           28.000000          0.140000   0.037584\n",
      "  occupation. Exec-managerial           26.000000          0.130000   0.034899\n",
      "                  sex. Female           25.000000          0.125000   0.033557\n",
      "   occupation. Prof-specialty           21.000000          0.105000   0.028188\n",
      "         education. Bachelors           18.000000          0.090000   0.024161\n",
      "           education. HS-grad           18.000000          0.090000   0.024161\n",
      "---\n",
      "      workclass. Self-emp-inc            2.000000          0.010000   0.002685\n",
      "        relationship. Husband            2.000000          0.010000   0.002685\n",
      "      relationship. Unmarried            1.000000          0.005000   0.001342\n",
      "occupation. Handlers-cleaners            1.000000          0.005000   0.001342\n",
      "         education. Assoc-voc            1.000000          0.005000   0.001342\n",
      "                occupation.NA            1.000000          0.005000   0.001342\n",
      "    marital_status. Separated            1.000000          0.005000   0.001342\n",
      "                  race. Black            1.000000          0.005000   0.001342\n",
      " occupation. Transport-moving            1.000000          0.005000   0.001342\n",
      "               education. 9th            1.000000          0.005000   0.001342\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      "\n",
      "10-20 18:27:42.591 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.087 (Wall: 20-Oct 18:27:42.591) \n",
      "10-20 18:27:42.591 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_323\n",
      "10-20 18:27:42.602 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:42.602) \n",
      "10-20 18:27:42.612 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_323\n",
      "10-20 18:27:42.617 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.08851301\n",
      " RMSE: 0.29751137\n",
      " AUC: 0.930563\n",
      " pr_auc: 0.8363083\n",
      " logloss: 0.28785235\n",
      " mean_per_class_error: 0.16929406\n",
      " default threshold: 0.3916528522968292\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17862  1876  0.0950  1,876 / 19,738\n",
      "     1   1537  4774  0.2435   1,537 / 6,311\n",
      "Totals  19399  6650  0.1310  3,413 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 25.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02760183         0.974889  4.127555         4.127555       1.000000  0.974889                  1.000000          0.974889      0.113928                 0.113928   312.755506       312.755506            0.113928\n",
      "      2                0.03032746         0.968724  4.127555         4.127555       1.000000  0.969438                  1.000000          0.974399      0.011250                 0.125178   312.755506       312.755506            0.125178\n",
      "      3                0.04007831         0.945987  4.095055         4.119648       0.992126  0.956236                  0.998084          0.969980      0.039930                 0.165109   309.505463       311.964787            0.165007\n",
      "      4                0.05002111         0.920843  4.095682         4.114884       0.992278  0.934051                  0.996930          0.962838      0.040723                 0.205831   309.568205       311.488413            0.205628\n",
      "      5                0.10000384         0.707783  3.690072         3.902560       0.894009  0.799693                  0.945489          0.881297      0.184440                 0.390271   269.007227       290.255974            0.383077\n",
      "      6                0.15033207         0.581723  2.956350         3.585787       0.716247  0.642670                  0.868744          0.801409      0.148788                 0.539059   195.634951       258.578711            0.513018\n",
      "      7                0.20000768         0.473641  2.280682         3.261640       0.552550  0.525919                  0.790211          0.732986      0.113294                 0.652353   128.068151       226.163996            0.596978\n",
      "      8                0.30001152         0.323600  1.649438         2.724239       0.399616  0.396682                  0.660013          0.620885      0.164950                 0.817303    64.943755       172.423916            0.682690\n",
      "      9                0.40001536         0.210806  1.036246         2.302241       0.251056  0.265663                  0.557774          0.532080      0.103629                 0.920932     3.624607       130.224089            0.687473\n",
      "     10                0.50001919         0.125830  0.432561         1.928305       0.104798  0.167508                  0.467179          0.459165      0.043258                 0.964190   -56.743857        92.830499            0.612583\n",
      "     11                0.59998464         0.065167  0.209231         1.641884       0.050691  0.091092                  0.397786          0.397839      0.020916                 0.985105   -79.076910        64.188431            0.508259\n",
      "     12                0.69998848         0.041475  0.098237         1.421351       0.023800  0.051567                  0.344357          0.348369      0.009824                 0.994929   -90.176261        42.135123            0.389245\n",
      "     13                0.79999232         0.031966  0.034858         1.248031       0.008445  0.036123                  0.302366          0.309336      0.003486                 0.998415   -96.514157        24.803131            0.261867\n",
      "     14                0.90717494         0.026821  0.014784         1.102323       0.003582  0.028440                  0.267064          0.276149      0.001585                 1.000000   -98.521649        10.232322            0.122505\n",
      "     15                1.00000000         0.024295  0.000000         1.000000       0.000000  0.024738                  0.242274          0.252811      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.09150596\n",
      " RMSE: 0.30249953\n",
      " AUC: 0.9215458\n",
      " pr_auc: 0.81372374\n",
      " logloss: 0.2955652\n",
      " mean_per_class_error: 0.17036822\n",
      " default threshold: 0.3316384553909302\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4359   623  0.1251  623 / 4,982\n",
      "     1   330  1200  0.2157  330 / 1,530\n",
      "Totals  4689  1823  0.1463  953 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 24.76 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02733415         0.974889  4.256209         4.256209       1.000000  0.974889                  1.000000          0.974889      0.116340                 0.116340   325.620915       325.620915            0.116340\n",
      "      2                0.03009828         0.968579  4.256209         4.256209       1.000000  0.969333                  1.000000          0.974379      0.011765                 0.128105   325.620915       325.620915            0.128105\n",
      "      3                0.04007985         0.947522  4.125249         4.223595       0.969231  0.955376                  0.992337          0.969646      0.041176                 0.169281   312.524887       322.359452            0.168880\n",
      "      4                0.05006143         0.923155  4.190729         4.217042       0.984615  0.935623                  0.990798          0.962862      0.041830                 0.211111   319.072901       321.704158            0.210509\n",
      "      5                0.10012285         0.698411  3.694807         3.955924       0.868098  0.794288                  0.929448          0.878575      0.184967                 0.396078   269.480733       295.592446            0.386845\n",
      "      6                0.15064496         0.564840  2.794350         3.566365       0.656535  0.628747                  0.837920          0.794790      0.141176                 0.537255   179.435008       256.636485            0.505340\n",
      "      7                0.20009214         0.453952  2.273503         3.246870       0.534161  0.507749                  0.762855          0.723856      0.112418                 0.649673   127.350302       224.687022            0.587650\n",
      "      8                0.30006143         0.307654  1.582185         2.692259       0.371736  0.377720                  0.632549          0.608536      0.158170                 0.807843    58.218528       169.225922            0.663724\n",
      "      9                0.40003071         0.207324  0.889162         2.241658       0.208909  0.255520                  0.526679          0.520316      0.088889                 0.896732   -11.083803       124.165795            0.649241\n",
      "     10                0.50000000         0.124809  0.647258         1.922876       0.152074  0.165939                  0.451781          0.449462      0.064706                 0.961438   -35.274239        92.287582            0.603148\n",
      "     11                0.59996929         0.062467  0.235366         1.641696       0.055300  0.089207                  0.385718          0.389435      0.023529                 0.984967   -76.463360        64.169623            0.503233\n",
      "     12                0.70009214         0.040809  0.091391         1.419981       0.021472  0.050579                  0.333626          0.340974      0.009150                 0.994118   -90.860901        41.998116            0.384322\n",
      "     13                0.80006143         0.031976  0.045766         1.248270       0.010753  0.035797                  0.293282          0.302842      0.004575                 0.998693   -95.423431        24.827017            0.259632\n",
      "     14                0.90171990         0.026501  0.012859         1.108992       0.003021  0.028368                  0.260559          0.271898      0.001307                 1.000000   -98.714136        10.899183            0.128462\n",
      "     15                1.00000000         0.024295  0.000000         1.000000       0.000000  0.024700                  0.234951          0.247603      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6052.132324          1.000000   0.377800\n",
      "                      capital_gain         3371.931885          0.557148   0.210490\n",
      "                               age         1303.345215          0.215353   0.081360\n",
      "                      capital_loss         1047.202148          0.173030   0.065371\n",
      "                    hours_per_week          779.533020          0.128803   0.048662\n",
      "        occupation. Prof-specialty          560.924316          0.092682   0.035015\n",
      "       occupation. Exec-managerial          558.327393          0.092253   0.034853\n",
      "              education. Bachelors          409.061676          0.067590   0.025535\n",
      "                            fnlwgt          242.967224          0.040146   0.015167\n",
      "                education. Masters          207.675171          0.034314   0.012964\n",
      "---\n",
      "              workclass. Local-gov            8.423349          0.001392   0.000526\n",
      "             education. Assoc-acdm            7.497360          0.001239   0.000468\n",
      "             relationship. Husband            6.320465          0.001044   0.000395\n",
      "      occupation. Transport-moving            4.152660          0.000686   0.000259\n",
      "                     occupation.NA            4.040448          0.000668   0.000252\n",
      "          race. Asian-Pac-Islander            2.417954          0.000400   0.000151\n",
      "           workclass. Self-emp-inc            1.841930          0.000304   0.000115\n",
      "           relationship. Unmarried            1.606339          0.000265   0.000100\n",
      "              workclass. State-gov            1.552299          0.000256   0.000097\n",
      "              education. Assoc-voc            0.581009          0.000096   0.000036\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        37805.378906          1.000000   0.167983\n",
      "                               age        32811.769531          0.867913   0.145795\n",
      "marital_status. Married-civ-spouse        26969.488281          0.713377   0.119836\n",
      "                    hours_per_week        19545.060547          0.516992   0.086846\n",
      "                      capital_loss        16451.908203          0.435174   0.073102\n",
      "              education. Bachelors        10589.047852          0.280094   0.047051\n",
      "        occupation. Prof-specialty         8646.250977          0.228704   0.038419\n",
      "                education. Masters         7288.037598          0.192778   0.032383\n",
      "       occupation. Exec-managerial         6826.769531          0.180577   0.030334\n",
      "                            fnlwgt         6361.466797          0.168269   0.028266\n",
      "---\n",
      "             education. Assoc-acdm          231.911560          0.006134   0.001030\n",
      "     marital_status. Never-married          219.620300          0.005809   0.000976\n",
      "          occupation. Craft-repair          215.204971          0.005692   0.000956\n",
      "                     occupation.NA          136.200623          0.003603   0.000605\n",
      "             relationship. Husband          118.805954          0.003143   0.000528\n",
      "              workclass. State-gov          106.275932          0.002811   0.000472\n",
      "           relationship. Unmarried          101.375816          0.002682   0.000450\n",
      "              education. Assoc-voc           99.452225          0.002631   0.000442\n",
      "           workclass. Self-emp-inc           90.845917          0.002403   0.000404\n",
      "          race. Asian-Pac-Islander           20.996851          0.000555   0.000093\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          216.000000          1.000000   0.271698\n",
      "                       fnlwgt           83.000000          0.384259   0.104403\n",
      "               hours_per_week           72.000000          0.333333   0.090566\n",
      "                 capital_gain           47.000000          0.217593   0.059119\n",
      "                 capital_loss           27.000000          0.125000   0.033962\n",
      "   occupation. Prof-specialty           27.000000          0.125000   0.033962\n",
      "         education. Bachelors           24.000000          0.111111   0.030189\n",
      "           workclass. Private           24.000000          0.111111   0.030189\n",
      "  occupation. Exec-managerial           23.000000          0.106481   0.028931\n",
      "           education. HS-grad           21.000000          0.097222   0.026415\n",
      "---\n",
      "      relationship. Own-child            2.000000          0.009259   0.002516\n",
      " occupation. Transport-moving            2.000000          0.009259   0.002516\n",
      "               education. 9th            2.000000          0.009259   0.002516\n",
      "occupation. Handlers-cleaners            1.000000          0.004630   0.001258\n",
      "         education. Assoc-voc            1.000000          0.004630   0.001258\n",
      "     race. Asian-Pac-Islander            1.000000          0.004630   0.001258\n",
      "         workclass. State-gov            1.000000          0.004630   0.001258\n",
      "      workclass. Self-emp-inc            1.000000          0.004630   0.001258\n",
      "        relationship. Husband            1.000000          0.004630   0.001258\n",
      "        education. Assoc-acdm            1.000000          0.004630   0.001258\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      "\n",
      "10-20 18:27:42.657 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:42.657) \n",
      "10-20 18:27:42.667 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:42.666) \n",
      "10-20 18:27:42.685 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:42.685) \n",
      "10-20 18:27:42.697 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_324\n",
      "10-20 18:27:42.713 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_324\n",
      "10-20 18:27:42.717 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.08809482\n",
      " RMSE: 0.29680774\n",
      " AUC: 0.9315531\n",
      " pr_auc: 0.83808863\n",
      " logloss: 0.28703502\n",
      " mean_per_class_error: 0.16317518\n",
      " default threshold: 0.352361261844635\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17704  2064  0.1044  2,064 / 19,768\n",
      "     1   1394  4887  0.2219   1,394 / 6,281\n",
      "Totals  19098  6951  0.1327  3,458 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 25.18 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01259165         0.974717  4.147270         4.147270       1.000000  0.974747                  1.000000          0.974747      0.052221                 0.052221   314.726954       314.726954            0.052221\n",
      "      2                0.02280318         0.970654  4.147270         4.147270       1.000000  0.972449                  1.000000          0.973718      0.042350                 0.094571   314.726954       314.726954            0.094571\n",
      "      3                0.03002035         0.963780  4.147270         4.147270       1.000000  0.968462                  1.000000          0.972454      0.029932                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.941441  4.131319         4.143289       0.996154  0.954110                  0.999040          0.967877      0.041235                 0.165738   313.131851       314.328944            0.165687\n",
      "      5                0.05021306         0.918514  4.116087         4.137757       0.992481  0.931512                  0.997706          0.960482      0.042032                 0.207769   311.608707       313.775746            0.207618\n",
      "      6                0.10000384         0.714284  3.706003         3.922792       0.893601  0.799648                  0.945873          0.880405      0.184525                 0.392294   270.600262       292.279161            0.385161\n",
      "      7                0.15002495         0.566502  2.963245         3.602861       0.714505  0.639531                  0.868731          0.800093      0.148225                 0.540519   196.324478       260.286082            0.514568\n",
      "      8                0.20004607         0.458334  2.333038         3.285344       0.562548  0.508935                  0.792170          0.727289      0.116701                 0.657220   133.303805       228.534421            0.602435\n",
      "      9                0.30020346         0.321399  1.632520         2.733910       0.393637  0.382153                  0.659207          0.612141      0.163509                 0.820729    63.252044       173.390978            0.685915\n",
      "     10                0.40185804         0.220050  0.975736         2.289160       0.235272  0.267837                  0.551968          0.525045      0.099188                 0.919917    -2.426400       128.915967            0.682665\n",
      "     11                0.50013436         0.125247  0.479528         1.933567       0.115625  0.170709                  0.466227          0.455418      0.047126                 0.967043   -52.047196        93.356733            0.615263\n",
      "     12                0.59998464         0.069948  0.205689         1.646011       0.049596  0.093481                  0.396890          0.395184      0.020538                 0.987582   -79.431074        64.601145            0.510750\n",
      "     13                0.70014204         0.045316  0.079480         1.421914       0.019164  0.056526                  0.342856          0.346738      0.007961                 0.995542   -92.051994        42.191449            0.389259\n",
      "     14                0.80033782         0.031912  0.027013         1.247284       0.006513  0.038274                  0.300748          0.308121      0.002707                 0.998249   -97.298713        24.728415            0.260794\n",
      "     15                0.98080541         0.024944  0.009704         1.019570       0.002340  0.026439                  0.245841          0.256292      0.001751                 1.000000   -99.029569         1.957024            0.025293\n",
      "     16                1.00000000         0.023583  0.000000         1.000000       0.000000  0.024457                  0.241122          0.251842      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09314057\n",
      " RMSE: 0.3051894\n",
      " AUC: 0.92017233\n",
      " pr_auc: 0.8118145\n",
      " logloss: 0.30024466\n",
      " mean_per_class_error: 0.18017377\n",
      " default threshold: 0.38408878445625305\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4450   502  0.1014  502 / 4,952\n",
      "     1   404  1156  0.2590  404 / 1,560\n",
      "Totals  4854  1658  0.1391  906 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 25.41 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01305283         0.974717  4.174359         4.174359       1.000000  0.974763                  1.000000          0.974763      0.054487                 0.054487  317.435897       317.435897            0.054487\n",
      "      2                0.02272727         0.970654  4.174359         4.174359       1.000000  0.972492                  1.000000          0.973796      0.040385                 0.094872  317.435897       317.435897            0.094872\n",
      "      3                0.03040541         0.966257  4.090872         4.153276       0.980000  0.968925                  0.994949          0.972566      0.031410                 0.126282  309.087179       315.327635            0.126080\n",
      "      4                0.04023342         0.941744  4.174359         4.158426       1.000000  0.955069                  0.996183          0.968292      0.041026                 0.167308  317.435897       315.842631            0.167106\n",
      "      5                0.05098280         0.922799  4.055092         4.136639       0.971429  0.931756                  0.990964          0.960589      0.043590                 0.210897  305.509158       313.663886            0.210292\n",
      "      6                0.10104423         0.724104  3.444486         3.793718       0.825153  0.804720                  0.908815          0.883365      0.172436                 0.383333  244.448639       279.371834            0.371217\n",
      "      7                0.15018428         0.583548  2.895962         3.499974       0.693750  0.648408                  0.838446          0.806488      0.142308                 0.525641  189.596154       249.997378            0.493735\n",
      "      8                0.20009214         0.475550  2.324797         3.206856       0.556923  0.526913                  0.768227          0.736755      0.116026                 0.641667  132.479684       220.685597            0.580681\n",
      "      9                0.30006143         0.324372  1.615881         2.676802       0.387097  0.393796                  0.641249          0.622494      0.161538                 0.803205   61.588089       167.680235            0.661646\n",
      "     10                0.40325553         0.220050  0.981471         2.242963       0.235119  0.269414                  0.537319          0.532140      0.101282                 0.904487   -1.852869       124.296288            0.659132\n",
      "     11                0.50000000         0.122855  0.556581         1.916667       0.133333  0.167474                  0.459152          0.461581      0.053846                 0.958333  -44.341880        91.666667            0.602719\n",
      "     12                0.59996929         0.066452  0.262901         1.641110       0.062980  0.089435                  0.393141          0.399573      0.026282                 0.984615  -73.709874        64.110965            0.505819\n",
      "     13                0.70024570         0.044602  0.063926         1.415254       0.015314  0.054425                  0.339035          0.350147      0.006410                 0.991026  -93.607414        41.525416            0.382383\n",
      "     14                0.79990786         0.031124  0.064320         1.246938       0.015408  0.037311                  0.298714          0.311170      0.006410                 0.997436  -93.568014        24.693848            0.259754\n",
      "     15                0.97804054         0.024944  0.010796         1.021797       0.002586  0.026267                  0.244779          0.259280      0.001923                 0.999359  -98.920424         2.179709            0.028034\n",
      "     16                1.00000000         0.023583  0.029191         1.000000       0.006993  0.024460                  0.239558          0.254123      0.000641                 1.000000  -97.080868         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5920.095215          1.000000   0.373577\n",
      "                      capital_gain         3427.524658          0.578964   0.216288\n",
      "                               age         1259.451294          0.212742   0.079475\n",
      "                      capital_loss         1072.740845          0.181203   0.067693\n",
      "                    hours_per_week          680.279846          0.114910   0.042928\n",
      "        occupation. Prof-specialty          584.593872          0.098747   0.036890\n",
      "       occupation. Exec-managerial          514.037842          0.086829   0.032437\n",
      "              education. Bachelors          402.511963          0.067991   0.025400\n",
      "                education. HS-grad          157.028320          0.026525   0.009909\n",
      "                            fnlwgt          155.868408          0.026329   0.009836\n",
      "---\n",
      "          marital_status. Divorced           13.049744          0.002204   0.000823\n",
      "             relationship. Husband           12.584022          0.002126   0.000794\n",
      "           workclass. Self-emp-inc           12.170273          0.002056   0.000768\n",
      "              education. Assoc-voc           11.123673          0.001879   0.000702\n",
      "              workclass. State-gov            6.915025          0.001168   0.000436\n",
      "                       race. Black            5.921021          0.001000   0.000374\n",
      "           relationship. Unmarried            4.165206          0.000704   0.000263\n",
      "                     occupation.NA            2.456347          0.000415   0.000155\n",
      "     marital_status. Never-married            2.245702          0.000379   0.000142\n",
      "           marital_status. Widowed            0.858694          0.000145   0.000054\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        42562.851563          1.000000   0.190456\n",
      "                               age        31755.992188          0.746096   0.142099\n",
      "marital_status. Married-civ-spouse        25144.419922          0.590760   0.112514\n",
      "                    hours_per_week        18725.128906          0.439941   0.083789\n",
      "                      capital_loss        18423.492188          0.432854   0.082440\n",
      "        occupation. Prof-specialty         9563.749023          0.224697   0.042795\n",
      "              education. Bachelors         8739.028320          0.205321   0.039105\n",
      "       occupation. Exec-managerial         7119.790039          0.167277   0.031859\n",
      "                education. Masters         5253.167480          0.123421   0.023506\n",
      "         occupation. Other-service         4529.018066          0.106408   0.020266\n",
      "---\n",
      "           workclass. Self-emp-inc          274.488922          0.006449   0.001228\n",
      "                       race. White          273.419098          0.006424   0.001223\n",
      "             relationship. Husband          256.441711          0.006025   0.001148\n",
      "              workclass. Local-gov          243.964294          0.005732   0.001092\n",
      "              workclass. State-gov          235.164993          0.005525   0.001052\n",
      "          marital_status. Divorced          228.069443          0.005358   0.001021\n",
      "                       race. Black          140.767120          0.003307   0.000630\n",
      "           relationship. Unmarried          126.292404          0.002967   0.000565\n",
      "                     occupation.NA          111.825424          0.002627   0.000500\n",
      "           marital_status. Widowed           35.119652          0.000825   0.000157\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          200.000000          1.000000   0.272851\n",
      "               hours_per_week           69.000000          0.345000   0.094134\n",
      "                       fnlwgt           66.000000          0.330000   0.090041\n",
      "                 capital_gain           51.000000          0.255000   0.069577\n",
      "                 capital_loss           30.000000          0.150000   0.040928\n",
      "  occupation. Exec-managerial           25.000000          0.125000   0.034106\n",
      "   occupation. Prof-specialty           23.000000          0.115000   0.031378\n",
      "         education. Bachelors           23.000000          0.115000   0.031378\n",
      "                  sex. Female           22.000000          0.110000   0.030014\n",
      "           education. HS-grad           22.000000          0.110000   0.030014\n",
      "---\n",
      "              education. 10th            2.000000          0.010000   0.002729\n",
      "                occupation.NA            2.000000          0.010000   0.002729\n",
      "           education. 7th-8th            2.000000          0.010000   0.002729\n",
      "                  race. Black            2.000000          0.010000   0.002729\n",
      "occupation. Machine-op-inspct            2.000000          0.010000   0.002729\n",
      "      workclass. Self-emp-inc            2.000000          0.010000   0.002729\n",
      "              education. 11th            2.000000          0.010000   0.002729\n",
      "      marital_status. Widowed            1.000000          0.005000   0.001364\n",
      "       native_country. Mexico            1.000000          0.005000   0.001364\n",
      "               education. 9th            1.000000          0.005000   0.001364\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      "\n",
      "10-20 18:27:42.734 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:42.734) \n",
      "10-20 18:27:42.738 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.081 (Wall: 20-Oct 18:27:42.738) \n",
      "10-20 18:27:42.778 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:42.778) \n",
      "10-20 18:27:42.824 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:42.824) \n",
      "10-20 18:27:42.833 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.106 (Wall: 20-Oct 18:27:42.833) \n",
      "10-20 18:27:42.835 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:42.835) \n",
      "10-20 18:27:42.870 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:42.870) \n",
      "10-20 18:27:42.906 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.168 (Wall: 20-Oct 18:27:42.906) \n",
      "10-20 18:27:42.955 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.122 (Wall: 20-Oct 18:27:42.955) \n",
      "10-20 18:27:42.991 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.156 (Wall: 20-Oct 18:27:42.991) \n",
      "10-20 18:27:42.999 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:43.222 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.316 (Wall: 20-Oct 18:27:43.222) \n",
      "10-20 18:27:43.223 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.232 (Wall: 20-Oct 18:27:43.223) \n",
      "█10-20 18:27:43.323 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.368 (Wall: 20-Oct 18:27:43.323) \n",
      "10-20 18:27:43.334 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_325\n",
      "10-20 18:27:43.361 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_325\n",
      "10-20 18:27:43.380 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:43.379) \n",
      "10-20 18:27:43.389 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_326\n",
      "10-20 18:27:43.397 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_327\n",
      "10-20 18:27:43.423 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_326\n",
      "10-20 18:27:43.439 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:43.439) \n",
      "10-20 18:27:43.444 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_327\n",
      "10-20 18:27:43.547 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_328\n",
      "10-20 18:27:43.549 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_329\n",
      "10-20 18:27:43.577 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_328\n",
      "10-20 18:27:43.583 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_329\n",
      "10-20 18:27:43.589 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.083431005\n",
      " RMSE: 0.28884426\n",
      " AUC: 0.93832177\n",
      " pr_auc: 0.8507542\n",
      " logloss: 0.26752272\n",
      " mean_per_class_error: 0.16380802\n",
      " default threshold: 0.40124109387397766\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18225  1520  0.0770  1,520 / 19,745\n",
      "     1   1580  4724  0.2506   1,580 / 6,304\n",
      "Totals  19805  6244  0.1190  3,100 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.48 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.982846  4.132138         4.132138       1.000000  0.985458                  1.000000          0.985458      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.979480  4.132138         4.132138       1.000000  0.981029                  1.000000          0.983248      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.972715  4.132138         4.132138       1.000000  0.976780                  1.000000          0.981089      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04003992         0.959462  4.116306         4.128177       0.996169  0.966660                  0.999041          0.977479      0.041244                 0.165292   311.630638       312.817654            0.165241\n",
      "      5                0.05005950         0.939891  4.100474         4.122632       0.992337  0.950790                  0.997699          0.972137      0.041085                 0.206377   310.047443       312.263187            0.206225\n",
      "      6                0.10000384         0.746093  3.738299         3.930687       0.904689  0.837866                  0.951248          0.905079      0.186707                 0.393084   273.829885       293.068667            0.386652\n",
      "      7                0.15006334         0.608025  3.061078         3.640595       0.740798  0.676882                  0.881044          0.828955      0.153236                 0.546320   206.107793       264.059463            0.522770\n",
      "      8                0.20000768         0.483072  2.426559         3.337435       0.587241  0.546532                  0.807678          0.758430      0.121193                 0.667513   142.655932       233.743533            0.616766\n",
      "      9                0.30004991         0.318797  1.656978         2.777140       0.400998  0.387429                  0.672083          0.634731      0.165768                 0.833280    65.697795       177.713954            0.703475\n",
      "     10                0.40001536         0.193529  0.963214         2.323832       0.233103  0.255213                  0.562380          0.539888      0.096288                 0.929569    -3.678650       132.383211            0.698624\n",
      "     11                0.50001919         0.100821  0.445732         1.948212       0.107869  0.145101                  0.471478          0.460931      0.044575                 0.974143   -55.426838        94.821201            0.625498\n",
      "     12                0.59998464         0.046856  0.165032         1.651110       0.039939  0.069854                  0.399578          0.395772      0.016497                 0.990641   -83.496836        65.111036            0.515381\n",
      "     13                0.69998848         0.024889  0.071381         1.425422       0.017274  0.033850                  0.344960          0.344066      0.007138                 0.997779   -92.861949        42.542229            0.392867\n",
      "     14                0.79999232         0.015762  0.011104         1.248624       0.002687  0.019892                  0.302174          0.303542      0.001110                 0.998890   -98.889637        24.862398            0.262399\n",
      "     15                0.90014972         0.009362  0.011087         1.110926       0.002683  0.012205                  0.268850          0.271126      0.001110                 1.000000   -98.891339        11.092631            0.131730\n",
      "     16                1.00000000         0.005717  0.000000         1.000000       0.000000  0.007070                  0.242005          0.244760      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09423641\n",
      " RMSE: 0.3069795\n",
      " AUC: 0.91443115\n",
      " pr_auc: 0.802669\n",
      " logloss: 0.29866168\n",
      " mean_per_class_error: 0.19656624\n",
      " default threshold: 0.4108709990978241\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4534   441  0.0886  441 / 4,975\n",
      "     1   468  1069  0.3045  468 / 1,537\n",
      "Totals  5002  1510  0.1396  909 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.982661  4.236825         4.236825       1.000000  0.985129                  1.000000          0.985129      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02042383         0.978804  4.236825         4.236825       1.000000  0.980650                  1.000000          0.982872      0.043591                 0.086532  323.682498       323.682498            0.086532\n",
      "      3                0.03009828         0.970164  4.236825         4.236825       1.000000  0.975877                  1.000000          0.980624      0.040989                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.951973  4.236825         4.236825       1.000000  0.962151                  1.000000          0.976023      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.930559  4.236825         4.236825       1.000000  0.942522                  1.000000          0.969344      0.042290                 0.212101  323.682498       323.682498            0.212101\n",
      "      6                0.10012285         0.723163  3.470038         3.853431       0.819018  0.819386                  0.909509          0.894365      0.173715                 0.385817  247.003764       285.343131            0.373957\n",
      "      7                0.15003071         0.597872  2.972296         3.560321       0.701538  0.657432                  0.840328          0.815549      0.148341                 0.534157  197.229568       256.032069            0.502801\n",
      "      8                0.20009214         0.475313  2.144405         3.206070       0.506135  0.535405                  0.756715          0.745459      0.107352                 0.641509  114.440528       220.607017            0.577791\n",
      "      9                0.30175061         0.318912  1.446409         2.613248       0.341390  0.383125                  0.616794          0.623390      0.147040                 0.788549   44.640853       161.324778            0.637192\n",
      "     10                0.40003071         0.197955  1.105547         2.242834       0.260938  0.259904                  0.529367          0.534089      0.108653                 0.897202   10.554652       124.283365            0.650770\n",
      "     11                0.50000000         0.102791  0.566212         1.907612       0.133641  0.148745                  0.450246          0.457043      0.056604                 0.953806  -43.378837        90.761223            0.594007\n",
      "     12                0.59996929         0.045839  0.247311         1.630966       0.058372  0.070135                  0.384950          0.392575      0.024723                 0.978530  -75.268917        63.096616            0.495515\n",
      "     13                0.69993857         0.024166  0.110639         1.413824       0.026114  0.033156                  0.333699          0.341241      0.011061                 0.989590  -88.936095        41.382422            0.379138\n",
      "     14                0.79990786         0.016280  0.078098         1.246891       0.018433  0.019911                  0.294298          0.301082      0.007807                 0.997398  -92.190184        24.689052            0.258503\n",
      "     15                0.89987715         0.009576  0.019525         1.110540       0.004608  0.012594                  0.262116          0.269033      0.001952                 0.999349  -98.047546        11.053979            0.130204\n",
      "     16                1.00000000         0.005719  0.006498         1.000000       0.001534  0.007197                  0.236026          0.242818      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6132.808594          1.000000   0.351275\n",
      "                      capital_gain         3495.041504          0.569892   0.200189\n",
      "                               age         1407.532837          0.229509   0.080621\n",
      "                      capital_loss         1141.807373          0.186180   0.065400\n",
      "                    hours_per_week          814.459839          0.132804   0.046651\n",
      "        occupation. Prof-specialty          642.688477          0.104795   0.036812\n",
      "       occupation. Exec-managerial          579.076843          0.094423   0.033168\n",
      "                            fnlwgt          519.842468          0.084764   0.029776\n",
      "              education. Bachelors          447.546082          0.072976   0.025635\n",
      "                education. Masters          241.199005          0.039329   0.013815\n",
      "---\n",
      "                       race. White           10.712988          0.001747   0.000614\n",
      "                education. 1st-4th            9.308963          0.001518   0.000533\n",
      "                       race. Other            7.845816          0.001279   0.000449\n",
      "           marital_status. Widowed            7.827892          0.001276   0.000448\n",
      "              education. Assoc-voc            6.760022          0.001102   0.000387\n",
      "      occupation. Transport-moving            2.426607          0.000396   0.000139\n",
      "                     occupation.NA            2.357271          0.000384   0.000135\n",
      "                       race. Black            1.005824          0.000164   0.000058\n",
      "           relationship. Unmarried            0.907308          0.000148   0.000052\n",
      "         marital_status. Separated            0.267845          0.000044   0.000015\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        48188.476563          1.000000   0.158073\n",
      "                               age        37907.898438          0.786659   0.124349\n",
      "marital_status. Married-civ-spouse        28526.453125          0.591977   0.093575\n",
      "                    hours_per_week        23728.458984          0.492409   0.077837\n",
      "                      capital_loss        22426.169922          0.465384   0.073565\n",
      "                            fnlwgt        13891.994141          0.288285   0.045570\n",
      "              education. Bachelors        11120.411133          0.230769   0.036478\n",
      "       occupation. Exec-managerial        10260.744141          0.212929   0.033658\n",
      "        occupation. Prof-specialty         9413.522461          0.195348   0.030879\n",
      "                education. Masters         9208.414063          0.191092   0.030206\n",
      "---\n",
      "              workclass. Local-gov          350.692413          0.007278   0.001150\n",
      "     marital_status. Never-married          340.729553          0.007071   0.001118\n",
      "                       race. White          335.235657          0.006957   0.001100\n",
      "              education. Assoc-voc          279.530792          0.005801   0.000917\n",
      "           marital_status. Widowed          210.179031          0.004362   0.000689\n",
      "         marital_status. Separated           97.625999          0.002026   0.000320\n",
      "      occupation. Transport-moving           83.694038          0.001737   0.000275\n",
      "                       race. Black           66.348007          0.001377   0.000218\n",
      "                     occupation.NA           63.607670          0.001320   0.000209\n",
      "           relationship. Unmarried           14.000000          0.000291   0.000046\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          236.000000          1.000000   0.231146\n",
      "                       fnlwgt          195.000000          0.826271   0.190989\n",
      "               hours_per_week          102.000000          0.432203   0.099902\n",
      "                 capital_gain           57.000000          0.241525   0.055828\n",
      "                 capital_loss           32.000000          0.135593   0.031342\n",
      "                  sex. Female           31.000000          0.131356   0.030362\n",
      "  occupation. Exec-managerial           30.000000          0.127119   0.029383\n",
      "         education. Bachelors           27.000000          0.114407   0.026445\n",
      "           education. HS-grad           26.000000          0.110169   0.025465\n",
      "   occupation. Prof-specialty           22.000000          0.093220   0.021548\n",
      "---\n",
      "occupation. Machine-op-inspct            2.000000          0.008475   0.001959\n",
      "               education. 9th            2.000000          0.008475   0.001959\n",
      "      relationship. Unmarried            1.000000          0.004237   0.000979\n",
      "                  race. Other            1.000000          0.004237   0.000979\n",
      "                occupation.NA            1.000000          0.004237   0.000979\n",
      "    marital_status. Separated            1.000000          0.004237   0.000979\n",
      "           education. 1st-4th            1.000000          0.004237   0.000979\n",
      "                  race. Black            1.000000          0.004237   0.000979\n",
      " occupation. Transport-moving            1.000000          0.004237   0.000979\n",
      "           education. 5th-6th            1.000000          0.004237   0.000979\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      "\n",
      "10-20 18:27:43.671 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_330\n",
      "10-20 18:27:43.689 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_330\n",
      "10-20 18:27:43.697 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.083947115\n",
      " RMSE: 0.28973627\n",
      " AUC: 0.9366474\n",
      " pr_auc: 0.8446663\n",
      " logloss: 0.26868415\n",
      " mean_per_class_error: 0.16885449\n",
      " default threshold: 0.39223894476890564\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18190  1643  0.0828  1,643 / 19,833\n",
      "     1   1584  4631  0.2549   1,584 / 6,215\n",
      "Totals  19774  6274  0.1239  3,227 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 24.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005835         0.985500  4.191150         4.191150       1.000000  0.987702                  1.000000          0.987702      0.042156                 0.042156   319.115044       319.115044            0.042156\n",
      "      2                0.02000154         0.981605  4.191150         4.191150       1.000000  0.983612                  1.000000          0.985669      0.041673                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.976489  4.191150         4.191150       1.000000  0.979381                  1.000000          0.983570      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.965283  4.158911         4.183106       0.992308  0.971343                  0.998081          0.980519      0.041512                 0.167337   315.891082       318.310601            0.167236\n",
      "      5                0.05002303         0.944224  4.175092         4.181501       0.996169  0.955661                  0.997698          0.975540      0.041834                 0.209171   317.509239       318.150083            0.209020\n",
      "      6                0.10008446         0.730439  3.763679         3.972510       0.898006  0.827284                  0.947833          0.901384      0.188415                 0.397586   276.367881       297.250968            0.390729\n",
      "      7                0.15003071         0.598408  2.999201         3.648489       0.715603  0.662038                  0.870522          0.821704      0.149799                 0.547385   199.920143       264.848869            0.521872\n",
      "      8                0.20001536         0.471445  2.449666         3.348898       0.584485  0.534341                  0.799040          0.749891      0.122446                 0.669831   144.966627       234.889814            0.617040\n",
      "      9                0.30013821         0.319643  1.637570         2.778018       0.390721  0.384784                  0.662829          0.628095      0.163958                 0.833789    63.756990       177.801760            0.700879\n",
      "     10                0.39999232         0.190185  0.974874         2.327881       0.232603  0.252836                  0.555428          0.534415      0.097345                 0.931134    -2.512648       132.788057            0.697584\n",
      "     11                0.50000000         0.098743  0.427964         1.947868       0.102111  0.141308                  0.464757          0.455788      0.042800                 0.973934   -57.203608        94.786806            0.622449\n",
      "     12                0.60000768         0.045436  0.162498         1.650287       0.038772  0.069113                  0.393755          0.391338      0.016251                 0.990185   -83.750242        65.028728            0.512446\n",
      "     13                0.69997697         0.025362  0.067599         1.424251       0.016129  0.033961                  0.339823          0.340298      0.006758                 0.996943   -93.240080        42.425098            0.390025\n",
      "     14                0.79998464         0.016150  0.020916         1.248817       0.004990  0.020398                  0.297965          0.300307      0.002092                 0.999035   -97.908447        24.881721            0.261426\n",
      "     15                0.89999232         0.009204  0.009653         1.111121       0.002303  0.012647                  0.265111          0.268342      0.000965                 1.000000   -99.034668        11.112059            0.131347\n",
      "     16                1.00000000         0.005610  0.000000         1.000000       0.000000  0.007124                  0.238598          0.242218      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.0915603\n",
      " RMSE: 0.30258933\n",
      " AUC: 0.92509955\n",
      " pr_auc: 0.83170164\n",
      " logloss: 0.2902648\n",
      " mean_per_class_error: 0.17529581\n",
      " default threshold: 0.3851375877857208\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4445   442  0.0904  442 / 4,887\n",
      "     1   423  1203  0.2601  423 / 1,626\n",
      "Totals  4868  1645  0.1328  865 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.43 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01105481         0.984852  4.005535         4.005535       1.000000  0.987135                  1.000000          0.987135      0.044280                 0.044280   300.553506       300.553506            0.044280\n",
      "      2                0.02011362         0.981614  4.005535         4.005535       1.000000  0.983087                  1.000000          0.985312      0.036285                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.976174  4.005535         4.005535       1.000000  0.979313                  1.000000          0.983323      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.965895  4.005535         4.005535       1.000000  0.971668                  1.000000          0.980420      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.948413  4.005535         4.005535       1.000000  0.958364                  1.000000          0.976023      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10026102         0.750515  3.564559         3.784709       0.889908  0.841995                  0.944870          0.908906      0.178967                 0.379459   256.455872       278.470923            0.372092\n",
      "      7                0.15000768         0.604195  2.868161         3.480757       0.716049  0.673232                  0.868987          0.830750      0.142681                 0.522140   186.816090       248.075667            0.495948\n",
      "      8                0.20006142         0.471596  2.309940         3.187828       0.576687  0.537305                  0.795856          0.757333      0.115621                 0.637761   130.994046       218.782798            0.583331\n",
      "      9                0.30078305         0.311427  1.599772         2.656044       0.399390  0.386644                  0.663093          0.633202      0.161132                 0.798893    59.977162       165.604392            0.663841\n",
      "     10                0.40012283         0.191809  1.021504         2.250232       0.255023  0.250079                  0.561781          0.538083      0.101476                 0.900369     2.150430       125.023151            0.666688\n",
      "     11                0.50007677         0.103247  0.590678         1.918525       0.147465  0.143393                  0.478968          0.459193      0.059041                 0.959410   -40.932202        91.852462            0.612162\n",
      "     12                0.60003071         0.046372  0.227657         1.636858       0.056836  0.071213                  0.408649          0.394563      0.022755                 0.982165   -77.234286        63.685760            0.509278\n",
      "     13                0.69998465         0.025614  0.104599         1.418060       0.026114  0.034018                  0.354025          0.343079      0.010455                 0.992620   -89.540077        41.805957            0.390001\n",
      "     14                0.79993858         0.016602  0.073835         1.250096       0.018433  0.020931                  0.312092          0.302826      0.007380                 1.000000   -92.616525        25.009597            0.266626\n",
      "     15                0.89989252         0.009605  0.000000         1.111244       0.000000  0.013096                  0.277427          0.270645      0.000000                 1.000000  -100.000000        11.124382            0.133415\n",
      "     16                1.00000000         0.005890  0.000000         1.000000       0.000000  0.007258                  0.249655          0.244278      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5126.254883          1.000000   0.296627\n",
      "                      capital_gain         3547.370117          0.692000   0.205266\n",
      "                               age         1424.374878          0.277859   0.082420\n",
      "                      capital_loss         1172.253174          0.228676   0.067831\n",
      "                    hours_per_week          960.735291          0.187415   0.055592\n",
      "     marital_status. Never-married          676.767639          0.132020   0.039161\n",
      "                            fnlwgt          568.106140          0.110823   0.032873\n",
      "        occupation. Prof-specialty          513.690918          0.100208   0.029724\n",
      "       occupation. Exec-managerial          502.140747          0.097955   0.029056\n",
      "              education. Bachelors          341.392273          0.066597   0.019754\n",
      "---\n",
      "          race. Asian-Pac-Islander           12.028238          0.002346   0.000696\n",
      "          marital_status. Divorced           11.231176          0.002191   0.000650\n",
      "                education. 5th-6th           10.893879          0.002125   0.000630\n",
      "      relationship. Other-relative            9.597805          0.001872   0.000555\n",
      "              workclass. State-gov            7.275020          0.001419   0.000421\n",
      "              education. Assoc-voc            7.106818          0.001386   0.000411\n",
      "                     occupation.NA            5.329042          0.001040   0.000308\n",
      "                       race. Black            4.205559          0.000820   0.000243\n",
      "           marital_status. Widowed            2.031811          0.000396   0.000118\n",
      "      occupation. Transport-moving            1.547573          0.000302   0.000090\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        48349.992188          1.000000   0.160098\n",
      "                               age        37518.500000          0.775977   0.124232\n",
      "                    hours_per_week        27423.064453          0.567178   0.090804\n",
      "marital_status. Married-civ-spouse        26228.625000          0.542474   0.086849\n",
      "                      capital_loss        25284.496094          0.522947   0.083723\n",
      "                            fnlwgt        12385.671875          0.256167   0.041012\n",
      "        occupation. Prof-specialty        10306.340820          0.213161   0.034127\n",
      "       occupation. Exec-managerial         9502.474609          0.196535   0.031465\n",
      "              education. Bachelors         8443.478516          0.174632   0.027958\n",
      "              education. Doctorate         6739.985840          0.139400   0.022318\n",
      "---\n",
      "          occupation. Craft-repair          326.437469          0.006752   0.001081\n",
      "             relationship. Husband          276.013367          0.005709   0.000914\n",
      "     native_country. United-States          266.665680          0.005515   0.000883\n",
      "          marital_status. Divorced          260.700165          0.005392   0.000863\n",
      "          race. Asian-Pac-Islander          220.023010          0.004551   0.000729\n",
      "                     occupation.NA          175.825058          0.003637   0.000582\n",
      "              workclass. State-gov          150.087875          0.003104   0.000497\n",
      "           marital_status. Widowed          110.467537          0.002285   0.000366\n",
      "                       race. Black          110.095306          0.002277   0.000365\n",
      "      occupation. Transport-moving          105.390991          0.002180   0.000349\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          227.000000          1.000000   0.206364\n",
      "                         age          216.000000          0.951542   0.196364\n",
      "              hours_per_week          120.000000          0.528634   0.109091\n",
      "                capital_loss           51.000000          0.224670   0.046364\n",
      "                capital_gain           51.000000          0.224670   0.046364\n",
      "  occupation. Prof-specialty           35.000000          0.154185   0.031818\n",
      "          education. HS-grad           32.000000          0.140969   0.029091\n",
      " occupation. Exec-managerial           29.000000          0.127753   0.026364\n",
      "        education. Bachelors           28.000000          0.123348   0.025455\n",
      "          workclass. Private           23.000000          0.101322   0.020909\n",
      "---\n",
      "        education. Assoc-voc            2.000000          0.008811   0.001818\n",
      "               occupation.NA            2.000000          0.008811   0.001818\n",
      "                 race. Black            2.000000          0.008811   0.001818\n",
      "        workclass. State-gov            2.000000          0.008811   0.001818\n",
      "     workclass. Self-emp-inc            2.000000          0.008811   0.001818\n",
      "              education. 9th            2.000000          0.008811   0.001818\n",
      "     marital_status. Widowed            1.000000          0.004405   0.000909\n",
      "relationship. Other-relative            1.000000          0.004405   0.000909\n",
      "occupation. Transport-moving            1.000000          0.004405   0.000909\n",
      "          education. 5th-6th            1.000000          0.004405   0.000909\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      "\n",
      "10-20 18:27:43.701 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:43.701) \n",
      "10-20 18:27:43.722 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_331\n",
      "10-20 18:27:43.737 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_331\n",
      "10-20 18:27:43.742 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.084074505\n",
      " RMSE: 0.28995603\n",
      " AUC: 0.9367749\n",
      " pr_auc: 0.8489144\n",
      " logloss: 0.27022976\n",
      " mean_per_class_error: 0.1614117\n",
      " default threshold: 0.38865840435028076\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17973  1765  0.0894  1,765 / 19,738\n",
      "     1   1473  4838  0.2334   1,473 / 6,311\n",
      "Totals  19446  6603  0.1243  3,238 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.50 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01193904         0.985599  4.127555         4.127555       1.000000  0.987174                  1.000000          0.987174      0.049279                 0.049279  312.755506       312.755506            0.049279\n",
      "      2                0.02015432         0.982413  4.127555         4.127555       1.000000  0.983911                  1.000000          0.985844      0.033909                 0.083188  312.755506       312.755506            0.083188\n",
      "      3                0.03002035         0.976243  4.127555         4.127555       1.000000  0.979692                  1.000000          0.983822      0.040723                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.961988  4.127555         4.127555       1.000000  0.969492                  1.000000          0.980247      0.041198                 0.165109  312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.941159  4.111741         4.124387       0.996169  0.953405                  0.999233          0.974870      0.041198                 0.206306  311.174068       312.438733            0.206256\n",
      "      6                0.10000384         0.742212  3.747135         3.935834       0.907834  0.834018                  0.953551          0.904471      0.187292                 0.393598  274.713524       293.583369            0.387468\n",
      "      7                0.15002495         0.604501  3.031520         3.634319       0.734459  0.673097                  0.880502          0.827327      0.151640                 0.545238  203.151972       263.431857            0.521579\n",
      "      8                0.20000768         0.483911  2.396645         3.325019       0.580645  0.544198                  0.805566          0.756572      0.119791                 0.665029  139.664488       232.501892            0.613707\n",
      "      9                0.30001152         0.311380  1.671620         2.773886       0.404990  0.393174                  0.672041          0.635439      0.167168                 0.832198   67.162019       177.388601            0.702347\n",
      "     10                0.40001536         0.189599  0.972867         2.323631       0.235701  0.248076                  0.562956          0.538598      0.097290                 0.929488   -2.713290       132.363129            0.698766\n",
      "     11                0.50001919         0.103025  0.407210         1.940347       0.098656  0.144066                  0.470096          0.459692      0.040723                 0.970211  -59.279015        94.034700            0.620530\n",
      "     12                0.59998464         0.049187  0.183870         1.647694       0.044547  0.073013                  0.399194          0.395266      0.018381                 0.988591  -81.613042        64.769442            0.512859\n",
      "     13                0.69998848         0.027449  0.080808         1.423841       0.019578  0.036527                  0.344960          0.344015      0.008081                 0.996672  -91.919182        42.384125            0.391545\n",
      "     14                0.79999232         0.017199  0.025352         1.249022       0.006142  0.021902                  0.302606          0.303749      0.002535                 0.999208  -97.464841        24.902165            0.262912\n",
      "     15                0.90003455         0.009399  0.006335         1.110892       0.001535  0.013008                  0.269141          0.271432      0.000634                 0.999842  -99.366454        11.089241            0.131719\n",
      "     16                1.00000000         0.005756  0.001585         1.000000       0.000384  0.007148                  0.242274          0.245013      0.000158                 1.000000  -99.841492         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.08897787\n",
      " RMSE: 0.2982916\n",
      " AUC: 0.9250058\n",
      " pr_auc: 0.8210969\n",
      " logloss: 0.28305578\n",
      " mean_per_class_error: 0.18072958\n",
      " default threshold: 0.3803216218948364\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4513   469  0.0941  469 / 4,982\n",
      "     1   409  1121  0.2673  409 / 1,530\n",
      "Totals  4922  1590  0.1348  878 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.90 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01044226         0.985599  4.256209         4.256209       1.000000  0.987296                  1.000000          0.987296      0.044444                 0.044444   325.620915       325.620915            0.044444\n",
      "      2                0.02011671         0.982126  4.256209         4.256209       1.000000  0.983799                  1.000000          0.985614      0.041176                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.975649  4.190729         4.234494       0.984615  0.979308                  0.994898          0.983523      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.961821  4.256209         4.239902       1.000000  0.968502                  0.996169          0.979782      0.042484                 0.169935   325.620915       323.990184            0.169734\n",
      "      5                0.05006143         0.943186  4.190729         4.230097       0.984615  0.953148                  0.993865          0.974471      0.041830                 0.211765   319.072901       323.009744            0.211363\n",
      "      6                0.10012285         0.731984  3.760087         3.995092       0.883436  0.827430                  0.938650          0.900951      0.188235                 0.400000   276.008661       299.509202            0.391971\n",
      "      7                0.15003071         0.589196  2.854934         3.615817       0.670769  0.657166                  0.849539          0.819856      0.142484                 0.542484   185.493414       261.581739            0.512977\n",
      "      8                0.20009214         0.464450  2.284775         3.282801       0.536810  0.522686                  0.771297          0.745506      0.114379                 0.656863   128.477485       228.280138            0.597047\n",
      "      9                0.30006143         0.289437  1.516806         2.694437       0.356375  0.371647                  0.633060          0.620950      0.151634                 0.808497    51.680572       169.443742            0.664579\n",
      "     10                0.40003071         0.185008  0.980693         2.266166       0.230415  0.237997                  0.532438          0.525249      0.098039                 0.906536    -1.930665       126.616587            0.662056\n",
      "     11                0.50000000         0.102624  0.581878         1.929412       0.136713  0.141891                  0.453317          0.448601      0.058170                 0.964706   -41.812194        92.941176            0.607420\n",
      "     12                0.59996929         0.046474  0.241904         1.648233       0.056836  0.071005                  0.387254          0.385684      0.024183                 0.988889   -75.809564        64.823252            0.508359\n",
      "     13                0.69993857         0.026561  0.071918         1.423094       0.016897  0.034997                  0.334357          0.335597      0.007190                 0.996078   -92.808249        42.309406            0.387086\n",
      "     14                0.79990786         0.016731  0.026152         1.248510       0.006144  0.021316                  0.293338          0.296319      0.002614                 0.998693   -97.384818        24.850981            0.259833\n",
      "     15                0.90033784         0.009131  0.013016         1.110694       0.003058  0.012737                  0.260959          0.264687      0.001307                 1.000000   -98.698407        11.069418            0.130269\n",
      "     16                1.00000000         0.005795  0.000000         1.000000       0.000000  0.006941                  0.234951          0.238999      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6087.082031          1.000000   0.349055\n",
      "                      capital_gain         3497.628662          0.574599   0.200566\n",
      "                               age         1495.323730          0.245655   0.085747\n",
      "                      capital_loss         1118.391113          0.183732   0.064133\n",
      "                    hours_per_week          895.128418          0.147054   0.051330\n",
      "       occupation. Exec-managerial          598.674561          0.098352   0.034330\n",
      "        occupation. Prof-specialty          587.652832          0.096541   0.033698\n",
      "                            fnlwgt          563.110413          0.092509   0.032291\n",
      "              education. Bachelors          437.529938          0.071878   0.025090\n",
      "                education. Masters          226.190582          0.037159   0.012971\n",
      "---\n",
      "                education. 5th-6th           11.257149          0.001849   0.000646\n",
      "     occupation. Handlers-cleaners            9.845740          0.001617   0.000565\n",
      "      relationship. Other-relative            8.906333          0.001463   0.000511\n",
      "     occupation. Machine-op-inspct            8.526011          0.001401   0.000489\n",
      "          race. Asian-Pac-Islander            8.412947          0.001382   0.000482\n",
      "             education. Assoc-acdm            7.497360          0.001232   0.000430\n",
      "              workclass. State-gov            7.316751          0.001202   0.000420\n",
      "                     occupation.NA            4.040448          0.000664   0.000232\n",
      "           relationship. Unmarried            1.606339          0.000264   0.000092\n",
      "              education. Assoc-voc            0.581009          0.000095   0.000033\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        49868.937500          1.000000   0.165333\n",
      "                               age        38992.226563          0.781894   0.129273\n",
      "marital_status. Married-civ-spouse        28830.548828          0.578126   0.095584\n",
      "                      capital_loss        23247.921875          0.466180   0.077075\n",
      "                    hours_per_week        22721.759766          0.455630   0.075331\n",
      "                            fnlwgt        15381.978516          0.308448   0.050997\n",
      "              education. Bachelors        11551.931641          0.231646   0.038299\n",
      "       occupation. Exec-managerial        10135.436523          0.203241   0.033603\n",
      "        occupation. Prof-specialty         9090.220703          0.182282   0.030137\n",
      "                education. Masters         8692.873047          0.174314   0.028820\n",
      "---\n",
      "          occupation. Craft-repair          383.429443          0.007689   0.001271\n",
      "                       race. Black          335.344849          0.006725   0.001112\n",
      "             relationship. Husband          278.478851          0.005584   0.000923\n",
      "     occupation. Machine-op-inspct          266.184631          0.005338   0.000882\n",
      "             education. Assoc-acdm          231.911560          0.004650   0.000769\n",
      "              workclass. State-gov          146.040192          0.002928   0.000484\n",
      "                     occupation.NA          136.200623          0.002731   0.000452\n",
      "          race. Asian-Pac-Islander          111.889297          0.002244   0.000371\n",
      "           relationship. Unmarried          101.375816          0.002033   0.000336\n",
      "              education. Assoc-voc           99.452225          0.001994   0.000330\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          270.000000          1.000000   0.239787\n",
      "                       fnlwgt          208.000000          0.770370   0.184725\n",
      "               hours_per_week           99.000000          0.366667   0.087922\n",
      "                 capital_gain           62.000000          0.229630   0.055062\n",
      "                 capital_loss           36.000000          0.133333   0.031972\n",
      "         education. Bachelors           36.000000          0.133333   0.031972\n",
      "   occupation. Prof-specialty           32.000000          0.118519   0.028419\n",
      "           workclass. Private           31.000000          0.114815   0.027531\n",
      "  occupation. Exec-managerial           28.000000          0.103704   0.024867\n",
      "           education. HS-grad           28.000000          0.103704   0.024867\n",
      "---\n",
      "                occupation.NA            2.000000          0.007407   0.001776\n",
      "     race. Asian-Pac-Islander            2.000000          0.007407   0.001776\n",
      "         workclass. State-gov            2.000000          0.007407   0.001776\n",
      "occupation. Machine-op-inspct            2.000000          0.007407   0.001776\n",
      "               education. 9th            2.000000          0.007407   0.001776\n",
      "occupation. Handlers-cleaners            1.000000          0.003704   0.000888\n",
      "         education. Assoc-voc            1.000000          0.003704   0.000888\n",
      " relationship. Other-relative            1.000000          0.003704   0.000888\n",
      "        education. Assoc-acdm            1.000000          0.003704   0.000888\n",
      "           education. 5th-6th            1.000000          0.003704   0.000888\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      "\n",
      "10-20 18:27:43.763 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:43.763) \n",
      "10-20 18:27:43.805 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.090 (Wall: 20-Oct 18:27:43.804) \n",
      "10-20 18:27:43.832 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:43.832) \n",
      "10-20 18:27:43.860 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:43.860) \n",
      "10-20 18:27:43.864 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:43.864) \n",
      "10-20 18:27:43.884 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_332\n",
      "10-20 18:27:43.896 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_332\n",
      "10-20 18:27:43.899 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.083687\n",
      " RMSE: 0.28928706\n",
      " AUC: 0.9374366\n",
      " pr_auc: 0.8494723\n",
      " logloss: 0.2685127\n",
      " mean_per_class_error: 0.1575687\n",
      " default threshold: 0.3536195158958435\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17762  2006  0.1015  2,006 / 19,768\n",
      "     1   1342  4939  0.2137   1,342 / 6,281\n",
      "Totals  19104  6945  0.1285  3,348 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.36 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.986162  4.147270         4.147270       1.000000  0.987828                  1.000000          0.987828      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.984088  4.147270         4.147270       1.000000  0.985179                  1.000000          0.986506      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.977440  4.147270         4.147270       1.000000  0.981490                  1.000000          0.984832      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.961817  4.147270         4.147270       1.000000  0.969502                  1.000000          0.981007      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.939812  4.131380         4.144087       0.996169  0.950713                  0.999233          0.974939      0.041395                 0.207292   313.137962       314.408668            0.207241\n",
      "      6                0.10000384         0.747481  3.768218         3.956224       0.908602  0.833161                  0.953935          0.904077      0.188346                 0.395638   276.821803       295.622450            0.389567\n",
      "      7                0.15002495         0.597413  3.052365         3.654861       0.735994  0.671262                  0.881269          0.826452      0.152683                 0.548320   205.236492       265.486088            0.524848\n",
      "      8                0.20000768         0.474423  2.417648         3.345676       0.582949  0.534662                  0.806718          0.753533      0.120841                 0.669161   141.764791       234.567637            0.618220\n",
      "      9                0.30001152         0.307985  1.615923         2.769092       0.389635  0.384707                  0.667690          0.630591      0.161598                 0.830759    61.592268       176.909181            0.699385\n",
      "     10                0.40001536         0.194858  0.975922         2.320799       0.235317  0.250019                  0.559597          0.535448      0.097596                 0.928355    -2.407822       132.079930            0.696213\n",
      "     11                0.50005758         0.102434  0.448784         1.946281       0.108212  0.145165                  0.469292          0.457367      0.044897                 0.973253   -55.121642        94.628119            0.623546\n",
      "     12                0.59998464         0.049682  0.165700         1.649726       0.039954  0.072644                  0.397786          0.393292      0.016558                 0.989811   -83.430041        64.972645            0.513688\n",
      "     13                0.70006526         0.027103  0.068405         1.423662       0.016494  0.036682                  0.343277          0.342311      0.006846                 0.996657   -93.159471        42.366239            0.390829\n",
      "     14                0.79999232         0.015647  0.025492         1.249017       0.006147  0.020744                  0.301166          0.302144      0.002547                 0.999204   -97.450776        24.901692            0.262508\n",
      "     15                0.90003455         0.008907  0.007957         1.111068       0.001919  0.011872                  0.267904          0.269879      0.000796                 1.000000   -99.204284        11.106846            0.131728\n",
      "     16                1.00000000         0.005699  0.000000         1.000000       0.000000  0.007114                  0.241122          0.243612      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09181099\n",
      " RMSE: 0.30300328\n",
      " AUC: 0.92275476\n",
      " pr_auc: 0.8138438\n",
      " logloss: 0.29009268\n",
      " mean_per_class_error: 0.16580972\n",
      " default threshold: 0.3267972469329834\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4278   674  0.1361  674 / 4,952\n",
      "     1   305  1255  0.1955  305 / 1,560\n",
      "Totals  4583  1929  0.1503  979 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.65 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.986422  4.174359         4.174359       1.000000  0.987748                  1.000000          0.987748      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.984385  4.110138         4.142494       0.984615  0.985349                  0.992366          0.986558      0.041026                 0.083333  311.013807       314.249364            0.083131\n",
      "      3                0.03009828         0.977685  4.174359         4.153061       1.000000  0.981763                  0.994898          0.984968      0.041667                 0.125000  317.435897       315.306122            0.124798\n",
      "      4                0.04007985         0.961393  4.174359         4.158365       1.000000  0.969911                  0.996169          0.981218      0.041667                 0.166667  317.435897       315.836526            0.166465\n",
      "      5                0.05006143         0.939815  4.110138         4.148749       0.984615  0.950415                  0.993865          0.975076      0.041026                 0.207692  311.013807       314.874941            0.207288\n",
      "      6                0.10012285         0.756619  3.457291         3.803020       0.828221  0.839182                  0.911043          0.907129      0.173077                 0.380769  245.729118       280.302029            0.369057\n",
      "      7                0.15018428         0.611537  2.842662         3.482901       0.680982  0.681023                  0.834356          0.831760      0.142308                 0.523077  184.266163       248.290074            0.490363\n",
      "      8                0.20024570         0.498192  2.317666         3.191592       0.555215  0.552706                  0.764571          0.761997      0.116026                 0.639103  131.766557       219.159195            0.577107\n",
      "      9                0.30006143         0.317816  1.708276         2.698165       0.409231  0.400087                  0.646366          0.641607      0.170513                 0.809615   70.827613       169.816550            0.670076\n",
      "     10                0.40003071         0.195139  1.006719         2.275466       0.241167  0.252361                  0.545106          0.544333      0.100641                 0.910256    0.671945       127.546631            0.670959\n",
      "     11                0.50000000         0.099821  0.500154         1.920513       0.119816  0.143817                  0.460074          0.464254      0.050000                 0.960256  -49.984639        92.051282            0.605248\n",
      "     12                0.59996929         0.046718  0.256489         1.643247       0.061444  0.070246                  0.393652          0.398603      0.025641                 0.985897  -74.351097        64.324651            0.507505\n",
      "     13                0.69993857         0.025896  0.096183         1.422286       0.023041  0.034898                  0.340720          0.346657      0.009615                 0.995513  -90.381661        42.228598            0.388687\n",
      "     14                0.79990786         0.015362  0.025649         1.247740       0.006144  0.020282                  0.298906          0.305868      0.002564                 0.998077  -97.435110        24.773986            0.260597\n",
      "     15                0.90018428         0.008854  0.012785         1.110172       0.003063  0.011665                  0.265950          0.273095      0.001282                 0.999359  -98.721483        11.017155            0.130417\n",
      "     16                1.00000000         0.005700  0.006422         1.000000       0.001538  0.007139                  0.239558          0.246548      0.000641                 1.000000  -99.357791         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5961.825195          1.000000   0.344709\n",
      "                      capital_gain         3552.177002          0.595820   0.205385\n",
      "                               age         1444.629028          0.242313   0.083528\n",
      "                      capital_loss         1112.235352          0.186560   0.064309\n",
      "                    hours_per_week          774.623535          0.129931   0.044788\n",
      "        occupation. Prof-specialty          609.850342          0.102293   0.035261\n",
      "       occupation. Exec-managerial          564.830261          0.094741   0.032658\n",
      "                            fnlwgt          475.371552          0.079736   0.027486\n",
      "              education. Bachelors          423.715820          0.071071   0.024499\n",
      "                education. HS-grad          187.943024          0.031524   0.010867\n",
      "---\n",
      "     occupation. Machine-op-inspct           14.490511          0.002431   0.000838\n",
      "              workclass. State-gov           13.784726          0.002312   0.000797\n",
      "              education. Assoc-voc           12.498524          0.002096   0.000723\n",
      "      relationship. Other-relative            9.440792          0.001584   0.000546\n",
      "           marital_status. Widowed            8.604737          0.001443   0.000498\n",
      "      occupation. Transport-moving            6.968823          0.001169   0.000403\n",
      "                       race. Black            5.921021          0.000993   0.000342\n",
      "          race. Asian-Pac-Islander            3.005394          0.000504   0.000174\n",
      "             education. Assoc-acdm            2.577040          0.000432   0.000149\n",
      "                     occupation.NA            2.456347          0.000412   0.000142\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        52304.902344          1.000000   0.173915\n",
      "                               age        39652.972656          0.758112   0.131847\n",
      "marital_status. Married-civ-spouse        28446.201172          0.543853   0.094584\n",
      "                    hours_per_week        21305.656250          0.407336   0.070842\n",
      "                      capital_loss        21086.091797          0.403138   0.070112\n",
      "                            fnlwgt        13562.227539          0.259292   0.045095\n",
      "        occupation. Prof-specialty        10093.244141          0.192969   0.033560\n",
      "       occupation. Exec-managerial         9893.143555          0.189144   0.032895\n",
      "              education. Bachelors         9497.343750          0.181577   0.031579\n",
      "                education. Masters         6683.548340          0.127781   0.022223\n",
      "---\n",
      "              education. Assoc-voc          433.497559          0.008288   0.001441\n",
      "             relationship. Husband          401.998932          0.007686   0.001337\n",
      "           marital_status. Widowed          341.939362          0.006537   0.001137\n",
      "              workclass. Local-gov          317.564728          0.006071   0.001056\n",
      "          marital_status. Divorced          294.003357          0.005621   0.000978\n",
      "      occupation. Transport-moving          264.611694          0.005059   0.000880\n",
      "          race. Asian-Pac-Islander          169.283142          0.003236   0.000563\n",
      "                       race. Black          140.767120          0.002691   0.000468\n",
      "             education. Assoc-acdm          139.246597          0.002662   0.000463\n",
      "                     occupation.NA          111.825424          0.002138   0.000372\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          242.000000          1.000000   0.230476\n",
      "                       fnlwgt          178.000000          0.735537   0.169524\n",
      "               hours_per_week           97.000000          0.400826   0.092381\n",
      "                 capital_gain           66.000000          0.272727   0.062857\n",
      "                 capital_loss           35.000000          0.144628   0.033333\n",
      "  occupation. Exec-managerial           31.000000          0.128099   0.029524\n",
      "         education. Bachelors           31.000000          0.128099   0.029524\n",
      "                  sex. Female           30.000000          0.123967   0.028571\n",
      "   occupation. Prof-specialty           27.000000          0.111570   0.025714\n",
      "           education. HS-grad           27.000000          0.111570   0.025714\n",
      "---\n",
      " occupation. Transport-moving            3.000000          0.012397   0.002857\n",
      "occupation. Handlers-cleaners            2.000000          0.008264   0.001905\n",
      " relationship. Other-relative            2.000000          0.008264   0.001905\n",
      "                occupation.NA            2.000000          0.008264   0.001905\n",
      "                  race. Black            2.000000          0.008264   0.001905\n",
      "occupation. Machine-op-inspct            2.000000          0.008264   0.001905\n",
      "           education. 5th-6th            2.000000          0.008264   0.001905\n",
      "               education. 9th            2.000000          0.008264   0.001905\n",
      "     race. Asian-Pac-Islander            1.000000          0.004132   0.000952\n",
      "        education. Assoc-acdm            1.000000          0.004132   0.000952\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      "\n",
      "10-20 18:27:43.912 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:43.912) \n",
      "10-20 18:27:43.912 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:43.912) \n",
      "10-20 18:27:43.916 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:43.916) \n",
      "10-20 18:27:43.930 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:43.951 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:43.951) \n",
      "10-20 18:27:43.951 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:43.951) \n",
      "10-20 18:27:43.989 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:43.989) \n",
      "10-20 18:27:43.989 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:43.989) \n",
      "10-20 18:27:44.043 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:44.043) \n",
      "10-20 18:27:44.043 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.130 (Wall: 20-Oct 18:27:44.043) \n",
      "10-20 18:27:44.043 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.092 (Wall: 20-Oct 18:27:44.043) \n",
      "10-20 18:27:44.115 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:44.115) \n",
      "10-20 18:27:44.119 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.075 (Wall: 20-Oct 18:27:44.119) \n",
      "10-20 18:27:44.164 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:44.164) \n",
      "10-20 18:27:44.166 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_333\n",
      "10-20 18:27:44.173 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:44.173) \n",
      "10-20 18:27:44.188 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_333\n",
      "10-20 18:27:44.263 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_334\n",
      "10-20 18:27:44.293 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_335\n",
      "10-20 18:27:44.293 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_334\n",
      "10-20 18:27:44.318 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_335\n",
      "10-20 18:27:44.334 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_336\n",
      "10-20 18:27:44.362 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_336\n",
      "10-20 18:27:44.402 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_337\n",
      "10-20 18:27:44.415 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_337\n",
      "10-20 18:27:44.422 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.08203568\n",
      " RMSE: 0.2864187\n",
      " AUC: 0.93934476\n",
      " pr_auc: 0.85004556\n",
      " logloss: 0.26137155\n",
      " mean_per_class_error: 0.16261867\n",
      " default threshold: 0.38785097002983093\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18131  1702  0.0858  1,702 / 19,833\n",
      "     1   1488  4727  0.2394   1,488 / 6,215\n",
      "Totals  19619  6429  0.1225  3,190 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.97 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.990842  4.191150         4.191150       1.000000  0.992603                  1.000000          0.992603      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.987272  4.191150         4.191150       1.000000  0.989266                  1.000000          0.990938      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.981629  4.191150         4.191150       1.000000  0.984852                  1.000000          0.988907      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.968988  4.158911         4.183106       0.992308  0.976058                  0.998081          0.985701      0.041512                 0.167337   315.891082       318.310601            0.167236\n",
      "      5                0.05002303         0.949605  4.175092         4.181501       0.996169  0.960157                  0.997698          0.980584      0.041834                 0.209171   317.509239       318.150083            0.209020\n",
      "      6                0.10000768         0.746511  3.798431         3.990040       0.906298  0.843910                  0.952015          0.912273      0.189863                 0.399035   279.843128       299.003958            0.392732\n",
      "      7                0.15003071         0.613264  3.046063         3.675300       0.726784  0.677846                  0.876919          0.834111      0.152373                 0.551408   204.606252       267.530004            0.527155\n",
      "      8                0.20001536         0.482653  2.452885         3.369814       0.585253  0.547964                  0.804031          0.762602      0.122607                 0.674014   145.288528       236.981367            0.622535\n",
      "      9                0.30006143         0.312324  1.650085         2.796424       0.393707  0.385876                  0.667221          0.636994      0.165084                 0.839099    65.008456       179.642395            0.707954\n",
      "     10                0.39999232         0.177350  0.956413         2.336730       0.228198  0.243650                  0.557539          0.538724      0.095575                 0.934674    -4.358688       133.673029            0.702233\n",
      "     11                0.50000000         0.086006  0.405440         1.950442       0.096737  0.127945                  0.465372          0.456562      0.040547                 0.975221   -59.456049        95.044248            0.624140\n",
      "     12                0.60000768         0.038423  0.160889         1.652164       0.038388  0.059198                  0.394203          0.390331      0.016090                 0.991311   -83.911131        65.216443            0.513925\n",
      "     13                0.69997697         0.020344  0.064380         1.425400       0.015361  0.027916                  0.340098          0.338571      0.006436                 0.997747   -93.561981        42.540031            0.391082\n",
      "     14                0.79998464         0.011458  0.016089         1.249219       0.003839  0.015548                  0.298061          0.298190      0.001609                 0.999356   -98.391113        24.921947            0.261848\n",
      "     15                0.89999232         0.005026  0.006436         1.111121       0.001536  0.008176                  0.265111          0.265963      0.000644                 1.000000   -99.356445        11.112059            0.131347\n",
      "     16                1.00000000         0.001554  0.000000         1.000000       0.000000  0.003102                  0.238598          0.239675      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09029158\n",
      " RMSE: 0.30048558\n",
      " AUC: 0.92720586\n",
      " pr_auc: 0.8352349\n",
      " logloss: 0.28514567\n",
      " mean_per_class_error: 0.1772488\n",
      " default threshold: 0.3929752707481384\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4474   413  0.0845  413 / 4,887\n",
      "     1   439  1187  0.2700  439 / 1,626\n",
      "Totals  4913  1600  0.1308  852 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.15 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.990615  4.005535         4.005535       1.000000  0.992279                  1.000000          0.992279      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.987558  4.005535         4.005535       1.000000  0.988991                  1.000000          0.990648      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.982108  4.005535         4.005535       1.000000  0.985331                  1.000000          0.988884      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.970909  4.005535         4.005535       1.000000  0.977078                  1.000000          0.985944      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.955592  4.005535         4.005535       1.000000  0.962862                  1.000000          0.981342      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.767511  3.563206         3.784371       0.889571  0.858433                  0.944785          0.919888      0.178352                 0.378844   256.320603       278.437054            0.371477\n",
      "      7                0.15000768         0.615121  2.920959         3.497156       0.729231  0.687811                  0.873081          0.842687      0.145756                 0.524600   192.095941       249.715599            0.499227\n",
      "      8                0.20006142         0.483314  2.322227         3.203198       0.579755  0.550855                  0.799693          0.769673      0.116236                 0.640836   132.222738       220.319841            0.587429\n",
      "      9                0.30001535         0.309908  1.661282         2.689489       0.414747  0.388000                  0.671443          0.642514      0.166052                 0.806888    66.128182       168.948925            0.675519\n",
      "     10                0.40012283         0.176994  0.995240         2.265602       0.248466  0.241881                  0.565618          0.542279      0.099631                 0.906519    -0.475969       126.560195            0.674884\n",
      "     11                0.50007677         0.088894  0.541455         1.920984       0.135177  0.128855                  0.479582          0.459645      0.054121                 0.960640   -45.854518        92.098427            0.613801\n",
      "     12                0.60003071         0.038923  0.233810         1.639932       0.058372  0.060554                  0.409417          0.393164      0.023370                 0.984010   -76.618997        63.993247            0.511736\n",
      "     13                0.69998465         0.020518  0.116905         1.422453       0.029186  0.027880                  0.355122          0.341003      0.011685                 0.995695   -88.309498        42.245257            0.394099\n",
      "     14                0.79993858         0.012006  0.036917         1.249327       0.009217  0.016127                  0.311900          0.300409      0.003690                 0.999385   -96.308263        24.932715            0.265806\n",
      "     15                0.89989252         0.005273  0.006153         1.111244       0.001536  0.008562                  0.277427          0.267993      0.000615                 1.000000   -99.384710        11.124382            0.133415\n",
      "     16                1.00000000         0.001554  0.000000         1.000000       0.000000  0.003150                  0.249655          0.241480      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5135.450195          1.000000   0.286208\n",
      "                      capital_gain         3652.287842          0.711191   0.203549\n",
      "                               age         1540.222290          0.299920   0.085839\n",
      "                      capital_loss         1187.258057          0.231189   0.066168\n",
      "                    hours_per_week          981.479309          0.191118   0.054700\n",
      "                            fnlwgt          702.453125          0.136785   0.039149\n",
      "     marital_status. Never-married          694.170044          0.135172   0.038687\n",
      "        occupation. Prof-specialty          515.515686          0.100384   0.028731\n",
      "       occupation. Exec-managerial          504.433624          0.098226   0.028113\n",
      "              education. Bachelors          346.367035          0.067446   0.019304\n",
      "---\n",
      "              workclass. State-gov            9.181472          0.001788   0.000512\n",
      "      occupation. Transport-moving            8.922398          0.001737   0.000497\n",
      "       native_country. Philippines            8.520394          0.001659   0.000475\n",
      "                     occupation.NA            8.328751          0.001622   0.000464\n",
      "       native_country. Puerto-Rico            7.210544          0.001404   0.000402\n",
      "                education. 1st-4th            6.118869          0.001191   0.000341\n",
      "                       race. Black            5.855782          0.001140   0.000326\n",
      "                 native_country.NA            3.842378          0.000748   0.000214\n",
      "           marital_status. Widowed            2.031811          0.000396   0.000113\n",
      "                      workclass.NA            0.116314          0.000023   0.000006\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        64756.808594          1.000000   0.172932\n",
      "                               age        44176.156250          0.682186   0.117972\n",
      "                    hours_per_week        30137.691406          0.465398   0.080482\n",
      "                      capital_loss        27312.142578          0.421765   0.072937\n",
      "marital_status. Married-civ-spouse        27205.316406          0.420115   0.072651\n",
      "                            fnlwgt        19794.906250          0.305681   0.052862\n",
      "        occupation. Prof-specialty        10332.770508          0.159563   0.027594\n",
      "              education. Bachelors         9789.545898          0.151174   0.026143\n",
      "       occupation. Exec-managerial         9567.565430          0.147746   0.025550\n",
      "              education. Doctorate         8972.301758          0.138554   0.023960\n",
      "---\n",
      "          occupation. Craft-repair          326.437469          0.005041   0.000872\n",
      "             relationship. Husband          302.731079          0.004675   0.000808\n",
      "                     occupation.NA          298.759613          0.004614   0.000798\n",
      "          marital_status. Divorced          277.640289          0.004287   0.000741\n",
      "              workclass. State-gov          252.043259          0.003892   0.000673\n",
      "                       race. Black          222.742371          0.003440   0.000595\n",
      "          race. Asian-Pac-Islander          220.023010          0.003398   0.000588\n",
      "                 native_country.NA          145.587036          0.002248   0.000389\n",
      "           marital_status. Widowed          110.467537          0.001706   0.000295\n",
      "                      workclass.NA           19.389284          0.000299   0.000052\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          272.000000          1.000000   0.211509\n",
      "                         age          272.000000          1.000000   0.211509\n",
      "              hours_per_week          127.000000          0.466912   0.098756\n",
      "                capital_gain           64.000000          0.235294   0.049767\n",
      "                capital_loss           54.000000          0.198529   0.041991\n",
      "  occupation. Prof-specialty           36.000000          0.132353   0.027994\n",
      "          education. HS-grad           35.000000          0.128676   0.027216\n",
      " occupation. Exec-managerial           30.000000          0.110294   0.023328\n",
      "        education. Bachelors           29.000000          0.106618   0.022551\n",
      "          workclass. Private           29.000000          0.106618   0.022551\n",
      "---\n",
      "occupation. Transport-moving            3.000000          0.011029   0.002333\n",
      "              education. 9th            3.000000          0.011029   0.002333\n",
      "          education. 5th-6th            2.000000          0.007353   0.001555\n",
      "     marital_status. Widowed            1.000000          0.003676   0.000778\n",
      "relationship. Other-relative            1.000000          0.003676   0.000778\n",
      "                workclass.NA            1.000000          0.003676   0.000778\n",
      "          education. 1st-4th            1.000000          0.003676   0.000778\n",
      " native_country. Philippines            1.000000          0.003676   0.000778\n",
      " native_country. Puerto-Rico            1.000000          0.003676   0.000778\n",
      "           native_country.NA            1.000000          0.003676   0.000778\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      "\n",
      "10-20 18:27:44.463 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_338\n",
      "10-20 18:27:44.482 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:44.482) \n",
      "10-20 18:27:44.485 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_338\n",
      "10-20 18:27:44.493 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.08069644\n",
      " RMSE: 0.2840712\n",
      " AUC: 0.94232744\n",
      " pr_auc: 0.85824054\n",
      " logloss: 0.2574508\n",
      " mean_per_class_error: 0.14870983\n",
      " default threshold: 0.36715683341026306\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17844  1901  0.0963  1,901 / 19,745\n",
      "     1   1268  5036  0.2011   1,268 / 6,304\n",
      "Totals  19112  6937  0.1217  3,169 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.33 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.990078  4.132138         4.132138       1.000000  0.991977                  1.000000          0.991977      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.986786  4.132138         4.132138       1.000000  0.988548                  1.000000          0.990265      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.980686  4.132138         4.132138       1.000000  0.984182                  1.000000          0.988235      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.968248  4.132138         4.132138       1.000000  0.974962                  1.000000          0.984923      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.950581  4.100474         4.125796       0.992337  0.959893                  0.998465          0.979909      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.769082  3.763991         3.944963       0.910906  0.854240                  0.954702          0.917099      0.188135                 0.394511   276.399082       294.496277            0.388535\n",
      "      7                0.15002495         0.633548  3.136366         3.675362       0.759018  0.700609                  0.889458          0.844917      0.156885                 0.551396   213.636593       267.536152            0.529517\n",
      "      8                0.20000768         0.499972  2.507211         3.383436       0.606759  0.566647                  0.818810          0.775376      0.125317                 0.676713   150.721143       238.343610            0.628904\n",
      "      9                0.30008830         0.318814  1.653172         2.806386       0.400077  0.398197                  0.679161          0.649586      0.165451                 0.842164    65.317233       180.638638            0.715144\n",
      "     10                0.40001536         0.178449  0.941359         2.340488       0.227814  0.243596                  0.566411          0.548166      0.094067                 0.936231    -5.864079       134.048756            0.707414\n",
      "     11                0.50001919         0.087781  0.423524         1.957095       0.102495  0.128850                  0.473628          0.464303      0.042354                 0.978585   -57.647565        95.709492            0.631358\n",
      "     12                0.59998464         0.039422  0.142816         1.654812       0.034562  0.060114                  0.400473          0.396960      0.014277                 0.992862   -85.718416        65.481181            0.518311\n",
      "     13                0.69998848         0.019683  0.053932         1.426102       0.013052  0.028089                  0.345124          0.344261      0.005393                 0.998255   -94.606806        42.610214            0.393494\n",
      "     14                0.79999232         0.009933  0.011104         1.249219       0.002687  0.014364                  0.302318          0.303022      0.001110                 0.999365   -98.889637        24.921884            0.263027\n",
      "     15                0.89999616         0.003793  0.006345         1.111116       0.001536  0.006578                  0.268896          0.270082      0.000635                 1.000000   -99.365507        11.111585            0.131932\n",
      "     16                1.00000000         0.001454  0.000000         1.000000       0.000000  0.002484                  0.242005          0.243321      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09368558\n",
      " RMSE: 0.306081\n",
      " AUC: 0.9156074\n",
      " pr_auc: 0.80477554\n",
      " logloss: 0.29567274\n",
      " mean_per_class_error: 0.18499799\n",
      " default threshold: 0.3744058907032013\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4429   546  0.1097  546 / 4,975\n",
      "     1   400  1137  0.2602  400 / 1,537\n",
      "Totals  4829  1683  0.1453  946 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.990195  4.236825         4.236825       1.000000  0.991894                  1.000000          0.991894      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.986783  4.236825         4.236825       1.000000  0.988608                  1.000000          0.990263      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.979715  4.236825         4.236825       1.000000  0.984068                  1.000000          0.988209      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.964588  4.236825         4.236825       1.000000  0.972135                  1.000000          0.984206      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.941838  4.236825         4.236825       1.000000  0.955437                  1.000000          0.978469      0.042290                 0.212101  323.682498       323.682498            0.212101\n",
      "      6                0.10012285         0.743319  3.522023         3.879424       0.831288  0.835063                  0.915644          0.906766      0.176318                 0.388419  252.202322       287.942410            0.377364\n",
      "      7                0.15003071         0.621661  2.841932         3.534301       0.670769  0.681006                  0.834186          0.831667      0.141835                 0.530254  184.193184       253.430129            0.497691\n",
      "      8                0.20009214         0.491792  2.222384         3.206070       0.524540  0.554167                  0.756715          0.762239      0.111256                 0.641509  122.238366       220.607017            0.577791\n",
      "      9                0.30006143         0.320505  1.470849         2.627959       0.347158  0.394427                  0.620266          0.639697      0.147040                 0.788549   47.084861       162.795900            0.639403\n",
      "     10                0.40003071         0.184006  1.112899         2.249339       0.262673  0.251635                  0.530902          0.542719      0.111256                 0.899805   11.289873       124.933933            0.654177\n",
      "     11                0.50000000         0.089855  0.579228         1.915420       0.136713  0.132825                  0.452088          0.460765      0.057905                 0.957710  -42.077201        91.541965            0.599117\n",
      "     12                0.59996929         0.038422  0.221278         1.633135       0.052227  0.060514                  0.385462          0.394074      0.022121                 0.979831  -77.872189        63.313500            0.497218\n",
      "     13                0.69993857         0.019472  0.091115         1.412895       0.021505  0.027699                  0.333480          0.341746      0.009109                 0.988939  -90.888548        41.289469            0.378286\n",
      "     14                0.79990786         0.010447  0.091115         1.247704       0.021505  0.014705                  0.294490          0.300874      0.009109                 0.998048  -90.888548        24.770388            0.259355\n",
      "     15                0.89987715         0.003928  0.013016         1.110540       0.003072  0.006995                  0.262116          0.268226      0.001301                 0.999349  -98.698364        11.053979            0.130204\n",
      "     16                1.00000000         0.001531  0.006498         1.000000       0.001534  0.002558                  0.236026          0.241627      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6136.934570          1.000000   0.333609\n",
      "                      capital_gain         3569.742676          0.581682   0.194054\n",
      "                               age         1592.467285          0.259489   0.086568\n",
      "                      capital_loss         1186.094238          0.193271   0.064477\n",
      "                    hours_per_week          883.943115          0.144037   0.048052\n",
      "                            fnlwgt          690.505005          0.112516   0.037536\n",
      "        occupation. Prof-specialty          667.543396          0.108775   0.036288\n",
      "       occupation. Exec-managerial          586.944885          0.095641   0.031907\n",
      "              education. Bachelors          464.466003          0.075684   0.025249\n",
      "                education. Masters          241.199005          0.039303   0.013112\n",
      "---\n",
      "       native_country. Philippines            9.531221          0.001553   0.000518\n",
      "                education. 1st-4th            9.308963          0.001517   0.000506\n",
      "           marital_status. Widowed            8.732368          0.001423   0.000475\n",
      "                       race. Other            7.845816          0.001278   0.000427\n",
      "                     occupation.NA            7.701414          0.001255   0.000419\n",
      "          race. Amer-Indian-Eskimo            7.005766          0.001142   0.000381\n",
      "              education. Assoc-voc            6.760022          0.001102   0.000367\n",
      "         marital_status. Separated            5.387891          0.000878   0.000293\n",
      "           relationship. Unmarried            4.047234          0.000659   0.000220\n",
      "                 native_country.NA            3.566940          0.000581   0.000194\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        56771.500000          1.000000   0.150903\n",
      "                               age        49071.085938          0.864361   0.130435\n",
      "marital_status. Married-civ-spouse        28577.000000          0.503369   0.075960\n",
      "                    hours_per_week        27025.728516          0.476044   0.071837\n",
      "                      capital_loss        26967.185547          0.475013   0.071681\n",
      "                            fnlwgt        20833.160156          0.366965   0.055376\n",
      "              education. Bachelors        11692.306641          0.205954   0.031079\n",
      "       occupation. Exec-managerial        10508.556641          0.185103   0.027933\n",
      "        occupation. Prof-specialty         9777.846680          0.172232   0.025990\n",
      "                education. Masters         9208.414063          0.162201   0.024477\n",
      "---\n",
      "          occupation. Craft-repair          861.214783          0.015170   0.002289\n",
      "       native_country. Philippines          650.629272          0.011460   0.001729\n",
      "                       race. Black          581.293335          0.010239   0.001545\n",
      "              workclass. Local-gov          421.259613          0.007420   0.001120\n",
      "                     occupation.NA          396.399567          0.006982   0.001054\n",
      "                       race. White          335.235657          0.005905   0.000891\n",
      "           relationship. Unmarried          330.472870          0.005821   0.000878\n",
      "              education. Assoc-voc          279.530792          0.004924   0.000743\n",
      "           marital_status. Widowed          248.945084          0.004385   0.000662\n",
      "                 native_country.NA           66.226852          0.001167   0.000176\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                         age          296.000000          1.000000   0.229992\n",
      "                      fnlwgt          261.000000          0.881757   0.202797\n",
      "              hours_per_week          126.000000          0.425676   0.097902\n",
      "                capital_gain           67.000000          0.226351   0.052059\n",
      "                capital_loss           41.000000          0.138514   0.031857\n",
      "                 sex. Female           36.000000          0.121622   0.027972\n",
      " occupation. Exec-managerial           34.000000          0.114865   0.026418\n",
      "        education. Bachelors           31.000000          0.104730   0.024087\n",
      "          education. HS-grad           31.000000          0.104730   0.024087\n",
      "  occupation. Prof-specialty           30.000000          0.101351   0.023310\n",
      "---\n",
      "        education. Assoc-voc            2.000000          0.006757   0.001554\n",
      "relationship. Other-relative            2.000000          0.006757   0.001554\n",
      "               occupation.NA            2.000000          0.006757   0.001554\n",
      "   marital_status. Separated            2.000000          0.006757   0.001554\n",
      " native_country. Philippines            2.000000          0.006757   0.001554\n",
      "          education. 5th-6th            2.000000          0.006757   0.001554\n",
      "                 race. Other            1.000000          0.003378   0.000777\n",
      "          education. 1st-4th            1.000000          0.003378   0.000777\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.003378   0.000777\n",
      "           native_country.NA            1.000000          0.003378   0.000777\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      " 2023-10-20 18:27:43  3.142 sec              20       0.28407          0.25745      0.94233         0.85824       4.13214                       0.12166         0.30608            0.29567        0.91561           0.80478         4.23682                         0.14527\n",
      "\n",
      "10-20 18:27:44.542 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_339\n",
      "10-20 18:27:44.546 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:44.546) \n",
      "10-20 18:27:44.548 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_340\n",
      "10-20 18:27:44.555 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:44.555) \n",
      "10-20 18:27:44.563 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_340\n",
      "10-20 18:27:44.570 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_339\n",
      "10-20 18:27:44.579 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.08206878\n",
      " RMSE: 0.2864765\n",
      " AUC: 0.9393934\n",
      " pr_auc: 0.8538331\n",
      " logloss: 0.26186308\n",
      " mean_per_class_error: 0.1524636\n",
      " default threshold: 0.36415237188339233\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17732  2006  0.1016  2,006 / 19,738\n",
      "     1   1283  5028  0.2033   1,283 / 6,311\n",
      "Totals  19015  7034  0.1263  3,289 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.35 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991079  4.127555         4.127555       1.000000  0.992810                  1.000000          0.992810      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.988141  4.127555         4.127555       1.000000  0.989684                  1.000000          0.991250      0.041198                 0.082554  312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.982769  4.127555         4.127555       1.000000  0.985770                  1.000000          0.989421      0.041356                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.973411  4.127555         4.127555       1.000000  0.978539                  1.000000          0.986706      0.041198                 0.165109  312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.954661  4.095926         4.121220       0.992337  0.964662                  0.998465          0.982290      0.041039                 0.206148  309.592629       312.121960            0.206047\n",
      "      6                0.10000384         0.769017  3.778837         3.950094       0.915515  0.857312                  0.957006          0.919825      0.188877                 0.395025  277.883689       295.009396            0.389350\n",
      "      7                0.15002495         0.630168  3.098042         3.666004       0.750576  0.699595                  0.888178          0.846396      0.154968                 0.549992  209.804210       266.600400            0.527852\n",
      "      8                0.20000768         0.500045  2.412496         3.352747       0.584485  0.565357                  0.812284          0.776163      0.120583                 0.670575  141.249570       235.274722            0.621026\n",
      "      9                0.30001152         0.312805  1.654191         2.786562       0.400768  0.402430                  0.675112          0.651586      0.165425                 0.836001   65.419097       178.656181            0.707366\n",
      "     10                0.40001536         0.173728  0.971283         2.332742       0.235317  0.240144                  0.565163          0.548725      0.097132                 0.933133   -2.871737       133.274201            0.703575\n",
      "     11                0.50001919         0.087365  0.407210         1.947636       0.098656  0.127305                  0.471862          0.464441      0.040723                 0.973855  -59.279015        94.763558            0.625340\n",
      "     12                0.59998464         0.038923  0.163264         1.650335       0.039555  0.060827                  0.399834          0.397194      0.016321                 0.990176  -83.673649        65.033538            0.514950\n",
      "     13                0.69998848         0.019655  0.068132         1.424294       0.016507  0.027875                  0.345070          0.344431      0.006814                 0.996989  -93.186761        42.429398            0.391964\n",
      "     14                0.79999232         0.010228  0.025352         1.249418       0.006142  0.014359                  0.302702          0.303170      0.002535                 0.999525  -97.464841        24.941779            0.263330\n",
      "     15                0.89999616         0.004508  0.003169         1.110940       0.000768  0.007103                  0.269152          0.270272      0.000317                 0.999842  -99.683105        11.093979            0.131770\n",
      "     16                1.00000000         0.001500  0.001584         1.000000       0.000384  0.002926                  0.242274          0.243537      0.000158                 1.000000  -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.088755906\n",
      " RMSE: 0.2979193\n",
      " AUC: 0.92503744\n",
      " pr_auc: 0.8203713\n",
      " logloss: 0.28058875\n",
      " mean_per_class_error: 0.18635152\n",
      " default threshold: 0.42619675397872925\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4597   385  0.0773  385 / 4,982\n",
      "     1   452  1078  0.2954  452 / 1,530\n",
      "Totals  5049  1463  0.1285  837 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.69 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.990773  4.256209         4.256209       1.000000  0.992662                  1.000000          0.992662      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.987399  4.190729         4.223719       0.984615  0.989102                  0.992366          0.990896      0.041830                 0.084967   319.072901       322.371900            0.084767\n",
      "      3                0.03009828         0.982710  4.256209         4.234494       1.000000  0.985105                  0.994898          0.988975      0.042484                 0.127451   325.620915       323.449380            0.127250\n",
      "      4                0.04007985         0.972607  4.256209         4.239902       1.000000  0.978115                  0.996169          0.986271      0.042484                 0.169935   325.620915       323.990184            0.169734\n",
      "      5                0.05006143         0.954091  4.125249         4.217042       0.969231  0.963737                  0.990798          0.981778      0.041176                 0.211111   312.524887       321.704158            0.210509\n",
      "      6                0.10012285         0.758950  3.747031         3.982036       0.880368  0.851176                  0.935583          0.916477      0.187582                 0.398693   274.703076       298.203617            0.390262\n",
      "      7                0.15003071         0.608454  2.828742         3.598392       0.664615  0.681238                  0.845445          0.838224      0.141176                 0.539869   182.874208       259.839177            0.509560\n",
      "      8                0.20009214         0.476057  2.428389         3.305667       0.570552  0.541728                  0.776669          0.764043      0.121569                 0.661438   142.838927       230.566666            0.603028\n",
      "      9                0.30006143         0.293168  1.438350         2.683546       0.337942  0.377962                  0.630502          0.635416      0.143791                 0.805229    43.835025       168.354640            0.660307\n",
      "     10                0.40003071         0.169429  1.013383         2.266166       0.238095  0.228421                  0.532438          0.533706      0.101307                 0.906536     1.338313       126.616587            0.662056\n",
      "     11                0.50000000         0.086946  0.588416         1.930719       0.138249  0.125355                  0.453624          0.452061      0.058824                 0.965359   -41.158399        93.071895            0.608274\n",
      "     12                0.59996929         0.036977  0.228828         1.647143       0.053763  0.058498                  0.386998          0.386484      0.022876                 0.988235   -77.117155        64.714314            0.507505\n",
      "     13                0.69993857         0.018304  0.071918         1.422160       0.016897  0.026514                  0.334138          0.335071      0.007190                 0.995425   -92.808249        42.216028            0.386232\n",
      "     14                0.79990786         0.010081  0.039228         1.249327       0.009217  0.013897                  0.293530          0.294932      0.003922                 0.999346   -96.077227        24.932689            0.260687\n",
      "     15                0.89987715         0.004146  0.006538         1.111263       0.001536  0.006898                  0.261092          0.262934      0.000654                 1.000000   -99.346204        11.126280            0.130871\n",
      "     16                1.00000000         0.001443  0.000000         1.000000       0.000000  0.002777                  0.234951          0.236886      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6110.791504          1.000000   0.335187\n",
      "                      capital_gain         3547.373779          0.580510   0.194579\n",
      "                               age         1621.095947          0.265284   0.088920\n",
      "                      capital_loss         1170.443481          0.191537   0.064201\n",
      "                    hours_per_week          928.732117          0.151982   0.050942\n",
      "                            fnlwgt          727.282959          0.119016   0.039893\n",
      "       occupation. Exec-managerial          610.556946          0.099915   0.033490\n",
      "        occupation. Prof-specialty          593.855225          0.097181   0.032574\n",
      "              education. Bachelors          449.851959          0.073616   0.024675\n",
      "                education. Masters          226.190582          0.037015   0.012407\n",
      "---\n",
      "          marital_status. Divorced           13.497120          0.002209   0.000740\n",
      "           relationship. Unmarried           12.763580          0.002089   0.000700\n",
      "          race. Asian-Pac-Islander           12.560319          0.002055   0.000689\n",
      "             education. Assoc-acdm           12.448408          0.002037   0.000683\n",
      "              education. Assoc-voc           11.522469          0.001886   0.000632\n",
      "         marital_status. Separated            9.593512          0.001570   0.000526\n",
      "              workclass. State-gov            9.267618          0.001517   0.000508\n",
      "      relationship. Other-relative            8.906333          0.001457   0.000489\n",
      "                     occupation.NA            4.040448          0.000661   0.000222\n",
      "                 native_country.NA            3.018235          0.000494   0.000166\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        55723.648438          1.000000   0.149128\n",
      "                               age        47417.472656          0.850940   0.126899\n",
      "marital_status. Married-civ-spouse        31565.833984          0.566471   0.084477\n",
      "                      capital_loss        29418.060547          0.527928   0.078729\n",
      "                            fnlwgt        25268.283203          0.453457   0.067623\n",
      "                    hours_per_week        25027.488281          0.449136   0.066979\n",
      "              education. Bachelors        13097.748047          0.235048   0.035052\n",
      "       occupation. Exec-managerial        11051.196289          0.198321   0.029575\n",
      "        occupation. Prof-specialty         9265.189453          0.166270   0.024796\n",
      "                education. Masters         8692.873047          0.156000   0.023264\n",
      "---\n",
      "                       race. Black          727.518372          0.013056   0.001947\n",
      "          marital_status. Divorced          512.554810          0.009198   0.001372\n",
      "           relationship. Unmarried          507.843323          0.009114   0.001359\n",
      "          occupation. Craft-repair          493.362793          0.008854   0.001320\n",
      "             education. Assoc-acdm          485.249054          0.008708   0.001299\n",
      "             relationship. Husband          392.501831          0.007044   0.001050\n",
      "              workclass. State-gov          261.739502          0.004697   0.000700\n",
      "          race. Asian-Pac-Islander          253.200989          0.004544   0.000678\n",
      "                 native_country.NA          202.733505          0.003638   0.000543\n",
      "                     occupation.NA          136.200623          0.002444   0.000365\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          318.000000          1.000000   0.236431\n",
      "                       fnlwgt          262.000000          0.823899   0.194796\n",
      "               hours_per_week          113.000000          0.355346   0.084015\n",
      "                 capital_gain           71.000000          0.223270   0.052788\n",
      "                 capital_loss           46.000000          0.144654   0.034201\n",
      "         education. Bachelors           38.000000          0.119497   0.028253\n",
      "           workclass. Private           38.000000          0.119497   0.028253\n",
      "   occupation. Prof-specialty           34.000000          0.106918   0.025279\n",
      "           education. HS-grad           34.000000          0.106918   0.025279\n",
      "  occupation. Exec-managerial           30.000000          0.094340   0.022305\n",
      "---\n",
      "     race. Asian-Pac-Islander            3.000000          0.009434   0.002230\n",
      "         workclass. State-gov            3.000000          0.009434   0.002230\n",
      "      workclass. Self-emp-inc            3.000000          0.009434   0.002230\n",
      "occupation. Handlers-cleaners            2.000000          0.006289   0.001487\n",
      "                occupation.NA            2.000000          0.006289   0.001487\n",
      "    marital_status. Separated            2.000000          0.006289   0.001487\n",
      "        education. Assoc-acdm            2.000000          0.006289   0.001487\n",
      "           education. 5th-6th            2.000000          0.006289   0.001487\n",
      " relationship. Other-relative            1.000000          0.003145   0.000743\n",
      "            native_country.NA            1.000000          0.003145   0.000743\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      "\n",
      "10-20 18:27:44.578 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.08201289\n",
      " RMSE: 0.28637892\n",
      " AUC: 0.9395548\n",
      " pr_auc: 0.8532678\n",
      " logloss: 0.26139718\n",
      " mean_per_class_error: 0.15842825\n",
      " default threshold: 0.37741178274154663\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17920  1848  0.0935  1,848 / 19,768\n",
      "     1   1403  4878  0.2234   1,403 / 6,281\n",
      "Totals  19323  6726  0.1248  3,251 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.27 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991255  4.147270         4.147270       1.000000  0.992609                  1.000000          0.992609      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.988805  4.147270         4.147270       1.000000  0.990023                  1.000000          0.991319      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.983972  4.147270         4.147270       1.000000  0.987005                  1.000000          0.989879      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04003992         0.971193  4.147270         4.147270       1.000000  0.977493                  1.000000          0.986780      0.041554                 0.166056   314.726954       314.726954            0.166056\n",
      "      5                0.05002111         0.953483  4.115367         4.140904       0.992308  0.963499                  0.998465          0.982134      0.041076                 0.207133   311.536747       314.090382            0.207031\n",
      "      6                0.10000384         0.766184  3.796886         3.968961       0.915515  0.853909                  0.957006          0.918046      0.189779                 0.396911   279.688579       296.896083            0.391246\n",
      "      7                0.15002495         0.621271  3.068279         3.668657       0.739831  0.694679                  0.884596          0.843572      0.153479                 0.550390   206.827923       266.865681            0.527575\n",
      "      8                0.20000768         0.490954  2.430389         3.359209       0.586022  0.555005                  0.809981          0.771458      0.121477                 0.671868   143.038914       235.920873            0.621787\n",
      "      9                0.30001152         0.307948  1.631843         2.783420       0.393474  0.394534                  0.671145          0.645816      0.163191                 0.835058    63.184310       178.342019            0.705050\n",
      "     10                0.40001536         0.181740  0.980698         2.332740       0.236468  0.242721                  0.562476          0.545042      0.098074                 0.933132    -1.930210       133.273962            0.702506\n",
      "     11                0.50001919         0.088627  0.421891         1.950570       0.101727  0.131154                  0.470326          0.462265      0.042191                 0.975322   -57.810886        95.056992            0.626324\n",
      "     12                0.59998464         0.041312  0.152895         1.651053       0.036866  0.061705                  0.398106          0.395526      0.015284                 0.990607   -84.710527        65.105324            0.514736\n",
      "     13                0.69998848         0.020455  0.066866         1.424728       0.016123  0.029445                  0.343534          0.343226      0.006687                 0.997293   -93.313423        42.472833            0.391769\n",
      "     14                0.79999232         0.010312  0.022289         1.249415       0.005374  0.014953                  0.301262          0.302190      0.002229                 0.999522   -97.771141        24.941495            0.262928\n",
      "     15                0.90014972         0.004281  0.004769         1.110926       0.001150  0.006973                  0.267869          0.269342      0.000478                 1.000000   -99.523120        11.092631            0.131576\n",
      "     16                1.00000000         0.001526  0.000000         1.000000       0.000000  0.002865                  0.241122          0.242734      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09109454\n",
      " RMSE: 0.3018187\n",
      " AUC: 0.92423475\n",
      " pr_auc: 0.81631094\n",
      " logloss: 0.28613096\n",
      " mean_per_class_error: 0.16393946\n",
      " default threshold: 0.3312135338783264\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4287   665  0.1343  665 / 4,952\n",
      "     1   302  1258  0.1936  302 / 1,560\n",
      "Totals  4589  1923  0.1485  967 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.55 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01028870         0.991016  4.174359         4.174359       1.000000  0.992509                  1.000000          0.992509      0.042949                 0.042949  317.435897       317.435897            0.042949\n",
      "      2                0.02011671         0.989156  4.174359         4.174359       1.000000  0.989990                  1.000000          0.991278      0.041026                 0.083974  317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.984982  4.110138         4.153061       0.984615  0.987044                  0.994898          0.989874      0.041026                 0.125000  311.013807       315.306122            0.124798\n",
      "      4                0.04007985         0.971309  4.174359         4.158365       1.000000  0.977420                  0.996169          0.986773      0.041667                 0.166667  317.435897       315.836526            0.166465\n",
      "      5                0.05006143         0.956285  4.110138         4.148749       0.984615  0.964186                  0.993865          0.982269      0.041026                 0.207692  311.013807       314.874941            0.207288\n",
      "      6                0.10012285         0.779307  3.457291         3.803020       0.828221  0.860492                  0.911043          0.921381      0.173077                 0.380769  245.729118       280.302029            0.369057\n",
      "      7                0.15003071         0.633471  2.902785         3.503556       0.695385  0.703370                  0.839304          0.848859      0.144872                 0.525641  190.278501       250.355615            0.493937\n",
      "      8                0.20009214         0.517958  2.292056         3.200449       0.549080  0.573923                  0.766692          0.780073      0.114744                 0.640385  129.205600       220.044867            0.578995\n",
      "      9                0.30006143         0.319310  1.718477         2.706711       0.411674  0.409263                  0.648414          0.656533      0.171795                 0.812179   71.847651       170.671076            0.673448\n",
      "     10                0.40003071         0.179302  1.006719         2.281876       0.241167  0.244798                  0.546641          0.553638      0.100641                 0.912821    0.671945       128.187608            0.674331\n",
      "     11                0.50000000         0.087359  0.500154         1.925641       0.119816  0.128545                  0.461302          0.468646      0.050000                 0.962821  -49.984639        92.564103            0.608620\n",
      "     12                0.59996929         0.038567  0.237252         1.644315       0.056836  0.059614                  0.393908          0.400491      0.023718                 0.986538  -76.274765        64.431494            0.508348\n",
      "     13                0.69993857         0.019981  0.096183         1.423202       0.023041  0.027860                  0.340939          0.347270      0.009615                 0.996154  -90.381661        42.320181            0.389530\n",
      "     14                0.79990786         0.009856  0.019237         1.247740       0.004608  0.014650                  0.298906          0.305700      0.001923                 0.998077  -98.076332        24.773986            0.260597\n",
      "     15                0.89987715         0.004285  0.012824         1.110550       0.003072  0.006768                  0.266041          0.272491      0.001282                 0.999359  -98.717555        11.055045            0.130821\n",
      "     16                1.00000000         0.001567  0.006402         1.000000       0.001534  0.002910                  0.239558          0.245500      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5971.696289          1.000000   0.332571\n",
      "                      capital_gain         3596.666504          0.602286   0.200303\n",
      "                               age         1564.525146          0.261990   0.087130\n",
      "                      capital_loss         1164.878052          0.195067   0.064873\n",
      "                    hours_per_week          814.587219          0.136408   0.045365\n",
      "        occupation. Prof-specialty          621.385620          0.104055   0.034606\n",
      "       occupation. Exec-managerial          568.919983          0.095269   0.031684\n",
      "                            fnlwgt          533.965942          0.089416   0.029737\n",
      "              education. Bachelors          429.649902          0.071948   0.023928\n",
      "                education. HS-grad          204.286133          0.034209   0.011377\n",
      "---\n",
      "          race. Amer-Indian-Eskimo           10.520233          0.001762   0.000586\n",
      "                      workclass.NA            8.126078          0.001361   0.000453\n",
      "          race. Asian-Pac-Islander            7.892856          0.001322   0.000440\n",
      "      occupation. Transport-moving            6.968823          0.001167   0.000388\n",
      "                   education. 12th            6.441113          0.001079   0.000359\n",
      "                education. 1st-4th            6.290231          0.001053   0.000350\n",
      "       native_country. Philippines            5.725068          0.000959   0.000319\n",
      "             education. Assoc-acdm            2.577040          0.000432   0.000144\n",
      "         marital_status. Separated            2.485362          0.000416   0.000138\n",
      "                     occupation.NA            2.456347          0.000411   0.000137\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        59517.847656          1.000000   0.159426\n",
      "                               age        48343.933594          0.812259   0.129495\n",
      "marital_status. Married-civ-spouse        29409.169922          0.494124   0.078776\n",
      "                      capital_loss        28288.611328          0.475296   0.075775\n",
      "                    hours_per_week        24595.929688          0.413253   0.065883\n",
      "                            fnlwgt        15816.475586          0.265743   0.042366\n",
      "        occupation. Prof-specialty        11325.034180          0.190280   0.030336\n",
      "       occupation. Exec-managerial        10237.769531          0.172012   0.027423\n",
      "              education. Bachelors         9924.269531          0.166744   0.026583\n",
      "                education. 7th-8th         7307.266113          0.122774   0.019573\n",
      "---\n",
      "                      workclass.NA          465.188629          0.007816   0.001246\n",
      "          race. Asian-Pac-Islander          454.609222          0.007638   0.001218\n",
      "              education. Assoc-voc          433.497559          0.007283   0.001161\n",
      "              workclass. Local-gov          317.564728          0.005336   0.000851\n",
      "          marital_status. Divorced          317.167572          0.005329   0.000850\n",
      "      occupation. Transport-moving          264.611694          0.004446   0.000709\n",
      "         marital_status. Separated          141.130630          0.002371   0.000378\n",
      "             education. Assoc-acdm          139.246597          0.002340   0.000373\n",
      "                     occupation.NA          111.825424          0.001879   0.000300\n",
      "       native_country. Philippines           96.539368          0.001622   0.000259\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                        age          276.000000          1.000000   0.226974\n",
      "                     fnlwgt          203.000000          0.735507   0.166941\n",
      "             hours_per_week          111.000000          0.402174   0.091283\n",
      "               capital_gain           72.000000          0.260870   0.059211\n",
      "               capital_loss           43.000000          0.155797   0.035362\n",
      "       education. Bachelors           33.000000          0.119565   0.027138\n",
      "         education. HS-grad           33.000000          0.119565   0.027138\n",
      "occupation. Exec-managerial           32.000000          0.115942   0.026316\n",
      "                sex. Female           32.000000          0.115942   0.026316\n",
      " occupation. Prof-specialty           31.000000          0.112319   0.025493\n",
      "---\n",
      "         education. 5th-6th            3.000000          0.010870   0.002467\n",
      "              occupation.NA            2.000000          0.007246   0.001645\n",
      "   race. Asian-Pac-Islander            2.000000          0.007246   0.001645\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.007246   0.001645\n",
      "            education. 12th            1.000000          0.003623   0.000822\n",
      "  marital_status. Separated            1.000000          0.003623   0.000822\n",
      "               workclass.NA            1.000000          0.003623   0.000822\n",
      "         education. 1st-4th            1.000000          0.003623   0.000822\n",
      "native_country. Philippines            1.000000          0.003623   0.000822\n",
      "      education. Assoc-acdm            1.000000          0.003623   0.000822\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      " 2023-10-20 18:27:44  3.317 sec              20       0.28638          0.26140      0.93955         0.85327       4.14727                       0.12480         0.30182            0.28613        0.92423           0.81631         4.17436                         0.14850\n",
      "\n",
      "10-20 18:27:44.618 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:44.618) \n",
      "10-20 18:27:44.632 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.076 (Wall: 20-Oct 18:27:44.632) \n",
      "10-20 18:27:44.652 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:44.652) \n",
      "10-20 18:27:44.657 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:44.657) \n",
      "10-20 18:27:44.667 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:44.667) \n",
      "10-20 18:27:44.706 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:44.706) \n",
      "10-20 18:27:44.718 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:44.718) \n",
      "10-20 18:27:44.722 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:44.722) \n",
      "10-20 18:27:44.731 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:44.731) \n",
      "10-20 18:27:44.786 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:44.786) \n",
      "10-20 18:27:44.806 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.088 (Wall: 20-Oct 18:27:44.806) \n",
      "10-20 18:27:44.817 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:44.817) \n",
      "10-20 18:27:44.822 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:44.822) \n",
      "10-20 18:27:44.844 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_341\n",
      "10-20 18:27:44.850 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:44.892 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_341\n",
      "10-20 18:27:44.910 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:44.909) \n",
      "10-20 18:27:44.910 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.093 (Wall: 20-Oct 18:27:44.910) \n",
      "10-20 18:27:44.927 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.105 (Wall: 20-Oct 18:27:44.927) \n",
      "10-20 18:27:45.115 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.205 (Wall: 20-Oct 18:27:45.115) \n",
      "10-20 18:27:45.284 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_342\n",
      "10-20 18:27:45.314 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_343\n",
      "10-20 18:27:45.345 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_344\n",
      "10-20 18:27:45.351 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_342\n",
      "10-20 18:27:45.396 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_343\n",
      "10-20 18:27:45.404 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_344\n",
      "10-20 18:27:45.506 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_345\n",
      "10-20 18:27:45.519 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_345\n",
      "10-20 18:27:45.532 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.08016495\n",
      " RMSE: 0.28313416\n",
      " AUC: 0.9422729\n",
      " pr_auc: 0.8555958\n",
      " logloss: 0.25489858\n",
      " mean_per_class_error: 0.1573449\n",
      " default threshold: 0.38783299922943115\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18120  1713  0.0864  1,713 / 19,833\n",
      "     1   1419  4796  0.2283   1,419 / 6,215\n",
      "Totals  19539  6509  0.1202  3,132 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.97 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005835         0.993585  4.191150         4.191150       1.000000  0.994931                  1.000000          0.994931      0.042156                 0.042156   319.115044       319.115044            0.042156\n",
      "      2                0.02000154         0.990489  4.191150         4.191150       1.000000  0.992105                  1.000000          0.993526      0.041673                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.985766  4.191150         4.191150       1.000000  0.988359                  1.000000          0.991801      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.974007  4.158911         4.183106       0.992308  0.980683                  0.998081          0.989027      0.041512                 0.167337   315.891082       318.310601            0.167236\n",
      "      5                0.05002303         0.957033  4.175092         4.181501       0.996169  0.966465                  0.997698          0.984508      0.041834                 0.209171   317.509239       318.150083            0.209020\n",
      "      6                0.10000768         0.764763  3.843497         4.012564       0.917051  0.857896                  0.957390          0.921226      0.192116                 0.401287   284.349741       301.256399            0.395690\n",
      "      7                0.15003071         0.623936  3.078228         3.701039       0.734459  0.692829                  0.883060          0.845074      0.153982                 0.555270   207.822792       270.103894            0.532227\n",
      "      8                0.20001536         0.491977  2.501170         3.401187       0.596774  0.559245                  0.811516          0.773645      0.125020                 0.680290   150.117043       240.118696            0.630776\n",
      "      9                0.30002303         0.314214  1.665198         2.822524       0.397313  0.392526                  0.673448          0.646605      0.166533                 0.846822    66.519797       182.252396            0.718148\n",
      "     10                0.39999232         0.170616  0.936732         2.351212       0.223502  0.239097                  0.560994          0.544757      0.093644                 0.940467    -6.326822       135.121166            0.709841\n",
      "     11                0.50000000         0.079065  0.373262         1.955591       0.089060  0.120415                  0.466600          0.459882      0.037329                 0.977796   -62.673823        95.559131            0.627521\n",
      "     12                0.60000768         0.034589  0.148018         1.654310       0.035317  0.053477                  0.394715          0.392144      0.014803                 0.992599   -85.198240        65.430975            0.515616\n",
      "     13                0.69997697         0.016795  0.056333         1.426090       0.013441  0.024341                  0.340262          0.339615      0.005632                 0.998230   -94.366733        42.608991            0.391716\n",
      "     14                0.79998464         0.008388  0.012871         1.249421       0.003071  0.012230                  0.298109          0.298688      0.001287                 0.999517   -98.712890        24.942060            0.262060\n",
      "     15                0.89999232         0.003338  0.004827         1.111121       0.001152  0.005604                  0.265111          0.266120      0.000483                 1.000000   -99.517334        11.112059            0.131347\n",
      "     16                1.00000000         0.000649  0.000000         1.000000       0.000000  0.002027                  0.238598          0.239709      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.089660436\n",
      " RMSE: 0.29943353\n",
      " AUC: 0.9281132\n",
      " pr_auc: 0.83677137\n",
      " logloss: 0.2829778\n",
      " mean_per_class_error: 0.17283863\n",
      " default threshold: 0.38463228940963745\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4460   427  0.0874  427 / 4,887\n",
      "     1   420  1206  0.2583  420 / 1,626\n",
      "Totals  4880  1633  0.1300  847 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.12 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.993398  4.005535         4.005535       1.000000  0.994598                  1.000000          0.994598      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.990880  4.005535         4.005535       1.000000  0.992236                  1.000000          0.993426      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.985423  4.005535         4.005535       1.000000  0.988502                  1.000000          0.991793      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.974728  4.005535         4.005535       1.000000  0.980784                  1.000000          0.989051      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.959728  4.005535         4.005535       1.000000  0.967765                  1.000000          0.984807      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.778867  3.550919         3.778227       0.886503  0.869789                  0.943252          0.927298      0.177737                 0.378229   255.091911       277.822708            0.370658\n",
      "      7                0.15000768         0.627542  2.945609         3.501256       0.735385  0.702718                  0.874104          0.852591      0.146986                 0.525215   194.560886       250.125582            0.500046\n",
      "      8                0.20006142         0.496457  2.383662         3.221643       0.595092  0.562320                  0.804298          0.779968      0.119311                 0.644526   138.366197       222.164293            0.592347\n",
      "      9                0.30001535         0.310753  1.648976         2.697689       0.411674  0.392458                  0.673490          0.650864      0.164822                 0.809348    64.897603       169.768891            0.678798\n",
      "     10                0.39996929         0.170892  0.978310         2.268009       0.244240  0.238151                  0.566219          0.547725      0.097786                 0.907134    -2.168959       126.800929            0.675908\n",
      "     11                0.50007677         0.080239  0.552911         1.924674       0.138037  0.121356                  0.480504          0.462373      0.055351                 0.962485   -44.708872        92.467374            0.616260\n",
      "     12                0.60003071         0.034847  0.221504         1.640957       0.055300  0.054675                  0.409672          0.394458      0.022140                 0.984625   -77.849576        64.095743            0.512556\n",
      "     13                0.69998465         0.017268  0.129211         1.425088       0.032258  0.024377                  0.355780          0.341612      0.012915                 0.997540   -87.078919        42.508837            0.396558\n",
      "     14                0.79993858         0.008765  0.012306         1.248558       0.003072  0.012671                  0.311708          0.300510      0.001230                 0.998770   -98.769421        24.855834            0.264986\n",
      "     15                0.89989252         0.003504  0.012306         1.111244       0.003072  0.006004                  0.277427          0.267799      0.001230                 1.000000   -98.769421        11.124382            0.133415\n",
      "     16                1.00000000         0.000578  0.000000         1.000000       0.000000  0.002093                  0.249655          0.241200      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5140.379883          1.000000   0.276390\n",
      "                      capital_gain         3677.057129          0.715328   0.197709\n",
      "                               age         1623.645752          0.315861   0.087301\n",
      "                      capital_loss         1230.851318          0.239448   0.066181\n",
      "                    hours_per_week         1064.563721          0.207098   0.057240\n",
      "                            fnlwgt          916.502869          0.178295   0.049279\n",
      "     marital_status. Never-married          701.744324          0.136516   0.037732\n",
      "        occupation. Prof-specialty          517.801453          0.100732   0.027841\n",
      "       occupation. Exec-managerial          509.839447          0.099183   0.027413\n",
      "              education. Bachelors          353.132690          0.068698   0.018987\n",
      "---\n",
      "           marital_status. Widowed           10.492587          0.002041   0.000564\n",
      "                education. 1st-4th            9.139928          0.001778   0.000491\n",
      "      occupation. Transport-moving            8.922398          0.001736   0.000480\n",
      "       native_country. Puerto-Rico            7.210544          0.001403   0.000388\n",
      "                   education. 12th            6.019437          0.001171   0.000324\n",
      "                       race. Black            5.855782          0.001139   0.000315\n",
      "          race. Amer-Indian-Eskimo            4.917121          0.000957   0.000264\n",
      "         marital_status. Separated            4.826701          0.000939   0.000260\n",
      "                 native_country.NA            3.842378          0.000747   0.000207\n",
      "                      workclass.NA            0.116314          0.000023   0.000006\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        70093.140625          1.000000   0.158203\n",
      "                               age        51459.832031          0.734164   0.116147\n",
      "                    hours_per_week        37238.257813          0.531268   0.084048\n",
      "                      capital_loss        32951.050781          0.470104   0.074372\n",
      "marital_status. Married-civ-spouse        27259.904297          0.388910   0.061527\n",
      "                            fnlwgt        25953.978516          0.370278   0.058579\n",
      "       occupation. Exec-managerial        10450.723633          0.149098   0.023588\n",
      "        occupation. Prof-specialty        10412.668945          0.148555   0.023502\n",
      "              education. Bachelors         9865.682617          0.140751   0.022267\n",
      "     marital_status. Never-married         9470.791016          0.135117   0.021376\n",
      "---\n",
      "                         sex. Male         1114.210205          0.015896   0.002515\n",
      "           workclass. Self-emp-inc          949.441406          0.013545   0.002143\n",
      "                     occupation.NA          923.451233          0.013175   0.002084\n",
      "             relationship. Husband          614.373108          0.008765   0.001387\n",
      "          marital_status. Divorced          341.801178          0.004876   0.000771\n",
      "          occupation. Craft-repair          326.437469          0.004657   0.000737\n",
      "                       race. Black          222.742371          0.003178   0.000503\n",
      "          race. Asian-Pac-Islander          220.023010          0.003139   0.000497\n",
      "                 native_country.NA          145.587036          0.002077   0.000329\n",
      "                      workclass.NA           19.389284          0.000277   0.000044\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          362.000000          1.000000   0.238158\n",
      "                         age          308.000000          0.850829   0.202632\n",
      "              hours_per_week          162.000000          0.447514   0.106579\n",
      "                capital_gain           70.000000          0.193370   0.046053\n",
      "                capital_loss           61.000000          0.168508   0.040132\n",
      "          education. HS-grad           39.000000          0.107735   0.025658\n",
      "  occupation. Prof-specialty           38.000000          0.104972   0.025000\n",
      "          workclass. Private           33.000000          0.091160   0.021711\n",
      " occupation. Exec-managerial           32.000000          0.088398   0.021053\n",
      "        education. Bachelors           32.000000          0.088398   0.021053\n",
      "---\n",
      "occupation. Transport-moving            3.000000          0.008287   0.001974\n",
      "          education. 5th-6th            3.000000          0.008287   0.001974\n",
      "          education. 1st-4th            2.000000          0.005525   0.001316\n",
      " native_country. Philippines            2.000000          0.005525   0.001316\n",
      "             education. 12th            1.000000          0.002762   0.000658\n",
      "   marital_status. Separated            1.000000          0.002762   0.000658\n",
      "                workclass.NA            1.000000          0.002762   0.000658\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002762   0.000658\n",
      " native_country. Puerto-Rico            1.000000          0.002762   0.000658\n",
      "           native_country.NA            1.000000          0.002762   0.000658\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      " 2023-10-20 18:27:44  3.876 sec              25       0.28313          0.25490      0.94227         0.85560       4.19115                       0.12024         0.29943            0.28298        0.92811           0.83677         4.00554                         0.13005\n",
      "\n",
      "10-20 18:27:45.561 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_346\n",
      "10-20 18:27:45.603 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_346\n",
      "10-20 18:27:45.611 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.0790988\n",
      " RMSE: 0.28124508\n",
      " AUC: 0.9444471\n",
      " pr_auc: 0.8629444\n",
      " logloss: 0.25204107\n",
      " mean_per_class_error: 0.14607906\n",
      " default threshold: 0.3648239076137543\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17832  1913  0.0969  1,913 / 19,745\n",
      "     1   1231  5073  0.1953   1,231 / 6,304\n",
      "Totals  19063  6986  0.1207  3,144 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.21 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.991597  4.132138         4.132138       1.000000  0.993404                  1.000000          0.993404      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.988389  4.132138         4.132138       1.000000  0.990008                  1.000000          0.991709      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.984117  4.132138         4.132138       1.000000  0.986503                  1.000000          0.989972      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.974523  4.132138         4.132138       1.000000  0.979761                  1.000000          0.987424      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.959178  4.100474         4.125796       0.992337  0.967402                  0.998465          0.983414      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.779192  3.795728         3.960825       0.918587  0.866680                  0.958541          0.925069      0.189721                 0.396098   279.572768       296.082510            0.390628\n",
      "      7                0.15002495         0.644619  3.139537         3.686992       0.759785  0.711333                  0.892272          0.853806      0.157043                 0.553141   213.953718       268.699241            0.531819\n",
      "      8                0.20000768         0.507911  2.519906         3.395333       0.609831  0.574349                  0.821689          0.783968      0.125952                 0.679093   151.990617       239.533285            0.632043\n",
      "      9                0.30001152         0.316436  1.692511         2.827726       0.409597  0.401153                  0.684325          0.656363      0.169258                 0.848350    69.251117       182.772563            0.723407\n",
      "     10                0.40001536         0.167869  0.899394         2.345643       0.217658  0.235669                  0.567658          0.551190      0.089943                 0.938293   -10.060559       134.564282            0.710134\n",
      "     11                0.50001919         0.079268  0.417179         1.959950       0.100960  0.119675                  0.474319          0.464887      0.041720                 0.980013   -58.282058        95.995014            0.633241\n",
      "     12                0.59998464         0.034686  0.139642         1.656663       0.033794  0.053621                  0.400921          0.396364      0.013959                 0.993972   -86.035784        65.666253            0.519776\n",
      "     13                0.69998848         0.016641  0.039656         1.425649       0.009597  0.024346                  0.345015          0.343216      0.003966                 0.997938   -96.034416        42.564891            0.393076\n",
      "     14                0.79999232         0.007739  0.015862         1.249417       0.003839  0.011719                  0.302366          0.301777      0.001586                 0.999524   -98.413766        24.941713            0.263236\n",
      "     15                0.89999616         0.002586  0.004759         1.111116       0.001152  0.004847                  0.268896          0.268783      0.000476                 1.000000   -99.524130        11.111585            0.131932\n",
      "     16                1.00000000         0.000559  0.000000         1.000000       0.000000  0.001594                  0.242005          0.242063      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09338494\n",
      " RMSE: 0.3055895\n",
      " AUC: 0.91661894\n",
      " pr_auc: 0.8055236\n",
      " logloss: 0.2943257\n",
      " mean_per_class_error: 0.18342964\n",
      " default threshold: 0.37470611929893494\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4409   566  0.1138  566 / 4,975\n",
      "     1   389  1148  0.2531  389 / 1,537\n",
      "Totals  4798  1714  0.1467  955 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.991778  4.236825         4.236825       1.000000  0.993215                  1.000000          0.993215      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.988428  4.236825         4.236825       1.000000  0.990273                  1.000000          0.991755      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.982565  4.236825         4.236825       1.000000  0.985788                  1.000000          0.989776      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.971357  4.236825         4.236825       1.000000  0.976929                  1.000000          0.986577      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.951366  4.171643         4.223829       0.984615  0.962867                  0.996933          0.981849      0.041640                 0.211451  317.164306       322.382859            0.211250\n",
      "      6                0.10012285         0.761054  3.561012         3.892420       0.840491  0.849380                  0.918712          0.915615      0.178269                 0.389720  256.101241       289.242050            0.379067\n",
      "      7                0.15003071         0.624413  2.841932         3.542974       0.670769  0.692895                  0.836233          0.841527      0.141835                 0.531555  184.193184       254.297442            0.499394\n",
      "      8                0.20009214         0.496268  2.105416         3.183309       0.496933  0.558259                  0.751343          0.770655      0.105400                 0.636955  110.541610       218.330902            0.571829\n",
      "      9                0.30006143         0.321256  1.555455         2.640969       0.367127  0.399131                  0.623337          0.646877      0.155498                 0.792453   55.545495       164.096870            0.644513\n",
      "     10                0.40003071         0.173528  1.119407         2.260724       0.264209  0.245824                  0.533589          0.546652      0.111906                 0.904359   11.940691       126.072427            0.660138\n",
      "     11                0.50000000         0.080245  0.559703         1.920625       0.132104  0.122001                  0.453317          0.461748      0.055953                 0.960312  -44.029655        92.062459            0.602523\n",
      "     12                0.59996929         0.033819  0.182229         1.630966       0.043011  0.053693                  0.384950          0.393756      0.018217                 0.978530  -81.777097        63.096616            0.495515\n",
      "     13                0.69993857         0.016614  0.071590         1.408247       0.016897  0.024091                  0.332383          0.340959      0.007157                 0.985686  -92.841002        40.824701            0.374028\n",
      "     14                0.79990786         0.008323  0.110639         1.246077       0.026114  0.011951                  0.294106          0.299841      0.011061                 0.996747  -88.936095        24.607715            0.257651\n",
      "     15                0.89987715         0.002673  0.026033         1.110540       0.006144  0.005232                  0.262116          0.267112      0.002602                 0.999349  -97.396728        11.053979            0.130204\n",
      "     16                1.00000000         0.000748  0.006498         1.000000       0.001534  0.001667                  0.236026          0.240535      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6145.112305          1.000000   0.323434\n",
      "                      capital_gain         3582.177734          0.582931   0.188540\n",
      "                               age         1670.716797          0.271877   0.087934\n",
      "                      capital_loss         1241.783691          0.202077   0.065359\n",
      "                    hours_per_week          929.520447          0.151262   0.048923\n",
      "                            fnlwgt          869.040588          0.141420   0.045740\n",
      "        occupation. Prof-specialty          674.020813          0.109684   0.035476\n",
      "       occupation. Exec-managerial          590.912476          0.096160   0.031101\n",
      "              education. Bachelors          475.934784          0.077449   0.025050\n",
      "                education. Masters          247.289001          0.040242   0.013016\n",
      "---\n",
      "                education. 1st-4th            9.308963          0.001515   0.000490\n",
      "              education. Assoc-voc            9.097088          0.001480   0.000479\n",
      "           marital_status. Widowed            8.732368          0.001421   0.000460\n",
      "           relationship. Unmarried            8.210783          0.001336   0.000432\n",
      "                       race. Other            7.845816          0.001277   0.000413\n",
      "         marital_status. Separated            5.387891          0.000877   0.000284\n",
      "            native_country. Canada            4.955166          0.000806   0.000261\n",
      "             native_country. India            3.964354          0.000645   0.000209\n",
      "                 native_country.NA            3.566940          0.000580   0.000188\n",
      "          race. Asian-Pac-Islander            2.542979          0.000414   0.000134\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        59219.894531          1.000000   0.133414\n",
      "                               age        56215.734375          0.949271   0.126646\n",
      "                      capital_loss        37049.847656          0.625632   0.083468\n",
      "                    hours_per_week        33276.550781          0.561915   0.074968\n",
      "                            fnlwgt        30468.738281          0.514502   0.068642\n",
      "marital_status. Married-civ-spouse        29662.740234          0.500891   0.066826\n",
      "              education. Bachelors        11913.606445          0.201176   0.026840\n",
      "       occupation. Exec-managerial        10626.428711          0.179440   0.023940\n",
      "                education. Masters        10571.888672          0.178519   0.023817\n",
      "        occupation. Prof-specialty         9955.981445          0.168119   0.022429\n",
      "---\n",
      "                         sex. Male          924.599304          0.015613   0.002083\n",
      "          occupation. Craft-repair          901.999695          0.015231   0.002032\n",
      "              workclass. Local-gov          688.077148          0.011619   0.001550\n",
      "       native_country. Philippines          650.629272          0.010987   0.001466\n",
      "              workclass. State-gov          458.582214          0.007744   0.001033\n",
      "              education. Assoc-voc          383.520966          0.006476   0.000864\n",
      "                       race. White          335.235657          0.005661   0.000755\n",
      "          race. Asian-Pac-Islander          262.803955          0.004438   0.000592\n",
      "           marital_status. Widowed          248.945084          0.004204   0.000561\n",
      "                 native_country.NA           66.226852          0.001118   0.000149\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                        age          328.000000          1.000000   0.218521\n",
      "                     fnlwgt          326.000000          0.993902   0.217189\n",
      "             hours_per_week          144.000000          0.439024   0.095936\n",
      "               capital_gain           70.000000          0.213415   0.046636\n",
      "               capital_loss           55.000000          0.167683   0.036642\n",
      "                sex. Female           40.000000          0.121951   0.026649\n",
      "occupation. Exec-managerial           37.000000          0.112805   0.024650\n",
      "         education. HS-grad           36.000000          0.109756   0.023984\n",
      "       education. Bachelors           35.000000          0.106707   0.023318\n",
      " occupation. Prof-specialty           34.000000          0.103659   0.022652\n",
      "---\n",
      "         education. 5th-6th            3.000000          0.009146   0.001999\n",
      "  marital_status. Separated            2.000000          0.006098   0.001332\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.006098   0.001332\n",
      "native_country. Philippines            2.000000          0.006098   0.001332\n",
      "     native_country. Canada            1.000000          0.003049   0.000666\n",
      "                race. Other            1.000000          0.003049   0.000666\n",
      "   race. Asian-Pac-Islander            1.000000          0.003049   0.000666\n",
      "         education. 1st-4th            1.000000          0.003049   0.000666\n",
      "      native_country. India            1.000000          0.003049   0.000666\n",
      "          native_country.NA            1.000000          0.003049   0.000666\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      " 2023-10-20 18:27:43  3.142 sec              20       0.28407          0.25745      0.94233         0.85824       4.13214                       0.12166         0.30608            0.29567        0.91561           0.80478         4.23682                         0.14527\n",
      " 2023-10-20 18:27:44  4.063 sec              25       0.28125          0.25204      0.94445         0.86294       4.13214                       0.12070         0.30559            0.29433        0.91662           0.80552         4.23682                         0.14665\n",
      "\n",
      "10-20 18:27:45.629 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_348\n",
      "10-20 18:27:45.624 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_347\n",
      "10-20 18:27:45.654 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_347\n",
      "10-20 18:27:45.660 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_348\n",
      "10-20 18:27:45.669 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.096 (Wall: 20-Oct 18:27:45.669) \n",
      "10-20 18:27:45.660 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.08045045\n",
      " RMSE: 0.28363788\n",
      " AUC: 0.94188875\n",
      " pr_auc: 0.8579017\n",
      " logloss: 0.25604552\n",
      " mean_per_class_error: 0.15620399\n",
      " default threshold: 0.38924872875213623\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18052  1716  0.0868  1,716 / 19,768\n",
      "     1   1417  4864  0.2256   1,417 / 6,281\n",
      "Totals  19469  6580  0.1203  3,133 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.14 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.992970  4.147270         4.147270       1.000000  0.994304                  1.000000          0.994304      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.990345  4.147270         4.147270       1.000000  0.991669                  1.000000          0.992989      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.986648  4.147270         4.147270       1.000000  0.988795                  1.000000          0.991589      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.977602  4.147270         4.147270       1.000000  0.982370                  1.000000          0.989289      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.963167  4.115490         4.140904       0.992337  0.971128                  0.998465          0.985651      0.041235                 0.207133   311.548970       314.090382            0.207031\n",
      "      6                0.10000384         0.781613  3.819183         3.980105       0.920891  0.867653                  0.959693          0.926675      0.190893                 0.398026   281.918294       298.010513            0.392714\n",
      "      7                0.15002495         0.630013  3.125571         3.695187       0.753645  0.703350                  0.890993          0.852214      0.156345                 0.554370   212.557075       269.518745            0.532820\n",
      "      8                0.20000768         0.497180  2.420833         3.376721       0.583717  0.561596                  0.814203          0.779587      0.121000                 0.675370   142.083322       237.672119            0.626402\n",
      "      9                0.30001152         0.308581  1.647764         2.800402       0.397313  0.395628                  0.675240          0.651601      0.164783                 0.840153    64.776352       180.040197            0.711764\n",
      "     10                0.40001536         0.170885  0.971146         2.343088       0.234165  0.235488                  0.564971          0.547573      0.097118                 0.937271    -2.885435       134.308789            0.707961\n",
      "     11                0.50001919         0.080669  0.405971         1.955664       0.097889  0.121359                  0.471555          0.462330      0.040599                 0.977870   -59.402928        95.566446            0.629681\n",
      "     12                0.59998464         0.036931  0.136968         1.652645       0.033026  0.055843                  0.398490          0.394604      0.013692                 0.991562   -86.303180        65.264538            0.515995\n",
      "     13                0.69998848         0.017798  0.057314         1.424728       0.013820  0.026247                  0.343534          0.341979      0.005732                 0.997293   -94.268649        42.472833            0.391769\n",
      "     14                0.79999232         0.008596  0.022289         1.249415       0.005374  0.012748                  0.301262          0.300823      0.002229                 0.999522   -97.771141        24.941495            0.262928\n",
      "     15                0.89999616         0.003376  0.004776         1.111116       0.001152  0.005696                  0.267915          0.268030      0.000478                 1.000000   -99.522387        11.111585            0.131779\n",
      "     16                1.00000000         0.000697  0.000000         1.000000       0.000000  0.002100                  0.241122          0.241436      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09084645\n",
      " RMSE: 0.30140746\n",
      " AUC: 0.9249334\n",
      " pr_auc: 0.8175476\n",
      " logloss: 0.28473225\n",
      " mean_per_class_error: 0.16845822\n",
      " default threshold: 0.353325217962265\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4347   605  0.1222  605 / 4,952\n",
      "     1   335  1225  0.2147  335 / 1,560\n",
      "Totals  4682  1830  0.1443  940 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.41 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.992833  4.174359         4.174359       1.000000  0.994255                  1.000000          0.994255      0.042308                 0.042308  317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.990221  4.110138         4.142494       0.984615  0.991489                  0.992366          0.992883      0.041026                 0.083333  311.013807       314.249364            0.083131\n",
      "      3                0.03009828         0.986600  4.174359         4.153061       1.000000  0.988573                  0.994898          0.991454      0.041667                 0.125000  317.435897       315.306122            0.124798\n",
      "      4                0.04007985         0.977270  4.110138         4.142372       0.984615  0.982328                  0.992337          0.989181      0.041026                 0.166026  311.013807       314.237155            0.165622\n",
      "      5                0.05006143         0.965814  4.174359         4.148749       1.000000  0.971948                  0.993865          0.985745      0.041667                 0.207692  317.435897       314.874941            0.207288\n",
      "      6                0.10012285         0.788254  3.508510         3.828630       0.840491  0.873859                  0.917178          0.929802      0.175641                 0.383333  250.851030       282.862986            0.372429\n",
      "      7                0.15003071         0.644395  2.812876         3.490738       0.673846  0.712115                  0.836233          0.857388      0.140385                 0.523718  181.287574       249.073826            0.491408\n",
      "      8                0.20009214         0.520067  2.394494         3.216467       0.573620  0.579914                  0.770530          0.787967      0.119872                 0.643590  139.449426       221.646693            0.583210\n",
      "      9                0.30006143         0.316977  1.680003         2.704574       0.402458  0.411122                  0.647902          0.662416      0.167949                 0.811538   68.000315       170.457444            0.672605\n",
      "     10                0.40018428         0.168449  0.998773         2.277797       0.239264  0.235288                  0.545664          0.555552      0.100000                 0.911538   -0.122699       127.779680            0.672443\n",
      "     11                0.50000000         0.079011  0.533034         1.929487       0.127692  0.119314                  0.462224          0.468465      0.053205                 0.964744  -46.696647        92.948718            0.611149\n",
      "     12                0.59996929         0.034778  0.243665         1.648589       0.058372  0.053712                  0.394932          0.399357      0.024359                 0.989103  -75.633542        64.858866            0.511720\n",
      "     13                0.69993857         0.017338  0.076947         1.424118       0.018433  0.024882                  0.341158          0.345872      0.007692                 0.996795  -92.305329        42.411764            0.390373\n",
      "     14                0.79990786         0.008576  0.012824         1.247740       0.003072  0.012550                  0.298906          0.304215      0.001282                 0.998077  -98.717555        24.773986            0.260597\n",
      "     15                0.89987715         0.003474  0.012824         1.110550       0.003072  0.005617                  0.266041          0.271043      0.001282                 0.999359  -98.717555        11.055045            0.130821\n",
      "     16                1.00000000         0.000805  0.006402         1.000000       0.001534  0.002176                  0.239558          0.244123      0.000641                 1.000000  -99.359761         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5972.958496          1.000000   0.323004\n",
      "                      capital_gain         3641.510010          0.609666   0.196924\n",
      "                               age         1649.587158          0.276176   0.089206\n",
      "                      capital_loss         1218.813721          0.204055   0.065911\n",
      "                    hours_per_week          859.416870          0.143885   0.046475\n",
      "                            fnlwgt          635.676270          0.106426   0.034376\n",
      "        occupation. Prof-specialty          624.667358          0.104583   0.033781\n",
      "       occupation. Exec-managerial          568.919983          0.095249   0.030766\n",
      "              education. Bachelors          450.753937          0.075466   0.024376\n",
      "                education. HS-grad          205.942215          0.034479   0.011137\n",
      "---\n",
      "              education. Assoc-voc           12.498524          0.002093   0.000676\n",
      "          race. Asian-Pac-Islander           11.052107          0.001850   0.000598\n",
      "       native_country. Philippines            9.389676          0.001572   0.000508\n",
      "                      workclass.NA            8.126078          0.001360   0.000439\n",
      "      occupation. Transport-moving            6.968823          0.001167   0.000377\n",
      "                education. 1st-4th            6.290231          0.001053   0.000340\n",
      "                 native_country.NA            2.794869          0.000468   0.000151\n",
      "             education. Assoc-acdm            2.577040          0.000431   0.000139\n",
      "         marital_status. Separated            2.485362          0.000416   0.000134\n",
      "                     occupation.NA            2.456347          0.000411   0.000133\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        69508.421875          1.000000   0.157273\n",
      "                               age        54947.105469          0.790510   0.124326\n",
      "                      capital_loss        40120.109375          0.577198   0.090778\n",
      "marital_status. Married-civ-spouse        29429.130859          0.423389   0.066588\n",
      "                    hours_per_week        28150.181641          0.404990   0.063694\n",
      "                            fnlwgt        22989.707031          0.330747   0.052018\n",
      "        occupation. Prof-specialty        11475.734375          0.165098   0.025966\n",
      "              education. Bachelors        10259.274414          0.147598   0.023213\n",
      "       occupation. Exec-managerial        10237.769531          0.147288   0.023165\n",
      "       occupation. Protective-serv         8224.522461          0.118324   0.018609\n",
      "---\n",
      "       relationship. Not-in-family          890.271057          0.012808   0.002014\n",
      "          race. Asian-Pac-Islander          551.065125          0.007928   0.001247\n",
      "                      workclass.NA          465.188629          0.006693   0.001053\n",
      "              education. Assoc-voc          433.497559          0.006237   0.000981\n",
      "              workclass. Local-gov          317.564728          0.004569   0.000719\n",
      "          marital_status. Divorced          317.167572          0.004563   0.000718\n",
      "      occupation. Transport-moving          264.611694          0.003807   0.000599\n",
      "         marital_status. Separated          141.130630          0.002030   0.000319\n",
      "             education. Assoc-acdm          139.246597          0.002003   0.000315\n",
      "                     occupation.NA          111.825424          0.001609   0.000253\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                         age          317.000000          1.000000   0.227077\n",
      "                      fnlwgt          247.000000          0.779180   0.176934\n",
      "              hours_per_week          129.000000          0.406940   0.092407\n",
      "                capital_gain           80.000000          0.252366   0.057307\n",
      "                capital_loss           54.000000          0.170347   0.038682\n",
      "        education. Bachelors           41.000000          0.129338   0.029370\n",
      "          education. HS-grad           35.000000          0.110410   0.025072\n",
      "  occupation. Prof-specialty           34.000000          0.107256   0.024355\n",
      " occupation. Exec-managerial           32.000000          0.100946   0.022923\n",
      "                 sex. Female           32.000000          0.100946   0.022923\n",
      "---\n",
      "    race. Amer-Indian-Eskimo            3.000000          0.009464   0.002149\n",
      "occupation. Transport-moving            3.000000          0.009464   0.002149\n",
      "             education. 12th            2.000000          0.006309   0.001433\n",
      "               occupation.NA            2.000000          0.006309   0.001433\n",
      " native_country. Philippines            2.000000          0.006309   0.001433\n",
      "   marital_status. Separated            1.000000          0.003155   0.000716\n",
      "                workclass.NA            1.000000          0.003155   0.000716\n",
      "          education. 1st-4th            1.000000          0.003155   0.000716\n",
      "       education. Assoc-acdm            1.000000          0.003155   0.000716\n",
      "           native_country.NA            1.000000          0.003155   0.000716\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      " 2023-10-20 18:27:44  3.317 sec              20       0.28638          0.26140      0.93955         0.85327       4.14727                       0.12480         0.30182            0.28613        0.92423           0.81631         4.17436                         0.14850\n",
      " 2023-10-20 18:27:44  4.080 sec              25       0.28364          0.25605      0.94189         0.85790       4.14727                       0.12027         0.30141            0.28473        0.92493           0.81755         4.17436                         0.14435\n",
      "\n",
      "10-20 18:27:45.693 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.060 (Wall: 20-Oct 18:27:45.692) \n",
      "10-20 18:27:45.676 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.08068106\n",
      " RMSE: 0.28404412\n",
      " AUC: 0.9416815\n",
      " pr_auc: 0.85767496\n",
      " logloss: 0.25688982\n",
      " mean_per_class_error: 0.15329283\n",
      " default threshold: 0.391923725605011\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17987  1751  0.0887  1,751 / 19,738\n",
      "     1   1375  4936  0.2179   1,375 / 6,311\n",
      "Totals  19362  6687  0.1200  3,126 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.25 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.992568  4.127555         4.127555       1.000000  0.994256                  1.000000          0.994256      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02007755         0.989989  4.127555         4.127555       1.000000  0.991327                  1.000000          0.992789      0.041515                 0.082871  312.755506       312.755506            0.082871\n",
      "      3                0.03002035         0.985119  4.127555         4.127555       1.000000  0.987860                  1.000000          0.991157      0.041039                 0.123911  312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.975363  4.127555         4.127555       1.000000  0.980883                  1.000000          0.988593      0.041198                 0.165109  312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.956010  4.095926         4.121220       0.992337  0.966968                  0.998465          0.984261      0.041039                 0.206148  309.592629       312.121960            0.206047\n",
      "      6                0.10000384         0.778442  3.766156         3.943756       0.912442  0.865706                  0.955470          0.925006      0.188243                 0.394391  276.615623       294.375607            0.388514\n",
      "      7                0.15002495         0.642119  3.139223         3.675510       0.760553  0.709636                  0.890481          0.853198      0.157027                 0.551418  213.922261       267.550963            0.529734\n",
      "      8                0.20000768         0.509861  2.475899         3.375722       0.599846  0.574118                  0.817850          0.783455      0.123752                 0.675170  147.589900       237.572210            0.627090\n",
      "      9                0.30001152         0.313885  1.651022         2.800822       0.400000  0.406241                  0.678567          0.657717      0.165109                 0.840279   65.102203       180.082207            0.713012\n",
      "     10                0.40001536         0.165241  0.966529         2.342249       0.234165  0.234809                  0.567466          0.551990      0.096657                 0.936936   -3.347079       134.224886            0.708594\n",
      "     11                0.50001919         0.078779  0.405625         1.954924       0.098273  0.118327                  0.473628          0.465257      0.040564                 0.977500  -59.437463        95.492416            0.630149\n",
      "     12                0.59998464         0.034840  0.144243         1.653240       0.034946  0.054498                  0.400537          0.396819      0.014419                 0.991919  -85.575748        65.324043            0.517251\n",
      "     13                0.69998848         0.016926  0.057041         1.425199       0.013820  0.024717                  0.345289          0.343659      0.005704                 0.997623  -94.295893        42.519944            0.392800\n",
      "     14                0.79999232         0.008060  0.019014         1.249418       0.004607  0.012035                  0.302702          0.302204      0.001901                 0.999525  -98.098631        24.941779            0.263330\n",
      "     15                0.89999616         0.003018  0.003169         1.110940       0.000768  0.005319                  0.269152          0.269215      0.000317                 0.999842  -99.683105        11.093979            0.131770\n",
      "     16                1.00000000         0.000747  0.001584         1.000000       0.000384  0.001879                  0.242274          0.242481      0.000158                 1.000000  -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.08828706\n",
      " RMSE: 0.2971314\n",
      " AUC: 0.92592406\n",
      " pr_auc: 0.82214\n",
      " logloss: 0.27902997\n",
      " mean_per_class_error: 0.16979925\n",
      " default threshold: 0.3423572778701782\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4407   575  0.1154  575 / 4,982\n",
      "     1   343  1187  0.2242  343 / 1,530\n",
      "Totals  4750  1762  0.1410  918 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.56 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.992263  4.256209         4.256209       1.000000  0.994154                  1.000000          0.994154      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.989205  4.256209         4.256209       1.000000  0.990689                  1.000000          0.992435      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.984645  4.190729         4.234494       0.984615  0.987289                  0.994898          0.990728      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.976163  4.256209         4.239902       1.000000  0.981223                  0.996169          0.988361      0.042484                 0.169935   325.620915       323.990184            0.169734\n",
      "      5                0.05006143         0.957744  4.125249         4.217042       0.969231  0.966626                  0.990798          0.984027      0.041176                 0.211111   312.524887       321.704158            0.210509\n",
      "      6                0.10012285         0.771630  3.786198         4.001620       0.889571  0.859819                  0.940184          0.921923      0.189542                 0.400654   278.619832       300.161995            0.392825\n",
      "      7                0.15003071         0.621653  2.828742         3.611461       0.664615  0.690421                  0.848516          0.844913      0.141176                 0.541830   182.874208       261.146099            0.512123\n",
      "      8                0.20009214         0.478136  2.297831         3.282801       0.539877  0.551121                  0.771297          0.771409      0.115033                 0.656863   129.783071       228.280138            0.597047\n",
      "      9                0.30006143         0.292510  1.477578         2.681368       0.347158  0.380338                  0.629990          0.641119      0.147712                 0.804575    47.757798       168.136820            0.659453\n",
      "     10                0.40003071         0.159369  1.059149         2.275969       0.248848  0.221737                  0.534741          0.536313      0.105882                 0.910458     5.914882       127.596904            0.667182\n",
      "     11                0.50000000         0.076343  0.555726         1.932026       0.130568  0.116381                  0.453931          0.452353      0.055556                 0.966013   -44.427377        93.202614            0.609128\n",
      "     12                0.59996929         0.033574  0.235366         1.649322       0.055300  0.052192                  0.387510          0.385676      0.023529                 0.989542   -76.463360        64.932190            0.509213\n",
      "     13                0.69993857         0.016135  0.052304         1.421226       0.012289  0.023363                  0.333918          0.333929      0.005229                 0.994771   -94.769635        42.122649            0.385377\n",
      "     14                0.79990786         0.007992  0.032690         1.247693       0.007680  0.011696                  0.293146          0.293657      0.003268                 0.998039   -96.731022        24.769272            0.258979\n",
      "     15                0.89987715         0.002813  0.019614         1.111263       0.004608  0.005168                  0.261092          0.261609      0.001961                 1.000000   -98.038613        11.126280            0.130871\n",
      "     16                1.00000000         0.000755  0.000000         1.000000       0.000000  0.001762                  0.234951          0.235592      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6113.553223          1.000000   0.326458\n",
      "                      capital_gain         3570.720703          0.584066   0.190673\n",
      "                               age         1679.789429          0.274765   0.089699\n",
      "                      capital_loss         1217.816650          0.199199   0.065030\n",
      "                    hours_per_week          983.609802          0.160890   0.052524\n",
      "                            fnlwgt          832.837280          0.136228   0.044473\n",
      "       occupation. Exec-managerial          611.602661          0.100040   0.032659\n",
      "        occupation. Prof-specialty          603.449097          0.098707   0.032224\n",
      "              education. Bachelors          451.382446          0.073833   0.024103\n",
      "                education. Masters          238.482483          0.039009   0.012735\n",
      "---\n",
      "              education. Assoc-voc           14.747139          0.002412   0.000787\n",
      "      relationship. Other-relative           14.572704          0.002384   0.000778\n",
      "          marital_status. Divorced           14.106035          0.002307   0.000753\n",
      "         marital_status. Separated            9.593512          0.001569   0.000512\n",
      "              workclass. State-gov            9.267618          0.001516   0.000495\n",
      "           marital_status. Widowed            6.365030          0.001041   0.000340\n",
      "                   education. 12th            5.532626          0.000905   0.000295\n",
      "           native_country. Germany            4.615104          0.000755   0.000246\n",
      "                     occupation.NA            4.040448          0.000661   0.000216\n",
      "                 native_country.NA            3.018235          0.000494   0.000161\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        60559.117188          1.000000   0.137306\n",
      "                               age        52104.894531          0.860397   0.118138\n",
      "                      capital_loss        36473.878906          0.602286   0.082697\n",
      "marital_status. Married-civ-spouse        31604.212891          0.521874   0.071656\n",
      "                    hours_per_week        31364.160156          0.517910   0.071112\n",
      "                            fnlwgt        31005.718750          0.511991   0.070299\n",
      "              education. Bachelors        13116.716797          0.216594   0.029740\n",
      "       occupation. Exec-managerial        11096.305664          0.183231   0.025159\n",
      "                education. Masters        10263.166016          0.169474   0.023270\n",
      "            education. Prof-school        10194.746094          0.168344   0.023115\n",
      "---\n",
      "      occupation. Transport-moving         1051.445557          0.017362   0.002384\n",
      "              workclass. Local-gov         1040.417725          0.017180   0.002359\n",
      "                         sex. Male          838.006348          0.013838   0.001900\n",
      "                       race. Black          810.023865          0.013376   0.001837\n",
      "          marital_status. Divorced          527.153625          0.008705   0.001195\n",
      "          occupation. Craft-repair          493.362793          0.008147   0.001119\n",
      "             relationship. Husband          392.501831          0.006481   0.000890\n",
      "              workclass. State-gov          261.739502          0.004322   0.000593\n",
      "                 native_country.NA          202.733505          0.003348   0.000460\n",
      "                     occupation.NA          136.200623          0.002249   0.000309\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                         age          352.000000          1.000000   0.229018\n",
      "                      fnlwgt          306.000000          0.869318   0.199089\n",
      "              hours_per_week          140.000000          0.397727   0.091087\n",
      "                capital_gain           77.000000          0.218750   0.050098\n",
      "                capital_loss           55.000000          0.156250   0.035784\n",
      "          workclass. Private           45.000000          0.127841   0.029278\n",
      "  occupation. Prof-specialty           39.000000          0.110795   0.025374\n",
      "        education. Bachelors           39.000000          0.110795   0.025374\n",
      "          education. HS-grad           36.000000          0.102273   0.023422\n",
      " occupation. Exec-managerial           31.000000          0.088068   0.020169\n",
      "---\n",
      "relationship. Other-relative            3.000000          0.008523   0.001952\n",
      "        workclass. State-gov            3.000000          0.008523   0.001952\n",
      "     workclass. Self-emp-inc            3.000000          0.008523   0.001952\n",
      "               occupation.NA            2.000000          0.005682   0.001301\n",
      "   marital_status. Separated            2.000000          0.005682   0.001301\n",
      "          education. 5th-6th            2.000000          0.005682   0.001301\n",
      "     marital_status. Widowed            1.000000          0.002841   0.000651\n",
      "             education. 12th            1.000000          0.002841   0.000651\n",
      "     native_country. Germany            1.000000          0.002841   0.000651\n",
      "           native_country.NA            1.000000          0.002841   0.000651\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      " 2023-10-20 18:27:45  4.269 sec              25       0.28404          0.25689      0.94168         0.85767       4.12756                       0.12000         0.29713            0.27903        0.92592           0.82214         4.25621                         0.14097\n",
      "\n",
      "10-20 18:27:45.738 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:45.737) \n",
      "10-20 18:27:45.744 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:45.744) \n",
      "10-20 18:27:45.749 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:45.749) \n",
      "█10-20 18:27:45.783 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:45.783) \n",
      "10-20 18:27:45.806 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:45.806) \n",
      "10-20 18:27:45.812 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.077 (Wall: 20-Oct 18:27:45.811) \n",
      "10-20 18:27:45.826 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:45.826) \n",
      "10-20 18:27:45.826 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:45.826) \n",
      "10-20 18:27:45.858 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:45.858) \n",
      "10-20 18:27:45.874 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:45.874) \n",
      "10-20 18:27:45.876 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:45.876) \n",
      "10-20 18:27:45.895 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:45.895) \n",
      "10-20 18:27:45.913 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:45.923 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:45.923) \n",
      "10-20 18:27:46.005 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.147 (Wall: 20-Oct 18:27:46.005) \n",
      "10-20 18:27:46.009 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.133 (Wall: 20-Oct 18:27:46.009) \n",
      "10-20 18:27:46.010 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.115 (Wall: 20-Oct 18:27:46.010) \n",
      "10-20 18:27:46.070 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:46.070) \n",
      "10-20 18:27:46.096 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_349\n",
      "10-20 18:27:46.114 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:46.114) \n",
      "10-20 18:27:46.116 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_349\n",
      "10-20 18:27:46.178 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_350\n",
      "10-20 18:27:46.194 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_351\n",
      "10-20 18:27:46.214 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_351\n",
      "10-20 18:27:46.221 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_350\n",
      "10-20 18:27:46.270 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_352\n",
      "10-20 18:27:46.288 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_352\n",
      "10-20 18:27:46.367 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_353\n",
      "10-20 18:27:46.382 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_353\n",
      "10-20 18:27:46.390 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.078588635\n",
      " RMSE: 0.28033665\n",
      " AUC: 0.94470775\n",
      " pr_auc: 0.86380523\n",
      " logloss: 0.25028184\n",
      " mean_per_class_error: 0.1564067\n",
      " default threshold: 0.4115675687789917\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18258  1510  0.0764  1,510 / 19,768\n",
      "     1   1485  4796  0.2364   1,485 / 6,281\n",
      "Totals  19743  6306  0.1150  2,995 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.18 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995127  4.147270         4.147270       1.000000  0.996280                  1.000000          0.996280      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.993308  4.147270         4.147270       1.000000  0.994250                  1.000000          0.995267      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.989932  4.147270         4.147270       1.000000  0.991752                  1.000000          0.994094      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.982200  4.147270         4.147270       1.000000  0.986599                  1.000000          0.992224      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.968603  4.131380         4.144087       0.996169  0.976118                  0.999233          0.988997      0.041395                 0.207292   313.137962       314.408668            0.207241\n",
      "      6                0.10000384         0.791620  3.838295         3.991249       0.925499  0.876711                  0.962380          0.932876      0.191848                 0.399140   283.829478       299.124942            0.394183\n",
      "      7                0.15002495         0.640843  3.189228         3.723841       0.768995  0.712821                  0.897902          0.859505      0.159529                 0.558669   218.922800       272.384054            0.538485\n",
      "      8                0.20000768         0.502644  2.474983         3.411746       0.596774  0.570268                  0.822649          0.787224      0.123706                 0.682375   147.498344       241.174612            0.635633\n",
      "      9                0.30001152         0.307158  1.681196         2.834896       0.405374  0.399213                  0.683557          0.657887      0.168126                 0.850502    68.119641       183.489621            0.725400\n",
      "     10                0.40001536         0.165600  0.904280         2.352242       0.218042  0.232418                  0.567179          0.551520      0.090431                 0.940933    -9.572011       135.224213            0.712786\n",
      "     11                0.50001919         0.077307  0.386866         1.959167       0.093282  0.117426                  0.472399          0.464701      0.038688                 0.979621   -61.313378        95.916695            0.631989\n",
      "     12                0.59998464         0.034797  0.136968         1.655564       0.033026  0.053322                  0.399194          0.396160      0.013692                 0.993313   -86.303180        65.556432            0.518303\n",
      "     13                0.69998848         0.016150  0.044577         1.425411       0.010749  0.024088                  0.343699          0.343004      0.004458                 0.997771   -95.542282        42.541067            0.392399\n",
      "     14                0.79999232         0.007326  0.017512         1.249415       0.004223  0.011258                  0.301262          0.301534      0.001751                 0.999522   -98.248754        24.941495            0.262928\n",
      "     15                0.89999616         0.002381  0.004776         1.111116       0.001152  0.004611                  0.267915          0.268541      0.000478                 1.000000   -99.522387        11.111585            0.131779\n",
      "     16                1.00000000         0.000229  0.000000         1.000000       0.000000  0.001314                  0.241122          0.241817      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09141384\n",
      " RMSE: 0.3023472\n",
      " AUC: 0.9242314\n",
      " pr_auc: 0.8162416\n",
      " logloss: 0.28595966\n",
      " mean_per_class_error: 0.1687834\n",
      " default threshold: 0.36076825857162476\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4366   586  0.1183  586 / 4,952\n",
      "     1   342  1218  0.2192  342 / 1,560\n",
      "Totals  4708  1804  0.1425  928 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.46 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995018  4.174359         4.174359       1.000000  0.996221                  1.000000          0.996221      0.042308                 0.042308   317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.993313  4.174359         4.174359       1.000000  0.994127                  1.000000          0.995182      0.041667                 0.083974   317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.989715  4.110138         4.153061       0.984615  0.991834                  0.994898          0.994072      0.041026                 0.125000   311.013807       315.306122            0.124798\n",
      "      4                0.04007985         0.981654  4.174359         4.158365       1.000000  0.986343                  0.996169          0.992147      0.041667                 0.166667   317.435897       315.836526            0.166465\n",
      "      5                0.05006143         0.971364  4.110138         4.148749       0.984615  0.977057                  0.993865          0.989138      0.041026                 0.207692   311.013807       314.874941            0.207288\n",
      "      6                0.10012285         0.799044  3.508510         3.828630       0.840491  0.882438                  0.917178          0.935788      0.175641                 0.383333   250.851030       282.862986            0.372429\n",
      "      7                0.15018428         0.656086  2.817052         3.491437       0.674847  0.722188                  0.836401          0.864588      0.141026                 0.524359   181.705207       249.143726            0.492049\n",
      "      8                0.20009214         0.526674  2.286264         3.190838       0.547692  0.589260                  0.764390          0.795915      0.114103                 0.638462   128.626430       219.083771            0.576466\n",
      "      9                0.30036855         0.317010  1.694035         2.691138       0.405819  0.414839                  0.644683          0.668695      0.169872                 0.808333    69.403542       169.113838            0.667986\n",
      "     10                0.40003071         0.162476  1.048414         2.281876       0.251156  0.232394                  0.546641          0.559996      0.104487                 0.912821     4.841373       128.187608            0.674331\n",
      "     11                0.50000000         0.076512  0.500154         1.925641       0.119816  0.115106                  0.461302          0.471046      0.050000                 0.962821   -49.984639        92.564103            0.608620\n",
      "     12                0.59996929         0.032374  0.243665         1.645383       0.058372  0.051156                  0.394164          0.401082      0.024359                 0.987179   -75.633542        64.538337            0.509191\n",
      "     13                0.69993857         0.015908  0.096183         1.424118       0.023041  0.023048                  0.341158          0.347089      0.009615                 0.996795   -90.381661        42.411764            0.390373\n",
      "     14                0.79990786         0.007333  0.012824         1.247740       0.003072  0.011182                  0.298906          0.305109      0.001282                 0.998077   -98.717555        24.773986            0.260597\n",
      "     15                0.89987715         0.002418  0.019237         1.111263       0.004608  0.004528                  0.266212          0.271717      0.001923                 1.000000   -98.076332        11.126280            0.131664\n",
      "     16                1.00000000         0.000265  0.000000         1.000000       0.000000  0.001368                  0.239558          0.244648      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5981.091797          1.000000   0.312261\n",
      "                      capital_gain         3669.097168          0.613449   0.191556\n",
      "                               age         1711.595825          0.286168   0.089359\n",
      "                      capital_loss         1253.092529          0.209509   0.065421\n",
      "                            fnlwgt          914.058655          0.152825   0.047721\n",
      "                    hours_per_week          910.890686          0.152295   0.047556\n",
      "        occupation. Prof-specialty          630.351135          0.105391   0.032909\n",
      "       occupation. Exec-managerial          572.197693          0.095668   0.029873\n",
      "              education. Bachelors          465.869873          0.077890   0.024322\n",
      "                education. HS-grad          218.114014          0.036467   0.011387\n",
      "---\n",
      "              education. Assoc-voc           12.498524          0.002090   0.000653\n",
      "                education. 1st-4th            9.983876          0.001669   0.000521\n",
      "       native_country. Philippines            9.389676          0.001570   0.000490\n",
      "                      workclass.NA            8.126078          0.001359   0.000424\n",
      "                 native_country.NA            7.530886          0.001259   0.000393\n",
      "      occupation. Transport-moving            6.968823          0.001165   0.000364\n",
      "         marital_status. Separated            5.486547          0.000917   0.000286\n",
      "           native_country. Germany            5.189872          0.000868   0.000271\n",
      "             education. Assoc-acdm            2.577040          0.000431   0.000135\n",
      "                     occupation.NA            2.456347          0.000411   0.000128\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        75827.789063          1.000000   0.148865\n",
      "                               age        59830.613281          0.789033   0.117460\n",
      "                      capital_loss        49076.714844          0.647213   0.096348\n",
      "                            fnlwgt        43722.929688          0.576608   0.085837\n",
      "                    hours_per_week        31568.562500          0.416319   0.061976\n",
      "marital_status. Married-civ-spouse        29573.734375          0.390012   0.058059\n",
      "        occupation. Prof-specialty        11689.773438          0.154162   0.022949\n",
      "       occupation. Exec-managerial        11001.474609          0.145085   0.021598\n",
      "              education. Bachelors        10457.389648          0.137910   0.020530\n",
      "            education. Prof-school         9297.812500          0.122617   0.018253\n",
      "---\n",
      "         marital_status. Separated         1120.864624          0.014782   0.002200\n",
      "       relationship. Not-in-family         1008.071594          0.013294   0.001979\n",
      "          race. Asian-Pac-Islander          844.689331          0.011140   0.001658\n",
      "              workclass. Local-gov          712.779663          0.009400   0.001399\n",
      "                      workclass.NA          465.188629          0.006135   0.000913\n",
      "              education. Assoc-voc          433.497559          0.005717   0.000851\n",
      "          marital_status. Divorced          317.167572          0.004183   0.000623\n",
      "      occupation. Transport-moving          264.611694          0.003490   0.000519\n",
      "             education. Assoc-acdm          139.246597          0.001836   0.000273\n",
      "                     occupation.NA          111.825424          0.001475   0.000220\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          347.000000          1.000000   0.213014\n",
      "                         age          342.000000          0.985591   0.209945\n",
      "              hours_per_week          147.000000          0.423631   0.090239\n",
      "                capital_gain           86.000000          0.247839   0.052793\n",
      "                capital_loss           62.000000          0.178674   0.038060\n",
      "        education. Bachelors           47.000000          0.135447   0.028852\n",
      "          education. HS-grad           42.000000          0.121037   0.025783\n",
      "  occupation. Prof-specialty           36.000000          0.103746   0.022099\n",
      "          workclass. Private           36.000000          0.103746   0.022099\n",
      "                 sex. Female           34.000000          0.097983   0.020872\n",
      "---\n",
      "    race. Amer-Indian-Eskimo            3.000000          0.008646   0.001842\n",
      "occupation. Transport-moving            3.000000          0.008646   0.001842\n",
      "               occupation.NA            2.000000          0.005764   0.001228\n",
      "   marital_status. Separated            2.000000          0.005764   0.001228\n",
      "          education. 1st-4th            2.000000          0.005764   0.001228\n",
      " native_country. Philippines            2.000000          0.005764   0.001228\n",
      "           native_country.NA            2.000000          0.005764   0.001228\n",
      "                workclass.NA            1.000000          0.002882   0.000614\n",
      "     native_country. Germany            1.000000          0.002882   0.000614\n",
      "       education. Assoc-acdm            1.000000          0.002882   0.000614\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      " 2023-10-20 18:27:44  3.317 sec              20       0.28638          0.26140      0.93955         0.85327       4.14727                       0.12480         0.30182            0.28613        0.92423           0.81631         4.17436                         0.14850\n",
      " 2023-10-20 18:27:44  4.080 sec              25       0.28364          0.25605      0.94189         0.85790       4.14727                       0.12027         0.30141            0.28473        0.92493           0.81755         4.17436                         0.14435\n",
      " 2023-10-20 18:27:45  5.076 sec              30       0.28034          0.25028      0.94471         0.86381       4.14727                       0.11498         0.30235            0.28596        0.92423           0.81624         4.17436                         0.14251\n",
      "\n",
      "10-20 18:27:46.407 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3127398197190701, 0.2921560961432877, 0.28698529513624127, 0.28560762562574765]\n",
      "10-20 18:27:46.408 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.3127398197190701 --> 0.28560762562574765 (still improving).\n",
      "10-20 18:27:46.446 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_354\n",
      "10-20 18:27:46.454 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_354\n",
      "10-20 18:27:46.464 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:46.464) \n",
      "10-20 18:27:46.466 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07691983\n",
      " RMSE: 0.27734426\n",
      " AUC: 0.9474925\n",
      " pr_auc: 0.8697221\n",
      " logloss: 0.2454232\n",
      " mean_per_class_error: 0.14242443\n",
      " default threshold: 0.3721690773963928\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17945  1800  0.0912  1,800 / 19,745\n",
      "     1   1221  5083  0.1937   1,221 / 6,304\n",
      "Totals  19166  6883  0.1160  3,021 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.994710  4.132138         4.132138       1.000000  0.996085                  1.000000          0.996085      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.992430  4.132138         4.132138       1.000000  0.993598                  1.000000          0.994844      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.988735  4.132138         4.132138       1.000000  0.990727                  1.000000          0.993470      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.980825  4.132138         4.132138       1.000000  0.985213                  1.000000          0.991409      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.964678  4.100474         4.125796       0.992337  0.973151                  0.998465          0.987752      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.797161  3.830638         3.978274       0.927035  0.882946                  0.962764          0.935369      0.191466                 0.397843   283.063822       297.827367            0.392930\n",
      "      7                0.15002495         0.651805  3.209305         3.721885       0.776669  0.723136                  0.900716          0.864606      0.160533                 0.558376   220.930467       272.188508            0.538725\n",
      "      8                0.20000768         0.509971  2.557990         3.431023       0.619048  0.580498                  0.830326          0.793607      0.127855                 0.686231   155.799039       243.102311            0.641460\n",
      "      9                0.30001152         0.309680  1.678235         2.846760       0.406142  0.400802                  0.688932          0.662672      0.167830                 0.854061    67.823507       184.676043            0.730941\n",
      "     10                0.40001536         0.162048  0.891463         2.357936       0.215739  0.230209                  0.570633          0.554556      0.089150                 0.943211   -10.853676       135.793613            0.716622\n",
      "     11                0.50001919         0.076004  0.372765         1.960902       0.090211  0.115133                  0.474549          0.466671      0.037278                 0.980489   -62.723512        96.090188            0.633869\n",
      "     12                0.59998464         0.032382  0.144403         1.658249       0.034946  0.050995                  0.401305          0.397414      0.014435                 0.994924   -85.559732        65.824887            0.521032\n",
      "     13                0.69998848         0.015118  0.036483         1.426555       0.008829  0.022662                  0.345234          0.343875      0.003648                 0.998572   -96.351663        42.655538            0.393913\n",
      "     14                0.79999232         0.006704  0.007931         1.249219       0.001919  0.010427                  0.302318          0.302192      0.000793                 0.999365   -99.206883        24.921884            0.263027\n",
      "     15                0.89999616         0.002125  0.006345         1.111116       0.001536  0.004130                  0.268896          0.269073      0.000635                 1.000000   -99.365507        11.111585            0.131932\n",
      "     16                1.00000000         0.000384  0.000000         1.000000       0.000000  0.001233                  0.242005          0.242288      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09372056\n",
      " RMSE: 0.30613816\n",
      " AUC: 0.91648334\n",
      " pr_auc: 0.80501133\n",
      " logloss: 0.29465267\n",
      " mean_per_class_error: 0.18732806\n",
      " default threshold: 0.38061749935150146\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4422   553  0.1112  553 / 4,975\n",
      "     1   405  1132  0.2635  405 / 1,537\n",
      "Totals  4827  1685  0.1471  958 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.01 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994777  4.236825         4.236825       1.000000  0.996030                  1.000000          0.996030      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.992035  4.236825         4.236825       1.000000  0.993605                  1.000000          0.994827      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.987222  4.236825         4.236825       1.000000  0.990246                  1.000000          0.993308      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.976977  4.171643         4.220592       0.984615  0.982509                  0.996169          0.990618      0.041640                 0.169161  317.164306       322.059194            0.168960\n",
      "      5                0.05006143         0.961219  4.236825         4.223829       1.000000  0.969930                  0.996933          0.986493      0.042290                 0.211451  323.682498       322.382859            0.211250\n",
      "      6                0.10012285         0.773348  3.561012         3.892420       0.840491  0.863581                  0.918712          0.925037      0.178269                 0.389720  256.101241       289.242050            0.379067\n",
      "      7                0.15003071         0.629029  2.854968         3.547311       0.673846  0.700300                  0.837257          0.850278      0.142485                 0.532206  185.496822       254.731099            0.500246\n",
      "      8                0.20009214         0.494773  2.079423         3.180057       0.490798  0.560558                  0.750576          0.777793      0.104099                 0.636304  107.942330       218.005743            0.570978\n",
      "      9                0.30006143         0.316105  1.522914         2.627959       0.359447  0.398490                  0.620266          0.651423      0.152245                 0.788549   52.291405       162.795900            0.639403\n",
      "     10                0.40003071         0.170075  1.177981         2.265604       0.278034  0.239090                  0.534741          0.548379      0.117762                 0.906311   17.798053       126.560353            0.662693\n",
      "     11                0.50000000         0.075497  0.540179         1.920625       0.127496  0.116575                  0.453317          0.462045      0.054001                 0.960312  -45.982109        92.062459            0.602523\n",
      "     12                0.59996929         0.032882  0.195245         1.633135       0.046083  0.051115                  0.385462          0.393574      0.019519                 0.979831  -80.475461        63.313500            0.497218\n",
      "     13                0.69993857         0.015363  0.071590         1.410106       0.016897  0.022862                  0.332821          0.340627      0.007157                 0.986988  -92.841002        41.010608            0.375731\n",
      "     14                0.79990786         0.007084  0.097623         1.246077       0.023041  0.010619                  0.294106          0.299384      0.009759                 0.996747  -90.237730        24.607715            0.257651\n",
      "     15                0.89987715         0.002245  0.026033         1.110540       0.006144  0.004441                  0.262116          0.266618      0.002602                 0.999349  -97.396728        11.053979            0.130204\n",
      "     16                1.00000000         0.000390  0.006498         1.000000       0.001534  0.001305                  0.236026          0.240054      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6151.899902          1.000000   0.310609\n",
      "                      capital_gain         3626.863770          0.589552   0.183120\n",
      "                               age         1754.416504          0.285183   0.088580\n",
      "                      capital_loss         1274.986328          0.207251   0.064374\n",
      "                            fnlwgt         1176.462280          0.191236   0.059399\n",
      "                    hours_per_week          996.617920          0.162002   0.050319\n",
      "        occupation. Prof-specialty          698.248352          0.113501   0.035254\n",
      "       occupation. Exec-managerial          590.912476          0.096054   0.029835\n",
      "              education. Bachelors          489.897217          0.079633   0.024735\n",
      "                education. Masters          257.099548          0.041792   0.012981\n",
      "---\n",
      "                       race. White           10.712988          0.001741   0.000541\n",
      "                education. 1st-4th            9.308963          0.001513   0.000470\n",
      "          race. Asian-Pac-Islander            8.950741          0.001455   0.000452\n",
      "                   education. 12th            8.412661          0.001367   0.000425\n",
      "           relationship. Unmarried            8.210783          0.001335   0.000415\n",
      "                       race. Other            7.845816          0.001275   0.000396\n",
      "            native_country. Canada            7.493516          0.001218   0.000378\n",
      "                 native_country.NA            6.556307          0.001066   0.000331\n",
      "         marital_status. Separated            5.387891          0.000876   0.000272\n",
      "             native_country. India            3.964354          0.000644   0.000200\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        68139.382813          1.000000   0.133758\n",
      "                               age        60821.015625          0.892597   0.119392\n",
      "                            fnlwgt        46352.476563          0.680260   0.090990\n",
      "                      capital_loss        43240.804688          0.634593   0.084882\n",
      "                    hours_per_week        37824.960938          0.555112   0.074250\n",
      "marital_status. Married-civ-spouse        29794.951172          0.437265   0.058487\n",
      "              education. Bachelors        12795.446289          0.187783   0.025117\n",
      "                education. Masters        12407.238281          0.182086   0.024355\n",
      "              education. Doctorate        10816.667969          0.158743   0.021233\n",
      "       occupation. Exec-managerial        10626.428711          0.155951   0.020860\n",
      "---\n",
      "             native_country. India         1213.528198          0.017809   0.002382\n",
      "                       race. Other         1159.867310          0.017022   0.002277\n",
      "           relationship. Unmarried         1147.709106          0.016844   0.002253\n",
      "         marital_status. Separated         1106.033081          0.016232   0.002171\n",
      "          occupation. Craft-repair         1010.896057          0.014836   0.001984\n",
      "                         sex. Male          999.216980          0.014664   0.001961\n",
      "              education. Assoc-voc          997.089111          0.014633   0.001957\n",
      "              workclass. State-gov          538.044617          0.007896   0.001056\n",
      "           marital_status. Widowed          510.363953          0.007490   0.001002\n",
      "                       race. White          335.235657          0.004920   0.000658\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          433.000000          1.000000   0.243258\n",
      "                        age          365.000000          0.842956   0.205056\n",
      "             hours_per_week          165.000000          0.381062   0.092697\n",
      "               capital_gain           79.000000          0.182448   0.044382\n",
      "               capital_loss           62.000000          0.143187   0.034831\n",
      "                sex. Female           45.000000          0.103926   0.025281\n",
      " occupation. Prof-specialty           42.000000          0.096998   0.023596\n",
      "       education. Bachelors           40.000000          0.092379   0.022472\n",
      "         workclass. Private           39.000000          0.090069   0.021910\n",
      "         education. HS-grad           38.000000          0.087760   0.021348\n",
      "---\n",
      "native_country. Philippines            3.000000          0.006928   0.001685\n",
      "         education. 5th-6th            3.000000          0.006928   0.001685\n",
      "     native_country. Canada            2.000000          0.004619   0.001124\n",
      "  marital_status. Separated            2.000000          0.004619   0.001124\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.004619   0.001124\n",
      "          native_country.NA            2.000000          0.004619   0.001124\n",
      "                race. Other            1.000000          0.002309   0.000562\n",
      "            education. 12th            1.000000          0.002309   0.000562\n",
      "         education. 1st-4th            1.000000          0.002309   0.000562\n",
      "      native_country. India            1.000000          0.002309   0.000562\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      " 2023-10-20 18:27:43  3.142 sec              20       0.28407          0.25745      0.94233         0.85824       4.13214                       0.12166         0.30608            0.29567        0.91561           0.80478         4.23682                         0.14527\n",
      " 2023-10-20 18:27:44  4.063 sec              25       0.28125          0.25204      0.94445         0.86294       4.13214                       0.12070         0.30559            0.29433        0.91662           0.80552         4.23682                         0.14665\n",
      " 2023-10-20 18:27:46  5.164 sec              30       0.27734          0.24542      0.94749         0.86972       4.13214                       0.11597         0.30614            0.29465        0.91648           0.80501         4.23682                         0.14711\n",
      "\n",
      "10-20 18:27:46.484 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_355\n",
      "10-20 18:27:46.489 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3204199558664507, 0.30084679157968575, 0.29622004163067045, 0.2948837085583686]\n",
      "10-20 18:27:46.492 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3204199558664507 --> 0.2948837085583686 (still improving).\n",
      "10-20 18:27:46.528 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:46.528) \n",
      "10-20 18:27:46.529 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_355\n",
      "10-20 18:27:46.534 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.07833153\n",
      " RMSE: 0.2798777\n",
      " AUC: 0.94497335\n",
      " pr_auc: 0.8614454\n",
      " logloss: 0.24912894\n",
      " mean_per_class_error: 0.15317516\n",
      " default threshold: 0.3999105989933014\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18212  1621  0.0817  1,621 / 19,833\n",
      "     1   1396  4819  0.2246   1,396 / 6,215\n",
      "Totals  19608  6440  0.1158  3,017 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.91 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.994952  4.191150         4.191150       1.000000  0.996334                  1.000000          0.996334      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.992232  4.191150         4.191150       1.000000  0.993686                  1.000000          0.995012      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.987400  4.191150         4.191150       1.000000  0.990103                  1.000000          0.993374      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.977778  4.175031         4.187128       0.996154  0.983338                  0.999040          0.990869      0.041673                 0.167498   317.503063       318.712823            0.167448\n",
      "      5                0.05002303         0.959134  4.175092         4.184717       0.996169  0.969864                  0.998465          0.986662      0.041834                 0.209332   317.509239       318.471736            0.209231\n",
      "      6                0.10000768         0.774551  3.843497         4.014173       0.917051  0.866163                  0.957774          0.926436      0.192116                 0.401448   284.349741       301.417288            0.395902\n",
      "      7                0.15003071         0.636572  3.145775         3.724633       0.750576  0.702322                  0.888690          0.851712      0.157361                 0.558809   214.577524       272.463293            0.536876\n",
      "      8                0.20001536         0.500103  2.565551         3.434974       0.612135  0.568264                  0.819578          0.780877      0.128238                 0.687047   156.555062       243.497359            0.639652\n",
      "      9                0.30002303         0.307115  1.642674         2.837540       0.391939  0.395874                  0.677031          0.652543      0.164280                 0.851327    64.267355       183.754024            0.724065\n",
      "     10                0.39999232         0.162856  0.912589         2.356441       0.217742  0.231934                  0.562242          0.547421      0.091231                 0.942558    -8.741079       135.644105            0.712588\n",
      "     11                0.50000000         0.073127  0.379697         1.961062       0.090595  0.113223                  0.467905          0.460575      0.037973                 0.980531   -62.030269        96.106195            0.631113\n",
      "     12                0.60000768         0.031274  0.130320         1.655919       0.031094  0.049651                  0.395099          0.392083      0.013033                 0.993564   -86.968016        65.591874            0.516884\n",
      "     13                0.69997697         0.014572  0.049895         1.426550       0.011905  0.021766                  0.340372          0.339195      0.004988                 0.998552   -95.010535        42.654964            0.392138\n",
      "     14                0.79998464         0.006848  0.009653         1.249421       0.002303  0.010291                  0.298109          0.298078      0.000965                 0.999517   -99.034668        24.942060            0.262060\n",
      "     15                0.89999232         0.002652  0.004827         1.111121       0.001152  0.004572                  0.265111          0.265464      0.000483                 1.000000   -99.517334        11.112059            0.131347\n",
      "     16                1.00000000         0.000332  0.000000         1.000000       0.000000  0.001541                  0.238598          0.239069      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.08962906\n",
      " RMSE: 0.29938114\n",
      " AUC: 0.9278921\n",
      " pr_auc: 0.83651227\n",
      " logloss: 0.28308526\n",
      " mean_per_class_error: 0.17540096\n",
      " default threshold: 0.3925076127052307\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4459   428  0.0876  428 / 4,887\n",
      "     1   428  1198  0.2632  428 / 1,626\n",
      "Totals  4887  1626  0.1314  856 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.07 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.994739  4.005535         4.005535       1.000000  0.995932                  1.000000          0.995932      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.992536  4.005535         4.005535       1.000000  0.993701                  1.000000          0.994825      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.987643  4.005535         4.005535       1.000000  0.990269                  1.000000          0.993314      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.977100  4.005535         4.005535       1.000000  0.983158                  1.000000          0.990785      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.962244  4.005535         4.005535       1.000000  0.970984                  1.000000          0.986837      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.788736  3.587780         3.796657       0.895706  0.877916                  0.947853          0.932376      0.179582                 0.380074   258.777987       279.665746            0.373117\n",
      "      7                0.15000768         0.640847  2.945609         3.513555       0.735385  0.714067                  0.877175          0.859756      0.146986                 0.527060   194.560886       251.355531            0.502505\n",
      "      8                0.20006142         0.505150  2.334514         3.218569       0.582822  0.569927                  0.803530          0.787243      0.116851                 0.643911   133.451430       221.856884            0.591528\n",
      "      9                0.30001535         0.303444  1.636670         2.691539       0.408602  0.395718                  0.671955          0.656801      0.163592                 0.807503    63.667024       169.153916            0.676339\n",
      "     10                0.39996929         0.162850  1.009075         2.271085       0.251920  0.232167                  0.566987          0.550683      0.100861                 0.908364     0.907488       127.108456            0.677548\n",
      "     11                0.50007677         0.074833  0.534481         1.923444       0.133436  0.113884                  0.480196          0.463243      0.053506                 0.961870   -46.551910        92.344391            0.615440\n",
      "     12                0.60003071         0.032537  0.221504         1.639932       0.055300  0.050890                  0.409417          0.394553      0.022140                 0.984010   -77.849576        63.993247            0.511736\n",
      "     13                0.69998465         0.014989  0.110752         1.421574       0.027650  0.022052                  0.354902          0.341362      0.011070                 0.995080   -88.924788        42.157397            0.393279\n",
      "     14                0.79993858         0.007278  0.036917         1.248558       0.009217  0.010636                  0.311708          0.300037      0.003690                 0.998770   -96.308263        24.855834            0.264986\n",
      "     15                0.89989252         0.002822  0.012306         1.111244       0.003072  0.004883                  0.277427          0.267253      0.001230                 1.000000   -98.769421        11.124382            0.133415\n",
      "     16                1.00000000         0.000297  0.000000         1.000000       0.000000  0.001613                  0.249655          0.240660      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5145.792969          1.000000   0.266501\n",
      "                      capital_gain         3686.859863          0.716480   0.190943\n",
      "                               age         1815.145630          0.352744   0.094007\n",
      "                      capital_loss         1249.290894          0.242779   0.064701\n",
      "                    hours_per_week         1093.566162          0.212517   0.056636\n",
      "                            fnlwgt         1089.179077          0.211664   0.056409\n",
      "     marital_status. Never-married          707.926086          0.137574   0.036664\n",
      "        occupation. Prof-specialty          530.902405          0.103172   0.027496\n",
      "       occupation. Exec-managerial          517.775269          0.100621   0.026816\n",
      "              education. Bachelors          368.047729          0.071524   0.019061\n",
      "---\n",
      "       native_country. Philippines           14.246078          0.002768   0.000738\n",
      "                education. 1st-4th           13.181145          0.002562   0.000683\n",
      "          race. Asian-Pac-Islander           12.028238          0.002337   0.000623\n",
      "           marital_status. Widowed           10.492587          0.002039   0.000543\n",
      "                   education. 12th            9.015594          0.001752   0.000467\n",
      "          race. Amer-Indian-Eskimo            8.193613          0.001592   0.000424\n",
      "       native_country. Puerto-Rico            7.210544          0.001401   0.000373\n",
      "         marital_status. Separated            4.826701          0.000938   0.000250\n",
      "                 native_country.NA            3.842378          0.000747   0.000199\n",
      "                      workclass.NA            2.801810          0.000544   0.000145\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        71838.171875          1.000000   0.141144\n",
      "                               age        59814.304688          0.832626   0.117520\n",
      "                    hours_per_week        40231.312500          0.560027   0.079045\n",
      "                      capital_loss        38256.062500          0.532531   0.075164\n",
      "                            fnlwgt        35775.183594          0.497997   0.070289\n",
      "marital_status. Married-civ-spouse        27920.119141          0.388653   0.054856\n",
      "        occupation. Prof-specialty        11892.545898          0.165546   0.023366\n",
      "              education. Bachelors        11074.909180          0.154165   0.021759\n",
      "       occupation. Exec-managerial        10552.625977          0.146894   0.020733\n",
      "              education. Doctorate        10277.798828          0.143069   0.020193\n",
      "---\n",
      "          marital_status. Divorced         1478.210449          0.020577   0.002904\n",
      "         marital_status. Separated         1390.543701          0.019357   0.002732\n",
      "     occupation. Machine-op-inspct         1265.528320          0.017616   0.002486\n",
      "                      workclass.NA         1260.344727          0.017544   0.002476\n",
      "           relationship. Unmarried         1167.892334          0.016257   0.002295\n",
      "                         sex. Male         1114.210205          0.015510   0.002189\n",
      "             relationship. Husband          708.437317          0.009862   0.001392\n",
      "                       race. Black          647.904541          0.009019   0.001273\n",
      "          race. Asian-Pac-Islander          220.023010          0.003063   0.000432\n",
      "                 native_country.NA          145.587036          0.002027   0.000286\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          421.000000          1.000000   0.234671\n",
      "                        age          402.000000          0.954869   0.224080\n",
      "             hours_per_week          175.000000          0.415677   0.097547\n",
      "               capital_gain           72.000000          0.171021   0.040134\n",
      "               capital_loss           65.000000          0.154394   0.036232\n",
      " occupation. Prof-specialty           43.000000          0.102138   0.023969\n",
      "         education. HS-grad           43.000000          0.102138   0.023969\n",
      "         workclass. Private           39.000000          0.092637   0.021739\n",
      "       education. Bachelors           37.000000          0.087886   0.020624\n",
      "occupation. Exec-managerial           35.000000          0.083135   0.019509\n",
      "---\n",
      "   race. Asian-Pac-Islander            3.000000          0.007126   0.001672\n",
      "         education. 1st-4th            3.000000          0.007126   0.001672\n",
      "native_country. Philippines            3.000000          0.007126   0.001672\n",
      "         education. 5th-6th            3.000000          0.007126   0.001672\n",
      "            education. 12th            2.000000          0.004751   0.001115\n",
      "               workclass.NA            2.000000          0.004751   0.001115\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.004751   0.001115\n",
      "  marital_status. Separated            1.000000          0.002375   0.000557\n",
      "native_country. Puerto-Rico            1.000000          0.002375   0.000557\n",
      "          native_country.NA            1.000000          0.002375   0.000557\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      " 2023-10-20 18:27:44  3.876 sec              25       0.28313          0.25490      0.94227         0.85560       4.19115                       0.12024         0.29943            0.28298        0.92811           0.83677         4.00554                         0.13005\n",
      " 2023-10-20 18:27:46  5.162 sec              30       0.27988          0.24913      0.94497         0.86145       4.19115                       0.11582         0.29938            0.28309        0.92789           0.83651         4.00554                         0.13143\n",
      "\n",
      "10-20 18:27:46.543 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:46.543) \n",
      "10-20 18:27:46.559 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3138710514277733, 0.2925293825647188, 0.2861294133601945, 0.28373624136936404]\n",
      "10-20 18:27:46.559 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3138710514277733 --> 0.28373624136936404 (still improving).\n",
      "10-20 18:27:46.601 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:46.601) \n",
      "10-20 18:27:46.602 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:46.602) \n",
      "10-20 18:27:46.606 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:46.606) \n",
      "10-20 18:27:46.638 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:46.638) \n",
      "10-20 18:27:46.646 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:46.646) \n",
      "10-20 18:27:46.653 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:46.653) \n",
      "10-20 18:27:46.662 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_356\n",
      "10-20 18:27:46.676 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_356\n",
      "10-20 18:27:46.681 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07901282\n",
      " RMSE: 0.2810922\n",
      " AUC: 0.9441531\n",
      " pr_auc: 0.8629324\n",
      " logloss: 0.25176048\n",
      " mean_per_class_error: 0.15065782\n",
      " default threshold: 0.39799872040748596\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18066  1672  0.0847  1,672 / 19,738\n",
      "     1   1367  4944  0.2166   1,367 / 6,311\n",
      "Totals  19433  6616  0.1167  3,039 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.25 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995060  4.127555         4.127555       1.000000  0.996276                  1.000000          0.996276      0.041356                 0.041356  312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.992844  4.127555         4.127555       1.000000  0.993968                  1.000000          0.995124      0.041198                 0.082554  312.755506       312.755506            0.082554\n",
      "      3                0.03005874         0.988623  4.127555         4.127555       1.000000  0.990955                  1.000000          0.993729      0.041515                 0.124069  312.755506       312.755506            0.124069\n",
      "      4                0.04000154         0.980800  4.127555         4.127555       1.000000  0.985208                  1.000000          0.991611      0.041039                 0.165109  312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.965631  4.064298         4.114884       0.984674  0.973809                  0.996930          0.988045      0.040723                 0.205831  306.429751       311.488413            0.205628\n",
      "      6                0.10000384         0.791419  3.813709         3.964354       0.923963  0.875021                  0.960461          0.931555      0.190620                 0.396451  281.370871       296.435423            0.391232\n",
      "      7                0.15002495         0.647942  3.170900         3.699802       0.768227  0.719233                  0.896366          0.860763      0.158612                 0.555063  217.089994       269.980179            0.534544\n",
      "      8                0.20000768         0.512057  2.444197         3.386021       0.592166  0.578937                  0.820345          0.790333      0.122168                 0.677230  144.419735       238.602118            0.629809\n",
      "      9                0.30001152         0.308850  1.703310         2.825117       0.412668  0.407354                  0.684453          0.662674      0.170338                 0.847568   70.330967       182.511734            0.722631\n",
      "     10                0.40001536         0.162105  0.906319         2.345418       0.219578  0.230360                  0.568234          0.554595      0.090635                 0.938203   -9.368081       134.541780            0.710267\n",
      "     11                0.50001919         0.075514  0.404041         1.957142       0.097889  0.114331                  0.474165          0.466542      0.040406                 0.978609  -59.595910        95.714242            0.631613\n",
      "     12                0.59998464         0.033295  0.129977         1.652712       0.031490  0.051938                  0.400409          0.397464      0.012993                 0.991602  -87.002323        65.271224            0.516832\n",
      "     13                0.69998848         0.015902  0.064963         1.425879       0.015739  0.023291                  0.345454          0.344007      0.006497                 0.998099  -93.503656        42.587854            0.393427\n",
      "     14                0.79999232         0.007145  0.015845         1.249616       0.003839  0.011047                  0.302750          0.302385      0.001585                 0.999683  -98.415526        24.961586            0.263540\n",
      "     15                0.89999616         0.002681  0.001584         1.110940       0.000384  0.004675                  0.269152          0.269305      0.000158                 0.999842  -99.841553        11.093979            0.131770\n",
      "     16                1.00000000         0.000349  0.001584         1.000000       0.000384  0.001619                  0.242274          0.242535      0.000158                 1.000000  -99.841553         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.088179186\n",
      " RMSE: 0.2969498\n",
      " AUC: 0.92621917\n",
      " pr_auc: 0.82273936\n",
      " logloss: 0.27844587\n",
      " mean_per_class_error:█ 0.1866858\n",
      " default threshold: 0.44865813851356506\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4636   346  0.0695  346 / 4,982\n",
      "     1   465  1065  0.3039  465 / 1,530\n",
      "Totals  5101  1411  0.1245  811 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.56 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.994915  4.256209         4.256209       1.000000  0.996181                  1.000000          0.996181      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.992335  4.190729         4.223719       0.984615  0.993556                  0.992366          0.994878      0.041830                 0.084967   319.072901       322.371900            0.084767\n",
      "      3                0.03009828         0.988307  4.256209         4.234494       1.000000  0.990541                  0.994898          0.993440      0.042484                 0.127451   325.620915       323.449380            0.127250\n",
      "      4                0.04007985         0.981129  4.256209         4.239902       1.000000  0.984927                  0.996169          0.991320      0.042484                 0.169935   325.620915       323.990184            0.169734\n",
      "      5                0.05006143         0.964481  4.125249         4.217042       0.969231  0.973537                  0.990798          0.987774      0.041176                 0.211111   312.524887       321.704158            0.210509\n",
      "      6                0.10012285         0.774762  3.773142         3.995092       0.886503  0.869255                  0.938650          0.928515      0.188889                 0.400000   277.314247       299.509202            0.391971\n",
      "      7                0.15003071         0.628579  2.894222         3.628887       0.680000  0.698315                  0.852610          0.851939      0.144444                 0.544444   189.422222       262.888661            0.515540\n",
      "      8                0.20009214         0.486289  2.310887         3.299134       0.542945  0.557711                  0.775134          0.778325      0.115686                 0.660131   131.088656       229.913372            0.601319\n",
      "      9                0.30006143         0.289909  1.484116         2.694437       0.348694  0.381579                  0.633060          0.646144      0.148366                 0.808497    48.411594       169.443742            0.664579\n",
      "     10                0.40003071         0.155315  1.019921         2.275969       0.239631  0.217716                  0.534741          0.539078      0.101961                 0.910458     1.992109       127.596904            0.667182\n",
      "     11                0.50000000         0.072389  0.562264         1.933333       0.132104  0.111126                  0.454238          0.453514      0.056209                 0.966667   -43.773581        93.333333            0.609983\n",
      "     12                0.59996929         0.032113  0.202677         1.644964       0.047619  0.049673                  0.386486          0.386225      0.020261                 0.986928   -79.732337        64.496438            0.505796\n",
      "     13                0.69993857         0.015117  0.078455         1.421226       0.018433  0.022298                  0.333918          0.334246      0.007843                 0.994771   -92.154453        42.122649            0.385377\n",
      "     14                0.79990786         0.006989  0.045766         1.249327       0.010753  0.010647                  0.293530          0.293804      0.004575                 0.999346   -95.423431        24.932689            0.260687\n",
      "     15                0.89987715         0.002393  0.000000         1.110536       0.000000  0.004458                  0.260922          0.261660      0.000000                 0.999346  -100.000000        11.053648            0.130017\n",
      "     16                1.00000000         0.000410  0.006528         1.000000       0.001534  0.001497                  0.234951          0.235612      0.000654                 1.000000   -99.347207         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6116.224609          1.000000   0.316060\n",
      "                      capital_gain         3589.736572          0.586920   0.185502\n",
      "                               age         1721.956909          0.281539   0.088983\n",
      "                      capital_loss         1261.499390          0.206255   0.065189\n",
      "                            fnlwgt         1112.296143          0.181860   0.057479\n",
      "                    hours_per_week         1036.980957          0.169546   0.053587\n",
      "       occupation. Exec-managerial          611.602661          0.099997   0.031605\n",
      "        occupation. Prof-specialty          610.612976          0.099835   0.031554\n",
      "              education. Bachelors          462.062958          0.075547   0.023877\n",
      "                education. Masters          256.378052          0.041918   0.013248\n",
      "---\n",
      "          marital_status. Divorced           14.106035          0.002306   0.000729\n",
      "                   education. 12th           13.561639          0.002217   0.000701\n",
      "         marital_status. Separated            9.593512          0.001569   0.000496\n",
      "           marital_status. Widowed            9.470652          0.001548   0.000489\n",
      "              workclass. State-gov            9.267618          0.001515   0.000479\n",
      "                 native_country.NA            6.232629          0.001019   0.000322\n",
      "           native_country. Germany            4.615104          0.000755   0.000238\n",
      "                education. 1st-4th            4.297473          0.000703   0.000222\n",
      "             native_country. India            3.007887          0.000492   0.000155\n",
      "          race. Amer-Indian-Eskimo            2.552530          0.000417   0.000132\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        65877.976563          1.000000   0.129878\n",
      "                               age        54946.550781          0.834066   0.108327\n",
      "                      capital_loss        48116.851563          0.730394   0.094862\n",
      "                            fnlwgt        47091.835938          0.714834   0.092841\n",
      "                    hours_per_week        33705.531250          0.511636   0.066450\n",
      "marital_status. Married-civ-spouse        31736.816406          0.481752   0.062569\n",
      "                education. Masters        13786.879883          0.209279   0.027181\n",
      "              education. Bachelors        13292.519531          0.201775   0.026206\n",
      "       occupation. Exec-managerial        11096.305664          0.168437   0.021876\n",
      "            education. Prof-school        10194.746094          0.154752   0.020099\n",
      "---\n",
      "             native_country. India         1254.505981          0.019043   0.002473\n",
      "                education. 1st-4th         1250.632324          0.018984   0.002466\n",
      "           native_country. Germany         1218.200195          0.018492   0.002402\n",
      "                 native_country.NA         1201.647095          0.018240   0.002369\n",
      "         marital_status. Separated         1175.023315          0.017836   0.002317\n",
      "      occupation. Transport-moving         1158.109741          0.017580   0.002283\n",
      "                         sex. Male          838.006348          0.012721   0.001652\n",
      "             relationship. Husband          538.747681          0.008178   0.001062\n",
      "          marital_status. Divorced          527.153625          0.008002   0.001039\n",
      "              workclass. State-gov          261.739502          0.003973   0.000516\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          428.000000          1.000000   0.241671\n",
      "                        age          366.000000          0.855140   0.206663\n",
      "             hours_per_week          155.000000          0.362150   0.087521\n",
      "               capital_gain           81.000000          0.189252   0.045737\n",
      "               capital_loss           67.000000          0.156542   0.037832\n",
      "         workclass. Private           48.000000          0.112150   0.027103\n",
      "       education. Bachelors           43.000000          0.100467   0.024280\n",
      " occupation. Prof-specialty           41.000000          0.095794   0.023151\n",
      "         education. HS-grad           39.000000          0.091121   0.022021\n",
      "                sex. Female           33.000000          0.077103   0.018634\n",
      "---\n",
      "    workclass. Self-emp-inc            3.000000          0.007009   0.001694\n",
      "    marital_status. Widowed            2.000000          0.004673   0.001129\n",
      "            education. 12th            2.000000          0.004673   0.001129\n",
      "  marital_status. Separated            2.000000          0.004673   0.001129\n",
      "          native_country.NA            2.000000          0.004673   0.001129\n",
      "         education. 5th-6th            2.000000          0.004673   0.001129\n",
      "         education. 1st-4th            1.000000          0.002336   0.000565\n",
      "      native_country. India            1.000000          0.002336   0.000565\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.002336   0.000565\n",
      "    native_country. Germany            1.000000          0.002336   0.000565\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      " 2023-10-20 18:27:45  4.269 sec              25       0.28404          0.25689      0.94168         0.85767       4.12756                       0.12000         0.29713            0.27903        0.92592           0.82214         4.25621                         0.14097\n",
      " 2023-10-20 18:27:46  5.267 sec              30       0.28109          0.25176      0.94415         0.86293       4.12756                       0.11666         0.29695            0.27845        0.92622           0.82274         4.25621                         0.12454\n",
      "\n",
      "10-20 18:27:46.690 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3079451621693427, 0.2864032351307502, 0.28089149436718375, 0.2793548586952809]\n",
      "10-20 18:27:46.691 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:46.691) \n",
      "10-20 18:27:46.690 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.3079451621693427 --> 0.2793548586952809 (still improving).\n",
      "10-20 18:27:46.701 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:46.701) \n",
      "10-20 18:27:46.712 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.059 (Wall: 20-Oct 18:27:46.712) \n",
      "10-20 18:27:46.792 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.079 (Wall: 20-Oct 18:27:46.792) \n",
      "10-20 18:27:46.855 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.161 (Wall: 20-Oct 18:27:46.855) \n",
      "10-20 18:27:46.855 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.161 (Wall: 20-Oct 18:27:46.855) \n",
      "10-20 18:27:46.857 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_357\n",
      "10-20 18:27:46.876 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_357\n",
      "10-20 18:27:46.910 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:46.910) \n",
      "10-20 18:27:46.928 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:46.928) \n",
      "10-20 18:27:47.037 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.127 (Wall: 20-Oct 18:27:47.037) \n",
      "10-20 18:27:47.041 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_358\n",
      "10-20 18:27:47.073 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:47.074 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_358\n",
      "10-20 18:27:47.111 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.074 (Wall: 20-Oct 18:27:47.111) \n",
      "10-20 18:27:47.146 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_359\n",
      "10-20 18:27:47.153 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:47.153) \n",
      "10-20 18:27:47.164 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_359\n",
      "10-20 18:27:47.255 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_360\n",
      "10-20 18:27:47.266 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_360\n",
      "10-20 18:27:47.271 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_361\n",
      "10-20 18:27:47.274 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.07639694\n",
      " RMSE: 0.27639997\n",
      " AUC: 0.9478249\n",
      " pr_auc: 0.87078184\n",
      " logloss: 0.24409038\n",
      " mean_per_class_error: 0.15123177\n",
      " default threshold: 0.4203299582004547\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18343  1425  0.0721  1,425 / 19,768\n",
      "     1   1447  4834  0.2304   1,447 / 6,281\n",
      "Totals  19790  6259  0.1103  2,872 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995473  4.147270         4.147270       1.000000  0.996836                  1.000000          0.996836      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.993552  4.147270         4.147270       1.000000  0.994507                  1.000000          0.995674      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.990293  4.147270         4.147270       1.000000  0.992154                  1.000000          0.994499      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.983272  4.147270         4.147270       1.000000  0.987287                  1.000000          0.992699      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.970259  4.131380         4.144087       0.996169  0.977156                  0.999233          0.989586      0.041395                 0.207292   313.137962       314.408668            0.207241\n",
      "      6                0.10000384         0.798827  3.860592         4.002394       0.930876  0.885191                  0.965067          0.937408      0.192963                 0.400255   286.059192       300.239372            0.395651\n",
      "      7                0.15002495         0.648648  3.214691         3.739759       0.775134  0.722003                  0.901740          0.865588      0.160802                 0.561057   221.469090       273.975892            0.541632\n",
      "      8                0.20000768         0.513440  2.586469         3.451547       0.623656  0.580018                  0.832246          0.794223      0.129279                 0.690336   158.646918       245.154717            0.646123\n",
      "      9                0.30001152         0.306133  1.670052         2.857715       0.402687  0.403113                  0.689060          0.663853      0.167012                 0.857348    67.005211       185.771548            0.734422\n",
      "     10                0.40001536         0.161290  0.878807         2.362988       0.211900  0.229056                  0.569770          0.555154      0.087884                 0.945232   -12.119279       136.298841            0.718451\n",
      "     11                0.50001919         0.075680  0.366170         1.963625       0.088292  0.113802                  0.473474          0.466883      0.036618                 0.981850   -63.383033        96.362467            0.634926\n",
      "     12                0.59998464         0.032728  0.109893         1.654768       0.026498  0.050896                  0.399002          0.397574      0.010986                 0.992836   -89.010691        65.476824            0.517674\n",
      "     13                0.69998848         0.014835  0.057314         1.426548       0.013820  0.022488                  0.343973          0.343988      0.005732                 0.998567   -94.268649        42.654791            0.393448\n",
      "     14                0.79999232         0.006667  0.012736         1.249813       0.003071  0.010254                  0.301358          0.302269      0.001274                 0.999841   -98.726366        24.981298            0.263347\n",
      "     15                0.89999616         0.002097  0.001592         1.111116       0.000384  0.004140                  0.267915          0.269142      0.000159                 1.000000   -99.840796        11.111585            0.131779\n",
      "     16                1.00000000         0.000129  0.000000         1.000000       0.000000  0.001011                  0.241122          0.242328      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09157633\n",
      " RMSE: 0.30261582\n",
      " AUC: 0.9240919\n",
      " pr_auc: 0.81618\n",
      " logloss: 0.28649643\n",
      " mean_per_class_error: 0.1638913\n",
      " default threshold: 0.3272441029548645\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4297   655  0.1323  655 / 4,952\n",
      "     1   305  1255  0.1955  305 / 1,560\n",
      "Totals  4602  1910  0.1474  960 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.54 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995238  4.174359         4.174359       1.000000  0.996766                  1.000000          0.996766      0.042308                 0.042308   317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.993533  4.174359         4.174359       1.000000  0.994358                  1.000000          0.995571      0.041667                 0.083974   317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.990570  4.110138         4.153061       0.984615  0.992126                  0.994898          0.994429      0.041026                 0.125000   311.013807       315.306122            0.124798\n",
      "      4                0.04007985         0.983767  4.110138         4.142372       0.984615  0.987615                  0.992337          0.992732      0.041026                 0.166026   311.013807       314.237155            0.165622\n",
      "      5                0.05006143         0.971091  4.174359         4.148749       1.000000  0.977881                  0.993865          0.989771      0.041667                 0.207692   317.435897       314.874941            0.207288\n",
      "      6                0.10012285         0.803213  3.508510         3.828630       0.840491  0.889893                  0.917178          0.939832      0.175641                 0.383333   250.851030       282.862986            0.372429\n",
      "      7                0.15003071         0.666819  2.825720         3.495011       0.676923  0.735750                  0.837257          0.871944      0.141026                 0.524359   182.571992       249.501089            0.492251\n",
      "      8                0.20009214         0.530378  2.279251         3.190838       0.546012  0.598426                  0.764390          0.803512      0.114103                 0.638462   127.925122       219.083771            0.576466\n",
      "      9                0.30006143         0.311856  1.750538         2.710983       0.419355  0.417800                  0.649437          0.675007      0.175000                 0.813462    75.053763       171.098339            0.675134\n",
      "     10                0.40003071         0.158852  0.987483         2.280274       0.236559  0.229798                  0.546257          0.563748      0.098718                 0.912179    -1.251723       128.027364            0.673488\n",
      "     11                0.50000000         0.075340  0.519390         1.928205       0.124424  0.112454                  0.461916          0.473517      0.051923                 0.964103   -48.060971        92.820513            0.610306\n",
      "     12                0.59996929         0.030924  0.224428         1.644315       0.053763  0.049522                  0.393908          0.402869      0.022436                 0.986538   -77.557210        64.431494            0.508348\n",
      "     13                0.69993857         0.014681  0.096183         1.423202       0.023041  0.021735                  0.340939          0.348433      0.009615                 0.996154   -90.381661        42.320181            0.389530\n",
      "     14                0.79990786         0.006394  0.019237         1.247740       0.004608  0.010117                  0.298906          0.306152      0.001923                 0.998077   -98.076332        24.773986            0.260597\n",
      "     15                0.89987715         0.002210  0.019237         1.111263       0.004608  0.004071                  0.266212          0.272593      0.001923                 1.000000   -98.076332        11.126280            0.131664\n",
      "     16                1.00000000         0.000165  0.000000         1.000000       0.000000  0.001088                  0.239558          0.245409      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5990.591797          1.000000   0.300622\n",
      "                      capital_gain         3671.153564          0.612820   0.184227\n",
      "                               age         1895.248535          0.316371   0.095108\n",
      "                      capital_loss         1260.200195          0.210363   0.063240\n",
      "                            fnlwgt         1194.117065          0.199332   0.059924\n",
      "                    hours_per_week          982.984802          0.164088   0.049328\n",
      "        occupation. Prof-specialty          633.428711          0.105737   0.031787\n",
      "       occupation. Exec-managerial          577.433044          0.096390   0.028977\n",
      "              education. Bachelors          470.779755          0.078587   0.023625\n",
      "                education. HS-grad          226.820053          0.037863   0.011382\n",
      "---\n",
      "      occupation. Transport-moving           14.443441          0.002411   0.000725\n",
      "          race. Asian-Pac-Islander           13.422075          0.002241   0.000674\n",
      "                education. 1st-4th            9.983876          0.001667   0.000501\n",
      "                      workclass.NA            9.783321          0.001633   0.000491\n",
      "       native_country. Philippines            9.389676          0.001567   0.000471\n",
      "                 native_country.NA            7.530886          0.001257   0.000378\n",
      "         marital_status. Separated            5.486547          0.000916   0.000275\n",
      "           native_country. Germany            5.189872          0.000866   0.000260\n",
      "             education. Assoc-acdm            2.577040          0.000430   0.000129\n",
      "                     occupation.NA            2.456347          0.000410   0.000123\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        76636.554688          1.000000   0.133586\n",
      "                               age        68529.570313          0.894215   0.119455\n",
      "                            fnlwgt        65310.511719          0.852211   0.113844\n",
      "                      capital_loss        50214.597656          0.655230   0.087530\n",
      "                    hours_per_week        36571.046875          0.477201   0.063747\n",
      "marital_status. Married-civ-spouse        29687.312500          0.387378   0.051748\n",
      "              education. Bachelors        13140.328125          0.171463   0.022905\n",
      "        occupation. Prof-specialty        11978.555664          0.156303   0.020880\n",
      "            education. Prof-school        11171.603516          0.145774   0.019473\n",
      "       occupation. Exec-managerial        11097.804688          0.144811   0.019345\n",
      "---\n",
      "           native_country. Germany         1329.175903          0.017344   0.002317\n",
      "       native_country. Philippines         1327.736328          0.017325   0.002314\n",
      "         marital_status. Separated         1120.864624          0.014626   0.001954\n",
      "      occupation. Transport-moving         1082.017578          0.014119   0.001886\n",
      "       relationship. Not-in-family         1008.071594          0.013154   0.001757\n",
      "          race. Asian-Pac-Islander          844.689331          0.011022   0.001472\n",
      "                      workclass.NA          617.092773          0.008052   0.001076\n",
      "          marital_status. Divorced          360.565552          0.004705   0.000629\n",
      "             education. Assoc-acdm          139.246597          0.001817   0.000243\n",
      "                     occupation.NA          111.825424          0.001459   0.000195\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          452.000000          1.000000   0.232750\n",
      "                          age          434.000000          0.960177   0.223481\n",
      "               hours_per_week          174.000000          0.384956   0.089598\n",
      "                 capital_gain           87.000000          0.192478   0.044799\n",
      "                 capital_loss           64.000000          0.141593   0.032956\n",
      "         education. Bachelors           49.000000          0.108407   0.025232\n",
      "           education. HS-grad           48.000000          0.106195   0.024717\n",
      "                  sex. Female           41.000000          0.090708   0.021112\n",
      "           workclass. Private           41.000000          0.090708   0.021112\n",
      "   occupation. Prof-specialty           37.000000          0.081858   0.019053\n",
      "---\n",
      "occupation. Handlers-cleaners            3.000000          0.006637   0.001545\n",
      "     race. Amer-Indian-Eskimo            3.000000          0.006637   0.001545\n",
      "                occupation.NA            2.000000          0.004425   0.001030\n",
      "    marital_status. Separated            2.000000          0.004425   0.001030\n",
      "                 workclass.NA            2.000000          0.004425   0.001030\n",
      "           education. 1st-4th            2.000000          0.004425   0.001030\n",
      "  native_country. Philippines            2.000000          0.004425   0.001030\n",
      "            native_country.NA            2.000000          0.004425   0.001030\n",
      "      native_country. Germany            1.000000          0.002212   0.000515\n",
      "        education. Assoc-acdm            1.000000          0.002212   0.000515\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      " 2023-10-20 18:27:44  3.317 sec              20       0.28638          0.26140      0.93955         0.85327       4.14727                       0.12480         0.30182            0.28613        0.92423           0.81631         4.17436                         0.14850\n",
      " 2023-10-20 18:27:44  4.080 sec              25       0.28364          0.25605      0.94189         0.85790       4.14727                       0.12027         0.30141            0.28473        0.92493           0.81755         4.17436                         0.14435\n",
      " 2023-10-20 18:27:45  5.076 sec              30       0.28034          0.25028      0.94471         0.86381       4.14727                       0.11498         0.30235            0.28596        0.92423           0.81624         4.17436                         0.14251\n",
      " 2023-10-20 18:27:46  5.854 sec              35       0.27640          0.24409      0.94782         0.87078       4.14727                       0.11025         0.30262            0.28650        0.92409           0.81618         4.17436                         0.14742\n",
      "\n",
      "10-20 18:27:47.281 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2921560961432877, 0.28698529513624127, 0.28560762562574765, 0.28572945374824205]\n",
      "10-20 18:27:47.282 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.2921560961432877 --> 0.28560762562574765 (still improving).\n",
      "10-20 18:27:47.292 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_362\n",
      "10-20 18:27:47.301 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_362\n",
      "10-20 18:27:47.307 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_361\n",
      "10-20 18:27:47.307 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07591083\n",
      " RMSE: 0.2755192\n",
      " AUC: 0.9490177\n",
      " pr_auc: 0.87261754\n",
      " logloss: 0.2419782\n",
      " mean_per_class_error: 0.14695893\n",
      " default threshold: 0.41076475381851196\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18289  1456  0.0737  1,456 / 19,745\n",
      "     1   1388  4916  0.2202   1,388 / 6,304\n",
      "Totals  19677  6372  0.1092  2,844 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.18 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995413  4.132138         4.132138       1.000000  0.996651                  1.000000          0.996651      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.993393  4.132138         4.132138       1.000000  0.994410                  1.000000          0.995533      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.990186  4.132138         4.132138       1.000000  0.991928                  1.000000          0.994330      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.982938  4.132138         4.132138       1.000000  0.986960                  1.000000          0.992491      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.968965  4.100474         4.125796       0.992337  0.976851                  0.998465          0.989358      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.802764  3.852854         3.989377       0.932412  0.888126                  0.965451          0.938761      0.192576                 0.398953   285.285401       298.937731            0.394395\n",
      "      7                0.15014012         0.658452  3.208261         3.728539       0.776417  0.729652                  0.902327          0.868933      0.160850                 0.559803   220.826054       272.853903            0.540457\n",
      "      8                0.20000768         0.512845  2.582984         3.442920       0.625096  0.584642                  0.833205          0.798052      0.128807                 0.688610   158.298408       244.291986            0.644599\n",
      "      9                0.30004991         0.307474  1.704547         2.863314       0.412510  0.401448                  0.692938          0.665817      0.170527                 0.859137    70.454670       186.331386            0.737587\n",
      "     10                0.40001536         0.157387  0.864829         2.363885       0.209293  0.226859                  0.572073          0.556119      0.086453                 0.945590   -13.517074       136.388451            0.719761\n",
      "     11                0.50001919         0.072863  0.366420         1.964392       0.088676  0.110625                  0.475393          0.467020      0.036643                 0.982234   -63.358006        96.439159            0.636171\n",
      "     12                0.59998464         0.030370  0.122187         1.657456       0.029570  0.048345                  0.401113          0.397263      0.012214                 0.994448   -87.781311        65.745570            0.520404\n",
      "     13                0.69998848         0.013710  0.039656         1.426329       0.009597  0.020948                  0.345179          0.343501      0.003966                 0.998414   -96.034416        42.632876            0.393704\n",
      "     14                0.79999232         0.005738  0.012690         1.249615       0.003071  0.009279                  0.302414          0.301721      0.001269                 0.999683   -98.731013        24.961542            0.263446\n",
      "     15                0.89999616         0.001639  0.003172         1.111116       0.000768  0.003437                  0.268896          0.268577      0.000317                 1.000000   -99.682753        11.111585            0.131932\n",
      "     16                1.00000000         0.000148  0.000000         1.000000       0.000000  0.000872                  0.242005          0.241806      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.09402123\n",
      " RMSE: 0.30662882\n",
      " AUC: 0.9162157\n",
      " pr_auc: 0.803902\n",
      " logloss: 0.29550883\n",
      " mean_per_class_error: 0.18483138\n",
      " default threshold: 0.3761792778968811\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4408   567  0.1140  567 / 4,975\n",
      "     1   393  1144  0.2557  393 / 1,537\n",
      "Totals  4801  1711  0.1474  960 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 23.94 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995538  4.236825         4.236825       1.000000  0.996632                  1.000000          0.996632      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.993146  4.236825         4.236825       1.000000  0.994491                  1.000000          0.995570      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.989025  4.236825         4.236825       1.000000  0.991488                  1.000000          0.994216      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.980973  4.236825         4.236825       1.000000  0.985071                  1.000000          0.991939      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.964522  4.171643         4.223829       0.984615  0.973638                  0.996933          0.988290      0.041640                 0.211451  317.164306       322.382859            0.211250\n",
      "      6                0.10012285         0.777036  3.600002         3.911915       0.849693  0.868203                  0.923313          0.928246      0.180221                 0.391672  260.000160       291.191509            0.381622\n",
      "      7                0.15003071         0.635896  2.776750         3.534301       0.655385  0.704076                  0.834186          0.853676      0.138582                 0.530254  177.674991       253.430129            0.497691\n",
      "      8                0.20009214         0.499168  2.066427         3.167051       0.487730  0.564757                  0.747506          0.781391      0.103448                 0.633702  106.642691       216.705106            0.567571\n",
      "      9                0.30006143         0.314752  1.581488         2.638800       0.373272  0.399507                  0.622825          0.654161      0.158100                 0.791802   58.148767       163.880041            0.643662\n",
      "     10                0.40003071         0.165588  1.125915         2.260724       0.265745  0.235889                  0.533589          0.549633      0.112557                 0.904359   12.591509       126.072427            0.660138\n",
      "     11                0.50000000         0.071357  0.553195         1.919323       0.130568  0.112038                  0.453010          0.462141      0.055303                 0.959662  -44.680473        91.932336            0.601672\n",
      "     12                0.59996929         0.030261  0.208262         1.634219       0.049155  0.047912                  0.385718          0.393121      0.020820                 0.980481  -79.173825        63.421941            0.498069\n",
      "     13                0.69993857         0.013685  0.091115         1.413824       0.021505  0.021176                  0.333699          0.339997      0.009109                 0.989590  -90.888548        41.382422            0.379138\n",
      "     14                0.79990786         0.006079  0.078098         1.246891       0.018433  0.009374                  0.294298          0.298677      0.007807                 0.997398  -92.190184        24.689052            0.258503\n",
      "     15                0.89987715         0.001711  0.019525         1.110540       0.004608  0.003685                  0.262116          0.265906      0.001952                 0.999349  -98.047546        11.053979            0.130204\n",
      "     16                1.00000000         0.000220  0.006498         1.000000       0.001534  0.000914                  0.236026          0.239374      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6156.391602          1.000000   0.303440\n",
      "                      capital_gain         3636.613037          0.590705   0.179244\n",
      "                               age         1877.290283          0.304934   0.092529\n",
      "                            fnlwgt         1338.025757          0.217339   0.065949\n",
      "                      capital_loss         1292.731689          0.209982   0.063717\n",
      "                    hours_per_week         1041.649658          0.169198   0.051342\n",
      "        occupation. Prof-specialty          704.547363          0.114442   0.034726\n",
      "       occupation. Exec-managerial          592.613464          0.096260   0.029209\n",
      "              education. Bachelors          493.990784          0.080240   0.024348\n",
      "                education. Masters          257.099548          0.041761   0.012672\n",
      "---\n",
      "          race. Asian-Pac-Islander            8.950741          0.001454   0.000441\n",
      "                   education. 12th            8.412661          0.001366   0.000415\n",
      "           relationship. Unmarried            8.210783          0.001334   0.000405\n",
      "                       race. Other            7.845816          0.001274   0.000387\n",
      "            native_country. Canada            7.493516          0.001217   0.000369\n",
      "                 native_country.NA            6.556307          0.001065   0.000323\n",
      "         marital_status. Separated            5.387891          0.000875   0.000266\n",
      "             education. Assoc-acdm            5.182331          0.000842   0.000255\n",
      "             native_country. India            3.964354          0.000644   0.000195\n",
      "                      workclass.NA            1.734532          0.000282   0.000085\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        70373.843750          1.000000   0.122716\n",
      "                               age        69379.976563          0.985877   0.120983\n",
      "                            fnlwgt        62832.375000          0.892837   0.109565\n",
      "                      capital_loss        47993.925781          0.681985   0.083691\n",
      "                    hours_per_week        44076.898438          0.626325   0.076860\n",
      "marital_status. Married-civ-spouse        31134.197266          0.442411   0.054291\n",
      "              education. Bachelors        14003.851563          0.198992   0.024420\n",
      "                education. Masters        12407.238281          0.176305   0.021635\n",
      "            education. Prof-school        11531.617188          0.163862   0.020109\n",
      "        occupation. Prof-specialty        10864.369141          0.154381   0.018945\n",
      "---\n",
      "          occupation. Craft-repair         1348.597168          0.019163   0.002352\n",
      "                      workclass.NA         1306.653687          0.018567   0.002279\n",
      "                       race. White         1291.492554          0.018352   0.002252\n",
      "             native_country. India         1213.528198          0.017244   0.002116\n",
      "                       race. Other         1159.867310          0.016482   0.002023\n",
      "           relationship. Unmarried         1147.709106          0.016309   0.002001\n",
      "         marital_status. Separated         1106.033081          0.015717   0.001929\n",
      "                         sex. Male          999.216980          0.014199   0.001742\n",
      "              workclass. State-gov          940.941162          0.013371   0.001641\n",
      "           marital_status. Widowed          510.363953          0.007252   0.000890\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          501.000000          1.000000   0.251632\n",
      "                        age          426.000000          0.850299   0.213963\n",
      "             hours_per_week          183.000000          0.365269   0.091914\n",
      "               capital_gain           83.000000          0.165669   0.041688\n",
      "               capital_loss           67.000000          0.133733   0.033651\n",
      "                sex. Female           46.000000          0.091816   0.023104\n",
      " occupation. Prof-specialty           46.000000          0.091816   0.023104\n",
      "         workclass. Private           46.000000          0.091816   0.023104\n",
      "       education. Bachelors           41.000000          0.081836   0.020593\n",
      "         education. HS-grad           40.000000          0.079840   0.020090\n",
      "---\n",
      "     native_country. Canada            2.000000          0.003992   0.001005\n",
      "  marital_status. Separated            2.000000          0.003992   0.001005\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003992   0.001005\n",
      "      education. Assoc-acdm            2.000000          0.003992   0.001005\n",
      "          native_country.NA            2.000000          0.003992   0.001005\n",
      "                race. Other            1.000000          0.001996   0.000502\n",
      "            education. 12th            1.000000          0.001996   0.000502\n",
      "               workclass.NA            1.000000          0.001996   0.000502\n",
      "         education. 1st-4th            1.000000          0.001996   0.000502\n",
      "      native_country. India            1.000000          0.001996   0.000502\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      " 2023-10-20 18:27:43  3.142 sec              20       0.28407          0.25745      0.94233         0.85824       4.13214                       0.12166         0.30608            0.29567        0.91561           0.80478         4.23682                         0.14527\n",
      " 2023-10-20 18:27:44  4.063 sec              25       0.28125          0.25204      0.94445         0.86294       4.13214                       0.12070         0.30559            0.29433        0.91662           0.80552         4.23682                         0.14665\n",
      " 2023-10-20 18:27:46  5.164 sec              30       0.27734          0.24542      0.94749         0.86972       4.13214                       0.11597         0.30614            0.29465        0.91648           0.80501         4.23682                         0.14711\n",
      " 2023-10-20 18:27:46  5.945 sec              35       0.27552          0.24198      0.94902         0.87262       4.13214                       0.10918         0.30663            0.29551        0.91622           0.80390         4.23682                         0.14742\n",
      "\n",
      "10-20 18:27:47.313 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.30084679157968575, 0.29622004163067045, 0.2948837085583686, 0.2948290717389652]\n",
      "10-20 18:27:47.313 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.30084679157968575 --> 0.2948290717389652 (still improving).\n",
      "10-20 18:27:47.322 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:47.322) \n",
      "10-20 18:27:47.378 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:47.378) \n",
      "10-20 18:27:47.395 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.073 (Wall: 20-Oct 18:27:47.395) \n",
      "10-20 18:27:47.441 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:47.441) \n",
      "10-20 18:27:47.456 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:47.456) \n",
      "10-20 18:27:47.494 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:47.494) \n",
      "10-20 18:27:47.535 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.079 (Wall: 20-Oct 18:27:47.535) \n",
      "10-20 18:27:47.541 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_363\n",
      "10-20 18:27:47.546 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_364\n",
      "10-20 18:27:47.563 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_364\n",
      "10-20 18:27:47.563 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_363\n",
      "10-20 18:27:47.570 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07711097\n",
      " RMSE: 0.27768862\n",
      " AUC: 0.946887\n",
      " pr_auc: 0.8688306\n",
      " logloss: 0.24630755\n",
      " mean_per_class_error: 0.13889192\n",
      " default threshold: 0.37343844771385193\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17955  1783  0.0903  1,783 / 19,738\n",
      "     1   1183  5128  0.1875   1,183 / 6,311\n",
      "Totals  19138  6911  0.1139  2,966 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.21 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996469  4.127555         4.127555       1.000000  0.997404                  1.000000          0.997404      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.994483  4.127555         4.127555       1.000000  0.995615                  1.000000          0.996511      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.990940  4.127555         4.127555       1.000000  0.992967                  1.000000          0.995328      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.983164  4.127555         4.127555       1.000000  0.987589                  1.000000          0.993397      0.041198                 0.165109   312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.968676  4.064298         4.114884       0.984674  0.975942                  0.996930          0.989901      0.040723                 0.205831   306.429751       311.488413            0.205628\n",
      "      6                0.10004223         0.800529  3.851962         3.983423       0.933231  0.881888                  0.965081          0.935894      0.192679                 0.398511   285.196236       298.342325            0.393900\n",
      "      7                0.15002495         0.654910  3.189186         3.718813       0.772657  0.727022                  0.900972          0.866306      0.159404                 0.557915   218.918617       271.881304            0.538308\n",
      "      8                0.20000768         0.516669  2.494920         3.412957       0.604455  0.582914                  0.826871          0.795485      0.124703                 0.682618   149.492000       241.295724            0.636919\n",
      "      9                0.30001152         0.305840  1.728661         2.851525       0.418810  0.406293                  0.690851          0.665754      0.172873                 0.855490    72.866126       185.152524            0.733087\n",
      "     10                0.40001536         0.157724  0.860369         2.353736       0.208445  0.225802                  0.570250          0.555766      0.086040                 0.941531   -13.963056       135.373629            0.714659\n",
      "     11                0.50001919         0.072827  0.380274         1.959044       0.092131  0.110376                  0.474626          0.466688      0.038029                 0.979559   -61.972621        95.904379            0.632868\n",
      "     12                0.59998464         0.031462  0.133147         1.654825       0.032258  0.049813                  0.400921          0.397231      0.013310                 0.992870   -86.685306        65.482501            0.518505\n",
      "     13                0.69998848         0.014630  0.061794         1.427237       0.014971  0.021896                  0.345783          0.343609      0.006180                 0.999049   -93.820551        42.723674            0.394682\n",
      "     14                0.79999232         0.006350  0.006338         1.249616       0.001536  0.009981                  0.302750          0.301903      0.000634                 0.999683   -99.366210        24.961586            0.263540\n",
      "     15                0.89999616         0.002245  0.003169         1.111116       0.000768  0.004077                  0.269195          0.268810      0.000317                 1.000000   -99.683105        11.111585            0.131979\n",
      "     16                1.00000000         0.000220  0.000000         1.000000       0.000000  0.001271                  0.242274          0.242055      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.08845608\n",
      " RMSE: 0.29741567\n",
      " AUC: 0.925923\n",
      " pr_auc: 0.82177883\n",
      " logloss: 0.27907464\n",
      " mean_per_class_error: 0.1690403\n",
      " default threshold: 0.3267195522785187\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4382   600  0.1204  600 / 4,982\n",
      "     1   333  1197  0.2176  333 / 1,530\n",
      "Totals  4715  1797  0.1433  933 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.54 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996337  4.256209         4.256209       1.000000  0.997353                  1.000000          0.997353      0.043137                 0.043137  325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.994250  4.190729         4.223719       0.984615  0.995191                  0.992366          0.996280      0.041830                 0.084967  319.072901       322.371900            0.084767\n",
      "      3                0.03009828         0.990737  4.256209         4.234494       1.000000  0.992485                  0.994898          0.995022      0.042484                 0.127451  325.620915       323.449380            0.127250\n",
      "      4                0.04007985         0.982801  4.190729         4.223595       0.984615  0.987181                  0.992337          0.993069      0.041830                 0.169281  319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.966585  4.190729         4.217042       0.984615  0.975464                  0.990798          0.989559      0.041830                 0.211111  319.072901       321.704158            0.210509\n",
      "      6                0.10012285         0.784283  3.747031         3.982036       0.880368  0.874837                  0.935583          0.932198      0.187582                 0.398693  274.703076       298.203617            0.390262\n",
      "      7                0.15003071         0.633491  2.894222         3.620174       0.680000  0.705966                  0.850563          0.856942      0.144444                 0.543137  189.422222       262.017380            0.513832\n",
      "      8                0.20009214         0.491720  2.258663         3.279535       0.530675  0.562251                  0.770530          0.783212      0.113072                 0.656209  125.866314       227.953491            0.596193\n",
      "      9                0.30006143         0.284527  1.510268         2.690081       0.354839  0.380381                  0.632037          0.649004      0.150980                 0.807190   51.026776       169.008101            0.662870\n",
      "     10                0.40003071         0.152591  1.052611         2.280871       0.247312  0.216240                  0.535893          0.540854      0.105229                 0.912418    5.261087       128.087062            0.669745\n",
      "     11                0.50000000         0.069785  0.562264         1.937255       0.132104  0.107956                  0.455160          0.454301      0.056209                 0.968627  -43.773581        93.725490            0.612546\n",
      "     12                0.59996929         0.029864  0.169987         1.642786       0.039939  0.047037                  0.385974          0.386441      0.016993                 0.985621  -83.001315        64.278562            0.504087\n",
      "     13                0.69993857         0.014071  0.084993         1.420293       0.019969  0.020842                  0.333699          0.334224      0.008497                 0.994118  -91.500658        42.029270            0.384523\n",
      "     14                0.79990786         0.006348  0.045766         1.248510       0.010753  0.009740                  0.293338          0.293672      0.004575                 0.998693  -95.423431        24.850981            0.259833\n",
      "     15                0.89987715         0.001994  0.006538         1.110536       0.001536  0.003858                  0.260922          0.261476      0.000654                 0.999346  -99.346204        11.053648            0.130017\n",
      "     16                1.00000000         0.000235  0.006528         1.000000       0.001534  0.001172                  0.234951          0.235413      0.000654                 1.000000  -99.347207         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6128.334473          1.000000   0.305805\n",
      "                      capital_gain         3624.673828          0.591461   0.180872\n",
      "                               age         1877.490112          0.306362   0.093687\n",
      "                            fnlwgt         1333.491333          0.217594   0.066541\n",
      "                      capital_loss         1264.466187          0.206331   0.063097\n",
      "                    hours_per_week         1099.295166          0.179379   0.054855\n",
      "       occupation. Exec-managerial          618.404297          0.100909   0.030858\n",
      "        occupation. Prof-specialty          614.475037          0.100268   0.030662\n",
      "              education. Bachelors          462.062958          0.075398   0.023057\n",
      "                education. Masters          256.378052          0.041835   0.012793\n",
      "---\n",
      "              workclass. State-gov           13.081568          0.002135   0.000653\n",
      "         marital_status. Separated            9.593512          0.001565   0.000479\n",
      "           marital_status. Widowed            9.470652          0.001545   0.000473\n",
      "                 native_country.NA            6.232629          0.001017   0.000311\n",
      "           native_country. Germany            4.615104          0.000753   0.000230\n",
      "            native_country. Canada            4.357147          0.000711   0.000217\n",
      "                education. 1st-4th            4.297473          0.000701   0.000214\n",
      "                      workclass.NA            4.086454          0.000667   0.000204\n",
      "             native_country. India            3.007887          0.000491   0.000150\n",
      "          race. Amer-Indian-Eskimo            2.552530          0.000417   0.000127\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        75466.945313          1.000000   0.131978\n",
      "                               age        68620.203125          0.909275   0.120004\n",
      "                            fnlwgt        55553.421875          0.736129   0.097153\n",
      "                      capital_loss        49170.789063          0.651554   0.085991\n",
      "                    hours_per_week        37249.140625          0.493582   0.065142\n",
      "marital_status. Married-civ-spouse        33202.601563          0.439962   0.058065\n",
      "                education. Masters        13786.879883          0.182688   0.024111\n",
      "              education. Bachelors        13292.519531          0.176137   0.023246\n",
      "       occupation. Exec-managerial        12328.195313          0.163359   0.021560\n",
      "            education. Prof-school        11573.013672          0.153352   0.020239\n",
      "---\n",
      "          race. Amer-Indian-Eskimo         1275.855103          0.016906   0.002231\n",
      "             native_country. India         1254.505981          0.016623   0.002194\n",
      "                education. 1st-4th         1250.632324          0.016572   0.002187\n",
      "           native_country. Germany         1218.200195          0.016142   0.002130\n",
      "                 native_country.NA         1201.647095          0.015923   0.002101\n",
      "         marital_status. Separated         1175.023315          0.015570   0.002055\n",
      "                      workclass.NA          866.905518          0.011487   0.001516\n",
      "                         sex. Male          851.890076          0.011288   0.001490\n",
      "          marital_status. Divorced          720.736694          0.009550   0.001260\n",
      "             relationship. Husband          687.584595          0.009111   0.001202\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          507.000000          1.000000   0.250742\n",
      "                        age          429.000000          0.846154   0.212166\n",
      "             hours_per_week          181.000000          0.357002   0.089515\n",
      "               capital_gain           91.000000          0.179487   0.045005\n",
      "               capital_loss           68.000000          0.134122   0.033630\n",
      "         workclass. Private           53.000000          0.104536   0.026212\n",
      "         education. HS-grad           44.000000          0.086785   0.021761\n",
      "       education. Bachelors           43.000000          0.084813   0.021266\n",
      " occupation. Prof-specialty           42.000000          0.082840   0.020772\n",
      "                sex. Female           35.000000          0.069034   0.017310\n",
      "---\n",
      "    marital_status. Widowed            2.000000          0.003945   0.000989\n",
      "            education. 12th            2.000000          0.003945   0.000989\n",
      "  marital_status. Separated            2.000000          0.003945   0.000989\n",
      "          native_country.NA            2.000000          0.003945   0.000989\n",
      "     native_country. Canada            1.000000          0.001972   0.000495\n",
      "               workclass.NA            1.000000          0.001972   0.000495\n",
      "         education. 1st-4th            1.000000          0.001972   0.000495\n",
      "      native_country. India            1.000000          0.001972   0.000495\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.001972   0.000495\n",
      "    native_country. Germany            1.000000          0.001972   0.000495\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      " 2023-10-20 18:27:45  4.269 sec              25       0.28404          0.25689      0.94168         0.85767       4.12756                       0.12000         0.29713            0.27903        0.92592           0.82214         4.25621                         0.14097\n",
      " 2023-10-20 18:27:46  5.267 sec              30       0.28109          0.25176      0.94415         0.86293       4.12756                       0.11666         0.29695            0.27845        0.92622           0.82274         4.25621                         0.12454\n",
      " 2023-10-20 18:27:47  6.306 sec              35       0.27769          0.24631      0.94689         0.86883       4.12756                       0.11386         0.29742            0.27907        0.92592           0.82178         4.25621                         0.14327\n",
      "\n",
      "10-20 18:27:47.584 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2864032351307502, 0.28089149436718375, 0.2793548586952809, 0.278850153484192]\n",
      "10-20 18:27:47.584 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.2864032351307502 --> 0.278850153484192 (still improving).\n",
      "10-20 18:27:47.569 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.0766335\n",
      " RMSE: 0.27682757\n",
      " AUC: 0.9474251\n",
      " pr_auc: 0.86726946\n",
      " logloss: 0.2442635\n",
      " mean_per_class_error: 0.15519972\n",
      " default threshold: 0.4240780472755432\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18454  1379  0.0695  1,379 / 19,833\n",
      "     1   1497  4718  0.2409   1,497 / 6,215\n",
      "Totals  19951  6097  0.1104  2,876 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.91 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.995728  4.191150         4.191150       1.000000  0.996882                  1.000000          0.996882      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.993259  4.191150         4.191150       1.000000  0.994491                  1.000000          0.995689      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.988657  4.191150         4.191150       1.000000  0.991341                  1.000000          0.994238      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.979467  4.158911         4.183106       0.992308  0.984674                  0.998081          0.991851      0.041512                 0.167337   315.891082       318.310601            0.167236\n",
      "      5                0.05002303         0.962717  4.175092         4.181501       0.996169  0.971686                  0.997698          0.987812      0.041834                 0.209171   317.509239       318.150083            0.209020\n",
      "      6                0.10000768         0.779772  3.888564         4.035088       0.927803  0.871771                  0.962764          0.929814      0.194368                 0.403540   288.856354       303.508841            0.398649\n",
      "      7                0.15003071         0.640543  3.219756         3.763241       0.768227  0.707599                  0.897902          0.855723      0.161062                 0.564602   221.975564       276.324127            0.544484\n",
      "      8                0.20001536         0.507425  2.578427         3.467151       0.615207  0.574598                  0.827255          0.785469      0.128882                 0.693484   157.842665       246.715133            0.648105\n",
      "      9                0.30002303         0.305143  1.623367         2.852557       0.387332  0.396156                  0.680614          0.655698      0.162349                 0.855833    62.336691       185.255652            0.729982\n",
      "     10                0.39999232         0.158392  0.898104         2.364084       0.214286  0.228611                  0.564066          0.548957      0.089783                 0.945615   -10.189633       136.408400            0.716603\n",
      "     11                0.50000000         0.070985  0.366826         1.964602       0.087524  0.110615                  0.468750          0.461282      0.036685                 0.982301   -63.317378        96.460177            0.633438\n",
      "     12                0.60000768         0.030580  0.122275         1.657528       0.029175  0.048341                  0.395483          0.392454      0.012228                 0.994529   -87.772459        65.752773            0.518152\n",
      "     13                0.69997697         0.013902  0.041847         1.426780       0.009985  0.021056                  0.340427          0.339411      0.004183                 0.998713   -95.815288        42.677951            0.392350\n",
      "     14                0.79998464         0.006222  0.008044         1.249421       0.001919  0.009574                  0.298109          0.298178      0.000805                 0.999517   -99.195557        24.942060            0.262060\n",
      "     15                0.89999232         0.002273  0.004827         1.111121       0.001152  0.004048                  0.265111          0.265494      0.000483                 1.000000   -99.517334        11.112059            0.131347\n",
      "     16                1.00000000         0.000220  0.000000         1.000000       0.000000  0.001267                  0.238598          0.239069      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09015094\n",
      " RMSE: 0.30025145\n",
      " AUC: 0.92732096\n",
      " pr_auc: 0.83485425\n",
      " logloss: 0.28413764\n",
      " mean_per_class_error: 0.17251754\n",
      " default threshold: 0.3578784465789795\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4388   499  0.1021  499 / 4,887\n",
      "     1   395  1231  0.2429  395 / 1,626\n",
      "Totals  4783  1730  0.1373  894 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.04 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.995634  4.005535         4.005535       1.000000  0.996624                  1.000000          0.996624      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.993140  4.005535         4.005535       1.000000  0.994495                  1.000000          0.995567      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.988976  4.005535         4.005535       1.000000  0.991144                  1.000000          0.994100      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.979842  4.005535         4.005535       1.000000  0.985071                  1.000000          0.991852      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.966486  4.005535         4.005535       1.000000  0.973311                  1.000000          0.988155      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.789584  3.501771         3.753653       0.874233  0.882088                  0.937117          0.935121      0.175277                 0.375769   250.177144       275.365325            0.367379\n",
      "      7                0.15000768         0.644704  2.994908         3.501256       0.747692  0.716357                  0.874104          0.862349      0.149446                 0.525215   199.490775       250.125582            0.500046\n",
      "      8                0.20006142         0.508591  2.383662         3.221643       0.595092  0.576363                  0.804298          0.790798      0.119311                 0.644526   138.366197       222.164293            0.592347\n",
      "      9                0.30001535         0.302819  1.624364         2.689489       0.405530  0.395377                  0.671443          0.659058      0.162362                 0.806888    62.436445       168.948925            0.675519\n",
      "     10                0.39996929         0.159999  1.009075         2.269547       0.251920  0.229220                  0.566603          0.551640      0.100861                 0.907749     0.907488       126.954693            0.676728\n",
      "     11                0.50007677         0.074083  0.522194         1.919754       0.130368  0.111737                  0.479275          0.463578      0.052276                 0.960025   -47.780601        91.975444            0.612981\n",
      "     12                0.60003071         0.030858  0.258422         1.643007       0.064516  0.048950                  0.410184          0.394509      0.025830                 0.985855   -74.157838        64.300734            0.514195\n",
      "     13                0.69998465         0.014215  0.086141         1.420695       0.021505  0.021139                  0.354683          0.341194      0.008610                 0.994465   -91.385946        42.069537            0.392460\n",
      "     14                0.79993858         0.006643  0.043070         1.248558       0.010753  0.009894                  0.311708          0.299797      0.004305                 0.998770   -95.692973        24.855834            0.264986\n",
      "     15                0.89989252         0.002437  0.012306         1.111244       0.003072  0.004342                  0.277427          0.266980      0.001230                 1.000000   -98.769421        11.124382            0.133415\n",
      "     16                1.00000000         0.000185  0.000000         1.000000       0.000000  0.001309                  0.249655          0.240384      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5147.806641          1.000000   0.257735\n",
      "                      capital_gain         3698.044189          0.718373   0.185150\n",
      "                               age         1879.997192          0.365204   0.094126\n",
      "                            fnlwgt         1323.647827          0.257129   0.066271\n",
      "                      capital_loss         1270.286621          0.246763   0.063599\n",
      "                    hours_per_week         1190.384277          0.231241   0.059599\n",
      "     marital_status. Never-married          721.847473          0.140224   0.036141\n",
      "        occupation. Prof-specialty          536.572083          0.104233   0.026864\n",
      "       occupation. Exec-managerial          524.005432          0.101792   0.026235\n",
      "              education. Bachelors          387.818970          0.075337   0.019417\n",
      "---\n",
      "                   education. 12th           13.833382          0.002687   0.000693\n",
      "                education. 1st-4th           13.181145          0.002561   0.000660\n",
      "           marital_status. Widowed           10.492587          0.002038   0.000525\n",
      "         marital_status. Separated           10.034459          0.001949   0.000502\n",
      "          race. Amer-Indian-Eskimo            8.193613          0.001592   0.000410\n",
      "       native_country. Puerto-Rico            7.210544          0.001401   0.000361\n",
      "             education. Assoc-acdm            5.504598          0.001069   0.000276\n",
      "                 native_country.NA            3.842378          0.000746   0.000192\n",
      "                      workclass.NA            2.801810          0.000544   0.000140\n",
      "             native_country. India            2.298777          0.000447   0.000115\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        76022.593750          1.000000   0.132568\n",
      "                               age        63761.000000          0.838711   0.111186\n",
      "                            fnlwgt        49713.863281          0.653935   0.086691\n",
      "                    hours_per_week        48636.953125          0.639770   0.084813\n",
      "                      capital_loss        43341.781250          0.570117   0.075579\n",
      "marital_status. Married-civ-spouse        27992.697266          0.368215   0.048814\n",
      "              education. Bachelors        12596.903320          0.165699   0.021966\n",
      "        occupation. Prof-specialty        12019.430664          0.158103   0.020959\n",
      "       occupation. Exec-managerial        11793.824219          0.155136   0.020566\n",
      "              education. Doctorate        11636.661133          0.153068   0.020292\n",
      "---\n",
      "          race. Asian-Pac-Islander         1598.284668          0.021024   0.002787\n",
      "       native_country. Puerto-Rico         1487.620605          0.019568   0.002594\n",
      "                       race. Black         1320.496826          0.017370   0.002303\n",
      "                      workclass.NA         1260.344727          0.016579   0.002198\n",
      "           relationship. Unmarried         1252.524902          0.016476   0.002184\n",
      "                         sex. Male         1114.210205          0.014656   0.001943\n",
      "             relationship. Husband          869.143188          0.011433   0.001516\n",
      "             education. Assoc-acdm          806.074280          0.010603   0.001406\n",
      "                 native_country.NA          145.587036          0.001915   0.000254\n",
      "             native_country. India           35.474113          0.000467   0.000062\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          501.000000          1.000000   0.242850\n",
      "                        age          431.000000          0.860279   0.208919\n",
      "             hours_per_week          223.000000          0.445110   0.108095\n",
      "               capital_gain           77.000000          0.153693   0.037324\n",
      "               capital_loss           70.000000          0.139721   0.033931\n",
      "         education. HS-grad           55.000000          0.109780   0.026660\n",
      "         workclass. Private           51.000000          0.101796   0.024721\n",
      " occupation. Prof-specialty           49.000000          0.097804   0.023752\n",
      "       education. Bachelors           44.000000          0.087824   0.021328\n",
      "    education. Some-college           41.000000          0.081836   0.019874\n",
      "---\n",
      "         education. 1st-4th            3.000000          0.005988   0.001454\n",
      "native_country. Philippines            3.000000          0.005988   0.001454\n",
      "         education. 5th-6th            3.000000          0.005988   0.001454\n",
      "  marital_status. Separated            2.000000          0.003992   0.000969\n",
      "               workclass.NA            2.000000          0.003992   0.000969\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003992   0.000969\n",
      "      education. Assoc-acdm            2.000000          0.003992   0.000969\n",
      "      native_country. India            1.000000          0.001996   0.000485\n",
      "native_country. Puerto-Rico            1.000000          0.001996   0.000485\n",
      "          native_country.NA            1.000000          0.001996   0.000485\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      " 2023-10-20 18:27:44  3.876 sec              25       0.28313          0.25490      0.94227         0.85560       4.19115                       0.12024         0.29943            0.28298        0.92811           0.83677         4.00554                         0.13005\n",
      " 2023-10-20 18:27:46  5.162 sec              30       0.27988          0.24913      0.94497         0.86145       4.19115                       0.11582         0.29938            0.28309        0.92789           0.83651         4.00554                         0.13143\n",
      " 2023-10-20 18:27:46  6.081 sec              35       0.27683          0.24426      0.94743         0.86727       4.19115                       0.11041         0.30025            0.28414        0.92732           0.83485         4.00554                         0.13726\n",
      "\n",
      "10-20 18:27:47.584 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2925293825647188, 0.2861294133601945, 0.28373624136936404, 0.28340023124948904]\n",
      "10-20 18:27:47.584 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2925293825647188 --> 0.28340023124948904 (still improving).\n",
      "10-20 18:27:47.596 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.102 (Wall: 20-Oct 18:27:47.596) \n",
      "10-20 18:27:47.617 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:47.617) \n",
      "█10-20 18:27:47.683 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.099 (Wall: 20-Oct 18:27:47.683) \n",
      "10-20 18:27:47.684 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.100 (Wall: 20-Oct 18:27:47.684) \n",
      "10-20 18:27:47.684 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.088 (Wall: 20-Oct 18:27:47.684) \n",
      "10-20 18:27:47.717 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:47.717) \n",
      "10-20 18:27:47.761 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:47.761) \n",
      "10-20 18:27:47.800 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:47.800) \n",
      "10-20 18:27:47.811 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_365\n",
      "10-20 18:27:47.833 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_365\n",
      "10-20 18:27:47.840 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:47.840) \n",
      "10-20 18:27:47.841 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:47.841) \n",
      "10-20 18:27:47.874 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:47.874) \n",
      "10-20 18:27:47.904 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:47.904) \n",
      "10-20 18:27:47.969 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:47.969) \n",
      "10-20 18:27:48.045 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_366\n",
      "10-20 18:27:48.088 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_366\n",
      "10-20 18:27:48.128 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_367\n",
      "10-20 18:27:48.145 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_367\n",
      "10-20 18:27:48.215 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_368\n",
      "10-20 18:27:48.235 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:48.240 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_368\n",
      "10-20 18:27:48.387 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_369\n",
      "10-20 18:27:48.396 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_370\n",
      "10-20 18:27:48.404 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_369\n",
      "10-20 18:27:48.404 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_370\n",
      "10-20 18:27:48.411 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07617121\n",
      " RMSE: 0.27599132\n",
      " AUC: 0.9482682\n",
      " pr_auc: 0.8716458\n",
      " logloss: 0.24322748\n",
      " mean_per_class_error: 0.13579834\n",
      " default threshold: 0.36969417333602905\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17927  1811  0.0918  1,811 / 19,738\n",
      "     1   1135  5176  0.1798   1,135 / 6,311\n",
      "Totals  19062  6987  0.1131  2,946 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.28 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.997156  4.127555         4.127555       1.000000  0.997931                  1.000000          0.997931      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.995378  4.127555         4.127555       1.000000  0.996414                  1.000000          0.997174      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.992155  4.127555         4.127555       1.000000  0.993988                  1.000000          0.996111      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.984337  4.127555         4.127555       1.000000  0.988832                  1.000000          0.994295      0.041198                 0.165109   312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.971360  4.111741         4.124387       0.996169  0.978180                  0.999233          0.991067      0.041198                 0.206306   311.174068       312.438733            0.206256\n",
      "      6                0.10000384         0.804954  3.861261         3.992875       0.935484  0.886774                  0.967370          0.938940      0.192996                 0.399303   286.126119       299.287476            0.394996\n",
      "      7                0.15002495         0.662678  3.199410         3.728319       0.775134  0.735223                  0.903275          0.871017      0.160038                 0.559341   219.940953       272.831867            0.540190\n",
      "      8                0.20004607         0.523479  2.540521         3.431312       0.615503  0.591213                  0.831318          0.801053      0.127080                 0.686421   154.052123       243.131233            0.641887\n",
      "      9                0.30001152         0.308311  1.716644         2.859976       0.415899  0.409009                  0.692898          0.670422      0.171605                 0.858026    71.664444       185.997577            0.736433\n",
      "     10                0.40001536         0.154666  0.860369         2.360074       0.208445  0.225598                  0.571785          0.559216      0.086040                 0.944066   -13.963056       136.007419            0.718005\n",
      "     11                0.50001919         0.071144  0.370767         1.962213       0.089827  0.107641                  0.475393          0.468901      0.037078                 0.981144   -62.923306        96.221274            0.634959\n",
      "     12                0.59998464         0.030452  0.131562         1.657202       0.031874  0.048079                  0.401497          0.398786      0.013152                 0.994296   -86.843815        65.720187            0.520387\n",
      "     13                0.69998848         0.013752  0.045950         1.427010       0.011132  0.020919                  0.345728          0.344802      0.004595                 0.998891   -95.405025        42.701037            0.394473\n",
      "     14                0.79999232         0.005833  0.009507         1.249814       0.002303  0.009345                  0.302798          0.302868      0.000951                 0.999842   -99.049316        24.981393            0.263749\n",
      "     15                0.89999616         0.001939  0.001584         1.111116       0.000384  0.003636                  0.269195          0.269619      0.000158                 1.000000   -99.841553        11.111585            0.131979\n",
      "     16                1.00000000         0.000109  0.000000         1.000000       0.000000  0.001044                  0.242274          0.242760      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.08866243\n",
      " RMSE: 0.29776236\n",
      " AUC: 0.9256859\n",
      " pr_auc: 0.8213788\n",
      " logloss: 0.27961716\n",
      " mean_per_class_error: 0.1762755\n",
      " default threshold: 0.37879857420921326\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4489   493  0.0990  493 / 4,982\n",
      "     1   388  1142  0.2536  388 / 1,530\n",
      "Totals  4877  1635  0.1353  881 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.56 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996979  4.256209         4.256209       1.000000  0.997896                  1.000000          0.997896      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.994888  4.256209         4.256209       1.000000  0.996052                  1.000000          0.996981      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.991522  4.190729         4.234494       0.984615  0.993589                  0.994898          0.995856      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.984326  4.190729         4.223595       0.984615  0.988379                  0.992337          0.993994      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.968538  4.190729         4.217042       0.984615  0.977155                  0.990798          0.990637      0.041830                 0.211111   319.072901       321.704158            0.210509\n",
      "      6                0.10012285         0.788312  3.773142         3.995092       0.886503  0.879499                  0.938650          0.935068      0.188889                 0.400000   277.314247       299.509202            0.391971\n",
      "      7                0.15003071         0.639624  2.763262         3.585323       0.649231  0.712377                  0.842375          0.860990      0.137908                 0.537908   176.326194       258.532255            0.506997\n",
      "      8                0.20009214         0.501123  2.402278         3.289334       0.564417  0.566368                  0.772832          0.787278      0.120261                 0.658170   140.227756       228.933432            0.598756\n",
      "      9                0.30006143         0.289230  1.523344         2.700972       0.357911  0.383030                  0.634596          0.652597      0.152288                 0.810458    52.334367       170.097203            0.667142\n",
      "     10                0.40003071         0.151132  1.026459         2.282504       0.241167  0.214079                  0.536276          0.543010      0.102614                 0.913072     2.645904       128.250448            0.670599\n",
      "     11                0.50000000         0.068735  0.529574         1.932026       0.124424  0.105138                  0.453931          0.455462      0.052941                 0.966013   -47.042559        93.202614            0.609128\n",
      "     12                0.59996929         0.028417  0.196139         1.642786       0.046083  0.045181                  0.385974          0.387100      0.019608                 0.985621   -80.386133        64.278562            0.504087\n",
      "     13                0.69993857         0.013057  0.078455         1.419359       0.018433  0.019790                  0.333480          0.334638      0.007843                 0.993464   -92.154453        41.935891            0.383669\n",
      "     14                0.79990786         0.005921  0.052304         1.248510       0.012289  0.009053                  0.293338          0.293948      0.005229                 0.998693   -94.769635        24.850981            0.259833\n",
      "     15                0.89987715         0.001758  0.013076         1.111263       0.003072  0.003459                  0.261092          0.261677      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000150  0.000000         1.000000       0.000000  0.000953                  0.234951          0.235573      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6135.072266          1.000000   0.299675\n",
      "                      capital_gain         3648.164307          0.594641   0.178199\n",
      "                               age         1946.514648          0.317277   0.095080\n",
      "                            fnlwgt         1435.230225          0.233939   0.070106\n",
      "                      capital_loss         1303.193970          0.212417   0.063656\n",
      "                    hours_per_week         1144.991943          0.186631   0.055929\n",
      "       occupation. Exec-managerial          629.198303          0.102558   0.030734\n",
      "        occupation. Prof-specialty          617.178955          0.100598   0.030147\n",
      "              education. Bachelors          464.417480          0.075699   0.022685\n",
      "                education. Masters          256.378052          0.041789   0.012523\n",
      "---\n",
      "                   education. 12th           13.561639          0.002211   0.000662\n",
      "           marital_status. Widowed           12.387218          0.002019   0.000605\n",
      "         marital_status. Separated            9.593512          0.001564   0.000469\n",
      "           native_country. Germany            7.056383          0.001150   0.000345\n",
      "                 native_country.NA            6.232629          0.001016   0.000304\n",
      "            native_country. Canada            4.357147          0.000710   0.000213\n",
      "          race. Amer-Indian-Eskimo            4.338013          0.000707   0.000212\n",
      "                education. 1st-4th            4.297473          0.000700   0.000210\n",
      "                      workclass.NA            4.086454          0.000666   0.000200\n",
      "             native_country. India            3.007887          0.000490   0.000147\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        81479.375000          1.000000   0.128127\n",
      "                               age        74677.976563          0.916526   0.117432\n",
      "                            fnlwgt        64561.425781          0.792365   0.101524\n",
      "                      capital_loss        59024.921875          0.724415   0.092818\n",
      "                    hours_per_week        43124.410156          0.529268   0.067814\n",
      "marital_status. Married-civ-spouse        33853.070313          0.415480   0.053234\n",
      "                education. Masters        13786.879883          0.169207   0.021680\n",
      "              education. Bachelors        13338.147461          0.163700   0.020974\n",
      "       occupation. Exec-managerial        13216.042969          0.162201   0.020782\n",
      "            education. Prof-school        12040.374023          0.147772   0.018934\n",
      "---\n",
      "                       race. Black         2132.069336          0.026167   0.003353\n",
      "                       race. White         1483.518188          0.018207   0.002333\n",
      "            native_country. Canada         1373.848999          0.016861   0.002160\n",
      "             native_country. India         1254.505981          0.015397   0.001973\n",
      "                education. 1st-4th         1250.632324          0.015349   0.001967\n",
      "                 native_country.NA         1201.647095          0.014748   0.001890\n",
      "         marital_status. Separated         1175.023315          0.014421   0.001848\n",
      "                      workclass.NA          866.905518          0.010640   0.001363\n",
      "             relationship. Husband          759.628784          0.009323   0.001195\n",
      "          marital_status. Divorced          720.736694          0.008846   0.001133\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          543.000000          1.000000   0.245590\n",
      "                        age          471.000000          0.867403   0.213026\n",
      "             hours_per_week          203.000000          0.373849   0.091814\n",
      "               capital_gain           97.000000          0.178637   0.043872\n",
      "               capital_loss           77.000000          0.141805   0.034826\n",
      "         workclass. Private           59.000000          0.108656   0.026685\n",
      "         education. HS-grad           55.000000          0.101289   0.024876\n",
      "       education. Bachelors           45.000000          0.082873   0.020353\n",
      " occupation. Prof-specialty           44.000000          0.081031   0.019900\n",
      "occupation. Exec-managerial           38.000000          0.069982   0.017187\n",
      "---\n",
      "         education. 5th-6th            3.000000          0.005525   0.001357\n",
      "            education. 12th            2.000000          0.003683   0.000905\n",
      "  marital_status. Separated            2.000000          0.003683   0.000905\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003683   0.000905\n",
      "    native_country. Germany            2.000000          0.003683   0.000905\n",
      "          native_country.NA            2.000000          0.003683   0.000905\n",
      "     native_country. Canada            1.000000          0.001842   0.000452\n",
      "               workclass.NA            1.000000          0.001842   0.000452\n",
      "         education. 1st-4th            1.000000          0.001842   0.000452\n",
      "      native_country. India            1.000000          0.001842   0.000452\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      " 2023-10-20 18:27:45  4.269 sec              25       0.28404          0.25689      0.94168         0.85767       4.12756                       0.12000         0.29713            0.27903        0.92592           0.82214         4.25621                         0.14097\n",
      " 2023-10-20 18:27:46  5.267 sec              30       0.28109          0.25176      0.94415         0.86293       4.12756                       0.11666         0.29695            0.27845        0.92622           0.82274         4.25621                         0.12454\n",
      " 2023-10-20 18:27:47  6.306 sec              35       0.27769          0.24631      0.94689         0.86883       4.12756                       0.11386         0.29742            0.27907        0.92592           0.82178         4.25621                         0.14327\n",
      " 2023-10-20 18:27:47  7.027 sec              40       0.27599          0.24323      0.94827         0.87165       4.12756                       0.11309         0.29776            0.27962        0.92569           0.82138         4.25621                         0.13529\n",
      "\n",
      "10-20 18:27:48.415 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28089149436718375, 0.2793548586952809, 0.278850153484192, 0.2790458919004084]\n",
      "10-20 18:27:48.415 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.28089149436718375 --> 0.278850153484192 (still improving).\n",
      "10-20 18:27:48.417 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.075211234\n",
      " RMSE: 0.27424666\n",
      " AUC: 0.94938755\n",
      " pr_auc: 0.8742743\n",
      " logloss: 0.2404666\n",
      " mean_per_class_error: 0.1402808\n",
      " default threshold: 0.3872784674167633\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18093  1675  0.0847  1,675 / 19,768\n",
      "     1   1230  5051  0.1958   1,230 / 6,281\n",
      "Totals  19323  6726  0.1115  2,905 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.24 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996722  4.147270         4.147270       1.000000  0.997730                  1.000000          0.997730      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.994709  4.147270         4.147270       1.000000  0.995724                  1.000000          0.996729      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.991656  4.147270         4.147270       1.000000  0.993396                  1.000000          0.995617      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.984476  4.147270         4.147270       1.000000  0.988325                  1.000000          0.993797      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.968690  4.131380         4.144087       0.996169  0.977276                  0.999233          0.990488      0.041395                 0.207292   313.137962       314.408668            0.207241\n",
      "      6                0.10000384         0.806990  3.863777         4.003986       0.931644  0.891529                  0.965451          0.941027      0.193122                 0.400414   286.377723       300.398576            0.395861\n",
      "      7                0.15002495         0.658162  3.240154         3.749310       0.781274  0.731836                  0.904043          0.871279      0.162076                 0.562490   224.015379       274.930995            0.543520\n",
      "      8                0.20000768         0.516667  2.627878         3.469060       0.633641  0.587285                  0.836468          0.800308      0.131349                 0.693839   162.787817       246.905963            0.650739\n",
      "      9                0.30001152         0.305056  1.668460         2.868860       0.402303  0.404713                  0.691747          0.668443      0.166852                 0.860691    66.846007       186.885978            0.738827\n",
      "     10                0.40001536         0.157043  0.867663         2.368561       0.209213  0.226589                  0.571113          0.557980      0.086770                 0.947461   -13.233708       136.856056            0.721388\n",
      "     11                0.50001919         0.071811  0.359802         1.966809       0.086756  0.109509                  0.474242          0.468285      0.035982                 0.983442   -64.019850        96.680875            0.637024\n",
      "     12                0.59998464         0.030725  0.103522         1.656360       0.024962  0.048145                  0.399386          0.398284      0.010349                 0.993791   -89.647753        65.636039            0.518932\n",
      "     13                0.69998848         0.013559  0.049353         1.426775       0.011900  0.020879                  0.344028          0.344366      0.004936                 0.998726   -95.064670        42.677536            0.393658\n",
      "     14                0.79999232         0.005890  0.009552         1.249614       0.002303  0.009210                  0.301310          0.302470      0.000955                 0.999682   -99.044775        24.961397            0.263138\n",
      "     15                0.89999616         0.001840  0.003184         1.111116       0.000768  0.003642                  0.267915          0.269265      0.000318                 1.000000   -99.681592        11.111585            0.131779\n",
      "     16                1.00000000         0.000095  0.000000         1.000000       0.000000  0.000890                  0.241122          0.242427      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09199154\n",
      " RMSE: 0.30330107\n",
      " AUC: 0.92410576\n",
      " pr_auc: 0.8149832\n",
      " logloss: 0.2873129\n",
      " mean_per_class_error: 0.17311317\n",
      " default threshold: 0.3826788067817688\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4412   540  0.1090  540 / 4,952\n",
      "     1   370  1190  0.2372  370 / 1,560\n",
      "Totals  4782  1730  0.1397  910 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.55 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996658  4.174359         4.174359       1.000000  0.997741                  1.000000          0.997741      0.042308                 0.042308   317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.994774  4.174359         4.174359       1.000000  0.995753                  1.000000          0.996755      0.041667                 0.083974   317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.991510  4.110138         4.153061       0.984615  0.993263                  0.994898          0.995597      0.041026                 0.125000   311.013807       315.306122            0.124798\n",
      "      4                0.04007985         0.984531  4.174359         4.158365       1.000000  0.988489                  0.996169          0.993826      0.041667                 0.166667   317.435897       315.836526            0.166465\n",
      "      5                0.05006143         0.970651  4.110138         4.148749       0.984615  0.978377                  0.993865          0.990746      0.041026                 0.207692   311.013807       314.874941            0.207288\n",
      "      6                0.10012285         0.813158  3.508510         3.828630       0.840491  0.896044                  0.917178          0.943395      0.175641                 0.383333   250.851030       282.862986            0.372429\n",
      "      7                0.15003071         0.675150  2.825720         3.495011       0.676923  0.746302                  0.837257          0.877832      0.141026                 0.524359   182.571992       249.501089            0.492251\n",
      "      8                0.20009214         0.536016  2.215227         3.174819       0.530675  0.603144                  0.760553          0.809107      0.110897                 0.635256   121.522731       217.481945            0.572252\n",
      "      9                0.30006143         0.312294  1.724889         2.691757       0.413210  0.417712                  0.644831          0.678709      0.172436                 0.807692    72.488873       169.175655            0.667547\n",
      "     10                0.40003071         0.158256  1.077254         2.288286       0.258065  0.228123                  0.548177          0.566105      0.107692                 0.915385     7.725393       128.828584            0.677703\n",
      "     11                0.50000000         0.071595  0.487329         1.928205       0.116743  0.109397                  0.461916          0.474792      0.048718                 0.964103   -51.267084        92.820513            0.610306\n",
      "     12                0.59996929         0.029490  0.243665         1.647520       0.058372  0.046733                  0.394676          0.403467      0.024359                 0.988462   -75.633542        64.752023            0.510877\n",
      "     13                0.69993857         0.013336  0.083359         1.424118       0.019969  0.020353                  0.341158          0.348748      0.008333                 0.996795   -91.664107        42.411764            0.390373\n",
      "     14                0.79990786         0.005627  0.019237         1.248541       0.004608  0.009096                  0.299098          0.306300      0.001923                 0.998718   -98.076332        24.854123            0.261440\n",
      "     15                0.89987715         0.001891  0.012824         1.111263       0.003072  0.003563                  0.266212          0.272668      0.001282                 1.000000   -98.717555        11.126280            0.131664\n",
      "     16                1.00000000         0.000104  0.000000         1.000000       0.000000  0.000959                  0.239558          0.245464      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5993.524414          1.000000   0.293509\n",
      "                         capital_gain         3696.601563          0.616766   0.181026\n",
      "                                  age         2021.097046          0.337213   0.098975\n",
      "                               fnlwgt         1282.381592          0.213961   0.062799\n",
      "                         capital_loss         1269.141479          0.211752   0.062151\n",
      "                       hours_per_week         1058.528687          0.176612   0.051837\n",
      "           occupation. Prof-specialty          638.453247          0.106524   0.031266\n",
      "          occupation. Exec-managerial          584.601135          0.097539   0.028628\n",
      "                 education. Bachelors          476.784393          0.079550   0.023349\n",
      "                   education. HS-grad          247.871750          0.041357   0.012139\n",
      "---\n",
      "                   education. 1st-4th            9.983876          0.001666   0.000489\n",
      "                         workclass.NA            9.783321          0.001632   0.000479\n",
      "          native_country. Philippines            9.389676          0.001567   0.000460\n",
      "                    native_country.NA            7.530886          0.001257   0.000369\n",
      "            marital_status. Separated            5.486547          0.000915   0.000269\n",
      "              native_country. Germany            5.189872          0.000866   0.000254\n",
      "marital_status. Married-spouse-absent            3.083752          0.000515   0.000151\n",
      "                education. Assoc-acdm            2.577040          0.000430   0.000126\n",
      "                        occupation.NA            2.456347          0.000410   0.000120\n",
      "                native_country. India            1.801291          0.000301   0.000088\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        83410.187500          1.000000   0.131006\n",
      "                                  age        73964.351563          0.886754   0.116170\n",
      "                               fnlwgt        73691.828125          0.883487   0.115742\n",
      "                         capital_loss        53599.660156          0.642603   0.084185\n",
      "                       hours_per_week        43583.886719          0.522525   0.068454\n",
      "   marital_status. Married-civ-spouse        30550.263672          0.366265   0.047983\n",
      "                 education. Bachelors        13239.991211          0.158734   0.020795\n",
      "           occupation. Prof-specialty        12174.285156          0.145957   0.019121\n",
      "          occupation. Exec-managerial        12019.623047          0.144103   0.018878\n",
      "               education. Prof-school        11171.603516          0.133936   0.017546\n",
      "---\n",
      "            marital_status. Separated         1120.864624          0.013438   0.001760\n",
      "          relationship. Not-in-family         1103.010986          0.013224   0.001732\n",
      "                native_country. India         1092.687500          0.013100   0.001716\n",
      "         occupation. Transport-moving         1082.017578          0.012972   0.001699\n",
      "             race. Asian-Pac-Islander          844.689331          0.010127   0.001327\n",
      "marital_status. Married-spouse-absent          827.302551          0.009918   0.001299\n",
      "                         workclass.NA          617.092773          0.007398   0.000969\n",
      "             marital_status. Divorced          471.624146          0.005654   0.000741\n",
      "                education. Assoc-acdm          139.246597          0.001669   0.000219\n",
      "                        occupation.NA          111.825424          0.001341   0.000176\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                                  age          494.000000          1.000000   0.227231\n",
      "                               fnlwgt          491.000000          0.993927   0.225851\n",
      "                       hours_per_week          211.000000          0.427126   0.097056\n",
      "                         capital_gain           96.000000          0.194332   0.044158\n",
      "                         capital_loss           68.000000          0.137652   0.031279\n",
      "                   education. HS-grad           59.000000          0.119433   0.027139\n",
      "                 education. Bachelors           53.000000          0.107287   0.024379\n",
      "                   workclass. Private           46.000000          0.093117   0.021159\n",
      "                          sex. Female           43.000000          0.087045   0.019779\n",
      "           occupation. Prof-specialty           41.000000          0.082996   0.018859\n",
      "---\n",
      "                        occupation.NA            2.000000          0.004049   0.000920\n",
      "            marital_status. Separated            2.000000          0.004049   0.000920\n",
      "                         workclass.NA            2.000000          0.004049   0.000920\n",
      "                   education. 1st-4th            2.000000          0.004049   0.000920\n",
      "          native_country. Philippines            2.000000          0.004049   0.000920\n",
      "                    native_country.NA            2.000000          0.004049   0.000920\n",
      "marital_status. Married-spouse-absent            1.000000          0.002024   0.000460\n",
      "                native_country. India            1.000000          0.002024   0.000460\n",
      "              native_country. Germany            1.000000          0.002024   0.000460\n",
      "                education. Assoc-acdm            1.000000          0.002024   0.000460\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      " 2023-10-20 18:27:44  3.317 sec              20       0.28638          0.26140      0.93955         0.85327       4.14727                       0.12480         0.30182            0.28613        0.92423           0.81631         4.17436                         0.14850\n",
      " 2023-10-20 18:27:44  4.080 sec              25       0.28364          0.25605      0.94189         0.85790       4.14727                       0.12027         0.30141            0.28473        0.92493           0.81755         4.17436                         0.14435\n",
      " 2023-10-20 18:27:45  5.076 sec              30       0.28034          0.25028      0.94471         0.86381       4.14727                       0.11498         0.30235            0.28596        0.92423           0.81624         4.17436                         0.14251\n",
      " 2023-10-20 18:27:46  5.854 sec              35       0.27640          0.24409      0.94782         0.87078       4.14727                       0.11025         0.30262            0.28650        0.92409           0.81618         4.17436                         0.14742\n",
      " 2023-10-20 18:27:47  6.770 sec              40       0.27425          0.24047      0.94939         0.87427       4.14727                       0.11152         0.30330            0.28731        0.92411           0.81498         4.17436                         0.13974\n",
      "\n",
      "10-20 18:27:48.419 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28698529513624127, 0.28560762562574765, 0.28572945374824205, 0.2865896696206557]\n",
      "10-20 18:27:48.419 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.28698529513624127 --> 0.28560762562574765 (converged).\n",
      "10-20 18:27:48.420 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:48.420 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:48.465 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 41. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:48.465) \n",
      "10-20 18:27:48.520 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 42. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:48.520) \n",
      "10-20 18:27:48.523 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_372\n",
      "10-20 18:27:48.524 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_371\n",
      "10-20 18:27:48.540 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_371\n",
      "10-20 18:27:48.543 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_372\n",
      "█10-20 18:27:48.550 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07470644\n",
      " RMSE: 0.2733248\n",
      " AUC: 0.95065427\n",
      " pr_auc: 0.8763505\n",
      " logloss: 0.23844892\n",
      " mean_per_class_error: 0.14173655\n",
      " default threshold: 0.40445905923843384\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18229  1516  0.0768  1,516 / 19,745\n",
      "     1   1303  5001  0.2067   1,303 / 6,304\n",
      "Totals  19532  6517  0.1082  2,819 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.32 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996637  4.132138         4.132138       1.000000  0.997719                  1.000000          0.997719      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.994471  4.132138         4.132138       1.000000  0.995564                  1.000000          0.996643      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.991197  4.132138         4.132138       1.000000  0.992946                  1.000000          0.995409      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.984721  4.132138         4.132138       1.000000  0.988339                  1.000000          0.993645      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.972186  4.100474         4.125796       0.992337  0.978967                  0.998465          0.990705      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.807725  3.878243         4.002067       0.938556  0.891887                  0.968522          0.941315      0.193845                 0.400222   287.824350       300.206718            0.396069\n",
      "      7                0.15002495         0.666176  3.241017         3.748319       0.784344  0.736253                  0.907114          0.872943      0.162119                 0.562341   224.101717       274.831893            0.543957\n",
      "      8                0.20000768         0.520763  2.567511         3.453230       0.621352  0.592208                  0.835701          0.802786      0.128331                 0.690673   156.751145       245.323038            0.647320\n",
      "      9                0.30001152         0.313231  1.722650         2.876370       0.416891  0.408170                  0.696097          0.671248      0.172272                 0.862944    72.264960       187.637012            0.742661\n",
      "     10                0.40001536         0.158046  0.864497         2.373402       0.209213  0.229963                  0.574376          0.560926      0.086453                 0.949397   -13.550273       137.340191            0.724783\n",
      "     11                0.50001919         0.071022  0.345799         1.967881       0.083685  0.110455                  0.476238          0.470832      0.034581                 0.983978   -65.420109        96.788131            0.638473\n",
      "     12                0.59998464         0.029126  0.103145         1.657191       0.024962  0.046726                  0.401049          0.400170      0.010311                 0.994289   -89.685523        65.719131            0.520195\n",
      "     13                0.69998848         0.012448  0.046001         1.427009       0.011132  0.019569                  0.345344          0.345796      0.004600                 0.998890   -95.399923        42.700861            0.394331\n",
      "     14                0.79999232         0.004898  0.009517         1.249814       0.002303  0.008243                  0.302462          0.303600      0.000952                 0.999841   -99.048260        24.981371            0.263655\n",
      "     15                0.89999616         0.001219  0.001586         1.111116       0.000384  0.002808                  0.268896          0.270177      0.000159                 1.000000   -99.841377        11.111585            0.131932\n",
      "     16                1.00000000         0.000100  0.000000         1.000000       0.000000  0.000603                  0.242005          0.243218      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.0937506\n",
      " RMSE: 0.3061872\n",
      " AUC: 0.9168492\n",
      " pr_auc: 0.8052179\n",
      " logloss: 0.29464528\n",
      " mean_per_class_error: 0.18862928\n",
      " default threshold: 0.3924434185028076\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4422   553  0.1112  553 / 4,975\n",
      "     1   409  1128  0.2661  409 / 1,537\n",
      "Totals  4831  1681  0.1477  962 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996994  4.236825         4.236825       1.000000  0.997762                  1.000000          0.997762      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.994424  4.236825         4.236825       1.000000  0.995747                  1.000000          0.996762      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.990421  4.236825         4.236825       1.000000  0.992562                  1.000000          0.995370      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.981922  4.236825         4.236825       1.000000  0.986663                  1.000000          0.993201      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.966004  4.171643         4.223829       0.984615  0.976234                  0.996933          0.989818      0.041640                 0.211451  317.164306       322.382859            0.211250\n",
      "      6                0.10012285         0.783479  3.600002         3.911915       0.849693  0.869966                  0.923313          0.929892      0.180221                 0.391672  260.000160       291.191509            0.381622\n",
      "      7                0.15003071         0.636907  2.776750         3.534301       0.655385  0.709069                  0.834186          0.856435      0.138582                 0.530254  177.674991       253.430129            0.497691\n",
      "      8                0.20009214         0.507251  2.131409         3.183309       0.503067  0.571195                  0.751343          0.785070      0.106701                 0.636955  113.140889       218.330902            0.571829\n",
      "      9                0.30006143         0.322432  1.548947         2.638800       0.365591  0.408028                  0.622825          0.659454      0.154847                 0.791802   54.894677       163.880041            0.643662\n",
      "     10                0.40003071         0.168767  1.164964         2.270483       0.274962  0.241083                  0.535893          0.554901      0.116461                 0.908263   16.496417       127.048279            0.665248\n",
      "     11                0.50000000         0.069151  0.514146         1.919323       0.121352  0.112178                  0.453010          0.466384      0.051399                 0.959662  -48.585380        91.932336            0.601672\n",
      "     12                0.59996929         0.029202  0.208262         1.634219       0.049155  0.046663                  0.385718          0.396448      0.020820                 0.980481  -79.173825        63.421941            0.498069\n",
      "     13                0.69993857         0.012585  0.078098         1.411965       0.018433  0.020211                  0.333260          0.342712      0.007807                 0.988289  -92.190184        41.196515            0.377435\n",
      "     14                0.79990786         0.005188  0.078098         1.245264       0.018433  0.008326                  0.293914          0.300922      0.007807                 0.996096  -92.190184        24.526378            0.256800\n",
      "     15                0.89987715         0.001318  0.032541         1.110540       0.007680  0.003008                  0.262116          0.267826      0.003253                 0.999349  -96.745910        11.053979            0.130204\n",
      "     16                1.00000000         0.000147  0.006498         1.000000       0.001534  0.000637                  0.236026          0.241074      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6163.356934          1.000000   0.296997\n",
      "                      capital_gain         3669.610352          0.595392   0.176830\n",
      "                               age         1945.182861          0.315604   0.093734\n",
      "                            fnlwgt         1421.407715          0.230622   0.068494\n",
      "                      capital_loss         1314.417969          0.213263   0.063339\n",
      "                    hours_per_week         1108.287354          0.179819   0.053406\n",
      "        occupation. Prof-specialty          706.988708          0.114708   0.034068\n",
      "       occupation. Exec-managerial          596.897705          0.096846   0.028763\n",
      "              education. Bachelors          501.983185          0.081446   0.024189\n",
      "                education. Masters          257.099548          0.041714   0.012389\n",
      "---\n",
      "         marital_status. Separated           11.026274          0.001789   0.000531\n",
      "                education. 1st-4th            9.308963          0.001510   0.000449\n",
      "          race. Asian-Pac-Islander            8.950741          0.001452   0.000431\n",
      "                   education. 12th            8.412661          0.001365   0.000405\n",
      "                       race. Other            7.845816          0.001273   0.000378\n",
      "            native_country. Canada            7.493516          0.001216   0.000361\n",
      "                 native_country.NA            6.556307          0.001064   0.000316\n",
      "             education. Assoc-acdm            5.182331          0.000841   0.000250\n",
      "             native_country. India            3.964354          0.000643   0.000191\n",
      "                      workclass.NA            1.734532          0.000281   0.000084\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        78687.359375          1.000000   0.123628\n",
      "                               age        74515.507813          0.946982   0.117074\n",
      "                            fnlwgt        70957.523438          0.901765   0.111484\n",
      "                      capital_loss        55239.210938          0.702009   0.086788\n",
      "                    hours_per_week        49269.285156          0.626140   0.077409\n",
      "marital_status. Married-civ-spouse        31618.164063          0.401820   0.049676\n",
      "              education. Bachelors        14288.891602          0.181591   0.022450\n",
      "                education. Masters        12407.238281          0.157678   0.019493\n",
      "            education. Prof-school        11531.617188          0.146550   0.018118\n",
      "              education. Doctorate        11057.767578          0.140528   0.017373\n",
      "---\n",
      "                education. 1st-4th         1538.888184          0.019557   0.002418\n",
      "          race. Asian-Pac-Islander         1536.225098          0.019523   0.002414\n",
      "           relationship. Unmarried         1519.896484          0.019316   0.002388\n",
      "             education. Assoc-acdm         1489.014160          0.018923   0.002339\n",
      "                 native_country.NA         1437.563599          0.018269   0.002259\n",
      "                   education. 12th         1396.824707          0.017752   0.002195\n",
      "                      workclass.NA         1306.653687          0.016606   0.002053\n",
      "                       race. White         1291.492554          0.016413   0.002029\n",
      "             native_country. India         1213.528198          0.015422   0.001907\n",
      "                       race. Other         1159.867310          0.014740   0.001822\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          536.000000          1.000000   0.245197\n",
      "                        age          454.000000          0.847015   0.207685\n",
      "             hours_per_week          212.000000          0.395522   0.096981\n",
      "               capital_gain           94.000000          0.175373   0.043001\n",
      "               capital_loss           75.000000          0.139925   0.034309\n",
      "         workclass. Private           53.000000          0.098881   0.024245\n",
      "         education. HS-grad           50.000000          0.093284   0.022873\n",
      "                sex. Female           49.000000          0.091418   0.022415\n",
      " occupation. Prof-specialty           48.000000          0.089552   0.021958\n",
      "       education. Bachelors           46.000000          0.085821   0.021043\n",
      "---\n",
      "         education. 5th-6th            4.000000          0.007463   0.001830\n",
      "     native_country. Canada            2.000000          0.003731   0.000915\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003731   0.000915\n",
      "      education. Assoc-acdm            2.000000          0.003731   0.000915\n",
      "          native_country.NA            2.000000          0.003731   0.000915\n",
      "                race. Other            1.000000          0.001866   0.000457\n",
      "            education. 12th            1.000000          0.001866   0.000457\n",
      "               workclass.NA            1.000000          0.001866   0.000457\n",
      "         education. 1st-4th            1.000000          0.001866   0.000457\n",
      "      native_country. India            1.000000          0.001866   0.000457\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      " 2023-10-20 18:27:43  3.142 sec              20       0.28407          0.25745      0.94233         0.85824       4.13214                       0.12166         0.30608            0.29567        0.91561           0.80478         4.23682                         0.14527\n",
      " 2023-10-20 18:27:44  4.063 sec              25       0.28125          0.25204      0.94445         0.86294       4.13214                       0.12070         0.30559            0.29433        0.91662           0.80552         4.23682                         0.14665\n",
      " 2023-10-20 18:27:46  5.164 sec              30       0.27734          0.24542      0.94749         0.86972       4.13214                       0.11597         0.30614            0.29465        0.91648           0.80501         4.23682                         0.14711\n",
      " 2023-10-20 18:27:46  5.945 sec              35       0.27552          0.24198      0.94902         0.87262       4.13214                       0.10918         0.30663            0.29551        0.91622           0.80390         4.23682                         0.14742\n",
      " 2023-10-20 18:27:47  6.837 sec              40       0.27332          0.23845      0.95065         0.87635       4.13214                       0.10822         0.30619            0.29465        0.91685           0.80522         4.23682                         0.14773\n",
      "\n",
      "10-20 18:27:48.553 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29622004163067045, 0.2948837085583686, 0.2948290717389652, 0.29493560205105046]\n",
      "10-20 18:27:48.553 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.29622004163067045 --> 0.2948290717389652 (converged).\n",
      "10-20 18:27:48.553 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:48.553 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 40\n",
      "10-20 18:27:48.624 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 43. tree was built in 00:00:00.103 (Wall: 20-Oct 18:27:48.624) \n",
      "10-20 18:27:48.627 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.075662464\n",
      " RMSE: 0.2750681\n",
      " AUC: 0.9486998\n",
      " pr_auc: 0.8702583\n",
      " logloss: 0.24124092\n",
      " mean_per_class_error: 0.14469635\n",
      " default threshold: 0.38399288058280945\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18159  1674  0.0844  1,674 / 19,833\n",
      "     1   1274  4941  0.2050   1,274 / 6,215\n",
      "Totals  19433  6615  0.1132  2,948 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.86 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.996314  4.191150         4.191150       1.000000  0.997408                  1.000000          0.997408      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.993925  4.191150         4.191150       1.000000  0.995136                  1.000000          0.996274      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.989933  4.191150         4.191150       1.000000  0.992159                  1.000000          0.994901      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.982114  4.158911         4.183106       0.992308  0.986443                  0.998081          0.992790      0.041512                 0.167337   315.891082       318.310601            0.167236\n",
      "      5                0.05002303         0.967174  4.191150         4.184717       1.000000  0.975494                  0.998465          0.989326      0.041995                 0.209332   319.115044       318.471736            0.209231\n",
      "      6                0.10000768         0.786035  3.904659         4.044742       0.931644  0.877443                  0.965067          0.933406      0.195173                 0.404505   290.465859       304.474173            0.399917\n",
      "      7                0.15003071         0.646309  3.210106         3.766459       0.765925  0.714083                  0.898669          0.860280      0.160579                 0.565084   221.010602       276.645864            0.545118\n",
      "      8                0.20001536         0.508590  2.607398         3.476805       0.622120  0.577515                  0.829559          0.789616      0.130330                 0.695414   160.739774       247.680465            0.650640\n",
      "      9                0.30002303         0.302963  1.665198         2.872936       0.397313  0.396614                  0.685477          0.658615      0.166533                 0.861947    66.519797       187.293575            0.738012\n",
      "     10                0.39999232         0.155114  0.854647         2.368509       0.203917  0.225497                  0.565121          0.550367      0.085438                 0.947385   -14.535296       136.850886            0.718928\n",
      "     11                0.50000000         0.067971  0.357173         1.966211       0.085221  0.107040                  0.469134          0.461694      0.035720                 0.983105   -64.282710        96.621078            0.634494\n",
      "     12                0.60000768         0.028632  0.117449         1.658064       0.028023  0.045530                  0.395611          0.392329      0.011746                 0.994851   -88.255125        65.806406            0.518574\n",
      "     13                0.69997697         0.012328  0.041847         1.427239       0.009985  0.019202                  0.340536          0.339040      0.004183                 0.999035   -95.815288        42.723924            0.392772\n",
      "     14                0.79998464         0.005356  0.006436         1.249622       0.001536  0.008380                  0.298157          0.297704      0.000644                 0.999678   -99.356445        24.962173            0.262271\n",
      "     15                0.89999232         0.001786  0.003218         1.111121       0.000768  0.003360                  0.265111          0.264996      0.000322                 1.000000   -99.678223        11.112059            0.131347\n",
      "     16                1.00000000         0.000124  0.000000         1.000000       0.000000  0.000940                  0.238598          0.238588      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09006249\n",
      " RMSE: 0.30010414\n",
      " AUC: 0.9273888\n",
      " pr_auc: 0.83525944\n",
      " logloss: 0.28393528\n",
      " mean_per_class_error: 0.16018909\n",
      " default threshold: 0.3001163899898529\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4238   649  0.1328  649 / 4,887\n",
      "     1   305  1321  0.1876  305 / 1,626\n",
      "Totals  4543  1970  0.1465  954 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 24.01 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.996320  4.005535         4.005535       1.000000  0.997232                  1.000000          0.997232      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.994020  4.005535         4.005535       1.000000  0.995126                  1.000000          0.996187      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.990452  4.005535         4.005535       1.000000  0.992297                  1.000000          0.994897      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.982344  4.005535         4.005535       1.000000  0.986676                  1.000000          0.992850      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.968314  4.005535         4.005535       1.000000  0.976715                  1.000000          0.989633      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.794901  3.538632         3.772084       0.883436  0.887467                  0.941718          0.938550      0.177122                 0.377614   253.863220       277.208363            0.369838\n",
      "      7                0.15000768         0.649074  2.933284         3.493056       0.732308  0.720720                  0.872057          0.866089      0.146371                 0.523985   193.328413       249.305616            0.498407\n",
      "      8                0.20006142         0.511210  2.420523         3.224717       0.604294  0.581692                  0.805065          0.794935      0.121156                 0.645141   142.052272       222.471702            0.593167\n",
      "      9                0.30001535         0.302990  1.618212         2.689489       0.403994  0.396152                  0.671443          0.662075      0.161747                 0.806888    61.821155       168.948925            0.675519\n",
      "     10                0.39996929         0.157137  0.996769         2.266472       0.248848  0.227399                  0.565835          0.553448      0.099631                 0.906519    -0.323091       126.647166            0.675089\n",
      "     11                0.50007677         0.071145  0.552911         1.923444       0.138037  0.108014                  0.480196          0.464279      0.055351                 0.961870   -44.708872        92.344391            0.615440\n",
      "     12                0.60003071         0.029160  0.239963         1.643007       0.059908  0.046483                  0.410184          0.394682      0.023985                 0.985855   -76.003707        64.300734            0.514195\n",
      "     13                0.69998465         0.012291  0.067682         1.418060       0.016897  0.019396                  0.354025          0.341093      0.006765                 0.992620   -93.231815        41.805957            0.390001\n",
      "     14                0.79993858         0.005572  0.061529         1.248558       0.015361  0.008613                  0.311708          0.299549      0.006150                 0.998770   -93.847104        24.855834            0.264986\n",
      "     15                0.89989252         0.001925  0.012306         1.111244       0.003072  0.003598                  0.277427          0.266677      0.001230                 1.000000   -98.769421        11.124382            0.133415\n",
      "     16                1.00000000         0.000131  0.000000         1.000000       0.000000  0.000979                  0.249655          0.240079      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5147.806641          1.000000   0.252125\n",
      "                      capital_gain         3711.622070          0.721010   0.181785\n",
      "                               age         1945.774780          0.377981   0.095299\n",
      "                            fnlwgt         1499.975830          0.291382   0.073465\n",
      "                      capital_loss         1312.059204          0.254877   0.064261\n",
      "                    hours_per_week         1228.343018          0.238615   0.060161\n",
      "     marital_status. Never-married          721.847473          0.140224   0.035354\n",
      "        occupation. Prof-specialty          542.417908          0.105369   0.026566\n",
      "       occupation. Exec-managerial          524.005432          0.101792   0.025664\n",
      "              education. Bachelors          387.818970          0.075337   0.018994\n",
      "---\n",
      "       native_country. Philippines           15.814737          0.003072   0.000775\n",
      "                   education. 12th           13.833382          0.002687   0.000678\n",
      "                education. 1st-4th           13.181145          0.002561   0.000646\n",
      "          race. Amer-Indian-Eskimo           12.538165          0.002436   0.000614\n",
      "         marital_status. Separated           10.034459          0.001949   0.000491\n",
      "                 native_country.NA            8.990942          0.001747   0.000440\n",
      "       native_country. Puerto-Rico            7.210544          0.001401   0.000353\n",
      "             education. Assoc-acdm            5.504598          0.001069   0.000270\n",
      "                      workclass.NA            2.801810          0.000544   0.000137\n",
      "             native_country. India            2.298777          0.000447   0.000113\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        79079.007813          1.000000   0.123979\n",
      "                            fnlwgt        69254.125000          0.875759   0.108575\n",
      "                               age        68841.820313          0.870545   0.107929\n",
      "                      capital_loss        54071.140625          0.683761   0.084772\n",
      "                    hours_per_week        53990.675781          0.682743   0.084646\n",
      "marital_status. Married-civ-spouse        27992.697266          0.353984   0.043886\n",
      "        occupation. Prof-specialty        13390.750977          0.169334   0.020994\n",
      "              education. Doctorate        13332.768555          0.168601   0.020903\n",
      "              education. Bachelors        12596.903320          0.159295   0.019749\n",
      "       occupation. Exec-managerial        11793.824219          0.149140   0.018490\n",
      "---\n",
      "              education. Assoc-voc         1800.567505          0.022769   0.002823\n",
      "                 native_country.NA         1752.922607          0.022167   0.002748\n",
      "          marital_status. Divorced         1745.460449          0.022072   0.002737\n",
      "     occupation. Machine-op-inspct         1633.048706          0.020651   0.002560\n",
      "       native_country. Puerto-Rico         1487.620605          0.018812   0.002332\n",
      "                       race. Black         1320.496826          0.016698   0.002070\n",
      "                      workclass.NA         1260.344727          0.015938   0.001976\n",
      "             relationship. Husband          958.264221          0.012118   0.001502\n",
      "             education. Assoc-acdm          806.074280          0.010193   0.001264\n",
      "             native_country. India           35.474113          0.000449   0.000056\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          572.000000          1.000000   0.255243\n",
      "                        age          463.000000          0.809441   0.206604\n",
      "             hours_per_week          238.000000          0.416084   0.106203\n",
      "               capital_loss           81.000000          0.141608   0.036145\n",
      "               capital_gain           81.000000          0.141608   0.036145\n",
      "         education. HS-grad           56.000000          0.097902   0.024989\n",
      "         workclass. Private           55.000000          0.096154   0.024543\n",
      " occupation. Prof-specialty           51.000000          0.089161   0.022758\n",
      "       education. Bachelors           44.000000          0.076923   0.019634\n",
      "    education. Some-college           42.000000          0.073427   0.018742\n",
      "---\n",
      "native_country. Philippines            4.000000          0.006993   0.001785\n",
      "            education. 12th            3.000000          0.005245   0.001339\n",
      "         education. 1st-4th            3.000000          0.005245   0.001339\n",
      "          native_country.NA            3.000000          0.005245   0.001339\n",
      "         education. 5th-6th            3.000000          0.005245   0.001339\n",
      "  marital_status. Separated            2.000000          0.003497   0.000892\n",
      "               workclass.NA            2.000000          0.003497   0.000892\n",
      "      education. Assoc-acdm            2.000000          0.003497   0.000892\n",
      "      native_country. India            1.000000          0.001748   0.000446\n",
      "native_country. Puerto-Rico            1.000000          0.001748   0.000446\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      " 2023-10-20 18:27:44  3.876 sec              25       0.28313          0.25490      0.94227         0.85560       4.19115                       0.12024         0.29943            0.28298        0.92811           0.83677         4.00554                         0.13005\n",
      " 2023-10-20 18:27:46  5.162 sec              30       0.27988          0.24913      0.94497         0.86145       4.19115                       0.11582         0.29938            0.28309        0.92789           0.83651         4.00554                         0.13143\n",
      " 2023-10-20 18:27:46  6.081 sec              35       0.27683          0.24426      0.94743         0.86727       4.19115                       0.11041         0.30025            0.28414        0.92732           0.83485         4.00554                         0.13726\n",
      " 2023-10-20 18:27:47  7.122 sec              40       0.27507          0.24124      0.94870         0.87026       4.19115                       0.11318         0.30010            0.28394        0.92739           0.83526         4.00554                         0.14648\n",
      "\n",
      "10-20 18:27:48.630 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2861294133601945, 0.28373624136936404, 0.28340023124948904, 0.28371940026227555]\n",
      "10-20 18:27:48.630 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.2861294133601945 --> 0.28340023124948904 (still improving).\n",
      "10-20 18:27:48.636 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_373\n",
      "10-20 18:27:48.653 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_373\n",
      "10-20 18:27:48.667 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 44. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:48.667) \n",
      "10-20 18:27:48.691 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 41. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:48.691) \n",
      "10-20 18:27:48.704 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 45. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:48.704) \n",
      "10-20 18:27:48.760 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 42. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:48.760) \n",
      "10-20 18:27:48.807 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_374\n",
      "10-20 18:27:48.809 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 43. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:48.809) \n",
      "10-20 18:27:48.821 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:48.829 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_374\n",
      "10-20 18:27:48.854 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 44. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:48.854) \n",
      "10-20 18:27:48.892 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_375\n",
      "10-20 18:27:48.918 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_375\n",
      "10-20 18:27:48.922 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 45. tree was built in 00:00:00.068 (Wall: 20-Oct 18:27:48.922) \n",
      "10-20 18:27:49.136 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_377\n",
      "10-20 18:27:49.149 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_376\n",
      "10-20 18:27:49.153 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_377\n",
      "10-20 18:27:49.160 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_376\n",
      "10-20 18:27:49.161 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.075211234\n",
      " RMSE: 0.27424666\n",
      " AUC: 0.94938755\n",
      " pr_auc: 0.8742743\n",
      " logloss: 0.2404666\n",
      " mean_per_class_error: 0.1402808\n",
      " default threshold: 0.3872784674167633\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18093  1675  0.0847  1,675 / 19,768\n",
      "     1   1230  5051  0.1958   1,230 / 6,281\n",
      "Totals  19323  6726  0.1115  2,905 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.24 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996722  4.147270         4.147270       1.000000  0.997730                  1.000000          0.997730      0.041554                 0.041554   314.726954       314.726954            0.041554\n",
      "      2                0.02000077         0.994709  4.147270         4.147270       1.000000  0.995724                  1.000000          0.996729      0.041395                 0.082949   314.726954       314.726954            0.082949\n",
      "      3                0.03002035         0.991656  4.147270         4.147270       1.000000  0.993396                  1.000000          0.995617      0.041554                 0.124502   314.726954       314.726954            0.124502\n",
      "      4                0.04000154         0.984476  4.147270         4.147270       1.000000  0.988325                  1.000000          0.993797      0.041395                 0.165897   314.726954       314.726954            0.165897\n",
      "      5                0.05002111         0.968690  4.131380         4.144087       0.996169  0.977276                  0.999233          0.990488      0.041395                 0.207292   313.137962       314.408668            0.207241\n",
      "      6                0.10000384         0.806990  3.863777         4.003986       0.931644  0.891529                  0.965451          0.941027      0.193122                 0.400414   286.377723       300.398576            0.395861\n",
      "      7                0.15002495         0.658162  3.240154         3.749310       0.781274  0.731836                  0.904043          0.871279      0.162076                 0.562490   224.015379       274.930995            0.543520\n",
      "      8                0.20000768         0.516667  2.627878         3.469060       0.633641  0.587285                  0.836468          0.800308      0.131349                 0.693839   162.787817       246.905963            0.650739\n",
      "      9                0.30001152         0.305056  1.668460         2.868860       0.402303  0.404713                  0.691747          0.668443      0.166852                 0.860691    66.846007       186.885978            0.738827\n",
      "     10                0.40001536         0.157043  0.867663         2.368561       0.209213  0.226589                  0.571113          0.557980      0.086770                 0.947461   -13.233708       136.856056            0.721388\n",
      "     11                0.50001919         0.071811  0.359802         1.966809       0.086756  0.109509                  0.474242          0.468285      0.035982                 0.983442   -64.019850        96.680875            0.637024\n",
      "     12                0.59998464         0.030725  0.103522         1.656360       0.024962  0.048145                  0.399386          0.398284      0.010349                 0.993791   -89.647753        65.636039            0.518932\n",
      "     13                0.69998848         0.013559  0.049353         1.426775       0.011900  0.020879                  0.344028          0.344366      0.004936                 0.998726   -95.064670        42.677536            0.393658\n",
      "     14                0.79999232         0.005890  0.009552         1.249614       0.002303  0.009210                  0.301310          0.302470      0.000955                 0.999682   -99.044775        24.961397            0.263138\n",
      "     15                0.89999616         0.001840  0.003184         1.111116       0.000768  0.003642                  0.267915          0.269265      0.000318                 1.000000   -99.681592        11.111585            0.131779\n",
      "     16                1.00000000         0.000095  0.000000         1.000000       0.000000  0.000890                  0.241122          0.242427      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.09199154\n",
      " RMSE: 0.30330107\n",
      " AUC: 0.92410576\n",
      " pr_auc: 0.8149832\n",
      " logloss: 0.2873129\n",
      " mean_per_class_error: 0.17311317\n",
      " default threshold: 0.3826788067817688\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4412   540  0.1090  540 / 4,952\n",
      "     1   370  1190  0.2372  370 / 1,560\n",
      "Totals  4782  1730  0.1397  910 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.55 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996658  4.174359         4.174359       1.000000  0.997741                  1.000000          0.997741      0.042308                 0.042308   317.435897       317.435897            0.042308\n",
      "      2                0.02011671         0.994774  4.174359         4.174359       1.000000  0.995753                  1.000000          0.996755      0.041667                 0.083974   317.435897       317.435897            0.083974\n",
      "      3                0.03009828         0.991510  4.110138         4.153061       0.984615  0.993263                  0.994898          0.995597      0.041026                 0.125000   311.013807       315.306122            0.124798\n",
      "      4                0.04007985         0.984531  4.174359         4.158365       1.000000  0.988489                  0.996169          0.993826      0.041667                 0.166667   317.435897       315.836526            0.166465\n",
      "      5                0.05006143         0.970651  4.110138         4.148749       0.984615  0.978377                  0.993865          0.990746      0.041026                 0.207692   311.013807       314.874941            0.207288\n",
      "      6                0.10012285         0.813158  3.508510         3.828630       0.840491  0.896044                  0.917178          0.943395      0.175641                 0.383333   250.851030       282.862986            0.372429\n",
      "      7                0.15003071         0.675150  2.825720         3.495011       0.676923  0.746302                  0.837257          0.877832      0.141026                 0.524359   182.571992       249.501089            0.492251\n",
      "      8                0.20009214         0.536016  2.215227         3.174819       0.530675  0.603144                  0.760553          0.809107      0.110897                 0.635256   121.522731       217.481945            0.572252\n",
      "      9                0.30006143         0.312294  1.724889         2.691757       0.413210  0.417712                  0.644831          0.678709      0.172436                 0.807692    72.488873       169.175655            0.667547\n",
      "     10                0.40003071         0.158256  1.077254         2.288286       0.258065  0.228123                  0.548177          0.566105      0.107692                 0.915385     7.725393       128.828584            0.677703\n",
      "     11                0.50000000         0.071595  0.487329         1.928205       0.116743  0.109397                  0.461916          0.474792      0.048718                 0.964103   -51.267084        92.820513            0.610306\n",
      "     12                0.59996929         0.029490  0.243665         1.647520       0.058372  0.046733                  0.394676          0.403467      0.024359                 0.988462   -75.633542        64.752023            0.510877\n",
      "     13                0.69993857         0.013336  0.083359         1.424118       0.019969  0.020353                  0.341158          0.348748      0.008333                 0.996795   -91.664107        42.411764            0.390373\n",
      "     14                0.79990786         0.005627  0.019237         1.248541       0.004608  0.009096                  0.299098          0.306300      0.001923                 0.998718   -98.076332        24.854123            0.261440\n",
      "     15                0.89987715         0.001891  0.012824         1.111263       0.003072  0.003563                  0.266212          0.272668      0.001282                 1.000000   -98.717555        11.126280            0.131664\n",
      "     16                1.00000000         0.000104  0.000000         1.000000       0.000000  0.000959                  0.239558          0.245464      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5993.524414          1.000000   0.293509\n",
      "                         capital_gain         3696.601563          0.616766   0.181026\n",
      "                                  age         2021.097046          0.337213   0.098975\n",
      "                               fnlwgt         1282.381592          0.213961   0.062799\n",
      "                         capital_loss         1269.141479          0.211752   0.062151\n",
      "                       hours_per_week         1058.528687          0.176612   0.051837\n",
      "           occupation. Prof-specialty          638.453247          0.106524   0.031266\n",
      "          occupation. Exec-managerial          584.601135          0.097539   0.028628\n",
      "                 education. Bachelors          476.784393          0.079550   0.023349\n",
      "                   education. HS-grad          247.871750          0.041357   0.012139\n",
      "---\n",
      "                   education. 1st-4th            9.983876          0.001666   0.000489\n",
      "                         workclass.NA            9.783321          0.001632   0.000479\n",
      "          native_country. Philippines            9.389676          0.001567   0.000460\n",
      "                    native_country.NA            7.530886          0.001257   0.000369\n",
      "            marital_status. Separated            5.486547          0.000915   0.000269\n",
      "              native_country. Germany            5.189872          0.000866   0.000254\n",
      "marital_status. Married-spouse-absent            3.083752          0.000515   0.000151\n",
      "                education. Assoc-acdm            2.577040          0.000430   0.000126\n",
      "                        occupation.NA            2.456347          0.000410   0.000120\n",
      "                native_country. India            1.801291          0.000301   0.000088\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        83410.187500          1.000000   0.131006\n",
      "                                  age        73964.351563          0.886754   0.116170\n",
      "                               fnlwgt        73691.828125          0.883487   0.115742\n",
      "                         capital_loss        53599.660156          0.642603   0.084185\n",
      "                       hours_per_week        43583.886719          0.522525   0.068454\n",
      "   marital_status. Married-civ-spouse        30550.263672          0.366265   0.047983\n",
      "                 education. Bachelors        13239.991211          0.158734   0.020795\n",
      "           occupation. Prof-specialty        12174.285156          0.145957   0.019121\n",
      "          occupation. Exec-managerial        12019.623047          0.144103   0.018878\n",
      "               education. Prof-school        11171.603516          0.133936   0.017546\n",
      "---\n",
      "            marital_status. Separated         1120.864624          0.013438   0.001760\n",
      "          relationship. Not-in-family         1103.010986          0.013224   0.001732\n",
      "                native_country. India         1092.687500          0.013100   0.001716\n",
      "         occupation. Transport-moving         1082.017578          0.012972   0.001699\n",
      "             race. Asian-Pac-Islander          844.689331          0.010127   0.001327\n",
      "marital_status. Married-spouse-absent          827.302551          0.009918   0.001299\n",
      "                         workclass.NA          617.092773          0.007398   0.000969\n",
      "             marital_status. Divorced          471.624146          0.005654   0.000741\n",
      "                education. Assoc-acdm          139.246597          0.001669   0.000219\n",
      "                        occupation.NA          111.825424          0.001341   0.000176\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                                  age          494.000000          1.000000   0.227231\n",
      "                               fnlwgt          491.000000          0.993927   0.225851\n",
      "                       hours_per_week          211.000000          0.427126   0.097056\n",
      "                         capital_gain           96.000000          0.194332   0.044158\n",
      "                         capital_loss           68.000000          0.137652   0.031279\n",
      "                   education. HS-grad           59.000000          0.119433   0.027139\n",
      "                 education. Bachelors           53.000000          0.107287   0.024379\n",
      "                   workclass. Private           46.000000          0.093117   0.021159\n",
      "                          sex. Female           43.000000          0.087045   0.019779\n",
      "           occupation. Prof-specialty           41.000000          0.082996   0.018859\n",
      "---\n",
      "                        occupation.NA            2.000000          0.004049   0.000920\n",
      "            marital_status. Separated            2.000000          0.004049   0.000920\n",
      "                         workclass.NA            2.000000          0.004049   0.000920\n",
      "                   education. 1st-4th            2.000000          0.004049   0.000920\n",
      "          native_country. Philippines            2.000000          0.004049   0.000920\n",
      "                    native_country.NA            2.000000          0.004049   0.000920\n",
      "marital_status. Married-spouse-absent            1.000000          0.002024   0.000460\n",
      "                native_country. India            1.000000          0.002024   0.000460\n",
      "              native_country. Germany            1.000000          0.002024   0.000460\n",
      "                education. Assoc-acdm            1.000000          0.002024   0.000460\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.352 sec               0       0.50000          0.69315      0.50000         0.24112       1.00000                       0.75888         0.50000            0.69315        0.50000           0.23956         1.00000                         0.76044\n",
      " 2023-10-20 18:27:41  0.771 sec               5       0.31543          0.34000      0.92252         0.82120       4.14727                       0.13828         0.32097            0.34788        0.91246           0.79624         4.13641                         0.15141\n",
      " 2023-10-20 18:27:42  1.556 sec              10       0.29681          0.28704      0.93155         0.83809       4.14727                       0.13275         0.30519            0.30024        0.92017           0.81181         4.17436                         0.13913\n",
      " 2023-10-20 18:27:43  2.592 sec              15       0.28929          0.26851      0.93744         0.84947       4.14727                       0.12853         0.30300            0.29009        0.92275           0.81384         4.17436                         0.15034\n",
      " 2023-10-20 18:27:44  3.317 sec              20       0.28638          0.26140      0.93955         0.85327       4.14727                       0.12480         0.30182            0.28613        0.92423           0.81631         4.17436                         0.14850\n",
      " 2023-10-20 18:27:44  4.080 sec              25       0.28364          0.25605      0.94189         0.85790       4.14727                       0.12027         0.30141            0.28473        0.92493           0.81755         4.17436                         0.14435\n",
      " 2023-10-20 18:27:45  5.076 sec              30       0.28034          0.25028      0.94471         0.86381       4.14727                       0.11498         0.30235            0.28596        0.92423           0.81624         4.17436                         0.14251\n",
      " 2023-10-20 18:27:46  5.854 sec              35       0.27640          0.24409      0.94782         0.87078       4.14727                       0.11025         0.30262            0.28650        0.92409           0.81618         4.17436                         0.14742\n",
      " 2023-10-20 18:27:47  6.770 sec              40       0.27425          0.24047      0.94939         0.87427       4.14727                       0.11152         0.30330            0.28731        0.92411           0.81498         4.17436                         0.13974\n",
      "\n",
      "10-20 18:27:49.172 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.07470644\n",
      " RMSE: 0.2733248\n",
      " AUC: 0.95065427\n",
      " pr_auc: 0.8763505\n",
      " logloss: 0.23844892\n",
      " mean_per_class_error: 0.14173655\n",
      " default threshold: 0.40445905923843384\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18229  1516  0.0768  1,516 / 19,745\n",
      "     1   1303  5001  0.2067   1,303 / 6,304\n",
      "Totals  19532  6517  0.1082  2,819 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.32 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.996637  4.132138         4.132138       1.000000  0.997719                  1.000000          0.997719      0.041402                 0.041402   313.213832       313.213832            0.041402\n",
      "      2                0.02000077         0.994471  4.132138         4.132138       1.000000  0.995564                  1.000000          0.996643      0.041244                 0.082646   313.213832       313.213832            0.082646\n",
      "      3                0.03002035         0.991197  4.132138         4.132138       1.000000  0.992946                  1.000000          0.995409      0.041402                 0.124048   313.213832       313.213832            0.124048\n",
      "      4                0.04000154         0.984721  4.132138         4.132138       1.000000  0.988339                  1.000000          0.993645      0.041244                 0.165292   313.213832       313.213832            0.165292\n",
      "      5                0.05002111         0.972186  4.100474         4.125796       0.992337  0.978967                  0.998465          0.990705      0.041085                 0.206377   310.047443       312.579583            0.206276\n",
      "      6                0.10000384         0.807725  3.878243         4.002067       0.938556  0.891887                  0.968522          0.941315      0.193845                 0.400222   287.824350       300.206718            0.396069\n",
      "      7                0.15002495         0.666176  3.241017         3.748319       0.784344  0.736253                  0.907114          0.872943      0.162119                 0.562341   224.101717       274.831893            0.543957\n",
      "      8                0.20000768         0.520763  2.567511         3.453230       0.621352  0.592208                  0.835701          0.802786      0.128331                 0.690673   156.751145       245.323038            0.647320\n",
      "      9                0.30001152         0.313231  1.722650         2.876370       0.416891  0.408170                  0.696097          0.671248      0.172272                 0.862944    72.264960       187.637012            0.742661\n",
      "     10                0.40001536         0.158046  0.864497         2.373402       0.209213  0.229963                  0.574376          0.560926      0.086453                 0.949397   -13.550273       137.340191            0.724783\n",
      "     11                0.50001919         0.071022  0.345799         1.967881       0.083685  0.110455                  0.476238          0.470832      0.034581                 0.983978   -65.420109        96.788131            0.638473\n",
      "     12                0.59998464         0.029126  0.103145         1.657191       0.024962  0.046726                  0.401049          0.400170      0.010311                 0.994289   -89.685523        65.719131            0.520195\n",
      "     13                0.69998848         0.012448  0.046001         1.427009       0.011132  0.019569                  0.345344          0.345796      0.004600                 0.998890   -95.399923        42.700861            0.394331\n",
      "     14                0.79999232         0.004898  0.009517         1.249814       0.002303  0.008243                  0.302462          0.303600      0.000952                 0.999841   -99.048260        24.981371            0.263655\n",
      "     15                0.89999616         0.001219  0.001586         1.111116       0.000384  0.002808                  0.268896          0.270177      0.000159                 1.000000   -99.841377        11.111585            0.131932\n",
      "     16                1.00000000         0.000100  0.000000         1.000000       0.000000  0.000603                  0.242005          0.243218      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.0937506\n",
      " RMSE: 0.3061872\n",
      " AUC: 0.9168492\n",
      " pr_auc: 0.8052179\n",
      " logloss: 0.29464528\n",
      " mean_per_class_error: 0.18862928\n",
      " default threshold: 0.3924434185028076\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4422   553  0.1112  553 / 4,975\n",
      "     1   409  1128  0.2661  409 / 1,537\n",
      "Totals  4831  1681  0.1477  962 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996994  4.236825         4.236825       1.000000  0.997762                  1.000000          0.997762      0.042941                 0.042941  323.682498       323.682498            0.042941\n",
      "      2                0.02011671         0.994424  4.236825         4.236825       1.000000  0.995747                  1.000000          0.996762      0.042290                 0.085231  323.682498       323.682498            0.085231\n",
      "      3                0.03009828         0.990421  4.236825         4.236825       1.000000  0.992562                  1.000000          0.995370      0.042290                 0.127521  323.682498       323.682498            0.127521\n",
      "      4                0.04007985         0.981922  4.236825         4.236825       1.000000  0.986663                  1.000000          0.993201      0.042290                 0.169811  323.682498       323.682498            0.169811\n",
      "      5                0.05006143         0.966004  4.171643         4.223829       0.984615  0.976234                  0.996933          0.989818      0.041640                 0.211451  317.164306       322.382859            0.211250\n",
      "      6                0.10012285         0.783479  3.600002         3.911915       0.849693  0.869966                  0.923313          0.929892      0.180221                 0.391672  260.000160       291.191509            0.381622\n",
      "      7                0.15003071         0.636907  2.776750         3.534301       0.655385  0.709069                  0.834186          0.856435      0.138582                 0.530254  177.674991       253.430129            0.497691\n",
      "      8                0.20009214         0.507251  2.131409         3.183309       0.503067  0.571195                  0.751343          0.785070      0.106701                 0.636955  113.140889       218.330902            0.571829\n",
      "      9                0.30006143         0.322432  1.548947         2.638800       0.365591  0.408028                  0.622825          0.659454      0.154847                 0.791802   54.894677       163.880041            0.643662\n",
      "     10                0.40003071         0.168767  1.164964         2.270483       0.274962  0.241083                  0.535893          0.554901      0.116461                 0.908263   16.496417       127.048279            0.665248\n",
      "     11                0.50000000         0.069151  0.514146         1.919323       0.121352  0.112178                  0.453010          0.466384      0.051399                 0.959662  -48.585380        91.932336            0.601672\n",
      "     12                0.59996929         0.029202  0.208262         1.634219       0.049155  0.046663                  0.385718          0.396448      0.020820                 0.980481  -79.173825        63.421941            0.498069\n",
      "     13                0.69993857         0.012585  0.078098         1.411965       0.018433  0.020211                  0.333260          0.342712      0.007807                 0.988289  -92.190184        41.196515            0.377435\n",
      "     14                0.79990786         0.005188  0.078098         1.245264       0.018433  0.008326                  0.293914          0.300922      0.007807                 0.996096  -92.190184        24.526378            0.256800\n",
      "     15                0.89987715         0.001318  0.032541         1.110540       0.007680  0.003008                  0.262116          0.267826      0.003253                 0.999349  -96.745910        11.053979            0.130204\n",
      "     16                1.00000000         0.000147  0.006498         1.000000       0.001534  0.000637                  0.236026          0.241074      0.000651                 1.000000  -99.350180         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6163.356934          1.000000   0.296997\n",
      "                      capital_gain         3669.610352          0.595392   0.176830\n",
      "                               age         1945.182861          0.315604   0.093734\n",
      "                            fnlwgt         1421.407715          0.230622   0.068494\n",
      "                      capital_loss         1314.417969          0.213263   0.063339\n",
      "                    hours_per_week         1108.287354          0.179819   0.053406\n",
      "        occupation. Prof-specialty          706.988708          0.114708   0.034068\n",
      "       occupation. Exec-managerial          596.897705          0.096846   0.028763\n",
      "              education. Bachelors          501.983185          0.081446   0.024189\n",
      "                education. Masters          257.099548          0.041714   0.012389\n",
      "---\n",
      "         marital_status. Separated           11.026274          0.001789   0.000531\n",
      "                education. 1st-4th            9.308963          0.001510   0.000449\n",
      "          race. Asian-Pac-Islander            8.950741          0.001452   0.000431\n",
      "                   education. 12th            8.412661          0.001365   0.000405\n",
      "                       race. Other            7.845816          0.001273   0.000378\n",
      "            native_country. Canada            7.493516          0.001216   0.000361\n",
      "                 native_country.NA            6.556307          0.001064   0.000316\n",
      "             education. Assoc-acdm            5.182331          0.000841   0.000250\n",
      "             native_country. India            3.964354          0.000643   0.000191\n",
      "                      workclass.NA            1.734532          0.000281   0.000084\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        78687.359375          1.000000   0.123628\n",
      "                               age        74515.507813          0.946982   0.117074\n",
      "                            fnlwgt        70957.523438          0.901765   0.111484\n",
      "                      capital_loss        55239.210938          0.702009   0.086788\n",
      "                    hours_per_week        49269.285156          0.626140   0.077409\n",
      "marital_status. Married-civ-spouse        31618.164063          0.401820   0.049676\n",
      "              education. Bachelors        14288.891602          0.181591   0.022450\n",
      "                education. Masters        12407.238281          0.157678   0.019493\n",
      "            education. Prof-school        11531.617188          0.146550   0.018118\n",
      "              education. Doctorate        11057.767578          0.140528   0.017373\n",
      "---\n",
      "                education. 1st-4th         1538.888184          0.019557   0.002418\n",
      "          race. Asian-Pac-Islander         1536.225098          0.019523   0.002414\n",
      "           relationship. Unmarried         1519.896484          0.019316   0.002388\n",
      "             education. Assoc-acdm         1489.014160          0.018923   0.002339\n",
      "                 native_country.NA         1437.563599          0.018269   0.002259\n",
      "                   education. 12th         1396.824707          0.017752   0.002195\n",
      "                      workclass.NA         1306.653687          0.016606   0.002053\n",
      "                       race. White         1291.492554          0.016413   0.002029\n",
      "             native_country. India         1213.528198          0.015422   0.001907\n",
      "                       race. Other         1159.867310          0.014740   0.001822\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          536.000000          1.000000   0.245197\n",
      "                        age          454.000000          0.847015   0.207685\n",
      "             hours_per_week          212.000000          0.395522   0.096981\n",
      "               capital_gain           94.000000          0.175373   0.043001\n",
      "               capital_loss           75.000000          0.139925   0.034309\n",
      "         workclass. Private           53.000000          0.098881   0.024245\n",
      "         education. HS-grad           50.000000          0.093284   0.022873\n",
      "                sex. Female           49.000000          0.091418   0.022415\n",
      " occupation. Prof-specialty           48.000000          0.089552   0.021958\n",
      "       education. Bachelors           46.000000          0.085821   0.021043\n",
      "---\n",
      "         education. 5th-6th            4.000000          0.007463   0.001830\n",
      "     native_country. Canada            2.000000          0.003731   0.000915\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003731   0.000915\n",
      "      education. Assoc-acdm            2.000000          0.003731   0.000915\n",
      "          native_country.NA            2.000000          0.003731   0.000915\n",
      "                race. Other            1.000000          0.001866   0.000457\n",
      "            education. 12th            1.000000          0.001866   0.000457\n",
      "               workclass.NA            1.000000          0.001866   0.000457\n",
      "         education. 1st-4th            1.000000          0.001866   0.000457\n",
      "      native_country. India            1.000000          0.001866   0.000457\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.399 sec               0       0.50000          0.69315      0.50000         0.24201       1.00000                       0.75799         0.50000            0.69315        0.50000           0.23603         1.00000                         0.76397\n",
      " 2023-10-20 18:27:41  0.829 sec               5       0.31390          0.33751      0.92503         0.82535       4.12734                       0.13425         0.32503            0.35439        0.90420           0.78310         4.23682                         0.15279\n",
      " 2023-10-20 18:27:42  1.358 sec              10       0.29576          0.28451      0.93335         0.84079       4.13214                       0.12776         0.31006            0.30821        0.91154           0.79718         4.23682                         0.14604\n",
      " 2023-10-20 18:27:42  2.023 sec              15       0.28884          0.26752      0.93832         0.85075       4.13214                       0.11901         0.30698            0.29866        0.91443           0.80267         4.23682                         0.13959\n",
      " 2023-10-20 18:27:43  3.142 sec              20       0.28407          0.25745      0.94233         0.85824       4.13214                       0.12166         0.30608            0.29567        0.91561           0.80478         4.23682                         0.14527\n",
      " 2023-10-20 18:27:44  4.063 sec              25       0.28125          0.25204      0.94445         0.86294       4.13214                       0.12070         0.30559            0.29433        0.91662           0.80552         4.23682                         0.14665\n",
      " 2023-10-20 18:27:46  5.164 sec              30       0.27734          0.24542      0.94749         0.86972       4.13214                       0.11597         0.30614            0.29465        0.91648           0.80501         4.23682                         0.14711\n",
      " 2023-10-20 18:27:46  5.945 sec              35       0.27552          0.24198      0.94902         0.87262       4.13214                       0.10918         0.30663            0.29551        0.91622           0.80390         4.23682                         0.14742\n",
      " 2023-10-20 18:27:47  6.837 sec              40       0.27332          0.23845      0.95065         0.87635       4.13214                       0.10822         0.30619            0.29465        0.91685           0.80522         4.23682                         0.14773\n",
      "\n",
      "10-20 18:27:49.174 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: In-training scoring took 5014ms.\n",
      "10-20 18:27:49.191 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: In-training scoring took 5063ms.\n",
      "10-20 18:27:49.200 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_378\n",
      "10-20 18:27:49.200 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model XGBoost_2_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:49.217 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_378\n",
      "10-20 18:27:49.218 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_379\n",
      "10-20 18:27:49.229 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Completing model XGBoost_2_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:49.240 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_379\n",
      "10-20 18:27:49.246 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07463581\n",
      " RMSE: 0.27319556\n",
      " AUC: 0.9505154\n",
      " pr_auc: 0.8765855\n",
      " logloss: 0.23859704\n",
      " mean_per_class_error: 0.13885884\n",
      " default threshold: 0.4008493721485138\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18194  1544  0.0782  1,544 / 19,738\n",
      "     1   1259  5052  0.1995   1,259 / 6,311\n",
      "Totals  19453  6596  0.1076  2,803 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.31 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.997990  4.127555         4.127555       1.000000  0.998523                  1.000000          0.998523      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.996568  4.127555         4.127555       1.000000  0.997365                  1.000000          0.997945      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.993807  4.127555         4.127555       1.000000  0.995420                  1.000000          0.997102      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.987193  4.127555         4.127555       1.000000  0.990912                  1.000000          0.995558      0.041198                 0.165109   312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.974931  4.111741         4.124387       0.996169  0.981349                  0.999233          0.992712      0.041198                 0.206306   311.174068       312.438733            0.206256\n",
      "      6                0.10000384         0.813462  3.851751         3.988121       0.933180  0.892727                  0.966219          0.942738      0.192521                 0.398827   285.175069       298.812134            0.394369\n",
      "      7                0.15002495         0.666586  3.269100         3.748386       0.792018  0.740439                  0.908137          0.875288      0.163524                 0.562351   226.909964       274.838611            0.544163\n",
      "      8                0.20000768         0.529585  2.561493         3.451777       0.620584  0.594584                  0.836276          0.805139      0.128030                 0.690382   156.149346       245.177685            0.647166\n",
      "      9                0.30001152         0.307721  1.736584         2.880046       0.420729  0.410646                  0.697761          0.673641      0.173665                 0.864047    73.658363       188.004578            0.744379\n",
      "     10                0.40001536         0.151466  0.816004         2.364035       0.197697  0.223551                  0.572745          0.561119      0.081604                 0.945650   -18.399583       136.403538            0.720096\n",
      "     11                0.50001919         0.069089  0.366014         1.964431       0.088676  0.105599                  0.475931          0.470015      0.036603                 0.982253   -63.398648        96.443100            0.636423\n",
      "     12                0.59998464         0.030075  0.128392         1.658522       0.031106  0.047038                  0.401817          0.399541      0.012835                 0.995088   -87.160831        65.852235            0.521433\n",
      "     13                0.69998848         0.013342  0.039612         1.427237       0.009597  0.020463                  0.345783          0.345384      0.003961                 0.999049   -96.038815        42.723674            0.394682\n",
      "     14                0.79999232         0.005406  0.007922         1.249814       0.001919  0.008918                  0.302798          0.303324      0.000792                 0.999842   -99.207763        24.981393            0.263749\n",
      "     15                0.89999616         0.001794  0.001584         1.111116       0.000384  0.003349                  0.269195          0.269992      0.000158                 1.000000   -99.841553        11.111585            0.131979\n",
      "     16                1.00000000         0.000080  0.000000         1.000000       0.000000  0.000938                  0.242274          0.243085      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.08885337\n",
      " RMSE: 0.2980828\n",
      " AUC: 0.9252122\n",
      " pr_auc: 0.82067364\n",
      " logloss: 0.28059536\n",
      " mean_per_class_error: 0.17899273\n",
      " default threshold: 0.384749174118042\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4501   481  0.0965  481 / 4,982\n",
      "     1   400  1130  0.2614  400 / 1,530\n",
      "Totals  4901  1611  0.1353  881 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.61 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.997734  4.256209         4.256209       1.000000  0.998505                  1.000000          0.998505      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.996299  4.256209         4.256209       1.000000  0.997111                  1.000000          0.997813      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.993572  4.190729         4.234494       0.984615  0.995130                  0.994898          0.996923      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.986516  4.190729         4.223595       0.984615  0.990272                  0.992337          0.995267      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.972014  4.190729         4.217042       0.984615  0.979797                  0.990798          0.992182      0.041830                 0.211111   319.072901       321.704158            0.210509\n",
      "      6                0.10012285         0.798954  3.707863         3.962452       0.871166  0.885256                  0.930982          0.938719      0.185621                 0.396732   270.786319       296.245238            0.387700\n",
      "      7                0.15003071         0.643965  2.894222         3.607105       0.680000  0.717302                  0.847492          0.865065      0.144444                 0.541176   189.422222       260.710458            0.511269\n",
      "      8                0.20009214         0.499507  2.415333         3.308933       0.567485  0.569693                  0.777437          0.791165      0.120915                 0.662092   141.533341       230.893313            0.603882\n",
      "      9                0.30006143         0.287093  1.484116         2.700972       0.348694  0.383480                  0.634596          0.655340      0.148366                 0.810458    48.411594       170.097203            0.667142\n",
      "     10                0.40003071         0.151290  1.019921         2.280871       0.239631  0.212501                  0.535893          0.544672      0.101961                 0.912418     1.992109       128.087062            0.669745\n",
      "     11                0.50000000         0.067536  0.542650         1.933333       0.127496  0.104750                  0.454238          0.456715      0.054248                 0.966667   -45.734968        93.333333            0.609983\n",
      "     12                0.59996929         0.028311  0.169987         1.639517       0.039939  0.044930                  0.385206          0.388102      0.016993                 0.983660   -83.001315        63.951747            0.501524\n",
      "     13                0.69993857         0.012481  0.084993         1.417491       0.019969  0.019408                  0.333041          0.335443      0.008497                 0.992157   -91.500658        41.749133            0.381960\n",
      "     14                0.79990786         0.005519  0.065380         1.248510       0.015361  0.008608                  0.293338          0.294596      0.006536                 0.998693   -93.462044        24.850981            0.259833\n",
      "     15                0.89987715         0.001555  0.013076         1.111263       0.003072  0.003235                  0.261092          0.262228      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000084  0.000000         1.000000       0.000000  0.000845                  0.234951          0.236058      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6135.072266          1.000000   0.290844\n",
      "                      capital_gain         3657.295410          0.596129   0.173381\n",
      "                               age         2044.541504          0.333255   0.096925\n",
      "                            fnlwgt         1654.933716          0.269750   0.078455\n",
      "                      capital_loss         1313.221313          0.214051   0.062256\n",
      "                    hours_per_week         1209.654419          0.197170   0.057346\n",
      "       occupation. Exec-managerial          638.469238          0.104069   0.030268\n",
      "        occupation. Prof-specialty          621.389099          0.101285   0.029458\n",
      "              education. Bachelors          494.951904          0.080676   0.023464\n",
      "                education. Masters          256.378052          0.041789   0.012154\n",
      "---\n",
      "                   education. 12th           13.561639          0.002211   0.000643\n",
      "         marital_status. Separated            9.593512          0.001564   0.000455\n",
      "           native_country. Germany            7.056383          0.001150   0.000335\n",
      "                 native_country.NA            6.232629          0.001016   0.000295\n",
      "            native_country. Canada            4.357147          0.000710   0.000207\n",
      "          race. Amer-Indian-Eskimo            4.338013          0.000707   0.000206\n",
      "                education. 1st-4th            4.297473          0.000700   0.000204\n",
      "                      workclass.NA            4.086454          0.000666   0.000194\n",
      "             native_country. India            3.007887          0.000490   0.000143\n",
      "       native_country. Philippines            2.614272          0.000426   0.000124\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        84646.320313          1.000000   0.121149\n",
      "                      capital_gain        84075.390625          0.993255   0.120332\n",
      "                            fnlwgt        83149.757813          0.982320   0.119007\n",
      "                      capital_loss        62230.054688          0.735177   0.089066\n",
      "                    hours_per_week        48245.222656          0.569962   0.069050\n",
      "marital_status. Married-civ-spouse        33853.070313          0.399936   0.048452\n",
      "              education. Bachelors        14598.665039          0.172467   0.020894\n",
      "       occupation. Exec-managerial        14461.186523          0.170842   0.020697\n",
      "                education. Masters        13786.879883          0.162876   0.019732\n",
      "            education. Prof-school        12103.163086          0.142985   0.017322\n",
      "---\n",
      "             relationship. Husband         2202.967773          0.026026   0.003153\n",
      "                       race. White         1645.513794          0.019440   0.002355\n",
      "            native_country. Canada         1373.848999          0.016230   0.001966\n",
      "       native_country. Philippines         1311.490234          0.015494   0.001877\n",
      "             native_country. India         1254.505981          0.014821   0.001795\n",
      "                education. 1st-4th         1250.632324          0.014775   0.001790\n",
      "                 native_country.NA         1201.647095          0.014196   0.001720\n",
      "         marital_status. Separated         1175.023315          0.013882   0.001682\n",
      "                      workclass.NA          866.905518          0.010242   0.001241\n",
      "          marital_status. Divorced          720.736694          0.008515   0.001032\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          619.000000          1.000000   0.252036\n",
      "                        age          520.000000          0.840065   0.211726\n",
      "             hours_per_week          230.000000          0.371567   0.093648\n",
      "               capital_gain          100.000000          0.161551   0.040717\n",
      "               capital_loss           80.000000          0.129241   0.032573\n",
      "         workclass. Private           65.000000          0.105008   0.026466\n",
      "         education. HS-grad           62.000000          0.100162   0.025244\n",
      "       education. Bachelors           54.000000          0.087237   0.021987\n",
      " occupation. Prof-specialty           46.000000          0.074313   0.018730\n",
      "occupation. Exec-managerial           42.000000          0.067851   0.017101\n",
      "---\n",
      "            education. 12th            2.000000          0.003231   0.000814\n",
      "  marital_status. Separated            2.000000          0.003231   0.000814\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003231   0.000814\n",
      "    native_country. Germany            2.000000          0.003231   0.000814\n",
      "          native_country.NA            2.000000          0.003231   0.000814\n",
      "     native_country. Canada            1.000000          0.001616   0.000407\n",
      "               workclass.NA            1.000000          0.001616   0.000407\n",
      "         education. 1st-4th            1.000000          0.001616   0.000407\n",
      "      native_country. India            1.000000          0.001616   0.000407\n",
      "native_country. Philippines            1.000000          0.001616   0.000407\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              45\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      " 2023-10-20 18:27:45  4.269 sec              25       0.28404          0.25689      0.94168         0.85767       4.12756                       0.12000         0.29713            0.27903        0.92592           0.82214         4.25621                         0.14097\n",
      " 2023-10-20 18:27:46  5.267 sec              30       0.28109          0.25176      0.94415         0.86293       4.12756                       0.11666         0.29695            0.27845        0.92622           0.82274         4.25621                         0.12454\n",
      " 2023-10-20 18:27:47  6.306 sec              35       0.27769          0.24631      0.94689         0.86883       4.12756                       0.11386         0.29742            0.27907        0.92592           0.82178         4.25621                         0.14327\n",
      " 2023-10-20 18:27:47  7.027 sec              40       0.27599          0.24323      0.94827         0.87165       4.12756                       0.11309         0.29776            0.27962        0.92569           0.82138         4.25621                         0.13529\n",
      " 2023-10-20 18:27:48  7.857 sec              45       0.27320          0.23860      0.95052         0.87659       4.12756                       0.10760         0.29808            0.28060        0.92521           0.82067         4.25621                         0.13529\n",
      "\n",
      "10-20 18:27:49.263 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.2793548586952809, 0.278850153484192, 0.2790458919004084, 0.27976238437111456]\n",
      "10-20 18:27:49.264 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.2793548586952809 --> 0.278850153484192 (converged).\n",
      "10-20 18:27:49.264 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:49.264 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 45\n",
      "10-20 18:27:49.469 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_380\n",
      "█10-20 18:27:49.490 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_380\n",
      "10-20 18:27:49.504 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_381\n",
      "10-20 18:27:49.524 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_381\n",
      "10-20 18:27:49.531 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.07369841\n",
      " RMSE: 0.2714745\n",
      " AUC: 0.9517113\n",
      " pr_auc: 0.8768454\n",
      " logloss: 0.23584324\n",
      " mean_per_class_error: 0.13168417\n",
      " default threshold: 0.3614193797111511\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18005  1828  0.0922  1,828 / 19,833\n",
      "     1   1064  5151  0.1712   1,064 / 6,215\n",
      "Totals  19069  6979  0.1110  2,892 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.82 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.996947  4.191150         4.191150       1.000000  0.997896                  1.000000          0.997896      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.994696  4.191150         4.191150       1.000000  0.995862                  1.000000          0.996881      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.990683  4.191150         4.191150       1.000000  0.992944                  1.000000          0.995567      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.982836  4.175031         4.187128       0.996154  0.987070                  0.999040          0.993447      0.041673                 0.167498   317.503063       318.712823            0.167448\n",
      "      5                0.05002303         0.966171  4.175092         4.184717       0.996169  0.975728                  0.998465          0.989898      0.041834                 0.209332   317.509239       318.471736            0.209231\n",
      "      6                0.10000768         0.787833  3.943287         4.064048       0.940860  0.878661                  0.969674          0.934301      0.197104                 0.406436   294.328671       306.404838            0.402453\n",
      "      7                0.15003071         0.645943  3.245488         3.791125       0.774367  0.713720                  0.904555          0.860755      0.162349                 0.568785   224.548795       279.112508            0.549978\n",
      "      8                0.20001536         0.509051  2.623493         3.499329       0.625960  0.576811                  0.834933          0.789796      0.131134                 0.699920   162.349279       249.932906            0.656557\n",
      "      9                0.30002303         0.304944  1.686113         2.894924       0.402303  0.396899                  0.690723          0.658830      0.168624                 0.868544    68.611350       189.492388            0.746676\n",
      "     10                0.39999232         0.154004  0.828895         2.378565       0.197773  0.223670                  0.567521          0.550072      0.082864                 0.951408   -17.110504       137.856537            0.724211\n",
      "     11                0.50000000         0.067170  0.333040         1.969429       0.079463  0.105151                  0.469902          0.461081      0.033307                 0.984714   -66.696041        96.942880            0.636608\n",
      "     12                0.60000768         0.028462  0.104578         1.658600       0.024952  0.045060                  0.395739          0.391739      0.010459                 0.995173   -89.542235        65.860039            0.518997\n",
      "     13                0.69997697         0.012285  0.037019         1.427009       0.008833  0.019196                  0.340482          0.338533      0.003701                 0.998874   -96.298139        42.700938            0.392561\n",
      "     14                0.79998464         0.005278  0.008044         1.249622       0.001919  0.008319                  0.298157          0.297253      0.000805                 0.999678   -99.195557        24.962173            0.262271\n",
      "     15                0.89999232         0.001781  0.003218         1.111121       0.000768  0.003294                  0.265111          0.264588      0.000322                 1.000000   -99.678223        11.112059            0.131347\n",
      "     16                1.00000000         0.000089  0.000000         1.000000       0.000000  0.000925                  0.238598          0.238220      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09053288\n",
      " RMSE: 0.3008868\n",
      " AUC: 0.92660946\n",
      " pr_auc: 0.83370733\n",
      " logloss: 0.28564513\n",
      " mean_per_class_error: 0.16851376\n",
      " default threshold: 0.34693124890327454\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4355   532  0.1089  532 / 4,887\n",
      "     1   371  1255  0.2282  371 / 1,626\n",
      "Totals  4726  1787  0.1386  903 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.96 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.996852  4.005535         4.005535       1.000000  0.997830                  1.000000          0.997830      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.994518  4.005535         4.005535       1.000000  0.995787                  1.000000          0.996816      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.991139  4.005535         4.005535       1.000000  0.993017                  1.000000          0.995556      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.984199  4.005535         4.005535       1.000000  0.988199                  1.000000          0.993724      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.968426  4.005535         4.005535       1.000000  0.977465                  1.000000          0.990482      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.794822  3.477198         3.741366       0.868098  0.886252                  0.934049          0.938367      0.174047                 0.374539   247.719761       274.136633            0.365740\n",
      "      7                0.15000768         0.648786  2.970258         3.484856       0.741538  0.721928                  0.870010          0.866368      0.148216                 0.522755   197.025830       248.485650            0.496768\n",
      "      8                0.20006142         0.517794  2.383662         3.209347       0.595092  0.579574                  0.801228          0.794615      0.119311                 0.642066   138.366197       220.934658            0.589069\n",
      "      9                0.30001535         0.302252  1.648976         2.689489       0.411674  0.398243                  0.671443          0.662558      0.164822                 0.806888    64.897603       168.948925            0.675519\n",
      "     10                0.39996929         0.152466  0.953699         2.255708       0.238095  0.223887                  0.563148          0.552932      0.095326                 0.902214    -4.630118       125.570823            0.669351\n",
      "     11                0.50007677         0.069484  0.577485         1.919754       0.144172  0.106039                  0.479275          0.463471      0.057811                 0.960025   -42.251488        91.975444            0.612981\n",
      "     12                0.60003071         0.029510  0.264575         1.644032       0.066052  0.046113                  0.410440          0.393947      0.026445                 0.986470   -73.542549        64.403230            0.515015\n",
      "     13                0.69998465         0.012395  0.079988         1.420695       0.019969  0.019411                  0.354683          0.340466      0.007995                 0.994465   -92.001236        42.069537            0.392460\n",
      "     14                0.79993858         0.005604  0.036917         1.247790       0.009217  0.008618                  0.311516          0.299001      0.003690                 0.998155   -96.308263        24.778952            0.264167\n",
      "     15                0.89989252         0.001875  0.018459         1.111244       0.004608  0.003542                  0.277427          0.266183      0.001845                 1.000000   -98.154131        11.124382            0.133415\n",
      "     16                1.00000000         0.000104  0.000000         1.000000       0.000000  0.000971                  0.249655          0.239633      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5156.290527          1.000000   0.242935\n",
      "                      capital_gain         3728.930176          0.723181   0.175686\n",
      "                               age         2080.204590          0.403430   0.098007\n",
      "                            fnlwgt         1879.766846          0.364558   0.088564\n",
      "                      capital_loss         1328.113647          0.257572   0.062573\n",
      "                    hours_per_week         1296.790649          0.251497   0.061097\n",
      "     marital_status. Never-married          726.741150          0.140943   0.034240\n",
      "        occupation. Prof-specialty          547.330688          0.106148   0.025787\n",
      "       occupation. Exec-managerial          532.884094          0.103346   0.025106\n",
      "              education. Bachelors          390.119934          0.075659   0.018380\n",
      "---\n",
      "       native_country. Philippines           15.814737          0.003067   0.000745\n",
      "                   education. 12th           13.833382          0.002683   0.000652\n",
      "                education. 1st-4th           13.181145          0.002556   0.000621\n",
      "          race. Amer-Indian-Eskimo           12.538165          0.002432   0.000591\n",
      "         marital_status. Separated           10.034459          0.001946   0.000473\n",
      "                 native_country.NA            8.990942          0.001744   0.000424\n",
      "       native_country. Puerto-Rico            7.210544          0.001398   0.000340\n",
      "             education. Assoc-acdm            5.504598          0.001068   0.000259\n",
      "                      workclass.NA            2.801810          0.000543   0.000132\n",
      "             native_country. India            2.298777          0.000446   0.000108\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        95765.601563          1.000000   0.136849\n",
      "                      capital_gain        82356.093750          0.859976   0.117687\n",
      "                               age        75691.296875          0.790381   0.108163\n",
      "                    hours_per_week        58748.085938          0.613457   0.083951\n",
      "                      capital_loss        57414.875000          0.599535   0.082046\n",
      "marital_status. Married-civ-spouse        28118.025391          0.293613   0.040181\n",
      "        occupation. Prof-specialty        13455.442383          0.140504   0.019228\n",
      "              education. Doctorate        13332.768555          0.139223   0.019053\n",
      "              education. Bachelors        12666.846680          0.132269   0.018101\n",
      "     marital_status. Never-married        12043.407227          0.125759   0.017210\n",
      "---\n",
      "           relationship. Unmarried         2090.959717          0.021834   0.002988\n",
      "         marital_status. Separated         2018.135010          0.021074   0.002884\n",
      "          race. Asian-Pac-Islander         1824.049194          0.019047   0.002607\n",
      "              education. Assoc-voc         1800.567505          0.018802   0.002573\n",
      "                 native_country.NA         1752.922607          0.018304   0.002505\n",
      "       native_country. Puerto-Rico         1487.620605          0.015534   0.002126\n",
      "             relationship. Husband         1342.676147          0.014020   0.001919\n",
      "                      workclass.NA         1260.344727          0.013161   0.001801\n",
      "             education. Assoc-acdm          806.074280          0.008417   0.001152\n",
      "             native_country. India           35.474113          0.000370   0.000051\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          734.000000          1.000000   0.285937\n",
      "                        age          514.000000          0.700272   0.200234\n",
      "             hours_per_week          259.000000          0.352861   0.100896\n",
      "               capital_loss           87.000000          0.118529   0.033892\n",
      "               capital_gain           86.000000          0.117166   0.033502\n",
      "         workclass. Private           68.000000          0.092643   0.026490\n",
      "         education. HS-grad           59.000000          0.080381   0.022984\n",
      " occupation. Prof-specialty           53.000000          0.072207   0.020647\n",
      "    education. Some-college           46.000000          0.062670   0.017920\n",
      "       education. Bachelors           46.000000          0.062670   0.017920\n",
      "---\n",
      "native_country. Philippines            4.000000          0.005450   0.001558\n",
      "         education. 5th-6th            4.000000          0.005450   0.001558\n",
      "            education. 12th            3.000000          0.004087   0.001169\n",
      "         education. 1st-4th            3.000000          0.004087   0.001169\n",
      "          native_country.NA            3.000000          0.004087   0.001169\n",
      "  marital_status. Separated            2.000000          0.002725   0.000779\n",
      "               workclass.NA            2.000000          0.002725   0.000779\n",
      "      education. Assoc-acdm            2.000000          0.002725   0.000779\n",
      "      native_country. India            1.000000          0.001362   0.000390\n",
      "native_country. Puerto-Rico            1.000000          0.001362   0.000390\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              45\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      " 2023-10-20 18:27:44  3.876 sec              25       0.28313          0.25490      0.94227         0.85560       4.19115                       0.12024         0.29943            0.28298        0.92811           0.83677         4.00554                         0.13005\n",
      " 2023-10-20 18:27:46  5.162 sec              30       0.27988          0.24913      0.94497         0.86145       4.19115                       0.11582         0.29938            0.28309        0.92789           0.83651         4.00554                         0.13143\n",
      " 2023-10-20 18:27:46  6.081 sec              35       0.27683          0.24426      0.94743         0.86727       4.19115                       0.11041         0.30025            0.28414        0.92732           0.83485         4.00554                         0.13726\n",
      " 2023-10-20 18:27:47  7.122 sec              40       0.27507          0.24124      0.94870         0.87026       4.19115                       0.11318         0.30010            0.28394        0.92739           0.83526         4.00554                         0.14648\n",
      " 2023-10-20 18:27:48  8.075 sec              45       0.27147          0.23584      0.95171         0.87685       4.19115                       0.11103         0.30089            0.28565        0.92661           0.83371         4.00554                         0.13865\n",
      "\n",
      "10-20 18:27:49.544 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28373624136936404, 0.28340023124948904, 0.28371940026227555, 0.2845726840780685]\n",
      "10-20 18:27:49.544 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.28373624136936404 --> 0.28340023124948904 (converged).\n",
      "10-20 18:27:49.544 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:49.545 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 45\n",
      "10-20 18:27:49.689 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_382\n",
      "10-20 18:27:49.707 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_382\n",
      "10-20 18:27:49.759 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_383\n",
      "10-20 18:27:49.775 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_383\n",
      "10-20 18:27:49.779 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.07463581\n",
      " RMSE: 0.27319556\n",
      " AUC: 0.9505154\n",
      " pr_auc: 0.8765855\n",
      " logloss: 0.23859704\n",
      " mean_per_class_error: 0.13885884\n",
      " default threshold: 0.4008493721485138\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18194  1544  0.0782  1,544 / 19,738\n",
      "     1   1259  5052  0.1995   1,259 / 6,311\n",
      "Totals  19453  6596  0.1076  2,803 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.31 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.997990  4.127555         4.127555       1.000000  0.998523                  1.000000          0.998523      0.041356                 0.041356   312.755506       312.755506            0.041356\n",
      "      2                0.02000077         0.996568  4.127555         4.127555       1.000000  0.997365                  1.000000          0.997945      0.041198                 0.082554   312.755506       312.755506            0.082554\n",
      "      3                0.03002035         0.993807  4.127555         4.127555       1.000000  0.995420                  1.000000          0.997102      0.041356                 0.123911   312.755506       312.755506            0.123911\n",
      "      4                0.04000154         0.987193  4.127555         4.127555       1.000000  0.990912                  1.000000          0.995558      0.041198                 0.165109   312.755506       312.755506            0.165109\n",
      "      5                0.05002111         0.974931  4.111741         4.124387       0.996169  0.981349                  0.999233          0.992712      0.041198                 0.206306   311.174068       312.438733            0.206256\n",
      "      6                0.10000384         0.813462  3.851751         3.988121       0.933180  0.892727                  0.966219          0.942738      0.192521                 0.398827   285.175069       298.812134            0.394369\n",
      "      7                0.15002495         0.666586  3.269100         3.748386       0.792018  0.740439                  0.908137          0.875288      0.163524                 0.562351   226.909964       274.838611            0.544163\n",
      "      8                0.20000768         0.529585  2.561493         3.451777       0.620584  0.594584                  0.836276          0.805139      0.128030                 0.690382   156.149346       245.177685            0.647166\n",
      "      9                0.30001152         0.307721  1.736584         2.880046       0.420729  0.410646                  0.697761          0.673641      0.173665                 0.864047    73.658363       188.004578            0.744379\n",
      "     10                0.40001536         0.151466  0.816004         2.364035       0.197697  0.223551                  0.572745          0.561119      0.081604                 0.945650   -18.399583       136.403538            0.720096\n",
      "     11                0.50001919         0.069089  0.366014         1.964431       0.088676  0.105599                  0.475931          0.470015      0.036603                 0.982253   -63.398648        96.443100            0.636423\n",
      "     12                0.59998464         0.030075  0.128392         1.658522       0.031106  0.047038                  0.401817          0.399541      0.012835                 0.995088   -87.160831        65.852235            0.521433\n",
      "     13                0.69998848         0.013342  0.039612         1.427237       0.009597  0.020463                  0.345783          0.345384      0.003961                 0.999049   -96.038815        42.723674            0.394682\n",
      "     14                0.79999232         0.005406  0.007922         1.249814       0.001919  0.008918                  0.302798          0.303324      0.000792                 0.999842   -99.207763        24.981393            0.263749\n",
      "     15                0.89999616         0.001794  0.001584         1.111116       0.000384  0.003349                  0.269195          0.269992      0.000158                 1.000000   -99.841553        11.111585            0.131979\n",
      "     16                1.00000000         0.000080  0.000000         1.000000       0.000000  0.000938                  0.242274          0.243085      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.08885337\n",
      " RMSE: 0.2980828\n",
      " AUC: 0.9252122\n",
      " pr_auc: 0.82067364\n",
      " logloss: 0.28059536\n",
      " mean_per_class_error: 0.17899273\n",
      " default threshold: 0.384749174118042\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4501   481  0.0965  481 / 4,982\n",
      "     1   400  1130  0.2614  400 / 1,530\n",
      "Totals  4901  1611  0.1353  881 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 23.61 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.997734  4.256209         4.256209       1.000000  0.998505                  1.000000          0.998505      0.043137                 0.043137   325.620915       325.620915            0.043137\n",
      "      2                0.02011671         0.996299  4.256209         4.256209       1.000000  0.997111                  1.000000          0.997813      0.042484                 0.085621   325.620915       325.620915            0.085621\n",
      "      3                0.03009828         0.993572  4.190729         4.234494       0.984615  0.995130                  0.994898          0.996923      0.041830                 0.127451   319.072901       323.449380            0.127250\n",
      "      4                0.04007985         0.986516  4.190729         4.223595       0.984615  0.990272                  0.992337          0.995267      0.041830                 0.169281   319.072901       322.359452            0.168880\n",
      "      5                0.05006143         0.972014  4.190729         4.217042       0.984615  0.979797                  0.990798          0.992182      0.041830                 0.211111   319.072901       321.704158            0.210509\n",
      "      6                0.10012285         0.798954  3.707863         3.962452       0.871166  0.885256                  0.930982          0.938719      0.185621                 0.396732   270.786319       296.245238            0.387700\n",
      "      7                0.15003071         0.643965  2.894222         3.607105       0.680000  0.717302                  0.847492          0.865065      0.144444                 0.541176   189.422222       260.710458            0.511269\n",
      "      8                0.20009214         0.499507  2.415333         3.308933       0.567485  0.569693                  0.777437          0.791165      0.120915                 0.662092   141.533341       230.893313            0.603882\n",
      "      9                0.30006143         0.287093  1.484116         2.700972       0.348694  0.383480                  0.634596          0.655340      0.148366                 0.810458    48.411594       170.097203            0.667142\n",
      "     10                0.40003071         0.151290  1.019921         2.280871       0.239631  0.212501                  0.535893          0.544672      0.101961                 0.912418     1.992109       128.087062            0.669745\n",
      "     11                0.50000000         0.067536  0.542650         1.933333       0.127496  0.104750                  0.454238          0.456715      0.054248                 0.966667   -45.734968        93.333333            0.609983\n",
      "     12                0.59996929         0.028311  0.169987         1.639517       0.039939  0.044930                  0.385206          0.388102      0.016993                 0.983660   -83.001315        63.951747            0.501524\n",
      "     13                0.69993857         0.012481  0.084993         1.417491       0.019969  0.019408                  0.333041          0.335443      0.008497                 0.992157   -91.500658        41.749133            0.381960\n",
      "     14                0.79990786         0.005519  0.065380         1.248510       0.015361  0.008608                  0.293338          0.294596      0.006536                 0.998693   -93.462044        24.850981            0.259833\n",
      "     15                0.89987715         0.001555  0.013076         1.111263       0.003072  0.003235                  0.261092          0.262228      0.001307                 1.000000   -98.692409        11.126280            0.130871\n",
      "     16                1.00000000         0.000084  0.000000         1.000000       0.000000  0.000845                  0.234951          0.236058      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6135.072266          1.000000   0.290844\n",
      "                      capital_gain         3657.295410          0.596129   0.173381\n",
      "                               age         2044.541504          0.333255   0.096925\n",
      "                            fnlwgt         1654.933716          0.269750   0.078455\n",
      "                      capital_loss         1313.221313          0.214051   0.062256\n",
      "                    hours_per_week         1209.654419          0.197170   0.057346\n",
      "       occupation. Exec-managerial          638.469238          0.104069   0.030268\n",
      "        occupation. Prof-specialty          621.389099          0.101285   0.029458\n",
      "              education. Bachelors          494.951904          0.080676   0.023464\n",
      "                education. Masters          256.378052          0.041789   0.012154\n",
      "---\n",
      "                   education. 12th           13.561639          0.002211   0.000643\n",
      "         marital_status. Separated            9.593512          0.001564   0.000455\n",
      "           native_country. Germany            7.056383          0.001150   0.000335\n",
      "                 native_country.NA            6.232629          0.001016   0.000295\n",
      "            native_country. Canada            4.357147          0.000710   0.000207\n",
      "          race. Amer-Indian-Eskimo            4.338013          0.000707   0.000206\n",
      "                education. 1st-4th            4.297473          0.000700   0.000204\n",
      "                      workclass.NA            4.086454          0.000666   0.000194\n",
      "             native_country. India            3.007887          0.000490   0.000143\n",
      "       native_country. Philippines            2.614272          0.000426   0.000124\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        84646.320313          1.000000   0.121149\n",
      "                      capital_gain        84075.390625          0.993255   0.120332\n",
      "                            fnlwgt        83149.757813          0.982320   0.119007\n",
      "                      capital_loss        62230.054688          0.735177   0.089066\n",
      "                    hours_per_week        48245.222656          0.569962   0.069050\n",
      "marital_status. Married-civ-spouse        33853.070313          0.399936   0.048452\n",
      "              education. Bachelors        14598.665039          0.172467   0.020894\n",
      "       occupation. Exec-managerial        14461.186523          0.170842   0.020697\n",
      "                education. Masters        13786.879883          0.162876   0.019732\n",
      "            education. Prof-school        12103.163086          0.142985   0.017322\n",
      "---\n",
      "             relationship. Husband         2202.967773          0.026026   0.003153\n",
      "                       race. White         1645.513794          0.019440   0.002355\n",
      "            native_country. Canada         1373.848999          0.016230   0.001966\n",
      "       native_country. Philippines         1311.490234          0.015494   0.001877\n",
      "             native_country. India         1254.505981          0.014821   0.001795\n",
      "                education. 1st-4th         1250.632324          0.014775   0.001790\n",
      "                 native_country.NA         1201.647095          0.014196   0.001720\n",
      "         marital_status. Separated         1175.023315          0.013882   0.001682\n",
      "                      workclass.NA          866.905518          0.010242   0.001241\n",
      "          marital_status. Divorced          720.736694          0.008515   0.001032\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          619.000000          1.000000   0.252036\n",
      "                        age          520.000000          0.840065   0.211726\n",
      "             hours_per_week          230.000000          0.371567   0.093648\n",
      "               capital_gain          100.000000          0.161551   0.040717\n",
      "               capital_loss           80.000000          0.129241   0.032573\n",
      "         workclass. Private           65.000000          0.105008   0.026466\n",
      "         education. HS-grad           62.000000          0.100162   0.025244\n",
      "       education. Bachelors           54.000000          0.087237   0.021987\n",
      " occupation. Prof-specialty           46.000000          0.074313   0.018730\n",
      "occupation. Exec-managerial           42.000000          0.067851   0.017101\n",
      "---\n",
      "            education. 12th            2.000000          0.003231   0.000814\n",
      "  marital_status. Separated            2.000000          0.003231   0.000814\n",
      "   race. Amer-Indian-Eskimo            2.000000          0.003231   0.000814\n",
      "    native_country. Germany            2.000000          0.003231   0.000814\n",
      "          native_country.NA            2.000000          0.003231   0.000814\n",
      "     native_country. Canada            1.000000          0.001616   0.000407\n",
      "               workclass.NA            1.000000          0.001616   0.000407\n",
      "         education. 1st-4th            1.000000          0.001616   0.000407\n",
      "      native_country. India            1.000000          0.001616   0.000407\n",
      "native_country. Philippines            1.000000          0.001616   0.000407\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              45\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.386 sec               0       0.50000          0.69315      0.50000         0.24227       1.00000                       0.75773         0.50000            0.69315        0.50000           0.23495         1.00000                         0.76505\n",
      " 2023-10-20 18:27:41  0.891 sec               5       0.31588          0.34085      0.92220         0.82109       4.12269                       0.14100         0.31899            0.34521        0.91452           0.79888         4.25621                         0.14942\n",
      " 2023-10-20 18:27:42  1.419 sec              10       0.29751          0.28785      0.93056         0.83631       4.12756                       0.13102         0.30250            0.29557        0.92155           0.81372         4.25621                         0.14635\n",
      " 2023-10-20 18:27:43  2.376 sec              15       0.28996          0.27023      0.93677         0.84891       4.12756                       0.12430         0.29829            0.28306        0.92501           0.82110         4.25621                         0.13483\n",
      " 2023-10-20 18:27:44  3.326 sec              20       0.28648          0.26186      0.93939         0.85383       4.12756                       0.12626         0.29792            0.28059        0.92504           0.82037         4.25621                         0.12853\n",
      " 2023-10-20 18:27:45  4.269 sec              25       0.28404          0.25689      0.94168         0.85767       4.12756                       0.12000         0.29713            0.27903        0.92592           0.82214         4.25621                         0.14097\n",
      " 2023-10-20 18:27:46  5.267 sec              30       0.28109          0.25176      0.94415         0.86293       4.12756                       0.11666         0.29695            0.27845        0.92622           0.82274         4.25621                         0.12454\n",
      " 2023-10-20 18:27:47  6.306 sec              35       0.27769          0.24631      0.94689         0.86883       4.12756                       0.11386         0.29742            0.27907        0.92592           0.82178         4.25621                         0.14327\n",
      " 2023-10-20 18:27:47  7.027 sec              40       0.27599          0.24323      0.94827         0.87165       4.12756                       0.11309         0.29776            0.27962        0.92569           0.82138         4.25621                         0.13529\n",
      " 2023-10-20 18:27:48  7.857 sec              45       0.27320          0.23860      0.95052         0.87659       4.12756                       0.10760         0.29808            0.28060        0.92521           0.82067         4.25621                         0.13529\n",
      "\n",
      "10-20 18:27:49.784 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: In-training scoring took 4824ms.\n",
      "10-20 18:27:49.801 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model XGBoost_2_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:49.940 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_384\n",
      "10-20 18:27:49.954 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_384\n",
      "10-20 18:27:49.959 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.07369841\n",
      " RMSE: 0.2714745\n",
      " AUC: 0.9517113\n",
      " pr_auc: 0.8768454\n",
      " logloss: 0.23584324\n",
      " mean_per_class_error: 0.13168417\n",
      " default threshold: 0.3614193797111511\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18005  1828  0.0922  1,828 / 19,833\n",
      "     1   1064  5151  0.1712   1,064 / 6,215\n",
      "Totals  19069  6979  0.1110  2,892 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.82 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001996         0.996947  4.191150         4.191150       1.000000  0.997896                  1.000000          0.997896      0.041995                 0.041995   319.115044       319.115044            0.041995\n",
      "      2                0.02000154         0.994696  4.191150         4.191150       1.000000  0.995862                  1.000000          0.996881      0.041834                 0.083829   319.115044       319.115044            0.083829\n",
      "      3                0.03002150         0.990683  4.191150         4.191150       1.000000  0.992944                  1.000000          0.995567      0.041995                 0.125825   319.115044       319.115044            0.125825\n",
      "      4                0.04000307         0.982836  4.175031         4.187128       0.996154  0.987070                  0.999040          0.993447      0.041673                 0.167498   317.503063       318.712823            0.167448\n",
      "      5                0.05002303         0.966171  4.175092         4.184717       0.996169  0.975728                  0.998465          0.989898      0.041834                 0.209332   317.509239       318.471736            0.209231\n",
      "      6                0.10000768         0.787833  3.943287         4.064048       0.940860  0.878661                  0.969674          0.934301      0.197104                 0.406436   294.328671       306.404838            0.402453\n",
      "      7                0.15003071         0.645943  3.245488         3.791125       0.774367  0.713720                  0.904555          0.860755      0.162349                 0.568785   224.548795       279.112508            0.549978\n",
      "      8                0.20001536         0.509051  2.623493         3.499329       0.625960  0.576811                  0.834933          0.789796      0.131134                 0.699920   162.349279       249.932906            0.656557\n",
      "      9                0.30002303         0.304944  1.686113         2.894924       0.402303  0.396899                  0.690723          0.658830      0.168624                 0.868544    68.611350       189.492388            0.746676\n",
      "     10                0.39999232         0.154004  0.828895         2.378565       0.197773  0.223670                  0.567521          0.550072      0.082864                 0.951408   -17.110504       137.856537            0.724211\n",
      "     11                0.50000000         0.067170  0.333040         1.969429       0.079463  0.105151                  0.469902          0.461081      0.033307                 0.984714   -66.696041        96.942880            0.636608\n",
      "     12                0.60000768         0.028462  0.104578         1.658600       0.024952  0.045060                  0.395739          0.391739      0.010459                 0.995173   -89.542235        65.860039            0.518997\n",
      "     13                0.69997697         0.012285  0.037019         1.427009       0.008833  0.019196                  0.340482          0.338533      0.003701                 0.998874   -96.298139        42.700938            0.392561\n",
      "     14                0.79998464         0.005278  0.008044         1.249622       0.001919  0.008319                  0.298157          0.297253      0.000805                 0.999678   -99.195557        24.962173            0.262271\n",
      "     15                0.89999232         0.001781  0.003218         1.111121       0.000768  0.003294                  0.265111          0.264588      0.000322                 1.000000   -99.678223        11.112059            0.131347\n",
      "     16                1.00000000         0.000089  0.000000         1.000000       0.000000  0.000925                  0.238598          0.238220      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.09053288\n",
      " RMSE: 0.3008868\n",
      " AUC: 0.92660946\n",
      " pr_auc: 0.83370733\n",
      " logloss: 0.28564513\n",
      " mean_per_class_error: 0.16851376\n",
      " default threshold: 0.34693124890327454\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4355   532  0.1089  532 / 4,887\n",
      "     1   371  1255  0.2282  371 / 1,626\n",
      "Totals  4726  1787  0.1386  903 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.96 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013358         0.996852  4.005535         4.005535       1.000000  0.997830                  1.000000          0.997830      0.040590                 0.040590   300.553506       300.553506            0.040590\n",
      "      2                0.02011362         0.994518  4.005535         4.005535       1.000000  0.995787                  1.000000          0.996816      0.039975                 0.080566   300.553506       300.553506            0.080566\n",
      "      3                0.03009366         0.991139  4.005535         4.005535       1.000000  0.993017                  1.000000          0.995556      0.039975                 0.120541   300.553506       300.553506            0.120541\n",
      "      4                0.04007370         0.984199  4.005535         4.005535       1.000000  0.988199                  1.000000          0.993724      0.039975                 0.160517   300.553506       300.553506            0.160517\n",
      "      5                0.05005374         0.968426  4.005535         4.005535       1.000000  0.977465                  1.000000          0.990482      0.039975                 0.200492   300.553506       300.553506            0.200492\n",
      "      6                0.10010748         0.794822  3.477198         3.741366       0.868098  0.886252                  0.934049          0.938367      0.174047                 0.374539   247.719761       274.136633            0.365740\n",
      "      7                0.15000768         0.648786  2.970258         3.484856       0.741538  0.721928                  0.870010          0.866368      0.148216                 0.522755   197.025830       248.485650            0.496768\n",
      "      8                0.20006142         0.517794  2.383662         3.209347       0.595092  0.579574                  0.801228          0.794615      0.119311                 0.642066   138.366197       220.934658            0.589069\n",
      "      9                0.30001535         0.302252  1.648976         2.689489       0.411674  0.398243                  0.671443          0.662558      0.164822                 0.806888    64.897603       168.948925            0.675519\n",
      "     10                0.39996929         0.152466  0.953699         2.255708       0.238095  0.223887                  0.563148          0.552932      0.095326                 0.902214    -4.630118       125.570823            0.669351\n",
      "     11                0.50007677         0.069484  0.577485         1.919754       0.144172  0.106039                  0.479275          0.463471      0.057811                 0.960025   -42.251488        91.975444            0.612981\n",
      "     12                0.60003071         0.029510  0.264575         1.644032       0.066052  0.046113                  0.410440          0.393947      0.026445                 0.986470   -73.542549        64.403230            0.515015\n",
      "     13                0.69998465         0.012395  0.079988         1.420695       0.019969  0.019411                  0.354683          0.340466      0.007995                 0.994465   -92.001236        42.069537            0.392460\n",
      "     14                0.79993858         0.005604  0.036917         1.247790       0.009217  0.008618                  0.311516          0.299001      0.003690                 0.998155   -96.308263        24.778952            0.264167\n",
      "     15                0.89989252         0.001875  0.018459         1.111244       0.004608  0.003542                  0.277427          0.266183      0.001845                 1.000000   -98.154131        11.124382            0.133415\n",
      "     16                1.00000000         0.000104  0.000000         1.000000       0.000000  0.000971                  0.249655          0.239633      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5156.290527          1.000000   0.242935\n",
      "                      capital_gain         3728.930176          0.723181   0.175686\n",
      "                               age         2080.204590          0.403430   0.098007\n",
      "                            fnlwgt         1879.766846          0.364558   0.088564\n",
      "                      capital_loss         1328.113647          0.257572   0.062573\n",
      "                    hours_per_week         1296.790649          0.251497   0.061097\n",
      "     marital_status. Never-married          726.741150          0.140943   0.034240\n",
      "        occupation. Prof-specialty          547.330688          0.106148   0.025787\n",
      "       occupation. Exec-managerial          532.884094          0.103346   0.025106\n",
      "              education. Bachelors          390.119934          0.075659   0.018380\n",
      "---\n",
      "       native_country. Philippines           15.814737          0.003067   0.000745\n",
      "                   education. 12th           13.833382          0.002683   0.000652\n",
      "                education. 1st-4th           13.181145          0.002556   0.000621\n",
      "          race. Amer-Indian-Eskimo           12.538165          0.002432   0.000591\n",
      "         marital_status. Separated           10.034459          0.001946   0.000473\n",
      "                 native_country.NA            8.990942          0.001744   0.000424\n",
      "       native_country. Puerto-Rico            7.210544          0.001398   0.000340\n",
      "             education. Assoc-acdm            5.504598          0.001068   0.000259\n",
      "                      workclass.NA            2.801810          0.000543   0.000132\n",
      "             native_country. India            2.298777          0.000446   0.000108\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        95765.601563          1.000000   0.136849\n",
      "                      capital_gain        82356.093750          0.859976   0.117687\n",
      "                               age        75691.296875          0.790381   0.108163\n",
      "                    hours_per_week        58748.085938          0.613457   0.083951\n",
      "                      capital_loss        57414.875000          0.599535   0.082046\n",
      "marital_status. Married-civ-spouse        28118.025391          0.293613   0.040181\n",
      "        occupation. Prof-specialty        13455.442383          0.140504   0.019228\n",
      "              education. Doctorate        13332.768555          0.139223   0.019053\n",
      "              education. Bachelors        12666.846680          0.132269   0.018101\n",
      "     marital_status. Never-married        12043.407227          0.125759   0.017210\n",
      "---\n",
      "           relationship. Unmarried         2090.959717          0.021834   0.002988\n",
      "         marital_status. Separated         2018.135010          0.021074   0.002884\n",
      "          race. Asian-Pac-Islander         1824.049194          0.019047   0.002607\n",
      "              education. Assoc-voc         1800.567505          0.018802   0.002573\n",
      "                 native_country.NA         1752.922607          0.018304   0.002505\n",
      "       native_country. Puerto-Rico         1487.620605          0.015534   0.002126\n",
      "             relationship. Husband         1342.676147          0.014020   0.001919\n",
      "                      workclass.NA         1260.344727          0.013161   0.001801\n",
      "             education. Assoc-acdm          806.074280          0.008417   0.001152\n",
      "             native_country. India           35.474113          0.000370   0.000051\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          734.000000          1.000000   0.285937\n",
      "                        age          514.000000          0.700272   0.200234\n",
      "             hours_per_week          259.000000          0.352861   0.100896\n",
      "               capital_loss           87.000000          0.118529   0.033892\n",
      "               capital_gain           86.000000          0.117166   0.033502\n",
      "         workclass. Private           68.000000          0.092643   0.026490\n",
      "         education. HS-grad           59.000000          0.080381   0.022984\n",
      " occupation. Prof-specialty           53.000000          0.072207   0.020647\n",
      "    education. Some-college           46.000000          0.062670   0.017920\n",
      "       education. Bachelors           46.000000          0.062670   0.017920\n",
      "---\n",
      "native_country. Philippines            4.000000          0.005450   0.001558\n",
      "         education. 5th-6th            4.000000          0.005450   0.001558\n",
      "            education. 12th            3.000000          0.004087   0.001169\n",
      "         education. 1st-4th            3.000000          0.004087   0.001169\n",
      "          native_country.NA            3.000000          0.004087   0.001169\n",
      "  marital_status. Separated            2.000000          0.002725   0.000779\n",
      "               workclass.NA            2.000000          0.002725   0.000779\n",
      "      education. Assoc-acdm            2.000000          0.002725   0.000779\n",
      "      native_country. India            1.000000          0.001362   0.000390\n",
      "native_country. Puerto-Rico            1.000000          0.001362   0.000390\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              45\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:41  0.364 sec               0       0.50000          0.69315      0.50000         0.23860       1.00000                       0.76140         0.50000            0.69315        0.50000           0.24965         1.00000                         0.75035\n",
      " 2023-10-20 18:27:41  0.870 sec               5       0.31539          0.34016      0.92307         0.81933       4.19115                       0.14489         0.32114            0.34917        0.91613           0.81882         4.00554                         0.14801\n",
      " 2023-10-20 18:27:42  1.416 sec              10       0.29670          0.28603      0.93138         0.83468       4.19115                       0.13514         0.30625            0.30218        0.92161           0.82801         4.00554                         0.13772\n",
      " 2023-10-20 18:27:43  2.375 sec              15       0.28974          0.26868      0.93665         0.84467       4.19115                       0.12389         0.30259            0.29026        0.92510           0.83170         4.00554                         0.13281\n",
      " 2023-10-20 18:27:44  3.197 sec              20       0.28642          0.26137      0.93934         0.85005       4.19115                       0.12247         0.30049            0.28515        0.92721           0.83523         4.00554                         0.13082\n",
      " 2023-10-20 18:27:44  3.876 sec              25       0.28313          0.25490      0.94227         0.85560       4.19115                       0.12024         0.29943            0.28298        0.92811           0.83677         4.00554                         0.13005\n",
      " 2023-10-20 18:27:46  5.162 sec              30       0.27988          0.24913      0.94497         0.86145       4.19115                       0.11582         0.29938            0.28309        0.92789           0.83651         4.00554                         0.13143\n",
      " 2023-10-20 18:27:46  6.081 sec              35       0.27683          0.24426      0.94743         0.86727       4.19115                       0.11041         0.30025            0.28414        0.92732           0.83485         4.00554                         0.13726\n",
      " 2023-10-20 18:27:47  7.122 sec              40       0.27507          0.24124      0.94870         0.87026       4.19115                       0.11318         0.30010            0.28394        0.92739           0.83526         4.00554                         0.14648\n",
      " 2023-10-20 18:27:48  8.075 sec              45       0.27147          0.23584      0.95171         0.87685       4.19115                       0.11103         0.30089            0.28565        0.92661           0.83371         4.00554                         0.13865\n",
      "\n",
      "10-20 18:27:49.963 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: In-training scoring took 5100ms.\n",
      "10-20 18:27:49.971 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model XGBoost_2_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:49.971 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:49.971 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 5 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:49.972 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_5_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":44,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":4,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":10000,\"_n_estimators\":0,\"_max_depth\":10,\"_min_rows\":5.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:49.974 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:49.982 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:49.984 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:50.010 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:50.010 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      "10-20 18:27:50.011 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:50.013 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  seed = 44\n",
      "10-20 18:27:50.014 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 10\n",
      "10-20 18:27:50.014 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:50.014 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  nround = 10000\n",
      "10-20 18:27:50.014 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:50.014 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 5.0\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:50.015 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:50.044 172.17.0.2:54321      22766  82658_cv_5  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:50.054 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_385\n",
      "10-20 18:27:50.058 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_385\n",
      "10-20 18:27:50.072 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_386\n",
      "10-20 18:27:50.074 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_386\n",
      "10-20 18:27:50.077 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2400476\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19796  1.0000  19,796 / 19,796\n",
      "     1  0   6253  0.0000        0 / 6,253\n",
      "Totals  0  26049  0.7600  19,796 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.240048  0.500000                  0.240048          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24385749\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4924  1.0000  4,924 / 4,924\n",
      "     1  0  1588  0.0000      0 / 1,588\n",
      "Totals  0  6512  0.7561  4,924 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.243857  0.500000                  0.243857          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      "\n",
      "10-20 18:27:50.121 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:50.121) \n",
      "10-20 18:27:50.155 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:50.155) \n",
      "10-20 18:27:50.194 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:50.194) \n",
      "10-20 18:27:50.231 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:50.231) \n",
      "10-20 18:27:50.273 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:50.273) \n",
      "10-20 18:27:50.308 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_387\n",
      "10-20 18:27:50.328 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_387\n",
      "10-20 18:27:50.363 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_388\n",
      "10-20 18:27:50.372 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_388\n",
      "10-20 18:27:50.376 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.09941302\n",
      " RMSE: 0.31529832\n",
      " AUC: 0.922394\n",
      " pr_auc: 0.8190859\n",
      " logloss: 0.33963236\n",
      " mean_per_class_error: 0.18343584\n",
      " default threshold: 0.3813055157661438\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17928  1868  0.0944  1,868 / 19,796\n",
      "     1   1704  4549  0.2725   1,704 / 6,253\n",
      "Totals  19632  6417  0.1371  3,572 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 29.15 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03263081         0.895810  4.160939         4.160939       0.998824  0.895810                  0.998824          0.895810      0.135775                 0.135775  316.093941       316.093941            0.135724\n",
      "      2                0.04011670         0.878752  4.144477         4.157867       0.994872  0.882316                  0.998086          0.893292      0.031025                 0.166800  314.447711       315.786750            0.166699\n",
      "      3                0.05071212         0.847097  4.120560         4.150073       0.989130  0.863062                  0.996215          0.886976      0.043659                 0.210459  312.055952       315.007264            0.210206\n",
      "      4                0.10000384         0.672035  3.633755         3.895581       0.872274  0.752521                  0.935125          0.820704      0.179114                 0.389573  263.375486       289.558050            0.381036\n",
      "      5                0.15010173         0.552855  2.860225         3.550021       0.686590  0.612810                  0.852174          0.751317      0.143291                 0.532864  186.022452       255.002051            0.503666\n",
      "      6                0.20012285         0.451609  2.199615         3.212484       0.528012  0.501472                  0.771149          0.688868      0.110027                 0.642891  119.961488       221.248387            0.582627\n",
      "      7                0.30016507         0.336378  1.582572         2.669249       0.379893  0.384670                  0.640747          0.587482      0.158324                 0.801215   58.257175       166.924931            0.659318\n",
      "      8                0.40062958         0.272128  1.029919         2.258160       0.247230  0.306936                  0.542066          0.517130      0.103470                 0.904686    2.991927       125.816013            0.663273\n",
      "      9                0.50036470         0.199438  0.545183         1.916721       0.130870  0.236915                  0.460104          0.461276      0.054374                 0.959060  -45.481688        91.672126            0.603584\n",
      "     10                0.60221122         0.134412  0.260659         1.636647       0.062571  0.164713                  0.392873          0.411121      0.026547                 0.985607  -73.934056        63.664655            0.504500\n",
      "     11                0.75300395         0.112019  0.072117         1.323342       0.017312  0.117294                  0.317665          0.352281      0.010875                 0.996482  -92.788260        32.334191            0.320386\n",
      "     12                0.84736458         0.106571  0.032201         1.179563       0.007730  0.108034                  0.283151          0.325082      0.003039                 0.999520  -96.779863        17.956338            0.200217\n",
      "     13                1.00000000         0.104874  0.003143         1.000000       0.000755  0.104939                  0.240048          0.291480      0.000480                 1.000000  -99.685676         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.10490655\n",
      " RMSE: 0.3238928\n",
      " AUC: 0.910937\n",
      " pr_auc: 0.7991666\n",
      " logloss: 0.35305962\n",
      " mean_per_class_error: 0.17632446\n",
      " default threshold: 0.32799017429351807\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error           Rate\n",
      "     0  4186   738  0.1499    738 / 4,924\n",
      "     1   322  1266  0.2028    322 / 1,588\n",
      "Totals  4508  2004  0.1628  1,060 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 29.19 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.03270885         0.895810  4.100756         4.100756       1.000000  0.895810                  1.000000          0.895810      0.134131                 0.134131  310.075567       310.075567            0.134131\n",
      "      2                0.04054054         0.878680  4.100756         4.100756       1.000000  0.881699                  1.000000          0.893084      0.032116                 0.166247  310.075567       310.075567            0.166247\n",
      "      3                0.05036855         0.847097  4.100756         4.100756       1.000000  0.863029                  1.000000          0.887220      0.040302                 0.206549  310.075567       310.075567            0.206549\n",
      "      4                0.10012285         0.670387  3.316043         3.710807       0.808642  0.744443                  0.904908          0.816269      0.164987                 0.371537  231.604316       271.080651            0.358945\n",
      "      5                0.15018428         0.545219  2.905750         3.442454       0.708589  0.609791                  0.839468          0.747443      0.145466                 0.517003  190.575018       244.245440            0.485118\n",
      "      6                0.20024570         0.451609  2.050378         3.094435       0.500000  0.496682                  0.754601          0.684753      0.102645                 0.619647  105.037783       209.443526            0.554660\n",
      "      7                0.30021499         0.336774  1.656680         2.615674       0.403994  0.385556                  0.637852          0.585123      0.165617                 0.785264   65.668009       161.567382            0.641479\n",
      "      8                0.40003071         0.271431  0.990490         2.210158       0.241538  0.306797                  0.538964          0.515675      0.098866                 0.884131   -0.950978       121.015776            0.640224\n",
      "      9                0.50000000         0.200938  0.611019         1.890428       0.149002  0.238963                  0.460995          0.460349      0.061083                 0.945214  -38.898111        89.042821            0.588797\n",
      "     10                0.59996929         0.139692  0.314958         1.627917       0.076805  0.171245                  0.396980          0.412178      0.031486                 0.976700  -68.504181        62.791708            0.498227\n",
      "     11                0.75721744         0.112019  0.108125         1.312308       0.026367  0.119739                  0.320016          0.351448      0.017003                 0.993703  -89.187461        31.230834            0.312752\n",
      "     12                0.80021499         0.108347  0.058582         1.244943       0.014286  0.109763                  0.303589          0.338462      0.002519                 0.996222  -94.141778        24.494252            0.259219\n",
      "     13                1.00000000         0.104874  0.018912         1.000000       0.004612  0.105352                  0.243857          0.291890      0.003778                 1.000000  -98.108798         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         5310.511719          1.000000   0.410534\n",
      "                      capital_gain         2822.990723          0.531585   0.218234\n",
      "                      capital_loss          885.509338          0.166747   0.068455\n",
      "                               age          795.692871          0.149834   0.061512\n",
      "        occupation. Prof-specialty          555.686035          0.104639   0.042958\n",
      "       occupation. Exec-managerial          533.859131          0.100529   0.041270\n",
      "                    hours_per_week          470.980896          0.088688   0.036410\n",
      "              education. Bachelors          327.503632          0.061671   0.025318\n",
      "                education. HS-grad          112.013206          0.021093   0.008659\n",
      "       workclass. Self-emp-not-inc          110.612724          0.020829   0.008551\n",
      "---\n",
      "     occupation. Handlers-cleaners            9.394995          0.001769   0.000726\n",
      "              education. Assoc-voc            8.953053          0.001686   0.000692\n",
      "             relationship. Husband            6.975345          0.001313   0.000539\n",
      "            native_country. Mexico            5.770859          0.001087   0.000446\n",
      "             education. Assoc-acdm            4.424337          0.000833   0.000342\n",
      "                   education. 10th            3.939209          0.000742   0.000305\n",
      "          occupation. Craft-repair            3.769367          0.000710   0.000291\n",
      "              workclass. State-gov            3.676487          0.000692   0.000284\n",
      "      occupation. Transport-moving            2.651623          0.000499   0.000205\n",
      "           relationship. Own-child            0.552917          0.000104   0.000043\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        20211.564453          1.000000   0.151374\n",
      "                      capital_gain        16998.304688          0.841019   0.127308\n",
      "marital_status. Married-civ-spouse        16616.494141          0.822128   0.124448\n",
      "                    hours_per_week        13609.775391          0.673366   0.101930\n",
      "                      capital_loss        11724.636719          0.580095   0.087811\n",
      "        occupation. Prof-specialty         9596.709961          0.474813   0.071874\n",
      "       occupation. Exec-managerial         7878.172363          0.389785   0.059003\n",
      "              education. Bachelors         5615.949219          0.277858   0.042060\n",
      "                education. Masters         3919.856201          0.193941   0.029358\n",
      "          occupation. Tech-support         2503.505371          0.123865   0.018750\n",
      "---\n",
      "                   education. 10th          247.525925          0.012247   0.001854\n",
      "           workclass. Self-emp-inc          244.569366          0.012100   0.001832\n",
      "                         sex. Male          240.959351          0.011922   0.001805\n",
      "             education. Assoc-acdm          219.599426          0.010865   0.001645\n",
      "     marital_status. Never-married          141.731873          0.007012   0.001061\n",
      "             relationship. Husband          140.492004          0.006951   0.001052\n",
      "              workclass. State-gov          136.802460          0.006769   0.001025\n",
      "          marital_status. Divorced          117.543167          0.005816   0.000880\n",
      "           relationship. Own-child          108.000000          0.005343   0.000809\n",
      "      occupation. Transport-moving           56.207062          0.002781   0.000421\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          126.000000          1.000000   0.280000\n",
      "               hours_per_week           40.000000          0.317460   0.088889\n",
      "                       fnlwgt           29.000000          0.230159   0.064444\n",
      "  occupation. Exec-managerial           22.000000          0.174603   0.048889\n",
      "                 capital_loss           21.000000          0.166667   0.046667\n",
      "                 capital_gain           18.000000          0.142857   0.040000\n",
      "   occupation. Prof-specialty           16.000000          0.126984   0.035556\n",
      "         education. Bachelors           15.000000          0.119048   0.033333\n",
      "           workclass. Private           15.000000          0.119048   0.033333\n",
      "           education. HS-grad           14.000000          0.111111   0.031111\n",
      "---\n",
      "      workclass. Self-emp-inc            2.000000          0.015873   0.004444\n",
      "        relationship. Husband            2.000000          0.015873   0.004444\n",
      "        education. Assoc-acdm            2.000000          0.015873   0.004444\n",
      "       native_country. Mexico            2.000000          0.015873   0.004444\n",
      "         workclass. State-gov            1.000000          0.007937   0.002222\n",
      "occupation. Handlers-cleaners            1.000000          0.007937   0.002222\n",
      "      relationship. Own-child            1.000000          0.007937   0.002222\n",
      "         education. Assoc-voc            1.000000          0.007937   0.002222\n",
      "              education. 10th            1.000000          0.007937   0.002222\n",
      " occupation. Transport-moving            1.000000          0.007937   0.002222\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      "\n",
      "█10-20 18:27:50.416 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:50.416) \n",
      "10-20 18:27:50.457 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:50.457) \n",
      "10-20 18:27:50.491 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:50.491) \n",
      "10-20 18:27:50.537 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:50.537) \n",
      "10-20 18:27:50.562 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:50.582 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:50.582) \n",
      "10-20 18:27:50.612 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_389\n",
      "10-20 18:27:50.627 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_389\n",
      "10-20 18:27:50.668 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_390\n",
      "10-20 18:27:50.679 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_390\n",
      "10-20 18:27:50.682 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.088152625\n",
      " RMSE: 0.29690507\n",
      " AUC: 0.93095374\n",
      " pr_auc: 0.83522385\n",
      " logloss: 0.2864024\n",
      " mean_per_class_error: 0.1752657\n",
      " default threshold: 0.38862144947052\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18147  1649  0.0833  1,649 / 19,796\n",
      "     1   1671  4582  0.2672   1,671 / 6,253\n",
      "Totals  19818  6231  0.1275  3,320 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 25.07 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.02506814         0.966122  4.165840         4.165840       1.000000  0.967904                  1.000000          0.967904      0.104430                 0.104430   316.584040       316.584040            0.104430\n",
      "      2                0.03021229         0.959127  4.165840         4.165840       1.000000  0.962404                  1.000000          0.966967      0.021430                 0.125860   316.584040       316.584040            0.125860\n",
      "      3                0.04000154         0.936128  4.165840         4.165840       1.000000  0.946709                  1.000000          0.962010      0.040780                 0.166640   316.584040       316.584040            0.166640\n",
      "      4                0.05028984         0.919479  4.119208         4.156300       0.988806  0.926897                  0.997710          0.954826      0.042380                 0.209020   311.920785       315.630030            0.208868\n",
      "      5                0.10008062         0.708134  3.735445         3.946922       0.896685  0.804470                  0.947449          0.880023      0.185991                 0.395010   273.544517       294.692205            0.388090\n",
      "      6                0.15002495         0.573592  2.923453         3.606202       0.701768  0.642459                  0.865660          0.800936      0.146010                 0.541020   192.345295       260.620217            0.514500\n",
      "      7                0.20008446         0.460092  2.351272         3.292229       0.564417  0.515991                  0.790292          0.729645      0.117704                 0.658724   135.127188       229.222882            0.603511\n",
      "      8                0.30001152         0.312338  1.590797         2.725520       0.381867  0.377722                  0.654255          0.612428      0.158964                 0.817688    59.079729       172.552040            0.681195\n",
      "      9                0.40005374         0.223498  1.021478         2.299387       0.245203  0.271713                  0.551962          0.527224      0.102191                 0.919878     2.147813       129.938720            0.684023\n",
      "     10                0.50124765         0.123347  0.478850         1.931850       0.114947  0.171358                  0.463736          0.455381      0.048457                 0.968335   -52.114961        93.184986            0.614627\n",
      "     11                0.59998464         0.061008  0.202461         1.647251       0.048600  0.088554                  0.395419          0.395014      0.019990                 0.988326   -79.753886        64.725150            0.511007\n",
      "     12                0.69998848         0.039951  0.073562         1.422426       0.017658  0.048514                  0.341450          0.345511      0.007356                 0.995682   -92.643814        42.242636            0.389095\n",
      "     13                0.80018427         0.031931  0.031922         1.248313       0.007663  0.035425                  0.299655          0.306683      0.003198                 0.998881   -96.807785        24.831314            0.261459\n",
      "     14                0.99850282         0.024657  0.005645         1.001499       0.001355  0.026409                  0.240408          0.251016      0.001119                 1.000000   -99.435523         0.149942            0.001970\n",
      "     15                1.00000000         0.023146  0.000000         1.000000       0.000000  0.024399                  0.240048          0.250677      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09468819\n",
      " RMSE: 0.30771446\n",
      " AUC: 0.91934323\n",
      " pr_auc: 0.8134956\n",
      " logloss: 0.30499274\n",
      " mean_per_class_error: 0.16726664\n",
      " default threshold: 0.3217761218547821\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4269   655  0.1330  655 / 4,924\n",
      "     1   320  1268  0.2015  320 / 1,588\n",
      "Totals  4589  1923  0.1497  975 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 25.14 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.966576  4.100756         4.100756       1.000000  0.971172                  1.000000          0.971172      0.041562                 0.041562   310.075567       310.075567            0.041562\n",
      "      2                0.02549140         0.966122  4.100756         4.100756       1.000000  0.966132                  1.000000          0.968136      0.062972                 0.104534   310.075567       310.075567            0.104534\n",
      "      3                0.03009828         0.955161  4.100756         4.100756       1.000000  0.961377                  1.000000          0.967101      0.018892                 0.123426   310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.937463  4.100756         4.100756       1.000000  0.945496                  1.000000          0.961721      0.040932                 0.164358   310.075567       310.075567            0.164358\n",
      "      5                0.05098280         0.919479  4.100756         4.100756       1.000000  0.927069                  1.000000          0.954310      0.044710                 0.209068   310.075567       310.075567            0.209068\n",
      "      6                0.10012285         0.703794  3.357494         3.735965       0.818750  0.789152                  0.911043          0.873251      0.164987                 0.374055   235.749370       273.596452            0.362276\n",
      "      7                0.15003071         0.573127  2.952544         3.475359       0.720000  0.639555                  0.847492          0.795512      0.147355                 0.521411   195.254408       247.535895            0.491151\n",
      "      8                0.20009214         0.451349  2.239063         3.166048       0.546012  0.514237                  0.772064          0.725139      0.112091                 0.633501   123.906291       216.604774            0.573184\n",
      "      9                0.30052211         0.312832  1.705513         2.677959       0.415902  0.378723                  0.653040          0.609372      0.171285                 0.804786    70.551306       167.795899            0.666890\n",
      "     10                0.40003071         0.222807  0.987219         2.257383       0.240741  0.271709                  0.550480          0.525378      0.098237                 0.903023    -1.278104       125.738335            0.665208\n",
      "     11                0.50000000         0.128851  0.491335         1.904282       0.119816  0.174752                  0.464373          0.455274      0.049118                 0.952141   -50.866522        90.428212            0.597957\n",
      "     12                0.59996929         0.069175  0.264565         1.631066       0.064516  0.096414                  0.397748          0.395479      0.026448                 0.978589   -73.543512        63.106586            0.500726\n",
      "     13                0.69993857         0.041510  0.144881         1.418800       0.035330  0.052135                  0.345985          0.346441      0.014484                 0.993073   -85.511923        41.880028            0.387671\n",
      "     14                0.80082924         0.032064  0.043691         1.245560       0.010654  0.035943                  0.303739          0.307323      0.004408                 0.997481   -95.630854        24.556030            0.260072\n",
      "     15                0.99923219         0.024657  0.012696         1.000768       0.003096  0.026374                  0.244045          0.251539      0.002519                 1.000000   -98.730416         0.076840            0.001015\n",
      "     16                1.00000000         0.023146  0.000000         1.000000       0.000000  0.023985                  0.243857          0.251365      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6010.858398          1.000000   0.380496\n",
      "                      capital_gain         3411.968750          0.567634   0.215983\n",
      "                               age         1197.023315          0.199143   0.075773\n",
      "                      capital_loss         1065.424805          0.177250   0.067443\n",
      "                    hours_per_week          639.635498          0.106413   0.040490\n",
      "        occupation. Prof-specialty          589.725830          0.098110   0.037331\n",
      "       occupation. Exec-managerial          562.921692          0.093651   0.035634\n",
      "              education. Bachelors          353.613525          0.058829   0.022384\n",
      "                            fnlwgt          204.722458          0.034059   0.012959\n",
      "                education. HS-grad          165.680893          0.027564   0.010488\n",
      "---\n",
      "     marital_status. Never-married           11.208782          0.001865   0.000710\n",
      "              education. Assoc-voc            8.953053          0.001489   0.000567\n",
      "             education. Assoc-acdm            6.684325          0.001112   0.000423\n",
      "              workclass. State-gov            6.465282          0.001076   0.000409\n",
      "                     occupation.NA            5.734882          0.000954   0.000363\n",
      "           marital_status. Widowed            4.914797          0.000818   0.000311\n",
      "     occupation. Machine-op-inspct            4.126471          0.000687   0.000261\n",
      "      occupation. Transport-moving            2.651623          0.000441   0.000168\n",
      "          race. Asian-Pac-Islander            2.318298          0.000386   0.000147\n",
      "                       race. Black            0.976868          0.000163   0.000062\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        37250.789063          1.000000   0.164697\n",
      "                               age        31779.166016          0.853114   0.140505\n",
      "marital_status. Married-civ-spouse        26223.730469          0.703978   0.115943\n",
      "                    hours_per_week        18792.996094          0.504499   0.083089\n",
      "                      capital_loss        18385.093750          0.493549   0.081286\n",
      "        occupation. Prof-specialty        10753.517578          0.288679   0.047544\n",
      "       occupation. Exec-managerial         9774.939453          0.262409   0.043218\n",
      "              education. Bachelors         7479.310059          0.200783   0.033068\n",
      "                            fnlwgt         5880.233398          0.157855   0.025998\n",
      "                education. Masters         4917.710938          0.132016   0.021743\n",
      "---\n",
      "          marital_status. Divorced          243.758865          0.006544   0.001078\n",
      "                         sex. Male          240.959351          0.006469   0.001065\n",
      "     marital_status. Never-married          195.791809          0.005256   0.000866\n",
      "             relationship. Husband          193.057678          0.005183   0.000854\n",
      "              workclass. State-gov          184.299164          0.004948   0.000815\n",
      "                       race. Black          167.645508          0.004500   0.000741\n",
      "           marital_status. Widowed          160.897476          0.004319   0.000711\n",
      "          race. Asian-Pac-Islander          157.332199          0.004224   0.000696\n",
      "     occupation. Machine-op-inspct          118.228470          0.003174   0.000523\n",
      "      occupation. Transport-moving           56.207062          0.001509   0.000249\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          186.000000          1.000000   0.251351\n",
      "                       fnlwgt           71.000000          0.381720   0.095946\n",
      "               hours_per_week           69.000000          0.370968   0.093243\n",
      "                 capital_gain           48.000000          0.258065   0.064865\n",
      "                 capital_loss           37.000000          0.198925   0.050000\n",
      "  occupation. Exec-managerial           25.000000          0.134409   0.033784\n",
      "   occupation. Prof-specialty           24.000000          0.129032   0.032432\n",
      "                  sex. Female           21.000000          0.112903   0.028378\n",
      "           workclass. Private           21.000000          0.112903   0.028378\n",
      "         education. Bachelors           20.000000          0.107527   0.027027\n",
      "---\n",
      "occupation. Handlers-cleaners            2.000000          0.010753   0.002703\n",
      "         workclass. State-gov            2.000000          0.010753   0.002703\n",
      "               education. 9th            2.000000          0.010753   0.002703\n",
      "         education. Assoc-voc            1.000000          0.005376   0.001351\n",
      "           education. 7th-8th            1.000000          0.005376   0.001351\n",
      "     race. Asian-Pac-Islander            1.000000          0.005376   0.001351\n",
      "                  race. Black            1.000000          0.005376   0.001351\n",
      "occupation. Machine-op-inspct            1.000000          0.005376   0.001351\n",
      " occupation. Transport-moving            1.000000          0.005376   0.001351\n",
      "           education. 5th-6th            1.000000          0.005376   0.001351\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      "\n",
      "10-20 18:27:50.719 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:50.719) \n",
      "10-20 18:27:50.756 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:50.756) \n",
      "10-20 18:27:50.785 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:50.785) \n",
      "10-20 18:27:50.821 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:50.821) \n",
      "10-20 18:27:50.849 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:50.849) \n",
      "10-20 18:27:50.889 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_391\n",
      "10-20 18:27:50.905 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_391\n",
      "10-20 18:27:50.959 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_392\n",
      "10-20 18:27:50.970 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_392\n",
      "10-20 18:27:50.973 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.08468194\n",
      " RMSE: 0.29100162\n",
      " AUC: 0.9357829\n",
      " pr_auc: 0.8441571\n",
      " logloss: 0.27052453\n",
      " mean_per_class_error: 0.16706747\n",
      " default threshold: 0.3864413797855377\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18155  1641  0.0829  1,641 / 19,796\n",
      "     1   1571  4682  0.2512   1,571 / 6,253\n",
      "Totals  19726  6323  0.1233  3,212 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.25 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01159354         0.986420  4.165840         4.165840       1.000000  0.988062                  1.000000          0.988062      0.048297                 0.048297  316.584040       316.584040            0.048297\n",
      "      2                0.02003916         0.984098  4.165840         4.165840       1.000000  0.985088                  1.000000          0.986808      0.035183                 0.083480  316.584040       316.584040            0.083480\n",
      "      3                0.03002035         0.977534  4.165840         4.165840       1.000000  0.981731                  1.000000          0.985120      0.041580                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.957768  4.165840         4.165840       1.000000  0.966712                  1.000000          0.980527      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.942358  4.086035         4.149855       0.980843  0.950442                  0.996163          0.974501      0.040940                 0.207580  308.603503       314.985482            0.207328\n",
      "      6                0.10000384         0.735147  3.753096         3.951551       0.900922  0.832599                  0.948560          0.903577      0.187590                 0.395170  275.309584       295.155149            0.388401\n",
      "      7                0.15002495         0.593465  3.011682         3.638181       0.722947  0.664994                  0.873337          0.824029      0.150648                 0.545818  201.168201       263.818149            0.520813\n",
      "      8                0.20000768         0.469584  2.348485         3.315881       0.563748  0.528015                  0.795969          0.750054      0.117384                 0.663202  134.848452       231.588102            0.609504\n",
      "      9                0.30001152         0.312583  1.658340         2.763367       0.398081  0.381156                  0.663340          0.627088      0.165840                 0.829042   65.834030       176.336745            0.696136\n",
      "     10                0.40001536         0.197136  0.996284         2.321596       0.239155  0.254313                  0.557294          0.533894      0.099632                 0.928674   -0.371648       132.159647            0.695647\n",
      "     11                0.50001919         0.099660  0.436574         1.944592       0.104798  0.144853                  0.466795          0.456086      0.043659                 0.972333  -56.342632        94.459191            0.621505\n",
      "     12                0.59998464         0.046467  0.179176         1.650450       0.043011  0.069913                  0.396187          0.391744      0.017911                 0.990245  -82.082407        65.045004            0.513532\n",
      "     13                0.69998848         0.025484  0.071963         1.424939       0.017274  0.033990                  0.342053          0.340634      0.007197                 0.997441  -92.803731        42.493948            0.391410\n",
      "     14                0.80003071         0.016533  0.019183         1.249152       0.004605  0.020574                  0.299856          0.300611      0.001919                 0.999360  -98.081731        24.915243            0.262292\n",
      "     15                0.90003455         0.008857  0.004798         1.110891       0.001152  0.012409                  0.266667          0.268589      0.000480                 0.999840  -99.520249        11.089077            0.131331\n",
      "     16                1.00000000         0.006056  0.001600         1.000000       0.000384  0.007306                  0.240048          0.242469      0.000160                 1.000000  -99.840021         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09261066\n",
      " RMSE: 0.30431998\n",
      " AUC: 0.92220396\n",
      " pr_auc: 0.8171677\n",
      " logloss: 0.2943965\n",
      " mean_per_class_error: 0.16438326\n",
      " default threshold: 0.33204254508018494\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4316   608  0.1235  608 / 4,924\n",
      "     1   326  1262  0.2053  326 / 1,588\n",
      "Totals  4642  1870  0.1434  934 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.32 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01320639         0.986420  4.100756         4.100756       1.000000  0.987937                  1.000000          0.987937      0.054156                 0.054156  310.075567       310.075567            0.054156\n",
      "      2                0.02011671         0.984097  4.100756         4.100756       1.000000  0.985241                  1.000000          0.987011      0.028338                 0.082494  310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.976585  4.100756         4.100756       1.000000  0.981482                  1.000000          0.985177      0.040932                 0.123426  310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.957944  4.037667         4.085044       0.984615  0.967081                  0.996169          0.980671      0.040302                 0.163728  303.766712       308.504396            0.163525\n",
      "      5                0.05006143         0.941036  3.974579         4.063019       0.969231  0.951711                  0.990798          0.974897      0.039673                 0.203401  297.457857       306.301865            0.202791\n",
      "      6                0.10012285         0.726525  3.383752         3.723386       0.825153  0.819301                  0.907975          0.897099      0.169395                 0.372796  238.375238       272.338551            0.360611\n",
      "      7                0.15003071         0.592538  2.952544         3.466964       0.720000  0.663391                  0.845445          0.819356      0.147355                 0.520151  195.254408       246.696436            0.489485\n",
      "      8                0.20009214         0.466487  2.364853         3.191225       0.576687  0.527396                  0.778204          0.746310      0.118388                 0.638539  136.485296       219.122506            0.579847\n",
      "      9                0.30006143         0.313843  1.725971         2.703057       0.420891  0.383106                  0.659161          0.625304      0.172544                 0.811083   72.597090       170.305696            0.675827\n",
      "     10                0.40003071         0.197724  0.951174         2.265254       0.231951  0.253396                  0.552399          0.532362      0.095088                 0.906171   -4.882626       126.525428            0.669372\n",
      "     11                0.50000000         0.105835  0.453540         1.903023       0.110599  0.148606                  0.464066          0.455635      0.045340                 0.951511  -54.646020        90.302267            0.597125\n",
      "     12                0.59996929         0.051088  0.296061         1.635264       0.072197  0.075790                  0.398771          0.392344      0.029597                 0.981108  -70.393930        63.526423            0.504057\n",
      "     13                0.69993857         0.027092  0.125983         1.419700       0.030722  0.037332                  0.346204          0.341639      0.012594                 0.993703  -87.401672        41.969997            0.388504\n",
      "     14                0.79990786         0.016463  0.050393         1.248569       0.012289  0.021122                  0.304473          0.301582      0.005038                 0.998741  -94.960669        24.856949            0.262957\n",
      "     15                0.90156634         0.008715  0.006194         1.108482       0.001511  0.012301                  0.270312          0.268963      0.000630                 0.999370  -99.380551        10.848224            0.129346\n",
      "     16                1.00000000         0.006056  0.006397         1.000000       0.001560  0.007273                  0.243857          0.243204      0.000630                 1.000000  -99.360257         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6026.149902          1.000000   0.354306\n",
      "                      capital_gain         3551.594971          0.589364   0.208815\n",
      "                               age         1370.286987          0.227390   0.080566\n",
      "                      capital_loss         1124.132080          0.186542   0.066093\n",
      "                    hours_per_week          732.593811          0.121569   0.043073\n",
      "        occupation. Prof-specialty          592.683411          0.098352   0.034847\n",
      "       occupation. Exec-managerial          578.538330          0.096005   0.034015\n",
      "                            fnlwgt          425.544189          0.070616   0.025020\n",
      "              education. Bachelors          387.991577          0.064385   0.022812\n",
      "                education. HS-grad          185.881958          0.030846   0.010929\n",
      "---\n",
      "      relationship. Other-relative           12.281457          0.002038   0.000722\n",
      "              education. Assoc-voc            8.953053          0.001486   0.000526\n",
      "      occupation. Transport-moving            8.799237          0.001460   0.000517\n",
      "              workclass. State-gov            6.465282          0.001073   0.000380\n",
      "                     occupation.NA            5.734882          0.000952   0.000337\n",
      "           marital_status. Widowed            4.914797          0.000816   0.000289\n",
      "              workclass. Local-gov            4.880513          0.000810   0.000287\n",
      "          race. Asian-Pac-Islander            2.318298          0.000385   0.000136\n",
      "                       race. Black            0.976868          0.000162   0.000057\n",
      "                      workclass.NA            0.657392          0.000109   0.000039\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        48495.804688          1.000000   0.159939\n",
      "                               age        42597.453125          0.878374   0.140486\n",
      "marital_status. Married-civ-spouse        27839.000000          0.574050   0.091813\n",
      "                      capital_loss        24350.968750          0.502125   0.080309\n",
      "                    hours_per_week        22735.232422          0.468808   0.074981\n",
      "                            fnlwgt        13559.138672          0.279594   0.044718\n",
      "        occupation. Prof-specialty        10844.014648          0.223607   0.035763\n",
      "       occupation. Exec-managerial        10269.432617          0.211759   0.033869\n",
      "              education. Bachelors         8248.058594          0.170078   0.027202\n",
      "                education. Masters         6813.949219          0.140506   0.022472\n",
      "---\n",
      "              education. Assoc-voc          380.606812          0.007848   0.001255\n",
      "             relationship. Husband          350.072754          0.007219   0.001155\n",
      "                     occupation.NA          314.734222          0.006490   0.001038\n",
      "              workclass. State-gov          184.299164          0.003800   0.000608\n",
      "                       race. Black          167.645508          0.003457   0.000553\n",
      "              workclass. Local-gov          163.791275          0.003377   0.000540\n",
      "           marital_status. Widowed          160.897476          0.003318   0.000531\n",
      "          race. Asian-Pac-Islander          157.332199          0.003244   0.000519\n",
      "      occupation. Transport-moving           85.276917          0.001758   0.000281\n",
      "                      workclass.NA           23.772663          0.000490   0.000078\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          214.000000          1.000000   0.215726\n",
      "                       fnlwgt          162.000000          0.757009   0.163306\n",
      "               hours_per_week           92.000000          0.429907   0.092742\n",
      "                 capital_gain           60.000000          0.280374   0.060484\n",
      "                 capital_loss           43.000000          0.200935   0.043347\n",
      "         education. Bachelors           29.000000          0.135514   0.029234\n",
      "  occupation. Exec-managerial           27.000000          0.126168   0.027218\n",
      "           education. HS-grad           26.000000          0.121495   0.026210\n",
      "   occupation. Prof-specialty           25.000000          0.116822   0.025202\n",
      "           workclass. Private           25.000000          0.116822   0.025202\n",
      "---\n",
      "occupation. Machine-op-inspct            2.000000          0.009346   0.002016\n",
      " occupation. Transport-moving            2.000000          0.009346   0.002016\n",
      "               education. 9th            2.000000          0.009346   0.002016\n",
      "         education. Assoc-voc            1.000000          0.004673   0.001008\n",
      " relationship. Other-relative            1.000000          0.004673   0.001008\n",
      "                 workclass.NA            1.000000          0.004673   0.001008\n",
      "     race. Asian-Pac-Islander            1.000000          0.004673   0.001008\n",
      "                  race. Black            1.000000          0.004673   0.001008\n",
      "         workclass. Local-gov            1.000000          0.004673   0.001008\n",
      "           education. 5th-6th            1.000000          0.004673   0.001008\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      "\n",
      "10-20 18:27:51.009 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:51.009) \n",
      "10-20 18:27:51.048 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:51.048) \n",
      "10-20 18:27:51.089 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:51.089) \n",
      "10-20 18:27:51.125 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:51.125) \n",
      "10-20 18:27:51.154 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:51.154) \n",
      "10-20 18:27:51.199 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_393\n",
      "10-20 18:27:51.219 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_393\n",
      "10-20 18:27:51.287 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_394\n",
      "10-20 18:27:51.300 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_394\n",
      "10-20 18:27:51.303 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.08241795\n",
      " RMSE: 0.28708526\n",
      " AUC: 0.93881994\n",
      " pr_auc: 0.85082006\n",
      " logloss: 0.2622271\n",
      " mean_per_class_error: 0.16353647\n",
      " default threshold: 0.39301952719688416\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18165  1631  0.0824  1,631 / 19,796\n",
      "     1   1530  4723  0.2447   1,530 / 6,253\n",
      "Totals  19695  6354  0.1213  3,161 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.10 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013475         0.991758  4.165840         4.165840       1.000000  0.993130                  1.000000          0.993130      0.042220                 0.042220  316.584040       316.584040            0.042220\n",
      "      2                0.02000077         0.989608  4.165840         4.165840       1.000000  0.990667                  1.000000          0.991915      0.041100                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.984342  4.165840         4.165840       1.000000  0.987649                  1.000000          0.990491      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.968873  4.165840         4.165840       1.000000  0.977186                  1.000000          0.987171      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.948378  4.101996         4.153052       0.984674  0.958851                  0.996930          0.981498      0.041100                 0.207740  310.199610       315.305194            0.207538\n",
      "      6                0.10000384         0.758699  3.788291         3.970742       0.909370  0.851581                  0.953167          0.916565      0.189349                 0.397089  278.829111       297.074154            0.390927\n",
      "      7                0.15006334         0.611054  3.060487         3.667091       0.734663  0.685209                  0.880276          0.839387      0.153206                 0.550296  206.048704       266.709051            0.526655\n",
      "      8                0.20000768         0.482448  2.452755         3.363856       0.588778  0.544824                  0.807486          0.765831      0.122501                 0.672797  145.275461       236.385615            0.622130\n",
      "      9                0.30001152         0.310903  1.610365         2.779359       0.386564  0.386551                  0.667179          0.639404      0.161043                 0.833840   61.036517       177.935916            0.702450\n",
      "     10                0.40001536         0.183242  0.986688         2.331191       0.236852  0.245103                  0.559597          0.540829      0.098673                 0.932512   -1.331151       133.119149            0.700698\n",
      "     11                0.50001919         0.089544  0.430177         1.950989       0.103263  0.132236                  0.468330          0.459110      0.043019                 0.975532  -56.982301        95.098859            0.625714\n",
      "     12                0.59998464         0.038694  0.159979         1.652582       0.038402  0.061150                  0.396698          0.392805      0.015992                 0.991524  -84.002149        65.258241            0.515216\n",
      "     13                0.69998848         0.019721  0.059169         1.424939       0.014203  0.027350                  0.342053          0.340594      0.005917                 0.997441  -94.083067        42.493948            0.391410\n",
      "     14                0.79999232         0.011044  0.020789         1.249412       0.004990  0.015167                  0.299918          0.299914      0.002079                 0.999520  -97.921078        24.941228            0.262553\n",
      "     15                0.90064878         0.004135  0.003178         1.110133       0.000763  0.007496                  0.266485          0.267233      0.000320                 0.999840  -99.682239        11.013316            0.130523\n",
      "     16                1.00000000         0.001665  0.001610         1.000000       0.000386  0.002922                  0.240048          0.240974      0.000160                 1.000000  -99.839032         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.0918564\n",
      " RMSE: 0.3030782\n",
      " AUC: 0.92303646\n",
      " pr_auc: 0.81856567\n",
      " logloss: 0.291331\n",
      " mean_per_class_error: 0.16051285\n",
      " default threshold: 0.31616339087486267\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4289   635  0.1290  635 / 4,924\n",
      "     1   305  1283  0.1921  305 / 1,588\n",
      "Totals  4594  1918  0.1443  940 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01044226         0.991847  4.100756         4.100756       1.000000  0.993209                  1.000000          0.993209      0.042821                 0.042821  310.075567       310.075567            0.042821\n",
      "      2                0.02011671         0.989365  4.100756         4.100756       1.000000  0.990699                  1.000000          0.992002      0.039673                 0.082494  310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.985281  4.100756         4.100756       1.000000  0.987687                  1.000000          0.990571      0.040932                 0.123426  310.075567       310.075567            0.123426\n",
      "      4                0.04007985         0.966932  4.037667         4.085044       0.984615  0.976602                  0.996169          0.987092      0.040302                 0.163728  303.766712       308.504396            0.163525\n",
      "      5                0.05006143         0.946758  3.974579         4.063019       0.969231  0.958309                  0.990798          0.981353      0.039673                 0.203401  297.457857       306.301865            0.202791\n",
      "      6                0.10012285         0.745301  3.421489         3.742254       0.834356  0.835663                  0.912577          0.908508      0.171285                 0.374685  242.148939       274.225402            0.363109\n",
      "      7                0.15003071         0.614242  2.864220         3.450175       0.698462  0.680467                  0.841351          0.832650      0.142947                 0.517632  186.422011       245.017519            0.486154\n",
      "      8                0.20039926         0.483583  2.525465         3.217758       0.615854  0.546269                  0.784674          0.760671      0.127204                 0.644836  152.546538       221.775770            0.587769\n",
      "      9                0.30006143         0.307338  1.699697         2.713550       0.414484  0.388399                  0.661720          0.637025      0.169395                 0.814232   69.969688       171.355019            0.679991\n",
      "     10                0.40003071         0.185777  0.875584         2.254235       0.213518  0.245919                  0.549712          0.539286      0.087531                 0.901763  -12.441622       125.423498            0.663542\n",
      "     11                0.50000000         0.096460  0.522831         1.908060       0.127496  0.136318                  0.465295          0.458717      0.052267                 0.954030  -47.716940        90.806045            0.600456\n",
      "     12                0.59996929         0.043658  0.283462         1.637363       0.069124  0.066623                  0.399283          0.393385      0.028338                 0.982368  -71.653763        63.736341            0.505723\n",
      "     13                0.69993857         0.020453  0.100787         1.417901       0.024578  0.030114                  0.345766          0.341501      0.010076                 0.992443  -89.921338        41.790060            0.386838\n",
      "     14                0.79990786         0.011087  0.056692         1.247782       0.013825  0.015494                  0.304281          0.300758      0.005668                 0.998111  -94.330753        24.778225            0.262124\n",
      "     15                0.90049140         0.004135  0.012521         1.109805       0.003053  0.007485                  0.270634          0.267999      0.001259                 0.999370  -98.747861        10.980546            0.130768\n",
      "     16                1.00000000         0.001668  0.006328         1.000000       0.001543  0.002943                  0.243857          0.241624      0.000630                 1.000000  -99.367167         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6040.872559          1.000000   0.339071\n",
      "                      capital_gain         3618.470215          0.598998   0.203103\n",
      "                               age         1508.433838          0.249705   0.084668\n",
      "                      capital_loss         1146.437500          0.189780   0.064349\n",
      "                    hours_per_week          811.692444          0.134367   0.045560\n",
      "                            fnlwgt          603.427307          0.099891   0.033870\n",
      "        occupation. Prof-specialty          601.227173          0.099527   0.033747\n",
      "       occupation. Exec-managerial          587.433655          0.097243   0.032972\n",
      "              education. Bachelors          402.181244          0.066577   0.022574\n",
      "                education. HS-grad          198.862411          0.032919   0.011162\n",
      "---\n",
      "                     occupation.NA            8.469040          0.001402   0.000475\n",
      "          race. Asian-Pac-Islander            7.679762          0.001271   0.000431\n",
      "       native_country. Philippines            7.437479          0.001231   0.000417\n",
      "              workclass. State-gov            6.465282          0.001070   0.000363\n",
      "                education. 1st-4th            5.899384          0.000977   0.000331\n",
      "           marital_status. Widowed            4.914797          0.000814   0.000276\n",
      "         marital_status. Separated            3.978377          0.000659   0.000223\n",
      "          race. Amer-Indian-Eskimo            3.275873          0.000542   0.000184\n",
      "           relationship. Unmarried            2.602089          0.000431   0.000146\n",
      "                      workclass.NA            0.657392          0.000109   0.000037\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        59710.375000          1.000000   0.159394\n",
      "                               age        49957.207031          0.836659   0.133358\n",
      "marital_status. Married-civ-spouse        28838.031250          0.482965   0.076982\n",
      "                    hours_per_week        28465.019531          0.476718   0.075986\n",
      "                      capital_loss        28326.001953          0.474390   0.075615\n",
      "                            fnlwgt        22898.830078          0.383498   0.061127\n",
      "        occupation. Prof-specialty        11059.778320          0.185224   0.029524\n",
      "       occupation. Exec-managerial        10633.988281          0.178093   0.028387\n",
      "              education. Bachelors         8911.500977          0.149245   0.023789\n",
      "              education. Doctorate         7694.042480          0.128856   0.020539\n",
      "---\n",
      "              education. Assoc-voc          380.606812          0.006374   0.001016\n",
      "             relationship. Husband          375.241913          0.006284   0.001002\n",
      "           relationship. Unmarried          307.608002          0.005152   0.000821\n",
      "          race. Asian-Pac-Islander          228.461472          0.003826   0.000610\n",
      "              workclass. Local-gov          191.075211          0.003200   0.000510\n",
      "              workclass. State-gov          184.299164          0.003087   0.000492\n",
      "           marital_status. Widowed          160.897476          0.002695   0.000430\n",
      "       native_country. Philippines          158.535355          0.002655   0.000423\n",
      "      occupation. Transport-moving          155.325363          0.002601   0.000415\n",
      "                      workclass.NA           23.772663          0.000398   0.000063\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                         age          269.000000          1.000000   0.219951\n",
      "                      fnlwgt          220.000000          0.817844   0.179886\n",
      "              hours_per_week          111.000000          0.412639   0.090760\n",
      "                capital_gain           70.000000          0.260223   0.057236\n",
      "                capital_loss           47.000000          0.174721   0.038430\n",
      "          workclass. Private           35.000000          0.130112   0.028618\n",
      "        education. Bachelors           33.000000          0.122677   0.026983\n",
      "          education. HS-grad           31.000000          0.115242   0.025348\n",
      " occupation. Exec-managerial           29.000000          0.107807   0.023712\n",
      "  occupation. Prof-specialty           28.000000          0.104089   0.022895\n",
      "---\n",
      "        workclass. Local-gov            2.000000          0.007435   0.001635\n",
      "        workclass. State-gov            2.000000          0.007435   0.001635\n",
      "     relationship. Unmarried            1.000000          0.003717   0.000818\n",
      "        education. Assoc-voc            1.000000          0.003717   0.000818\n",
      "relationship. Other-relative            1.000000          0.003717   0.000818\n",
      "   marital_status. Separated            1.000000          0.003717   0.000818\n",
      "                workclass.NA            1.000000          0.003717   0.000818\n",
      "          education. 1st-4th            1.000000          0.003717   0.000818\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.003717   0.000818\n",
      " native_country. Philippines            1.000000          0.003717   0.000818\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      "\n",
      "█10-20 18:27:51.353 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:51.353) \n",
      "10-20 18:27:51.377 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.023 (Wall: 20-Oct 18:27:51.377) \n",
      "10-20 18:27:51.401 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.024 (Wall: 20-Oct 18:27:51.401) \n",
      "10-20 18:27:51.425 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.024 (Wall: 20-Oct 18:27:51.425) \n",
      "10-20 18:27:51.451 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.026 (Wall: 20-Oct 18:27:51.451) \n",
      "10-20 18:27:51.513 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_395\n",
      "10-20 18:27:51.537 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_395\n",
      "10-20 18:27:51.627 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_396\n",
      "10-20 18:27:51.639 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_396\n",
      "10-20 18:27:51.642 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.08044621\n",
      " RMSE: 0.28363043\n",
      " AUC: 0.94169277\n",
      " pr_auc: 0.85675955\n",
      " logloss: 0.25578362\n",
      " mean_per_class_error: 0.15221325\n",
      " default threshold: 0.3600172996520996\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  17882  1914  0.0967  1,914 / 19,796\n",
      "     1   1299  4954  0.2077   1,299 / 6,253\n",
      "Totals  19181  6868  0.1233  3,213 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.993264  4.165840         4.165840       1.000000  0.994782                  1.000000          0.994782      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.991078  4.165840         4.165840       1.000000  0.992244                  1.000000          0.993516      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.986531  4.165840         4.165840       1.000000  0.989177                  1.000000          0.992068      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.974723  4.165840         4.165840       1.000000  0.981227                  1.000000          0.989363      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.955639  4.117957         4.156249       0.988506  0.966049                  0.997698          0.984693      0.041260                 0.207900  311.795717       315.624905            0.207749\n",
      "      6                0.10000384         0.776655  3.829886         3.993130       0.919355  0.865069                  0.958541          0.924904      0.191428                 0.399328  282.988553       299.312993            0.393873\n",
      "      7                0.15006334         0.627430  3.066876         3.684142       0.736196  0.702065                  0.884369          0.850568      0.153526                 0.552855  206.687637       268.414179            0.530022\n",
      "      8                0.20000768         0.487421  2.513593         3.391842       0.603382  0.556427                  0.814203          0.777117      0.125540                 0.678394  151.359317       239.184164            0.629496\n",
      "      9                0.30001152         0.305754  1.611964         2.798549       0.386948  0.387311                  0.671785          0.647182      0.161203                 0.839597   61.196435       179.854921            0.710025\n",
      "     10                0.40001536         0.174376  0.983490         2.344784       0.236084  0.237392                  0.562860          0.544734      0.098353                 0.937950   -1.650985       134.478445            0.707853\n",
      "     11                0.50001919         0.080655  0.404590         1.956746       0.097121  0.122377                  0.469712          0.460263      0.040461                 0.978410  -59.540974        95.674561            0.629501\n",
      "     12                0.59998464         0.034539  0.135982         1.653382       0.032642  0.054784                  0.396890          0.392705      0.013593                 0.992004  -86.401827        65.338204            0.515847\n",
      "     13                0.69998848         0.016920  0.054372         1.424939       0.013052  0.024000                  0.342053          0.340030      0.005437                 0.997441  -94.562819        42.493948            0.391410\n",
      "     14                0.79999232         0.008731  0.022388         1.249612       0.005374  0.012433                  0.299966          0.299078      0.002239                 0.999680  -97.761161        24.961218            0.262764\n",
      "     15                0.89999616         0.003007  0.001599         1.110938       0.000384  0.005695                  0.266678          0.266479      0.000160                 0.999840  -99.840083        11.093816            0.131382\n",
      "     16                1.00000000         0.000768  0.001599         1.000000       0.000384  0.001927                  0.240048          0.240022      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09143313\n",
      " RMSE: 0.30237913\n",
      " AUC: 0.9238999\n",
      " pr_auc: 0.8197256\n",
      " logloss: 0.28931773\n",
      " mean_per_class_error: 0.16370392\n",
      " default threshold: 0.3373657464981079\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4363   561  0.1139  561 / 4,924\n",
      "     1   339  1249  0.2135  339 / 1,588\n",
      "Totals  4702  1810  0.1382  900 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.04 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.993318  4.100756         4.100756       1.000000  0.994819                  1.000000          0.994819      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.990869  4.100756         4.100756       1.000000  0.992200                  1.000000          0.993519      0.040932                 0.082494  310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.987200  4.037667         4.079833       0.984615  0.989366                  0.994898          0.992142      0.040302                 0.122796  303.766712       307.983344            0.122593\n",
      "      4                0.04007985         0.973524  4.100756         4.085044       1.000000  0.981183                  0.996169          0.989413      0.040932                 0.163728  310.075567       308.504396            0.163525\n",
      "      5                0.05006143         0.952091  3.911490         4.050440       0.953846  0.964711                  0.987730          0.984488      0.039043                 0.202771  291.149002       305.043965            0.201958\n",
      "      6                0.10012285         0.761373  3.471805         3.761123       0.846626  0.849870                  0.917178          0.917179      0.173804                 0.376574  247.180541       276.112253            0.365608\n",
      "      7                0.15003071         0.628543  2.939926         3.487951       0.716923  0.692330                  0.850563          0.842383      0.146725                 0.523300  193.992637       248.795083            0.493649\n",
      "      8                0.20009214         0.492439  2.364853         3.206961       0.576687  0.558666                  0.782041          0.771399      0.118388                 0.641688  136.485296       220.696088            0.584011\n",
      "      9                0.30006143         0.305026  1.700774         2.705156       0.414747  0.388190                  0.659672          0.643728      0.170025                 0.811713   70.077424       170.515561            0.676660\n",
      "     10                0.40003071         0.174766  0.932276         2.262106       0.227343  0.239317                  0.551631          0.542664      0.093199                 0.904912   -6.772375       126.210591            0.667706\n",
      "     11                0.50000000         0.086960  0.516531         1.913098       0.125960  0.126880                  0.466523          0.459533      0.051637                 0.956549  -48.346856        91.309824            0.603787\n",
      "     12                0.59996929         0.038181  0.277163         1.640512       0.067588  0.059662                  0.400051          0.392905      0.027708                 0.984257  -72.283679        64.051219            0.508221\n",
      "     13                0.69993857         0.017424  0.081889         1.417901       0.019969  0.026188                  0.345766          0.340528      0.008186                 0.992443  -91.811087        41.790060            0.386838\n",
      "     14                0.79990786         0.008881  0.056692         1.247782       0.013825  0.012957                  0.304281          0.299590      0.005668                 0.998111  -94.330753        24.778225            0.262124\n",
      "     15                0.89987715         0.003012  0.012598         1.110563       0.003072  0.005699                  0.270819          0.266941      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000806  0.006290         1.000000       0.001534  0.001957                  0.243857          0.240410      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6044.105957          1.000000   0.327062\n",
      "                      capital_gain         3651.139648          0.604083   0.197573\n",
      "                               age         1586.208374          0.262439   0.085834\n",
      "                      capital_loss         1193.699463          0.197498   0.064594\n",
      "                    hours_per_week          859.097534          0.142138   0.046488\n",
      "                            fnlwgt          823.423767          0.136236   0.044558\n",
      "        occupation. Prof-specialty          615.528015          0.101839   0.033308\n",
      "       occupation. Exec-managerial          591.322021          0.097834   0.031998\n",
      "              education. Bachelors          422.981598          0.069982   0.022889\n",
      "                education. HS-grad          209.093079          0.034595   0.011315\n",
      "---\n",
      "           relationship. Unmarried           10.157953          0.001681   0.000550\n",
      "          race. Asian-Pac-Islander            9.433745          0.001561   0.000510\n",
      "                   education. 12th            7.331263          0.001213   0.000397\n",
      "              workclass. State-gov            6.465282          0.001070   0.000350\n",
      "                education. 1st-4th            5.899384          0.000976   0.000319\n",
      "           marital_status. Widowed            4.914797          0.000813   0.000266\n",
      "         marital_status. Separated            3.978377          0.000658   0.000215\n",
      "          race. Amer-Indian-Eskimo            3.275873          0.000542   0.000177\n",
      "                 native_country.NA            3.163395          0.000523   0.000171\n",
      "                      workclass.NA            0.657392          0.000109   0.000036\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        64280.800781          1.000000   0.145039\n",
      "                               age        54890.136719          0.853912   0.123850\n",
      "                      capital_loss        38654.761719          0.601342   0.087218\n",
      "                            fnlwgt        36751.382813          0.571732   0.082923\n",
      "                    hours_per_week        30859.519531          0.480074   0.069629\n",
      "marital_status. Married-civ-spouse        30078.089844          0.467917   0.067866\n",
      "        occupation. Prof-specialty        11244.128906          0.174922   0.025370\n",
      "       occupation. Exec-managerial        10815.007813          0.168246   0.024402\n",
      "              education. Bachelors        10221.538086          0.159014   0.023063\n",
      "              education. Doctorate         9585.492188          0.149119   0.021628\n",
      "---\n",
      "                       race. Black          692.995056          0.010781   0.001564\n",
      "          marital_status. Divorced          570.022949          0.008868   0.001286\n",
      "       relationship. Not-in-family          531.099060          0.008262   0.001198\n",
      "          race. Asian-Pac-Islander          472.863831          0.007356   0.001067\n",
      "             relationship. Husband          405.529327          0.006309   0.000915\n",
      "              workclass. Local-gov          299.056793          0.004652   0.000675\n",
      "                 native_country.NA          289.332642          0.004501   0.000653\n",
      "              workclass. State-gov          184.299164          0.002867   0.000416\n",
      "           marital_status. Widowed          160.897476          0.002503   0.000363\n",
      "                      workclass.NA           23.772663          0.000370   0.000054\n",
      "Variable Importances - Frequency:\n",
      "                   Variable Relative Importance Scaled Importance Percentage\n",
      "                     fnlwgt          306.000000          1.000000   0.210165\n",
      "                        age          302.000000          0.986928   0.207418\n",
      "             hours_per_week          132.000000          0.431373   0.090659\n",
      "               capital_gain           78.000000          0.254902   0.053571\n",
      "               capital_loss           56.000000          0.183007   0.038462\n",
      "       education. Bachelors           40.000000          0.130719   0.027473\n",
      "         workclass. Private           40.000000          0.130719   0.027473\n",
      "         education. HS-grad           36.000000          0.117647   0.024725\n",
      " occupation. Prof-specialty           34.000000          0.111111   0.023352\n",
      "occupation. Exec-managerial           31.000000          0.101307   0.021291\n",
      "---\n",
      "    marital_status. Widowed            2.000000          0.006536   0.001374\n",
      "       education. Assoc-voc            2.000000          0.006536   0.001374\n",
      "       workclass. State-gov            2.000000          0.006536   0.001374\n",
      "native_country. Philippines            2.000000          0.006536   0.001374\n",
      "            education. 12th            1.000000          0.003268   0.000687\n",
      "  marital_status. Separated            1.000000          0.003268   0.000687\n",
      "               workclass.NA            1.000000          0.003268   0.000687\n",
      "         education. 1st-4th            1.000000          0.003268   0.000687\n",
      "   race. Amer-Indian-Eskimo            1.000000          0.003268   0.000687\n",
      "          native_country.NA            1.000000          0.003268   0.000687\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      " 2023-10-20 18:27:51 10.605 sec              25       0.28363          0.25578      0.94169         0.85676       4.16584                       0.12334         0.30238            0.28932        0.92390           0.81973         4.10076                         0.13821\n",
      "\n",
      "10-20 18:27:51.676 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:51.676) \n",
      "10-20 18:27:51.702 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.026 (Wall: 20-Oct 18:27:51.702) \n",
      "10-20 18:27:51.727 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:51.739 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:51.739) \n",
      "10-20 18:27:51.773 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:51.772) \n",
      "10-20 18:27:51.806 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:51.806) \n",
      "10-20 18:27:51.843 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_397\n",
      "10-20 18:27:51.863 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_397\n",
      "10-20 18:27:51.966 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_398\n",
      "10-20 18:27:51.980 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_398\n",
      "10-20 18:27:51.984 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07862472\n",
      " RMSE: 0.280401\n",
      " AUC: 0.9444593\n",
      " pr_auc: 0.86251634\n",
      " logloss: 0.2500945\n",
      " mean_per_class_error: 0.15508111\n",
      " default threshold: 0.3975403308868408\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18237  1559  0.0788  1,559 / 19,796\n",
      "     1   1447  4806  0.2314   1,447 / 6,253\n",
      "Totals  19684  6365  0.1154  3,006 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.03 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.995724  4.165840         4.165840       1.000000  0.996697                  1.000000          0.996697      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.993974  4.165840         4.165840       1.000000  0.994889                  1.000000          0.995795      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.990451  4.165840         4.165840       1.000000  0.992553                  1.000000          0.994713      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.980521  4.149818         4.161842       0.996154  0.985735                  0.999040          0.992473      0.041420                 0.166480  314.981793       316.184247            0.166430\n",
      "      5                0.05002111         0.966590  4.133918         4.156249       0.992337  0.973981                  0.997698          0.988769      0.041420                 0.207900  313.391825       315.624905            0.207749\n",
      "      6                0.10000384         0.787120  3.855482         4.005923       0.925499  0.876064                  0.961612          0.932438      0.192708                 0.400608  285.548209       300.592330            0.395556\n",
      "      7                0.15002495         0.636980  3.098004         3.703206       0.743668  0.712664                  0.888946          0.859161      0.154966                 0.555573  209.800410       270.320613            0.533650\n",
      "      8                0.20000768         0.496395  2.585253         3.423825       0.620584  0.563947                  0.821881          0.785386      0.129218                 0.684791  158.525272       242.382506            0.637913\n",
      "      9                0.30001152         0.306310  1.613564         2.820405       0.387332  0.390471                  0.677031          0.653748      0.161363                 0.846154   61.356352       182.040455            0.718653\n",
      "     10                0.40001536         0.167328  0.941912         2.350781       0.226104  0.233429                  0.564299          0.548668      0.094195                 0.940349   -5.808829       135.078134            0.711009\n",
      "     11                0.50001919         0.076656  0.391797         1.958984       0.094050  0.117276                  0.470250          0.462389      0.039181                 0.979530  -60.820311        95.898445            0.630975\n",
      "     12                0.59998464         0.032261  0.137582         1.655514       0.033026  0.051335                  0.397402          0.393902      0.013753                 0.993283  -86.241848        65.551441            0.517531\n",
      "     13                0.69998848         0.015468  0.046376         1.425625       0.011132  0.022293                  0.342218          0.340812      0.004638                 0.997921  -95.362404        42.562488            0.392041\n",
      "     14                0.79999232         0.007633  0.017591         1.249612       0.004223  0.011146                  0.299966          0.299602      0.001759                 0.999680  -98.240912        24.961218            0.262764\n",
      "     15                0.89999616         0.002711  0.001599         1.110938       0.000384  0.004944                  0.266678          0.266861      0.000160                 0.999840  -99.840083        11.093816            0.131382\n",
      "     16                1.00000000         0.000475  0.001599         1.000000       0.000384  0.001726                  0.240048          0.240346      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09134748\n",
      " RMSE: 0.30223745\n",
      " AUC: 0.9239894\n",
      " pr_auc: 0.8210345\n",
      " logloss: 0.2886834\n",
      " mean_per_class_error: 0.16215877\n",
      " default threshold: 0.32452136278152466\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4310   614  0.1247  614 / 4,924\n",
      "     1   317  1271  0.1996  317 / 1,588\n",
      "Totals  4627  1885  0.1430  931 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.08 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.995718  4.100756         4.100756       1.000000  0.996713                  1.000000          0.996713      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.994112  4.100756         4.100756       1.000000  0.994915                  1.000000          0.995821      0.040932                 0.082494  310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.990109  4.037667         4.079833       0.984615  0.992442                  0.994898          0.994700      0.040302                 0.122796  303.766712       307.983344            0.122593\n",
      "      4                0.04007985         0.979800  4.100756         4.085044       1.000000  0.985373                  0.996169          0.992377      0.040932                 0.163728  310.075567       308.504396            0.163525\n",
      "      5                0.05006143         0.966344  3.911490         4.050440       0.953846  0.973239                  0.987730          0.988561      0.039043                 0.202771  291.149002       305.043965            0.201958\n",
      "      6                0.10012285         0.766816  3.559858         3.805149       0.868098  0.861495                  0.927914          0.925028      0.178212                 0.380982  255.985845       280.514905            0.371437\n",
      "      7                0.15003071         0.637152  2.813749         3.475359       0.686154  0.699957                  0.847492          0.850158      0.140428                 0.521411  181.374927       247.535895            0.491151\n",
      "      8                0.20009214         0.497005  2.415169         3.210108       0.588957  0.562679                  0.782809          0.778233      0.120907                 0.642317  141.516898       221.010804            0.584844\n",
      "      9                0.30006143         0.311021  1.675578         2.698860       0.408602  0.394206                  0.658137          0.650289      0.167506                 0.809824   67.557758       169.885967            0.674162\n",
      "     10                0.40003071         0.170581  0.976370         2.268403       0.238095  0.236112                  0.553167          0.546785      0.097607                 0.907431   -2.362960       126.840266            0.671038\n",
      "     11                0.50000000         0.081235  0.522831         1.919395       0.127496  0.121945                  0.468059          0.461843      0.052267                 0.959698  -47.716940        91.939547            0.607951\n",
      "     12                0.59996929         0.035767  0.245667         1.640512       0.059908  0.056230                  0.400051          0.394258      0.024559                 0.984257  -75.433261        64.051219            0.508221\n",
      "     13                0.69993857         0.016240  0.088188         1.418800       0.021505  0.024299                  0.345985          0.341419      0.008816                 0.993073  -91.181171        41.880028            0.387671\n",
      "     14                0.79990786         0.007800  0.050393         1.247782       0.012289  0.011620                  0.304281          0.300202      0.005038                 0.998111  -94.960669        24.778225            0.262124\n",
      "     15                0.89987715         0.002684  0.012598         1.110563       0.003072  0.004912                  0.270819          0.267397      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000586  0.006290         1.000000       0.001534  0.001765                  0.243857          0.240801      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6047.879395          1.000000   0.316235\n",
      "                      capital_gain         3693.835205          0.610765   0.193145\n",
      "                               age         1674.147461          0.276816   0.087539\n",
      "                      capital_loss         1231.186401          0.203573   0.064377\n",
      "                            fnlwgt         1067.098999          0.176442   0.055797\n",
      "                    hours_per_week          909.854614          0.150442   0.047575\n",
      "        occupation. Prof-specialty          619.645691          0.102457   0.032400\n",
      "       occupation. Exec-managerial          595.776428          0.098510   0.031152\n",
      "              education. Bachelors          424.543335          0.070197   0.022199\n",
      "                education. HS-grad          220.310074          0.036428   0.011520\n",
      "---\n",
      "                     occupation.NA           12.583540          0.002081   0.000658\n",
      "           marital_status. Widowed           12.067593          0.001995   0.000631\n",
      "           relationship. Unmarried           11.893723          0.001967   0.000622\n",
      "          race. Asian-Pac-Islander            9.433745          0.001560   0.000493\n",
      "                 native_country.NA            8.507712          0.001407   0.000445\n",
      "                   education. 12th            7.331263          0.001212   0.000383\n",
      "                education. 1st-4th            5.899384          0.000975   0.000308\n",
      "         marital_status. Separated            5.695473          0.000942   0.000298\n",
      "          race. Amer-Indian-Eskimo            3.275873          0.000542   0.000171\n",
      "                      workclass.NA            0.657392          0.000109   0.000034\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                      capital_gain        73290.273438          1.000000   0.143659\n",
      "                               age        60499.128906          0.825473   0.118586\n",
      "                            fnlwgt        54027.468750          0.737171   0.105901\n",
      "                      capital_loss        48530.062500          0.662162   0.095125\n",
      "                    hours_per_week        36539.468750          0.498558   0.071622\n",
      "marital_status. Married-civ-spouse        30137.533203          0.411208   0.059074\n",
      "        occupation. Prof-specialty        11553.185547          0.157636   0.022646\n",
      "       occupation. Exec-managerial        10923.727539          0.149047   0.021412\n",
      "              education. Bachelors        10317.774414          0.140780   0.020224\n",
      "                education. Masters        10236.707031          0.139673   0.020065\n",
      "---\n",
      "                education. 1st-4th         1446.890259          0.019742   0.002836\n",
      "                     occupation.NA         1219.994995          0.016646   0.002391\n",
      "          race. Amer-Indian-Eskimo          928.019043          0.012662   0.001819\n",
      "                       race. Black          755.577454          0.010309   0.001481\n",
      "              workclass. Local-gov          734.479004          0.010022   0.001440\n",
      "       relationship. Not-in-family          655.851868          0.008949   0.001286\n",
      "          marital_status. Divorced          570.022949          0.007778   0.001117\n",
      "          race. Asian-Pac-Islander          472.863831          0.006452   0.000927\n",
      "              workclass. State-gov          302.190186          0.004123   0.000592\n",
      "                      workclass.NA           23.772663          0.000324   0.000047\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          397.000000          1.000000   0.235190\n",
      "                         age          335.000000          0.843829   0.198460\n",
      "              hours_per_week          153.000000          0.385390   0.090640\n",
      "                capital_gain           89.000000          0.224181   0.052725\n",
      "                capital_loss           65.000000          0.163728   0.038507\n",
      "          workclass. Private           50.000000          0.125945   0.029621\n",
      "        education. Bachelors           41.000000          0.103275   0.024289\n",
      "          education. HS-grad           40.000000          0.100756   0.023697\n",
      "  occupation. Prof-specialty           36.000000          0.090680   0.021327\n",
      " occupation. Exec-managerial           32.000000          0.080605   0.018957\n",
      "---\n",
      "     marital_status. Widowed            3.000000          0.007557   0.001777\n",
      "relationship. Other-relative            3.000000          0.007557   0.001777\n",
      " native_country. Philippines            3.000000          0.007557   0.001777\n",
      "        education. Assoc-voc            2.000000          0.005038   0.001185\n",
      "   marital_status. Separated            2.000000          0.005038   0.001185\n",
      "           native_country.NA            2.000000          0.005038   0.001185\n",
      "             education. 12th            1.000000          0.002519   0.000592\n",
      "                workclass.NA            1.000000          0.002519   0.000592\n",
      "          education. 1st-4th            1.000000          0.002519   0.000592\n",
      "    race. Amer-Indian-Eskimo            1.000000          0.002519   0.000592\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      " 2023-10-20 18:27:51 10.605 sec              25       0.28363          0.25578      0.94169         0.85676       4.16584                       0.12334         0.30238            0.28932        0.92390           0.81973         4.10076                         0.13821\n",
      " 2023-10-20 18:27:51 10.959 sec              30       0.28040          0.25009      0.94446         0.86252       4.16584                       0.11540         0.30224            0.28868        0.92399           0.82103         4.10076                         0.14297\n",
      "\n",
      "10-20 18:27:51.988 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3174829494227812, 0.29690674192082595, 0.29168173437120953, 0.28977738047184537]\n",
      "10-20 18:27:51.988 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3174829494227812 --> 0.28977738047184537 (still improving).\n",
      "10-20 18:27:52.022 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:52.022) \n",
      "10-20 18:27:52.046 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.024 (Wall: 20-Oct 18:27:52.046) \n",
      "10-20 18:27:52.073 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.027 (Wall: 20-Oct 18:27:52.073) \n",
      "10-20 18:27:52.101 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:52.101) \n",
      "10-20 18:27:52.121 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.020 (Wall: 20-Oct 18:27:52.121) \n",
      "10-20 18:27:52.165 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_399\n",
      "10-20 18:27:52.179 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_399\n",
      "10-20 18:27:52.245 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:52.296 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_400\n",
      "10-20 18:27:52.307 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_400\n",
      "10-20 18:27:52.310 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07682697\n",
      " RMSE: 0.27717677\n",
      " AUC: 0.94687283\n",
      " pr_auc: 0.8683937\n",
      " logloss: 0.2452491\n",
      " mean_per_class_error: 0.1482845\n",
      " default threshold: 0.39505448937416077\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18218  1578  0.0797  1,578 / 19,796\n",
      "     1   1356  4897  0.2169   1,356 / 6,253\n",
      "Totals  19574  6475  0.1126  2,934 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.07 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01005797         0.996394  4.165840         4.165840       1.000000  0.997299                  1.000000          0.997299      0.041900                 0.041900   316.584040       316.584040            0.041900\n",
      "      2                0.02000077         0.994761  4.165840         4.165840       1.000000  0.995624                  1.000000          0.996466      0.041420                 0.083320   316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.991156  4.165840         4.165840       1.000000  0.993426                  1.000000          0.995451      0.041740                 0.125060   316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.981643  4.149818         4.161842       0.996154  0.986875                  0.999040          0.993311      0.041420                 0.166480   314.981793       316.184247            0.166430\n",
      "      5                0.05002111         0.967995  4.133918         4.156249       0.992337  0.975394                  0.997698          0.989722      0.041420                 0.207900   313.391825       315.624905            0.207749\n",
      "      6                0.10000384         0.793448  3.881079         4.018717       0.931644  0.880623                  0.964683          0.935194      0.193987                 0.401887   288.107865       301.871667            0.397240\n",
      "      7                0.15002495         0.644069  3.190720         3.742647       0.765925  0.720702                  0.898414          0.863678      0.159603                 0.561490   219.072043       274.264730            0.541436\n",
      "      8                0.20004607         0.503756  2.573677         3.450349       0.617805  0.571668                  0.828248          0.790662      0.128738                 0.690229   157.367730       245.034871            0.645018\n",
      "      9                0.30001152         0.304664  1.639780         2.847057       0.393625  0.394836                  0.683429          0.658770      0.163921                 0.854150    63.977973       184.705740            0.729175\n",
      "     10                0.40001536         0.163920  0.890738         2.357978       0.213820  0.230914                  0.566027          0.551806      0.089077                 0.943227   -10.926177       135.797761            0.714797\n",
      "     11                0.50001919         0.073444  0.375805         1.961543       0.090211  0.113495                  0.470864          0.464144      0.037582                 0.980809   -62.419482        96.154312            0.632658\n",
      "     12                0.59998464         0.030696  0.123183         1.655248       0.029570  0.049039                  0.397338          0.394982      0.012314                 0.993123   -87.681655        65.524786            0.517320\n",
      "     13                0.69998848         0.014458  0.047975         1.425625       0.011516  0.021265                  0.342218          0.341591      0.004798                 0.997921   -95.202487        42.562488            0.392041\n",
      "     14                0.79999232         0.006793  0.015992         1.249412       0.003839  0.010229                  0.299918          0.300169      0.001599                 0.999520   -98.400829        24.941228            0.262553\n",
      "     15                0.89999616         0.002162  0.004798         1.111116       0.001152  0.004260                  0.266721          0.267289      0.000480                 1.000000   -99.520249        11.111585            0.131592\n",
      "     16                1.00000000         0.000273  0.000000         1.000000       0.000000  0.001298                  0.240048          0.240689      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09154613\n",
      " RMSE: 0.30256593\n",
      " AUC: 0.9233741\n",
      " pr_auc: 0.8198333\n",
      " logloss: 0.28968748\n",
      " mean_per_class_error: 0.16950366\n",
      " default threshold: 0.35165610909461975\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4371   553  0.1123  553 / 4,924\n",
      "     1   360  1228  0.2267  360 / 1,588\n",
      "Totals  4731  1781  0.1402  913 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.12 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.996334  4.100756         4.100756       1.000000  0.997299                  1.000000          0.997299      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.994736  4.100756         4.100756       1.000000  0.995643                  1.000000          0.996477      0.040932                 0.082494  310.075567       310.075567            0.082494\n",
      "      3                0.03009828         0.991197  4.037667         4.079833       0.984615  0.993104                  0.994898          0.995359      0.040302                 0.122796  303.766712       307.983344            0.122593\n",
      "      4                0.04007985         0.980708  4.037667         4.069332       0.984615  0.986609                  0.992337          0.993180      0.040302                 0.163098  303.766712       306.933225            0.162692\n",
      "      5                0.05006143         0.967784  3.974579         4.050440       0.969231  0.974624                  0.987730          0.989480      0.039673                 0.202771  297.457857       305.043965            0.201958\n",
      "      6                0.10012285         0.777630  3.534700         3.792570       0.861963  0.867835                  0.924847          0.928658      0.176952                 0.379723  253.470044       279.257004            0.369772\n",
      "      7                0.15003071         0.637985  2.813749         3.466964       0.686154  0.707848                  0.845445          0.855205      0.140428                 0.520151  181.374927       246.696436            0.489485\n",
      "      8                0.20009214         0.510714  2.452906         3.213255       0.598160  0.572877                  0.783576          0.784569      0.122796                 0.642947  145.290600       221.325521            0.585677\n",
      "      9                0.30006143         0.304038  1.644082         2.690465       0.400922  0.398153                  0.656090          0.655830      0.164358                 0.807305   64.408177       169.046508            0.670830\n",
      "     10                0.40003071         0.167314  0.995268         2.266828       0.242704  0.233425                  0.552783          0.550269      0.099496                 0.906801   -0.473211       126.682847            0.670205\n",
      "     11                0.50000000         0.077471  0.516531         1.916877       0.125960  0.117680                  0.467445          0.463778      0.051637                 0.958438  -48.346856        91.687657            0.606286\n",
      "     12                0.59996929         0.033822  0.239368         1.637363       0.058372  0.053726                  0.399283          0.395453      0.023929                 0.982368  -76.063177        63.736341            0.505723\n",
      "     13                0.69993857         0.015017  0.107086         1.418800       0.026114  0.023051                  0.345985          0.342265      0.010705                 0.993073  -89.291421        41.880028            0.387671\n",
      "     14                0.79990786         0.006963  0.050393         1.247782       0.012289  0.010495                  0.304281          0.300801      0.005038                 0.998111  -94.960669        24.778225            0.262124\n",
      "     15                0.89987715         0.002194  0.012598         1.110563       0.003072  0.004282                  0.270819          0.267860      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000392  0.006290         1.000000       0.001534  0.001332                  0.243857          0.241175      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6055.376953          1.000000   0.306484\n",
      "                      capital_gain         3700.682373          0.611140   0.187304\n",
      "                               age         1840.232056          0.303900   0.093141\n",
      "                            fnlwgt         1305.528809          0.215598   0.066077\n",
      "                      capital_loss         1233.227783          0.203658   0.062418\n",
      "                    hours_per_week          962.625305          0.158970   0.048722\n",
      "        occupation. Prof-specialty          630.709534          0.104157   0.031922\n",
      "       occupation. Exec-managerial          607.904419          0.100391   0.030768\n",
      "              education. Bachelors          432.663055          0.071451   0.021899\n",
      "                education. HS-grad          223.476944          0.036906   0.011311\n",
      "---\n",
      "                       race. Black           15.939830          0.002632   0.000807\n",
      "           relationship. Unmarried           13.759626          0.002272   0.000696\n",
      "           marital_status. Widowed           12.067593          0.001993   0.000611\n",
      "          race. Asian-Pac-Islander            9.433745          0.001558   0.000477\n",
      "          race. Amer-Indian-Eskimo            9.011002          0.001488   0.000456\n",
      "                 native_country.NA            8.507712          0.001405   0.000431\n",
      "                   education. 12th            7.331263          0.001211   0.000371\n",
      "                education. 1st-4th            5.899384          0.000974   0.000299\n",
      "         marital_status. Separated            5.695473          0.000941   0.000288\n",
      "                      workclass.NA            0.657392          0.000109   0.000033\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        78312.742188          1.000000   0.136264\n",
      "                      capital_gain        75235.000000          0.960699   0.130908\n",
      "                               age        66981.468750          0.855307   0.116547\n",
      "                      capital_loss        49830.296875          0.636299   0.086704\n",
      "                    hours_per_week        40493.769531          0.517078   0.070459\n",
      "marital_status. Married-civ-spouse        30507.763672          0.389563   0.053083\n",
      "        occupation. Prof-specialty        12174.849609          0.155464   0.021184\n",
      "       occupation. Exec-managerial        11151.792969          0.142401   0.019404\n",
      "              education. Bachelors        10549.041992          0.134704   0.018355\n",
      "                education. Masters        10236.707031          0.130716   0.017812\n",
      "---\n",
      "           marital_status. Widowed         1573.643066          0.020094   0.002738\n",
      "           relationship. Unmarried         1542.044556          0.019691   0.002683\n",
      "                   education. 12th         1464.636719          0.018702   0.002548\n",
      "             education. Assoc-acdm         1453.942017          0.018566   0.002530\n",
      "                education. 1st-4th         1446.890259          0.018476   0.002518\n",
      "          marital_status. Divorced          756.609924          0.009661   0.001316\n",
      "                       race. Black          755.577454          0.009648   0.001315\n",
      "       relationship. Not-in-family          655.851868          0.008375   0.001141\n",
      "          race. Asian-Pac-Islander          472.863831          0.006038   0.000823\n",
      "                      workclass.NA           23.772663          0.000304   0.000041\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          485.000000          1.000000   0.249743\n",
      "                          age          410.000000          0.845361   0.211123\n",
      "               hours_per_week          174.000000          0.358763   0.089598\n",
      "                 capital_gain           93.000000          0.191753   0.047889\n",
      "                 capital_loss           66.000000          0.136082   0.033986\n",
      "           workclass. Private           54.000000          0.111340   0.027806\n",
      "         education. Bachelors           45.000000          0.092784   0.023172\n",
      "           education. HS-grad           42.000000          0.086598   0.021627\n",
      "   occupation. Prof-specialty           40.000000          0.082474   0.020597\n",
      "  occupation. Exec-managerial           37.000000          0.076289   0.019053\n",
      "---\n",
      "     race. Asian-Pac-Islander            4.000000          0.008247   0.002060\n",
      "occupation. Machine-op-inspct            4.000000          0.008247   0.002060\n",
      "      marital_status. Widowed            3.000000          0.006186   0.001545\n",
      "     race. Amer-Indian-Eskimo            3.000000          0.006186   0.001545\n",
      "  native_country. Philippines            3.000000          0.006186   0.001545\n",
      "    marital_status. Separated            2.000000          0.004124   0.001030\n",
      "            native_country.NA            2.000000          0.004124   0.001030\n",
      "              education. 12th            1.000000          0.002062   0.000515\n",
      "                 workclass.NA            1.000000          0.002062   0.000515\n",
      "           education. 1st-4th            1.000000          0.002062   0.000515\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      " 2023-10-20 18:27:51 10.605 sec              25       0.28363          0.25578      0.94169         0.85676       4.16584                       0.12334         0.30238            0.28932        0.92390           0.81973         4.10076                         0.13821\n",
      " 2023-10-20 18:27:51 10.959 sec              30       0.28040          0.25009      0.94446         0.86252       4.16584                       0.11540         0.30224            0.28868        0.92399           0.82103         4.10076                         0.14297\n",
      " 2023-10-20 18:27:52 11.274 sec              35       0.27718          0.24525      0.94687         0.86839       4.16584                       0.11263         0.30257            0.28969        0.92337           0.81983         4.10076                         0.14020\n",
      "\n",
      "10-20 18:27:52.312 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29690674192082595, 0.29168173437120953, 0.28977738047184537, 0.28922954474835305]\n",
      "10-20 18:27:52.312 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29690674192082595 --> 0.28922954474835305 (still improving).\n",
      "10-20 18:27:52.338 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.026 (Wall: 20-Oct 18:27:52.338) \n",
      "10-20 18:27:52.363 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.024 (Wall: 20-Oct 18:27:52.362) \n",
      "10-20 18:27:52.396 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:52.396) \n",
      "10-20 18:27:52.431 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:52.431) \n",
      "10-20 18:27:52.467 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:52.467) \n",
      "10-20 18:27:52.553 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_401\n",
      "10-20 18:27:52.570 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_401\n",
      "10-20 18:27:52.697 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_402\n",
      "10-20 18:27:52.708 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_402\n",
      "10-20 18:27:52.711 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.07520626\n",
      " RMSE: 0.2742376\n",
      " AUC: 0.94925964\n",
      " pr_auc: 0.87361234\n",
      " logloss: 0.24042636\n",
      " mean_per_class_error: 0.14186686\n",
      " default threshold: 0.38854607939720154\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18165  1631  0.0824  1,631 / 19,796\n",
      "     1   1259  4994  0.2013   1,259 / 6,253\n",
      "Totals  19424  6625  0.1109  2,890 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.16 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.997468  4.165840         4.165840       1.000000  0.998162                  1.000000          0.998162      0.041740                 0.041740  316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.995934  4.165840         4.165840       1.000000  0.996733                  1.000000          0.997448      0.041580                 0.083320  316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.992816  4.165840         4.165840       1.000000  0.994663                  1.000000          0.996519      0.041740                 0.125060  316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.985007  4.165840         4.165840       1.000000  0.989241                  1.000000          0.994703      0.041580                 0.166640  316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.972937  4.133918         4.159446       0.992337  0.979871                  0.998465          0.991732      0.041420                 0.208060  313.391825       315.944617            0.207959\n",
      "      6                0.10000384         0.801031  3.887478         4.023514       0.933180  0.888714                  0.965835          0.940243      0.194307                 0.402367  288.747779       302.351418            0.397871\n",
      "      7                0.15002495         0.650155  3.270648         3.772495       0.785111  0.725612                  0.905578          0.868681      0.163601                 0.565968  227.064829       277.249467            0.547328\n",
      "      8                0.20000768         0.508187  2.569255         3.471800       0.616743  0.576577                  0.833397          0.795683      0.128418                 0.694387  156.925487       247.180019            0.650539\n",
      "      9                0.30001152         0.308314  1.635952         2.859851       0.392706  0.399947                  0.686500          0.663771      0.163601                 0.857988   63.595191       185.985076            0.734226\n",
      "     10                0.40001536         0.162255  0.889139         2.367173       0.213436  0.231214                  0.568234          0.555632      0.088917                 0.946905  -11.086094       136.717284            0.719637\n",
      "     11                0.50001919         0.071607  0.350218         1.963782       0.084069  0.111672                  0.471401          0.466840      0.035023                 0.981929  -64.978156        96.378196            0.634131\n",
      "     12                0.59998464         0.029623  0.124783         1.657380       0.029954  0.047672                  0.397850          0.397001      0.012474                 0.994403  -87.521676        65.738023            0.519004\n",
      "     13                0.69998848         0.013703  0.041578         1.426539       0.009981  0.020426                  0.342437          0.343201      0.004158                 0.998561  -95.842155        42.653874            0.392883\n",
      "     14                0.79999232         0.005941  0.009595         1.249412       0.002303  0.009496                  0.299918          0.301486      0.000960                 0.999520  -99.040497        24.941228            0.262553\n",
      "     15                0.89999616         0.001648  0.003198         1.110938       0.000768  0.003548                  0.266678          0.268381      0.000320                 0.999840  -99.680166        11.093816            0.131382\n",
      "     16                1.00000000         0.000146  0.001599         1.000000       0.000384  0.000960                  0.240048          0.241638      0.000160                 1.000000  -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09190376\n",
      " RMSE: 0.30315635\n",
      " AUC: 0.92287827\n",
      " pr_auc: 0.8184632\n",
      " logloss: 0.29067665\n",
      " mean_per_class_error: 0.17471537\n",
      " default threshold: 0.3794865012168884\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4422   502  0.1019  502 / 4,924\n",
      "     1   393  1195  0.2475  393 / 1,588\n",
      "Totals  4815  1697  0.1374  895 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.22 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.997430  4.100756         4.100756       1.000000  0.998113                  1.000000          0.998113      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.995926  4.037667         4.069452       0.984615  0.996687                  0.992366          0.997405      0.040302                 0.081864  303.766712       306.945219            0.081661\n",
      "      3                0.03009828         0.992869  4.100756         4.079833       1.000000  0.994602                  0.994898          0.996476      0.040932                 0.122796  310.075567       307.983344            0.122593\n",
      "      4                0.04007985         0.983570  4.100756         4.085044       1.000000  0.988883                  0.996169          0.994585      0.040932                 0.163728  310.075567       308.504396            0.163525\n",
      "      5                0.05006143         0.972781  3.848401         4.037861       0.938462  0.978058                  0.984663          0.991289      0.038413                 0.202141  284.840147       303.786064            0.201126\n",
      "      6                0.10012285         0.784053  3.572437         3.805149       0.871166  0.875584                  0.927914          0.933437      0.178841                 0.380982  257.243745       280.514905            0.371437\n",
      "      7                0.15003071         0.651430  2.788514         3.466964       0.680000  0.714483                  0.845445          0.860602      0.139169                 0.520151  178.851385       246.696436            0.489485\n",
      "      8                0.20009214         0.512019  2.364853         3.191225       0.576687  0.576804                  0.778204          0.789598      0.118388                 0.638539  136.485296       219.122506            0.579847\n",
      "      9                0.30006143         0.313312  1.656680         2.679972       0.403994  0.402818                  0.653531          0.660737      0.165617                 0.804156   65.668009       167.997185            0.666666\n",
      "     10                0.40003071         0.162608  1.007866         2.262106       0.245776  0.234168                  0.551631          0.554136      0.100756                 0.904912    0.786622       126.210591            0.667706\n",
      "     11                0.50000000         0.076147  0.541728         1.918136       0.132104  0.116276                  0.467752          0.466591      0.054156                 0.959068  -45.827191        91.813602            0.607118\n",
      "     12                0.59996929         0.032667  0.239368         1.638413       0.058372  0.052544                  0.399539          0.397601      0.023929                 0.982997  -76.063177        63.841300            0.506556\n",
      "     13                0.69993857         0.014570  0.107086         1.419700       0.026114  0.022241                  0.346204          0.343990      0.010705                 0.993703  -89.291421        41.969997            0.388504\n",
      "     14                0.79990786         0.005911  0.044094         1.247782       0.010753  0.009778                  0.304281          0.302221      0.004408                 0.998111  -95.590585        24.778225            0.262124\n",
      "     15                0.89987715         0.001646  0.012598         1.110563       0.003072  0.003528                  0.270819          0.269039      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000205  0.006290         1.000000       0.001534  0.000969                  0.243857          0.242199      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6058.916992          1.000000   0.297558\n",
      "                      capital_gain         3717.098877          0.613492   0.182550\n",
      "                               age         1932.313477          0.318921   0.094897\n",
      "                            fnlwgt         1474.584229          0.243374   0.072418\n",
      "                      capital_loss         1281.109985          0.211442   0.062916\n",
      "                    hours_per_week         1038.336670          0.171373   0.050994\n",
      "        occupation. Prof-specialty          643.681030          0.106237   0.031612\n",
      "       occupation. Exec-managerial          609.408752          0.100580   0.029929\n",
      "              education. Bachelors          445.063721          0.073456   0.021857\n",
      "                education. HS-grad          250.129303          0.041283   0.012284\n",
      "---\n",
      "       native_country. Philippines           16.811863          0.002775   0.000826\n",
      "           relationship. Unmarried           13.759626          0.002271   0.000676\n",
      "          race. Asian-Pac-Islander           12.104334          0.001998   0.000594\n",
      "           marital_status. Widowed           12.067593          0.001992   0.000593\n",
      "          race. Amer-Indian-Eskimo            9.011002          0.001487   0.000443\n",
      "         marital_status. Separated            8.747306          0.001444   0.000430\n",
      "                 native_country.NA            8.507712          0.001404   0.000418\n",
      "                   education. 12th            7.331263          0.001210   0.000360\n",
      "                education. 1st-4th            5.899384          0.000974   0.000290\n",
      "                      workclass.NA            0.657392          0.000108   0.000032\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt        89777.820313          1.000000   0.140714\n",
      "                      capital_gain        81178.085938          0.904211   0.127235\n",
      "                               age        73106.250000          0.814302   0.114584\n",
      "                      capital_loss        60090.429688          0.669324   0.094183\n",
      "                    hours_per_week        48193.660156          0.536810   0.075537\n",
      "marital_status. Married-civ-spouse        31528.652344          0.351185   0.049417\n",
      "        occupation. Prof-specialty        12605.799805          0.140411   0.019758\n",
      "       occupation. Exec-managerial        11217.691406          0.124949   0.017582\n",
      "              education. Doctorate        10944.467773          0.121906   0.017154\n",
      "              education. Bachelors        10808.049805          0.120387   0.016940\n",
      "---\n",
      "             education. Assoc-acdm         1623.535156          0.018084   0.002545\n",
      "           marital_status. Widowed         1573.643066          0.017528   0.002466\n",
      "          race. Asian-Pac-Islander         1571.618896          0.017506   0.002463\n",
      "           relationship. Unmarried         1542.044556          0.017176   0.002417\n",
      "                   education. 12th         1464.636719          0.016314   0.002296\n",
      "                education. 1st-4th         1446.890259          0.016116   0.002268\n",
      "       relationship. Not-in-family         1148.717285          0.012795   0.001800\n",
      "                       race. Black         1130.777344          0.012595   0.001772\n",
      "          marital_status. Divorced          756.609924          0.008428   0.001186\n",
      "                      workclass.NA           23.772663          0.000265   0.000037\n",
      "Variable Importances - Frequency:\n",
      "                    Variable Relative Importance Scaled Importance Percentage\n",
      "                      fnlwgt          547.000000          1.000000   0.250114\n",
      "                         age          450.000000          0.822669   0.205761\n",
      "              hours_per_week          211.000000          0.385740   0.096479\n",
      "                capital_gain          100.000000          0.182815   0.045725\n",
      "                capital_loss           81.000000          0.148080   0.037037\n",
      "          workclass. Private           61.000000          0.111517   0.027892\n",
      "          education. HS-grad           53.000000          0.096892   0.024234\n",
      "        education. Bachelors           50.000000          0.091408   0.022862\n",
      "  occupation. Prof-specialty           43.000000          0.078611   0.019662\n",
      "                 sex. Female           41.000000          0.074954   0.018747\n",
      "---\n",
      "        education. Assoc-voc            4.000000          0.007313   0.001829\n",
      "relationship. Other-relative            4.000000          0.007313   0.001829\n",
      "     marital_status. Widowed            3.000000          0.005484   0.001372\n",
      "   marital_status. Separated            3.000000          0.005484   0.001372\n",
      "    race. Amer-Indian-Eskimo            3.000000          0.005484   0.001372\n",
      " native_country. Philippines            3.000000          0.005484   0.001372\n",
      "           native_country.NA            2.000000          0.003656   0.000914\n",
      "             education. 12th            1.000000          0.001828   0.000457\n",
      "                workclass.NA            1.000000          0.001828   0.000457\n",
      "          education. 1st-4th            1.000000          0.001828   0.000457\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      " 2023-10-20 18:27:51 10.605 sec              25       0.28363          0.25578      0.94169         0.85676       4.16584                       0.12334         0.30238            0.28932        0.92390           0.81973         4.10076                         0.13821\n",
      " 2023-10-20 18:27:51 10.959 sec              30       0.28040          0.25009      0.94446         0.86252       4.16584                       0.11540         0.30224            0.28868        0.92399           0.82103         4.10076                         0.14297\n",
      " 2023-10-20 18:27:52 11.274 sec              35       0.27718          0.24525      0.94687         0.86839       4.16584                       0.11263         0.30257            0.28969        0.92337           0.81983         4.10076                         0.14020\n",
      " 2023-10-20 18:27:52 11.620 sec              40       0.27424          0.24043      0.94926         0.87361       4.16584                       0.11094         0.30316            0.29068        0.92288           0.81846         4.10076                         0.13744\n",
      "\n",
      "10-20 18:27:52.713 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29168173437120953, 0.28977738047184537, 0.28922954474835305, 0.28968252060937755]\n",
      "10-20 18:27:52.713 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29168173437120953 --> 0.28922954474835305 (still improving).\n",
      "10-20 18:27:52.736 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 41. tree was built in 00:00:00.023 (Wall: 20-Oct 18:27:52.736) \n",
      "10-20 18:27:52.759 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 42. tree was built in 00:00:00.023 (Wall: 20-Oct 18:27:52.759) \n",
      "10-20 18:27:52.781 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 43. tree was built in 00:00:00.022 (Wall: 20-Oct 18:27:52.781) \n",
      "10-20 18:27:52.806 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 44. tree was built in 00:00:00.024 (Wall: 20-Oct 18:27:52.806) \n",
      "10-20 18:27:52.836 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: 45. tree was built in 00:00:00.030 (Wall: 20-Oct 18:27:52.836) \n",
      "10-20 18:27:52.898 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_403\n",
      "10-20 18:27:52.911 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_403\n",
      "10-20 18:27:53.064 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_404\n",
      "10-20 18:27:53.076 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_404\n",
      "10-20 18:27:53.080 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.073907696\n",
      " RMSE: 0.2718597\n",
      " AUC: 0.95115536\n",
      " pr_auc: 0.87790024\n",
      " logloss: 0.23653659\n",
      " mean_per_class_error: 0.14112502\n",
      " default threshold: 0.40619057416915894\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18340  1456  0.0736  1,456 / 19,796\n",
      "     1   1305  4948  0.2087   1,305 / 6,253\n",
      "Totals  19645  6404  0.1060  2,761 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.18 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.997979  4.165840         4.165840       1.000000  0.998545                  1.000000          0.998545      0.041740                 0.041740   316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.996735  4.165840         4.165840       1.000000  0.997358                  1.000000          0.997953      0.041580                 0.083320   316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.994172  4.165840         4.165840       1.000000  0.995654                  1.000000          0.997186      0.041740                 0.125060   316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.987266  4.165840         4.165840       1.000000  0.990999                  1.000000          0.995642      0.041580                 0.166640   316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.976142  4.133918         4.159446       0.992337  0.982146                  0.998465          0.992939      0.041420                 0.208060   313.391825       315.944617            0.207959\n",
      "      6                0.10000384         0.805975  3.919473         4.039506       0.940860  0.893314                  0.969674          0.943145      0.195906                 0.403966   291.947349       303.950589            0.399975\n",
      "      7                0.15002495         0.649841  3.312211         3.797012       0.795088  0.729555                  0.911464          0.871930      0.165680                 0.569647   231.221078       279.701215            0.552168\n",
      "      8                0.20000768         0.509420  2.588452         3.494988       0.621352  0.578493                  0.838964          0.798599      0.129378                 0.699024   158.845229       249.498817            0.656642\n",
      "      9                0.30001152         0.307456  1.653543         2.881173       0.396929  0.401382                  0.691619          0.666193      0.165361                 0.864385    65.354279       188.117304            0.742643\n",
      "     10                0.40001536         0.158951  0.844362         2.371970       0.202687  0.230516                  0.569386          0.557274      0.084439                 0.948825   -15.563772       137.197035            0.722163\n",
      "     11                0.50001919         0.070326  0.351818         1.967940       0.084453  0.109885                  0.472399          0.467796      0.035183                 0.984008   -64.818238        96.793981            0.636867\n",
      "     12                0.59998464         0.029065  0.105586         1.657647       0.025346  0.046738                  0.397914          0.397642      0.010555                 0.994563   -89.441418        65.764677            0.519214\n",
      "     13                0.69998848         0.012962  0.043178         1.426996       0.010365  0.019683                  0.342547          0.343645      0.004318                 0.998881   -95.682238        42.699567            0.393304\n",
      "     14                0.79999232         0.005479  0.009595         1.249812       0.002303  0.008879                  0.300014          0.301797      0.000960                 0.999840   -99.040497        24.981209            0.262974\n",
      "     15                0.89999616         0.001499  0.000000         1.110938       0.000000  0.003250                  0.266678          0.268624      0.000000                 0.999840  -100.000000        11.093816            0.131382\n",
      "     16                1.00000000         0.000067  0.001599         1.000000       0.000384  0.000774                  0.240048          0.241838      0.000160                 1.000000   -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09232961\n",
      " RMSE: 0.30385786\n",
      " AUC: 0.92183685\n",
      " pr_auc: 0.8176585\n",
      " logloss: 0.29228127\n",
      " mean_per_class_error: 0.17552848\n",
      " default threshold: 0.39179596304893494\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4445   479  0.0973  479 / 4,924\n",
      "     1   403  1185  0.2538  403 / 1,588\n",
      "Totals  4848  1664  0.1354  882 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.997879  4.100756         4.100756       1.000000  0.998476                  1.000000          0.998476      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.996600  4.037667         4.069452       0.984615  0.997300                  0.992366          0.997893      0.040302                 0.081864  303.766712       306.945219            0.081661\n",
      "      3                0.03009828         0.993671  4.100756         4.079833       1.000000  0.995432                  0.994898          0.997077      0.040932                 0.122796  310.075567       307.983344            0.122593\n",
      "      4                0.04007985         0.986865  4.037667         4.069332       0.984615  0.990381                  0.992337          0.995409      0.040302                 0.163098  303.766712       306.933225            0.162692\n",
      "      5                0.05006143         0.974855  3.974579         4.050440       0.969231  0.981338                  0.987730          0.992603      0.039673                 0.202771  297.457857       305.043965            0.201958\n",
      "      6                0.10012285         0.790859  3.547279         3.798860       0.865031  0.878721                  0.926380          0.935662      0.177582                 0.380353  254.727944       279.885954            0.370604\n",
      "      7                0.15003071         0.651227  2.788514         3.462767       0.680000  0.717434                  0.844422          0.863069      0.139169                 0.519521  178.851385       246.276707            0.488652\n",
      "      8                0.20009214         0.508628  2.377432         3.191225       0.579755  0.577142                  0.778204          0.791532      0.119018                 0.638539  137.743197       219.122506            0.579847\n",
      "      9                0.30006143         0.309608  1.618885         2.667380       0.394777  0.404014                  0.650461          0.662425      0.161839                 0.800378   61.888511       166.737997            0.661669\n",
      "     10                0.40003071         0.162637  1.014165         2.254235       0.247312  0.233253                  0.549712          0.555173      0.101385                 0.901763    1.416538       125.423498            0.663542\n",
      "     11                0.50000000         0.074638  0.573224         1.918136       0.139785  0.116019                  0.467752          0.467370      0.057305                 0.959068  -42.677609        91.813602            0.607118\n",
      "     12                0.59996929         0.032244  0.233069         1.637363       0.056836  0.051430                  0.399283          0.398064      0.023300                 0.982368  -76.693094        63.736341            0.505723\n",
      "     13                0.69993857         0.013811  0.113385         1.419700       0.027650  0.021524                  0.346204          0.344284      0.011335                 0.993703  -88.661505        41.969997            0.388504\n",
      "     14                0.79990786         0.005528  0.044094         1.247782       0.010753  0.009177                  0.304281          0.302404      0.004408                 0.998111  -95.590585        24.778225            0.262124\n",
      "     15                0.89987715         0.001556  0.012598         1.110563       0.003072  0.003251                  0.270819          0.269171      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000112  0.006290         1.000000       0.001534  0.000803                  0.243857          0.242301      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6065.943848          1.000000   0.289381\n",
      "                      capital_gain         3724.468018          0.613996   0.177679\n",
      "                               age         2040.241699          0.336344   0.097331\n",
      "                            fnlwgt         1717.520630          0.283142   0.081936\n",
      "                      capital_loss         1302.093384          0.214656   0.062117\n",
      "                    hours_per_week         1095.400269          0.180582   0.052257\n",
      "        occupation. Prof-specialty          651.489014          0.107401   0.031080\n",
      "       occupation. Exec-managerial          615.809509          0.101519   0.029378\n",
      "              education. Bachelors          457.918976          0.075490   0.021845\n",
      "                education. HS-grad          259.572479          0.042792   0.012383\n",
      "---\n",
      "       native_country. Philippines           16.811863          0.002772   0.000802\n",
      "           relationship. Unmarried           13.759626          0.002268   0.000656\n",
      "          race. Asian-Pac-Islander           12.104334          0.001995   0.000577\n",
      "          race. Amer-Indian-Eskimo            9.011002          0.001486   0.000430\n",
      "         marital_status. Separated            8.747306          0.001442   0.000417\n",
      "                 native_country.NA            8.507712          0.001403   0.000406\n",
      "                   education. 12th            7.331263          0.001209   0.000350\n",
      "                education. 1st-4th            5.899384          0.000973   0.000281\n",
      "                      workclass.NA            5.026763          0.000829   0.000240\n",
      "             native_country. Italy            3.126183          0.000515   0.000149\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       110634.625000          1.000000   0.157728\n",
      "                               age        85396.343750          0.771877   0.121746\n",
      "                      capital_gain        83504.156250          0.754774   0.119049\n",
      "                      capital_loss        65210.898438          0.589426   0.092969\n",
      "                    hours_per_week        53791.707031          0.486210   0.076689\n",
      "marital_status. Married-civ-spouse        32647.298828          0.295091   0.046544\n",
      "        occupation. Prof-specialty        14061.217773          0.127096   0.020047\n",
      "       occupation. Exec-managerial        11386.997070          0.102924   0.016234\n",
      "              education. Bachelors        11197.124023          0.101208   0.015963\n",
      "              education. Doctorate        10944.467773          0.098924   0.015603\n",
      "---\n",
      "                 native_country.NA         1689.621704          0.015272   0.002409\n",
      "          race. Asian-Pac-Islander         1571.618896          0.014205   0.002241\n",
      "           relationship. Unmarried         1542.044556          0.013938   0.002198\n",
      "                       race. Black         1499.752441          0.013556   0.002138\n",
      "                   education. 12th         1464.636719          0.013239   0.002088\n",
      "                education. 1st-4th         1446.890259          0.013078   0.002063\n",
      "             native_country. Italy         1318.275391          0.011916   0.001879\n",
      "       relationship. Not-in-family         1148.717285          0.010383   0.001638\n",
      "                      workclass.NA         1055.413818          0.009540   0.001505\n",
      "          marital_status. Divorced          756.609924          0.006839   0.001079\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          633.000000          1.000000   0.261570\n",
      "                          age          499.000000          0.788310   0.206198\n",
      "               hours_per_week          235.000000          0.371248   0.097107\n",
      "                 capital_gain          102.000000          0.161137   0.042149\n",
      "                 capital_loss           86.000000          0.135861   0.035537\n",
      "           workclass. Private           65.000000          0.102686   0.026860\n",
      "           education. HS-grad           58.000000          0.091627   0.023967\n",
      "         education. Bachelors           56.000000          0.088468   0.023140\n",
      "   occupation. Prof-specialty           46.000000          0.072670   0.019008\n",
      "                  sex. Female           43.000000          0.067930   0.017769\n",
      "---\n",
      "occupation. Handlers-cleaners            4.000000          0.006319   0.001653\n",
      "         education. Assoc-voc            4.000000          0.006319   0.001653\n",
      "    marital_status. Separated            3.000000          0.004739   0.001240\n",
      "                 workclass.NA            3.000000          0.004739   0.001240\n",
      "     race. Amer-Indian-Eskimo            3.000000          0.004739   0.001240\n",
      "  native_country. Philippines            3.000000          0.004739   0.001240\n",
      "            native_country.NA            2.000000          0.003160   0.000826\n",
      "              education. 12th            1.000000          0.001580   0.000413\n",
      "        native_country. Italy            1.000000          0.001580   0.000413\n",
      "           education. 1st-4th            1.000000          0.001580   0.000413\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              45\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      " 2023-10-20 18:27:51 10.605 sec              25       0.28363          0.25578      0.94169         0.85676       4.16584                       0.12334         0.30238            0.28932        0.92390           0.81973         4.10076                         0.13821\n",
      " 2023-10-20 18:27:51 10.959 sec              30       0.28040          0.25009      0.94446         0.86252       4.16584                       0.11540         0.30224            0.28868        0.92399           0.82103         4.10076                         0.14297\n",
      " 2023-10-20 18:27:52 11.274 sec              35       0.27718          0.24525      0.94687         0.86839       4.16584                       0.11263         0.30257            0.28969        0.92337           0.81983         4.10076                         0.14020\n",
      " 2023-10-20 18:27:52 11.620 sec              40       0.27424          0.24043      0.94926         0.87361       4.16584                       0.11094         0.30316            0.29068        0.92288           0.81846         4.10076                         0.13744\n",
      " 2023-10-20 18:27:52 11.989 sec              45       0.27186          0.23654      0.95116         0.87790       4.16584                       0.10599         0.30386            0.29228        0.92184           0.81766         4.10076                         0.13544\n",
      "\n",
      "10-20 18:27:53.082 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.28977738047184537, 0.28922954474835305, 0.28968252060937755, 0.29088180689003623]\n",
      "10-20 18:27:53.082 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.28977738047184537 --> 0.28922954474835305 (converged).\n",
      "10-20 18:27:53.082 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Early stopping triggered - stopping XGBoost training\n",
      "10-20 18:27:53.082 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Setting actual ntrees to the 45\n",
      "10-20 18:27:53.151 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_405\n",
      "10-20 18:27:53.164 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_405\n",
      "10-20 18:27:53.169 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:53.314 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_406\n",
      "10-20 18:27:53.324 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_406\n",
      "10-20 18:27:53.328 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_train\n",
      " MSE: 0.073907696\n",
      " RMSE: 0.2718597\n",
      " AUC: 0.95115536\n",
      " pr_auc: 0.87790024\n",
      " logloss: 0.23653659\n",
      " mean_per_class_error: 0.14112502\n",
      " default threshold: 0.40619057416915894\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  18340  1456  0.0736  1,456 / 19,796\n",
      "     1   1305  4948  0.2087   1,305 / 6,253\n",
      "Totals  19645  6404  0.1060  2,761 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.00 %, avg score: 24.18 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001958         0.997979  4.165840         4.165840       1.000000  0.998545                  1.000000          0.998545      0.041740                 0.041740   316.584040       316.584040            0.041740\n",
      "      2                0.02000077         0.996735  4.165840         4.165840       1.000000  0.997358                  1.000000          0.997953      0.041580                 0.083320   316.584040       316.584040            0.083320\n",
      "      3                0.03002035         0.994172  4.165840         4.165840       1.000000  0.995654                  1.000000          0.997186      0.041740                 0.125060   316.584040       316.584040            0.125060\n",
      "      4                0.04000154         0.987266  4.165840         4.165840       1.000000  0.990999                  1.000000          0.995642      0.041580                 0.166640   316.584040       316.584040            0.166640\n",
      "      5                0.05002111         0.976142  4.133918         4.159446       0.992337  0.982146                  0.998465          0.992939      0.041420                 0.208060   313.391825       315.944617            0.207959\n",
      "      6                0.10000384         0.805975  3.919473         4.039506       0.940860  0.893314                  0.969674          0.943145      0.195906                 0.403966   291.947349       303.950589            0.399975\n",
      "      7                0.15002495         0.649841  3.312211         3.797012       0.795088  0.729555                  0.911464          0.871930      0.165680                 0.569647   231.221078       279.701215            0.552168\n",
      "      8                0.20000768         0.509420  2.588452         3.494988       0.621352  0.578493                  0.838964          0.798599      0.129378                 0.699024   158.845229       249.498817            0.656642\n",
      "      9                0.30001152         0.307456  1.653543         2.881173       0.396929  0.401382                  0.691619          0.666193      0.165361                 0.864385    65.354279       188.117304            0.742643\n",
      "     10                0.40001536         0.158951  0.844362         2.371970       0.202687  0.230516                  0.569386          0.557274      0.084439                 0.948825   -15.563772       137.197035            0.722163\n",
      "     11                0.50001919         0.070326  0.351818         1.967940       0.084453  0.109885                  0.472399          0.467796      0.035183                 0.984008   -64.818238        96.793981            0.636867\n",
      "     12                0.59998464         0.029065  0.105586         1.657647       0.025346  0.046738                  0.397914          0.397642      0.010555                 0.994563   -89.441418        65.764677            0.519214\n",
      "     13                0.69998848         0.012962  0.043178         1.426996       0.010365  0.019683                  0.342547          0.343645      0.004318                 0.998881   -95.682238        42.699567            0.393304\n",
      "     14                0.79999232         0.005479  0.009595         1.249812       0.002303  0.008879                  0.300014          0.301797      0.000960                 0.999840   -99.040497        24.981209            0.262974\n",
      "     15                0.89999616         0.001499  0.000000         1.110938       0.000000  0.003250                  0.266678          0.268624      0.000000                 0.999840  -100.000000        11.093816            0.131382\n",
      "     16                1.00000000         0.000067  0.001599         1.000000       0.000384  0.000774                  0.240048          0.241838      0.000160                 1.000000   -99.840083         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      " frame id: XGBoost_2_AutoML_1_20231020_182658_cv_5_valid\n",
      " MSE: 0.09232961\n",
      " RMSE: 0.30385786\n",
      " AUC: 0.92183685\n",
      " pr_auc: 0.8176585\n",
      " logloss: 0.29228127\n",
      " mean_per_class_error: 0.17552848\n",
      " default threshold: 0.39179596304893494\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "           0     1   Error         Rate\n",
      "     0  4445   479  0.0973  479 / 4,924\n",
      "     1   403  1185  0.2538  403 / 1,588\n",
      "Totals  4848  1664  0.1354  882 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 24.39 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01013514         0.997879  4.100756         4.100756       1.000000  0.998476                  1.000000          0.998476      0.041562                 0.041562  310.075567       310.075567            0.041562\n",
      "      2                0.02011671         0.996600  4.037667         4.069452       0.984615  0.997300                  0.992366          0.997893      0.040302                 0.081864  303.766712       306.945219            0.081661\n",
      "      3                0.03009828         0.993671  4.100756         4.079833       1.000000  0.995432                  0.994898          0.997077      0.040932                 0.122796  310.075567       307.983344            0.122593\n",
      "      4                0.04007985         0.986865  4.037667         4.069332       0.984615  0.990381                  0.992337          0.995409      0.040302                 0.163098  303.766712       306.933225            0.162692\n",
      "      5                0.05006143         0.974855  3.974579         4.050440       0.969231  0.981338                  0.987730          0.992603      0.039673                 0.202771  297.457857       305.043965            0.201958\n",
      "      6                0.10012285         0.790859  3.547279         3.798860       0.865031  0.878721                  0.926380          0.935662      0.177582                 0.380353  254.727944       279.885954            0.370604\n",
      "      7                0.15003071         0.651227  2.788514         3.462767       0.680000  0.717434                  0.844422          0.863069      0.139169                 0.519521  178.851385       246.276707            0.488652\n",
      "      8                0.20009214         0.508628  2.377432         3.191225       0.579755  0.577142                  0.778204          0.791532      0.119018                 0.638539  137.743197       219.122506            0.579847\n",
      "      9                0.30006143         0.309608  1.618885         2.667380       0.394777  0.404014                  0.650461          0.662425      0.161839                 0.800378   61.888511       166.737997            0.661669\n",
      "     10                0.40003071         0.162637  1.014165         2.254235       0.247312  0.233253                  0.549712          0.555173      0.101385                 0.901763    1.416538       125.423498            0.663542\n",
      "     11                0.50000000         0.074638  0.573224         1.918136       0.139785  0.116019                  0.467752          0.467370      0.057305                 0.959068  -42.677609        91.813602            0.607118\n",
      "     12                0.59996929         0.032244  0.233069         1.637363       0.056836  0.051430                  0.399283          0.398064      0.023300                 0.982368  -76.693094        63.736341            0.505723\n",
      "     13                0.69993857         0.013811  0.113385         1.419700       0.027650  0.021524                  0.346204          0.344284      0.011335                 0.993703  -88.661505        41.969997            0.388504\n",
      "     14                0.79990786         0.005528  0.044094         1.247782       0.010753  0.009177                  0.304281          0.302404      0.004408                 0.998111  -95.590585        24.778225            0.262124\n",
      "     15                0.89987715         0.001556  0.012598         1.110563       0.003072  0.003251                  0.270819          0.269171      0.001259                 0.999370  -98.740167        11.056301            0.131580\n",
      "     16                1.00000000         0.000112  0.006290         1.000000       0.001534  0.000803                  0.243857          0.242301      0.000630                 1.000000  -99.371050         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         6065.943848          1.000000   0.289381\n",
      "                      capital_gain         3724.468018          0.613996   0.177679\n",
      "                               age         2040.241699          0.336344   0.097331\n",
      "                            fnlwgt         1717.520630          0.283142   0.081936\n",
      "                      capital_loss         1302.093384          0.214656   0.062117\n",
      "                    hours_per_week         1095.400269          0.180582   0.052257\n",
      "        occupation. Prof-specialty          651.489014          0.107401   0.031080\n",
      "       occupation. Exec-managerial          615.809509          0.101519   0.029378\n",
      "              education. Bachelors          457.918976          0.075490   0.021845\n",
      "                education. HS-grad          259.572479          0.042792   0.012383\n",
      "---\n",
      "       native_country. Philippines           16.811863          0.002772   0.000802\n",
      "           relationship. Unmarried           13.759626          0.002268   0.000656\n",
      "          race. Asian-Pac-Islander           12.104334          0.001995   0.000577\n",
      "          race. Amer-Indian-Eskimo            9.011002          0.001486   0.000430\n",
      "         marital_status. Separated            8.747306          0.001442   0.000417\n",
      "                 native_country.NA            8.507712          0.001403   0.000406\n",
      "                   education. 12th            7.331263          0.001209   0.000350\n",
      "                education. 1st-4th            5.899384          0.000973   0.000281\n",
      "                      workclass.NA            5.026763          0.000829   0.000240\n",
      "             native_country. Italy            3.126183          0.000515   0.000149\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                            fnlwgt       110634.625000          1.000000   0.157728\n",
      "                               age        85396.343750          0.771877   0.121746\n",
      "                      capital_gain        83504.156250          0.754774   0.119049\n",
      "                      capital_loss        65210.898438          0.589426   0.092969\n",
      "                    hours_per_week        53791.707031          0.486210   0.076689\n",
      "marital_status. Married-civ-spouse        32647.298828          0.295091   0.046544\n",
      "        occupation. Prof-specialty        14061.217773          0.127096   0.020047\n",
      "       occupation. Exec-managerial        11386.997070          0.102924   0.016234\n",
      "              education. Bachelors        11197.124023          0.101208   0.015963\n",
      "              education. Doctorate        10944.467773          0.098924   0.015603\n",
      "---\n",
      "                 native_country.NA         1689.621704          0.015272   0.002409\n",
      "          race. Asian-Pac-Islander         1571.618896          0.014205   0.002241\n",
      "           relationship. Unmarried         1542.044556          0.013938   0.002198\n",
      "                       race. Black         1499.752441          0.013556   0.002138\n",
      "                   education. 12th         1464.636719          0.013239   0.002088\n",
      "                education. 1st-4th         1446.890259          0.013078   0.002063\n",
      "             native_country. Italy         1318.275391          0.011916   0.001879\n",
      "       relationship. Not-in-family         1148.717285          0.010383   0.001638\n",
      "                      workclass.NA         1055.413818          0.009540   0.001505\n",
      "          marital_status. Divorced          756.609924          0.006839   0.001079\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                       fnlwgt          633.000000          1.000000   0.261570\n",
      "                          age          499.000000          0.788310   0.206198\n",
      "               hours_per_week          235.000000          0.371248   0.097107\n",
      "                 capital_gain          102.000000          0.161137   0.042149\n",
      "                 capital_loss           86.000000          0.135861   0.035537\n",
      "           workclass. Private           65.000000          0.102686   0.026860\n",
      "           education. HS-grad           58.000000          0.091627   0.023967\n",
      "         education. Bachelors           56.000000          0.088468   0.023140\n",
      "   occupation. Prof-specialty           46.000000          0.072670   0.019008\n",
      "                  sex. Female           43.000000          0.067930   0.017769\n",
      "---\n",
      "occupation. Handlers-cleaners            4.000000          0.006319   0.001653\n",
      "         education. Assoc-voc            4.000000          0.006319   0.001653\n",
      "    marital_status. Separated            3.000000          0.004739   0.001240\n",
      "                 workclass.NA            3.000000          0.004739   0.001240\n",
      "     race. Amer-Indian-Eskimo            3.000000          0.004739   0.001240\n",
      "  native_country. Philippines            3.000000          0.004739   0.001240\n",
      "            native_country.NA            2.000000          0.003160   0.000826\n",
      "              education. 12th            1.000000          0.001580   0.000413\n",
      "        native_country. Italy            1.000000          0.001580   0.000413\n",
      "           education. 1st-4th            1.000000          0.001580   0.000413\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround           10000\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              45\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:50  9.163 sec               0       0.50000          0.69315      0.50000         0.24005       1.00000                       0.75995         0.50000            0.69315        0.50000           0.24386         1.00000                         0.75614\n",
      " 2023-10-20 18:27:50  9.426 sec               5       0.31530          0.33963      0.92239         0.81909       4.16094                       0.13713         0.32389            0.35306        0.91094           0.79917         4.10076                         0.16278\n",
      " 2023-10-20 18:27:50  9.735 sec              10       0.29691          0.28640      0.93095         0.83522       4.16584                       0.12745         0.30771            0.30499        0.91934           0.81350         4.10076                         0.14972\n",
      " 2023-10-20 18:27:50 10.002 sec              15       0.29100          0.27052      0.93578         0.84416       4.16584                       0.12331         0.30432            0.29440        0.92220           0.81717         4.10076                         0.14343\n",
      " 2023-10-20 18:27:51 10.307 sec              20       0.28709          0.26223      0.93882         0.85082       4.16584                       0.12135         0.30308            0.29133        0.92304           0.81857         4.10076                         0.14435\n",
      " 2023-10-20 18:27:51 10.605 sec              25       0.28363          0.25578      0.94169         0.85676       4.16584                       0.12334         0.30238            0.28932        0.92390           0.81973         4.10076                         0.13821\n",
      " 2023-10-20 18:27:51 10.959 sec              30       0.28040          0.25009      0.94446         0.86252       4.16584                       0.11540         0.30224            0.28868        0.92399           0.82103         4.10076                         0.14297\n",
      " 2023-10-20 18:27:52 11.274 sec              35       0.27718          0.24525      0.94687         0.86839       4.16584                       0.11263         0.30257            0.28969        0.92337           0.81983         4.10076                         0.14020\n",
      " 2023-10-20 18:27:52 11.620 sec              40       0.27424          0.24043      0.94926         0.87361       4.16584                       0.11094         0.30316            0.29068        0.92288           0.81846         4.10076                         0.13744\n",
      " 2023-10-20 18:27:52 11.989 sec              45       0.27186          0.23654      0.95116         0.87790       4.16584                       0.10599         0.30386            0.29228        0.92184           0.81766         4.10076                         0.13544\n",
      "\n",
      "10-20 18:27:53.330 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: In-training scoring took 1827ms.\n",
      "10-20 18:27:53.336 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model XGBoost_2_AutoML_1_20231020_182658_cv_5\n",
      "10-20 18:27:53.337 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 4 / 5.\n",
      "10-20 18:27:53.337 172.17.0.2:54321      22766      FJ-2-3  WARN water.default: _ntrees: Setting optimal _ntrees to 43 for cross-validation main model based on early stopping of cross-validation models.\n",
      "10-20 18:27:53.337 172.17.0.2:54321      22766      FJ-2-3  WARN water.default: _stopping_rounds: Disabling convergence-based early stopping for cross-validation main model.\n",
      "10-20 18:27:53.337 172.17.0.2:54321      22766      FJ-2-3  WARN water.default: _max_runtime_secs: Disabling maximum allowed runtime for cross-validation main model.\n",
      "10-20 18:27:53.337 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Scoring the 5 CV models\n",
      "10-20 18:27:53.373 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_407\n",
      "10-20 18:27:53.385 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_407\n",
      "10-20 18:27:53.425 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_408\n",
      "10-20 18:27:53.436 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_408\n",
      "10-20 18:27:53.467 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_409\n",
      "10-20 18:27:53.477 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_409\n",
      "10-20 18:27:53.510 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model Quantiles_model_1697826262527_410\n",
      "10-20 18:27:53.521 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model Quantiles_model_1697826262527_410\n",
      "10-20 18:27:53.562 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_411\n",
      "10-20 18:27:53.575 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_411\n",
      "10-20 18:27:53.579 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Building main model.\n",
      "10-20 18:27:53.579 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Remaining time for main model (ms): 0\n",
      "10-20 18:27:53.579 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Building H2O XGBoost model with these parameters:\n",
      "10-20 18:27:53.580 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: {\"_train\":{\"name\":\"AutoML_1_20231020_182658_training_py_9_sid_88b4\",\"type\":\"Key\"},\"_valid\":null,\"_nfolds\":5,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":44,\"_fold_assignment\":\"Modulo\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":null,\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":false,\"_cv_fold\":-1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":0,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_quiet_mode\":true,\"_ntrees\":43,\"_n_estimators\":0,\"_max_depth\":10,\"_min_rows\":5.0,\"_min_child_weight\":1.0,\"_learn_rate\":0.3,\"_eta\":0.3,\"_learn_rate_annealing\":1.0,\"_sample_rate\":0.6,\"_subsample\":1.0,\"_col_sample_rate\":0.8,\"_colsample_bylevel\":1.0,\"_colsample_bynode\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_colsample_bytree\":1.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null,\"_max_abs_leafnode_pred\":0.0,\"_max_delta_step\":0.0,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_min_split_improvement\":0.0,\"_gamma\":0.0,\"_nthread\":-1,\"_save_matrix_directory\":null,\"_build_tree_one_node\":false,\"_max_bins\":256,\"_max_leaves\":0,\"_tree_method\":\"auto\",\"_grow_policy\":\"depthwise\",\"_booster\":\"gbtree\",\"_dmatrix_type\":\"auto\",\"_reg_lambda\":1.0,\"_reg_alpha\":0.0,\"_scale_pos_weight\":1.0,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_sample_type\":\"uniform\",\"_normalize_type\":\"tree\",\"_rate_drop\":0.0,\"_one_drop\":false,\"_skip_drop\":0.0,\"_gpu_id\":null,\"_backend\":\"auto\",\"_eval_metric\":null,\"_score_eval_metric_only\":false}\n",
      "10-20 18:27:53.580 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:53.587 172.17.0.2:54321      22766      FJ-3-3  WARN water.default: _stopping_metric: Stopping metric is ignored for _stopping_rounds=0.\n",
      "10-20 18:27:53.587 172.17.0.2:54321      22766      FJ-3-3  WARN water.default: _stopping_tolerance: Stopping tolerance is ignored for _stopping_rounds=0.\n",
      "10-20 18:27:53.595 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: No GPU (gpu_id: null) found. Using CPU backend.\n",
      "10-20 18:27:53.595 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model XGBoost_2_AutoML_1_20231020_182658\n",
      "10-20 18:27:53.595 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: fill ratio: 0.10401813763211365\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Need to score validation frame by XGBoost native backend: false\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: Using CPU backend.\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: Using exact tree method.\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: XGBoost Parameters:\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  colsample_bytree = 0.8\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  silent = true\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  tree_method = exact\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  seed = 44\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  max_depth = 10\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  booster = gbtree\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  nround = 43\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  objective = binary:logistic\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  lambda = 1.0\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  eta = 0.3\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  grow_policy = depthwise\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  nthread = 4\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  alpha = 0.0\n",
      "10-20 18:27:53.596 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  subsample = 0.6\n",
      "10-20 18:27:53.597 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  colsample_bylevel = 0.8\n",
      "10-20 18:27:53.597 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  max_delta_step = 0.0\n",
      "10-20 18:27:53.597 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  min_child_weight = 5.0\n",
      "10-20 18:27:53.597 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel:  gamma = 0.0\n",
      "10-20 18:27:53.597 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoostModel: \n",
      "10-20 18:27:53.613 172.17.0.2:54321      22766  020_182658  INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=438\n",
      "10-20 18:27:53.618 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_412\n",
      "10-20 18:27:53.619 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_412\n",
      "10-20 18:27:53.622 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.25\n",
      " RMSE: 0.5\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24080956\n",
      " logloss: 0.6931472\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.5\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  24720  1.0000  24,720 / 24,720\n",
      "     1  0   7841  0.0000        0 / 7,841\n",
      "Totals  0  32561  0.7592  24,720 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 50.00 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.500000  1.000000         1.000000       0.240810  0.500000                  0.240810          0.500000      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               0\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      "\n",
      "10-20 18:27:53.660 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 1. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:53.660) \n",
      "10-20 18:27:53.696 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 2. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:53.696) \n",
      "10-20 18:27:53.734 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 3. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:53.734) \n",
      "10-20 18:27:53.773 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 4. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:53.773) \n",
      "10-20 18:27:53.813 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 5. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:53.813) \n",
      "10-20 18:27:53.848 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_413\n",
      "10-20 18:27:53.864 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_413\n",
      "10-20 18:27:53.866 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.10050318\n",
      " RMSE: 0.31702235\n",
      " AUC: 0.92366016\n",
      " pr_auc: 0.820731\n",
      " logloss: 0.34409085\n",
      " mean_per_class_error: 0.17351387\n",
      " default threshold: 0.3794315755367279\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22100  2620  0.1060  2,620 / 24,720\n",
      "     1   1890  5951  0.2410   1,890 / 7,841\n",
      "Totals  23990  8571  0.1385  4,510 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 29.17 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01114831         0.872958  4.129779         4.129779       0.994490  0.883691                  0.994490          0.883691      0.046040                 0.046040  312.977944       312.977944            0.045959\n",
      "      2                0.02020822         0.860379  4.152659         4.140037       1.000000  0.865984                  0.996960          0.875752      0.037623                 0.083663  315.265910       314.003704            0.083582\n",
      "      3                0.03015878         0.834948  4.139842         4.139973       0.996914  0.847167                  0.996945          0.866321      0.041194                 0.124857  313.984225       313.997277            0.124735\n",
      "      4                0.04115353         0.813144  4.117860         4.134065       0.991620  0.820758                  0.995522          0.854148      0.045275                 0.170131  311.786028       313.406510            0.169889\n",
      "      5                0.05002918         0.787858  4.037707         4.116970       0.972318  0.802398                  0.991406          0.844967      0.035837                 0.205969  303.770660       311.697019            0.205402\n",
      "      6                0.10125610         0.668159  3.622373         3.866747       0.872302  0.723107                  0.931150          0.783316      0.185563                 0.391532  262.237350       286.674657            0.382349\n",
      "      7                0.15070176         0.562115  2.909441         3.552652       0.700621  0.613344                  0.855513          0.727548      0.143859                 0.535391  190.944066       255.265191            0.506710\n",
      "      8                0.20017813         0.448941  2.172993         3.211653       0.523277  0.503458                  0.773397          0.672162      0.107512                 0.642903  117.299294       221.165304            0.583154\n",
      "      9                0.32044470         0.357125  1.575805         2.597700       0.379469  0.388610                  0.625551          0.565741      0.189517                 0.832419   57.580476       159.770040            0.674369\n",
      "     10                0.40001843         0.278697  0.894320         2.258855       0.215361  0.313848                  0.543954          0.515633      0.071164                 0.903584  -10.567975       125.885526            0.663292\n",
      "     11                0.50004607         0.200892  0.567373         1.920496       0.136629  0.236482                  0.462474          0.459793      0.056753                 0.960337  -43.262717        92.049644            0.606291\n",
      "     12                0.60001228         0.141745  0.246225         1.641551       0.059293  0.166882                  0.395301          0.410992      0.024614                 0.984951  -75.377474        64.155122            0.507038\n",
      "     13                0.70492307         0.115812  0.088742         1.410453       0.021370  0.125533                  0.339651          0.368508      0.009310                 0.994261  -91.125758        41.045311            0.381114\n",
      "     14                0.80501213         0.109879  0.035678         1.239524       0.008592  0.113873                  0.298489          0.336849      0.003571                 0.997832  -96.432205        23.952407            0.253981\n",
      "     15                0.99910936         0.105150  0.010513         1.000764       0.002532  0.105499                  0.240993          0.291904      0.002041                 0.999872  -98.948694         0.076378            0.001005\n",
      "     16                1.00000000         0.104796  0.143195         1.000000       0.034483  0.104796                  0.240810          0.291738      0.000128                 1.000000  -85.680486         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "marital_status. Married-civ-spouse         4997.172852          1.000000   0.314904\n",
      "                      capital_gain         2996.000732          0.599539   0.188797\n",
      "                      capital_loss         1121.020142          0.224331   0.070643\n",
      "                               age          944.505188          0.189008   0.059519\n",
      "     marital_status. Never-married          842.223450          0.168540   0.053074\n",
      "              education. Bachelors          702.467957          0.140573   0.044267\n",
      "       occupation. Exec-managerial          655.809143          0.131236   0.041327\n",
      "                    hours_per_week          654.171509          0.130908   0.041224\n",
      "        occupation. Prof-specialty          652.378296          0.130549   0.041111\n",
      "          marital_status. Divorced          282.622040          0.056556   0.017810\n",
      "---\n",
      "                       race. White           12.404493          0.002482   0.000782\n",
      "                         sex. Male            9.085772          0.001818   0.000573\n",
      "           workclass. Self-emp-inc            8.738655          0.001749   0.000551\n",
      "              education. Assoc-voc            8.055565          0.001612   0.000508\n",
      "      occupation. Transport-moving            5.795803          0.001160   0.000365\n",
      "     occupation. Handlers-cleaners            5.112198          0.001023   0.000322\n",
      "          occupation. Craft-repair            3.546286          0.000710   0.000223\n",
      "          occupation. Adm-clerical            2.863495          0.000573   0.000180\n",
      "          race. Asian-Pac-Islander            1.317688          0.000264   0.000083\n",
      "              workclass. Local-gov            0.962058          0.000193   0.000061\n",
      "Variable Importances - Cover:\n",
      "                          Variable Relative Importance Scaled Importance Percentage\n",
      "                               age        24353.367188          1.000000   0.143172\n",
      "                    hours_per_week        19175.103516          0.787370   0.112730\n",
      "marital_status. Married-civ-spouse        16291.193359          0.668950   0.095775\n",
      "                      capital_loss        15446.536133          0.634267   0.090810\n",
      "                      capital_gain        13953.951172          0.572978   0.082035\n",
      "              education. Bachelors        10349.507813          0.424972   0.060844\n",
      "        occupation. Prof-specialty         8840.917969          0.363027   0.051975\n",
      "       occupation. Exec-managerial         7672.046387          0.315030   0.045104\n",
      "                education. Masters         5772.160156          0.237017   0.033934\n",
      "     marital_status. Never-married         4828.817871          0.198281   0.028388\n",
      "---\n",
      "                workclass. Private          505.624695          0.020762   0.002973\n",
      "                       race. White          486.406647          0.019973   0.002860\n",
      "          race. Asian-Pac-Islander          325.724457          0.013375   0.001915\n",
      "             relationship. Husband          320.460114          0.013159   0.001884\n",
      "              education. Assoc-voc          285.136353          0.011708   0.001676\n",
      "     occupation. Handlers-cleaners          228.046097          0.009364   0.001341\n",
      "          occupation. Craft-repair          200.474152          0.008232   0.001179\n",
      "          occupation. Adm-clerical          127.276100          0.005226   0.000748\n",
      "      occupation. Transport-moving           70.082146          0.002878   0.000412\n",
      "              workclass. Local-gov           25.396742          0.001043   0.000149\n",
      "Variable Importances - Frequency:\n",
      "                     Variable Relative Importance Scaled Importance Percentage\n",
      "                          age          105.000000          1.000000   0.202312\n",
      "                       fnlwgt           94.000000          0.895238   0.181118\n",
      "               hours_per_week           66.000000          0.628571   0.127168\n",
      "                 capital_loss           30.000000          0.285714   0.057803\n",
      "           education. Masters           17.000000          0.161905   0.032755\n",
      "           education. HS-grad           15.000000          0.142857   0.028902\n",
      "                  sex. Female           15.000000          0.142857   0.028902\n",
      "         education. Bachelors           14.000000          0.133333   0.026975\n",
      "  occupation. Exec-managerial           13.000000          0.123810   0.025048\n",
      "                 capital_gain           12.000000          0.114286   0.023121\n",
      "---\n",
      "     occupation. Craft-repair            2.000000          0.019048   0.003854\n",
      "      marital_status. Widowed            1.000000          0.009524   0.001927\n",
      "occupation. Handlers-cleaners            1.000000          0.009524   0.001927\n",
      "     occupation. Adm-clerical            1.000000          0.009524   0.001927\n",
      "         education. Assoc-voc            1.000000          0.009524   0.001927\n",
      "    marital_status. Separated            1.000000          0.009524   0.001927\n",
      " occupation. Transport-moving            1.000000          0.009524   0.001927\n",
      "     race. Asian-Pac-Islander            1.000000          0.009524   0.001927\n",
      "               education. 9th            1.000000          0.009524   0.001927\n",
      "         workclass. Local-gov            1.000000          0.009524   0.001927\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "               5\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      "\n",
      "10-20 18:27:53.901 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 6. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:53.900) \n",
      "10-20 18:27:53.944 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 7. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:53.944) \n",
      "10-20 18:27:53.980 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 8. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:53.979) \n",
      "10-20 18:27:54.015 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 9. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:54.015) \n",
      "10-20 18:27:54.057 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:54.059 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 10. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:54.059) \n",
      "10-20 18:27:54.089 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_414\n",
      "█10-20 18:27:54.102 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_414\n",
      "10-20 18:27:54.105 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08748201\n",
      " RMSE: 0.2957736\n",
      " AUC: 0.9329283\n",
      " pr_auc: 0.83965963\n",
      " logloss: 0.2855052\n",
      " mean_per_class_error: 0.16142863\n",
      " default threshold: 0.3752673268318176\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22171  2549  0.1031  2,549 / 24,720\n",
      "     1   1723  6118  0.2197   1,723 / 7,841\n",
      "Totals  23894  8667  0.1312  4,272 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 25.17 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.967796  4.152659         4.152659       1.000000  0.972046                  1.000000          0.972046      0.041576                 0.041576   315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.957340  4.152659         4.152659       1.000000  0.961991                  1.000000          0.967019      0.041576                 0.083153   315.265910       315.265910            0.083153\n",
      "      3                0.03009736         0.946055  4.152659         4.152659       1.000000  0.950570                  1.000000          0.961514      0.041831                 0.124984   315.265910       315.265910            0.124984\n",
      "      4                0.04035503         0.932569  4.140226         4.149499       0.997006  0.939632                  0.999239          0.955952      0.042469                 0.167453   314.022599       314.949878            0.167413\n",
      "      5                0.05005989         0.914511  4.139518         4.147564       0.996835  0.923467                  0.998773          0.949654      0.040173                 0.207627   313.951777       314.756381            0.207546\n",
      "      6                0.10005835         0.707341  3.698621         3.923230       0.890663  0.795052                  0.944751          0.872400      0.184925                 0.392552   269.862143       292.323042            0.385270\n",
      "      7                0.15002610         0.582085  3.037286         3.628157       0.731407  0.643203                  0.873695          0.796064      0.151766                 0.544318   203.728600       262.815743            0.519359\n",
      "      8                0.20002457         0.455769  2.275290         3.289992       0.547912  0.515421                  0.792262          0.725914      0.113761                 0.658079   127.528988       228.999247            0.603346\n",
      "      9                0.30051288         0.337487  1.651164         2.741986       0.397616  0.390025                  0.660296          0.613596      0.165923                 0.824002    65.116427       174.198574            0.689536\n",
      "     10                0.40050981         0.214875  0.988425         2.304167       0.238022  0.272300                  0.554865          0.528384      0.098839                 0.922841    -1.157531       130.416695            0.688011\n",
      "     11                0.50001536         0.125914  0.460125         1.937193       0.110802  0.167899                  0.466495          0.456645      0.045785                 0.968626   -53.987512        93.719341            0.617251\n",
      "     12                0.60001228         0.064723  0.181105         1.644527       0.043612  0.092217                  0.396018          0.395910      0.018110                 0.986736   -81.889509        64.452697            0.509390\n",
      "     13                0.70000921         0.041164  0.094379         1.423087       0.022727  0.050245                  0.342693          0.346532      0.009438                 0.996174   -90.562138        42.308692            0.390106\n",
      "     14                0.80000614         0.032675  0.031885         1.249193       0.007678  0.036142                  0.300818          0.307734      0.003188                 0.999362   -96.811533        24.919332            0.262590\n",
      "     15                0.90006449         0.026503  0.006373         1.111031       0.001535  0.029788                  0.267547          0.276836      0.000638                 1.000000   -99.362698        11.103149            0.131634\n",
      "     16                1.00000000         0.024261  0.000000         1.000000       0.000000  0.024896                  0.240810          0.251658      0.000000                 1.000000  -100.000000         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5776.862793          1.000000   0.290074\n",
      "                         capital_gain         4145.891602          0.717672   0.208178\n",
      "                                  age         1400.037109          0.242352   0.070300\n",
      "                         capital_loss         1343.118530          0.232500   0.067442\n",
      "                       hours_per_week          870.063965          0.150612   0.043689\n",
      "        marital_status. Never-married          860.952209          0.149035   0.043231\n",
      "          occupation. Exec-managerial          731.073242          0.126552   0.036709\n",
      "                 education. Bachelors          728.181152          0.126051   0.036564\n",
      "           occupation. Prof-specialty          719.938232          0.124624   0.036150\n",
      "                               fnlwgt          396.916168          0.068708   0.019930\n",
      "---\n",
      "             occupation. Craft-repair            8.587360          0.001487   0.000431\n",
      "                 education. Assoc-voc            8.055565          0.001394   0.000404\n",
      "                 workclass. Local-gov            7.346596          0.001272   0.000369\n",
      "         occupation. Transport-moving            5.795803          0.001003   0.000291\n",
      "marital_status. Married-spouse-absent            4.704323          0.000814   0.000236\n",
      "                          race. Black            4.681392          0.000810   0.000235\n",
      "                 workclass. State-gov            3.615422          0.000626   0.000182\n",
      "                education. Assoc-acdm            3.451469          0.000597   0.000173\n",
      "             race. Asian-Pac-Islander            1.317688          0.000228   0.000066\n",
      "                        occupation.NA            0.568393          0.000098   0.000029\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        42626.222656          1.000000   0.147891\n",
      "                                  age        36772.113281          0.862664   0.127580\n",
      "   marital_status. Married-civ-spouse        26726.898438          0.627006   0.092729\n",
      "                       hours_per_week        26626.451172          0.624650   0.092380\n",
      "                         capital_loss        22816.521484          0.535270   0.079162\n",
      "          occupation. Exec-managerial        12033.024414          0.282292   0.041748\n",
      "           occupation. Prof-specialty        11256.817383          0.264082   0.039055\n",
      "                 education. Bachelors        10920.424805          0.256190   0.037888\n",
      "                               fnlwgt         8678.648438          0.203599   0.030110\n",
      "                   education. Masters         6192.139648          0.145266   0.021484\n",
      "---\n",
      "             occupation. Craft-repair          376.535522          0.008833   0.001306\n",
      "             race. Asian-Pac-Islander          325.724457          0.007641   0.001130\n",
      "                 workclass. Local-gov          305.967560          0.007178   0.001062\n",
      "                 education. Assoc-voc          285.136353          0.006689   0.000989\n",
      "                          race. Black          131.646164          0.003088   0.000457\n",
      "                education. Assoc-acdm          125.953941          0.002955   0.000437\n",
      "marital_status. Married-spouse-absent           72.840508          0.001709   0.000253\n",
      "         occupation. Transport-moving           70.082146          0.001644   0.000243\n",
      "                 workclass. State-gov           66.276764          0.001555   0.000230\n",
      "                        occupation.NA           39.904648          0.000936   0.000138\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          159.000000          1.000000   0.176667\n",
      "                                  age          156.000000          0.981132   0.173333\n",
      "                       hours_per_week          108.000000          0.679245   0.120000\n",
      "                         capital_gain           45.000000          0.283019   0.050000\n",
      "                         capital_loss           43.000000          0.270440   0.047778\n",
      "                   education. HS-grad           31.000000          0.194969   0.034444\n",
      "                   workclass. Private           25.000000          0.157233   0.027778\n",
      "                          sex. Female           24.000000          0.150943   0.026667\n",
      "                 education. Bachelors           24.000000          0.150943   0.026667\n",
      "          occupation. Exec-managerial           20.000000          0.125786   0.022222\n",
      "---\n",
      "              workclass. Self-emp-inc            2.000000          0.012579   0.002222\n",
      "marital_status. Married-spouse-absent            1.000000          0.006289   0.001111\n",
      "                 education. Assoc-voc            1.000000          0.006289   0.001111\n",
      "                      education. 10th            1.000000          0.006289   0.001111\n",
      "                        occupation.NA            1.000000          0.006289   0.001111\n",
      "             race. Asian-Pac-Islander            1.000000          0.006289   0.001111\n",
      "                 workclass. State-gov            1.000000          0.006289   0.001111\n",
      "                education. Assoc-acdm            1.000000          0.006289   0.001111\n",
      "         occupation. Transport-moving            1.000000          0.006289   0.001111\n",
      "                   education. 5th-6th            1.000000          0.006289   0.001111\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              10\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      "\n",
      "10-20 18:27:54.140 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 11. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:54.140) \n",
      "10-20 18:27:54.178 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 12. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:54.178) \n",
      "10-20 18:27:54.210 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 13. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:54.210) \n",
      "10-20 18:27:54.239 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 14. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:54.239) \n",
      "10-20 18:27:54.267 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 15. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:54.267) \n",
      "10-20 18:27:54.298 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_415\n",
      "10-20 18:27:54.311 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_415\n",
      "10-20 18:27:54.314 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08404366\n",
      " RMSE: 0.28990284\n",
      " AUC: 0.9371328\n",
      " pr_auc: 0.847658\n",
      " logloss: 0.26950556\n",
      " mean_per_class_error: 0.1564682\n",
      " default threshold: 0.37084609270095825\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22246  2474  0.1001  2,474 / 24,720\n",
      "     1   1669  6172  0.2129   1,669 / 7,841\n",
      "Totals  23915  8646  0.1272  4,143 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.39 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.987204  4.152659         4.152659       1.000000  0.989117                  1.000000          0.989117      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02020822         0.981544  4.152659         4.152659       1.000000  0.984494                  1.000000          0.986784      0.042342                 0.083918  315.265910       315.265910            0.083918\n",
      "      3                0.03006664         0.972682  4.152659         4.152659       1.000000  0.977204                  1.000000          0.983643      0.040939                 0.124857  315.265910       315.265910            0.124857\n",
      "      4                0.04001720         0.954704  4.139842         4.149472       0.996914  0.964079                  0.999233          0.978778      0.041194                 0.166050  313.984225       314.947210            0.166010\n",
      "      5                0.05002918         0.934357  4.127183         4.145011       0.993865  0.945419                  0.998158          0.972102      0.041321                 0.207372  312.718266       314.501148            0.207250\n",
      "      6                0.10002764         0.732252  3.770043         3.957585       0.907862  0.824737                  0.953024          0.898442      0.188496                 0.395868  277.004309       295.758485            0.389679\n",
      "      7                0.15008753         0.600094  3.008767         3.641118       0.724540  0.664363                  0.876816          0.820368      0.150619                 0.546486  200.876711       264.111812            0.522134\n",
      "      8                0.20002457         0.478278  2.382799         3.326973       0.573801  0.534961                  0.801167          0.749115      0.118990                 0.665476  138.279886       232.697301            0.613090\n",
      "      9                0.30011363         0.322009  1.667944         2.773681       0.401657  0.394666                  0.667929          0.630905      0.166943                 0.832419   66.794439       177.368051            0.701149\n",
      "     10                0.40001843         0.192102  0.976571         2.324851       0.235168  0.255537                  0.559846          0.537156      0.097564                 0.929983   -2.342938       132.485145            0.698066\n",
      "     11                0.50001536         0.100452  0.420878         1.944080       0.101351  0.143400                  0.468153          0.458410      0.042086                 0.972070  -57.912239        94.408007            0.621787\n",
      "     12                0.60001228         0.046571  0.173453         1.648991       0.041769  0.070670                  0.397093          0.393790      0.017345                 0.989415  -82.654741        64.899060            0.512918\n",
      "     13                0.70000921         0.025769  0.073972         1.423998       0.017813  0.034502                  0.342912          0.342465      0.007397                 0.996812  -92.602757        42.399787            0.390946\n",
      "     14                0.80000614         0.016939  0.026783         1.249353       0.006450  0.021019                  0.300856          0.302286      0.002678                 0.999490  -97.321688        24.935273            0.262758\n",
      "     15                0.90120082         0.009604  0.003781         1.109489       0.000910  0.013131                  0.267176          0.269817      0.000383                 0.999872  -99.621913        10.948907            0.129970\n",
      "     16                1.00000000         0.005959  0.001291         1.000000       0.000311  0.007109                  0.240810          0.243862      0.000128                 1.000000  -99.870915         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5800.445801          1.000000   0.271226\n",
      "                         capital_gain         4354.676758          0.750749   0.203622\n",
      "                                  age         1632.619995          0.281465   0.076340\n",
      "                         capital_loss         1427.801270          0.246154   0.066763\n",
      "                       hours_per_week          958.966187          0.165326   0.044841\n",
      "        marital_status. Never-married          919.895142          0.158590   0.043014\n",
      "           occupation. Prof-specialty          747.183105          0.128815   0.034938\n",
      "                 education. Bachelors          739.893616          0.127558   0.034597\n",
      "          occupation. Exec-managerial          731.073242          0.126037   0.034185\n",
      "                               fnlwgt          597.931458          0.103084   0.027959\n",
      "---\n",
      "         occupation. Transport-moving           10.637457          0.001834   0.000497\n",
      "          native_country. Philippines            9.250633          0.001595   0.000433\n",
      "         relationship. Other-relative            8.135685          0.001403   0.000380\n",
      "                 education. Assoc-voc            8.055565          0.001389   0.000377\n",
      "marital_status. Married-spouse-absent            4.704323          0.000811   0.000220\n",
      "                 workclass. State-gov            3.615422          0.000623   0.000169\n",
      "                education. Assoc-acdm            3.451469          0.000595   0.000161\n",
      "                         workclass.NA            2.702182          0.000466   0.000126\n",
      "             race. Asian-Pac-Islander            1.317688          0.000227   0.000062\n",
      "                        occupation.NA            0.568393          0.000098   0.000027\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        59574.359375          1.000000   0.154198\n",
      "                                  age        45671.921875          0.766637   0.118214\n",
      "                       hours_per_week        34461.699219          0.578465   0.089198\n",
      "                         capital_loss        29454.953125          0.494423   0.076239\n",
      "   marital_status. Married-civ-spouse        28757.988281          0.482724   0.074435\n",
      "                               fnlwgt        16412.125000          0.275490   0.042480\n",
      "          occupation. Exec-managerial        12033.024414          0.201983   0.031145\n",
      "           occupation. Prof-specialty        11926.952148          0.200203   0.030871\n",
      "                 education. Bachelors        11179.335938          0.187653   0.028936\n",
      "                   education. Masters         8466.502930          0.142117   0.021914\n",
      "---\n",
      "                 workclass. Local-gov          438.865143          0.007367   0.001136\n",
      "                          race. Black          339.761322          0.005703   0.000879\n",
      "             race. Asian-Pac-Islander          325.724457          0.005468   0.000843\n",
      "                 education. Assoc-voc          285.136353          0.004786   0.000738\n",
      "                education. Assoc-acdm          125.953941          0.002114   0.000326\n",
      "                         workclass.NA          116.242905          0.001951   0.000301\n",
      "         occupation. Transport-moving          111.226440          0.001867   0.000288\n",
      "marital_status. Married-spouse-absent           72.840508          0.001223   0.000189\n",
      "                 workclass. State-gov           66.276764          0.001113   0.000172\n",
      "                        occupation.NA           39.904648          0.000670   0.000103\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          236.000000          1.000000   0.203098\n",
      "                                  age          206.000000          0.872881   0.177281\n",
      "                       hours_per_week          132.000000          0.559322   0.113597\n",
      "                         capital_gain           57.000000          0.241525   0.049053\n",
      "                         capital_loss           52.000000          0.220339   0.044750\n",
      "                   education. HS-grad           32.000000          0.135593   0.027539\n",
      "                   workclass. Private           30.000000          0.127119   0.025818\n",
      "                          sex. Female           29.000000          0.122881   0.024957\n",
      "                 education. Bachelors           28.000000          0.118644   0.024096\n",
      "           occupation. Prof-specialty           25.000000          0.105932   0.021515\n",
      "---\n",
      "         occupation. Transport-moving            2.000000          0.008475   0.001721\n",
      "marital_status. Married-spouse-absent            1.000000          0.004237   0.000861\n",
      "                 education. Assoc-voc            1.000000          0.004237   0.000861\n",
      "         relationship. Other-relative            1.000000          0.004237   0.000861\n",
      "                        occupation.NA            1.000000          0.004237   0.000861\n",
      "                         workclass.NA            1.000000          0.004237   0.000861\n",
      "             race. Asian-Pac-Islander            1.000000          0.004237   0.000861\n",
      "                 workclass. State-gov            1.000000          0.004237   0.000861\n",
      "          native_country. Philippines            1.000000          0.004237   0.000861\n",
      "                education. Assoc-acdm            1.000000          0.004237   0.000861\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              15\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      "\n",
      "10-20 18:27:54.345 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 16. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:54.344) \n",
      "10-20 18:27:54.376 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 17. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:54.376) \n",
      "10-20 18:27:54.404 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 18. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:54.404) \n",
      "10-20 18:27:54.431 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 19. tree was built in 00:00:00.026 (Wall: 20-Oct 18:27:54.431) \n",
      "10-20 18:27:54.462 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 20. tree was built in 00:00:00.031 (Wall: 20-Oct 18:27:54.462) \n",
      "10-20 18:27:54.501 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_416\n",
      "10-20 18:27:54.519 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_416\n",
      "10-20 18:27:54.522 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08222058\n",
      " RMSE: 0.28674132\n",
      " AUC: 0.939538\n",
      " pr_auc: 0.8519841\n",
      " logloss: 0.26175007\n",
      " mean_per_class_error: 0.15005396\n",
      " default threshold: 0.3573343753814697\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22065  2655  0.1074  2,655 / 24,720\n",
      "     1   1511  6330  0.1927   1,511 / 7,841\n",
      "Totals  23576  8985  0.1279  4,166 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.20 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.993425  4.152659         4.152659       1.000000  0.994539                  1.000000          0.994539      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.990167  4.152659         4.152659       1.000000  0.992009                  1.000000          0.993274      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.984452  4.152659         4.152659       1.000000  0.987645                  1.000000          0.991402      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.968909  4.152659         4.152659       1.000000  0.977423                  1.000000          0.987904      0.041576                 0.166178  315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.951088  4.114444         4.145011       0.990798  0.960736                  0.998158          0.982467      0.041194                 0.207372  311.444445       314.501148            0.207250\n",
      "      6                0.10002764         0.755203  3.782797         3.963960       0.910934  0.847275                  0.954559          0.914892      0.189134                 0.396506  278.279696       296.395982            0.390518\n",
      "      7                0.15002610         0.620403  3.045623         3.657910       0.733415  0.686847                  0.880860          0.838893      0.152276                 0.548782  204.562344       265.791036            0.525238\n",
      "      8                0.20002457         0.491061  2.451293         3.356302       0.590295  0.552188                  0.808230          0.767227      0.122561                 0.671343  145.129324       235.630240            0.620817\n",
      "      9                0.30002150         0.319338  1.665655         2.792811       0.401106  0.397819                  0.672536          0.644104      0.166560                 0.837903   66.565503       179.281096            0.708494\n",
      "     10                0.40001843         0.178712  0.962917         2.335373       0.231880  0.245405                  0.562380          0.544437      0.096289                 0.934192   -3.708304       133.537258            0.703610\n",
      "     11                0.50001536         0.088145  0.404298         1.949181       0.097359  0.129903                  0.469381          0.461535      0.040429                 0.974621  -59.570242        94.918131            0.625146\n",
      "     12                0.60001228         0.038349  0.165800         1.651966       0.039926  0.060224                  0.397809          0.394653      0.016580                 0.991200  -83.419973        65.196635            0.515270\n",
      "     13                0.70000921         0.019878  0.063769         1.425091       0.015356  0.027514                  0.343176          0.342207      0.006377                 0.997577  -93.623066        42.509101            0.391954\n",
      "     14                0.80000614         0.010695  0.017855         1.249193       0.004300  0.015067                  0.300818          0.301316      0.001785                 0.999362  -98.214459        24.919332            0.262590\n",
      "     15                0.90018734         0.004319  0.005092         1.110738       0.001226  0.007168                  0.267476          0.268581      0.000510                 0.999872  -99.490784        11.073820            0.131305\n",
      "     16                1.00000000         0.001550  0.001278         1.000000       0.000308  0.002775                  0.240810          0.242050      0.000128                 1.000000  -99.872226         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5807.592285          1.000000   0.261985\n",
      "                         capital_gain         4437.973145          0.764167   0.200201\n",
      "                                  age         1716.676758          0.295592   0.077441\n",
      "                         capital_loss         1498.656250          0.258051   0.067606\n",
      "                       hours_per_week         1013.645752          0.174538   0.045726\n",
      "        marital_status. Never-married          941.170654          0.162059   0.042457\n",
      "           occupation. Prof-specialty          758.825989          0.130661   0.034231\n",
      "                 education. Bachelors          752.585693          0.129587   0.033950\n",
      "          occupation. Exec-managerial          743.078735          0.127950   0.033521\n",
      "                               fnlwgt          680.525330          0.117179   0.030699\n",
      "---\n",
      "         relationship. Other-relative            8.135685          0.001401   0.000367\n",
      "             race. Amer-Indian-Eskimo            7.941867          0.001367   0.000358\n",
      "                   education. 1st-4th            7.691736          0.001324   0.000347\n",
      "                         workclass.NA            6.943602          0.001196   0.000313\n",
      "               native_country. Canada            4.888330          0.000842   0.000221\n",
      "             race. Asian-Pac-Islander            4.789636          0.000825   0.000216\n",
      "marital_status. Married-spouse-absent            4.704323          0.000810   0.000212\n",
      "                 workclass. State-gov            3.615422          0.000623   0.000163\n",
      "                education. Assoc-acdm            3.451469          0.000594   0.000156\n",
      "                        occupation.NA            0.568393          0.000098   0.000026\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        71338.718750          1.000000   0.149512\n",
      "                                  age        52346.765625          0.733778   0.109708\n",
      "                         capital_loss        39163.246094          0.548976   0.082078\n",
      "                       hours_per_week        38004.308594          0.532730   0.079649\n",
      "   marital_status. Married-civ-spouse        30550.410156          0.428244   0.064028\n",
      "                               fnlwgt        19266.033203          0.270064   0.040378\n",
      "          occupation. Exec-managerial        13534.380859          0.189720   0.028365\n",
      "           occupation. Prof-specialty        12109.584961          0.169748   0.025379\n",
      "                 education. Bachelors        11624.970703          0.162955   0.024364\n",
      "        marital_status. Never-married        11493.982422          0.161118   0.024089\n",
      "---\n",
      "             occupation. Adm-clerical         1208.061279          0.016934   0.002532\n",
      "              relationship. Unmarried          916.786926          0.012851   0.001921\n",
      "                 workclass. Local-gov          871.278992          0.012213   0.001826\n",
      "                 education. Assoc-voc          849.996216          0.011915   0.001781\n",
      "             race. Asian-Pac-Islander          731.437195          0.010253   0.001533\n",
      "             occupation. Craft-repair          456.967987          0.006406   0.000958\n",
      "                education. Assoc-acdm          125.953941          0.001766   0.000264\n",
      "marital_status. Married-spouse-absent           72.840508          0.001021   0.000153\n",
      "                 workclass. State-gov           66.276764          0.000929   0.000139\n",
      "                        occupation.NA           39.904648          0.000559   0.000084\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          265.000000          1.000000   0.193008\n",
      "                                  age          232.000000          0.875472   0.168973\n",
      "                       hours_per_week          158.000000          0.596226   0.115076\n",
      "                         capital_gain           67.000000          0.252830   0.048798\n",
      "                         capital_loss           60.000000          0.226415   0.043700\n",
      "                   education. HS-grad           39.000000          0.147170   0.028405\n",
      "                   workclass. Private           36.000000          0.135849   0.026220\n",
      "                          sex. Female           34.000000          0.128302   0.024763\n",
      "           occupation. Prof-specialty           30.000000          0.113208   0.021850\n",
      "                 education. Bachelors           30.000000          0.113208   0.021850\n",
      "---\n",
      "             race. Asian-Pac-Islander            2.000000          0.007547   0.001457\n",
      "               native_country. Canada            1.000000          0.003774   0.000728\n",
      "marital_status. Married-spouse-absent            1.000000          0.003774   0.000728\n",
      "         relationship. Other-relative            1.000000          0.003774   0.000728\n",
      "                        occupation.NA            1.000000          0.003774   0.000728\n",
      "                   education. 1st-4th            1.000000          0.003774   0.000728\n",
      "                 workclass. State-gov            1.000000          0.003774   0.000728\n",
      "             race. Amer-Indian-Eskimo            1.000000          0.003774   0.000728\n",
      "          native_country. Philippines            1.000000          0.003774   0.000728\n",
      "                education. Assoc-acdm            1.000000          0.003774   0.000728\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              20\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      " 2023-10-20 18:27:54 13.615 sec              20       0.28674          0.26175      0.93954         0.85198       4.15266                       0.12794\n",
      "\n",
      "10-20 18:27:54.559 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 21. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:54.559) \n",
      "10-20 18:27:54.588 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 22. tree was built in 00:00:00.028 (Wall: 20-Oct 18:27:54.588) \n",
      "10-20 18:27:54.609 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 23. tree was built in 00:00:00.021 (Wall: 20-Oct 18:27:54.609) \n",
      "10-20 18:27:54.622 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 24. tree was built in 00:00:00.013 (Wall: 20-Oct 18:27:54.622) \n",
      "10-20 18:27:54.640 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 25. tree was built in 00:00:00.018 (Wall: 20-Oct 18:27:54.640) \n",
      "10-20 18:27:54.693 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_417\n",
      "10-20 18:27:54.707 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_417\n",
      "10-20 18:27:54.710 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.08049287\n",
      " RMSE: 0.28371266\n",
      " AUC: 0.9420351\n",
      " pr_auc: 0.8571101\n",
      " logloss: 0.25593525\n",
      " mean_per_class_error: 0.15532407\n",
      " default threshold: 0.39447441697120667\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22580  2140  0.0866  2,140 / 24,720\n",
      "     1   1757  6084  0.2241   1,757 / 7,841\n",
      "Totals  24337  8224  0.1197  3,897 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.15 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.995802  4.152659         4.152659       1.000000  0.996714                  1.000000          0.996714      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.993390  4.152659         4.152659       1.000000  0.994696                  1.000000          0.995705      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.988012  4.152659         4.152659       1.000000  0.991069                  1.000000          0.994163      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.975688  4.152659         4.152659       1.000000  0.982439                  1.000000          0.991230      0.041576                 0.166178  315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.958919  4.127183         4.147561       0.993865  0.968235                  0.998772          0.986628      0.041321                 0.207499  312.718266       314.756068            0.207418\n",
      "      6                0.10008906         0.768241  3.798537         3.972995       0.914724  0.858351                  0.956735          0.922470      0.190154                 0.397653  279.853664       297.299511            0.391949\n",
      "      7                0.15002610         0.632665  3.080017         3.675762       0.741697  0.699564                  0.885159          0.848274      0.153807                 0.551460  208.001653       267.576212            0.528766\n",
      "      8                0.20002457         0.501188  2.538020         3.391370       0.611179  0.566359                  0.816674          0.777807      0.126897                 0.678357  153.801954       239.137014            0.630056\n",
      "      9                0.30002150         0.317598  1.641423         2.808114       0.395270  0.401307                  0.676221          0.652320      0.164137                 0.842495   64.142268       180.811404            0.714542\n",
      "     10                0.40001843         0.169228  0.946337         2.342705       0.227887  0.238714                  0.564146          0.548926      0.094631                 0.937125   -5.366307       134.270549            0.707473\n",
      "     11                0.50001536         0.080084  0.406848         1.955558       0.097973  0.120221                  0.470917          0.463190      0.040684                 0.977809  -59.315164        95.555785            0.629346\n",
      "     12                0.60001228         0.034919  0.141568         1.653242       0.034091  0.054710                  0.398116          0.395114      0.014156                 0.991965  -85.843208        65.324167            0.516278\n",
      "     13                0.70000921         0.017375  0.063769         1.426184       0.015356  0.024770                  0.343439          0.342210      0.006377                 0.998342  -93.623066        42.618415            0.392962\n",
      "     14                0.80000614         0.008515  0.008928         1.249034       0.002150  0.012669                  0.300779          0.301019      0.000893                 0.999235  -99.107229        24.903390            0.262422\n",
      "     15                0.90000307         0.003052  0.006377         1.110966       0.001536  0.005475                  0.267531          0.268182      0.000638                 0.999872  -99.362307        11.096561            0.131547\n",
      "     16                1.00000000         0.000870  0.001275         1.000000       0.000307  0.001839                  0.240810          0.241548      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5811.460938          1.000000   0.253647\n",
      "                         capital_gain         4507.515137          0.775625   0.196735\n",
      "                                  age         1852.554443          0.318776   0.080857\n",
      "                         capital_loss         1534.049194          0.263970   0.066955\n",
      "                       hours_per_week         1054.671143          0.181481   0.046032\n",
      "        marital_status. Never-married          944.157471          0.162465   0.041209\n",
      "                               fnlwgt          874.884155          0.150545   0.038185\n",
      "                 education. Bachelors          767.149658          0.132006   0.033483\n",
      "          occupation. Exec-managerial          759.851379          0.130750   0.033165\n",
      "           occupation. Prof-specialty          758.825989          0.130574   0.033120\n",
      "---\n",
      "                education. Assoc-acdm            9.735489          0.001675   0.000425\n",
      "          native_country. Philippines            9.250633          0.001592   0.000404\n",
      "                         workclass.NA            6.943602          0.001195   0.000303\n",
      "                 workclass. State-gov            6.809789          0.001172   0.000297\n",
      "              native_country. England            6.248845          0.001075   0.000273\n",
      "                      education. 12th            5.691929          0.000979   0.000248\n",
      "               native_country. Canada            4.888330          0.000841   0.000213\n",
      "             race. Asian-Pac-Islander            4.789636          0.000824   0.000209\n",
      "marital_status. Married-spouse-absent            4.704323          0.000809   0.000205\n",
      "                        occupation.NA            0.568393          0.000098   0.000025\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        84232.234375          1.000000   0.149572\n",
      "                                  age        61405.421875          0.729001   0.109038\n",
      "                         capital_loss        46979.582031          0.557739   0.083422\n",
      "                       hours_per_week        40350.664063          0.479041   0.071651\n",
      "   marital_status. Married-civ-spouse        30583.183594          0.363082   0.054307\n",
      "                               fnlwgt        29403.255859          0.349074   0.052212\n",
      "          occupation. Exec-managerial        13864.550781          0.164599   0.024619\n",
      "           occupation. Prof-specialty        12109.584961          0.143764   0.021503\n",
      "                 education. Bachelors        12099.765625          0.143648   0.021486\n",
      "        marital_status. Never-married        12085.840820          0.143482   0.021461\n",
      "---\n",
      "             occupation. Adm-clerical         1269.491455          0.015071   0.002254\n",
      "                 education. Assoc-voc         1199.021973          0.014235   0.002129\n",
      "              relationship. Unmarried          932.760986          0.011074   0.001656\n",
      "                 workclass. Local-gov          871.278992          0.010344   0.001547\n",
      "             race. Asian-Pac-Islander          731.437195          0.008684   0.001299\n",
      "             occupation. Craft-repair          566.850159          0.006730   0.001007\n",
      "                education. Assoc-acdm          281.623077          0.003343   0.000500\n",
      "                 workclass. State-gov          252.311127          0.002995   0.000448\n",
      "marital_status. Married-spouse-absent           72.840508          0.000865   0.000129\n",
      "                        occupation.NA           39.904648          0.000474   0.000071\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          332.000000          1.000000   0.205955\n",
      "                                  age          287.000000          0.864458   0.178040\n",
      "                       hours_per_week          175.000000          0.527108   0.108561\n",
      "                         capital_gain           79.000000          0.237952   0.049007\n",
      "                         capital_loss           67.000000          0.201807   0.041563\n",
      "                   education. HS-grad           43.000000          0.129518   0.026675\n",
      "                   workclass. Private           40.000000          0.120482   0.024814\n",
      "                          sex. Female           38.000000          0.114458   0.023573\n",
      "                 education. Bachelors           37.000000          0.111446   0.022953\n",
      "          occupation. Exec-managerial           30.000000          0.090361   0.018610\n",
      "---\n",
      "             race. Asian-Pac-Islander            2.000000          0.006024   0.001241\n",
      "                 workclass. State-gov            2.000000          0.006024   0.001241\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.006024   0.001241\n",
      "                education. Assoc-acdm            2.000000          0.006024   0.001241\n",
      "               native_country. Canada            1.000000          0.003012   0.000620\n",
      "marital_status. Married-spouse-absent            1.000000          0.003012   0.000620\n",
      "                      education. 12th            1.000000          0.003012   0.000620\n",
      "                        occupation.NA            1.000000          0.003012   0.000620\n",
      "              native_country. England            1.000000          0.003012   0.000620\n",
      "          native_country. Philippines            1.000000          0.003012   0.000620\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              25\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      " 2023-10-20 18:27:54 13.615 sec              20       0.28674          0.26175      0.93954         0.85198       4.15266                       0.12794\n",
      " 2023-10-20 18:27:54 13.793 sec              25       0.28371          0.25594      0.94204         0.85711       4.15266                       0.11968\n",
      "\n",
      "10-20 18:27:54.749 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 26. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:54.749) \n",
      "10-20 18:27:54.778 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 27. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:54.778) \n",
      "10-20 18:27:54.797 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 28. tree was built in 00:00:00.018 (Wall: 20-Oct 18:27:54.797) \n",
      "10-20 18:27:54.824 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 29. tree was built in 00:00:00.027 (Wall: 20-Oct 18:27:54.824) \n",
      "10-20 18:27:54.839 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 30. tree was built in 00:00:00.014 (Wall: 20-Oct 18:27:54.839) \n",
      "10-20 18:27:54.892 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_418\n",
      "10-20 18:27:54.906 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_418\n",
      "10-20 18:27:54.911 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.07832689\n",
      " RMSE: 0.2798694\n",
      " AUC: 0.945251\n",
      " pr_auc: 0.8638935\n",
      " logloss: 0.24959297\n",
      " mean_per_class_error: 0.1528257\n",
      " default threshold: 0.41356512904167175\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22858  1862  0.0753  1,862 / 24,720\n",
      "     1   1806  6035  0.2303   1,806 / 7,841\n",
      "Totals  24664  7897  0.1127  3,668 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.10 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.997241  4.152659         4.152659       1.000000  0.997942                  1.000000          0.997942      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.995201  4.152659         4.152659       1.000000  0.996345                  1.000000          0.997144      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.990317  4.152659         4.152659       1.000000  0.993182                  1.000000          0.995826      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.979242  4.152659         4.152659       1.000000  0.985407                  1.000000          0.993219      0.041576                 0.166178  315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.962119  4.114444         4.145011       0.990798  0.971441                  0.998158          0.988861      0.041194                 0.207372  311.444445       314.501148            0.207250\n",
      "      6                0.10002764         0.778639  3.810855         3.977985       0.917690  0.865690                  0.957937          0.927294      0.190537                 0.397908  281.085546       297.798477            0.392366\n",
      "      7                0.15002610         0.642988  3.140002         3.698714       0.756143  0.710521                  0.890686          0.855051      0.156995                 0.554904  214.000206       269.871438            0.533302\n",
      "      8                0.20002457         0.508042  2.555875         3.413048       0.615479  0.573787                  0.821895          0.784746      0.127790                 0.682694  155.587495       241.304839            0.635768\n",
      "      9                0.30002150         0.309416  1.696264         2.840846       0.408477  0.401712                  0.684103          0.657081      0.169621                 0.852315   69.626431       184.084561            0.727477\n",
      "     10                0.40001843         0.161328  0.888945         2.352908       0.214066  0.232096                  0.566603          0.550843      0.088892                 0.941206  -11.105547       135.290780            0.712849\n",
      "     11                0.50001536         0.076493  0.386442         1.959639       0.093059  0.114965                  0.471900          0.463673      0.038643                 0.979850  -61.355783        95.963883            0.632034\n",
      "     12                0.60001228         0.032692  0.124988         1.653879       0.030098  0.051853                  0.398270          0.395040      0.012498                 0.992348  -87.501210        65.387933            0.516782\n",
      "     13                0.70000921         0.015428  0.057392         1.425820       0.013821  0.022752                  0.343351          0.341858      0.005739                 0.998087  -94.260760        42.581977            0.392626\n",
      "     14                0.80000614         0.007240  0.014029         1.249353       0.003378  0.010999                  0.300856          0.300502      0.001403                 0.999490  -98.597075        24.935273            0.262758\n",
      "     15                0.90000307         0.002259  0.003826         1.110966       0.000921  0.004398                  0.267531          0.267603      0.000383                 0.999872  -99.617384        11.096561            0.131547\n",
      "     16                1.00000000         0.000290  0.001275         1.000000       0.000307  0.001209                  0.240810          0.240964      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5812.690918          1.000000   0.243960\n",
      "                         capital_gain         4528.450195          0.779063   0.190060\n",
      "                                  age         2013.452881          0.346389   0.084505\n",
      "                         capital_loss         1536.728027          0.264375   0.064497\n",
      "                               fnlwgt         1228.748047          0.211391   0.051571\n",
      "                       hours_per_week         1168.958862          0.201105   0.049061\n",
      "        marital_status. Never-married          947.362427          0.162982   0.039761\n",
      "          occupation. Exec-managerial          780.670288          0.134304   0.032765\n",
      "                 education. Bachelors          775.191650          0.133362   0.032535\n",
      "           occupation. Prof-specialty          758.825989          0.130546   0.031848\n",
      "---\n",
      "                         workclass.NA           10.449273          0.001798   0.000439\n",
      "                education. Assoc-acdm            9.735489          0.001675   0.000409\n",
      "                 workclass. State-gov            9.599773          0.001652   0.000403\n",
      "                        occupation.NA            8.650459          0.001488   0.000363\n",
      "               native_country. Canada            7.408252          0.001274   0.000311\n",
      "              native_country. England            6.248845          0.001075   0.000262\n",
      "             race. Asian-Pac-Islander            4.789636          0.000824   0.000201\n",
      "marital_status. Married-spouse-absent            4.704323          0.000809   0.000197\n",
      "                          race. Other            4.060807          0.000699   0.000170\n",
      "                    native_country.NA            3.287840          0.000566   0.000138\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        90610.484375          1.000000   0.140201\n",
      "                                  age        68681.515625          0.757986   0.106270\n",
      "                       hours_per_week        51000.281250          0.562852   0.078912\n",
      "                               fnlwgt        50575.820313          0.558167   0.078256\n",
      "                         capital_loss        47555.417969          0.524834   0.073582\n",
      "   marital_status. Married-civ-spouse        30604.107422          0.337755   0.047354\n",
      "          occupation. Exec-managerial        14294.412109          0.157757   0.022118\n",
      "                 education. Bachelors        13558.096680          0.149631   0.020978\n",
      "        marital_status. Never-married        12267.802734          0.135391   0.018982\n",
      "           occupation. Prof-specialty        12109.584961          0.133644   0.018737\n",
      "---\n",
      "                          race. White         1479.164307          0.016324   0.002289\n",
      "             occupation. Adm-clerical         1269.491455          0.014010   0.001964\n",
      "                 education. Assoc-voc         1199.021973          0.013233   0.001855\n",
      "              relationship. Unmarried         1181.413452          0.013038   0.001828\n",
      "                 workclass. Local-gov         1034.795410          0.011420   0.001601\n",
      "                 workclass. State-gov          866.484131          0.009563   0.001341\n",
      "             race. Asian-Pac-Islander          731.437195          0.008072   0.001132\n",
      "             occupation. Craft-repair          652.098145          0.007197   0.001009\n",
      "                education. Assoc-acdm          281.623077          0.003108   0.000436\n",
      "marital_status. Married-spouse-absent           72.840508          0.000804   0.000113\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          455.000000          1.000000   0.237103\n",
      "                                  age          345.000000          0.758242   0.179781\n",
      "                       hours_per_week          208.000000          0.457143   0.108390\n",
      "                         capital_gain           85.000000          0.186813   0.044294\n",
      "                         capital_loss           69.000000          0.151648   0.035956\n",
      "                   education. HS-grad           54.000000          0.118681   0.028140\n",
      "                   workclass. Private           49.000000          0.107692   0.025534\n",
      "                          sex. Female           40.000000          0.087912   0.020844\n",
      "                 education. Bachelors           39.000000          0.085714   0.020323\n",
      "          occupation. Exec-managerial           37.000000          0.081319   0.019281\n",
      "---\n",
      "               native_country. Canada            2.000000          0.004396   0.001042\n",
      "                      education. 12th            2.000000          0.004396   0.001042\n",
      "             race. Asian-Pac-Islander            2.000000          0.004396   0.001042\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.004396   0.001042\n",
      "          native_country. Philippines            2.000000          0.004396   0.001042\n",
      "                education. Assoc-acdm            2.000000          0.004396   0.001042\n",
      "marital_status. Married-spouse-absent            1.000000          0.002198   0.000521\n",
      "                          race. Other            1.000000          0.002198   0.000521\n",
      "              native_country. England            1.000000          0.002198   0.000521\n",
      "                    native_country.NA            1.000000          0.002198   0.000521\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              30\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      " 2023-10-20 18:27:54 13.615 sec              20       0.28674          0.26175      0.93954         0.85198       4.15266                       0.12794\n",
      " 2023-10-20 18:27:54 13.793 sec              25       0.28371          0.25594      0.94204         0.85711       4.15266                       0.11968\n",
      " 2023-10-20 18:27:54 13.992 sec              30       0.27987          0.24959      0.94525         0.86389       4.15266                       0.11265\n",
      "\n",
      "10-20 18:27:54.989 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 31. tree was built in 00:00:00.076 (Wall: 20-Oct 18:27:54.989) \n",
      "10-20 18:27:55.022 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:55.054 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 32. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:55.054) \n",
      "10-20 18:27:55.109 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 33. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:55.109) \n",
      "10-20 18:27:55.147 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 34. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:55.147) \n",
      "10-20 18:27:55.200 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 35. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:55.199) \n",
      "10-20 18:27:55.265 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_419\n",
      "10-20 18:27:55.276 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_419\n",
      "10-20 18:27:55.279 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.07675086\n",
      " RMSE: 0.27703944\n",
      " AUC: 0.94743764\n",
      " pr_auc: 0.8688213\n",
      " logloss: 0.24491595\n",
      " mean_per_class_error: 0.15140027\n",
      " default threshold: 0.4259791672229767\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22960  1760  0.0712  1,760 / 24,720\n",
      "     1   1816  6025  0.2316   1,816 / 7,841\n",
      "Totals  24776  7785  0.1098  3,576 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.997411  4.152659         4.152659       1.000000  0.998160                  1.000000          0.998160      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.995538  4.152659         4.152659       1.000000  0.996577                  1.000000          0.997368      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.990930  4.152659         4.152659       1.000000  0.993502                  1.000000          0.996082      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.980709  4.152659         4.152659       1.000000  0.986293                  1.000000          0.993633      0.041576                 0.166178  315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.963081  4.139921         4.150110       0.996933  0.972123                  0.999386          0.989328      0.041449                 0.207627  313.992088       315.010989            0.207586\n",
      "      6                0.10002764         0.788241  3.846566         3.998385       0.926290  0.873009                  0.962849          0.931187      0.192322                 0.399949  284.656629       299.838469            0.395054\n",
      "      7                0.15002610         0.650622  3.188467         3.728467       0.767813  0.718079                  0.897851          0.860165      0.159418                 0.559367  218.846675       272.846731            0.539181\n",
      "      8                0.20002457         0.513606  2.591586         3.444291       0.624079  0.582599                  0.829418          0.790784      0.129575                 0.688943  159.158578       244.429057            0.643999\n",
      "      9                0.30002150         0.310781  1.680960         2.856574       0.404791  0.405617                  0.687890          0.662409      0.168091                 0.857034   68.095967       185.657377            0.733692\n",
      "     10                0.40001843         0.158225  0.874915         2.361197       0.210688  0.228706                  0.568599          0.553991      0.087489                 0.944522  -12.508472       136.119718            0.717217\n",
      "     11                0.50001536         0.072825  0.367311         1.962445       0.088452  0.111099                  0.472575          0.465418      0.036730                 0.981252  -63.268863        96.244451            0.633882\n",
      "     12                0.60001228         0.030238  0.118611         1.655155       0.028563  0.048559                  0.398577          0.395945      0.011861                 0.993113  -88.138904        65.515465            0.517789\n",
      "     13                0.70000921         0.013932  0.051015         1.426002       0.012285  0.020892                  0.343395          0.342369      0.005101                 0.998215  -94.898453        42.600196            0.392794\n",
      "     14                0.80000614         0.006254  0.014029         1.249512       0.003378  0.009752                  0.300894          0.300793      0.001403                 0.999617  -98.597075        24.951215            0.262926\n",
      "     15                0.90000307         0.001917  0.002551         1.110966       0.000614  0.003765                  0.267531          0.267791      0.000255                 0.999872  -99.744923        11.096561            0.131547\n",
      "     16                1.00000000         0.000166  0.001275         1.000000       0.000307  0.000993                  0.240810          0.241112      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5823.425781          1.000000   0.237069\n",
      "                         capital_gain         4535.339355          0.778810   0.184631\n",
      "                                  age         2113.711182          0.362967   0.086048\n",
      "                         capital_loss         1552.806763          0.266648   0.063214\n",
      "                               fnlwgt         1501.949097          0.257915   0.061144\n",
      "                       hours_per_week         1231.062622          0.211398   0.050116\n",
      "        marital_status. Never-married          952.442627          0.163554   0.038773\n",
      "          occupation. Exec-managerial          789.524048          0.135577   0.032141\n",
      "                 education. Bachelors          787.329834          0.135200   0.032052\n",
      "           occupation. Prof-specialty          765.689148          0.131484   0.031171\n",
      "---\n",
      "                         workclass.NA           10.449273          0.001794   0.000425\n",
      "                        occupation.NA            8.650459          0.001485   0.000352\n",
      "               native_country. Canada            7.408252          0.001272   0.000302\n",
      "                          race. Other            6.296602          0.001081   0.000256\n",
      "              native_country. England            6.248845          0.001073   0.000254\n",
      "marital_status. Married-spouse-absent            4.704323          0.000808   0.000192\n",
      "              native_country. Germany            4.504293          0.000773   0.000183\n",
      "          native_country. Puerto-Rico            3.870092          0.000665   0.000158\n",
      "                native_country. Italy            3.628579          0.000623   0.000148\n",
      "                    native_country.NA            3.287840          0.000565   0.000134\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain        92129.351563          1.000000   0.126614\n",
      "                                  age        74891.429688          0.812894   0.102924\n",
      "                               fnlwgt        68010.937500          0.738211   0.093468\n",
      "                       hours_per_week        60541.628906          0.657137   0.083203\n",
      "                         capital_loss        53552.230469          0.581272   0.073597\n",
      "   marital_status. Married-civ-spouse        31678.822266          0.343852   0.043536\n",
      "          occupation. Exec-managerial        14666.061523          0.159190   0.020156\n",
      "                 education. Doctorate        14332.511719          0.155569   0.019697\n",
      "                 education. Bachelors        13919.745117          0.151089   0.019130\n",
      "        marital_status. Never-married        12459.065430          0.135234   0.017123\n",
      "---\n",
      "                          race. White         1642.899902          0.017833   0.002258\n",
      "                    native_country.NA         1534.693970          0.016658   0.002109\n",
      "              relationship. Unmarried         1289.057251          0.013992   0.001772\n",
      "             occupation. Adm-clerical         1269.491455          0.013779   0.001745\n",
      "             occupation. Craft-repair         1261.933960          0.013697   0.001734\n",
      "                 education. Assoc-voc         1199.021973          0.013015   0.001648\n",
      "                 workclass. Local-gov         1194.654785          0.012967   0.001642\n",
      "                 workclass. State-gov          892.276428          0.009685   0.001226\n",
      "                education. Assoc-acdm          520.981201          0.005655   0.000716\n",
      "marital_status. Married-spouse-absent           72.840508          0.000791   0.000100\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          555.000000          1.000000   0.251131\n",
      "                                  age          392.000000          0.706306   0.177376\n",
      "                       hours_per_week          232.000000          0.418018   0.104977\n",
      "                         capital_gain           88.000000          0.158559   0.039819\n",
      "                         capital_loss           74.000000          0.133333   0.033484\n",
      "                   education. HS-grad           63.000000          0.113514   0.028507\n",
      "                   workclass. Private           62.000000          0.111712   0.028054\n",
      "                 education. Bachelors           45.000000          0.081081   0.020362\n",
      "          occupation. Exec-managerial           41.000000          0.073874   0.018552\n",
      "                          sex. Female           41.000000          0.073874   0.018552\n",
      "---\n",
      "               native_country. Canada            2.000000          0.003604   0.000905\n",
      "                          race. Other            2.000000          0.003604   0.000905\n",
      "                      education. 12th            2.000000          0.003604   0.000905\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.003604   0.000905\n",
      "marital_status. Married-spouse-absent            1.000000          0.001802   0.000452\n",
      "              native_country. England            1.000000          0.001802   0.000452\n",
      "                native_country. Italy            1.000000          0.001802   0.000452\n",
      "              native_country. Germany            1.000000          0.001802   0.000452\n",
      "          native_country. Puerto-Rico            1.000000          0.001802   0.000452\n",
      "                    native_country.NA            1.000000          0.001802   0.000452\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              35\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      " 2023-10-20 18:27:54 13.615 sec              20       0.28674          0.26175      0.93954         0.85198       4.15266                       0.12794\n",
      " 2023-10-20 18:27:54 13.793 sec              25       0.28371          0.25594      0.94204         0.85711       4.15266                       0.11968\n",
      " 2023-10-20 18:27:54 13.992 sec              30       0.27987          0.24959      0.94525         0.86389       4.15266                       0.11265\n",
      " 2023-10-20 18:27:55 14.353 sec              35       0.27704          0.24492      0.94744         0.86882       4.15266                       0.10982\n",
      "\n",
      "10-20 18:27:55.323 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 36. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:55.323) \n",
      "10-20 18:27:55.336 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 37. tree was built in 00:00:00.013 (Wall: 20-Oct 18:27:55.336) \n",
      "10-20 18:27:55.347 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 38. tree was built in 00:00:00.011 (Wall: 20-Oct 18:27:55.347) \n",
      "10-20 18:27:55.365 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 39. tree was built in 00:00:00.018 (Wall: 20-Oct 18:27:55.365) \n",
      "10-20 18:27:55.389 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 40. tree was built in 00:00:00.024 (Wall: 20-Oct 18:27:55.389) \n",
      "10-20 18:27:55.456 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_420\n",
      "10-20 18:27:55.471 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_420\n",
      "10-20 18:27:55.476 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.07567573\n",
      " RMSE: 0.2750922\n",
      " AUC: 0.94899124\n",
      " pr_auc: 0.87208104\n",
      " logloss: 0.2414322\n",
      " mean_per_class_error: 0.14036407\n",
      " default threshold: 0.3781588077545166\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22522  2198  0.0889  2,198 / 24,720\n",
      "     1   1504  6337  0.1918   1,504 / 7,841\n",
      "Totals  24026  8535  0.1137  3,702 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.05 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.997876  4.152659         4.152659       1.000000  0.998520                  1.000000          0.998520      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.996259  4.152659         4.152659       1.000000  0.997125                  1.000000          0.997822      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.991995  4.152659         4.152659       1.000000  0.994385                  1.000000          0.996679      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.983938  4.152659         4.152659       1.000000  0.988344                  1.000000          0.994594      0.041576                 0.166178  315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.968390  4.139921         4.150110       0.996933  0.976567                  0.999386          0.990986      0.041449                 0.207627  313.992088       315.010989            0.207586\n",
      "      6                0.10002764         0.792722  3.844016         3.997110       0.925676  0.880499                  0.962542          0.935759      0.192195                 0.399821  284.401552       299.710970            0.394886\n",
      "      7                0.15002610         0.652969  3.231830         3.742069       0.778256  0.722873                  0.901126          0.864812      0.161587                 0.561408  223.182990       274.206865            0.541869\n",
      "      8                0.20002457         0.518028  2.604340         3.457680       0.627150  0.585236                  0.832642          0.794929      0.130213                 0.691621  160.433964       245.768007            0.647527\n",
      "      9                0.30002150         0.306234  1.692438         2.869326       0.407555  0.404212                  0.690961          0.664703      0.169239                 0.860860   69.243815       186.932633            0.738732\n",
      "     10                0.40001843         0.152789  0.863437         2.367892       0.207924  0.223659                  0.570211          0.554451      0.086341                 0.947201  -13.656320       136.789245            0.720744\n",
      "     11                0.50001536         0.069758  0.364761         1.967291       0.087838  0.107147                  0.473742          0.464995      0.036475                 0.983676  -63.523940        96.729068            0.637074\n",
      "     12                0.60001228         0.029087  0.094379         1.655155       0.022727  0.046430                  0.398577          0.395238      0.009438                 0.993113  -90.562138        65.515465            0.517789\n",
      "     13                0.70000921         0.012998  0.053566         1.426366       0.012899  0.019823                  0.343483          0.341610      0.005356                 0.998470  -94.643376        42.636634            0.393130\n",
      "     14                0.80000614         0.005622  0.012754         1.249672       0.003071  0.008952                  0.300933          0.300029      0.001275                 0.999745  -98.724613        24.967157            0.263094\n",
      "     15                0.90000307         0.001735  0.001275         1.110966       0.000307  0.003377                  0.267531          0.267069      0.000128                 0.999872  -99.872461        11.096561            0.131547\n",
      "     16                1.00000000         0.000118  0.001275         1.000000       0.000307  0.000878                  0.240810          0.240451      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5845.723633          1.000000   0.232544\n",
      "                         capital_gain         4555.224609          0.779241   0.181207\n",
      "                                  age         2206.111816          0.377389   0.087759\n",
      "                               fnlwgt         1711.106689          0.292711   0.068068\n",
      "                         capital_loss         1575.682861          0.269545   0.062681\n",
      "                       hours_per_week         1237.953857          0.211771   0.049246\n",
      "        marital_status. Never-married          954.491028          0.163280   0.037970\n",
      "          occupation. Exec-managerial          790.384033          0.135207   0.031442\n",
      "                 education. Bachelors          788.146545          0.134824   0.031353\n",
      "           occupation. Prof-specialty          773.501160          0.132319   0.030770\n",
      "---\n",
      "                         workclass.NA           10.449273          0.001788   0.000416\n",
      "               native_country. Canada            7.408252          0.001267   0.000295\n",
      "                          race. Other            6.296602          0.001077   0.000250\n",
      "              native_country. England            6.248845          0.001069   0.000249\n",
      "                native_country. Italy            6.018877          0.001030   0.000239\n",
      "marital_status. Married-spouse-absent            4.704323          0.000805   0.000187\n",
      "              native_country. Germany            4.504293          0.000771   0.000179\n",
      "          native_country. Puerto-Rico            3.870092          0.000662   0.000154\n",
      "                    native_country.NA            3.287840          0.000562   0.000131\n",
      "                 native_country. Cuba            2.305434          0.000394   0.000092\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                         capital_gain       100374.078125          1.000000   0.124103\n",
      "                               fnlwgt        88964.976563          0.886334   0.109996\n",
      "                                  age        77383.078125          0.770947   0.095677\n",
      "                         capital_loss        63183.281250          0.629478   0.078120\n",
      "                       hours_per_week        61122.359375          0.608946   0.075572\n",
      "   marital_status. Married-civ-spouse        32541.763672          0.324205   0.040235\n",
      "          occupation. Exec-managerial        14740.866211          0.146859   0.018226\n",
      "                 education. Doctorate        14332.511719          0.142791   0.017721\n",
      "                 education. Bachelors        14001.287109          0.139491   0.017311\n",
      "           occupation. Prof-specialty        12613.464844          0.125665   0.015595\n",
      "---\n",
      "          native_country. Puerto-Rico         1707.990234          0.017016   0.002112\n",
      "                 native_country. Cuba         1630.260864          0.016242   0.002016\n",
      "                 education. Assoc-voc         1609.848755          0.016038   0.001990\n",
      "                    native_country.NA         1534.693970          0.015290   0.001897\n",
      "             occupation. Adm-clerical         1470.285767          0.014648   0.001818\n",
      "             occupation. Craft-repair         1321.972412          0.013170   0.001634\n",
      "              relationship. Unmarried         1289.057251          0.012843   0.001594\n",
      "                 workclass. State-gov         1195.172363          0.011907   0.001478\n",
      "                education. Assoc-acdm          520.981201          0.005190   0.000644\n",
      "marital_status. Married-spouse-absent           72.840508          0.000726   0.000090\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          625.000000          1.000000   0.256674\n",
      "                                  age          440.000000          0.704000   0.180698\n",
      "                       hours_per_week          234.000000          0.374400   0.096099\n",
      "                         capital_gain           93.000000          0.148800   0.038193\n",
      "                         capital_loss           82.000000          0.131200   0.033676\n",
      "                   education. HS-grad           71.000000          0.113600   0.029158\n",
      "                   workclass. Private           66.000000          0.105600   0.027105\n",
      "                          sex. Female           47.000000          0.075200   0.019302\n",
      "                 education. Bachelors           46.000000          0.073600   0.018891\n",
      "          occupation. Exec-managerial           43.000000          0.068800   0.017659\n",
      "---\n",
      "               native_country. Canada            2.000000          0.003200   0.000821\n",
      "                          race. Other            2.000000          0.003200   0.000821\n",
      "                native_country. Italy            2.000000          0.003200   0.000821\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.003200   0.000821\n",
      "marital_status. Married-spouse-absent            1.000000          0.001600   0.000411\n",
      "              native_country. England            1.000000          0.001600   0.000411\n",
      "                 native_country. Cuba            1.000000          0.001600   0.000411\n",
      "              native_country. Germany            1.000000          0.001600   0.000411\n",
      "          native_country. Puerto-Rico            1.000000          0.001600   0.000411\n",
      "                    native_country.NA            1.000000          0.001600   0.000411\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              40\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      " 2023-10-20 18:27:54 13.615 sec              20       0.28674          0.26175      0.93954         0.85198       4.15266                       0.12794\n",
      " 2023-10-20 18:27:54 13.793 sec              25       0.28371          0.25594      0.94204         0.85711       4.15266                       0.11968\n",
      " 2023-10-20 18:27:54 13.992 sec              30       0.27987          0.24959      0.94525         0.86389       4.15266                       0.11265\n",
      " 2023-10-20 18:27:55 14.353 sec              35       0.27704          0.24492      0.94744         0.86882       4.15266                       0.10982\n",
      " 2023-10-20 18:27:55 14.542 sec              40       0.27509          0.24143      0.94899         0.87208       4.15266                       0.11369\n",
      "\n",
      "10-20 18:27:55.513 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 41. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:55.513) \n",
      "10-20 18:27:55.532 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 42. tree was built in 00:00:00.019 (Wall: 20-Oct 18:27:55.532) \n",
      "10-20 18:27:55.543 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: 43. tree was built in 00:00:00.010 (Wall: 20-Oct 18:27:55.543) \n",
      "10-20 18:27:55.621 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_421\n",
      "10-20 18:27:55.636 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_421\n",
      "10-20 18:27:55.639 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.xgboost.XGBoost: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: XGBoost_2_AutoML_1_20231020_182658\n",
      " frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      " MSE: 0.07487452\n",
      " RMSE: 0.27363208\n",
      " AUC: 0.9500904\n",
      " pr_auc: 0.8747198\n",
      " logloss: 0.23908134\n",
      " mean_per_class_error: 0.13855325\n",
      " default threshold: 0.38302361965179443\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "            0     1   Error            Rate\n",
      "     0  22580  2140  0.0866  2,140 / 24,720\n",
      "     1   1494  6347  0.1905   1,494 / 7,841\n",
      "Totals  24074  8487  0.1116  3,634 / 32,561\n",
      "Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.08 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                0.01001198         0.998021  4.152659         4.152659       1.000000  0.998597                  1.000000          0.998597      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "      2                0.02002396         0.996471  4.152659         4.152659       1.000000  0.997294                  1.000000          0.997945      0.041576                 0.083153  315.265910       315.265910            0.083153\n",
      "      3                0.03000522         0.992549  4.152659         4.152659       1.000000  0.994743                  1.000000          0.996880      0.041449                 0.124601  315.265910       315.265910            0.124601\n",
      "      4                0.04001720         0.985715  4.152659         4.152659       1.000000  0.989522                  1.000000          0.995039      0.041576                 0.166178  315.265910       315.265910            0.166178\n",
      "      5                0.05002918         0.972016  4.139921         4.150110       0.996933  0.979166                  0.999386          0.991863      0.041449                 0.207627  313.992088       315.010989            0.207586\n",
      "      6                0.10002764         0.798648  3.869523         4.009860       0.931818  0.884510                  0.965613          0.938203      0.193470                 0.401097  286.952325       300.985965            0.396566\n",
      "      7                0.15005682         0.655672  3.270633         3.763400       0.787600  0.725726                  0.906263          0.867363      0.163627                 0.564724  227.063329       276.340043            0.546196\n",
      "      8                0.20002457         0.519178  2.570208         3.465331       0.618931  0.587447                  0.834485          0.797437      0.128427                 0.693151  157.020757       246.533122            0.649543\n",
      "      9                0.30002150         0.306513  1.682235         2.871027       0.405098  0.406098                  0.691371          0.667004      0.168218                 0.861370   68.223506       187.102667            0.739404\n",
      "     10                0.40001843         0.152170  0.869814         2.370762       0.209459  0.222807                  0.570902          0.555964      0.086979                 0.948348  -13.018627       137.076185            0.722256\n",
      "     11                0.50001536         0.068698  0.353282         1.967291       0.085074  0.106017                  0.473742          0.465980      0.035327                 0.983676  -64.671788        96.729068            0.637074\n",
      "     12                0.60001228         0.028669  0.100756         1.656217       0.024263  0.045647                  0.398833          0.395928      0.010075                 0.993751  -89.924445        65.621742            0.518629\n",
      "     13                0.70000921         0.012773  0.049740         1.426731       0.011978  0.019529                  0.343570          0.342159      0.004974                 0.998725  -95.025992        42.673072            0.393466\n",
      "     14                0.80000614         0.005516  0.010203         1.249672       0.002457  0.008786                  0.300933          0.300489      0.001020                 0.999745  -98.979691        24.967157            0.263094\n",
      "     15                0.90000307         0.001710  0.001275         1.110966       0.000307  0.003335                  0.267531          0.267473      0.000128                 0.999872  -99.872461        11.096561            0.131547\n",
      "     16                1.00000000         0.000105  0.001275         1.000000       0.000307  0.000861                  0.240810          0.240813      0.000128                 1.000000  -99.872461         0.000000            0.000000\n",
      "Variable Importances:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "   marital_status. Married-civ-spouse         5845.946289          1.000000   0.228957\n",
      "                         capital_gain         4562.787598          0.780505   0.178702\n",
      "                                  age         2256.929199          0.386067   0.088393\n",
      "                               fnlwgt         1864.588989          0.318954   0.073027\n",
      "                         capital_loss         1614.153687          0.276115   0.063218\n",
      "                       hours_per_week         1282.596802          0.219399   0.050233\n",
      "        marital_status. Never-married          960.434631          0.164291   0.037616\n",
      "          occupation. Exec-managerial          794.256470          0.135864   0.031107\n",
      "                 education. Bachelors          793.337769          0.135707   0.031071\n",
      "           occupation. Prof-specialty          777.733154          0.133038   0.030460\n",
      "---\n",
      "                         workclass.NA           10.449273          0.001787   0.000409\n",
      "              native_country. Germany            7.604247          0.001301   0.000298\n",
      "               native_country. Canada            7.408252          0.001267   0.000290\n",
      "                          race. Other            6.296602          0.001077   0.000247\n",
      "              native_country. England            6.248845          0.001069   0.000245\n",
      "                native_country. Italy            6.018877          0.001030   0.000236\n",
      "                    native_country.NA            5.425213          0.000928   0.000212\n",
      "marital_status. Married-spouse-absent            4.704323          0.000805   0.000184\n",
      "          native_country. Puerto-Rico            3.870092          0.000662   0.000152\n",
      "                 native_country. Cuba            2.305434          0.000394   0.000090\n",
      "Variable Importances - Cover:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt       103175.054688          1.000000   0.120513\n",
      "                         capital_gain       102065.351563          0.989244   0.119216\n",
      "                                  age        80281.015625          0.778105   0.093771\n",
      "                         capital_loss        73783.656250          0.715131   0.086182\n",
      "                       hours_per_week        63208.968750          0.612638   0.073831\n",
      "   marital_status. Married-civ-spouse        32559.490234          0.315575   0.038031\n",
      "          occupation. Exec-managerial        16379.384766          0.158753   0.019132\n",
      "                 education. Doctorate        14332.511719          0.138915   0.016741\n",
      "                 education. Bachelors        14064.441406          0.136316   0.016428\n",
      "        marital_status. Never-married        12937.087891          0.125390   0.015111\n",
      "---\n",
      "          relationship. Not-in-family         2248.092285          0.021789   0.002626\n",
      "              native_country. England         1777.494629          0.017228   0.002076\n",
      "          native_country. Puerto-Rico         1707.990234          0.016554   0.001995\n",
      "                 native_country. Cuba         1630.260864          0.015801   0.001904\n",
      "             occupation. Adm-clerical         1470.285767          0.014250   0.001717\n",
      "             occupation. Craft-repair         1449.095215          0.014045   0.001693\n",
      "              relationship. Unmarried         1428.910889          0.013849   0.001669\n",
      "                 workclass. State-gov         1367.316650          0.013252   0.001597\n",
      "                education. Assoc-acdm          520.981201          0.005049   0.000609\n",
      "marital_status. Married-spouse-absent           72.840508          0.000706   0.000085\n",
      "Variable Importances - Frequency:\n",
      "                             Variable Relative Importance Scaled Importance Percentage\n",
      "                               fnlwgt          690.000000          1.000000   0.265794\n",
      "                                  age          465.000000          0.673913   0.179122\n",
      "                       hours_per_week          253.000000          0.366667   0.097458\n",
      "                         capital_gain           95.000000          0.137681   0.036595\n",
      "                         capital_loss           93.000000          0.134783   0.035824\n",
      "                   education. HS-grad           73.000000          0.105797   0.028120\n",
      "                   workclass. Private           72.000000          0.104348   0.027735\n",
      "                 education. Bachelors           48.000000          0.069565   0.018490\n",
      "                          sex. Female           47.000000          0.068116   0.018105\n",
      "          occupation. Exec-managerial           44.000000          0.063768   0.016949\n",
      "---\n",
      "               native_country. Canada            2.000000          0.002899   0.000770\n",
      "                          race. Other            2.000000          0.002899   0.000770\n",
      "                native_country. Italy            2.000000          0.002899   0.000770\n",
      "             race. Amer-Indian-Eskimo            2.000000          0.002899   0.000770\n",
      "              native_country. Germany            2.000000          0.002899   0.000770\n",
      "                    native_country.NA            2.000000          0.002899   0.000770\n",
      "marital_status. Married-spouse-absent            1.000000          0.001449   0.000385\n",
      "              native_country. England            1.000000          0.001449   0.000385\n",
      "                 native_country. Cuba            1.000000          0.001449   0.000385\n",
      "          native_country. Puerto-Rico            1.000000          0.001449   0.000385\n",
      "Native XGBoost Parameters:\n",
      "              Name           Value\n",
      "            silent            true\n",
      "               eta             0.3\n",
      " colsample_bylevel             0.8\n",
      "         objective binary:logistic\n",
      "  min_child_weight             5.0\n",
      "           nthread               4\n",
      "              seed              44\n",
      "         max_depth              10\n",
      "  colsample_bytree             0.8\n",
      "            lambda             1.0\n",
      "             gamma             0.0\n",
      "             alpha             0.0\n",
      "           booster          gbtree\n",
      "       grow_policy       depthwise\n",
      "            nround              43\n",
      "         subsample             0.6\n",
      "    max_delta_step             0.0\n",
      "       tree_method           exact\n",
      "Model Summary:\n",
      " Number of Trees\n",
      "              43\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error\n",
      " 2023-10-20 18:27:53 12.748 sec               0       0.50000          0.69315      0.50000         0.24081       1.00000                       0.75919\n",
      " 2023-10-20 18:27:53 12.966 sec               5       0.31702          0.34409      0.92366         0.82073       4.12978                       0.13851\n",
      " 2023-10-20 18:27:54 13.212 sec              10       0.29577          0.28551      0.93293         0.83966       4.15266                       0.13120\n",
      " 2023-10-20 18:27:54 13.420 sec              15       0.28990          0.26951      0.93713         0.84766       4.15266                       0.12724\n",
      " 2023-10-20 18:27:54 13.615 sec              20       0.28674          0.26175      0.93954         0.85198       4.15266                       0.12794\n",
      " 2023-10-20 18:27:54 13.793 sec              25       0.28371          0.25594      0.94204         0.85711       4.15266                       0.11968\n",
      " 2023-10-20 18:27:54 13.992 sec              30       0.27987          0.24959      0.94525         0.86389       4.15266                       0.11265\n",
      " 2023-10-20 18:27:55 14.353 sec              35       0.27704          0.24492      0.94744         0.86882       4.15266                       0.10982\n",
      " 2023-10-20 18:27:55 14.542 sec              40       0.27509          0.24143      0.94899         0.87208       4.15266                       0.11369\n",
      " 2023-10-20 18:27:55 14.696 sec              43       0.27363          0.23908      0.95009         0.87472       4.15266                       0.11161\n",
      "\n",
      "10-20 18:27:55.642 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: In-training scoring took 636ms.\n",
      "10-20 18:27:55.649 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model XGBoost_2_AutoML_1_20231020_182658\n",
      "10-20 18:27:55.649 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Computing 5-fold cross-validation metrics.\n",
      "10-20 18:27:55.662 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model Quantiles_model_1697826262527_422\n",
      "10-20 18:27:55.680 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model Quantiles_model_1697826262527_422\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Model Metrics Type: Binomial\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  Description: 5-fold cross-validation on training data (Metrics computed for combined holdout predictions)\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  model id: XGBoost_2_AutoML_1_20231020_182658\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  frame id: AutoML_1_20231020_182658_training_py_9_sid_88b4\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  MSE: 0.091491565\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  RMSE: 0.30247572\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  AUC: 0.92290586\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  pr_auc: 0.81824\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  logloss: 0.28809592\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  mean_per_class_error: 0.17843738\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  default threshold: 0.3851810395717621\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:  CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:             0     1   Error            Rate\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      0  22175  2545  0.1030  2,545 / 24,720\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      1   1991  5850  0.2539   1,991 / 7,841\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Totals  24166  8395  0.1393  4,536 / 32,561\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Gains/Lift Table (Avg response rate: 24.08 %, avg score: 24.09 %):\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:   Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate        Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       1                0.01001198         0.997384  4.152659         4.152659       1.000000  0.998157                  1.000000          0.998157      0.041576                 0.041576  315.265910       315.265910            0.041576\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       2                0.02002396         0.995426  4.139921         4.146290       0.996933  0.996469                  0.998466          0.997313      0.041449                 0.083025  313.992088       314.628999            0.082985\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       3                0.03000522         0.991825  4.127104         4.139908       0.993846  0.993877                  0.996929          0.996170      0.041194                 0.124219  312.710427       313.990784            0.124097\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       4                0.04001720         0.984932  4.127183         4.136724       0.993865  0.988828                  0.996163          0.994333      0.041321                 0.165540  312.718266       313.672411            0.165338\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       5                0.05002918         0.971225  4.076230         4.124618       0.981595  0.978817                  0.993247          0.991228      0.040811                 0.206351  307.622979       312.461782            0.205906\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       6                0.10002764         0.796488  3.563430         3.844110       0.858108  0.883751                  0.925698          0.937506      0.178166                 0.384517  256.343044       284.411028            0.374728\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       7                0.15002610         0.651797  2.844112         3.510846       0.684889  0.722648                  0.845445          0.865901      0.142201                 0.526719  184.411234       251.084587            0.496176\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       8                0.20002457         0.514693  2.311001         3.210931       0.556511  0.580348                  0.773223          0.794524      0.115546                 0.642265  131.100070       221.093063            0.582516\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:       9                0.30002150         0.306701  1.610813         2.677613       0.387899  0.402539                  0.644795          0.663876      0.161076                 0.803341   61.081340       167.761282            0.662969\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      10                0.40001843         0.158381  1.050919         2.270971       0.253071  0.227559                  0.546871          0.554805      0.105089                 0.908430    5.091864       127.097050            0.669676\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      11                0.50001536         0.070686  0.533112         1.923420       0.128378  0.109539                  0.463178          0.465757      0.053310                 0.961740  -46.688836        92.342008            0.608180\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      12                0.60001228         0.029635  0.227019         1.640701       0.054668  0.047144                  0.395096          0.395992      0.022701                 0.984441  -77.298117        64.070101            0.506366\n",
      "10-20 18:27:55.684 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      13                0.70000921         0.012880  0.084176         1.418350       0.020270  0.020157                  0.341552          0.342304      0.008417                 0.992858  -91.582448        41.834998            0.385738\n",
      "10-20 18:27:55.685 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      14                0.80000614         0.005480  0.051015         1.247440       0.012285  0.008748                  0.300395          0.300611      0.005101                 0.997959  -94.898453        24.743973            0.260743\n",
      "10-20 18:27:55.685 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      15                0.90000307         0.001649  0.017855         1.110824       0.004300  0.003323                  0.267497          0.267580      0.001785                 0.999745  -98.214459        11.082391            0.131379\n",
      "10-20 18:27:55.685 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:      16                1.00000000         0.000084  0.002551         1.000000       0.000614  0.000832                  0.240810          0.240906      0.000255                 1.000000  -99.744923         0.000000            0.000000\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Cross-Validation Metrics Summary:\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                                mean         sd  cv_1_valid  cv_2_valid  cv_3_valid  cv_4_valid  cv_5_valid\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                accuracy    0.860631   0.005064    0.861354    0.864711    0.852273    0.860258    0.864558\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                     auc    0.922923   0.003818    0.926609    0.925212    0.916849    0.924106    0.921837\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                     err    0.139369   0.005064    0.138646    0.135289    0.147727    0.139742    0.135442\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:               err_count  907.599976  32.974232  903.000000  881.000000  962.000000  910.000000  882.000000\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                f0point5    0.705363   0.014237    0.715181    0.708553    0.682726    0.701651    0.718705\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                      f1    0.721637   0.012964    0.735423    0.719516    0.701057    0.723404    0.728782\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                      f2    0.738753   0.014036    0.756845    0.730824    0.720399    0.746550    0.739147\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:          lift_top_group    4.154737   0.103193    4.005535    4.256209    4.236825    4.174359    4.100756\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                 logloss    0.288096   0.005552    0.285645    0.280595    0.294645    0.287313    0.292281\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:     max_per_class_error    0.249333   0.016149    0.228167    0.261438    0.266103    0.237179    0.253778\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                     mcc    0.629768   0.015128    0.643084    0.630815    0.604281    0.631760    0.638900\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: mean_per_class_accuracy    0.823045   0.007558    0.831486    0.821007    0.811371    0.826887    0.824472\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:    mean_per_class_error    0.176955   0.007558    0.168514    0.178993    0.188629    0.173113    0.175528\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                     mse    0.091492   0.001866    0.090533    0.088853    0.093751    0.091992    0.092330\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                  pr_auc    0.818448   0.010313    0.833707    0.820674    0.805218    0.814983    0.817658\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:               precision    0.694950   0.015920    0.702294    0.701428    0.671029    0.687861    0.712139\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                      r2    0.499354   0.013524    0.516712    0.505681    0.480081    0.495023    0.499273\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                  recall    0.750667   0.016149    0.771833    0.738562    0.733897    0.762821    0.746222\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:                    rmse    0.302463   0.003090    0.300887    0.298083    0.306187    0.303301    0.303858\n",
      "10-20 18:27:55.692 172.17.0.2:54321      22766      FJ-2-3  INFO water.default:             specificity    0.895422   0.007059    0.891140    0.903452    0.888844    0.890953    0.902721\n",
      "10-20 18:27:55.695 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: 5 CV models were removed\n",
      "10-20 18:27:55.697 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML step returned with state: StepResultState{_id='XGBoost:def_1', _status=success}\n",
      "10-20 18:27:55.698 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML step returned with state: StepResultState{_id='DRF:def_1', _status=skipped}\n",
      "10-20 18:27:55.699 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: AutoML: starting GBM_2_AutoML_1_20231020_182658 model training\n",
      "10-20 18:27:55.709 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Creating 5 cross-validation splits with random number seed: 45\n",
      "10-20 18:27:55.728 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 1 / 5.\n",
      "10-20 18:27:55.728 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 2 / 5.\n",
      "10-20 18:27:55.728 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:55.728 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: {\"_train\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_1_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_1_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":45,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":0,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":7,\"_min_rows\":10.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:55.729 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:55.729 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: {\"_train\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_2_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_2_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":45,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":1,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":7,\"_min_rows\":10.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:55.729 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:55.730 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:55.737 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 3 / 5.\n",
      "10-20 18:27:55.738 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:55.738 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: {\"_train\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_3_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_3_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":45,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":2,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":7,\"_min_rows\":10.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:55.739 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Building cross-validation model 4 / 5.\n",
      "10-20 18:27:55.739 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Building H2O GBM model with these parameters:\n",
      "10-20 18:27:55.739 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: {\"_train\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_4_train\",\"type\":\"Key\"},\"_valid\":{\"name\":\"GBM_2_AutoML_1_20231020_182658_cv_4_valid\",\"type\":\"Key\"},\"_nfolds\":0,\"_keep_cross_validation_models\":false,\"_keep_cross_validation_predictions\":true,\"_keep_cross_validation_predictions_precision\":-1,\"_keep_cross_validation_fold_assignment\":false,\"_parallelize_cross_validation\":true,\"_auto_rebalance\":true,\"_preprocessors\":null,\"_seed\":45,\"_fold_assignment\":\"AUTO\",\"_categorical_encoding\":\"AUTO\",\"_max_categorical_levels\":10,\"_distribution\":\"bernoulli\",\"_tweedie_power\":1.5,\"_quantile_alpha\":0.5,\"_huber_alpha\":0.9,\"_ignored_columns\":null,\"_ignore_const_cols\":true,\"_weights_column\":\"__internal_cv_weights__\",\"_offset_column\":null,\"_fold_column\":null,\"_treatment_column\":null,\"_check_constant_response\":true,\"_is_cv_model\":true,\"_cv_fold\":3,\"_score_each_iteration\":false,\"_max_runtime_secs\":0.0,\"_main_model_time_budget_factor\":2.0,\"_stopping_rounds\":3,\"_stopping_metric\":\"logloss\",\"_stopping_tolerance\":0.005541803630764712,\"_response_column\":\"label\",\"_balance_classes\":false,\"_max_after_balance_size\":5.0,\"_class_sampling_factors\":null,\"_max_confusion_matrix_size\":20,\"_checkpoint\":null,\"_pretrained_autoencoder\":null,\"_custom_metric_func\":null,\"_custom_distribution_func\":null,\"_export_checkpoints_dir\":null,\"_gainslift_bins\":-1,\"_auc_type\":\"AUTO\",\"_auuc_type\":\"AUTO\",\"_auuc_nbins\":-1,\"_ntrees\":10000,\"_max_depth\":7,\"_min_rows\":10.0,\"_nbins\":20,\"_nbins_cats\":1024,\"_min_split_improvement\":1.0E-5,\"_histogram_type\":\"AUTO\",\"_r2_stopping\":1.7976931348623157E308,\"_nbins_top_level\":1024,\"_build_tree_one_node\":false,\"_score_tree_interval\":5,\"_initial_score_interval\":4000,\"_score_interval\":4000,\"_sample_rate\":0.8,\"_sample_rate_per_class\":null,\"_calibrate_model\":false,\"_calibration_frame\":null,\"_calibration_method\":\"AUTO\",\"_col_sample_rate_change_per_level\":1.0,\"_col_sample_rate_per_tree\":0.8,\"_parallel_main_model_building\":false,\"_use_best_cv_iteration\":true,\"_in_training_checkpoints_dir\":null,\"_in_training_checkpoints_tree_interval\":1,\"_learn_rate\":0.1,\"_learn_rate_annealing\":1.0,\"_col_sample_rate\":0.8,\"_max_abs_leafnode_pred\":1.7976931348623157E308,\"_pred_noise_bandwidth\":0.0,\"_monotone_constraints\":null,\"_interaction_constraints\":null}\n",
      "10-20 18:27:55.743 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:55.744 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:55.743 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing train dataset into 4 chunks.\n",
      "10-20 18:27:55.757 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:55.758 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:55.771 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Rebalancing valid dataset into 4 chunks.\n",
      "10-20 18:27:55.784 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Starting model GBM_2_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:55.784 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Prior class distribution: [0.7577258244078467, 0.24227417559215325]\n",
      "10-20 18:27:55.784 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model class distribution: [0.7577258244078467, 0.24227417559215325]\n",
      "10-20 18:27:55.794 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Starting model GBM_2_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:55.795 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Prior class distribution: [0.761402027027027, 0.23859797297297297]\n",
      "10-20 18:27:55.795 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Model class distribution: [0.761402027027027, 0.23859797297297297]\n",
      "10-20 18:27:55.797 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Starting model GBM_2_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:55.797 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Prior class distribution: [0.7579945487350762, 0.2420054512649238]\n",
      "10-20 18:27:55.797 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Model class distribution: [0.7579945487350762, 0.2420054512649238]\n",
      "10-20 18:27:55.804 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Starting model GBM_2_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:55.804 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Prior class distribution: [0.758877500095973, 0.24112249990402704]\n",
      "10-20 18:27:55.804 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Model class distribution: [0.758877500095973, 0.24112249990402704]\n",
      "10-20 18:27:55.807 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:55.808 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "\n",
      "18:27:55.696: XGBoost_2_AutoML_1_20231020_182658 [XGBoost def_1] complete\n",
      "18:27:55.696: Adding model XGBoost_2_AutoML_1_20231020_182658 to leaderboard Leaderboard_AutoML_1_20231020_182658@@label. Training time: model=2s, total=15s\n",
      "18:27:55.699: No time limitation for GBM_2_AutoML_1_20231020_182658\n",
      "18:27:55.699: AutoML: starting GBM_2_AutoML_1_20231020_182658 model training\n",
      "18:27:55.701: GBM_2_AutoML_1_20231020_182658 [GBM def_2] started\n",
      "\n",
      "10-20 18:27:55.825 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:55.832 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_424\n",
      "10-20 18:27:55.837 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_425\n",
      "10-20 18:27:55.847 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:55.853 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:55.856 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_426\n",
      "10-20 18:27:55.859 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_424\n",
      "10-20 18:27:55.860 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_426\n",
      "10-20 18:27:55.870 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_427\n",
      "10-20 18:27:55.870 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_425\n",
      "10-20 18:27:55.874 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_427\n",
      "10-20 18:27:55.874 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_428\n",
      "10-20 18:27:55.877 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_2_train\n",
      " MSE: 0.1835774\n",
      " RMSE: 0.42845935\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24227418\n",
      " logloss: 0.55368716\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.2422741800546646\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19738  1.0000  19,738 / 19,738\n",
      "     1  0   6311  0.0000        0 / 6,311\n",
      "Totals  0  26049  0.7577  19,738 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.23 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242274  1.000000         1.000000       0.242274  0.242274                  0.242274          0.242274      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_2\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_2_valid\n",
      " MSE: 0.17980258\n",
      " RMSE: 0.42403135\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23495086\n",
      " logloss: 0.5453368\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.2422741800546646\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4982  1.0000  4,982 / 4,982\n",
      "     1  0  1530  0.0000      0 / 1,530\n",
      "Totals  0  6512  0.7650  4,982 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.50 %, avg score: 24.23 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242274  1.000000         1.000000       0.234951  0.242274                  0.234951          0.242274      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:55  0.082 sec               0       0.42846          0.55369      0.50000         0.24227       1.00000                       0.75773         0.42403            0.54534        0.50000           0.23495         1.00000                         0.76505\n",
      "\n",
      "10-20 18:27:55.880 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_429\n",
      "10-20 18:27:55.881 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_428\n",
      "10-20 18:27:55.883 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_430\n",
      "10-20 18:27:55.886 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_429\n",
      "10-20 18:27:55.888 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_430\n",
      "10-20 18:27:55.892 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_1_train\n",
      " MSE: 0.18166898\n",
      " RMSE: 0.42622644\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23859797\n",
      " logloss: 0.54945844\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.23859797418117523\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19833  1.0000  19,833 / 19,833\n",
      "     1  0   6215  0.0000        0 / 6,215\n",
      "Totals  0  26048  0.7614  19,833 / 26,048\n",
      "Gains/Lift Table (Avg response rate: 23.86 %, avg score: 23.86 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.238598  1.000000         1.000000       0.238598  0.238598                  0.238598          0.238598      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_1\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_1_valid\n",
      " MSE: 0.1874494\n",
      " RMSE: 0.43295425\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24965453\n",
      " logloss: 0.5622883\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.23859797418117523\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4887  1.0000  4,887 / 4,887\n",
      "     1  0  1626  0.0000      0 / 1,626\n",
      "Totals  0  6513  0.7503  4,887 / 6,513\n",
      "Gains/Lift Table (Avg response rate: 24.97 %, avg score: 23.86 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.238598  1.000000         1.000000       0.249655  0.238598                  0.249655          0.238598      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:55  0.093 sec               0       0.42623          0.54946      0.50000         0.23860       1.00000                       0.76140         0.43295            0.56229        0.50000           0.24965         1.00000                         0.75035\n",
      "\n",
      "10-20 18:27:55.894 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_3_train\n",
      " MSE: 0.18343881\n",
      " RMSE: 0.42829758\n",
      " AUC: 0.5\n",
      " pr_auc: 0.24200545\n",
      " logloss: 0.55338055\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24200545251369476\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19745  1.0000  19,745 / 19,745\n",
      "     1  0   6304  0.0000        0 / 6,304\n",
      "Totals  0  26049  0.7580  19,745 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.20 %, avg score: 24.20 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242005  1.000000         1.000000       0.242005  0.242005                  0.242005          0.242005      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_3\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_3_valid\n",
      " MSE: 0.18035337\n",
      " RMSE: 0.42468032\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2360258\n",
      " logloss: 0.5465535\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24200545251369476\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4975  1.0000  4,975 / 4,975\n",
      "     1  0  1537  0.0000      0 / 1,537\n",
      "Totals  0  6512  0.7640  4,975 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.60 %, avg score: 24.20 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.242005  1.000000         1.000000       0.236026  0.242005                  0.236026          0.242005      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:55  0.096 sec               0       0.42830          0.55338      0.50000         0.24201       1.00000                       0.75799         0.42468            0.54655        0.50000           0.23603         1.00000                         0.76397\n",
      "\n",
      "10-20 18:27:55.900 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_431\n",
      "10-20 18:27:55.903 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_431\n",
      "10-20 18:27:55.919 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_4_train\n",
      " MSE: 0.18298244\n",
      " RMSE: 0.42776448\n",
      " AUC: 0.5\n",
      " pr_auc: 0.2411225\n",
      " logloss: 0.55237037\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24112249910831451\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0      1   Error             Rate\n",
      "     0  0  19768  1.0000  19,768 / 19,768\n",
      "     1  0   6281  0.0000        0 / 6,281\n",
      "Totals  0  26049  0.7589  19,768 / 26,049\n",
      "Gains/Lift Table (Avg response rate: 24.11 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.241122  1.000000         1.000000       0.241122  0.241122                  0.241122          0.241122      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Metrics Type: Binomial\n",
      " Description: N/A\n",
      " model id: GBM_2_AutoML_1_20231020_182658_cv_4\n",
      " frame id: GBM_2_AutoML_1_20231020_182658_cv_4_valid\n",
      " MSE: 0.18217228\n",
      " RMSE: 0.42681643\n",
      " AUC: 0.5\n",
      " pr_auc: 0.23955774\n",
      " logloss: 0.5505763\n",
      " mean_per_class_error: 0.5\n",
      " default threshold: 0.24112249910831451\n",
      " CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n",
      "        0     1   Error           Rate\n",
      "     0  0  4952  1.0000  4,952 / 4,952\n",
      "     1  0  1560  0.0000      0 / 1,560\n",
      "Totals  0  6512  0.7604  4,952 / 6,512\n",
      "Gains/Lift Table (Avg response rate: 23.96 %, avg score: 24.11 %):\n",
      "  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate      Gain  Cumulative Gain  Kolmogorov Smirnov\n",
      "      1                1.00000000         0.241122  1.000000         1.000000       0.239558  0.241122                  0.239558          0.241122      1.000000                 1.000000  0.000000         0.000000            0.000000\n",
      "Model Summary:\n",
      " Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\n",
      "               0                        0                   0          0          0    0.00000           0           0     0.00000\n",
      "Scoring History:\n",
      "           Timestamp   Duration Number of Trees Training RMSE Training LogLoss Training AUC Training pr_auc Training Lift Training Classification Error Validation RMSE Validation LogLoss Validation AUC Validation pr_auc Validation Lift Validation Classification Error\n",
      " 2023-10-20 18:27:55  0.103 sec               0       0.42776          0.55237      0.50000         0.24112       1.00000                       0.75888         0.42682            0.55058        0.50000           0.23956         1.00000                         0.76044\n",
      "\n",
      "█10-20 18:27:55.950 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:55.950) \n",
      "10-20 18:27:55.962 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:55.961) \n",
      "10-20 18:27:55.971 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.076 (Wall: 20-Oct 18:27:55.971) \n",
      "10-20 18:27:55.974 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 1. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:55.974) \n",
      "10-20 18:27:56.009 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:56.009) \n",
      "10-20 18:27:56.011 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:56.011) \n",
      "10-20 18:27:56.034 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.060 (Wall: 20-Oct 18:27:56.034) \n",
      "10-20 18:27:56.041 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 2. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:56.041) \n",
      "10-20 18:27:56.064 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:56.064) \n",
      "10-20 18:27:56.076 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:56.076) \n",
      "10-20 18:27:56.094 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.060 (Wall: 20-Oct 18:27:56.094) \n",
      "10-20 18:27:56.095 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 3. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:56.095) \n",
      "10-20 18:27:56.125 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:56.125) \n",
      "10-20 18:27:56.134 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:56.134) \n",
      "10-20 18:27:56.141 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:56.141) \n",
      "10-20 18:27:56.145 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 4. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:56.145) \n",
      "10-20 18:27:56.164 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:56.164) \n",
      "10-20 18:27:56.166 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.182 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:56.182) \n",
      "10-20 18:27:56.184 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.195 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:56.195) \n",
      "10-20 18:27:56.196 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.202 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_432\n",
      "10-20 18:27:56.202 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 5. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:56.202) \n",
      "10-20 18:27:56.203 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.214 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_433\n",
      "10-20 18:27:56.219 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_434\n",
      "10-20 18:27:56.222 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_435\n",
      "10-20 18:27:56.229 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_432\n",
      "10-20 18:27:56.238 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_433\n",
      "10-20 18:27:56.246 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_435\n",
      "10-20 18:27:56.254 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_434\n",
      "10-20 18:27:56.264 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_437\n",
      "10-20 18:27:56.267 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_438\n",
      "10-20 18:27:56.275 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_438\n",
      "10-20 18:27:56.278 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_437\n",
      "10-20 18:27:56.280 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_439\n",
      "10-20 18:27:56.291 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_436\n",
      "10-20 18:27:56.295 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_439\n",
      "10-20 18:27:56.307 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_436\n",
      "10-20 18:27:56.313 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:56.313) \n",
      "10-20 18:27:56.314 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:56.314) \n",
      "10-20 18:27:56.349 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:56.349) \n",
      "10-20 18:27:56.355 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:56.355) \n",
      "10-20 18:27:56.356 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:56.356) \n",
      "10-20 18:27:56.357 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 6. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:56.357) \n",
      "10-20 18:27:56.387 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:56.397 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:56.396) \n",
      "10-20 18:27:56.399 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:56.399) \n",
      "10-20 18:27:56.409 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:56.409) \n",
      "10-20 18:27:56.419 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 7. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:56.419) \n",
      "10-20 18:27:56.439 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:56.439) \n",
      "10-20 18:27:56.451 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:56.451) \n",
      "10-20 18:27:56.471 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:56.471) \n",
      "10-20 18:27:56.488 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 8. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:56.488) \n",
      "10-20 18:27:56.495 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:56.495) \n",
      "10-20 18:27:56.496 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.521 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:56.521) \n",
      "10-20 18:27:56.525 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.531 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:56.531) \n",
      "10-20 18:27:56.541 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_440\n",
      "10-20 18:27:56.545 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 9. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:56.545) \n",
      "10-20 18:27:56.565 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_441\n",
      "10-20 18:27:56.586 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:56.586) \n",
      "10-20 18:27:56.587 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.594 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 10. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:56.594) \n",
      "10-20 18:27:56.595 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_441\n",
      "10-20 18:27:56.595 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.596 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_440\n",
      "10-20 18:27:56.619 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_442\n",
      "10-20 18:27:56.626 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_443\n",
      "10-20 18:27:56.632 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_444\n",
      "10-20 18:27:56.637 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_442\n",
      "10-20 18:27:56.642 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_445\n",
      "10-20 18:27:56.646 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_444\n",
      "10-20 18:27:56.650 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_443\n",
      "10-20 18:27:56.671 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_445\n",
      "10-20 18:27:56.687 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:56.687) \n",
      "10-20 18:27:56.694 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_447\n",
      "10-20 18:27:56.703 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_446\n",
      "10-20 18:27:56.716 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:56.716) \n",
      "10-20 18:27:56.719 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_447\n",
      "10-20 18:27:56.728 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:56.728) \n",
      "10-20 18:27:56.743 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_446\n",
      "10-20 18:27:56.768 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:56.768) \n",
      "10-20 18:27:56.768 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:56.768) \n",
      "10-20 18:27:56.779 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:56.779) \n",
      "10-20 18:27:56.810 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:56.810) \n",
      "10-20 18:27:56.813 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 11. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:56.813) \n",
      "10-20 18:27:56.823 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:56.823) \n",
      "10-20 18:27:56.847 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:56.847) \n",
      "10-20 18:27:56.865 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 12. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:56.865) \n",
      "█10-20 18:27:56.867 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:56.867) \n",
      "10-20 18:27:56.894 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:56.894) \n",
      "10-20 18:27:56.901 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.929 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:56.929) \n",
      "10-20 18:27:56.947 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 13. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:56.947) \n",
      "10-20 18:27:56.949 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_448\n",
      "10-20 18:27:56.953 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.086 (Wall: 20-Oct 18:27:56.953) \n",
      "10-20 18:27:56.955 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:56.969 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:56.987 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_449\n",
      "10-20 18:27:56.990 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_448\n",
      "10-20 18:27:56.992 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:56.992) \n",
      "10-20 18:27:57.006 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_449\n",
      "10-20 18:27:57.032 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 14. tree was built in 00:00:00.085 (Wall: 20-Oct 18:27:57.032) \n",
      "10-20 18:27:57.033 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_450\n",
      "10-20 18:27:57.049 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_450\n",
      "10-20 18:27:57.057 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:57.057) \n",
      "10-20 18:27:57.061 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.090 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_451\n",
      "10-20 18:27:57.092 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 15. tree was built in 00:00:00.060 (Wall: 20-Oct 18:27:57.092) \n",
      "10-20 18:27:57.093 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.098 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:57.098) \n",
      "10-20 18:27:57.110 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_452\n",
      "10-20 18:27:57.117 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_451\n",
      "10-20 18:27:57.123 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_453\n",
      "10-20 18:27:57.135 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.037 (Wall: 20-Oct 18:27:57.135) \n",
      "10-20 18:27:57.155 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_452\n",
      "10-20 18:27:57.159 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_453\n",
      "10-20 18:27:57.165 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:57.165) \n",
      "10-20 18:27:57.193 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:57.193) \n",
      "10-20 18:27:57.198 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_454\n",
      "10-20 18:27:57.208 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_454\n",
      "10-20 18:27:57.213 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:57.213) \n",
      "10-20 18:27:57.231 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:57.231) \n",
      "10-20 18:27:57.232 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_455\n",
      "10-20 18:27:57.256 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_455\n",
      "10-20 18:27:57.261 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:57.261) \n",
      "10-20 18:27:57.267 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:57.267) \n",
      "10-20 18:27:57.277 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:57.277) \n",
      "10-20 18:27:57.278 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.300 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:57.300) \n",
      "10-20 18:27:57.304 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 16. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:57.304) \n",
      "10-20 18:27:57.325 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_456\n",
      "10-20 18:27:57.337 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:57.337) \n",
      "10-20 18:27:57.347 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 17. tree was built in 00:00:00.043 (Wall: 20-Oct 18:27:57.347) \n",
      "10-20 18:27:57.353 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:57.353) \n",
      "10-20 18:27:57.354 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.386 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_457\n",
      "10-20 18:27:57.392 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_456\n",
      "10-20 18:27:57.404 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:57.404) \n",
      "10-20 18:27:57.409 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_457\n",
      "10-20 18:27:57.425 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 18. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:57.425) \n",
      "10-20 18:27:57.441 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_458\n",
      "10-20 18:27:57.461 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_458\n",
      "10-20 18:27:57.471 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_459\n",
      "10-20 18:27:57.484 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.080 (Wall: 20-Oct 18:27:57.484) \n",
      "10-20 18:27:57.491 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 19. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:57.491) \n",
      "10-20 18:27:57.497 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_459\n",
      "10-20 18:27:57.528 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.056 (Wall: 20-Oct 18:27:57.528) \n",
      "10-20 18:27:57.555 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.071 (Wall: 20-Oct 18:27:57.555) \n",
      "10-20 18:27:57.558 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.560 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:57.560) \n",
      "10-20 18:27:57.561 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 20. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:57.561) \n",
      "10-20 18:27:57.564 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.598 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_460\n",
      "10-20 18:27:57.599 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_461\n",
      "10-20 18:27:57.611 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:57.611) \n",
      "10-20 18:27:57.623 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.063 (Wall: 20-Oct 18:27:57.623) \n",
      "10-20 18:27:57.633 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_460\n",
      "10-20 18:27:57.654 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:57.654) \n",
      "10-20 18:27:57.665 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_461\n",
      "10-20 18:27:57.665 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_462\n",
      "10-20 18:27:57.681 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:57.681) \n",
      "10-20 18:27:57.699 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:57.699) \n",
      "10-20 18:27:57.707 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_462\n",
      "10-20 18:27:57.733 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_463\n",
      "10-20 18:27:57.735 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:57.735) \n",
      "10-20 18:27:57.738 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:57.738) \n",
      "10-20 18:27:57.740 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.752 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_463\n",
      "10-20 18:27:57.761 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.045 (Wall: 20-Oct 18:27:57.761) \n",
      "10-20 18:27:57.763 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_464\n",
      "10-20 18:27:57.783 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:57.783) \n",
      "10-20 18:27:57.786 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:57.787 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_464\n",
      "10-20 18:27:57.793 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "█10-20 18:27:57.830 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:57.830) \n",
      "10-20 18:27:57.835 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_465\n",
      "10-20 18:27:57.841 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_466\n",
      "10-20 18:27:57.854 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 21. tree was built in 00:00:00.097 (Wall: 20-Oct 18:27:57.854) \n",
      "10-20 18:27:57.864 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_465\n",
      "10-20 18:27:57.864 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_466\n",
      "10-20 18:27:57.878 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:57.878) \n",
      "10-20 18:27:57.895 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 22. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:57.894) \n",
      "10-20 18:27:57.920 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:57.920) \n",
      "10-20 18:27:57.925 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:57.925) \n",
      "10-20 18:27:57.935 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 23. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:57.934) \n",
      "10-20 18:27:57.937 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_467\n",
      "10-20 18:27:57.961 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_467\n",
      "10-20 18:27:57.967 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 24. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:57.967) \n",
      "10-20 18:27:57.974 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:57.974) \n",
      "10-20 18:27:58.016 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:58.016) \n",
      "10-20 18:27:58.017 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.096 (Wall: 20-Oct 18:27:58.017) \n",
      "10-20 18:27:58.019 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.020 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:58.020) \n",
      "10-20 18:27:58.034 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 25. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:58.034) \n",
      "10-20 18:27:58.035 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.043 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_468\n",
      "10-20 18:27:58.062 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:58.062) \n",
      "10-20 18:27:58.065 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_469\n",
      "10-20 18:27:58.065 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_468\n",
      "10-20 18:27:58.065 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:58.065) \n",
      "10-20 18:27:58.084 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_469\n",
      "10-20 18:27:58.117 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_470\n",
      "10-20 18:27:58.120 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:58.120) \n",
      "10-20 18:27:58.120 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.057 (Wall: 20-Oct 18:27:58.120) \n",
      "10-20 18:27:58.121 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.136 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_471\n",
      "10-20 18:27:58.140 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_470\n",
      "10-20 18:27:58.142 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_472\n",
      "10-20 18:27:58.157 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_471\n",
      "10-20 18:27:58.171 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:58.171) \n",
      "10-20 18:27:58.180 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_472\n",
      "10-20 18:27:58.192 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:58.192) \n",
      "10-20 18:27:58.225 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:58.225) \n",
      "10-20 18:27:58.226 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.263 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 26. tree was built in 00:00:00.101 (Wall: 20-Oct 18:27:58.263) \n",
      "10-20 18:27:58.269 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_473\n",
      "10-20 18:27:58.290 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_474\n",
      "10-20 18:27:58.299 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_473\n",
      "10-20 18:27:58.303 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.37226296018515975, 0.3378396233333172, 0.3199312153243731, 0.3101409559650236]\n",
      "10-20 18:27:58.303 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.37226296018515975 --> 0.3101409559650236 (still improving).\n",
      "10-20 18:27:58.311 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.119 (Wall: 20-Oct 18:27:58.311) \n",
      "10-20 18:27:58.326 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 27. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:58.326) \n",
      "10-20 18:27:58.338 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_474\n",
      "10-20 18:27:58.363 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.060 (Wall: 20-Oct 18:27:58.363) \n",
      "10-20 18:27:58.375 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.064 (Wall: 20-Oct 18:27:58.375) \n",
      "10-20 18:27:58.430 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 28. tree was built in 00:00:00.104 (Wall: 20-Oct 18:27:58.430) \n",
      "10-20 18:27:58.437 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_475\n",
      "10-20 18:27:58.452 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_475\n",
      "10-20 18:27:58.457 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.37456317654273263, 0.3368016244358795, 0.31645808103494816, 0.30444125366622]\n",
      "10-20 18:27:58.457 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.082 (Wall: 20-Oct 18:27:58.457) \n",
      "10-20 18:27:58.457 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.37456317654273263 --> 0.30444125366622 (still improving).\n",
      "10-20 18:27:58.470 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.107 (Wall: 20-Oct 18:27:58.470) \n",
      "10-20 18:27:58.479 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 29. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:58.479) \n",
      "10-20 18:27:58.523 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.066 (Wall: 20-Oct 18:27:58.523) \n",
      "10-20 18:27:58.524 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.532 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.062 (Wall: 20-Oct 18:27:58.532) \n",
      "10-20 18:27:58.553 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.096 (Wall: 20-Oct 18:27:58.553) \n",
      "10-20 18:27:58.556 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_476\n",
      "10-20 18:27:58.562 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 30. tree was built in 00:00:00.083 (Wall: 20-Oct 18:27:58.562) \n",
      "10-20 18:27:58.566 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.582 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_476\n",
      "10-20 18:27:58.585 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_477\n",
      "10-20 18:27:58.600 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_477\n",
      "10-20 18:27:58.604 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:58.604) \n",
      "10-20 18:27:58.622 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.069 (Wall: 20-Oct 18:27:58.622) \n",
      "10-20 18:27:58.626 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_478\n",
      "10-20 18:27:58.639 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_479\n",
      "10-20 18:27:58.653 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:58.653) \n",
      "10-20 18:27:58.654 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.659 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_478\n",
      "10-20 18:27:58.662 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_479\n",
      "10-20 18:27:58.664 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.36829536543632885, 0.33214475436400964, 0.3134441316389072, 0.3033334382173673]\n",
      "10-20 18:27:58.664 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.36829536543632885 --> 0.3033334382173673 (still improving).\n",
      "10-20 18:27:58.670 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3653696439918444, 0.32750532896272716, 0.30668112376072804, 0.29511866010129306]\n",
      "10-20 18:27:58.670 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.3653696439918444 --> 0.29511866010129306 (still improving).\n",
      "10-20 18:27:58.675 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.053 (Wall: 20-Oct 18:27:58.675) \n",
      "10-20 18:27:58.680 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_480\n",
      "10-20 18:27:58.694 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_480\n",
      "10-20 18:27:58.697 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:58.697) \n",
      "10-20 18:27:58.715 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:58.715) \n",
      "10-20 18:27:58.719 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_481\n",
      "10-20 18:27:58.722 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 31. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:58.722) \n",
      "10-20 18:27:58.752 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:58.752) \n",
      "10-20 18:27:58.754 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_481\n",
      "10-20 18:27:58.754 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 32. tree was built in 00:00:00.032 (Wall: 20-Oct 18:27:58.754) \n",
      "10-20 18:27:58.757 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3378396233333172, 0.3199312153243731, 0.3101409559650236, 0.30402336960477605]\n",
      "10-20 18:27:58.757 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3378396233333172 --> 0.30402336960477605 (still improving).\n",
      "10-20 18:27:58.762 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:58.762) \n",
      "10-20 18:27:58.762 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.784 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_482\n",
      "10-20 18:27:58.790 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:58.790) \n",
      "10-20 18:27:58.791 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 33. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:58.790) \n",
      "10-20 18:27:58.807 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "10-20 18:27:58.816 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:58.816) \n",
      "10-20 18:27:58.824 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.033 (Wall: 20-Oct 18:27:58.824) \n",
      "10-20 18:27:58.831 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 34. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:58.831) \n",
      "10-20 18:27:58.847 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_482\n",
      "10-20 18:27:58.857 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.041 (Wall: 20-Oct 18:27:58.857) \n",
      "10-20 18:27:58.876 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_483\n",
      "10-20 18:27:58.878 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:58.878) \n",
      "10-20 18:27:58.882 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.892 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_483\n",
      "10-20 18:27:58.896 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3368016244358795, 0.31645808103494816, 0.30444125366622, 0.2967018243527491]\n",
      "10-20 18:27:58.900 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.3368016244358795 --> 0.2967018243527491 (still improving).\n",
      "10-20 18:27:58.907 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 35. tree was built in 00:00:00.076 (Wall: 20-Oct 18:27:58.907) \n",
      "10-20 18:27:58.908 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:58.925 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_484\n",
      "10-20 18:27:58.926 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:58.924) \n",
      "10-20 18:27:58.925 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_485\n",
      "10-20 18:27:58.952 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:58.952) \n",
      "10-20 18:27:58.966 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_484\n",
      "10-20 18:27:58.975 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:58.975) \n",
      "10-20 18:27:58.981 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_485\n",
      "10-20 18:27:59.003 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:59.003) \n",
      "10-20 18:27:59.015 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:59.015) \n",
      "10-20 18:27:59.016 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.016 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_486\n",
      "10-20 18:27:59.024 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_487\n",
      "10-20 18:27:59.035 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_487\n",
      "10-20 18:27:59.038 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.33214475436400964, 0.3134441316389072, 0.3033334382173673, 0.29653698505207354]\n",
      "10-20 18:27:59.038 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.33214475436400964 --> 0.29653698505207354 (still improving).\n",
      "10-20 18:27:59.049 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:59.049) \n",
      "10-20 18:27:59.052 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_486\n",
      "10-20 18:27:59.054 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_488\n",
      "10-20 18:27:59.055 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.32750532896272716, 0.30668112376072804, 0.29511866010129306, 0.287843131218122]\n",
      "10-20 18:27:59.055 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.32750532896272716 --> 0.287843131218122 (still improving).\n",
      "10-20 18:27:59.078 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_488\n",
      "10-20 18:27:59.089 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:59.088) \n",
      "10-20 18:27:59.097 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:59.097) \n",
      "10-20 18:27:59.099 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 36. tree was built in 00:00:00.061 (Wall: 20-Oct 18:27:59.099) \n",
      "10-20 18:27:59.130 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_489\n",
      "10-20 18:27:59.133 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.044 (Wall: 20-Oct 18:27:59.133) \n",
      "10-20 18:27:59.134 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.144 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_489\n",
      "10-20 18:27:59.146 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:59.146) \n",
      "10-20 18:27:59.147 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 37. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:59.147) \n",
      "10-20 18:27:59.151 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3199312153243731, 0.3101409559650236, 0.30402336960477605, 0.29975780787171713]\n",
      "10-20 18:27:59.151 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3199312153243731 --> 0.29975780787171713 (still improving).\n",
      "10-20 18:27:59.166 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_490\n",
      "10-20 18:27:59.181 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_490\n",
      "10-20 18:27:59.182 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:59.182) \n",
      "10-20 18:27:59.184 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 38. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:59.184) \n",
      "10-20 18:27:59.203 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.052 (Wall: 20-Oct 18:27:59.203) \n",
      "10-20 18:27:59.223 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.038 (Wall: 20-Oct 18:27:59.223) \n",
      "10-20 18:27:59.231 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 39. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:59.230) \n",
      "10-20 18:27:59.238 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:59.238) \n",
      "10-20 18:27:59.243 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_491\n",
      "10-20 18:27:59.255 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_491\n",
      "10-20 18:27:59.258 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:59.258) \n",
      "10-20 18:27:59.259 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.260 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.31645808103494816, 0.30444125366622, 0.2967018243527491, 0.2915159612441636]\n",
      "10-20 18:27:59.260 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.31645808103494816 --> 0.2915159612441636 (still improving).\n",
      "10-20 18:27:59.285 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_492\n",
      "10-20 18:27:59.293 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:59.293) \n",
      "10-20 18:27:59.298 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 40. tree was built in 00:00:00.067 (Wall: 20-Oct 18:27:59.298) \n",
      "10-20 18:27:59.299 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.310 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_492\n",
      "10-20 18:27:59.315 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.055 (Wall: 20-Oct 18:27:59.315) \n",
      "10-20 18:27:59.323 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Starting model Quantiles_model_1697826262527_493\n",
      "10-20 18:27:59.343 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_494\n",
      "10-20 18:27:59.344 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.029 (Wall: 20-Oct 18:27:59.344) \n",
      "10-20 18:27:59.351 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:59.351) \n",
      "10-20 18:27:59.361 172.17.0.2:54321      22766      FJ-4-7  INFO water.default: Completing model Quantiles_model_1697826262527_493\n",
      "10-20 18:27:59.374 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_494\n",
      "10-20 18:27:59.379 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3134441316389072, 0.3033334382173673, 0.29653698505207354, 0.292065268400544]\n",
      "10-20 18:27:59.379 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.3134441316389072 --> 0.292065268400544 (still improving).\n",
      "10-20 18:27:59.380 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.036 (Wall: 20-Oct 18:27:59.380) \n",
      "10-20 18:27:59.401 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.050 (Wall: 20-Oct 18:27:59.401) \n",
      "10-20 18:27:59.402 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.414 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:59.414) \n",
      "10-20 18:27:59.418 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_495\n",
      "10-20 18:27:59.426 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Starting model Quantiles_model_1697826262527_496\n",
      "10-20 18:27:59.428 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_495\n",
      "10-20 18:27:59.431 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.051 (Wall: 20-Oct 18:27:59.431) \n",
      "10-20 18:27:59.432 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.30668112376072804, 0.29511866010129306, 0.287843131218122, 0.28311806987217486]\n",
      "10-20 18:27:59.432 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.30668112376072804 --> 0.28311806987217486 (still improving).\n",
      "10-20 18:27:59.453 172.17.0.2:54321      22766      FJ-4-5  INFO water.default: Completing model Quantiles_model_1697826262527_496\n",
      "10-20 18:27:59.456 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.042 (Wall: 20-Oct 18:27:59.456) \n",
      "10-20 18:27:59.479 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.048 (Wall: 20-Oct 18:27:59.479) \n",
      "10-20 18:27:59.480 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.497 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 41. tree was built in 00:00:00.065 (Wall: 20-Oct 18:27:59.497) \n",
      "10-20 18:27:59.499 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Starting model Quantiles_model_1697826262527_497\n",
      "10-20 18:27:59.505 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.049 (Wall: 20-Oct 18:27:59.505) \n",
      "10-20 18:27:59.513 172.17.0.2:54321      22766     FJ-4-11  INFO water.default: Completing model Quantiles_model_1697826262527_497\n",
      "10-20 18:27:59.522 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3101409559650236, 0.30402336960477605, 0.29975780787171713, 0.2966594095843955]\n",
      "10-20 18:27:59.522 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Checking convergence with logloss metric: 0.3101409559650236 --> 0.2966594095843955 (still improving).\n",
      "10-20 18:27:59.529 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_498\n",
      "10-20 18:27:59.537 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 42. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:59.537) \n",
      "10-20 18:27:59.540 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.035 (Wall: 20-Oct 18:27:59.540) \n",
      "10-20 18:27:59.551 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_498\n",
      "10-20 18:27:59.580 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.040 (Wall: 20-Oct 18:27:59.580) \n",
      "10-20 18:27:59.581 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.593 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_499\n",
      "10-20 18:27:59.594 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.072 (Wall: 20-Oct 18:27:59.594) \n",
      "10-20 18:27:59.606 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_499\n",
      "10-20 18:27:59.615 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 43. tree was built in 00:00:00.078 (Wall: 20-Oct 18:27:59.615) \n",
      "10-20 18:27:59.620 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Starting model Quantiles_model_1697826262527_500\n",
      "10-20 18:27:59.633 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Starting model Quantiles_model_1697826262527_501\n",
      "10-20 18:27:59.640 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 47. tree was built in 00:00:00.046 (Wall: 20-Oct 18:27:59.640) \n",
      "10-20 18:27:59.649 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 44. tree was built in 00:00:00.034 (Wall: 20-Oct 18:27:59.649) \n",
      "10-20 18:27:59.655 172.17.0.2:54321      22766      FJ-4-1  INFO water.default: Completing model Quantiles_model_1697826262527_501\n",
      "10-20 18:27:59.659 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.3033334382173673, 0.29653698505207354, 0.292065268400544, 0.288643895845532]\n",
      "10-20 18:27:59.659 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Checking convergence with logloss metric: 0.3033334382173673 --> 0.288643895845532 (still improving).\n",
      "10-20 18:27:59.674 172.17.0.2:54321      22766     FJ-4-13  INFO water.default: Completing model Quantiles_model_1697826262527_500\n",
      "10-20 18:27:59.683 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.30444125366622, 0.2967018243527491, 0.2915159612441636, 0.2877921044098615]\n",
      "10-20 18:27:59.684 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Checking convergence with logloss metric: 0.30444125366622 --> 0.2877921044098615 (still improving).\n",
      "10-20 18:27:59.694 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 48. tree was built in 00:00:00.054 (Wall: 20-Oct 18:27:59.694) \n",
      "10-20 18:27:59.696 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 45. tree was built in 00:00:00.047 (Wall: 20-Oct 18:27:59.696) \n",
      "10-20 18:27:59.697 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: ============================================================== \n",
      "10-20 18:27:59.717 172.17.0.2:54321      22766      FJ-3-1  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.058 (Wall: 20-Oct 18:27:59.717) \n",
      "10-20 18:27:59.721 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Starting model Quantiles_model_1697826262527_502\n",
      "10-20 18:27:59.722 172.17.0.2:54321      22766      FJ-4-3  INFO water.default: Completing model Quantiles_model_1697826262527_502\n",
      "10-20 18:27:59.733 172.17.0.2:54321      22766      FJ-3-7  INFO hex.tree.SharedTree: 49. tree was built in 00:00:00.039 (Wall: 20-Oct 18:27:59.733) \n",
      "10-20 18:27:59.740 172.17.0.2:54321      22766      FJ-3-1  INFO water.default: Completing model GBM_2_AutoML_1_20231020_182658_cv_4\n",
      "10-20 18:27:59.749 172.17.0.2:54321      22766      FJ-3-7  INFO water.default: Completing model GBM_2_AutoML_1_20231020_182658_cv_3\n",
      "10-20 18:27:59.753 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Starting model Quantiles_model_1697826262527_503\n",
      "10-20 18:27:59.753 172.17.0.2:54321      22766     FJ-4-15  INFO water.default: Completing model Quantiles_model_1697826262527_503\n",
      "10-20 18:27:59.754 172.17.0.2:54321      22766      FJ-3-3  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.070 (Wall: 20-Oct 18:27:59.754) \n",
      "10-20 18:27:59.756 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Windowed averages (window size 3) of model's last 4 logloss metrics: [0.29511866010129306, 0.287843131218122, 0.28311806987217486, 0.27959179586598976]\n",
      "10-20 18:27:59.757 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Checking convergence with logloss metric: 0.29511866010129306 --> 0.27959179586598976 (still improving).\n",
      "10-20 18:27:59.757 172.17.0.2:54321      22766      FJ-3-3  INFO water.default: Completing model GBM_2_AutoML_1_20231020_182658_cv_1\n",
      "10-20 18:27:59.757 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Exception from CV model #0 will be reported as main exception.\n",
      "10-20 18:27:59.757 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 0 / 5.\n",
      "10-20 18:27:59.784 172.17.0.2:54321      22766      FJ-3-5  INFO hex.tree.SharedTree: 46. tree was built in 00:00:00.027 (Wall: 20-Oct 18:27:59.784) \n",
      "10-20 18:27:59.787 172.17.0.2:54321      22766      FJ-3-5  INFO water.default: Completing model GBM_2_AutoML_1_20231020_182658_cv_2\n",
      "10-20 18:27:59.788 172.17.0.2:54321      22766      FJ-2-3  WARN hex.CVModelBuilder: CV model #1 failed, the exception will not be reported\n",
      "water.Job$JobCancelledException\n",
      "\tat hex.tree.SharedTree$Driver.scoreAndBuildTrees(SharedTree.java:532)\n",
      "\tat hex.tree.SharedTree$Driver.computeImpl(SharedTree.java:405)\n",
      "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:253)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1677)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "10-20 18:27:59.793 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 1 / 5.\n",
      "10-20 18:27:59.793 172.17.0.2:54321      22766      FJ-2-3  WARN hex.CVModelBuilder: CV model #2 failed, the exception will not be reported\n",
      "water.Job$JobCancelledException\n",
      "\tat hex.tree.SharedTree$Driver.scoreAndBuildTrees(SharedTree.java:532)\n",
      "\tat hex.tree.SharedTree$Driver.computeImpl(SharedTree.java:405)\n",
      "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:253)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1677)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "10-20 18:27:59.794 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 2 / 5.\n",
      "10-20 18:27:59.794 172.17.0.2:54321      22766      FJ-2-3  WARN hex.CVModelBuilder: CV model #3 failed, the exception will not be reported\n",
      "water.Job$JobCancelledException\n",
      "\tat hex.tree.SharedTree$Driver.scoreAndBuildTrees(SharedTree.java:532)\n",
      "\tat hex.tree.SharedTree$Driver.computeImpl(SharedTree.java:405)\n",
      "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:253)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1677)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "10-20 18:27:59.795 172.17.0.2:54321      22766      FJ-2-3  INFO hex.CVModelBuilder: Completed cross-validation model 3 / 5.\n",
      "10-20 18:27:59.796 172.17.0.2:54321      22766      FJ-2-3  WARN water.default: Model training job GBM def_2 completed with exception: water.Job$JobCancelledException\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: ModelTraining: GBM_2_AutoML_1_20231020_182658 [GBM def_2] cancelled\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML step returned with state: StepResultState{_id='GBM:def_2', _status=cancelled}\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Workflow: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}]\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Workflow: AutoML build stopped: 2023.10.20 18:27:59.797\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Workflow: AutoML build done: built 3 models\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Workflow: AutoML duration:  1 min  1.079 sec\n",
      "10-20 18:27:59.797 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: AutoML run summary:\n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.631 INFO  Workflow         Project: AutoML_1_20231020_182658  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.649 INFO  Validation       Setting stopping tolerance adaptively based on the training frame: 0.005541803630764712  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.649 INFO  Validation       Build control seed: 42  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       training frame: Frame key: AutoML_1_20231020_182658_training_py_9_sid_88b4    cols: 14    rows: 32561  chunks: 1    size: 472097  checksum: 2962903763109092816  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       validation frame: NULL  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       leaderboard frame: NULL  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       blending frame: NULL  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       response column: label  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       fold column: null  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.650 INFO  DataImport       weights column: null  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.668 INFO  Workflow         Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.703 INFO  Workflow         Disabling Algo: StackedEnsemble as requested by the user.  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.703 INFO  Workflow         Disabling Algo: DRF as requested by the user.  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.703 INFO  Workflow         Disabling Algo: GLM as requested by the user.  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.703 INFO  Workflow         Disabling Algo: DeepLearning as requested by the user.  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.703 DEBUG Workflow         Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{resume_best_grids, virtual, Dynamic, group=6, weight=60}, Work{lr_search, XGBoost, Selection, group=7, weight=30}, Work{lr_annealing, GBM, Selection, group=7, weight=10}]  \n",
      "10-20 18:27:59.798 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.703 DEBUG Workflow         Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{resume_best_grids, virtual, Dynamic, group=6, weight=60}, Work{lr_search, XGBoost, Selection, group=7, weight=30}, Work{lr_annealing, GBM, Selection, group=7, weight=10}]  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.710 INFO  Workflow         AutoML job created: 2023.10.20 18:26:58.588 creation_epoch 1697826419\n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.724 INFO  Workflow         AutoML build started: 2023.10.20 18:26:58.718 start_epoch 1697826419\n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.756 DEBUG ModelTraining    No time limitation for XGBoost_1_AutoML_1_20231020_182658  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.756 INFO  ModelTraining    AutoML: starting XGBoost_1_AutoML_1_20231020_182658 model training start_XGBoost_def_2 1697826419\n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:26:58.770 DEBUG ModelTraining    XGBoost_1_AutoML_1_20231020_182658 [XGBoost def_2] started  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:15.997 DEBUG ModelTraining    XGBoost_1_AutoML_1_20231020_182658 [XGBoost def_2] complete  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:15.998 DEBUG ModelTraining    Adding model XGBoost_1_AutoML_1_20231020_182658 to leaderboard Leaderboard_AutoML_1_20231020_182658@@label. Training time: model=3s, total=17s  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:16.48  INFO  ModelTraining    New leader: XGBoost_1_AutoML_1_20231020_182658, auc: 0.9205608851530974  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:16.55  DEBUG ModelTraining    No time limitation for GBM_1_AutoML_1_20231020_182658  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:16.56  INFO  ModelTraining    AutoML: starting GBM_1_AutoML_1_20231020_182658 model training start_GBM_def_5 1697826436\n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:16.68  DEBUG ModelTraining    GBM_1_AutoML_1_20231020_182658 [GBM def_5] started  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:40.840 DEBUG ModelTraining    GBM_1_AutoML_1_20231020_182658 [GBM def_5] complete  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:40.840 DEBUG ModelTraining    Adding model GBM_1_AutoML_1_20231020_182658 to leaderboard Leaderboard_AutoML_1_20231020_182658@@label. Training time: model=4s, total=25s  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:40.843 INFO  ModelTraining    New leader: GBM_1_AutoML_1_20231020_182658, auc: 0.9246906817908851  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:40.845 DEBUG ModelTraining    No time limitation for XGBoost_2_AutoML_1_20231020_182658  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:40.845 INFO  ModelTraining    AutoML: starting XGBoost_2_AutoML_1_20231020_182658 model training start_XGBoost_def_1 1697826461\n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:40.847 DEBUG ModelTraining    XGBoost_2_AutoML_1_20231020_182658 [XGBoost def_1] started  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:55.696 DEBUG ModelTraining    XGBoost_2_AutoML_1_20231020_182658 [XGBoost def_1] complete  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:55.696 DEBUG ModelTraining    Adding model XGBoost_2_AutoML_1_20231020_182658 to leaderboard Leaderboard_AutoML_1_20231020_182658@@label. Training time: model=2s, total=15s  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:55.699 DEBUG ModelTraining    No time limitation for GBM_2_AutoML_1_20231020_182658  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:55.699 INFO  ModelTraining    AutoML: starting GBM_2_AutoML_1_20231020_182658 model training start_GBM_def_2 1697826476\n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:55.701 DEBUG ModelTraining    GBM_2_AutoML_1_20231020_182658 [GBM def_2] started  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.702 DEBUG ModelTraining    AutoML: out of time; skipping GBM_2_AutoML_1_20231020_182658 [GBM def_2]  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 INFO  ModelTraining    GBM_2_AutoML_1_20231020_182658 [GBM def_2] cancelled  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping GBM def_3  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping GBM def_4  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping XGBoost def_3  \n",
      "10-20 18:27:59.799 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping DRF XRT (Extremely Randomized Trees)  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping GBM def_1  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping DeepLearning def_1  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping XGBoost grid_1  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping GBM grid_1  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping DeepLearning grid_1  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping DeepLearning grid_2  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping DeepLearning grid_3  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping completion resume_best_grids  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping XGBoost lr_search  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping GBM lr_annealing  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping StackedEnsemble monotonic (built with AUTO metalearner, using monotonically constrained AutoML models)  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 DEBUG ModelTraining    AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 INFO  Workflow         Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}]  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 INFO  Workflow         AutoML build stopped: 2023.10.20 18:27:59.797 stop_epoch 1697826480\n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 INFO  Workflow         AutoML build done: built 3 models  \n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 18:27:59.797 INFO  Workflow         AutoML duration:  1 min  1.079 sec duration_secs 61\n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Leaderboard for project AutoML_1_20231020_182658@@label (models sorted in order of auc, best first):\n",
      "10-20 18:27:59.800 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: #                            model_id       auc   logloss     aucpr  mean_per_class_error      rmse       mse\n",
      "10-20 18:27:59.801 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 0  GBM_1_AutoML_1_20231020_182658      0.924691  0.285989  0.819320              0.169888  0.301272  0.090765\n",
      "10-20 18:27:59.801 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 1  XGBoost_2_AutoML_1_20231020_182658  0.922906  0.288096  0.818240              0.178437  0.302476  0.091492\n",
      "10-20 18:27:59.801 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 2  XGBoost_1_AutoML_1_20231020_182658  0.920561  0.293746  0.811266              0.177030  0.305881  0.093563\n",
      "█| (done) 100%\n",
      "10-20 18:28:00.063 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {verbosity=debug}\n",
      "\n",
      "18:27:59.702: AutoML: out of time; skipping GBM_2_AutoML_1_20231020_182658 [GBM def_2]\n",
      "18:27:59.797: GBM_2_AutoML_1_20231020_182658 [GBM def_2] cancelled\n",
      "18:27:59.797: AutoML: out of time; skipping GBM def_3\n",
      "18:27:59.797: AutoML: out of time; skipping GBM def_4\n",
      "18:27:59.797: AutoML: out of time; skipping XGBoost def_3\n",
      "18:27:59.797: AutoML: out of time; skipping DRF XRT (Extremely Randomized Trees)\n",
      "18:27:59.797: AutoML: out of time; skipping GBM def_1\n",
      "18:27:59.797: AutoML: out of time; skipping DeepLearning def_1\n",
      "18:27:59.797: AutoML: out of time; skipping XGBoost grid_1\n",
      "18:27:59.797: AutoML: out of time; skipping GBM grid_1\n",
      "18:27:59.797: AutoML: out of time; skipping DeepLearning grid_1\n",
      "18:27:59.797: AutoML: out of time; skipping DeepLearning grid_2\n",
      "18:27:59.797: AutoML: out of time; skipping DeepLearning grid_3\n",
      "18:27:59.797: AutoML: out of time; skipping completion resume_best_grids\n",
      "18:27:59.797: AutoML: out of time; skipping XGBoost lr_search\n",
      "18:27:59.797: AutoML: out of time; skipping GBM lr_annealing\n",
      "18:27:59.797: AutoML: out of time; skipping StackedEnsemble monotonic (built with AUTO metalearner, using monotonically constrained AutoML models)\n",
      "18:27:59.797: AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)\n",
      "18:27:59.797: AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)\n",
      "18:27:59.797: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}]\n",
      "18:27:59.797: AutoML build stopped: 2023.10.20 18:27:59.797\n",
      "18:27:59.797: AutoML build done: built 3 models\n",
      "18:27:59.797: AutoML duration:  1 min  1.079 sec\n",
      "18:27:59.801: Verifying training frame immutability. . .\n",
      "18:27:59.801: Training frame was not mutated (as expected).\n",
      "\n",
      "10-20 18:28:00.080 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /99/AutoML/AutoML_1_20231020_182658@@label, parms: {}\n",
      "10-20 18:28:00.088 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Models/GBM_1_AutoML_1_20231020_182658, parms: {}\n",
      "10-20 18:28:00.241 172.17.0.2:54321      22766  4648757-70  INFO water.default: Reading byte InputStream into Frame:\n",
      "10-20 18:28:00.242 172.17.0.2:54321      22766  4648757-70  INFO water.default:     frameKey:    upload_b9e615146b8c6c87398099ceae8a42c3\n",
      "10-20 18:28:00.242 172.17.0.2:54321      22766  4648757-70  INFO water.default:     totalChunks: 1\n",
      "10-20 18:28:00.242 172.17.0.2:54321      22766  4648757-70  INFO water.default:     totalBytes:  546\n",
      "10-20 18:28:00.255 172.17.0.2:54321      22766  4648757-70  INFO water.default:     Success.\n",
      "10-20 18:28:00.263 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /3/ParseSetup, parms: {source_frames=[\"upload_b9e615146b8c6c87398099ceae8a42c3\"], single_quotes=False, check_header=1, separator=44}\n",
      "10-20 18:28:00.562 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /3/Parse, parms: {chunk_size=4194304, single_quotes=False, delete_on_done=True, parse_type=CSV, check_header=1, separator=44, escapechar=0, column_types=[\"string\",\"string\",\"double\",\"double\",\"double\",\"double\",\"double\",\"double\"], destination_frame=AutoML_1_20231020_182658_leaderboard, blocking=False, source_frames=[\"upload_b9e615146b8c6c87398099ceae8a42c3\"], number_columns=8, column_names=[\"\",\"model_id\",\"auc\",\"logloss\",\"aucpr\",\"mean_per_class_error\",\"rmse\",\"mse\"]}\n",
      "10-20 18:28:00.572 172.17.0.2:54321      22766  4648757-67  INFO water.default: Total file size:  546  B\n",
      "10-20 18:28:00.572 172.17.0.2:54321      22766  4648757-67  INFO water.default: Parse chunk size 4194304\n",
      "10-20 18:28:00.603 172.17.0.2:54321      22766      FJ-2-3  INFO water.default: Key upload_b9e615146b8c6c87398099ceae8a42c3 will be parsed using method DistributedParse.\n",
      "10-20 18:28:00.624 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Parse result for AutoML_1_20231020_182658_leaderboard (3 rows, 8 columns):\n",
      "10-20 18:28:00.641 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                 ColV2    type          min          max         mean        sigma         NAs constant cardinality\n",
      "10-20 18:28:00.642 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                    C1:  string                                                                                \n",
      "10-20 18:28:00.642 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:              model_id:  string                                                                                \n",
      "10-20 18:28:00.643 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                   auc: numeric     0.920561     0.924691     0.922719   0.00207122                            \n",
      "10-20 18:28:00.644 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:               logloss: numeric     0.285989     0.293746     0.289277   0.00401083                            \n",
      "10-20 18:28:00.644 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                 aucpr: numeric     0.811266     0.819320     0.816275   0.00437155                            \n",
      "10-20 18:28:00.644 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:  mean_per_class_error: numeric     0.169888     0.178437     0.175119   0.00458388                            \n",
      "10-20 18:28:00.645 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                  rmse: numeric     0.301272     0.305881     0.303210   0.00239089                            \n",
      "10-20 18:28:00.645 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                   mse: numeric    0.0907647    0.0935635    0.0919399   0.00145227                            \n",
      "10-20 18:28:00.646 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Chunk compression summary:\n",
      "10-20 18:28:00.646 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:   Chunk Type    Chunk Name       Count  Count Percentage        Size  Size Percentage\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:         CStr       Strings           2          25.000 %      277  B         33.414 %\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:          C8D  64-bit Reals           6          75.000 %      552  B         66.586 %\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Frame distribution summary:\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                         Size  Number of Rows  Number of Chunks per Column  Number of Chunks\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 172.17.0.2:54321      829  B               3                            1                 8\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:             mean      829  B        3.000000                     1.000000          8.000000\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:              min      829  B        3.000000                     1.000000          8.000000\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:              max      829  B        3.000000                     1.000000          8.000000\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:           stddev        0  B        0.000000                     0.000000          0.000000\n",
      "10-20 18:28:00.647 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:            total      829  B               3                            1                 8\n",
      "10-20 18:28:00.819 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/AutoML_1_20231020_182658_leaderboard, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:28:00.842 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_10_sid_88b4 (cols_py AutoML_1_20231020_182658_leaderboard [1:7])), session_id=_sid_88b4}\n",
      "10-20 18:28:00.864 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(assign 'AutoML_1_20231020_182658_leaderboard' py_10_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:28:00.876 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_10_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:28:00.893 172.17.0.2:54321      22766  4648757-70  INFO water.default: Reading byte InputStream into Frame:\n",
      "10-20 18:28:00.893 172.17.0.2:54321      22766  4648757-70  INFO water.default:     frameKey:    upload_b85ef847287620fc8039ee1014974c20\n",
      "10-20 18:28:00.893 172.17.0.2:54321      22766  4648757-70  INFO water.default:     totalChunks: 1\n",
      "10-20 18:28:00.893 172.17.0.2:54321      22766  4648757-70  INFO water.default:     totalBytes:  9186\n",
      "10-20 18:28:00.894 172.17.0.2:54321      22766  4648757-70  INFO water.default:     Success.\n",
      "10-20 18:28:00.899 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /3/ParseSetup, parms: {source_frames=[\"upload_b85ef847287620fc8039ee1014974c20\"], single_quotes=False, check_header=1, separator=44}\n",
      "10-20 18:28:00.969 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /3/Parse, parms: {chunk_size=4194304, single_quotes=False, delete_on_done=True, parse_type=CSV, check_header=1, separator=44, escapechar=0, column_types=[\"string\",\"string\",\"string\",\"string\",\"string\",\"string\",\"string\"], destination_frame=AutoML_1_20231020_182658_eventlog, blocking=False, source_frames=[\"upload_b85ef847287620fc8039ee1014974c20\"], number_columns=7, column_names=[\"\",\"timestamp\",\"level\",\"stage\",\"message\",\"name\",\"value\"]}\n",
      "10-20 18:28:00.970 172.17.0.2:54321      22766  4648757-70  INFO water.default: Total file size: 9.0 KB\n",
      "10-20 18:28:00.970 172.17.0.2:54321      22766  4648757-70  INFO water.default: Parse chunk size 4194304\n",
      "10-20 18:28:00.971 172.17.0.2:54321      22766      FJ-2-7  INFO water.default: Key upload_b85ef847287620fc8039ee1014974c20 will be parsed using method DistributedParse.\n",
      "10-20 18:28:00.988 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Parse result for AutoML_1_20231020_182658_eventlog (64 rows, 7 columns):\n",
      "10-20 18:28:00.991 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:      ColV2    type          min          max         mean        sigma         NAs constant cardinality\n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:         C1:  string                                                                                \n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:  timestamp:  string                                                                                \n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:      level:  string                                                                                \n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:      stage:  string                                                                                \n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:    message:  string                                                                                \n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:       name:  string                                                                                \n",
      "10-20 18:28:00.992 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:      value:  string                                                                                \n",
      "10-20 18:28:00.993 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Chunk compression summary:\n",
      "10-20 18:28:00.993 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:   Chunk Type  Chunk Name       Count  Count Percentage        Size  Size Percentage\n",
      "10-20 18:28:00.993 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:         CStr     Strings           7         100.000 %     10.2 KB        100.000 %\n",
      "10-20 18:28:00.993 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: Frame distribution summary:\n",
      "10-20 18:28:00.993 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:                         Size  Number of Rows  Number of Chunks per Column  Number of Chunks\n",
      "10-20 18:28:00.994 172.17.0.2:54321      22766      FJ-1-7  INFO water.default: 172.17.0.2:54321     10.2 KB              64                            1                 7\n",
      "10-20 18:28:00.994 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:             mean     10.2 KB       64.000000                     1.000000          7.000000\n",
      "10-20 18:28:00.994 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:              min     10.2 KB       64.000000                     1.000000          7.000000\n",
      "10-20 18:28:00.994 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:              max     10.2 KB       64.000000                     1.000000          7.000000\n",
      "10-20 18:28:00.994 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:           stddev        0  B        0.000000                     0.000000          0.000000\n",
      "10-20 18:28:00.994 172.17.0.2:54321      22766      FJ-1-7  INFO water.default:            total     10.2 KB              64                            1                 7\n",
      "10-20 18:28:01.193 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /3/Frames/AutoML_1_20231020_182658_eventlog, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:28:01.223 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_11_sid_88b4 (cols_py AutoML_1_20231020_182658_eventlog [1:6])), session_id=_sid_88b4}\n",
      "10-20 18:28:01.248 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(assign 'AutoML_1_20231020_182658_eventlog' py_11_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:28:01.258 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_11_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:28:01.263 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /3/Frames/AutoML_1_20231020_182658_eventlog, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:28:01.337 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_12_sid_88b4 (rows (cols_py AutoML_1_20231020_182658_eventlog ['name' 'value']) (!= (cols_py AutoML_1_20231020_182658_eventlog 'name') ''))), session_id=_sid_88b4}\n",
      "10-20 18:28:01.358 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_12_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:28:01.363 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /3/Models/GBM_1_AutoML_1_20231020_182658, parms: {}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: GBM_1_AutoML_1_20231020_182658\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th>\n",
       "<th>number_of_internal_trees</th>\n",
       "<th>model_size_in_bytes</th>\n",
       "<th>min_depth</th>\n",
       "<th>max_depth</th>\n",
       "<th>mean_depth</th>\n",
       "<th>min_leaves</th>\n",
       "<th>max_leaves</th>\n",
       "<th>mean_leaves</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>72.0</td>\n",
       "<td>72.0</td>\n",
       "<td>116356.0</td>\n",
       "<td>15.0</td>\n",
       "<td>15.0</td>\n",
       "<td>15.0</td>\n",
       "<td>39.0</td>\n",
       "<td>191.0</td>\n",
       "<td>120.19444</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.07499008289803473\n",
       "RMSE: 0.2738431720858395\n",
       "LogLoss: 0.23889571105783058\n",
       "Mean Per-Class Error: 0.14244552377780226\n",
       "AUC: 0.9514336309556976\n",
       "AUCPR: 0.8749514407177378\n",
       "Gini: 0.9028672619113951</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3881431172229534</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>22665.0</td>\n",
       "<td>2055.0</td>\n",
       "<td>0.0831</td>\n",
       "<td> (2055.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1582.0</td>\n",
       "<td>6259.0</td>\n",
       "<td>0.2018</td>\n",
       "<td> (1582.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>24247.0</td>\n",
       "<td>8314.0</td>\n",
       "<td>0.1117</td>\n",
       "<td> (3637.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3881431</td>\n",
       "<td>0.7748685</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1904882</td>\n",
       "<td>0.8448426</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5957142</td>\n",
       "<td>0.8090894</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4578943</td>\n",
       "<td>0.8923559</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0101622</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4199531</td>\n",
       "<td>0.7019311</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2946177</td>\n",
       "<td>0.8717000</td>\n",
       "<td>241.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2487023</td>\n",
       "<td>0.8753788</td>\n",
       "<td>260.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946796</td>\n",
       "<td>24720.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946796</td>\n",
       "<td>7775.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0012164</td>\n",
       "<td>24720.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0101622</td>\n",
       "<td>7841.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946796</td>\n",
       "<td>0.9915827</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0012164</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0101622</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.08 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9909478</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928232</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0415763</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9873610</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9892439</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9910336</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0831527</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0831527</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9826722</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9852002</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9890931</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.1246015</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.1246015</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9750012</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9793438</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9866539</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.1661778</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.1661778</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9574821</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1501099</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9681042</td>\n",
       "<td>0.9993861</td>\n",
       "<td>0.9829417</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.2076266</td>\n",
       "<td>313.9920882</td>\n",
       "<td>315.0109892</td>\n",
       "<td>0.2075861</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7894574</td>\n",
       "<td>3.8924802</td>\n",
       "<td>4.0213346</td>\n",
       "<td>0.9373464</td>\n",
       "<td>0.8701897</td>\n",
       "<td>0.9683758</td>\n",
       "<td>0.9265830</td>\n",
       "<td>0.1946180</td>\n",
       "<td>0.4022446</td>\n",
       "<td>289.2480213</td>\n",
       "<td>302.1334602</td>\n",
       "<td>0.3980779</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6511950</td>\n",
       "<td>3.2267284</td>\n",
       "<td>3.7565201</td>\n",
       "<td>0.7770270</td>\n",
       "<td>0.7202185</td>\n",
       "<td>0.9046059</td>\n",
       "<td>0.8578089</td>\n",
       "<td>0.1613315</td>\n",
       "<td>0.5635761</td>\n",
       "<td>222.6728354</td>\n",
       "<td>275.6520074</td>\n",
       "<td>0.5447249</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5191145</td>\n",
       "<td>2.5099610</td>\n",
       "<td>3.4449282</td>\n",
       "<td>0.6044226</td>\n",
       "<td>0.5834808</td>\n",
       "<td>0.8295716</td>\n",
       "<td>0.7892374</td>\n",
       "<td>0.1254942</td>\n",
       "<td>0.6890703</td>\n",
       "<td>150.9961028</td>\n",
       "<td>244.4928161</td>\n",
       "<td>0.6441674</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3043034</td>\n",
       "<td>1.7383521</td>\n",
       "<td>2.8761277</td>\n",
       "<td>0.4186118</td>\n",
       "<td>0.4027787</td>\n",
       "<td>0.6925990</td>\n",
       "<td>0.6604310</td>\n",
       "<td>0.1738299</td>\n",
       "<td>0.8629001</td>\n",
       "<td>73.8352074</td>\n",
       "<td>187.6127697</td>\n",
       "<td>0.7414196</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1584669</td>\n",
       "<td>0.9131769</td>\n",
       "<td>2.3854277</td>\n",
       "<td>0.2199017</td>\n",
       "<td>0.2269236</td>\n",
       "<td>0.5744338</td>\n",
       "<td>0.5520625</td>\n",
       "<td>0.0913149</td>\n",
       "<td>0.9542150</td>\n",
       "<td>-8.6823122</td>\n",
       "<td>138.5427669</td>\n",
       "<td>0.7299836</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0722390</td>\n",
       "<td>0.3264990</td>\n",
       "<td>1.9736672</td>\n",
       "<td>0.0786241</td>\n",
       "<td>0.1111587</td>\n",
       "<td>0.4752779</td>\n",
       "<td>0.4638872</td>\n",
       "<td>0.0326489</td>\n",
       "<td>0.9868639</td>\n",
       "<td>-67.3501004</td>\n",
       "<td>97.3667226</td>\n",
       "<td>0.6412733</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0312478</td>\n",
       "<td>0.1045817</td>\n",
       "<td>1.6621689</td>\n",
       "<td>0.0251843</td>\n",
       "<td>0.0486476</td>\n",
       "<td>0.4002662</td>\n",
       "<td>0.3946841</td>\n",
       "<td>0.0104578</td>\n",
       "<td>0.9973218</td>\n",
       "<td>-89.5418290</td>\n",
       "<td>66.2168918</td>\n",
       "<td>0.5233331</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0143291</td>\n",
       "<td>0.0216816</td>\n",
       "<td>1.4278239</td>\n",
       "<td>0.0052211</td>\n",
       "<td>0.0214481</td>\n",
       "<td>0.3438336</td>\n",
       "<td>0.3413670</td>\n",
       "<td>0.0021681</td>\n",
       "<td>0.9994899</td>\n",
       "<td>-97.8318426</td>\n",
       "<td>42.7823865</td>\n",
       "<td>0.3944737</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0072545</td>\n",
       "<td>0.0051015</td>\n",
       "<td>1.2499904</td>\n",
       "<td>0.0012285</td>\n",
       "<td>0.0103919</td>\n",
       "<td>0.3010096</td>\n",
       "<td>0.2999967</td>\n",
       "<td>0.0005101</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.4898453</td>\n",
       "<td>24.9990403</td>\n",
       "<td>0.2634304</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000031</td>\n",
       "<td>0.0034743</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111073</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051790</td>\n",
       "<td>0.2675653</td>\n",
       "<td>0.2672403</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1107320</td>\n",
       "<td>0.1317152</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003635</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0024043</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.2407575</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.09076467337180787\n",
       "RMSE: 0.3012717599971957\n",
       "LogLoss: 0.28598910685141826\n",
       "Mean Per-Class Error: 0.16988825283166362\n",
       "AUC: 0.9246906817908851\n",
       "AUCPR: 0.819319713891667\n",
       "Gini: 0.8493813635817702</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>21923.0</td>\n",
       "<td>2797.0</td>\n",
       "<td>0.1131</td>\n",
       "<td> (2797.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1777.0</td>\n",
       "<td>6064.0</td>\n",
       "<td>0.2266</td>\n",
       "<td> (1777.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23700.0</td>\n",
       "<td>8861.0</td>\n",
       "<td>0.1405</td>\n",
       "<td> (4574.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3552160</td>\n",
       "<td>0.7261406</td>\n",
       "<td>214.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1400254</td>\n",
       "<td>0.8035536</td>\n",
       "<td>302.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6142915</td>\n",
       "<td>0.7559369</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5160227</td>\n",
       "<td>0.8702435</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0028543</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4035434</td>\n",
       "<td>0.6358758</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2624334</td>\n",
       "<td>0.8375405</td>\n",
       "<td>249.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2419123</td>\n",
       "<td>0.8395175</td>\n",
       "<td>257.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9947330</td>\n",
       "<td>24720.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9947330</td>\n",
       "<td>7759.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0014753</td>\n",
       "<td>24720.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0028543</td>\n",
       "<td>7841.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9947330</td>\n",
       "<td>0.9895422</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0014753</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0028543</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.00 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9914024</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931894</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931894</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0415763</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9872966</td>\n",
       "<td>4.1271827</td>\n",
       "<td>4.1399209</td>\n",
       "<td>0.9938650</td>\n",
       "<td>0.9894588</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9913241</td>\n",
       "<td>0.0413213</td>\n",
       "<td>0.0828976</td>\n",
       "<td>312.7182663</td>\n",
       "<td>313.9920882</td>\n",
       "<td>0.0828167</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9812125</td>\n",
       "<td>4.1143269</td>\n",
       "<td>4.1314070</td>\n",
       "<td>0.9907692</td>\n",
       "<td>0.9845142</td>\n",
       "<td>0.9948823</td>\n",
       "<td>0.9890588</td>\n",
       "<td>0.0410662</td>\n",
       "<td>0.1239638</td>\n",
       "<td>311.4326862</td>\n",
       "<td>313.1407006</td>\n",
       "<td>0.1237615</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9707915</td>\n",
       "<td>4.1271827</td>\n",
       "<td>4.1303501</td>\n",
       "<td>0.9938650</td>\n",
       "<td>0.9767070</td>\n",
       "<td>0.9946278</td>\n",
       "<td>0.9859685</td>\n",
       "<td>0.0413213</td>\n",
       "<td>0.1652850</td>\n",
       "<td>312.7182663</td>\n",
       "<td>313.0350110</td>\n",
       "<td>0.1650019</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9504264</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1322654</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9622305</td>\n",
       "<td>0.9950890</td>\n",
       "<td>0.9812180</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.2067338</td>\n",
       "<td>313.9920882</td>\n",
       "<td>313.2265439</td>\n",
       "<td>0.2064102</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7849150</td>\n",
       "<td>3.5353719</td>\n",
       "<td>3.8339103</td>\n",
       "<td>0.8513514</td>\n",
       "<td>0.8627023</td>\n",
       "<td>0.9232422</td>\n",
       "<td>0.9219783</td>\n",
       "<td>0.1767632</td>\n",
       "<td>0.3834970</td>\n",
       "<td>253.5371936</td>\n",
       "<td>283.3910320</td>\n",
       "<td>0.3733837</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6403136</td>\n",
       "<td>2.8747216</td>\n",
       "<td>3.5142462</td>\n",
       "<td>0.6922604</td>\n",
       "<td>0.7134062</td>\n",
       "<td>0.8462641</td>\n",
       "<td>0.8524685</td>\n",
       "<td>0.1437317</td>\n",
       "<td>0.5272287</td>\n",
       "<td>187.4721625</td>\n",
       "<td>251.4246206</td>\n",
       "<td>0.4968484</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5106238</td>\n",
       "<td>2.3671177</td>\n",
       "<td>3.2275081</td>\n",
       "<td>0.5700246</td>\n",
       "<td>0.5762666</td>\n",
       "<td>0.7772148</td>\n",
       "<td>0.7834287</td>\n",
       "<td>0.1183523</td>\n",
       "<td>0.6455809</td>\n",
       "<td>136.7117718</td>\n",
       "<td>222.7508116</td>\n",
       "<td>0.5868835</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3014894</td>\n",
       "<td>1.6503504</td>\n",
       "<td>2.7018427</td>\n",
       "<td>0.3974201</td>\n",
       "<td>0.4011178</td>\n",
       "<td>0.6506295</td>\n",
       "<td>0.6560047</td>\n",
       "<td>0.1650300</td>\n",
       "<td>0.8106109</td>\n",
       "<td>65.0350392</td>\n",
       "<td>170.1842690</td>\n",
       "<td>0.6725445</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1602280</td>\n",
       "<td>0.9833231</td>\n",
       "<td>2.2722458</td>\n",
       "<td>0.2367936</td>\n",
       "<td>0.2265763</td>\n",
       "<td>0.5471785</td>\n",
       "<td>0.5486559</td>\n",
       "<td>0.0983293</td>\n",
       "<td>0.9089402</td>\n",
       "<td>-1.6676853</td>\n",
       "<td>127.2245789</td>\n",
       "<td>0.6703480</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0750068</td>\n",
       "<td>0.5458655</td>\n",
       "<td>1.9269909</td>\n",
       "<td>0.1314496</td>\n",
       "<td>0.1134429</td>\n",
       "<td>0.4640378</td>\n",
       "<td>0.4616186</td>\n",
       "<td>0.0545849</td>\n",
       "<td>0.9635251</td>\n",
       "<td>-45.4134492</td>\n",
       "<td>92.6990940</td>\n",
       "<td>0.6105315</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0324734</td>\n",
       "<td>0.2180911</td>\n",
       "<td>1.6421889</td>\n",
       "<td>0.0525184</td>\n",
       "<td>0.0508273</td>\n",
       "<td>0.3954548</td>\n",
       "<td>0.3931569</td>\n",
       "<td>0.0218084</td>\n",
       "<td>0.9853335</td>\n",
       "<td>-78.1908874</td>\n",
       "<td>64.2188883</td>\n",
       "<td>0.5075422</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0152883</td>\n",
       "<td>0.0982048</td>\n",
       "<td>1.4216294</td>\n",
       "<td>0.0236486</td>\n",
       "<td>0.0225705</td>\n",
       "<td>0.3423419</td>\n",
       "<td>0.3402183</td>\n",
       "<td>0.0098202</td>\n",
       "<td>0.9951537</td>\n",
       "<td>-90.1795224</td>\n",
       "<td>42.1629402</td>\n",
       "<td>0.3887621</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0075502</td>\n",
       "<td>0.0357108</td>\n",
       "<td>1.2483962</td>\n",
       "<td>0.0085995</td>\n",
       "<td>0.0109297</td>\n",
       "<td>0.3006257</td>\n",
       "<td>0.2990588</td>\n",
       "<td>0.0035710</td>\n",
       "<td>0.9987247</td>\n",
       "<td>-96.4289172</td>\n",
       "<td>24.8396231</td>\n",
       "<td>0.2617505</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000031</td>\n",
       "<td>0.0035946</td>\n",
       "<td>0.0102031</td>\n",
       "<td>1.1108239</td>\n",
       "<td>0.0024570</td>\n",
       "<td>0.0053519</td>\n",
       "<td>0.2674970</td>\n",
       "<td>0.2664258</td>\n",
       "<td>0.0010203</td>\n",
       "<td>0.9997449</td>\n",
       "<td>-98.9796906</td>\n",
       "<td>11.0823910</td>\n",
       "<td>0.1313792</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003254</td>\n",
       "<td>0.0025508</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0006143</td>\n",
       "<td>0.0025178</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.2400358</td>\n",
       "<td>0.0002551</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.7449227</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8601089</td>\n",
       "<td>0.0044925</td>\n",
       "<td>0.8565945</td>\n",
       "<td>0.8571867</td>\n",
       "<td>0.8567261</td>\n",
       "<td>0.8653256</td>\n",
       "<td>0.8647113</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9245689</td>\n",
       "<td>0.0045425</td>\n",
       "<td>0.9281911</td>\n",
       "<td>0.9266950</td>\n",
       "<td>0.9169862</td>\n",
       "<td>0.9237955</td>\n",
       "<td>0.9271767</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1398912</td>\n",
       "<td>0.0044925</td>\n",
       "<td>0.1434055</td>\n",
       "<td>0.1428133</td>\n",
       "<td>0.1432740</td>\n",
       "<td>0.1346744</td>\n",
       "<td>0.1352887</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>911.0</td>\n",
       "<td>29.2831</td>\n",
       "<td>934.0</td>\n",
       "<td>930.0</td>\n",
       "<td>933.0</td>\n",
       "<td>877.0</td>\n",
       "<td>881.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7012632</td>\n",
       "<td>0.0115764</td>\n",
       "<td>0.7013696</td>\n",
       "<td>0.6881533</td>\n",
       "<td>0.6912776</td>\n",
       "<td>0.7130832</td>\n",
       "<td>0.7124323</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7275420</td>\n",
       "<td>0.0129064</td>\n",
       "<td>0.7373453</td>\n",
       "<td>0.7181818</td>\n",
       "<td>0.7106976</td>\n",
       "<td>0.7300708</td>\n",
       "<td>0.7414147</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.756029</td>\n",
       "<td>0.0189628</td>\n",
       "<td>0.7772113</td>\n",
       "<td>0.7509506</td>\n",
       "<td>0.7312405</td>\n",
       "<td>0.7478875</td>\n",
       "<td>0.7728552</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.154737</td>\n",
       "<td>0.1031931</td>\n",
       "<td>4.005535</td>\n",
       "<td>4.2562094</td>\n",
       "<td>4.236825</td>\n",
       "<td>4.174359</td>\n",
       "<td>4.1007557</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2862227</td>\n",
       "<td>0.0061799</td>\n",
       "<td>0.2837649</td>\n",
       "<td>0.2790983</td>\n",
       "<td>0.2956500</td>\n",
       "<td>0.2881814</td>\n",
       "<td>0.2844188</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2236025</td>\n",
       "<td>0.0248165</td>\n",
       "<td>0.1937269</td>\n",
       "<td>0.2254902</td>\n",
       "<td>0.2543917</td>\n",
       "<td>0.2397436</td>\n",
       "<td>0.2046600</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.6363711</td>\n",
       "<td>0.0145571</td>\n",
       "<td>0.6441514</td>\n",
       "<td>0.6261857</td>\n",
       "<td>0.6169552</td>\n",
       "<td>0.6414377</td>\n",
       "<td>0.6531257</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8314466</td>\n",
       "<td>0.0093553</td>\n",
       "<td>0.8398052</td>\n",
       "<td>0.8285435</td>\n",
       "<td>0.8183318</td>\n",
       "<td>0.8293406</td>\n",
       "<td>0.8412119</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1685534</td>\n",
       "<td>0.0093553</td>\n",
       "<td>0.1601947</td>\n",
       "<td>0.1714565</td>\n",
       "<td>0.1816682</td>\n",
       "<td>0.1706593</td>\n",
       "<td>0.1587881</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0908619</td>\n",
       "<td>0.0017549</td>\n",
       "<td>0.0901266</td>\n",
       "<td>0.0889858</td>\n",
       "<td>0.0934920</td>\n",
       "<td>0.0916711</td>\n",
       "<td>0.0900341</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.8190482</td>\n",
       "<td>0.0109963</td>\n",
       "<td>0.8347300</td>\n",
       "<td>0.8194151</td>\n",
       "<td>0.8051474</td>\n",
       "<td>0.8133871</td>\n",
       "<td>0.8225615</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6848409</td>\n",
       "<td>0.0131621</td>\n",
       "<td>0.6792746</td>\n",
       "<td>0.6694915</td>\n",
       "<td>0.6789100</td>\n",
       "<td>0.7021906</td>\n",
       "<td>0.6943375</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5027688</td>\n",
       "<td>0.0144230</td>\n",
       "<td>0.5188814</td>\n",
       "<td>0.5049439</td>\n",
       "<td>0.4815146</td>\n",
       "<td>0.4967821</td>\n",
       "<td>0.5117221</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7763975</td>\n",
       "<td>0.0248165</td>\n",
       "<td>0.8062730</td>\n",
       "<td>0.7745098</td>\n",
       "<td>0.7456083</td>\n",
       "<td>0.7602564</td>\n",
       "<td>0.7953401</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3014219</td>\n",
       "<td>0.0029039</td>\n",
       "<td>0.3002109</td>\n",
       "<td>0.2983049</td>\n",
       "<td>0.3057647</td>\n",
       "<td>0.3027724</td>\n",
       "<td>0.3000568</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8864957</td>\n",
       "<td>0.0093800</td>\n",
       "<td>0.8733374</td>\n",
       "<td>0.8825773</td>\n",
       "<td>0.8910553</td>\n",
       "<td>0.8984249</td>\n",
       "<td>0.8870837</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-10-20 18:27:36</td>\n",
       "<td>20.514 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4275749</td>\n",
       "<td>0.5520113</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2408096</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7591904</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:36</td>\n",
       "<td>20.884 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3580666</td>\n",
       "<td>0.4139024</td>\n",
       "<td>0.9231494</td>\n",
       "<td>0.8119101</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1419797</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.111 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3250431</td>\n",
       "<td>0.3518230</td>\n",
       "<td>0.9274531</td>\n",
       "<td>0.8224114</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1421639</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.338 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.3101333</td>\n",
       "<td>0.3198260</td>\n",
       "<td>0.9293457</td>\n",
       "<td>0.8274675</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1381714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.617 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.3008138</td>\n",
       "<td>0.2977300</td>\n",
       "<td>0.9326196</td>\n",
       "<td>0.8341006</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1341482</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.843 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2960021</td>\n",
       "<td>0.2850261</td>\n",
       "<td>0.9348525</td>\n",
       "<td>0.8383497</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1340868</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:38</td>\n",
       "<td>22.070 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2919021</td>\n",
       "<td>0.2753741</td>\n",
       "<td>0.9375426</td>\n",
       "<td>0.8442169</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1300943</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:38</td>\n",
       "<td>22.330 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2887171</td>\n",
       "<td>0.2682057</td>\n",
       "<td>0.9398145</td>\n",
       "<td>0.8490477</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1257640</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:38</td>\n",
       "<td>22.888 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2859562</td>\n",
       "<td>0.2622116</td>\n",
       "<td>0.9418439</td>\n",
       "<td>0.8537178</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1244126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.154 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2838987</td>\n",
       "<td>0.2576104</td>\n",
       "<td>0.9433872</td>\n",
       "<td>0.8571123</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1214336</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.394 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2819706</td>\n",
       "<td>0.2535553</td>\n",
       "<td>0.9448745</td>\n",
       "<td>0.8604069</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1192224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.650 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.2802449</td>\n",
       "<td>0.2500008</td>\n",
       "<td>0.9462984</td>\n",
       "<td>0.8633119</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1181168</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.929 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.2781576</td>\n",
       "<td>0.2464724</td>\n",
       "<td>0.9479604</td>\n",
       "<td>0.8671609</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1157827</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:40</td>\n",
       "<td>24.275 sec</td>\n",
       "<td>65.0</td>\n",
       "<td>0.2762984</td>\n",
       "<td>0.2431486</td>\n",
       "<td>0.9494307</td>\n",
       "<td>0.8705289</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1142778</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:40</td>\n",
       "<td>24.485 sec</td>\n",
       "<td>70.0</td>\n",
       "<td>0.2745972</td>\n",
       "<td>0.2401383</td>\n",
       "<td>0.9507812</td>\n",
       "<td>0.8735590</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1141857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:40</td>\n",
       "<td>24.609 sec</td>\n",
       "<td>72.0</td>\n",
       "<td>0.2738432</td>\n",
       "<td>0.2388957</td>\n",
       "<td>0.9514336</td>\n",
       "<td>0.8749514</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1116980</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>relationship</td>\n",
       "<td>4602.7446289</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2862720</td></tr>\n",
       "<tr><td>capital_gain</td>\n",
       "<td>3140.7709961</td>\n",
       "<td>0.6823692</td>\n",
       "<td>0.1953432</td></tr>\n",
       "<tr><td>education</td>\n",
       "<td>2609.7946777</td>\n",
       "<td>0.5670084</td>\n",
       "<td>0.1623186</td></tr>\n",
       "<tr><td>occupation</td>\n",
       "<td>1140.8848877</td>\n",
       "<td>0.2478706</td>\n",
       "<td>0.0709584</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>1114.5206299</td>\n",
       "<td>0.2421426</td>\n",
       "<td>0.0693187</td></tr>\n",
       "<tr><td>marital_status</td>\n",
       "<td>1045.3726807</td>\n",
       "<td>0.2271194</td>\n",
       "<td>0.0650179</td></tr>\n",
       "<tr><td>capital_loss</td>\n",
       "<td>740.7708740</td>\n",
       "<td>0.1609411</td>\n",
       "<td>0.0460729</td></tr>\n",
       "<tr><td>hours_per_week</td>\n",
       "<td>622.1322021</td>\n",
       "<td>0.1351655</td>\n",
       "<td>0.0386941</td></tr>\n",
       "<tr><td>workclass</td>\n",
       "<td>353.1838379</td>\n",
       "<td>0.0767333</td>\n",
       "<td>0.0219666</td></tr>\n",
       "<tr><td>fnlwgt</td>\n",
       "<td>329.3720703</td>\n",
       "<td>0.0715599</td>\n",
       "<td>0.0204856</td></tr>\n",
       "<tr><td>native_country</td>\n",
       "<td>275.4145508</td>\n",
       "<td>0.0598370</td>\n",
       "<td>0.0171297</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>65.1697006</td>\n",
       "<td>0.0141589</td>\n",
       "<td>0.0040533</td></tr>\n",
       "<tr><td>race</td>\n",
       "<td>38.0887489</td>\n",
       "<td>0.0082752</td>\n",
       "<td>0.0023690</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: GBM_1_AutoML_1_20231020_182658\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    72                 72                          116356                 15           15           15            39            191           120.194\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.07499008289803473\n",
       "RMSE: 0.2738431720858395\n",
       "LogLoss: 0.23889571105783058\n",
       "Mean Per-Class Error: 0.14244552377780226\n",
       "AUC: 0.9514336309556976\n",
       "AUCPR: 0.8749514407177378\n",
       "Gini: 0.9028672619113951\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3881431172229534\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      22665  2055  0.0831   (2055.0/24720.0)\n",
       "1      1582   6259  0.2018   (1582.0/7841.0)\n",
       "Total  24247  8314  0.1117   (3637.0/32561.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.388143     0.774868  204\n",
       "max f2                       0.190488     0.844843  284\n",
       "max f0point5                 0.595714     0.809089  134\n",
       "max accuracy                 0.457894     0.892356  181\n",
       "max precision                0.99468      1         0\n",
       "max recall                   0.0101622    1         386\n",
       "max specificity              0.99468      1         0\n",
       "max absolute_mcc             0.419953     0.701931  192\n",
       "max min_per_class_accuracy   0.294618     0.8717    241\n",
       "max mean_per_class_accuracy  0.248702     0.875379  260\n",
       "max tns                      0.99468      24720     0\n",
       "max fns                      0.99468      7775      0\n",
       "max fps                      0.00121637   24720     399\n",
       "max tps                      0.0101622    7841      386\n",
       "max tnr                      0.99468      1         0\n",
       "max fnr                      0.99468      0.991583  0\n",
       "max fpr                      0.00121637   1         399\n",
       "max tpr                      0.0101622    1         386\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.08 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010012                    0.990948           4.15266     4.15266            1                0.992823    1                           0.992823            0.0415763       0.0415763                  315.266   315.266            0.0415763\n",
       "2        0.020024                    0.987361           4.15266     4.15266            1                0.989244    1                           0.991034            0.0415763       0.0831527                  315.266   315.266            0.0831527\n",
       "3        0.0300052                   0.982672           4.15266     4.15266            1                0.9852      1                           0.989093            0.0414488       0.124601                   315.266   315.266            0.124601\n",
       "4        0.0400172                   0.975001           4.15266     4.15266            1                0.979344    1                           0.986654            0.0415763       0.166178                   315.266   315.266            0.166178\n",
       "5        0.0500292                   0.957482           4.13992     4.15011            0.996933         0.968104    0.999386                    0.982942            0.0414488       0.207627                   313.992   315.011            0.207586\n",
       "6        0.100028                    0.789457           3.89248     4.02133            0.937346         0.87019     0.968376                    0.926583            0.194618        0.402245                   289.248   302.133            0.398078\n",
       "7        0.150026                    0.651195           3.22673     3.75652            0.777027         0.720218    0.904606                    0.857809            0.161331        0.563576                   222.673   275.652            0.544725\n",
       "8        0.200025                    0.519115           2.50996     3.44493            0.604423         0.583481    0.829572                    0.789237            0.125494        0.68907                    150.996   244.493            0.644167\n",
       "9        0.300021                    0.304303           1.73835     2.87613            0.418612         0.402779    0.692599                    0.660431            0.17383         0.8629                     73.8352   187.613            0.74142\n",
       "10       0.400018                    0.158467           0.913177    2.38543            0.219902         0.226924    0.574434                    0.552062            0.0913149       0.954215                   -8.68231  138.543            0.729984\n",
       "11       0.500015                    0.072239           0.326499    1.97367            0.0786241        0.111159    0.475278                    0.463887            0.0326489       0.986864                   -67.3501  97.3667            0.641273\n",
       "12       0.600012                    0.0312478          0.104582    1.66217            0.0251843        0.0486476   0.400266                    0.394684            0.0104578       0.997322                   -89.5418  66.2169            0.523333\n",
       "13       0.700009                    0.0143291          0.0216816   1.42782            0.00522113       0.0214481   0.343834                    0.341367            0.00216809      0.99949                    -97.8318  42.7824            0.394474\n",
       "14       0.800006                    0.00725448         0.00510155  1.24999            0.0012285        0.0103919   0.30101                     0.299997            0.000510139     1                          -99.4898  24.999             0.26343\n",
       "15       0.900003                    0.00347433         0           1.11111            0                0.00517905  0.267565                    0.26724             0               1                          -100      11.1107            0.131715\n",
       "16       1                           0.000363483        0           1                  0                0.00240433  0.24081                     0.240758            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.09076467337180787\n",
       "RMSE: 0.3012717599971957\n",
       "LogLoss: 0.28598910685141826\n",
       "Mean Per-Class Error: 0.16988825283166362\n",
       "AUC: 0.9246906817908851\n",
       "AUCPR: 0.819319713891667\n",
       "Gini: 0.8493813635817702\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      21923  2797  0.1131   (2797.0/24720.0)\n",
       "1      1777   6064  0.2266   (1777.0/7841.0)\n",
       "Total  23700  8861  0.1405   (4574.0/32561.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.355216     0.726141  214\n",
       "max f2                       0.140025     0.803554  302\n",
       "max f0point5                 0.614291     0.755937  125\n",
       "max accuracy                 0.516023     0.870244  157\n",
       "max precision                0.994733     1         0\n",
       "max recall                   0.00285428   1         396\n",
       "max specificity              0.994733     1         0\n",
       "max absolute_mcc             0.403543     0.635876  197\n",
       "max min_per_class_accuracy   0.262433     0.83754   249\n",
       "max mean_per_class_accuracy  0.241912     0.839518  257\n",
       "max tns                      0.994733     24720     0\n",
       "max fns                      0.994733     7759      0\n",
       "max fps                      0.00147532   24720     399\n",
       "max tps                      0.00285428   7841      396\n",
       "max tnr                      0.994733     1         0\n",
       "max fnr                      0.994733     0.989542  0\n",
       "max fpr                      0.00147532   1         399\n",
       "max tpr                      0.00285428   1         396\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.00 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010012                    0.991402           4.15266     4.15266            1                0.993189    1                           0.993189            0.0415763       0.0415763                  315.266   315.266            0.0415763\n",
       "2        0.020024                    0.987297           4.12718     4.13992            0.993865         0.989459    0.996933                    0.991324            0.0413213       0.0828976                  312.718   313.992            0.0828167\n",
       "3        0.0300052                   0.981213           4.11433     4.13141            0.990769         0.984514    0.994882                    0.989059            0.0410662       0.123964                   311.433   313.141            0.123762\n",
       "4        0.0400172                   0.970792           4.12718     4.13035            0.993865         0.976707    0.994628                    0.985968            0.0413213       0.165285                   312.718   313.035            0.165002\n",
       "5        0.0500292                   0.950426           4.13992     4.13227            0.996933         0.962231    0.995089                    0.981218            0.0414488       0.206734                   313.992   313.227            0.20641\n",
       "6        0.100028                    0.784915           3.53537     3.83391            0.851351         0.862702    0.923242                    0.921978            0.176763        0.383497                   253.537   283.391            0.373384\n",
       "7        0.150026                    0.640314           2.87472     3.51425            0.69226          0.713406    0.846264                    0.852469            0.143732        0.527229                   187.472   251.425            0.496848\n",
       "8        0.200025                    0.510624           2.36712     3.22751            0.570025         0.576267    0.777215                    0.783429            0.118352        0.645581                   136.712   222.751            0.586884\n",
       "9        0.300021                    0.301489           1.65035     2.70184            0.39742          0.401118    0.65063                     0.656005            0.16503         0.810611                   65.035    170.184            0.672545\n",
       "10       0.400018                    0.160228           0.983323    2.27225            0.236794         0.226576    0.547179                    0.548656            0.0983293       0.90894                    -1.66769  127.225            0.670348\n",
       "11       0.500015                    0.0750068          0.545866    1.92699            0.13145          0.113443    0.464038                    0.461619            0.0545849       0.963525                   -45.4134  92.6991            0.610532\n",
       "12       0.600012                    0.0324734          0.218091    1.64219            0.0525184        0.0508273   0.395455                    0.393157            0.0218084       0.985334                   -78.1909  64.2189            0.507542\n",
       "13       0.700009                    0.0152883          0.0982048   1.42163            0.0236486        0.0225705   0.342342                    0.340218            0.00982018      0.995154                   -90.1795  42.1629            0.388762\n",
       "14       0.800006                    0.00755018         0.0357108   1.2484             0.00859951       0.0109297   0.300626                    0.299059            0.00357097      0.998725                   -96.4289  24.8396            0.261751\n",
       "15       0.900003                    0.00359462         0.0102031   1.11082            0.002457         0.00535194  0.267497                    0.266426            0.00102028      0.999745                   -98.9797  11.0824            0.131379\n",
       "16       1                           0.00032544         0.00255077  1                  0.000614251      0.00251784  0.24081                     0.240036            0.00025507      1                          -99.7449  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.860109   0.00449248  0.856595      0.857187      0.856726      0.865326      0.864711\n",
       "auc                      0.924569   0.00454247  0.928191      0.926695      0.916986      0.923795      0.927177\n",
       "err                      0.139891   0.00449248  0.143405      0.142813      0.143274      0.134674      0.135289\n",
       "err_count                911        29.2831     934           930           933           877           881\n",
       "f0point5                 0.701263   0.0115764   0.70137       0.688153      0.691278      0.713083      0.712432\n",
       "f1                       0.727542   0.0129064   0.737345      0.718182      0.710698      0.730071      0.741415\n",
       "f2                       0.756029   0.0189628   0.777211      0.750951      0.73124       0.747888      0.772855\n",
       "lift_top_group           4.15474    0.103193    4.00554       4.25621       4.23682       4.17436       4.10076\n",
       "logloss                  0.286223   0.00617988  0.283765      0.279098      0.29565       0.288181      0.284419\n",
       "max_per_class_error      0.223602   0.0248165   0.193727      0.22549       0.254392      0.239744      0.20466\n",
       "mcc                      0.636371   0.0145571   0.644151      0.626186      0.616955      0.641438      0.653126\n",
       "mean_per_class_accuracy  0.831447   0.00935532  0.839805      0.828544      0.818332      0.829341      0.841212\n",
       "mean_per_class_error     0.168553   0.00935532  0.160195      0.171456      0.181668      0.170659      0.158788\n",
       "mse                      0.0908619  0.00175487  0.0901266     0.0889858     0.093492      0.0916711     0.0900341\n",
       "pr_auc                   0.819048   0.0109963   0.83473       0.819415      0.805147      0.813387      0.822561\n",
       "precision                0.684841   0.0131621   0.679275      0.669492      0.67891       0.702191      0.694338\n",
       "r2                       0.502769   0.014423    0.518881      0.504944      0.481515      0.496782      0.511722\n",
       "recall                   0.776397   0.0248165   0.806273      0.77451       0.745608      0.760256      0.79534\n",
       "rmse                     0.301422   0.00290386  0.300211      0.298305      0.305765      0.302772      0.300057\n",
       "specificity              0.886496   0.00937997  0.873337      0.882577      0.891055      0.898425      0.887084\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-10-20 18:27:36  20.514 sec  0                  0.427575         0.552011            0.5             0.24081            1                0.75919\n",
       "    2023-10-20 18:27:36  20.884 sec  5                  0.358067         0.413902            0.923149        0.81191            4.15266          0.14198\n",
       "    2023-10-20 18:27:37  21.111 sec  10                 0.325043         0.351823            0.927453        0.822411           4.15266          0.142164\n",
       "    2023-10-20 18:27:37  21.338 sec  15                 0.310133         0.319826            0.929346        0.827467           4.15266          0.138171\n",
       "    2023-10-20 18:27:37  21.617 sec  20                 0.300814         0.29773             0.93262         0.834101           4.15266          0.134148\n",
       "    2023-10-20 18:27:37  21.843 sec  25                 0.296002         0.285026            0.934852        0.83835            4.15266          0.134087\n",
       "    2023-10-20 18:27:38  22.070 sec  30                 0.291902         0.275374            0.937543        0.844217           4.15266          0.130094\n",
       "    2023-10-20 18:27:38  22.330 sec  35                 0.288717         0.268206            0.939815        0.849048           4.15266          0.125764\n",
       "    2023-10-20 18:27:38  22.888 sec  40                 0.285956         0.262212            0.941844        0.853718           4.15266          0.124413\n",
       "    2023-10-20 18:27:39  23.154 sec  45                 0.283899         0.25761             0.943387        0.857112           4.15266          0.121434\n",
       "    2023-10-20 18:27:39  23.394 sec  50                 0.281971         0.253555            0.944875        0.860407           4.15266          0.119222\n",
       "    2023-10-20 18:27:39  23.650 sec  55                 0.280245         0.250001            0.946298        0.863312           4.15266          0.118117\n",
       "    2023-10-20 18:27:39  23.929 sec  60                 0.278158         0.246472            0.94796         0.867161           4.15266          0.115783\n",
       "    2023-10-20 18:27:40  24.275 sec  65                 0.276298         0.243149            0.949431        0.870529           4.15266          0.114278\n",
       "    2023-10-20 18:27:40  24.485 sec  70                 0.274597         0.240138            0.950781        0.873559           4.15266          0.114186\n",
       "    2023-10-20 18:27:40  24.609 sec  72                 0.273843         0.238896            0.951434        0.874951           4.15266          0.111698\n",
       "\n",
       "Variable Importances: \n",
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "relationship    4602.74                1                    0.286272\n",
       "capital_gain    3140.77                0.682369             0.195343\n",
       "education       2609.79                0.567008             0.162319\n",
       "occupation      1140.88                0.247871             0.0709584\n",
       "age             1114.52                0.242143             0.0693187\n",
       "marital_status  1045.37                0.227119             0.0650179\n",
       "capital_loss    740.771                0.160941             0.0460729\n",
       "hours_per_week  622.132                0.135165             0.0386941\n",
       "workclass       353.184                0.0767333            0.0219666\n",
       "fnlwgt          329.372                0.0715599            0.0204856\n",
       "native_country  275.415                0.059837             0.0171297\n",
       "sex             65.1697                0.0141589            0.00405329\n",
       "race            38.0887                0.00827523           0.00236897\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "x = [a for a in list(train_hdf.columns) if a != 'label']\n",
    "y = 'label'\n",
    "model = H2OAutoML(\n",
    "    # max_models=250,\n",
    "    # max_runtime_secs=3600,\n",
    "    max_models=5,\n",
    "    max_runtime_secs=60,\n",
    "    include_algos=['XGBoost', 'GBM'],\n",
    "    seed=seed,\n",
    "    verbosity='debug',\n",
    "    keep_cross_validation_predictions=True,\n",
    "    nfolds=5\n",
    ")\n",
    "model.train(x=x, y=y, training_frame=train_hdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8b12d-687f-43fe-815a-a8493c2f6c79",
   "metadata": {},
   "source": [
    "### Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9da4475a-aefd-4f09-b3db-6a0920597c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>aucpr</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBM_1_AutoML_1_20231020_182658</td>\n",
       "      <td>0.924691</td>\n",
       "      <td>0.285989</td>\n",
       "      <td>0.819320</td>\n",
       "      <td>0.169888</td>\n",
       "      <td>0.301272</td>\n",
       "      <td>0.090765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost_2_AutoML_1_20231020_182658</td>\n",
       "      <td>0.922906</td>\n",
       "      <td>0.288096</td>\n",
       "      <td>0.818240</td>\n",
       "      <td>0.178437</td>\n",
       "      <td>0.302476</td>\n",
       "      <td>0.091492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_1_AutoML_1_20231020_182658</td>\n",
       "      <td>0.920561</td>\n",
       "      <td>0.293746</td>\n",
       "      <td>0.811266</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>0.305881</td>\n",
       "      <td>0.093563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model_id       auc   logloss     aucpr  \\\n",
       "0      GBM_1_AutoML_1_20231020_182658  0.924691  0.285989  0.819320   \n",
       "1  XGBoost_2_AutoML_1_20231020_182658  0.922906  0.288096  0.818240   \n",
       "2  XGBoost_1_AutoML_1_20231020_182658  0.920561  0.293746  0.811266   \n",
       "\n",
       "   mean_per_class_error      rmse       mse  \n",
       "0              0.169888  0.301272  0.090765  \n",
       "1              0.178437  0.302476  0.091492  \n",
       "2              0.177030  0.305881  0.093563  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.leaderboard.as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91a54c-e76c-4046-acdd-b2f57975c7f6",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99423fda-bd13-411d-8ed3-3ddf31c1a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:34:27.437 172.17.0.2:54321      22766  4648757-70  INFO water.default: GET /3/Models/GBM_1_AutoML_1_20231020_182658, parms: {}\n"
     ]
    }
   ],
   "source": [
    "best_model = model.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "883b500a-e7ea-4ae3-b8a2-bfbf57a2a013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'GBM_1_AutoML_1_20231020_182658',\n",
       " 'training_frame': 'AutoML_1_20231020_182658_training_py_9_sid_88b4',\n",
       " 'validation_frame': None,\n",
       " 'nfolds': 5,\n",
       " 'keep_cross_validation_models': False,\n",
       " 'keep_cross_validation_predictions': True,\n",
       " 'keep_cross_validation_fold_assignment': False,\n",
       " 'score_each_iteration': False,\n",
       " 'score_tree_interval': 5,\n",
       " 'fold_assignment': 'Modulo',\n",
       " 'fold_column': None,\n",
       " 'response_column': 'label',\n",
       " 'ignored_columns': None,\n",
       " 'ignore_const_cols': True,\n",
       " 'offset_column': None,\n",
       " 'weights_column': None,\n",
       " 'balance_classes': False,\n",
       " 'class_sampling_factors': None,\n",
       " 'max_after_balance_size': 5.0,\n",
       " 'max_confusion_matrix_size': 20,\n",
       " 'ntrees': 72,\n",
       " 'max_depth': 15,\n",
       " 'min_rows': 100.0,\n",
       " 'nbins': 20,\n",
       " 'nbins_top_level': 1024,\n",
       " 'nbins_cats': 1024,\n",
       " 'r2_stopping': 1.7976931348623157e+308,\n",
       " 'stopping_rounds': 0,\n",
       " 'stopping_metric': 'logloss',\n",
       " 'stopping_tolerance': 0.005541803630764712,\n",
       " 'max_runtime_secs': 0.0,\n",
       " 'seed': 43,\n",
       " 'build_tree_one_node': False,\n",
       " 'learn_rate': 0.1,\n",
       " 'learn_rate_annealing': 1.0,\n",
       " 'distribution': 'bernoulli',\n",
       " 'quantile_alpha': 0.5,\n",
       " 'tweedie_power': 1.5,\n",
       " 'huber_alpha': 0.9,\n",
       " 'checkpoint': None,\n",
       " 'sample_rate': 0.8,\n",
       " 'sample_rate_per_class': None,\n",
       " 'col_sample_rate': 0.8,\n",
       " 'col_sample_rate_change_per_level': 1.0,\n",
       " 'col_sample_rate_per_tree': 0.8,\n",
       " 'min_split_improvement': 1e-05,\n",
       " 'histogram_type': 'UniformAdaptive',\n",
       " 'max_abs_leafnode_pred': 1.7976931348623157e+308,\n",
       " 'pred_noise_bandwidth': 0.0,\n",
       " 'categorical_encoding': 'Enum',\n",
       " 'calibrate_model': False,\n",
       " 'calibration_frame': None,\n",
       " 'calibration_method': 'PlattScaling',\n",
       " 'custom_metric_func': None,\n",
       " 'custom_distribution_func': None,\n",
       " 'export_checkpoints_dir': None,\n",
       " 'in_training_checkpoints_dir': None,\n",
       " 'in_training_checkpoints_tree_interval': 1,\n",
       " 'monotone_constraints': None,\n",
       " 'check_constant_response': True,\n",
       " 'gainslift_bins': -1,\n",
       " 'auc_type': 'AUTO',\n",
       " 'interaction_constraints': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.actual_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a96c6c-689a-41a5-935b-f76da39b5dc6",
   "metadata": {},
   "source": [
    "### Model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d94d3aa5-3afe-4c54-a152-e5142e22b63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.07499008289803473\n",
       "RMSE: 0.2738431720858395\n",
       "LogLoss: 0.23889571105783058\n",
       "Mean Per-Class Error: 0.14244552377780226\n",
       "AUC: 0.9514336309556976\n",
       "AUCPR: 0.8749514407177378\n",
       "Gini: 0.9028672619113951</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3881431172229534</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>22665.0</td>\n",
       "<td>2055.0</td>\n",
       "<td>0.0831</td>\n",
       "<td> (2055.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1582.0</td>\n",
       "<td>6259.0</td>\n",
       "<td>0.2018</td>\n",
       "<td> (1582.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>24247.0</td>\n",
       "<td>8314.0</td>\n",
       "<td>0.1117</td>\n",
       "<td> (3637.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3881431</td>\n",
       "<td>0.7748685</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1904882</td>\n",
       "<td>0.8448426</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5957142</td>\n",
       "<td>0.8090894</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4578943</td>\n",
       "<td>0.8923559</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0101622</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4199531</td>\n",
       "<td>0.7019311</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2946177</td>\n",
       "<td>0.8717000</td>\n",
       "<td>241.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2487023</td>\n",
       "<td>0.8753788</td>\n",
       "<td>260.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946796</td>\n",
       "<td>24720.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946796</td>\n",
       "<td>7775.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0012164</td>\n",
       "<td>24720.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0101622</td>\n",
       "<td>7841.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946796</td>\n",
       "<td>0.9915827</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0012164</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0101622</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.08 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9909478</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928232</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0415763</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9873610</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9892439</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9910336</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0831527</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0831527</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9826722</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9852002</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9890931</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.1246015</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.1246015</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9750012</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9793438</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9866539</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.1661778</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.1661778</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9574821</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1501099</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9681042</td>\n",
       "<td>0.9993861</td>\n",
       "<td>0.9829417</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.2076266</td>\n",
       "<td>313.9920882</td>\n",
       "<td>315.0109892</td>\n",
       "<td>0.2075861</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7894574</td>\n",
       "<td>3.8924802</td>\n",
       "<td>4.0213346</td>\n",
       "<td>0.9373464</td>\n",
       "<td>0.8701897</td>\n",
       "<td>0.9683758</td>\n",
       "<td>0.9265830</td>\n",
       "<td>0.1946180</td>\n",
       "<td>0.4022446</td>\n",
       "<td>289.2480213</td>\n",
       "<td>302.1334602</td>\n",
       "<td>0.3980779</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6511950</td>\n",
       "<td>3.2267284</td>\n",
       "<td>3.7565201</td>\n",
       "<td>0.7770270</td>\n",
       "<td>0.7202185</td>\n",
       "<td>0.9046059</td>\n",
       "<td>0.8578089</td>\n",
       "<td>0.1613315</td>\n",
       "<td>0.5635761</td>\n",
       "<td>222.6728354</td>\n",
       "<td>275.6520074</td>\n",
       "<td>0.5447249</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5191145</td>\n",
       "<td>2.5099610</td>\n",
       "<td>3.4449282</td>\n",
       "<td>0.6044226</td>\n",
       "<td>0.5834808</td>\n",
       "<td>0.8295716</td>\n",
       "<td>0.7892374</td>\n",
       "<td>0.1254942</td>\n",
       "<td>0.6890703</td>\n",
       "<td>150.9961028</td>\n",
       "<td>244.4928161</td>\n",
       "<td>0.6441674</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3043034</td>\n",
       "<td>1.7383521</td>\n",
       "<td>2.8761277</td>\n",
       "<td>0.4186118</td>\n",
       "<td>0.4027787</td>\n",
       "<td>0.6925990</td>\n",
       "<td>0.6604310</td>\n",
       "<td>0.1738299</td>\n",
       "<td>0.8629001</td>\n",
       "<td>73.8352074</td>\n",
       "<td>187.6127697</td>\n",
       "<td>0.7414196</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1584669</td>\n",
       "<td>0.9131769</td>\n",
       "<td>2.3854277</td>\n",
       "<td>0.2199017</td>\n",
       "<td>0.2269236</td>\n",
       "<td>0.5744338</td>\n",
       "<td>0.5520625</td>\n",
       "<td>0.0913149</td>\n",
       "<td>0.9542150</td>\n",
       "<td>-8.6823122</td>\n",
       "<td>138.5427669</td>\n",
       "<td>0.7299836</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0722390</td>\n",
       "<td>0.3264990</td>\n",
       "<td>1.9736672</td>\n",
       "<td>0.0786241</td>\n",
       "<td>0.1111587</td>\n",
       "<td>0.4752779</td>\n",
       "<td>0.4638872</td>\n",
       "<td>0.0326489</td>\n",
       "<td>0.9868639</td>\n",
       "<td>-67.3501004</td>\n",
       "<td>97.3667226</td>\n",
       "<td>0.6412733</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0312478</td>\n",
       "<td>0.1045817</td>\n",
       "<td>1.6621689</td>\n",
       "<td>0.0251843</td>\n",
       "<td>0.0486476</td>\n",
       "<td>0.4002662</td>\n",
       "<td>0.3946841</td>\n",
       "<td>0.0104578</td>\n",
       "<td>0.9973218</td>\n",
       "<td>-89.5418290</td>\n",
       "<td>66.2168918</td>\n",
       "<td>0.5233331</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0143291</td>\n",
       "<td>0.0216816</td>\n",
       "<td>1.4278239</td>\n",
       "<td>0.0052211</td>\n",
       "<td>0.0214481</td>\n",
       "<td>0.3438336</td>\n",
       "<td>0.3413670</td>\n",
       "<td>0.0021681</td>\n",
       "<td>0.9994899</td>\n",
       "<td>-97.8318426</td>\n",
       "<td>42.7823865</td>\n",
       "<td>0.3944737</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0072545</td>\n",
       "<td>0.0051015</td>\n",
       "<td>1.2499904</td>\n",
       "<td>0.0012285</td>\n",
       "<td>0.0103919</td>\n",
       "<td>0.3010096</td>\n",
       "<td>0.2999967</td>\n",
       "<td>0.0005101</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.4898453</td>\n",
       "<td>24.9990403</td>\n",
       "<td>0.2634304</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000031</td>\n",
       "<td>0.0034743</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111073</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051790</td>\n",
       "<td>0.2675653</td>\n",
       "<td>0.2672403</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1107320</td>\n",
       "<td>0.1317152</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003635</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0024043</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.2407575</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.07499008289803473\n",
       "RMSE: 0.2738431720858395\n",
       "LogLoss: 0.23889571105783058\n",
       "Mean Per-Class Error: 0.14244552377780226\n",
       "AUC: 0.9514336309556976\n",
       "AUCPR: 0.8749514407177378\n",
       "Gini: 0.9028672619113951\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3881431172229534\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      22665  2055  0.0831   (2055.0/24720.0)\n",
       "1      1582   6259  0.2018   (1582.0/7841.0)\n",
       "Total  24247  8314  0.1117   (3637.0/32561.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.388143     0.774868  204\n",
       "max f2                       0.190488     0.844843  284\n",
       "max f0point5                 0.595714     0.809089  134\n",
       "max accuracy                 0.457894     0.892356  181\n",
       "max precision                0.99468      1         0\n",
       "max recall                   0.0101622    1         386\n",
       "max specificity              0.99468      1         0\n",
       "max absolute_mcc             0.419953     0.701931  192\n",
       "max min_per_class_accuracy   0.294618     0.8717    241\n",
       "max mean_per_class_accuracy  0.248702     0.875379  260\n",
       "max tns                      0.99468      24720     0\n",
       "max fns                      0.99468      7775      0\n",
       "max fps                      0.00121637   24720     399\n",
       "max tps                      0.0101622    7841      386\n",
       "max tnr                      0.99468      1         0\n",
       "max fnr                      0.99468      0.991583  0\n",
       "max fpr                      0.00121637   1         399\n",
       "max tpr                      0.0101622    1         386\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.08 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010012                    0.990948           4.15266     4.15266            1                0.992823    1                           0.992823            0.0415763       0.0415763                  315.266   315.266            0.0415763\n",
       "2        0.020024                    0.987361           4.15266     4.15266            1                0.989244    1                           0.991034            0.0415763       0.0831527                  315.266   315.266            0.0831527\n",
       "3        0.0300052                   0.982672           4.15266     4.15266            1                0.9852      1                           0.989093            0.0414488       0.124601                   315.266   315.266            0.124601\n",
       "4        0.0400172                   0.975001           4.15266     4.15266            1                0.979344    1                           0.986654            0.0415763       0.166178                   315.266   315.266            0.166178\n",
       "5        0.0500292                   0.957482           4.13992     4.15011            0.996933         0.968104    0.999386                    0.982942            0.0414488       0.207627                   313.992   315.011            0.207586\n",
       "6        0.100028                    0.789457           3.89248     4.02133            0.937346         0.87019     0.968376                    0.926583            0.194618        0.402245                   289.248   302.133            0.398078\n",
       "7        0.150026                    0.651195           3.22673     3.75652            0.777027         0.720218    0.904606                    0.857809            0.161331        0.563576                   222.673   275.652            0.544725\n",
       "8        0.200025                    0.519115           2.50996     3.44493            0.604423         0.583481    0.829572                    0.789237            0.125494        0.68907                    150.996   244.493            0.644167\n",
       "9        0.300021                    0.304303           1.73835     2.87613            0.418612         0.402779    0.692599                    0.660431            0.17383         0.8629                     73.8352   187.613            0.74142\n",
       "10       0.400018                    0.158467           0.913177    2.38543            0.219902         0.226924    0.574434                    0.552062            0.0913149       0.954215                   -8.68231  138.543            0.729984\n",
       "11       0.500015                    0.072239           0.326499    1.97367            0.0786241        0.111159    0.475278                    0.463887            0.0326489       0.986864                   -67.3501  97.3667            0.641273\n",
       "12       0.600012                    0.0312478          0.104582    1.66217            0.0251843        0.0486476   0.400266                    0.394684            0.0104578       0.997322                   -89.5418  66.2169            0.523333\n",
       "13       0.700009                    0.0143291          0.0216816   1.42782            0.00522113       0.0214481   0.343834                    0.341367            0.00216809      0.99949                    -97.8318  42.7824            0.394474\n",
       "14       0.800006                    0.00725448         0.00510155  1.24999            0.0012285        0.0103919   0.30101                     0.299997            0.000510139     1                          -99.4898  24.999             0.26343\n",
       "15       0.900003                    0.00347433         0           1.11111            0                0.00517905  0.267565                    0.26724             0               1                          -100      11.1107            0.131715\n",
       "16       1                           0.000363483        0           1                  0                0.00240433  0.24081                     0.240758            0               1                          -100      0                  0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.model_performance(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f5734cc-6a33-4a5a-9be4-5d7040a41e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.09076467337180787\n",
       "RMSE: 0.3012717599971957\n",
       "LogLoss: 0.28598910685141826\n",
       "Mean Per-Class Error: 0.16988825283166362\n",
       "AUC: 0.9246906817908851\n",
       "AUCPR: 0.819319713891667\n",
       "Gini: 0.8493813635817702</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>21923.0</td>\n",
       "<td>2797.0</td>\n",
       "<td>0.1131</td>\n",
       "<td> (2797.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1777.0</td>\n",
       "<td>6064.0</td>\n",
       "<td>0.2266</td>\n",
       "<td> (1777.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23700.0</td>\n",
       "<td>8861.0</td>\n",
       "<td>0.1405</td>\n",
       "<td> (4574.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3552160</td>\n",
       "<td>0.7261406</td>\n",
       "<td>214.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1400254</td>\n",
       "<td>0.8035536</td>\n",
       "<td>302.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6142915</td>\n",
       "<td>0.7559369</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5160227</td>\n",
       "<td>0.8702435</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0028543</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4035434</td>\n",
       "<td>0.6358758</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2624334</td>\n",
       "<td>0.8375405</td>\n",
       "<td>249.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2419123</td>\n",
       "<td>0.8395175</td>\n",
       "<td>257.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9947330</td>\n",
       "<td>24720.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9947330</td>\n",
       "<td>7759.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0014753</td>\n",
       "<td>24720.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0028543</td>\n",
       "<td>7841.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9947330</td>\n",
       "<td>0.9895422</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0014753</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0028543</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.00 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9914024</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931894</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931894</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0415763</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9872966</td>\n",
       "<td>4.1271827</td>\n",
       "<td>4.1399209</td>\n",
       "<td>0.9938650</td>\n",
       "<td>0.9894588</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9913241</td>\n",
       "<td>0.0413213</td>\n",
       "<td>0.0828976</td>\n",
       "<td>312.7182663</td>\n",
       "<td>313.9920882</td>\n",
       "<td>0.0828167</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9812125</td>\n",
       "<td>4.1143269</td>\n",
       "<td>4.1314070</td>\n",
       "<td>0.9907692</td>\n",
       "<td>0.9845142</td>\n",
       "<td>0.9948823</td>\n",
       "<td>0.9890588</td>\n",
       "<td>0.0410662</td>\n",
       "<td>0.1239638</td>\n",
       "<td>311.4326862</td>\n",
       "<td>313.1407006</td>\n",
       "<td>0.1237615</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9707915</td>\n",
       "<td>4.1271827</td>\n",
       "<td>4.1303501</td>\n",
       "<td>0.9938650</td>\n",
       "<td>0.9767070</td>\n",
       "<td>0.9946278</td>\n",
       "<td>0.9859685</td>\n",
       "<td>0.0413213</td>\n",
       "<td>0.1652850</td>\n",
       "<td>312.7182663</td>\n",
       "<td>313.0350110</td>\n",
       "<td>0.1650019</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9504264</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1322654</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9622305</td>\n",
       "<td>0.9950890</td>\n",
       "<td>0.9812180</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.2067338</td>\n",
       "<td>313.9920882</td>\n",
       "<td>313.2265439</td>\n",
       "<td>0.2064102</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7849150</td>\n",
       "<td>3.5353719</td>\n",
       "<td>3.8339103</td>\n",
       "<td>0.8513514</td>\n",
       "<td>0.8627023</td>\n",
       "<td>0.9232422</td>\n",
       "<td>0.9219783</td>\n",
       "<td>0.1767632</td>\n",
       "<td>0.3834970</td>\n",
       "<td>253.5371936</td>\n",
       "<td>283.3910320</td>\n",
       "<td>0.3733837</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6403136</td>\n",
       "<td>2.8747216</td>\n",
       "<td>3.5142462</td>\n",
       "<td>0.6922604</td>\n",
       "<td>0.7134062</td>\n",
       "<td>0.8462641</td>\n",
       "<td>0.8524685</td>\n",
       "<td>0.1437317</td>\n",
       "<td>0.5272287</td>\n",
       "<td>187.4721625</td>\n",
       "<td>251.4246206</td>\n",
       "<td>0.4968484</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5106238</td>\n",
       "<td>2.3671177</td>\n",
       "<td>3.2275081</td>\n",
       "<td>0.5700246</td>\n",
       "<td>0.5762666</td>\n",
       "<td>0.7772148</td>\n",
       "<td>0.7834287</td>\n",
       "<td>0.1183523</td>\n",
       "<td>0.6455809</td>\n",
       "<td>136.7117718</td>\n",
       "<td>222.7508116</td>\n",
       "<td>0.5868835</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3014894</td>\n",
       "<td>1.6503504</td>\n",
       "<td>2.7018427</td>\n",
       "<td>0.3974201</td>\n",
       "<td>0.4011178</td>\n",
       "<td>0.6506295</td>\n",
       "<td>0.6560047</td>\n",
       "<td>0.1650300</td>\n",
       "<td>0.8106109</td>\n",
       "<td>65.0350392</td>\n",
       "<td>170.1842690</td>\n",
       "<td>0.6725445</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1602280</td>\n",
       "<td>0.9833231</td>\n",
       "<td>2.2722458</td>\n",
       "<td>0.2367936</td>\n",
       "<td>0.2265763</td>\n",
       "<td>0.5471785</td>\n",
       "<td>0.5486559</td>\n",
       "<td>0.0983293</td>\n",
       "<td>0.9089402</td>\n",
       "<td>-1.6676853</td>\n",
       "<td>127.2245789</td>\n",
       "<td>0.6703480</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0750068</td>\n",
       "<td>0.5458655</td>\n",
       "<td>1.9269909</td>\n",
       "<td>0.1314496</td>\n",
       "<td>0.1134429</td>\n",
       "<td>0.4640378</td>\n",
       "<td>0.4616186</td>\n",
       "<td>0.0545849</td>\n",
       "<td>0.9635251</td>\n",
       "<td>-45.4134492</td>\n",
       "<td>92.6990940</td>\n",
       "<td>0.6105315</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0324734</td>\n",
       "<td>0.2180911</td>\n",
       "<td>1.6421889</td>\n",
       "<td>0.0525184</td>\n",
       "<td>0.0508273</td>\n",
       "<td>0.3954548</td>\n",
       "<td>0.3931569</td>\n",
       "<td>0.0218084</td>\n",
       "<td>0.9853335</td>\n",
       "<td>-78.1908874</td>\n",
       "<td>64.2188883</td>\n",
       "<td>0.5075422</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0152883</td>\n",
       "<td>0.0982048</td>\n",
       "<td>1.4216294</td>\n",
       "<td>0.0236486</td>\n",
       "<td>0.0225705</td>\n",
       "<td>0.3423419</td>\n",
       "<td>0.3402183</td>\n",
       "<td>0.0098202</td>\n",
       "<td>0.9951537</td>\n",
       "<td>-90.1795224</td>\n",
       "<td>42.1629402</td>\n",
       "<td>0.3887621</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0075502</td>\n",
       "<td>0.0357108</td>\n",
       "<td>1.2483962</td>\n",
       "<td>0.0085995</td>\n",
       "<td>0.0109297</td>\n",
       "<td>0.3006257</td>\n",
       "<td>0.2990588</td>\n",
       "<td>0.0035710</td>\n",
       "<td>0.9987247</td>\n",
       "<td>-96.4289172</td>\n",
       "<td>24.8396231</td>\n",
       "<td>0.2617505</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000031</td>\n",
       "<td>0.0035946</td>\n",
       "<td>0.0102031</td>\n",
       "<td>1.1108239</td>\n",
       "<td>0.0024570</td>\n",
       "<td>0.0053519</td>\n",
       "<td>0.2674970</td>\n",
       "<td>0.2664258</td>\n",
       "<td>0.0010203</td>\n",
       "<td>0.9997449</td>\n",
       "<td>-98.9796906</td>\n",
       "<td>11.0823910</td>\n",
       "<td>0.1313792</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003254</td>\n",
       "<td>0.0025508</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0006143</td>\n",
       "<td>0.0025178</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.2400358</td>\n",
       "<td>0.0002551</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.7449227</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.09076467337180787\n",
       "RMSE: 0.3012717599971957\n",
       "LogLoss: 0.28598910685141826\n",
       "Mean Per-Class Error: 0.16988825283166362\n",
       "AUC: 0.9246906817908851\n",
       "AUCPR: 0.819319713891667\n",
       "Gini: 0.8493813635817702\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      21923  2797  0.1131   (2797.0/24720.0)\n",
       "1      1777   6064  0.2266   (1777.0/7841.0)\n",
       "Total  23700  8861  0.1405   (4574.0/32561.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.355216     0.726141  214\n",
       "max f2                       0.140025     0.803554  302\n",
       "max f0point5                 0.614291     0.755937  125\n",
       "max accuracy                 0.516023     0.870244  157\n",
       "max precision                0.994733     1         0\n",
       "max recall                   0.00285428   1         396\n",
       "max specificity              0.994733     1         0\n",
       "max absolute_mcc             0.403543     0.635876  197\n",
       "max min_per_class_accuracy   0.262433     0.83754   249\n",
       "max mean_per_class_accuracy  0.241912     0.839518  257\n",
       "max tns                      0.994733     24720     0\n",
       "max fns                      0.994733     7759      0\n",
       "max fps                      0.00147532   24720     399\n",
       "max tps                      0.00285428   7841      396\n",
       "max tnr                      0.994733     1         0\n",
       "max fnr                      0.994733     0.989542  0\n",
       "max fpr                      0.00147532   1         399\n",
       "max tpr                      0.00285428   1         396\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.00 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010012                    0.991402           4.15266     4.15266            1                0.993189    1                           0.993189            0.0415763       0.0415763                  315.266   315.266            0.0415763\n",
       "2        0.020024                    0.987297           4.12718     4.13992            0.993865         0.989459    0.996933                    0.991324            0.0413213       0.0828976                  312.718   313.992            0.0828167\n",
       "3        0.0300052                   0.981213           4.11433     4.13141            0.990769         0.984514    0.994882                    0.989059            0.0410662       0.123964                   311.433   313.141            0.123762\n",
       "4        0.0400172                   0.970792           4.12718     4.13035            0.993865         0.976707    0.994628                    0.985968            0.0413213       0.165285                   312.718   313.035            0.165002\n",
       "5        0.0500292                   0.950426           4.13992     4.13227            0.996933         0.962231    0.995089                    0.981218            0.0414488       0.206734                   313.992   313.227            0.20641\n",
       "6        0.100028                    0.784915           3.53537     3.83391            0.851351         0.862702    0.923242                    0.921978            0.176763        0.383497                   253.537   283.391            0.373384\n",
       "7        0.150026                    0.640314           2.87472     3.51425            0.69226          0.713406    0.846264                    0.852469            0.143732        0.527229                   187.472   251.425            0.496848\n",
       "8        0.200025                    0.510624           2.36712     3.22751            0.570025         0.576267    0.777215                    0.783429            0.118352        0.645581                   136.712   222.751            0.586884\n",
       "9        0.300021                    0.301489           1.65035     2.70184            0.39742          0.401118    0.65063                     0.656005            0.16503         0.810611                   65.035    170.184            0.672545\n",
       "10       0.400018                    0.160228           0.983323    2.27225            0.236794         0.226576    0.547179                    0.548656            0.0983293       0.90894                    -1.66769  127.225            0.670348\n",
       "11       0.500015                    0.0750068          0.545866    1.92699            0.13145          0.113443    0.464038                    0.461619            0.0545849       0.963525                   -45.4134  92.6991            0.610532\n",
       "12       0.600012                    0.0324734          0.218091    1.64219            0.0525184        0.0508273   0.395455                    0.393157            0.0218084       0.985334                   -78.1909  64.2189            0.507542\n",
       "13       0.700009                    0.0152883          0.0982048   1.42163            0.0236486        0.0225705   0.342342                    0.340218            0.00982018      0.995154                   -90.1795  42.1629            0.388762\n",
       "14       0.800006                    0.00755018         0.0357108   1.2484             0.00859951       0.0109297   0.300626                    0.299059            0.00357097      0.998725                   -96.4289  24.8396            0.261751\n",
       "15       0.900003                    0.00359462         0.0102031   1.11082            0.002457         0.00535194  0.267497                    0.266426            0.00102028      0.999745                   -98.9797  11.0824            0.131379\n",
       "16       1                           0.00032544         0.00255077  1                  0.000614251      0.00251784  0.24081                     0.240036            0.00025507      1                          -99.7449  0                  0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_perf_test = best_model.model_performance(valid=True)\n",
    "model_perf_xval = best_model.model_performance(xval=True)\n",
    "model_perf_xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c944b041-8c8a-4787-9220-f5a10c72ca22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.24191229880798307, 0.1604824564390399]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf_xval.mean_per_class_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b263b1db-9ba3-4d39-abf1-6ac2986bae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28598910685141826"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf_xval.logloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f678d26-a62c-4fd5-8d7a-cd4c87f799de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9246906817908851"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf_xval.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e3dbc41-b9bc-401c-9613-706f43654514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>21923.0</td>\n",
       "<td>2797.0</td>\n",
       "<td>0.1131</td>\n",
       "<td> (2797.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1777.0</td>\n",
       "<td>6064.0</td>\n",
       "<td>0.2266</td>\n",
       "<td> (1777.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23700.0</td>\n",
       "<td>8861.0</td>\n",
       "<td>0.1405</td>\n",
       "<td> (4574.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      21923  2797  0.1131   (2797.0/24720.0)\n",
       "1      1777   6064  0.2266   (1777.0/7841.0)\n",
       "Total  23700  8861  0.1405   (4574.0/32561.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf_xval.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a471ba1f-90ca-4a13-b126-866042949e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.856595</td>\n",
       "      <td>0.857187</td>\n",
       "      <td>0.856726</td>\n",
       "      <td>0.865326</td>\n",
       "      <td>0.864711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.924569</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.928191</td>\n",
       "      <td>0.926695</td>\n",
       "      <td>0.916986</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.927177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.139891</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.143405</td>\n",
       "      <td>0.142813</td>\n",
       "      <td>0.143274</td>\n",
       "      <td>0.134674</td>\n",
       "      <td>0.135289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>911.000000</td>\n",
       "      <td>29.283100</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>877.000000</td>\n",
       "      <td>881.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.701263</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.701370</td>\n",
       "      <td>0.688153</td>\n",
       "      <td>0.691278</td>\n",
       "      <td>0.713083</td>\n",
       "      <td>0.712432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.727542</td>\n",
       "      <td>0.012906</td>\n",
       "      <td>0.737345</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.710698</td>\n",
       "      <td>0.730071</td>\n",
       "      <td>0.741415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.756029</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>0.777211</td>\n",
       "      <td>0.750951</td>\n",
       "      <td>0.731240</td>\n",
       "      <td>0.747888</td>\n",
       "      <td>0.772855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>4.154737</td>\n",
       "      <td>0.103193</td>\n",
       "      <td>4.005535</td>\n",
       "      <td>4.256209</td>\n",
       "      <td>4.236825</td>\n",
       "      <td>4.174359</td>\n",
       "      <td>4.100756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.286223</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.283765</td>\n",
       "      <td>0.279098</td>\n",
       "      <td>0.295650</td>\n",
       "      <td>0.288181</td>\n",
       "      <td>0.284419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.223602</td>\n",
       "      <td>0.024817</td>\n",
       "      <td>0.193727</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.254392</td>\n",
       "      <td>0.239744</td>\n",
       "      <td>0.204660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.636371</td>\n",
       "      <td>0.014557</td>\n",
       "      <td>0.644151</td>\n",
       "      <td>0.626186</td>\n",
       "      <td>0.616955</td>\n",
       "      <td>0.641438</td>\n",
       "      <td>0.653126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.831447</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.839805</td>\n",
       "      <td>0.828544</td>\n",
       "      <td>0.818332</td>\n",
       "      <td>0.829341</td>\n",
       "      <td>0.841212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.168553</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.160195</td>\n",
       "      <td>0.171456</td>\n",
       "      <td>0.181668</td>\n",
       "      <td>0.170659</td>\n",
       "      <td>0.158788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.090127</td>\n",
       "      <td>0.088986</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>0.091671</td>\n",
       "      <td>0.090034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.834730</td>\n",
       "      <td>0.819415</td>\n",
       "      <td>0.805147</td>\n",
       "      <td>0.813387</td>\n",
       "      <td>0.822561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.684841</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.679275</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.678910</td>\n",
       "      <td>0.702191</td>\n",
       "      <td>0.694338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.502769</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.518881</td>\n",
       "      <td>0.504944</td>\n",
       "      <td>0.481515</td>\n",
       "      <td>0.496782</td>\n",
       "      <td>0.511722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.776397</td>\n",
       "      <td>0.024817</td>\n",
       "      <td>0.806273</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.745608</td>\n",
       "      <td>0.760256</td>\n",
       "      <td>0.795340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.301422</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.300211</td>\n",
       "      <td>0.298305</td>\n",
       "      <td>0.305765</td>\n",
       "      <td>0.302772</td>\n",
       "      <td>0.300057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.886496</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.873337</td>\n",
       "      <td>0.882577</td>\n",
       "      <td>0.891055</td>\n",
       "      <td>0.898425</td>\n",
       "      <td>0.887084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean         sd  cv_1_valid  cv_2_valid  \\\n",
       "0                  accuracy    0.860109   0.004492    0.856595    0.857187   \n",
       "1                       auc    0.924569   0.004542    0.928191    0.926695   \n",
       "2                       err    0.139891   0.004492    0.143405    0.142813   \n",
       "3                 err_count  911.000000  29.283100  934.000000  930.000000   \n",
       "4                  f0point5    0.701263   0.011576    0.701370    0.688153   \n",
       "5                        f1    0.727542   0.012906    0.737345    0.718182   \n",
       "6                        f2    0.756029   0.018963    0.777211    0.750951   \n",
       "7            lift_top_group    4.154737   0.103193    4.005535    4.256209   \n",
       "8                   logloss    0.286223   0.006180    0.283765    0.279098   \n",
       "9       max_per_class_error    0.223602   0.024817    0.193727    0.225490   \n",
       "10                      mcc    0.636371   0.014557    0.644151    0.626186   \n",
       "11  mean_per_class_accuracy    0.831447   0.009355    0.839805    0.828544   \n",
       "12     mean_per_class_error    0.168553   0.009355    0.160195    0.171456   \n",
       "13                      mse    0.090862   0.001755    0.090127    0.088986   \n",
       "14                   pr_auc    0.819048   0.010996    0.834730    0.819415   \n",
       "15                precision    0.684841   0.013162    0.679275    0.669492   \n",
       "16                       r2    0.502769   0.014423    0.518881    0.504944   \n",
       "17                   recall    0.776397   0.024817    0.806273    0.774510   \n",
       "18                     rmse    0.301422   0.002904    0.300211    0.298305   \n",
       "19              specificity    0.886496   0.009380    0.873337    0.882577   \n",
       "\n",
       "    cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0     0.856726    0.865326    0.864711  \n",
       "1     0.916986    0.923795    0.927177  \n",
       "2     0.143274    0.134674    0.135289  \n",
       "3   933.000000  877.000000  881.000000  \n",
       "4     0.691278    0.713083    0.712432  \n",
       "5     0.710698    0.730071    0.741415  \n",
       "6     0.731240    0.747888    0.772855  \n",
       "7     4.236825    4.174359    4.100756  \n",
       "8     0.295650    0.288181    0.284419  \n",
       "9     0.254392    0.239744    0.204660  \n",
       "10    0.616955    0.641438    0.653126  \n",
       "11    0.818332    0.829341    0.841212  \n",
       "12    0.181668    0.170659    0.158788  \n",
       "13    0.093492    0.091671    0.090034  \n",
       "14    0.805147    0.813387    0.822561  \n",
       "15    0.678910    0.702191    0.694338  \n",
       "16    0.481515    0.496782    0.511722  \n",
       "17    0.745608    0.760256    0.795340  \n",
       "18    0.305765    0.302772    0.300057  \n",
       "19    0.891055    0.898425    0.887084  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cross_validation_metrics_summary().as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e6bc3-7e18-478b-b9b1-ab05fe0e86fc",
   "metadata": {},
   "source": [
    "### Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e54fcfab-70e4-49d2-89b8-c45f7e9a05d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:35:11.997 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_13_sid_88b4 (table (cols_py py_9_sid_88b4 'label') True)), session_id=_sid_88b4}\n",
      "10-20 18:35:12.046 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_13_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  Count\n",
       "0      0  24720\n",
       "1      1   7841"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hdf['label'].table().as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa4688-7c43-4497-b37a-14b208a48ee4",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c164ed0-ad99-45b3-ae6d-9bc30c81b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>imp1</th>\n",
       "      <th>imp2</th>\n",
       "      <th>imp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationship</td>\n",
       "      <td>4602.744629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>3140.770996</td>\n",
       "      <td>0.682369</td>\n",
       "      <td>0.195343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education</td>\n",
       "      <td>2609.794678</td>\n",
       "      <td>0.567008</td>\n",
       "      <td>0.162319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>occupation</td>\n",
       "      <td>1140.884888</td>\n",
       "      <td>0.247871</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>1114.520630</td>\n",
       "      <td>0.242143</td>\n",
       "      <td>0.069319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>1045.372681</td>\n",
       "      <td>0.227119</td>\n",
       "      <td>0.065018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>740.770874</td>\n",
       "      <td>0.160941</td>\n",
       "      <td>0.046073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>622.132202</td>\n",
       "      <td>0.135165</td>\n",
       "      <td>0.038694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>workclass</td>\n",
       "      <td>353.183838</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>0.021967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fnlwgt</td>\n",
       "      <td>329.372070</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.020486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>native_country</td>\n",
       "      <td>275.414551</td>\n",
       "      <td>0.059837</td>\n",
       "      <td>0.017130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sex</td>\n",
       "      <td>65.169701</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race</td>\n",
       "      <td>38.088749</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_name         imp1      imp2      imp3\n",
       "0     relationship  4602.744629  1.000000  0.286272\n",
       "1     capital_gain  3140.770996  0.682369  0.195343\n",
       "2        education  2609.794678  0.567008  0.162319\n",
       "3       occupation  1140.884888  0.247871  0.070958\n",
       "4              age  1114.520630  0.242143  0.069319\n",
       "5   marital_status  1045.372681  0.227119  0.065018\n",
       "6     capital_loss   740.770874  0.160941  0.046073\n",
       "7   hours_per_week   622.132202  0.135165  0.038694\n",
       "8        workclass   353.183838  0.076733  0.021967\n",
       "9           fnlwgt   329.372070  0.071560  0.020486\n",
       "10  native_country   275.414551  0.059837  0.017130\n",
       "11             sex    65.169701  0.014159  0.004053\n",
       "12            race    38.088749  0.008275  0.002369"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(best_model.varimp(), columns=['feature_name', 'imp1', 'imp2', 'imp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33485c80-c3c8-47d6-bf84-dbbcaa0b536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29da16d610>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20879e3e-bbd4-4a48-9ec3-f62515046f9a",
   "metadata": {},
   "source": [
    "### Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7230a43-c1f9-4607-90a4-ab59cf78c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:39:08.236 172.17.0.2:54321      22766  4648757-69  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_14_sid_88b4 (rows py_9_sid_88b4 [26 53 59 67 82 96 103 225 270 274 296 351 412 421 435 561 568 656 671 708 721 755 756 760 761 789 842 888 912 914 942 951 955 959 983 995 1004 1074 1129 1133 1165 1264 1286 1292 1332 1352 1355 1405 1412 1414 1423 1457 1494 1506 1542 1594 1640 1688 1716 1758 1787 1788 1811 1921 1964 1969 1983 2017 2060 2092 2106 2123 2149 2168 2183 2198 2230 2235 2256 2259 2293 2306 2308 2444 2454 2491 2499 2507 2596 2641 2707 2709 2711 2715 2751 2754 2805 2843 2896 2915 2922 2959 2964 2973 2977 3050 3098 3107 3108 3143 3155 3162 3181 3182 3218 3229 3231 3320 3333 3358 3383 3441 3459 3513 3561 3603 3623 3678 3823 3836 3874 3876 4012 4076 4133 4141 4151 4161 4221 4237 4241 4242 4243 4285 4302 4343 4350 4372 4373 4386 4388 4409 4454 4523 4527 4548 4552 4566 4586 4620 4706 4719 4746 4792 4824 4859 4866 4982 4984 4989 5002 5067 5242 5262 5270 5290 5302 5333 5363 5377 5384 5419 5463 5510 5519 5597 5654 5747 5774 5780 5849 5864 5882 5896 5988 6061 6067 6086 6091 6119 6120 6204 6221 6222 6265 6318 6331 6355 6384 6410 6416 6425 6479 6495 6502 6510 6537 6547 6578 6594 6663 6768 6804 6821 6857 6872 6874 6876 6946 6970 6985 7047 7077 7139 7199 7278 7300 7312 7331 7357 7367 7389 7390 7413 7464 7478 7480 7485 7524 7532 7536 7598 7615 7668 7706 7780 7839 7864 7872 7933 7973 8017 8021 8034 8038 8083 8179 8192 8216 8283 8449 8463 8464 8512 8517 8533 8598 8613 8636 8678 8740 8751 8803 8840 8848 8870 8935 8953 8963 8969 8993 9017 9026 9027 9038 9070 9138 9186 9197 9229 9264 9291 9314 9333 9463 9546 9554 9573 9591 9635 9642 9653 9672 9687 9784 9834 9839 9857 9937 9972 9976 10090 10212 10222 10268 10276 10303 10311 10331 10382 10449 10474 10505 10525 10536 10597 10642 10716 10785 10851 10894 10954 10998 11064 11078 11112 11160 11185 11191 11269 11277 11312 11315 11345 11446 11523 11596 11711 11712 11756 11984 11993 12017 12033 12039 12073 12097 12114 12215 12246 12299 12304 12378 12383 12391 12525 12536 12598 12609 12618 12733 12754 12761 12813 12846 12896 12897 12926 12939 12953 12963 12978 13016 13037 13089 13114 13169 13190 13195 13254 13335 13357 13401 13403 13414 13443 13457 13499 13510 13513 13516 13598 13604 13607 13627 13667 13693 13705 13745 13748 13763 13773 13850 13872 13886 13887 13916 13953 14018 14103 14219 14226 14376 14428 14436 14462 14514 14515 14568 14595 14611 14620 14699 14714 14743 14774 14792 14868 14873 14889 14901 14920 14950 14978 14992 14993 15013 15029 15054 15066 15107 15129 15156 15162 15179 15188 15193 15220 15273 15304 15305 15330 15372 15386 15391 15402 15405 15427 15532 15555 15615 15633 15643 15673 15677 15699 15711 15788 15804 15817 15836 15848 15926 15942 15944 15949 15987 16000 16007 16027 16035 16044 16072 16077 16089 16158 16192 16219 16235 16289 16299 16354 16364 16390 16403 16430 16440 16552 16554 16615 16621 16742 16793 16836 16890 16912 16948 17033 17050 17053 17144 17217 17224 17236 17274 17324 17340 17389 17408 17413 17433 17458 17523 17537 17554 17611 17640 17649 17712 17751 17773 17776 17799 17823 17882 17885 17928 17938 17996 18043 18090 18154 18222 18228 18279 18293 18296 18331 18341 18372 18383 18473 18497 18511 18519 18543 18548 18557 18564 18603 18621 18667 18684 18685 18688 18718 18736 18750 18814 18834 18945 18982 18992 19006 19011 19013 19014 19045 19085 19112 19151 19160 19232 19244 19352 19469 19478 19498 19614 19628 19679 19697 19761 19774 19819 19828 19896 19900 19968 20007 20017 20029 20081 20127 20132 20179 20180 20236 20359 20489 20513 20593 20618 20644 20676 20710 20744 20815 20867 20879 20906 20963 21050 21090 21104 21107 21139 21179 21249 21285 21365 21370 21540 21543 21546 21631 21717 21739 21740 21763 21767 21774 21797 21810 21818 21828 21846 21848 21932 21936 21946 21950 21970 21980 22091 22203 22267 22270 22302 22314 22328 22333 22397 22398 22410 22411 22464 22598 22600 22603 22610 22694 22696 22710 22742 22757 22761 22766 22789 22796 22809 22823 22862 22953 22989 22999 23018 23031 23056 23099 23149 23153 23204 23276 23283 23297 23335 23344 23356 23478 23494 23502 23539 23626 23648 23667 23676 23717 23750 23804 23806 23863 23871 23942 23948 23953 23965 24067 24069 24100 24151 24195 24332 24343 24372 24373 24429 24461 24618 24649 24698 24702 24766 24798 24806 24904 24916 24932 24965 24988 25028 25045 25128 25207 25213 25247 25303 25365 25423 25443 25451 25518 25587 25747 25787 25804 25818 25841 25872 25920 25928 25929 25962 25987 26009 26014 26015 26018 26023 26025 26105 26124 26129 26146 26248 26249 26253 26341 26355 26372 26455 26468 26471 26482 26492 26493 26522 26532 26561 26629 26709 26749 26750 26777 26789 26815 26828 26852 26860 26945 26975 26992 27057 27095 27137 27153 27193 27228 27239 27244 27298 27312 27369 27375 27387 27395 27396 27463 27484 27527 27535 27600 27619 27726 27761 27795 27797 27829 27862 27913 27922 28040 28096 28108 28143 28152 28154 28246 28252 28270 28284 28303 28315 28323 28327 28358 28376 28389 28400 28421 28435 28449 28456 28463 28513 28523 28525 28533 28549 28575 28614 28628 28635 28681 28783 28793 28822 28846 28903 28911 29004 29043 29057 29119 29132 29236 29274 29278 29286 29297 29342 29349 29432 29462 29482 29547 29592 29617 29638 29644 29659 29715 29720 29756 29787 29817 29846 29901 29935 29951 29973 30061 30076 30077 30130 30133 30134 30167 30186 30211 30224 30309 30332 30364 30365 30415 30432 30519 30530 30582 30609 30614 30627 30702 30704 30763 30775 30864 30894 30917 30939 30951 30956 31056 31070 31095 31102 31122 31130 31253 31344 31374 31408 31424 31434 31453 31493 31512 31540 31625 31640 31676 31702 31756 31759 31768 31832 31854 31936 32039 32066 32130 32132 32135 32163 32173 32175 32268 32318 32324 32341 32359 32367 32370 32429 32431 32450 32502 32506 32524])), session_id=_sid_88b4}\n",
      "10-20 18:39:08.296 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /4/Predictions/models/GBM_1_AutoML_1_20231020_182658/frames/py_14_sid_88b4, parms: {predict_contributions_output_format=Original, compare_abs=False, predict_contributions=True}\n",
      "10-20 18:39:12.126 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/Frames/contributions__89bd_GBM_1_AutoML_1_20231020_182658_on_py_14_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:39:12.152 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor contributions__89bd_GBM_1_AutoML_1_20231020_182658_on_py_14_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.177 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character contributions__89bd_GBM_1_AutoML_1_20231020_182658_on_py_14_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.204 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric contributions__89bd_GBM_1_AutoML_1_20231020_182658_on_py_14_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.265 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor py_14_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.284 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_14_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.305 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_14_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.363 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_16_sid_88b4 (levels (tmp= py_15_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'workclass'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.374 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_16_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.379 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_15_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.434 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_18_sid_88b4 (levels (tmp= py_17_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'education'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.444 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_18_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.449 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_17_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.499 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_20_sid_88b4 (levels (tmp= py_19_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'marital_status'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.508 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_20_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.516 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_19_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.571 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_22_sid_88b4 (levels (tmp= py_21_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'occupation'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.585 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_22_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.592 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_21_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.645 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_24_sid_88b4 (levels (tmp= py_23_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'relationship'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.653 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_24_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.658 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_23_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.705 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_26_sid_88b4 (levels (tmp= py_25_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'race'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.714 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_26_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.718 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_25_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.766 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_28_sid_88b4 (levels (tmp= py_27_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'sex'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.777 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_28_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.782 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_27_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.839 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_30_sid_88b4 (levels (tmp= py_29_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'native_country'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.847 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_30_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.851 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_29_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.899 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_32_sid_88b4 (levels (tmp= py_31_sid_88b4 (as.factor (cols_py py_14_sid_88b4 'label'))))), session_id=_sid_88b4}\n",
      "10-20 18:39:12.908 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_32_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.912 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_31_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:39:12.934 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_14_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29e39e3a30>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.shap_summary_plot(train_hdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0a7d4-2dbd-4586-a831-8395ec343e6a",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51555468-77a4-42c9-9ec1-798c70bf4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:48:20.844 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 18:48:20.981 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 18:48:20.981 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 18:48:20.981 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 18:48:20.992 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 176.1 KiB, free 433.9 MiB)\n",
      "10-20 18:48:21.008 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on 95675304fa2d:41565 in memory (size: 13.7 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.014 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on 95675304fa2d:41565 in memory (size: 28.1 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.017 172.17.0.2:54321      22766  d-pool-111  INFO org.apache.spark.storage.BlockManager: Removing RDD 60\n",
      "10-20 18:48:21.022 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 28.1 KiB, free 434.2 MiB)\n",
      "10-20 18:48:21.026 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 95675304fa2d:41565 (size: 28.1 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.027 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 24 from rdd at SparkDataFrameConverter.scala:53\n",
      "10-20 18:48:21.028 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on 95675304fa2d:41565 in memory (size: 11.9 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.029 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 18:48:21.051 172.17.0.2:54321      22766  4648757-65  INFO water.default: POST /3/InitializeFrame, parms: {columns=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\"native_country\",\"label\"], key=frame_rdd_68-647583423}\n",
      "10-20 18:48:21.052 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/InitializeFrame successfully responded for the POST.\n",
      "10-20 18:48:21.061 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: fold at PartitionStatsGenerator.scala:35\n",
      "10-20 18:48:21.062 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 15 (fold at PartitionStatsGenerator.scala:35) with 1 output partitions\n",
      "10-20 18:48:21.062 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 16 (fold at PartitionStatsGenerator.scala:35)\n",
      "10-20 18:48:21.062 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:48:21.063 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:48:21.064 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[70] at mapPartitionsWithIndex at PartitionStatsGenerator.scala:29), which has no missing parents\n",
      "10-20 18:48:21.100 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 27.5 KiB, free 434.2 MiB)\n",
      "10-20 18:48:21.106 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 434.2 MiB)\n",
      "10-20 18:48:21.106 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 95675304fa2d:41565 (size: 11.8 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.107 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:48:21.108 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[70] at mapPartitionsWithIndex at PartitionStatsGenerator.scala:29) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:48:21.108 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "10-20 18:48:21.109 172.17.0.2:54321      22766  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (95675304fa2d, executor driver, partition 0, ANY, 4865 bytes) taskResourceAssignments Map()\n",
      "10-20 18:48:21.110 172.17.0.2:54321      22766  0 (TID 16)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 16.0 (TID 16)\n",
      "10-20 18:48:21.119 172.17.0.2:54321      22766  0 (TID 16)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n",
      "10-20 18:48:21.125 172.17.0.2:54321      22766  0 (TID 16)  WARN org.apache.spark.sql.catalyst.csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: |1x3 Cross validator, , , , , , , , , , , , , \n",
      " Schema: age, workclass, fnlwgt, education, marital_status, occupation, relationship, race, sex, capital_gain, capital_loss, hours_per_week, native_country, income_level\n",
      "Expected: age but found: |1x3 Cross validator\n",
      "CSV file: file:///home/jovyan/data/census-test.csv\n",
      "10-20 18:48:21.206 172.17.0.2:54321      22766  0 (TID 16)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 16.0 (TID 16). 1744 bytes result sent to driver\n",
      "10-20 18:48:21.209 172.17.0.2:54321      22766  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 100 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:48:21.210 172.17.0.2:54321      22766  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "10-20 18:48:21.210 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 16 (fold at PartitionStatsGenerator.scala:35) finished in 0.145 s\n",
      "10-20 18:48:21.210 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:48:21.210 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished\n",
      "10-20 18:48:21.211 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 15 finished: fold at PartitionStatsGenerator.scala:35, took 0.149207 s\n",
      "10-20 18:48:21.214 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/UploadPlan, parms: {number_of_chunks=1}\n",
      "10-20 18:48:21.215 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/UploadPlan?number_of_chunks=1 successfully responded for the GET.\n",
      "10-20 18:48:21.217 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at Writer.scala:104\n",
      "10-20 18:48:21.218 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 16 (runJob at Writer.scala:104) with 1 output partitions\n",
      "10-20 18:48:21.218 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 17 (runJob at Writer.scala:104)\n",
      "10-20 18:48:21.218 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:48:21.219 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:48:21.222 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 17 (H2OAwareRDD[69] at RDD at H2OAwareBaseRDD.scala:29), which has no missing parents\n",
      "10-20 18:48:21.224 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 30.7 KiB, free 434.1 MiB)\n",
      "10-20 18:48:21.248 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 434.1 MiB)\n",
      "10-20 18:48:21.249 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 95675304fa2d:41565 (size: 13.7 KiB, free: 434.3 MiB)\n",
      "10-20 18:48:21.250 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:48:21.251 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (H2OAwareRDD[69] at RDD at H2OAwareBaseRDD.scala:29) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:48:21.252 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "10-20 18:48:21.254 172.17.0.2:54321      22766  ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (95675304fa2d, executor driver, partition 0, ANY, 4865 bytes) taskResourceAssignments Map()\n",
      "10-20 18:48:21.255 172.17.0.2:54321      22766  0 (TID 17)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 17.0 (TID 17)\n",
      "10-20 18:48:21.268 172.17.0.2:54321      22766  0 (TID 17)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n",
      "10-20 18:48:21.274 172.17.0.2:54321      22766  0 (TID 17)  WARN org.apache.spark.sql.catalyst.csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: |1x3 Cross validator, , , , , , , , , , , , , \n",
      " Schema: age, workclass, fnlwgt, education, marital_status, occupation, relationship, race, sex, capital_gain, capital_loss, hours_per_week, native_country, income_level\n",
      "Expected: age but found: |1x3 Cross validator\n",
      "CSV file: file:///home/jovyan/data/census-test.csv\n",
      "10-20 18:48:21.366 172.17.0.2:54321      22766  0 (TID 17)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/Chunk?frame_name=frame_rdd_68-647583423&num_rows=16281&compression=SNAPPY&maximum_vector_sizes=&expected_types=BAsHCwsLCwsLBwcHCwQ%3D&chunk_id=0 successfully responded for the PUT.\n",
      "10-20 18:48:21.367 172.17.0.2:54321      22766  0 (TID 17)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/ChunkCategoricalDomains?frame_name=frame_rdd_68-647583423&chunk_id=0&compression=SNAPPY successfully responded for the PUT.\n",
      "10-20 18:48:21.367 172.17.0.2:54321      22766  0 (TID 17)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/ChunkCategoricalDomains?frame_name=frame_rdd_68-647583423&chunk_id=0&compression=SNAPPY successfully responded for the PUT.\n",
      "10-20 18:48:21.369 172.17.0.2:54321      22766  0 (TID 17)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 17.0 (TID 17). 1592 bytes result sent to driver\n",
      "10-20 18:48:21.370 172.17.0.2:54321      22766  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 116 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:48:21.370 172.17.0.2:54321      22766  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "10-20 18:48:21.371 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 17 (runJob at Writer.scala:104) finished in 0.149 s\n",
      "10-20 18:48:21.371 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:48:21.371 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "10-20 18:48:21.371 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 16 finished: runJob at Writer.scala:104, took 0.153683 s\n",
      "10-20 18:48:21.373 172.17.0.2:54321      22766  4648757-65  INFO water.default: POST /3/FinalizeFrame, parms: {column_types=AwQDBAQEBAQEAwMDBAM=, rows_per_chunk=mT8AAAAAAAA=, key=frame_rdd_68-647583423}\n",
      "10-20 18:48:21.390 172.17.0.2:54321      22766  4648757-65  INFO water.default: Parse result for frame_rdd_68-647583423 (16281 rows, 14 columns):\n",
      "10-20 18:48:21.392 172.17.0.2:54321      22766  4648757-65  INFO water.default:           ColV2    type          min          max         mean        sigma         NAs constant cardinality\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:             age: numeric      17.0000      90.0000      38.7675      13.8492                            \n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:       workclass:  factor  Federal-gov           NA                                                     9\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:          fnlwgt: numeric      13492.0  1.49040e+06       189436       105715                            \n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:       education:  factor         10th  Some-colleg                                                    16\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:  marital_status:  factor     Divorced      Widowed                                                     7\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:      occupation:  factor  Adm-clerica           NA                                                    15\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:    relationship:  factor      Husband         Wife                                                     6\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:            race:  factor  Amer-Indian        White                                                     5\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:             sex:  factor       Female         Male                                                     2\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:    capital_gain: numeric      0.00000      99999.0      1081.91      7583.94                            \n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:    capital_loss: numeric      0.00000      3770.00      87.8993      403.105                            \n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:  hours_per_week: numeric      1.00000      99.0000      40.3922      12.4793                            \n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:  native_country:  factor     Cambodia           NA                                                    41\n",
      "10-20 18:48:21.393 172.17.0.2:54321      22766  4648757-65  INFO water.default:           label: numeric      0.00000      1.00000     0.236226     0.424776                            \n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default: Chunk compression summary:\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:   Chunk Type                 Chunk Name       Count  Count Percentage        Size  Size Percentage\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:          CBS                     Binary           2          14.286 %      4.1 KB          1.829 %\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:          CXI            Sparse Integers           2          14.286 %     13.5 KB          5.986 %\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:          C1N  1-Byte Integers (w/o NAs)           9          64.286 %    143.7 KB         63.882 %\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:           C4            4-Byte Integers           1           7.143 %     63.7 KB         28.303 %\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default: Frame distribution summary:\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:                         Size  Number of Rows  Number of Chunks per Column  Number of Chunks\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default: 172.17.0.2:54321    224.9 KB           16281                            1                14\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:             mean    224.9 KB    16281.000000                     1.000000         14.000000\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:              min    224.9 KB    16281.000000                     1.000000         14.000000\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:              max    224.9 KB    16281.000000                     1.000000         14.000000\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:           stddev        0  B        0.000000                     0.000000          0.000000\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766  4648757-65  INFO water.default:            total    224.9 KB           16281                            1                14\n",
      "10-20 18:48:21.394 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/FinalizeFrame successfully responded for the POST.\n",
      "10-20 18:48:21.395 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/Frames/frame_rdd_68-647583423/light, parms: {full_column_count=0, row_count=0}\n",
      "10-20 18:48:21.396 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/Frames/frame_rdd_68-647583423/light?row_count=0&full_column_count=0 successfully responded for the GET.\n",
      "10-20 18:48:21.398 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 18:48:21.399 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/FrameChunks/frame_rdd_68-647583423, parms: {}\n",
      "10-20 18:48:21.400 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/FrameChunks/frame_rdd_68-647583423 successfully responded for the GET.\n",
      "10-20 18:48:21.401 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 68 from persistence list\n",
      "10-20 18:48:21.402 172.17.0.2:54321      22766  d-pool-117  INFO org.apache.spark.storage.BlockManager: Removing RDD 68\n",
      "10-20 18:48:21.406 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /3/Frames/frame_rdd_68-647583423/light, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:21.413 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/Models/GBM_1_AutoML_1_20231020_182658, parms: {}\n",
      "10-20 18:48:21.445 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on 95675304fa2d:41565 in memory (size: 11.8 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.470 172.17.0.2:54321      22766  d-pool-123  INFO org.apache.spark.storage.BlockManager: Removing RDD 68\n",
      "10-20 18:48:21.503 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on 95675304fa2d:41565 in memory (size: 13.7 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:21.567 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on 95675304fa2d:41565 in memory (size: 28.1 KiB, free: 434.4 MiB)\n",
      "10-20 18:48:22.099 172.17.0.2:54321      22766  4648757-65  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_60_sid_88b4 (:= (tmp= py_59_sid_88b4 (:= (tmp= py_58_sid_88b4 (:= (tmp= py_57_sid_88b4 (:= (tmp= py_56_sid_88b4 (:= (tmp= py_55_sid_88b4 (:= (tmp= py_54_sid_88b4 (:= (tmp= py_53_sid_88b4 (:= frame_rdd_68-647583423 (as.factor (cols_py frame_rdd_68-647583423 'workclass')) 1 [])) (as.factor (cols_py py_53_sid_88b4 'education')) 3 [])) (as.factor (cols_py py_54_sid_88b4 'marital_status')) 4 [])) (as.factor (cols_py py_55_sid_88b4 'occupation')) 5 [])) (as.factor (cols_py py_56_sid_88b4 'relationship')) 6 [])) (as.factor (cols_py py_57_sid_88b4 'race')) 7 [])) (as.factor (cols_py py_58_sid_88b4 'sex')) 8 [])) (as.factor (cols_py py_59_sid_88b4 'native_country')) 12 [])), session_id=_sid_88b4}\n",
      "10-20 18:48:22.107 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /4/Predictions/models/GBM_1_AutoML_1_20231020_182658/frames/py_60_sid_88b4, parms: {}\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "10-20 18:48:22.532 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /3/Frames/transformation_adf7_GBM_1_AutoML_1_20231020_182658_on_py_60_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "test_df = (\n",
    "        spark.read\n",
    "        .format('csv')\n",
    "        .option('header', 'true')\n",
    "        .option('delimiter', ',')\n",
    "        .schema(schema)\n",
    "        .load(test_path)\n",
    "        .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "        .drop('education_num', 'income_level')\n",
    "        .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "        .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "        .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    "    )\n",
    "\n",
    "test_hdf = hc.asH2OFrame(test_df)\n",
    "test_hdf['workclass'] = test_hdf['workclass'].asfactor()\n",
    "test_hdf['education'] = test_hdf['education'].asfactor()\n",
    "test_hdf['marital_status'] = test_hdf['marital_status'].asfactor()\n",
    "test_hdf['occupation'] = test_hdf['occupation'].asfactor()\n",
    "test_hdf['relationship'] = test_hdf['relationship'].asfactor()\n",
    "test_hdf['race'] = test_hdf['race'].asfactor()\n",
    "test_hdf['sex'] = test_hdf['sex'].asfactor()\n",
    "test_hdf['native_country'] = test_hdf['native_country'].asfactor()\n",
    "\n",
    "df_predict = model.predict(test_hdf)\n",
    "df_predict = df_predict.cbind(test_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc105d04-65b1-4434-8432-fa0b137c1d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:48:29.780 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_62_sid_88b4 (cols_py py_61_sid_88b4 'label'))), session_id=_sid_88b4}\n",
      "10-20 18:48:29.790 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_62_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>SHAP Explanation</h1>"
      ],
      "text/markdown": [
       "\n",
       "\n",
       "# SHAP Explanation"
      ],
      "text/plain": [
       "\n",
       "\n",
       "# SHAP Explanation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<blockquote>SHAP explanation shows contribution of features for a given instance. The sum of the feature contributions and the bias term is equal to the raw prediction of the model, i.e., prediction before applying inverse link function. H2O implements TreeSHAP which when the features are correlated, can increase contribution of a feature that had no influence on the prediction.</blockquote>"
      ],
      "text/markdown": [
       "\n",
       "> SHAP explanation shows contribution of features for a given instance. The sum of the feature contributions and the bias term is equal to the raw prediction of the model, i.e., prediction before applying inverse link function. H2O implements TreeSHAP which when the features are correlated, can increase contribution of a feature that had no influence on the prediction."
      ],
      "text/plain": [
       "\n",
       "> SHAP explanation shows contribution of features for a given instance. The sum of the feature contributions and the bias term is equal to the raw prediction of the model, i.e., prediction before applying inverse link function. H2O implements TreeSHAP which when the features are correlated, can increase contribution of a feature that had no influence on the prediction."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:48:29.844 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_63_sid_88b4 (rows py_61_sid_88b4 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:29.863 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /4/Predictions/models/GBM_1_AutoML_1_20231020_182658/frames/py_63_sid_88b4, parms: {predict_contributions_output_format=Original, compare_abs=False, predict_contributions=True}\n",
      "10-20 18:48:30.089 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/Frames/contributions__baec_GBM_1_AutoML_1_20231020_182658_on_py_63_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:30.127 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor contributions__baec_GBM_1_AutoML_1_20231020_182658_on_py_63_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.155 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character contributions__baec_GBM_1_AutoML_1_20231020_182658_on_py_63_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.185 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric contributions__baec_GBM_1_AutoML_1_20231020_182658_on_py_63_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.197 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /4/Predictions/models/GBM_1_AutoML_1_20231020_182658/frames/py_63_sid_88b4, parms: {}\n",
      "10-20 18:48:30.211 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/transformation_ac4f_GBM_1_AutoML_1_20231020_182658_on_py_63_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:30.279 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_64_sid_88b4 (rows (cols_py transformation_ac4f_GBM_1_AutoML_1_20231020_182658_on_py_63_sid_88b4 'predict') 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:30.286 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/py_64_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:30.331 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(flatten py_64_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.338 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_64_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.379 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor py_63_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.417 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_63_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.448 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_63_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.530 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_66_sid_88b4 (levels (tmp= py_65_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'predict'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:30.540 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_66_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.545 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_65_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.622 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_68_sid_88b4 (levels (tmp= py_67_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'workclass'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:30.631 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_68_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.637 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_67_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.711 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_70_sid_88b4 (levels (tmp= py_69_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'education'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:30.720 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_70_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.724 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_69_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.803 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_72_sid_88b4 (levels (tmp= py_71_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'marital_status'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:30.812 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_72_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.816 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_71_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.896 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_74_sid_88b4 (levels (tmp= py_73_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'occupation'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:30.905 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_74_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.910 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_73_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:30.992 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_76_sid_88b4 (levels (tmp= py_75_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'relationship'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.001 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_76_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.008 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_75_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.110 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_78_sid_88b4 (levels (tmp= py_77_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'race'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.118 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_78_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.123 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_77_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.201 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_80_sid_88b4 (levels (tmp= py_79_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'sex'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.210 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_80_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.221 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_79_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.306 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_82_sid_88b4 (levels (tmp= py_81_sid_88b4 (as.factor (cols_py py_63_sid_88b4 'native_country'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.315 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_82_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.320 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_81_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.330 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_63_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>Individual Conditional Expectation</h1>"
      ],
      "text/markdown": [
       "\n",
       "\n",
       "# Individual Conditional Expectation"
      ],
      "text/plain": [
       "\n",
       "\n",
       "# Individual Conditional Expectation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<blockquote>Individual conditional expectations (ICE) plot gives a graphical depiction of the marginal effect of a variable on the response for a given row. ICE plot is similar to partial dependence plot (PDP), PDP shows the average effect of a feature while ICE plot shows the effect for a single instance.</blockquote>"
      ],
      "text/markdown": [
       "\n",
       "> Individual conditional expectations (ICE) plot gives a graphical depiction of the marginal effect of a variable on the response for a given row. ICE plot is similar to partial dependence plot (PDP), PDP shows the average effect of a feature while ICE plot shows the effect for a single instance."
      ],
      "text/plain": [
       "\n",
       "> Individual conditional expectations (ICE) plot gives a graphical depiction of the marginal effect of a variable on the response for a given row. ICE plot is similar to partial dependence plot (PDP), PDP shows the average effect of a feature while ICE plot shows the effect for a single instance."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:48:31.608 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_83_sid_88b4 (cols_py py_61_sid_88b4 'relationship'))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.614 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_83_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.667 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_84_sid_88b4 (rows (cols_py py_61_sid_88b4 'relationship') 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:31.673 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/py_84_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:31.702 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(flatten py_84_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.706 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_84_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.758 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_86_sid_88b4 (levels (tmp= py_85_sid_88b4 (cols_py py_61_sid_88b4 'relationship')))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.767 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_86_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.771 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_85_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.831 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_87_sid_88b4 (cols_py py_61_sid_88b4 'relationship'))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.864 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_87_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.895 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_87_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.970 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_89_sid_88b4 (levels (tmp= py_88_sid_88b4 (as.factor (cols_py py_87_sid_88b4 'relationship'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:31.980 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_89_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:31.985 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_88_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.013 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_87_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.073 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_91_sid_88b4 (levels (tmp= py_90_sid_88b4 (cols_py py_61_sid_88b4 'relationship')))), session_id=_sid_88b4}\n",
      "10-20 18:48:32.082 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_91_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.087 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_90_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.091 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /3/PartialDependence/, parms: {row_index=0, nbins=7, add_missing_na=False, model_id=GBM_1_AutoML_1_20231020_182658, cols=[relationship], frame_id=py_61_sid_88b4}\n",
      "10-20 18:48:32.330 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/PartialDependence/_b615806bb3a59a5e2dab6152e27d40c0, parms: {}\n",
      "10-20 18:48:32.416 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_92_sid_88b4 (cols_py py_61_sid_88b4 'relationship'))), session_id=_sid_88b4}\n",
      "10-20 18:48:32.451 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_92_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.496 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_92_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.613 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_94_sid_88b4 (levels (tmp= py_93_sid_88b4 (as.factor (cols_py py_92_sid_88b4 'relationship'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:32.626 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_94_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.632 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_93_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.662 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_92_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10-20 18:48:32.883 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_95_sid_88b4 (cols_py py_61_sid_88b4 'capital_gain'))), session_id=_sid_88b4}\n",
      "10-20 18:48:32.890 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_95_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:32.960 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_96_sid_88b4 (rows (cols_py py_61_sid_88b4 'capital_gain') 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:32.967 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/Frames/py_96_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:32.999 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(flatten py_96_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.003 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_96_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.009 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /3/PartialDependence/, parms: {row_index=0, nbins=100, add_missing_na=False, model_id=GBM_1_AutoML_1_20231020_182658, cols=[capital_gain], frame_id=py_61_sid_88b4}\n",
      "10-20 18:48:33.230 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/PartialDependence/_b2fcc1097268f4b566c998a0ae0248f7, parms: {}\n",
      "10-20 18:48:33.310 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_97_sid_88b4 (cols_py py_61_sid_88b4 'capital_gain'))), session_id=_sid_88b4}\n",
      "10-20 18:48:33.347 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_97_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.383 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_97_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.410 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_97_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10-20 18:48:33.646 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_98_sid_88b4 (cols_py py_61_sid_88b4 'education'))), session_id=_sid_88b4}\n",
      "10-20 18:48:33.650 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_98_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.707 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_99_sid_88b4 (rows (cols_py py_61_sid_88b4 'education') 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:33.713 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/py_99_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:33.744 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(flatten py_99_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.749 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_99_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.807 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_101_sid_88b4 (levels (tmp= py_100_sid_88b4 (cols_py py_61_sid_88b4 'education')))), session_id=_sid_88b4}\n",
      "10-20 18:48:33.816 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_101_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.820 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_100_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.879 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_102_sid_88b4 (cols_py py_61_sid_88b4 'education'))), session_id=_sid_88b4}\n",
      "10-20 18:48:33.915 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_102_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:33.948 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_102_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.030 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_104_sid_88b4 (levels (tmp= py_103_sid_88b4 (as.factor (cols_py py_102_sid_88b4 'education'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:34.041 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_104_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.045 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_103_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.076 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_102_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.143 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_106_sid_88b4 (levels (tmp= py_105_sid_88b4 (cols_py py_61_sid_88b4 'education')))), session_id=_sid_88b4}\n",
      "10-20 18:48:34.158 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_106_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.163 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_105_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.171 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /3/PartialDependence/, parms: {row_index=0, nbins=17, add_missing_na=False, model_id=GBM_1_AutoML_1_20231020_182658, cols=[education], frame_id=py_61_sid_88b4}\n",
      "10-20 18:48:34.225 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/PartialDependence/_bf6d3a0026d64e0a3eff471a53784546, parms: {}\n",
      "10-20 18:48:34.299 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_107_sid_88b4 (cols_py py_61_sid_88b4 'education'))), session_id=_sid_88b4}\n",
      "10-20 18:48:34.328 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_107_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.387 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_107_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.467 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_109_sid_88b4 (levels (tmp= py_108_sid_88b4 (as.factor (cols_py py_107_sid_88b4 'education'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:34.476 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_109_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.482 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_108_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.617 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_33_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.638 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_107_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10-20 18:48:34.904 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_110_sid_88b4 (cols_py py_61_sid_88b4 'occupation'))), session_id=_sid_88b4}\n",
      "10-20 18:48:34.908 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_110_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:34.962 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_111_sid_88b4 (rows (cols_py py_61_sid_88b4 'occupation') 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:34.969 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/py_111_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:35.005 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(flatten py_111_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.009 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_111_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.063 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_113_sid_88b4 (levels (tmp= py_112_sid_88b4 (cols_py py_61_sid_88b4 'occupation')))), session_id=_sid_88b4}\n",
      "10-20 18:48:35.071 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_113_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.076 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_112_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.128 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_114_sid_88b4 (cols_py py_61_sid_88b4 'occupation'))), session_id=_sid_88b4}\n",
      "10-20 18:48:35.159 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_114_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.188 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_114_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.261 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_116_sid_88b4 (levels (tmp= py_115_sid_88b4 (as.factor (cols_py py_114_sid_88b4 'occupation'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:35.270 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_116_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.274 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_115_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.301 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_114_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.355 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_118_sid_88b4 (levels (tmp= py_117_sid_88b4 (cols_py py_61_sid_88b4 'occupation')))), session_id=_sid_88b4}\n",
      "10-20 18:48:35.366 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_118_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.370 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_117_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.374 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /3/PartialDependence/, parms: {row_index=0, nbins=16, add_missing_na=False, model_id=GBM_1_AutoML_1_20231020_182658, cols=[occupation], frame_id=py_61_sid_88b4}\n",
      "10-20 18:48:35.607 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/PartialDependence/_8e5668c30a5348caf65a45db0fcb4f8f, parms: {}\n",
      "10-20 18:48:35.689 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_119_sid_88b4 (cols_py py_61_sid_88b4 'occupation'))), session_id=_sid_88b4}\n",
      "10-20 18:48:35.722 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_119_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.754 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_119_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.847 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_121_sid_88b4 (levels (tmp= py_120_sid_88b4 (as.factor (cols_py py_119_sid_88b4 'occupation'))))), session_id=_sid_88b4}\n",
      "10-20 18:48:35.859 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_121_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.864 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_120_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:35.898 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_119_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10-20 18:48:36.163 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_122_sid_88b4 (cols_py py_61_sid_88b4 'age'))), session_id=_sid_88b4}\n",
      "10-20 18:48:36.168 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_122_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:36.231 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(tmp= py_123_sid_88b4 (rows (cols_py py_61_sid_88b4 'age') 0)), session_id=_sid_88b4}\n",
      "10-20 18:48:36.237 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/py_123_sid_88b4, parms: {column_count=-1, column_offset=0, row_offset=0, full_column_count=-1, row_count=10}\n",
      "10-20 18:48:36.270 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(flatten py_123_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:36.274 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_123_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:36.280 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /3/PartialDependence/, parms: {row_index=0, nbins=100, add_missing_na=False, model_id=GBM_1_AutoML_1_20231020_182658, cols=[age], frame_id=py_61_sid_88b4}\n",
      "10-20 18:48:36.531 172.17.0.2:54321      22766  4648757-64  INFO water.default: GET /3/PartialDependence/_99f39d6f955d86336e1a8b1427744122, parms: {}\n",
      "10-20 18:48:36.612 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.factor (tmp= py_124_sid_88b4 (cols_py py_61_sid_88b4 'age'))), session_id=_sid_88b4}\n",
      "10-20 18:48:36.638 172.17.0.2:54321      22766  4648757-64  INFO water.default: POST /99/Rapids, parms: {ast=(is.character py_124_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:36.664 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(is.numeric py_124_sid_88b4), session_id=_sid_88b4}\n",
      "10-20 18:48:36.685 172.17.0.2:54321      22766  4648757-67  INFO water.default: POST /99/Rapids, parms: {ast=(rm py_124_sid_88b4), session_id=_sid_88b4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>SHAP Explanation</h1>"
      ],
      "text/markdown": [
       "\n",
       "\n",
       "# SHAP Explanation"
      ],
      "text/plain": [
       "\n",
       "\n",
       "# SHAP Explanation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<blockquote>SHAP explanation shows contribution of features for a given instance. The sum of the feature contributions and the bias term is equal to the raw prediction of the model, i.e., prediction before applying inverse link function. H2O implements TreeSHAP which when the features are correlated, can increase contribution of a feature that had no influence on the prediction.</blockquote>"
      ],
      "text/markdown": [
       "\n",
       "> SHAP explanation shows contribution of features for a given instance. The sum of the feature contributions and the bias term is equal to the raw prediction of the model, i.e., prediction before applying inverse link function. H2O implements TreeSHAP which when the features are correlated, can increase contribution of a feature that had no influence on the prediction."
      ],
      "text/plain": [
       "\n",
       "> SHAP explanation shows contribution of features for a given instance. The sum of the feature contributions and the bias term is equal to the raw prediction of the model, i.e., prediction before applying inverse link function. H2O implements TreeSHAP which when the features are correlated, can increase contribution of a feature that had no influence on the prediction."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29da16eb20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Individual Conditional Expectation</h1>"
      ],
      "text/markdown": [
       "\n",
       "\n",
       "# Individual Conditional Expectation"
      ],
      "text/plain": [
       "\n",
       "\n",
       "# Individual Conditional Expectation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<blockquote>Individual conditional expectations (ICE) plot gives a graphical depiction of the marginal effect of a variable on the response for a given row. ICE plot is similar to partial dependence plot (PDP), PDP shows the average effect of a feature while ICE plot shows the effect for a single instance.</blockquote>"
      ],
      "text/markdown": [
       "\n",
       "> Individual conditional expectations (ICE) plot gives a graphical depiction of the marginal effect of a variable on the response for a given row. ICE plot is similar to partial dependence plot (PDP), PDP shows the average effect of a feature while ICE plot shows the effect for a single instance."
      ],
      "text/plain": [
       "\n",
       "> Individual conditional expectations (ICE) plot gives a graphical depiction of the marginal effect of a variable on the response for a given row. ICE plot is similar to partial dependence plot (PDP), PDP shows the average effect of a feature while ICE plot shows the effect for a single instance."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29da0e1bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29d3b4c9a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29d39e0ee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29d3f806a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7f29d3bc8e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.explain_row(df_predict, row_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580763e-444c-407d-9105-0640668b15b5",
   "metadata": {},
   "source": [
    "### Saving output and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64db75da-8fab-474a-bd03-f617fd01d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:50:09.142 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/Frames/py_61_sid_88b4/light, parms: {full_column_count=0, row_count=0}\n",
      "10-20 18:50:09.144 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/Frames/py_61_sid_88b4/light?row_count=0&full_column_count=0 successfully responded for the GET.\n",
      "10-20 18:50:09.150 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 18:50:09.154 172.17.0.2:54321      22766  4648757-67  INFO water.default: GET /3/FrameChunks/py_61_sid_88b4, parms: {}\n",
      "10-20 18:50:09.156 172.17.0.2:54321      22766    Thread-4  INFO ai.h2o.sparkling.H2OFrame: H2O node http://172.17.0.2:54321/3/FrameChunks/py_61_sid_88b4 successfully responded for the GET.\n",
      "10-20 18:50:09.320 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 18:50:09.340 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 18:50:09.341 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 18:50:09.396 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "10-20 18:50:09.397 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 19 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 18:50:09.398 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 20 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "10-20 18:50:09.398 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:50:09.398 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:50:09.402 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[78] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 18:50:09.419 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 188.6 KiB, free 434.2 MiB)\n",
      "10-20 18:50:09.443 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 70.0 KiB, free 434.1 MiB)\n",
      "10-20 18:50:09.443 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 95675304fa2d:41565 (size: 70.0 KiB, free: 434.3 MiB)\n",
      "10-20 18:50:09.445 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on 95675304fa2d:41565 in memory (size: 9.3 KiB, free: 434.3 MiB)\n",
      "10-20 18:50:09.448 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:50:09.449 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[78] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:50:09.449 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "10-20 18:50:09.451 172.17.0.2:54321      22766  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (95675304fa2d, executor driver, partition 0, ANY, 4267 bytes) taskResourceAssignments Map()\n",
      "10-20 18:50:09.451 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 20.0 (TID 20)\n",
      "10-20 18:50:09.499 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 18:50:09.500 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 18:50:09.504 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 18:50:09.508 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 18:50:09.520 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 18:50:09.520 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 18:50:09.520 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 18:50:09.520 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 18:50:09.521 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 18:50:09.521 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 18:50:09.521 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 18:50:09.521 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 18:50:09.521 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 18:50:09.521 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 18:50:09.547 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"predict\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 2,\n",
      "      \"vals\" : [ \"0\", \"1\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p0\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 0.7649085917862691,\n",
      "      \"min\" : 0.003855634140302655,\n",
      "      \"std\" : 0.3028886678091514,\n",
      "      \"max\" : 0.9996194657177525,\n",
      "      \"sparsity\" : 0.0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p1\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 0.23509140821372984,\n",
      "      \"min\" : 3.805342822475405E-4,\n",
      "      \"std\" : 0.3028886678091515,\n",
      "      \"max\" : 0.9961443658596973,\n",
      "      \"sparsity\" : 0.0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age\",\n",
      "    \"type\" : \"byte\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 38.76745900129004,\n",
      "      \"min\" : 17.0,\n",
      "      \"std\" : 13.849186814264337,\n",
      "      \"max\" : 90.0,\n",
      "      \"sparsity\" : 0.0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"workclass\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 9,\n",
      "      \"vals\" : [ \" Federal-gov\", \" Local-gov\", \" Never-worked\", \" Private\", \" Self-emp-inc\", \" Self-emp-not-inc\", \" State-gov\", \" Without-pay\", \"NA\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"fnlwgt\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 189435.6777839201,\n",
      "      \"min\" : 13492.0,\n",
      "      \"std\" : 105714.90767083282,\n",
      "      \"max\" : 1490400.0,\n",
      "      \"sparsity\" : 0.0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"education\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 16,\n",
      "      \"vals\" : [ \" 10th\", \" 11th\", \" 12th\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" Assoc-acdm\", \" Assoc-voc\", \" Bachelors\", \" Doctorate\", \" HS-grad\", \" Masters\", \" Preschool\", \" Prof-school\", \" Some-college\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"marital_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 7,\n",
      "      \"vals\" : [ \" Divorced\", \" Married-AF-spouse\", \" Married-civ-spouse\", \" Married-spouse-absent\", \" Never-married\", \" Separated\", \" Widowed\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"occupation\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 15,\n",
      "      \"vals\" : [ \" Adm-clerical\", \" Armed-Forces\", \" Craft-repair\", \" Exec-managerial\", \" Farming-fishing\", \" Handlers-cleaners\", \" Machine-op-inspct\", \" Other-service\", \" Priv-house-serv\", \" Prof-specialty\", \" Protective-serv\", \" Sales\", \" Tech-support\", \" Transport-moving\", \"NA\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"relationship\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 6,\n",
      "      \"vals\" : [ \" Husband\", \" Not-in-family\", \" Other-relative\", \" Own-child\", \" Unmarried\", \" Wife\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"race\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 5,\n",
      "      \"vals\" : [ \" Amer-Indian-Eskimo\", \" Asian-Pac-Islander\", \" Black\", \" Other\", \" White\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sex\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 2,\n",
      "      \"vals\" : [ \" Female\", \" Male\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"capital_gain\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 1081.905104109084,\n",
      "      \"min\" : 0.0,\n",
      "      \"std\" : 7583.935967887082,\n",
      "      \"max\" : 99999.0,\n",
      "      \"sparsity\" : 0.9187396351575456\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"capital_loss\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 87.89926908666544,\n",
      "      \"min\" : 0.0,\n",
      "      \"std\" : 403.10528562931455,\n",
      "      \"max\" : 3770.0,\n",
      "      \"sparsity\" : 0.9531355567839813\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"hours_per_week\",\n",
      "    \"type\" : \"byte\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"naCnt\" : 0,\n",
      "      \"count\" : 16281,\n",
      "      \"mean\" : 40.39223634911842,\n",
      "      \"min\" : 1.0,\n",
      "      \"std\" : 12.479332247112266,\n",
      "      \"max\" : 99.0,\n",
      "      \"sparsity\" : 0.0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"native_country\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"count\" : 16281,\n",
      "      \"cardinality\" : 41,\n",
      "      \"vals\" : [ \" Cambodia\", \" Canada\", \" China\", \" Columbia\", \" Cuba\", \" Dominican-Republic\", \" Ecuador\", \" El-Salvador\", \" England\", \" France\", \" Germany\", \" Greece\", \" Guatemala\", \" Haiti\", \" Honduras\", \" Hong\", \" Hungary\", \" India\", \" Iran\", \" Ireland\", \" Italy\", \" Jamaica\", \" Japan\", \" Laos\", \" Mexico\", \" Nicaragua\", \" Outlying-US(Guam-USVI-etc)\", \" Peru\", \" Philippines\", \" Poland\", \" Portugal\", \" Puerto-Rico\", \" Scotland\", \" South\", \" Taiwan\", \" Thailand\", \" Trinadad&Tobago\", \" United-States\", \" Vietnam\", \" Yugoslavia\", \"NA\" ],\n",
      "      \"naCnt\" : 0\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required binary predict (UTF8);\n",
      "  required double p0;\n",
      "  required double p1;\n",
      "  required int32 age (INT_8);\n",
      "  required binary workclass (UTF8);\n",
      "  required int32 fnlwgt;\n",
      "  required binary education (UTF8);\n",
      "  required binary marital_status (UTF8);\n",
      "  required binary occupation (UTF8);\n",
      "  required binary relationship (UTF8);\n",
      "  required binary race (UTF8);\n",
      "  required binary sex (UTF8);\n",
      "  required int32 capital_gain;\n",
      "  required int32 capital_loss (INT_16);\n",
      "  required int32 hours_per_week (INT_8);\n",
      "  required binary native_country (UTF8);\n",
      "}\n",
      "\n",
      "       \n",
      "10-20 18:50:09.657 172.17.0.2:54321      22766  0 (TID 20)  INFO ai.h2o.sparkling.backend.H2OChunk: H2O node http://172.17.0.2:54321/3/Chunk successfully responded for the POST.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:50:10.082 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1355376\n",
      "10-20 18:50:10.322 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201850094284408001017747594_0020_m_000000_20: Committed\n",
      "10-20 18:50:10.334 172.17.0.2:54321      22766  0 (TID 20)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 20.0 (TID 20). 2396 bytes result sent to driver\n",
      "10-20 18:50:10.335 172.17.0.2:54321      22766  t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 884 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:50:10.335 172.17.0.2:54321      22766  t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "10-20 18:50:10.335 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 20 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.933 s\n",
      "10-20 18:50:10.336 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:50:10.336 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished\n",
      "10-20 18:50:10.336 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 19 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.940755 s\n",
      "10-20 18:50:10.354 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job ec1138e0-6767-4fc4-b70c-b4c4cbd3da1b committed.\n",
      "10-20 18:50:10.357 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job ec1138e0-6767-4fc4-b70c-b4c4cbd3da1b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    hc.asSparkFrame(df_predict).drop('label')\n",
    "    .write.parquet(pred_path, mode='overwrite')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98733ca6-cc56-4358-b68c-c3aea7bbf6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:50:20.282 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.\n",
      "10-20 18:50:20.355 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on 95675304fa2d:41565 in memory (size: 70.0 KiB, free: 434.4 MiB)\n",
      "10-20 18:50:20.374 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n",
      "10-20 18:50:20.375 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 20 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 18:50:20.375 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 21 (load at NativeMethodAccessorImpl.java:0)\n",
      "10-20 18:50:20.375 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:50:20.376 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:50:20.377 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[82] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 18:50:20.386 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 84.5 KiB, free 434.3 MiB)\n",
      "10-20 18:50:20.399 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 434.3 MiB)\n",
      "10-20 18:50:20.400 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 95675304fa2d:41565 (size: 30.1 KiB, free: 434.4 MiB)\n",
      "10-20 18:50:20.401 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:50:20.402 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[82] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:50:20.403 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "10-20 18:50:20.409 172.17.0.2:54321      22766  ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4700 bytes) taskResourceAssignments Map()\n",
      "10-20 18:50:20.413 172.17.0.2:54321      22766  0 (TID 21)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 21.0 (TID 21)\n",
      "10-20 18:50:20.520 172.17.0.2:54321      22766  0 (TID 21)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 21.0 (TID 21). 5595 bytes result sent to driver\n",
      "10-20 18:50:20.522 172.17.0.2:54321      22766  t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 118 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:50:20.522 172.17.0.2:54321      22766  t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "10-20 18:50:20.522 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 21 (load at NativeMethodAccessorImpl.java:0) finished in 0.144 s\n",
      "10-20 18:50:20.522 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:50:20.522 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "10-20 18:50:20.523 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 20 finished: load at NativeMethodAccessorImpl.java:0, took 0.147993 s\n",
      "10-20 18:50:20.547 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 18:50:20.548 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 18:50:20.548 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<predict: string, p0: double, p1: double, age: tinyint, workclass: string ... 14 more fields>\n",
      "10-20 18:50:20.613 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 46.934767 ms\n",
      "10-20 18:50:20.621 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 184.4 KiB, free 434.1 MiB)\n",
      "10-20 18:50:20.666 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 32.3 KiB, free 434.1 MiB)\n",
      "10-20 18:50:20.670 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 95675304fa2d:41565 (size: 32.3 KiB, free: 434.3 MiB)\n",
      "10-20 18:50:20.671 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 31 from toPandas at /tmp/ipykernel_18038/2714501010.py:1\n",
      "10-20 18:50:20.674 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 18:50:20.684 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.SparkContext: Starting job: toPandas at /tmp/ipykernel_18038/2714501010.py:1\n",
      "10-20 18:50:20.685 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 21 (toPandas at /tmp/ipykernel_18038/2714501010.py:1) with 1 output partitions\n",
      "10-20 18:50:20.686 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 22 (toPandas at /tmp/ipykernel_18038/2714501010.py:1)\n",
      "10-20 18:50:20.686 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 18:50:20.686 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 18:50:20.687 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[86] at toPandas at /tmp/ipykernel_18038/2714501010.py:1), which has no missing parents\n",
      "10-20 18:50:20.697 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 23.7 KiB, free 434.1 MiB)\n",
      "10-20 18:50:20.698 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 434.0 MiB)\n",
      "10-20 18:50:20.699 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 95675304fa2d:41565 (size: 8.5 KiB, free: 434.3 MiB)\n",
      "10-20 18:50:20.700 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 18:50:20.700 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[86] at toPandas at /tmp/ipykernel_18038/2714501010.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 18:50:20.701 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "10-20 18:50:20.703 172.17.0.2:54321      22766  ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()\n",
      "10-20 18:50:20.704 172.17.0.2:54321      22766  0 (TID 22)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 22.0 (TID 22)\n",
      "10-20 18:50:20.763 172.17.0.2:54321      22766  0 (TID 22)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark_pred/part-00000-ad794f34-eb0a-4562-adc8-263e430af157-c000.snappy.parquet, range: 0-419257, partition values: [empty row]\n",
      "10-20 18:50:20.859 172.17.0.2:54321      22766  0 (TID 22)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 22.0 (TID 22). 2940 bytes result sent to driver\n",
      "10-20 18:50:20.859 172.17.0.2:54321      22766  t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 157 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 18:50:20.860 172.17.0.2:54321      22766  t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "10-20 18:50:20.860 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 22 (toPandas at /tmp/ipykernel_18038/2714501010.py:1) finished in 0.173 s\n",
      "10-20 18:50:20.860 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 18:50:20.860 172.17.0.2:54321      22766  event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished\n",
      "10-20 18:50:20.860 172.17.0.2:54321      22766    Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 21 finished: toPandas at /tmp/ipykernel_18038/2714501010.py:1, took 0.176481 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995022</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.819929</td>\n",
       "      <td>0.180071</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.577573</td>\n",
       "      <td>0.422427</td>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012681</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998556</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>18</td>\n",
       "      <td>NA</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NA</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994051</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>198693</td>\n",
       "      <td>10th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997010</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>29</td>\n",
       "      <td>NA</td>\n",
       "      <td>227026</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NA</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090285</td>\n",
       "      <td>0.909715</td>\n",
       "      <td>63</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>104626</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3103</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994831</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>369667</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.944497</td>\n",
       "      <td>0.055503</td>\n",
       "      <td>55</td>\n",
       "      <td>Private</td>\n",
       "      <td>104996</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predict        p0        p1  age          workclass  fnlwgt      education  \\\n",
       "0       0  0.995022  0.004978   25            Private  226802           11th   \n",
       "1       0  0.819929  0.180071   38            Private   89814        HS-grad   \n",
       "2       1  0.577573  0.422427   28          Local-gov  336951     Assoc-acdm   \n",
       "3       1  0.012681  0.987319   44            Private  160323   Some-college   \n",
       "4       0  0.998556  0.001444   18                 NA  103497   Some-college   \n",
       "5       0  0.994051  0.005949   34            Private  198693           10th   \n",
       "6       0  0.997010  0.002990   29                 NA  227026        HS-grad   \n",
       "7       1  0.090285  0.909715   63   Self-emp-not-inc  104626    Prof-school   \n",
       "8       0  0.994831  0.005169   24            Private  369667   Some-college   \n",
       "9       0  0.944497  0.055503   55            Private  104996        7th-8th   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married   Machine-op-inspct       Own-child   Black     Male   \n",
       "1   Married-civ-spouse     Farming-fishing         Husband   White     Male   \n",
       "2   Married-civ-spouse     Protective-serv         Husband   White     Male   \n",
       "3   Married-civ-spouse   Machine-op-inspct         Husband   Black     Male   \n",
       "4        Never-married                  NA       Own-child   White   Female   \n",
       "5        Never-married       Other-service   Not-in-family   White     Male   \n",
       "6        Never-married                  NA       Unmarried   Black     Male   \n",
       "7   Married-civ-spouse      Prof-specialty         Husband   White     Male   \n",
       "8        Never-married       Other-service       Unmarried   White   Female   \n",
       "9   Married-civ-spouse        Craft-repair         Husband   White     Male   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  \n",
       "0             0             0              40   United-States  \n",
       "1             0             0              50   United-States  \n",
       "2             0             0              40   United-States  \n",
       "3          7688             0              40   United-States  \n",
       "4             0             0              30   United-States  \n",
       "5             0             0              30   United-States  \n",
       "6             0             0              40   United-States  \n",
       "7          3103             0              32   United-States  \n",
       "8             0             0              40   United-States  \n",
       "9             0             0              10   United-States  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.load(pred_path).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2810bd2-7307-495a-a64c-420f03188701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:52:23.333 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Rapids, parms: {ast=(rename 'GBM_1_AutoML_1_20231020_182658' 'automl_leader'), session_id=_sid_88b4}\n",
      "10-20 18:52:23.354 172.17.0.2:54321      22766  4648757-65  INFO water.default: GET /99/Models.bin/automl_leader, parms: {export_cross_validation_predictions=False, force=True, dir=outputs/income_automl_h2o/automl_leader}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/notebooks/outputs/income_automl_h2o/automl_leader'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.model_id = 'automl_leader'\n",
    "h2o.save_model(best_model, model_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be459558-f92c-4764-a6fb-88a53d23d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 18:52:42.014 172.17.0.2:54321      22766  4648757-70  INFO water.default: POST /99/Models.bin/, parms: {dir=outputs/income_automl_h2o/automl_leader}\n",
      "10-20 18:52:42.100 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on 95675304fa2d:41565 in memory (size: 32.3 KiB, free: 434.4 MiB)\n",
      "10-20 18:52:42.118 172.17.0.2:54321      22766  4648757-69  INFO water.default: GET /3/Models/automl_leader, parms: {}\n",
      "10-20 18:52:42.138 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on 95675304fa2d:41565 in memory (size: 8.5 KiB, free: 434.4 MiB)\n",
      "10-20 18:52:42.176 172.17.0.2:54321      22766  agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on 95675304fa2d:41565 in memory (size: 30.1 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "model = h2o.load_model(model_path + '/automl_leader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "085ad7eb-934a-4db5-906c-94c7072d0ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: automl_leader\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-22.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-22 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-22 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-22 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-22 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-22 .h2o-table th,\n",
       "#h2o-table-22 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-22 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-22\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th>\n",
       "<th>number_of_internal_trees</th>\n",
       "<th>model_size_in_bytes</th>\n",
       "<th>min_depth</th>\n",
       "<th>max_depth</th>\n",
       "<th>mean_depth</th>\n",
       "<th>min_leaves</th>\n",
       "<th>max_leaves</th>\n",
       "<th>mean_leaves</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>72.0</td>\n",
       "<td>72.0</td>\n",
       "<td>116356.0</td>\n",
       "<td>15.0</td>\n",
       "<td>15.0</td>\n",
       "<td>15.0</td>\n",
       "<td>39.0</td>\n",
       "<td>191.0</td>\n",
       "<td>120.19444</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.07499008289803473\n",
       "RMSE: 0.2738431720858395\n",
       "LogLoss: 0.23889571105783058\n",
       "Mean Per-Class Error: 0.14244552377780226\n",
       "AUC: 0.9514336309556976\n",
       "AUCPR: 0.8749514407177378\n",
       "Gini: 0.9028672619113951</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-23.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-23 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-23 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-23 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table th,\n",
       "#h2o-table-23 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3881431172229534</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>22665.0</td>\n",
       "<td>2055.0</td>\n",
       "<td>0.0831</td>\n",
       "<td> (2055.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1582.0</td>\n",
       "<td>6259.0</td>\n",
       "<td>0.2018</td>\n",
       "<td> (1582.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>24247.0</td>\n",
       "<td>8314.0</td>\n",
       "<td>0.1117</td>\n",
       "<td> (3637.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-24.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-24 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-24 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-24 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-24 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-24 .h2o-table th,\n",
       "#h2o-table-24 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-24 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-24\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3881431</td>\n",
       "<td>0.7748685</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1904882</td>\n",
       "<td>0.8448426</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5957142</td>\n",
       "<td>0.8090894</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4578943</td>\n",
       "<td>0.8923559</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0101622</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4199531</td>\n",
       "<td>0.7019311</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2946177</td>\n",
       "<td>0.8717000</td>\n",
       "<td>241.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2487023</td>\n",
       "<td>0.8753788</td>\n",
       "<td>260.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946796</td>\n",
       "<td>24720.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946796</td>\n",
       "<td>7775.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0012164</td>\n",
       "<td>24720.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0101622</td>\n",
       "<td>7841.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946796</td>\n",
       "<td>0.9915827</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0012164</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0101622</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-25.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-25 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-25 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-25 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-25 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-25 .h2o-table th,\n",
       "#h2o-table-25 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-25 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-25\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.08 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9909478</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928232</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0415763</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9873610</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9892439</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9910336</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0831527</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0831527</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9826722</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9852002</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9890931</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.1246015</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.1246015</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9750012</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9793438</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9866539</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.1661778</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.1661778</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9574821</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1501099</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9681042</td>\n",
       "<td>0.9993861</td>\n",
       "<td>0.9829417</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.2076266</td>\n",
       "<td>313.9920882</td>\n",
       "<td>315.0109892</td>\n",
       "<td>0.2075861</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7894574</td>\n",
       "<td>3.8924802</td>\n",
       "<td>4.0213346</td>\n",
       "<td>0.9373464</td>\n",
       "<td>0.8701897</td>\n",
       "<td>0.9683758</td>\n",
       "<td>0.9265830</td>\n",
       "<td>0.1946180</td>\n",
       "<td>0.4022446</td>\n",
       "<td>289.2480213</td>\n",
       "<td>302.1334602</td>\n",
       "<td>0.3980779</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6511950</td>\n",
       "<td>3.2267284</td>\n",
       "<td>3.7565201</td>\n",
       "<td>0.7770270</td>\n",
       "<td>0.7202185</td>\n",
       "<td>0.9046059</td>\n",
       "<td>0.8578089</td>\n",
       "<td>0.1613315</td>\n",
       "<td>0.5635761</td>\n",
       "<td>222.6728354</td>\n",
       "<td>275.6520074</td>\n",
       "<td>0.5447249</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5191145</td>\n",
       "<td>2.5099610</td>\n",
       "<td>3.4449282</td>\n",
       "<td>0.6044226</td>\n",
       "<td>0.5834808</td>\n",
       "<td>0.8295716</td>\n",
       "<td>0.7892374</td>\n",
       "<td>0.1254942</td>\n",
       "<td>0.6890703</td>\n",
       "<td>150.9961028</td>\n",
       "<td>244.4928161</td>\n",
       "<td>0.6441674</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3043034</td>\n",
       "<td>1.7383521</td>\n",
       "<td>2.8761277</td>\n",
       "<td>0.4186118</td>\n",
       "<td>0.4027787</td>\n",
       "<td>0.6925990</td>\n",
       "<td>0.6604310</td>\n",
       "<td>0.1738299</td>\n",
       "<td>0.8629001</td>\n",
       "<td>73.8352074</td>\n",
       "<td>187.6127697</td>\n",
       "<td>0.7414196</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1584669</td>\n",
       "<td>0.9131769</td>\n",
       "<td>2.3854277</td>\n",
       "<td>0.2199017</td>\n",
       "<td>0.2269236</td>\n",
       "<td>0.5744338</td>\n",
       "<td>0.5520625</td>\n",
       "<td>0.0913149</td>\n",
       "<td>0.9542150</td>\n",
       "<td>-8.6823122</td>\n",
       "<td>138.5427669</td>\n",
       "<td>0.7299836</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0722390</td>\n",
       "<td>0.3264990</td>\n",
       "<td>1.9736672</td>\n",
       "<td>0.0786241</td>\n",
       "<td>0.1111587</td>\n",
       "<td>0.4752779</td>\n",
       "<td>0.4638872</td>\n",
       "<td>0.0326489</td>\n",
       "<td>0.9868639</td>\n",
       "<td>-67.3501004</td>\n",
       "<td>97.3667226</td>\n",
       "<td>0.6412733</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0312478</td>\n",
       "<td>0.1045817</td>\n",
       "<td>1.6621689</td>\n",
       "<td>0.0251843</td>\n",
       "<td>0.0486476</td>\n",
       "<td>0.4002662</td>\n",
       "<td>0.3946841</td>\n",
       "<td>0.0104578</td>\n",
       "<td>0.9973218</td>\n",
       "<td>-89.5418290</td>\n",
       "<td>66.2168918</td>\n",
       "<td>0.5233331</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0143291</td>\n",
       "<td>0.0216816</td>\n",
       "<td>1.4278239</td>\n",
       "<td>0.0052211</td>\n",
       "<td>0.0214481</td>\n",
       "<td>0.3438336</td>\n",
       "<td>0.3413670</td>\n",
       "<td>0.0021681</td>\n",
       "<td>0.9994899</td>\n",
       "<td>-97.8318426</td>\n",
       "<td>42.7823865</td>\n",
       "<td>0.3944737</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0072545</td>\n",
       "<td>0.0051015</td>\n",
       "<td>1.2499904</td>\n",
       "<td>0.0012285</td>\n",
       "<td>0.0103919</td>\n",
       "<td>0.3010096</td>\n",
       "<td>0.2999967</td>\n",
       "<td>0.0005101</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.4898453</td>\n",
       "<td>24.9990403</td>\n",
       "<td>0.2634304</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000031</td>\n",
       "<td>0.0034743</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111073</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051790</td>\n",
       "<td>0.2675653</td>\n",
       "<td>0.2672403</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1107320</td>\n",
       "<td>0.1317152</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003635</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0024043</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.2407575</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.09076467337180787\n",
       "RMSE: 0.3012717599971957\n",
       "LogLoss: 0.28598910685141826\n",
       "Mean Per-Class Error: 0.16988825283166362\n",
       "AUC: 0.9246906817908851\n",
       "AUCPR: 0.819319713891667\n",
       "Gini: 0.8493813635817702</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-26.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-26 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-26 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-26 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-26 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-26 .h2o-table th,\n",
       "#h2o-table-26 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-26 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-26\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>21923.0</td>\n",
       "<td>2797.0</td>\n",
       "<td>0.1131</td>\n",
       "<td> (2797.0/24720.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1777.0</td>\n",
       "<td>6064.0</td>\n",
       "<td>0.2266</td>\n",
       "<td> (1777.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23700.0</td>\n",
       "<td>8861.0</td>\n",
       "<td>0.1405</td>\n",
       "<td> (4574.0/32561.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-27.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-27 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-27 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-27 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-27 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-27 .h2o-table th,\n",
       "#h2o-table-27 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-27 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-27\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3552160</td>\n",
       "<td>0.7261406</td>\n",
       "<td>214.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1400254</td>\n",
       "<td>0.8035536</td>\n",
       "<td>302.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6142915</td>\n",
       "<td>0.7559369</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5160227</td>\n",
       "<td>0.8702435</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0028543</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4035434</td>\n",
       "<td>0.6358758</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2624334</td>\n",
       "<td>0.8375405</td>\n",
       "<td>249.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2419123</td>\n",
       "<td>0.8395175</td>\n",
       "<td>257.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9947330</td>\n",
       "<td>24720.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9947330</td>\n",
       "<td>7759.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0014753</td>\n",
       "<td>24720.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0028543</td>\n",
       "<td>7841.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9947330</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9947330</td>\n",
       "<td>0.9895422</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0014753</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0028543</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-28.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-28 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-28 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-28 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-28 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-28 .h2o-table th,\n",
       "#h2o-table-28 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-28 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-28\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.00 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9914024</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931894</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931894</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td>\n",
       "<td>0.0415763</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9872966</td>\n",
       "<td>4.1271827</td>\n",
       "<td>4.1399209</td>\n",
       "<td>0.9938650</td>\n",
       "<td>0.9894588</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9913241</td>\n",
       "<td>0.0413213</td>\n",
       "<td>0.0828976</td>\n",
       "<td>312.7182663</td>\n",
       "<td>313.9920882</td>\n",
       "<td>0.0828167</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9812125</td>\n",
       "<td>4.1143269</td>\n",
       "<td>4.1314070</td>\n",
       "<td>0.9907692</td>\n",
       "<td>0.9845142</td>\n",
       "<td>0.9948823</td>\n",
       "<td>0.9890588</td>\n",
       "<td>0.0410662</td>\n",
       "<td>0.1239638</td>\n",
       "<td>311.4326862</td>\n",
       "<td>313.1407006</td>\n",
       "<td>0.1237615</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9707915</td>\n",
       "<td>4.1271827</td>\n",
       "<td>4.1303501</td>\n",
       "<td>0.9938650</td>\n",
       "<td>0.9767070</td>\n",
       "<td>0.9946278</td>\n",
       "<td>0.9859685</td>\n",
       "<td>0.0413213</td>\n",
       "<td>0.1652850</td>\n",
       "<td>312.7182663</td>\n",
       "<td>313.0350110</td>\n",
       "<td>0.1650019</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9504264</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1322654</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9622305</td>\n",
       "<td>0.9950890</td>\n",
       "<td>0.9812180</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.2067338</td>\n",
       "<td>313.9920882</td>\n",
       "<td>313.2265439</td>\n",
       "<td>0.2064102</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7849150</td>\n",
       "<td>3.5353719</td>\n",
       "<td>3.8339103</td>\n",
       "<td>0.8513514</td>\n",
       "<td>0.8627023</td>\n",
       "<td>0.9232422</td>\n",
       "<td>0.9219783</td>\n",
       "<td>0.1767632</td>\n",
       "<td>0.3834970</td>\n",
       "<td>253.5371936</td>\n",
       "<td>283.3910320</td>\n",
       "<td>0.3733837</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6403136</td>\n",
       "<td>2.8747216</td>\n",
       "<td>3.5142462</td>\n",
       "<td>0.6922604</td>\n",
       "<td>0.7134062</td>\n",
       "<td>0.8462641</td>\n",
       "<td>0.8524685</td>\n",
       "<td>0.1437317</td>\n",
       "<td>0.5272287</td>\n",
       "<td>187.4721625</td>\n",
       "<td>251.4246206</td>\n",
       "<td>0.4968484</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5106238</td>\n",
       "<td>2.3671177</td>\n",
       "<td>3.2275081</td>\n",
       "<td>0.5700246</td>\n",
       "<td>0.5762666</td>\n",
       "<td>0.7772148</td>\n",
       "<td>0.7834287</td>\n",
       "<td>0.1183523</td>\n",
       "<td>0.6455809</td>\n",
       "<td>136.7117718</td>\n",
       "<td>222.7508116</td>\n",
       "<td>0.5868835</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3014894</td>\n",
       "<td>1.6503504</td>\n",
       "<td>2.7018427</td>\n",
       "<td>0.3974201</td>\n",
       "<td>0.4011178</td>\n",
       "<td>0.6506295</td>\n",
       "<td>0.6560047</td>\n",
       "<td>0.1650300</td>\n",
       "<td>0.8106109</td>\n",
       "<td>65.0350392</td>\n",
       "<td>170.1842690</td>\n",
       "<td>0.6725445</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1602280</td>\n",
       "<td>0.9833231</td>\n",
       "<td>2.2722458</td>\n",
       "<td>0.2367936</td>\n",
       "<td>0.2265763</td>\n",
       "<td>0.5471785</td>\n",
       "<td>0.5486559</td>\n",
       "<td>0.0983293</td>\n",
       "<td>0.9089402</td>\n",
       "<td>-1.6676853</td>\n",
       "<td>127.2245789</td>\n",
       "<td>0.6703480</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0750068</td>\n",
       "<td>0.5458655</td>\n",
       "<td>1.9269909</td>\n",
       "<td>0.1314496</td>\n",
       "<td>0.1134429</td>\n",
       "<td>0.4640378</td>\n",
       "<td>0.4616186</td>\n",
       "<td>0.0545849</td>\n",
       "<td>0.9635251</td>\n",
       "<td>-45.4134492</td>\n",
       "<td>92.6990940</td>\n",
       "<td>0.6105315</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0324734</td>\n",
       "<td>0.2180911</td>\n",
       "<td>1.6421889</td>\n",
       "<td>0.0525184</td>\n",
       "<td>0.0508273</td>\n",
       "<td>0.3954548</td>\n",
       "<td>0.3931569</td>\n",
       "<td>0.0218084</td>\n",
       "<td>0.9853335</td>\n",
       "<td>-78.1908874</td>\n",
       "<td>64.2188883</td>\n",
       "<td>0.5075422</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0152883</td>\n",
       "<td>0.0982048</td>\n",
       "<td>1.4216294</td>\n",
       "<td>0.0236486</td>\n",
       "<td>0.0225705</td>\n",
       "<td>0.3423419</td>\n",
       "<td>0.3402183</td>\n",
       "<td>0.0098202</td>\n",
       "<td>0.9951537</td>\n",
       "<td>-90.1795224</td>\n",
       "<td>42.1629402</td>\n",
       "<td>0.3887621</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0075502</td>\n",
       "<td>0.0357108</td>\n",
       "<td>1.2483962</td>\n",
       "<td>0.0085995</td>\n",
       "<td>0.0109297</td>\n",
       "<td>0.3006257</td>\n",
       "<td>0.2990588</td>\n",
       "<td>0.0035710</td>\n",
       "<td>0.9987247</td>\n",
       "<td>-96.4289172</td>\n",
       "<td>24.8396231</td>\n",
       "<td>0.2617505</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000031</td>\n",
       "<td>0.0035946</td>\n",
       "<td>0.0102031</td>\n",
       "<td>1.1108239</td>\n",
       "<td>0.0024570</td>\n",
       "<td>0.0053519</td>\n",
       "<td>0.2674970</td>\n",
       "<td>0.2664258</td>\n",
       "<td>0.0010203</td>\n",
       "<td>0.9997449</td>\n",
       "<td>-98.9796906</td>\n",
       "<td>11.0823910</td>\n",
       "<td>0.1313792</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003254</td>\n",
       "<td>0.0025508</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0006143</td>\n",
       "<td>0.0025178</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.2400358</td>\n",
       "<td>0.0002551</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.7449227</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-29.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-29 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-29 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-29 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-29 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-29 .h2o-table th,\n",
       "#h2o-table-29 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-29 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-29\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8601089</td>\n",
       "<td>0.0044925</td>\n",
       "<td>0.8565945</td>\n",
       "<td>0.8571867</td>\n",
       "<td>0.8567261</td>\n",
       "<td>0.8653256</td>\n",
       "<td>0.8647113</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9245689</td>\n",
       "<td>0.0045425</td>\n",
       "<td>0.9281911</td>\n",
       "<td>0.9266950</td>\n",
       "<td>0.9169862</td>\n",
       "<td>0.9237955</td>\n",
       "<td>0.9271767</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1398912</td>\n",
       "<td>0.0044925</td>\n",
       "<td>0.1434055</td>\n",
       "<td>0.1428133</td>\n",
       "<td>0.1432740</td>\n",
       "<td>0.1346744</td>\n",
       "<td>0.1352887</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>911.0</td>\n",
       "<td>29.2831</td>\n",
       "<td>934.0</td>\n",
       "<td>930.0</td>\n",
       "<td>933.0</td>\n",
       "<td>877.0</td>\n",
       "<td>881.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7012632</td>\n",
       "<td>0.0115764</td>\n",
       "<td>0.7013696</td>\n",
       "<td>0.6881533</td>\n",
       "<td>0.6912776</td>\n",
       "<td>0.7130832</td>\n",
       "<td>0.7124323</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7275420</td>\n",
       "<td>0.0129064</td>\n",
       "<td>0.7373453</td>\n",
       "<td>0.7181818</td>\n",
       "<td>0.7106976</td>\n",
       "<td>0.7300708</td>\n",
       "<td>0.7414147</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.756029</td>\n",
       "<td>0.0189628</td>\n",
       "<td>0.7772113</td>\n",
       "<td>0.7509506</td>\n",
       "<td>0.7312405</td>\n",
       "<td>0.7478875</td>\n",
       "<td>0.7728552</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.154737</td>\n",
       "<td>0.1031931</td>\n",
       "<td>4.005535</td>\n",
       "<td>4.2562094</td>\n",
       "<td>4.236825</td>\n",
       "<td>4.174359</td>\n",
       "<td>4.1007557</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2862227</td>\n",
       "<td>0.0061799</td>\n",
       "<td>0.2837649</td>\n",
       "<td>0.2790983</td>\n",
       "<td>0.2956500</td>\n",
       "<td>0.2881814</td>\n",
       "<td>0.2844188</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2236025</td>\n",
       "<td>0.0248165</td>\n",
       "<td>0.1937269</td>\n",
       "<td>0.2254902</td>\n",
       "<td>0.2543917</td>\n",
       "<td>0.2397436</td>\n",
       "<td>0.2046600</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.6363711</td>\n",
       "<td>0.0145571</td>\n",
       "<td>0.6441514</td>\n",
       "<td>0.6261857</td>\n",
       "<td>0.6169552</td>\n",
       "<td>0.6414377</td>\n",
       "<td>0.6531257</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8314466</td>\n",
       "<td>0.0093553</td>\n",
       "<td>0.8398052</td>\n",
       "<td>0.8285435</td>\n",
       "<td>0.8183318</td>\n",
       "<td>0.8293406</td>\n",
       "<td>0.8412119</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1685534</td>\n",
       "<td>0.0093553</td>\n",
       "<td>0.1601947</td>\n",
       "<td>0.1714565</td>\n",
       "<td>0.1816682</td>\n",
       "<td>0.1706593</td>\n",
       "<td>0.1587881</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0908619</td>\n",
       "<td>0.0017549</td>\n",
       "<td>0.0901266</td>\n",
       "<td>0.0889858</td>\n",
       "<td>0.0934920</td>\n",
       "<td>0.0916711</td>\n",
       "<td>0.0900341</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.8190482</td>\n",
       "<td>0.0109963</td>\n",
       "<td>0.8347300</td>\n",
       "<td>0.8194151</td>\n",
       "<td>0.8051474</td>\n",
       "<td>0.8133871</td>\n",
       "<td>0.8225615</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6848409</td>\n",
       "<td>0.0131621</td>\n",
       "<td>0.6792746</td>\n",
       "<td>0.6694915</td>\n",
       "<td>0.6789100</td>\n",
       "<td>0.7021906</td>\n",
       "<td>0.6943375</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5027688</td>\n",
       "<td>0.0144230</td>\n",
       "<td>0.5188814</td>\n",
       "<td>0.5049439</td>\n",
       "<td>0.4815146</td>\n",
       "<td>0.4967821</td>\n",
       "<td>0.5117221</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7763975</td>\n",
       "<td>0.0248165</td>\n",
       "<td>0.8062730</td>\n",
       "<td>0.7745098</td>\n",
       "<td>0.7456083</td>\n",
       "<td>0.7602564</td>\n",
       "<td>0.7953401</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3014219</td>\n",
       "<td>0.0029039</td>\n",
       "<td>0.3002109</td>\n",
       "<td>0.2983049</td>\n",
       "<td>0.3057647</td>\n",
       "<td>0.3027724</td>\n",
       "<td>0.3000568</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8864957</td>\n",
       "<td>0.0093800</td>\n",
       "<td>0.8733374</td>\n",
       "<td>0.8825773</td>\n",
       "<td>0.8910553</td>\n",
       "<td>0.8984249</td>\n",
       "<td>0.8870837</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-30.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-30 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-30 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-30 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-30 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-30 .h2o-table th,\n",
       "#h2o-table-30 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-30 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-30\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-10-20 18:27:36</td>\n",
       "<td>20.514 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4275749</td>\n",
       "<td>0.5520113</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2408096</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7591904</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:36</td>\n",
       "<td>20.884 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3580666</td>\n",
       "<td>0.4139024</td>\n",
       "<td>0.9231494</td>\n",
       "<td>0.8119101</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1419797</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.111 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3250431</td>\n",
       "<td>0.3518230</td>\n",
       "<td>0.9274531</td>\n",
       "<td>0.8224114</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1421639</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.338 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.3101333</td>\n",
       "<td>0.3198260</td>\n",
       "<td>0.9293457</td>\n",
       "<td>0.8274675</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1381714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.617 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.3008138</td>\n",
       "<td>0.2977300</td>\n",
       "<td>0.9326196</td>\n",
       "<td>0.8341006</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1341482</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:37</td>\n",
       "<td>21.843 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2960021</td>\n",
       "<td>0.2850261</td>\n",
       "<td>0.9348525</td>\n",
       "<td>0.8383497</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1340868</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:38</td>\n",
       "<td>22.070 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2919021</td>\n",
       "<td>0.2753741</td>\n",
       "<td>0.9375426</td>\n",
       "<td>0.8442169</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1300943</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:38</td>\n",
       "<td>22.330 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2887171</td>\n",
       "<td>0.2682057</td>\n",
       "<td>0.9398145</td>\n",
       "<td>0.8490477</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1257640</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:38</td>\n",
       "<td>22.888 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2859562</td>\n",
       "<td>0.2622116</td>\n",
       "<td>0.9418439</td>\n",
       "<td>0.8537178</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1244126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.154 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2838987</td>\n",
       "<td>0.2576104</td>\n",
       "<td>0.9433872</td>\n",
       "<td>0.8571123</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1214336</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.394 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2819706</td>\n",
       "<td>0.2535553</td>\n",
       "<td>0.9448745</td>\n",
       "<td>0.8604069</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1192224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.650 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.2802449</td>\n",
       "<td>0.2500008</td>\n",
       "<td>0.9462984</td>\n",
       "<td>0.8633119</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1181168</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:39</td>\n",
       "<td>23.929 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.2781576</td>\n",
       "<td>0.2464724</td>\n",
       "<td>0.9479604</td>\n",
       "<td>0.8671609</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1157827</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:40</td>\n",
       "<td>24.275 sec</td>\n",
       "<td>65.0</td>\n",
       "<td>0.2762984</td>\n",
       "<td>0.2431486</td>\n",
       "<td>0.9494307</td>\n",
       "<td>0.8705289</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1142778</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:40</td>\n",
       "<td>24.485 sec</td>\n",
       "<td>70.0</td>\n",
       "<td>0.2745972</td>\n",
       "<td>0.2401383</td>\n",
       "<td>0.9507812</td>\n",
       "<td>0.8735590</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1141857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-10-20 18:27:40</td>\n",
       "<td>24.609 sec</td>\n",
       "<td>72.0</td>\n",
       "<td>0.2738432</td>\n",
       "<td>0.2388957</td>\n",
       "<td>0.9514336</td>\n",
       "<td>0.8749514</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1116980</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-31.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-31 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-31 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-31 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-31 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-31 .h2o-table th,\n",
       "#h2o-table-31 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-31 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-31\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>relationship</td>\n",
       "<td>4602.7446289</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2862720</td></tr>\n",
       "<tr><td>capital_gain</td>\n",
       "<td>3140.7709961</td>\n",
       "<td>0.6823692</td>\n",
       "<td>0.1953432</td></tr>\n",
       "<tr><td>education</td>\n",
       "<td>2609.7946777</td>\n",
       "<td>0.5670084</td>\n",
       "<td>0.1623186</td></tr>\n",
       "<tr><td>occupation</td>\n",
       "<td>1140.8848877</td>\n",
       "<td>0.2478706</td>\n",
       "<td>0.0709584</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>1114.5206299</td>\n",
       "<td>0.2421426</td>\n",
       "<td>0.0693187</td></tr>\n",
       "<tr><td>marital_status</td>\n",
       "<td>1045.3726807</td>\n",
       "<td>0.2271194</td>\n",
       "<td>0.0650179</td></tr>\n",
       "<tr><td>capital_loss</td>\n",
       "<td>740.7708740</td>\n",
       "<td>0.1609411</td>\n",
       "<td>0.0460729</td></tr>\n",
       "<tr><td>hours_per_week</td>\n",
       "<td>622.1322021</td>\n",
       "<td>0.1351655</td>\n",
       "<td>0.0386941</td></tr>\n",
       "<tr><td>workclass</td>\n",
       "<td>353.1838379</td>\n",
       "<td>0.0767333</td>\n",
       "<td>0.0219666</td></tr>\n",
       "<tr><td>fnlwgt</td>\n",
       "<td>329.3720703</td>\n",
       "<td>0.0715599</td>\n",
       "<td>0.0204856</td></tr>\n",
       "<tr><td>native_country</td>\n",
       "<td>275.4145508</td>\n",
       "<td>0.0598370</td>\n",
       "<td>0.0171297</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>65.1697006</td>\n",
       "<td>0.0141589</td>\n",
       "<td>0.0040533</td></tr>\n",
       "<tr><td>race</td>\n",
       "<td>38.0887489</td>\n",
       "<td>0.0082752</td>\n",
       "<td>0.0023690</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: automl_leader\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    72                 72                          116356                 15           15           15            39            191           120.194\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.07499008289803473\n",
       "RMSE: 0.2738431720858395\n",
       "LogLoss: 0.23889571105783058\n",
       "Mean Per-Class Error: 0.14244552377780226\n",
       "AUC: 0.9514336309556976\n",
       "AUCPR: 0.8749514407177378\n",
       "Gini: 0.9028672619113951\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3881431172229534\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      22665  2055  0.0831   (2055.0/24720.0)\n",
       "1      1582   6259  0.2018   (1582.0/7841.0)\n",
       "Total  24247  8314  0.1117   (3637.0/32561.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.388143     0.774868  204\n",
       "max f2                       0.190488     0.844843  284\n",
       "max f0point5                 0.595714     0.809089  134\n",
       "max accuracy                 0.457894     0.892356  181\n",
       "max precision                0.99468      1         0\n",
       "max recall                   0.0101622    1         386\n",
       "max specificity              0.99468      1         0\n",
       "max absolute_mcc             0.419953     0.701931  192\n",
       "max min_per_class_accuracy   0.294618     0.8717    241\n",
       "max mean_per_class_accuracy  0.248702     0.875379  260\n",
       "max tns                      0.99468      24720     0\n",
       "max fns                      0.99468      7775      0\n",
       "max fps                      0.00121637   24720     399\n",
       "max tps                      0.0101622    7841      386\n",
       "max tnr                      0.99468      1         0\n",
       "max fnr                      0.99468      0.991583  0\n",
       "max fpr                      0.00121637   1         399\n",
       "max tpr                      0.0101622    1         386\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.08 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010012                    0.990948           4.15266     4.15266            1                0.992823    1                           0.992823            0.0415763       0.0415763                  315.266   315.266            0.0415763\n",
       "2        0.020024                    0.987361           4.15266     4.15266            1                0.989244    1                           0.991034            0.0415763       0.0831527                  315.266   315.266            0.0831527\n",
       "3        0.0300052                   0.982672           4.15266     4.15266            1                0.9852      1                           0.989093            0.0414488       0.124601                   315.266   315.266            0.124601\n",
       "4        0.0400172                   0.975001           4.15266     4.15266            1                0.979344    1                           0.986654            0.0415763       0.166178                   315.266   315.266            0.166178\n",
       "5        0.0500292                   0.957482           4.13992     4.15011            0.996933         0.968104    0.999386                    0.982942            0.0414488       0.207627                   313.992   315.011            0.207586\n",
       "6        0.100028                    0.789457           3.89248     4.02133            0.937346         0.87019     0.968376                    0.926583            0.194618        0.402245                   289.248   302.133            0.398078\n",
       "7        0.150026                    0.651195           3.22673     3.75652            0.777027         0.720218    0.904606                    0.857809            0.161331        0.563576                   222.673   275.652            0.544725\n",
       "8        0.200025                    0.519115           2.50996     3.44493            0.604423         0.583481    0.829572                    0.789237            0.125494        0.68907                    150.996   244.493            0.644167\n",
       "9        0.300021                    0.304303           1.73835     2.87613            0.418612         0.402779    0.692599                    0.660431            0.17383         0.8629                     73.8352   187.613            0.74142\n",
       "10       0.400018                    0.158467           0.913177    2.38543            0.219902         0.226924    0.574434                    0.552062            0.0913149       0.954215                   -8.68231  138.543            0.729984\n",
       "11       0.500015                    0.072239           0.326499    1.97367            0.0786241        0.111159    0.475278                    0.463887            0.0326489       0.986864                   -67.3501  97.3667            0.641273\n",
       "12       0.600012                    0.0312478          0.104582    1.66217            0.0251843        0.0486476   0.400266                    0.394684            0.0104578       0.997322                   -89.5418  66.2169            0.523333\n",
       "13       0.700009                    0.0143291          0.0216816   1.42782            0.00522113       0.0214481   0.343834                    0.341367            0.00216809      0.99949                    -97.8318  42.7824            0.394474\n",
       "14       0.800006                    0.00725448         0.00510155  1.24999            0.0012285        0.0103919   0.30101                     0.299997            0.000510139     1                          -99.4898  24.999             0.26343\n",
       "15       0.900003                    0.00347433         0           1.11111            0                0.00517905  0.267565                    0.26724             0               1                          -100      11.1107            0.131715\n",
       "16       1                           0.000363483        0           1                  0                0.00240433  0.24081                     0.240758            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.09076467337180787\n",
       "RMSE: 0.3012717599971957\n",
       "LogLoss: 0.28598910685141826\n",
       "Mean Per-Class Error: 0.16988825283166362\n",
       "AUC: 0.9246906817908851\n",
       "AUCPR: 0.819319713891667\n",
       "Gini: 0.8493813635817702\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35521602618575066\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      21923  2797  0.1131   (2797.0/24720.0)\n",
       "1      1777   6064  0.2266   (1777.0/7841.0)\n",
       "Total  23700  8861  0.1405   (4574.0/32561.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.355216     0.726141  214\n",
       "max f2                       0.140025     0.803554  302\n",
       "max f0point5                 0.614291     0.755937  125\n",
       "max accuracy                 0.516023     0.870244  157\n",
       "max precision                0.994733     1         0\n",
       "max recall                   0.00285428   1         396\n",
       "max specificity              0.994733     1         0\n",
       "max absolute_mcc             0.403543     0.635876  197\n",
       "max min_per_class_accuracy   0.262433     0.83754   249\n",
       "max mean_per_class_accuracy  0.241912     0.839518  257\n",
       "max tns                      0.994733     24720     0\n",
       "max fns                      0.994733     7759      0\n",
       "max fps                      0.00147532   24720     399\n",
       "max tps                      0.00285428   7841      396\n",
       "max tnr                      0.994733     1         0\n",
       "max fnr                      0.994733     0.989542  0\n",
       "max fpr                      0.00147532   1         399\n",
       "max tpr                      0.00285428   1         396\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.08 %, avg score: 24.00 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010012                    0.991402           4.15266     4.15266            1                0.993189    1                           0.993189            0.0415763       0.0415763                  315.266   315.266            0.0415763\n",
       "2        0.020024                    0.987297           4.12718     4.13992            0.993865         0.989459    0.996933                    0.991324            0.0413213       0.0828976                  312.718   313.992            0.0828167\n",
       "3        0.0300052                   0.981213           4.11433     4.13141            0.990769         0.984514    0.994882                    0.989059            0.0410662       0.123964                   311.433   313.141            0.123762\n",
       "4        0.0400172                   0.970792           4.12718     4.13035            0.993865         0.976707    0.994628                    0.985968            0.0413213       0.165285                   312.718   313.035            0.165002\n",
       "5        0.0500292                   0.950426           4.13992     4.13227            0.996933         0.962231    0.995089                    0.981218            0.0414488       0.206734                   313.992   313.227            0.20641\n",
       "6        0.100028                    0.784915           3.53537     3.83391            0.851351         0.862702    0.923242                    0.921978            0.176763        0.383497                   253.537   283.391            0.373384\n",
       "7        0.150026                    0.640314           2.87472     3.51425            0.69226          0.713406    0.846264                    0.852469            0.143732        0.527229                   187.472   251.425            0.496848\n",
       "8        0.200025                    0.510624           2.36712     3.22751            0.570025         0.576267    0.777215                    0.783429            0.118352        0.645581                   136.712   222.751            0.586884\n",
       "9        0.300021                    0.301489           1.65035     2.70184            0.39742          0.401118    0.65063                     0.656005            0.16503         0.810611                   65.035    170.184            0.672545\n",
       "10       0.400018                    0.160228           0.983323    2.27225            0.236794         0.226576    0.547179                    0.548656            0.0983293       0.90894                    -1.66769  127.225            0.670348\n",
       "11       0.500015                    0.0750068          0.545866    1.92699            0.13145          0.113443    0.464038                    0.461619            0.0545849       0.963525                   -45.4134  92.6991            0.610532\n",
       "12       0.600012                    0.0324734          0.218091    1.64219            0.0525184        0.0508273   0.395455                    0.393157            0.0218084       0.985334                   -78.1909  64.2189            0.507542\n",
       "13       0.700009                    0.0152883          0.0982048   1.42163            0.0236486        0.0225705   0.342342                    0.340218            0.00982018      0.995154                   -90.1795  42.1629            0.388762\n",
       "14       0.800006                    0.00755018         0.0357108   1.2484             0.00859951       0.0109297   0.300626                    0.299059            0.00357097      0.998725                   -96.4289  24.8396            0.261751\n",
       "15       0.900003                    0.00359462         0.0102031   1.11082            0.002457         0.00535194  0.267497                    0.266426            0.00102028      0.999745                   -98.9797  11.0824            0.131379\n",
       "16       1                           0.00032544         0.00255077  1                  0.000614251      0.00251784  0.24081                     0.240036            0.00025507      1                          -99.7449  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.860109   0.00449248  0.856595      0.857187      0.856726      0.865326      0.864711\n",
       "auc                      0.924569   0.00454247  0.928191      0.926695      0.916986      0.923795      0.927177\n",
       "err                      0.139891   0.00449248  0.143405      0.142813      0.143274      0.134674      0.135289\n",
       "err_count                911        29.2831     934           930           933           877           881\n",
       "f0point5                 0.701263   0.0115764   0.70137       0.688153      0.691278      0.713083      0.712432\n",
       "f1                       0.727542   0.0129064   0.737345      0.718182      0.710698      0.730071      0.741415\n",
       "f2                       0.756029   0.0189628   0.777211      0.750951      0.73124       0.747888      0.772855\n",
       "lift_top_group           4.15474    0.103193    4.00554       4.25621       4.23682       4.17436       4.10076\n",
       "logloss                  0.286223   0.00617988  0.283765      0.279098      0.29565       0.288181      0.284419\n",
       "max_per_class_error      0.223602   0.0248165   0.193727      0.22549       0.254392      0.239744      0.20466\n",
       "mcc                      0.636371   0.0145571   0.644151      0.626186      0.616955      0.641438      0.653126\n",
       "mean_per_class_accuracy  0.831447   0.00935532  0.839805      0.828544      0.818332      0.829341      0.841212\n",
       "mean_per_class_error     0.168553   0.00935532  0.160195      0.171456      0.181668      0.170659      0.158788\n",
       "mse                      0.0908619  0.00175487  0.0901266     0.0889858     0.093492      0.0916711     0.0900341\n",
       "pr_auc                   0.819048   0.0109963   0.83473       0.819415      0.805147      0.813387      0.822561\n",
       "precision                0.684841   0.0131621   0.679275      0.669492      0.67891       0.702191      0.694338\n",
       "r2                       0.502769   0.014423    0.518881      0.504944      0.481515      0.496782      0.511722\n",
       "recall                   0.776397   0.0248165   0.806273      0.77451       0.745608      0.760256      0.79534\n",
       "rmse                     0.301422   0.00290386  0.300211      0.298305      0.305765      0.302772      0.300057\n",
       "specificity              0.886496   0.00937997  0.873337      0.882577      0.891055      0.898425      0.887084\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-10-20 18:27:36  20.514 sec  0                  0.427575         0.552011            0.5             0.24081            1                0.75919\n",
       "    2023-10-20 18:27:36  20.884 sec  5                  0.358067         0.413902            0.923149        0.81191            4.15266          0.14198\n",
       "    2023-10-20 18:27:37  21.111 sec  10                 0.325043         0.351823            0.927453        0.822411           4.15266          0.142164\n",
       "    2023-10-20 18:27:37  21.338 sec  15                 0.310133         0.319826            0.929346        0.827467           4.15266          0.138171\n",
       "    2023-10-20 18:27:37  21.617 sec  20                 0.300814         0.29773             0.93262         0.834101           4.15266          0.134148\n",
       "    2023-10-20 18:27:37  21.843 sec  25                 0.296002         0.285026            0.934852        0.83835            4.15266          0.134087\n",
       "    2023-10-20 18:27:38  22.070 sec  30                 0.291902         0.275374            0.937543        0.844217           4.15266          0.130094\n",
       "    2023-10-20 18:27:38  22.330 sec  35                 0.288717         0.268206            0.939815        0.849048           4.15266          0.125764\n",
       "    2023-10-20 18:27:38  22.888 sec  40                 0.285956         0.262212            0.941844        0.853718           4.15266          0.124413\n",
       "    2023-10-20 18:27:39  23.154 sec  45                 0.283899         0.25761             0.943387        0.857112           4.15266          0.121434\n",
       "    2023-10-20 18:27:39  23.394 sec  50                 0.281971         0.253555            0.944875        0.860407           4.15266          0.119222\n",
       "    2023-10-20 18:27:39  23.650 sec  55                 0.280245         0.250001            0.946298        0.863312           4.15266          0.118117\n",
       "    2023-10-20 18:27:39  23.929 sec  60                 0.278158         0.246472            0.94796         0.867161           4.15266          0.115783\n",
       "    2023-10-20 18:27:40  24.275 sec  65                 0.276298         0.243149            0.949431        0.870529           4.15266          0.114278\n",
       "    2023-10-20 18:27:40  24.485 sec  70                 0.274597         0.240138            0.950781        0.873559           4.15266          0.114186\n",
       "    2023-10-20 18:27:40  24.609 sec  72                 0.273843         0.238896            0.951434        0.874951           4.15266          0.111698\n",
       "\n",
       "Variable Importances: \n",
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "relationship    4602.74                1                    0.286272\n",
       "capital_gain    3140.77                0.682369             0.195343\n",
       "education       2609.79                0.567008             0.162319\n",
       "occupation      1140.88                0.247871             0.0709584\n",
       "age             1114.52                0.242143             0.0693187\n",
       "marital_status  1045.37                0.227119             0.0650179\n",
       "capital_loss    740.771                0.160941             0.0460729\n",
       "hours_per_week  622.132                0.135165             0.0386941\n",
       "workclass       353.184                0.0767333            0.0219666\n",
       "fnlwgt          329.372                0.0715599            0.0204856\n",
       "native_country  275.415                0.059837             0.0171297\n",
       "sex             65.1697                0.0141589            0.00405329\n",
       "race            38.0887                0.00827523           0.00236897\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eac30-5a4b-4d9f-b9f9-639949917577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
